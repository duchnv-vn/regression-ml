{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-27T17:21:22.574516Z",
     "start_time": "2025-05-27T17:20:15.135953Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def predict(X, w):\n",
    "    return np.matmul(X, w)\n",
    "\n",
    "\n",
    "def loss(X, Y, w):\n",
    "    return np.average((predict(X, w) - Y) ** 2)\n",
    "\n",
    "\n",
    "def gradient(X, Y, w):\n",
    "    return 2 * (np.matmul(X.T, (predict(X, w) - Y))) / X.shape[0]\n",
    "\n",
    "\n",
    "def train(X, Y, iter, lr):\n",
    "    w = np.zeros((X.shape[1], 1))\n",
    "    for i in range(iter):\n",
    "        print(\"Iteration %4d => Loss: %.20f\" % (i, loss(X, Y, w)))\n",
    "        w -= gradient(X, Y, w) * lr\n",
    "    return w\n",
    "\n",
    "\n",
    "data = np.loadtxt('life-expectancy-without-country-names.txt', skiprows=1)\n",
    "X = data[:, :-1]\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "Y = data[:, -1].reshape(-1, 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "w = train(X, Y, iter=50000, lr=0.0001)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 4)\n",
      "(167, 1)\n",
      "Iteration    0 => Loss: 5148.41185360395593306748\n",
      "Iteration    1 => Loss: 3235.55091165184740020777\n",
      "Iteration    2 => Loss: 2041.87377112154490532703\n",
      "Iteration    3 => Loss: 1296.87126159225840638101\n",
      "Iteration    4 => Loss: 831.80092696140832231322\n",
      "Iteration    5 => Loss: 541.39875409119906635169\n",
      "Iteration    6 => Loss: 359.99684973918056130060\n",
      "Iteration    7 => Loss: 246.62674383666094968248\n",
      "Iteration    8 => Loss: 175.72743974809259270842\n",
      "Iteration    9 => Loss: 131.34941448978884181997\n",
      "Iteration   10 => Loss: 103.53922121568797365398\n",
      "Iteration   11 => Loss: 86.08425313668719525140\n",
      "Iteration   12 => Loss: 75.10592201480093876853\n",
      "Iteration   13 => Loss: 68.18204987356072876992\n",
      "Iteration   14 => Loss: 63.79937154535650023490\n",
      "Iteration   15 => Loss: 61.01195678492182139507\n",
      "Iteration   16 => Loss: 59.22808622781101206556\n",
      "Iteration   17 => Loss: 58.07726049113832544890\n",
      "Iteration   18 => Loss: 57.32720098832210453565\n",
      "Iteration   19 => Loss: 56.83204047531999236753\n",
      "Iteration   20 => Loss: 56.49997446875310203040\n",
      "Iteration   21 => Loss: 56.27305668191329601768\n",
      "Iteration   22 => Loss: 56.11457375000028235945\n",
      "Iteration   23 => Loss: 56.00115127806705572766\n",
      "Iteration   24 => Loss: 55.91781418497627242914\n",
      "Iteration   25 => Loss: 55.85489241042252217539\n",
      "Iteration   26 => Loss: 55.80607985712944696388\n",
      "Iteration   27 => Loss: 55.76721449194762669777\n",
      "Iteration   28 => Loss: 55.73550979557550988375\n",
      "Iteration   29 => Loss: 55.70906901360941532175\n",
      "Iteration   30 => Loss: 55.68657686607593859662\n",
      "Iteration   31 => Loss: 55.66710283130019831788\n",
      "Iteration   32 => Loss: 55.64997476157132894059\n",
      "Iteration   33 => Loss: 55.63469698271503460774\n",
      "Iteration   34 => Loss: 55.62089665251528458612\n",
      "Iteration   35 => Loss: 55.60828817221512565538\n",
      "Iteration   36 => Loss: 55.59664921407802751219\n",
      "Iteration   37 => Loss: 55.58580429061009908764\n",
      "Iteration   38 => Loss: 55.57561327461591815791\n",
      "Iteration   39 => Loss: 55.56596321288066064881\n",
      "Iteration   40 => Loss: 55.55676236548747226607\n",
      "Iteration   41 => Loss: 55.54793577602653442682\n",
      "Iteration   42 => Loss: 55.53942191553606022580\n",
      "Iteration   43 => Loss: 55.53117009518307156668\n",
      "Iteration   44 => Loss: 55.52313844091718664231\n",
      "Iteration   45 => Loss: 55.51529228735854815113\n",
      "Iteration   46 => Loss: 55.50760289041595996196\n",
      "Iteration   47 => Loss: 55.50004638639105536413\n",
      "Iteration   48 => Loss: 55.49260294454574449219\n",
      "Iteration   49 => Loss: 55.48525607342922683074\n",
      "Iteration   50 => Loss: 55.47799205067510541767\n",
      "Iteration   51 => Loss: 55.47079945277384638302\n",
      "Iteration   52 => Loss: 55.46366876633220499571\n",
      "Iteration   53 => Loss: 55.45659206609404634492\n",
      "Iteration   54 => Loss: 55.44956274787720218455\n",
      "Iteration   55 => Loss: 55.44257530682167356417\n",
      "Iteration   56 => Loss: 55.43562515311209182300\n",
      "Iteration   57 => Loss: 55.42870845874797680608\n",
      "Iteration   58 => Loss: 55.42182203007273955109\n",
      "Iteration   59 => Loss: 55.41496320169432010516\n",
      "Iteration   60 => Loss: 55.40812974818491909446\n",
      "Iteration   61 => Loss: 55.40131981056589438595\n",
      "Iteration   62 => Loss: 55.39453183509329647904\n",
      "Iteration   63 => Loss: 55.38776452227985203081\n",
      "Iteration   64 => Loss: 55.38101678443901221272\n",
      "Iteration   65 => Loss: 55.37428771032343632896\n",
      "Iteration   66 => Loss: 55.36757653567165959885\n",
      "Iteration   67 => Loss: 55.36088261867450910358\n",
      "Iteration   68 => Loss: 55.35420541953932627166\n",
      "Iteration   69 => Loss: 55.34754448346706823259\n",
      "Iteration   70 => Loss: 55.34089942647205617732\n",
      "Iteration   71 => Loss: 55.33426992356961449104\n",
      "Iteration   72 => Loss: 55.32765569893621915298\n",
      "Iteration   73 => Loss: 55.32105651771239251957\n",
      "Iteration   74 => Loss: 55.31447217917443026636\n",
      "Iteration   75 => Loss: 55.30790251104630073087\n",
      "Iteration   76 => Loss: 55.30134736476074408529\n",
      "Iteration   77 => Loss: 55.29480661151236375872\n",
      "Iteration   78 => Loss: 55.28828013896883675216\n",
      "Iteration   79 => Loss: 55.28176784853183534096\n",
      "Iteration   80 => Loss: 55.27526965305494144332\n",
      "Iteration   81 => Loss: 55.26878547494263216322\n",
      "Iteration   82 => Loss: 55.26231524456655819222\n",
      "Iteration   83 => Loss: 55.25585889894637858788\n",
      "Iteration   84 => Loss: 55.24941638065072879726\n",
      "Iteration   85 => Loss: 55.24298763688157265506\n",
      "Iteration   86 => Loss: 55.23657261871149160015\n",
      "Iteration   87 => Loss: 55.23017128044839552103\n",
      "Iteration   88 => Loss: 55.22378357910604762537\n",
      "Iteration   89 => Loss: 55.21740947396318688334\n",
      "Iteration   90 => Loss: 55.21104892619601400838\n",
      "Iteration   91 => Loss: 55.20470189857231702035\n",
      "Iteration   92 => Loss: 55.19836835519625850566\n",
      "Iteration   93 => Loss: 55.19204826129609386953\n",
      "Iteration   94 => Loss: 55.18574158304719645685\n",
      "Iteration   95 => Loss: 55.17944828742442098246\n",
      "Iteration   96 => Loss: 55.17316834207930043021\n",
      "Iteration   97 => Loss: 55.16690171523787000751\n",
      "Iteration   98 => Loss: 55.16064837561498279683\n",
      "Iteration   99 => Loss: 55.15440829234358943722\n",
      "Iteration  100 => Loss: 55.14818143491520885391\n",
      "Iteration  101 => Loss: 55.14196777313075870097\n",
      "Iteration  102 => Loss: 55.13576727705925151213\n",
      "Iteration  103 => Loss: 55.12957991700360338427\n",
      "Iteration  104 => Loss: 55.12340566347198489439\n",
      "Iteration  105 => Loss: 55.11724448715387580933\n",
      "Iteration  106 => Loss: 55.11109635890036173578\n",
      "Iteration  107 => Loss: 55.10496124970745057681\n",
      "Iteration  108 => Loss: 55.09883913070215299967\n",
      "Iteration  109 => Loss: 55.09272997313104980321\n",
      "Iteration  110 => Loss: 55.08663374835061432577\n",
      "Iteration  111 => Loss: 55.08055042781901988747\n",
      "Iteration  112 => Loss: 55.07447998308963832415\n",
      "Iteration  113 => Loss: 55.06842238580521353697\n",
      "Iteration  114 => Loss: 55.06237760769318612120\n",
      "Iteration  115 => Loss: 55.05634562056185643542\n",
      "Iteration  116 => Loss: 55.05032639629685320415\n",
      "Iteration  117 => Loss: 55.04431990685858266943\n",
      "Iteration  118 => Loss: 55.03832612427972748037\n",
      "Iteration  119 => Loss: 55.03234502066332822778\n",
      "Iteration  120 => Loss: 55.02637656818114919588\n",
      "Iteration  121 => Loss: 55.02042073907219332796\n",
      "Iteration  122 => Loss: 55.01447750564156535802\n",
      "Iteration  123 => Loss: 55.00854684025948415638\n",
      "Iteration  124 => Loss: 55.00262871536031639152\n",
      "Iteration  125 => Loss: 54.99672310344189440912\n",
      "Iteration  126 => Loss: 54.99082997706482700551\n",
      "Iteration  127 => Loss: 54.98494930885204468041\n",
      "Iteration  128 => Loss: 54.97908107148820988641\n",
      "Iteration  129 => Loss: 54.97322523771926938707\n",
      "Iteration  130 => Loss: 54.96738178035221977780\n",
      "Iteration  131 => Loss: 54.96155067225459589508\n",
      "Iteration  132 => Loss: 54.95573188635430739168\n",
      "Iteration  133 => Loss: 54.94992539563929767610\n",
      "Iteration  134 => Loss: 54.94413117315728101175\n",
      "Iteration  135 => Loss: 54.93834919201556488133\n",
      "Iteration  136 => Loss: 54.93257942538086524564\n",
      "Iteration  137 => Loss: 54.92682184647892285057\n",
      "Iteration  138 => Loss: 54.92107642859460980844\n",
      "Iteration  139 => Loss: 54.91534314507150327245\n",
      "Iteration  140 => Loss: 54.90962196931182148774\n",
      "Iteration  141 => Loss: 54.90391287477628878833\n",
      "Iteration  142 => Loss: 54.89821583498391532885\n",
      "Iteration  143 => Loss: 54.89253082351181944887\n",
      "Iteration  144 => Loss: 54.88685781399524898916\n",
      "Iteration  145 => Loss: 54.88119678012726865290\n",
      "Iteration  146 => Loss: 54.87554769565866763514\n",
      "Iteration  147 => Loss: 54.86991053439786014678\n",
      "Iteration  148 => Loss: 54.86428527021065093550\n",
      "Iteration  149 => Loss: 54.85867187702028502372\n",
      "Iteration  150 => Loss: 54.85307032880711375356\n",
      "Iteration  151 => Loss: 54.84748059960860899764\n",
      "Iteration  152 => Loss: 54.84190266351913578546\n",
      "Iteration  153 => Loss: 54.83633649468987414366\n",
      "Iteration  154 => Loss: 54.83078206732869830375\n",
      "Iteration  155 => Loss: 54.82523935570005590989\n",
      "Iteration  156 => Loss: 54.81970833412477617230\n",
      "Iteration  157 => Loss: 54.81418897698002723473\n",
      "Iteration  158 => Loss: 54.80868125869912432790\n",
      "Iteration  159 => Loss: 54.80318515377142318812\n",
      "Iteration  160 => Loss: 54.79770063674229163553\n",
      "Iteration  161 => Loss: 54.79222768221278982992\n",
      "Iteration  162 => Loss: 54.78676626483974132498\n",
      "Iteration  163 => Loss: 54.78131635933549148376\n",
      "Iteration  164 => Loss: 54.77587794046781510815\n",
      "Iteration  165 => Loss: 54.77045098305983117370\n",
      "Iteration  166 => Loss: 54.76503546198985361571\n",
      "Iteration  167 => Loss: 54.75963135219124922060\n",
      "Iteration  168 => Loss: 54.75423862865230972830\n",
      "Iteration  169 => Loss: 54.74885726641623051592\n",
      "Iteration  170 => Loss: 54.74348724058084769695\n",
      "Iteration  171 => Loss: 54.73812852629861680498\n",
      "Iteration  172 => Loss: 54.73278109877646357972\n",
      "Iteration  173 => Loss: 54.72744493327568449104\n",
      "Iteration  174 => Loss: 54.72212000511174068151\n",
      "Iteration  175 => Loss: 54.71680628965428638821\n",
      "Iteration  176 => Loss: 54.71150376232692735812\n",
      "Iteration  177 => Loss: 54.70621239860712847758\n",
      "Iteration  178 => Loss: 54.70093217402615692890\n",
      "Iteration  179 => Loss: 54.69566306416889034381\n",
      "Iteration  180 => Loss: 54.69040504467373864372\n",
      "Iteration  181 => Loss: 54.68515809123250193124\n",
      "Iteration  182 => Loss: 54.67992217959028522500\n",
      "Iteration  183 => Loss: 54.67469728554535635112\n",
      "Iteration  184 => Loss: 54.66948338494903225637\n",
      "Iteration  185 => Loss: 54.66428045370557953220\n",
      "Iteration  186 => Loss: 54.65908846777208651702\n",
      "Iteration  187 => Loss: 54.65390740315832829310\n",
      "Iteration  188 => Loss: 54.64873723592670273774\n",
      "Iteration  189 => Loss: 54.64357794219203157127\n",
      "Iteration  190 => Loss: 54.63842949812153193534\n",
      "Iteration  191 => Loss: 54.63329187993468849527\n",
      "Iteration  192 => Loss: 54.62816506390307580432\n",
      "Iteration  193 => Loss: 54.62304902635030856572\n",
      "Iteration  194 => Loss: 54.61794374365186399700\n",
      "Iteration  195 => Loss: 54.61284919223506051367\n",
      "Iteration  196 => Loss: 54.60776534857886588270\n",
      "Iteration  197 => Loss: 54.60269218921382616827\n",
      "Iteration  198 => Loss: 54.59762969072188099062\n",
      "Iteration  199 => Loss: 54.59257782973638484236\n",
      "Iteration  200 => Loss: 54.58753658294188682021\n",
      "Iteration  201 => Loss: 54.58250592707399562187\n",
      "Iteration  202 => Loss: 54.57748583891940796775\n",
      "Iteration  203 => Loss: 54.57247629531564570016\n",
      "Iteration  204 => Loss: 54.56747727315099893985\n",
      "Iteration  205 => Loss: 54.56248874936445503181\n",
      "Iteration  206 => Loss: 54.55751070094557775292\n",
      "Iteration  207 => Loss: 54.55254310493433678175\n",
      "Iteration  208 => Loss: 54.54758593842097980087\n",
      "Iteration  209 => Loss: 54.54263917854609644564\n",
      "Iteration  210 => Loss: 54.53770280250031277092\n",
      "Iteration  211 => Loss: 54.53277678752424151298\n",
      "Iteration  212 => Loss: 54.52786111090843945703\n",
      "Iteration  213 => Loss: 54.52295574999321559062\n",
      "Iteration  214 => Loss: 54.51806068216854583852\n",
      "Iteration  215 => Loss: 54.51317588487401621933\n",
      "Iteration  216 => Loss: 54.50830133559863099890\n",
      "Iteration  217 => Loss: 54.50343701188072031982\n",
      "Iteration  218 => Loss: 54.49858289130787625254\n",
      "Iteration  219 => Loss: 54.49373895151686042482\n",
      "Iteration  220 => Loss: 54.48890517019339796434\n",
      "Iteration  221 => Loss: 54.48408152507217749871\n",
      "Iteration  222 => Loss: 54.47926799393665220350\n",
      "Iteration  223 => Loss: 54.47446455461903269679\n",
      "Iteration  224 => Loss: 54.46967118500007387638\n",
      "Iteration  225 => Loss: 54.46488786300902518178\n",
      "Iteration  226 => Loss: 54.46011456662355243452\n",
      "Iteration  227 => Loss: 54.45535127386958151874\n",
      "Iteration  228 => Loss: 54.45059796282118469435\n",
      "Iteration  229 => Loss: 54.44585461160053085905\n",
      "Iteration  230 => Loss: 54.44112119837775765063\n",
      "Iteration  231 => Loss: 54.43639770137079381129\n",
      "Iteration  232 => Loss: 54.43168409884537339849\n",
      "Iteration  233 => Loss: 54.42698036911487236011\n",
      "Iteration  234 => Loss: 54.42228649054023037479\n",
      "Iteration  235 => Loss: 54.41760244152972347820\n",
      "Iteration  236 => Loss: 54.41292820053906353905\n",
      "Iteration  237 => Loss: 54.40826374607115667459\n",
      "Iteration  238 => Loss: 54.40360905667601798541\n",
      "Iteration  239 => Loss: 54.39896411095070760666\n",
      "Iteration  240 => Loss: 54.39432888753920281033\n",
      "Iteration  241 => Loss: 54.38970336513224879127\n",
      "Iteration  242 => Loss: 54.38508752246738708891\n",
      "Iteration  243 => Loss: 54.38048133832872110816\n",
      "Iteration  244 => Loss: 54.37588479154682374883\n",
      "Iteration  245 => Loss: 54.37129786099878003824\n",
      "Iteration  246 => Loss: 54.36672052560786738695\n",
      "Iteration  247 => Loss: 54.36215276434364085389\n",
      "Iteration  248 => Loss: 54.35759455622172708900\n",
      "Iteration  249 => Loss: 54.35304588030376748975\n",
      "Iteration  250 => Loss: 54.34850671569729030352\n",
      "Iteration  251 => Loss: 54.34397704155564667872\n",
      "Iteration  252 => Loss: 54.33945683707784013450\n",
      "Iteration  253 => Loss: 54.33494608150851945538\n",
      "Iteration  254 => Loss: 54.33044475413780105555\n",
      "Iteration  255 => Loss: 54.32595283430124766255\n",
      "Iteration  256 => Loss: 54.32147030137966225993\n",
      "Iteration  257 => Loss: 54.31699713479907387637\n",
      "Iteration  258 => Loss: 54.31253331403063100424\n",
      "Iteration  259 => Loss: 54.30807881859046659656\n",
      "Iteration  260 => Loss: 54.30363362803961280179\n",
      "Iteration  261 => Loss: 54.29919772198388727702\n",
      "Iteration  262 => Loss: 54.29477108007388608257\n",
      "Iteration  263 => Loss: 54.29035368200473499201\n",
      "Iteration  264 => Loss: 54.28594550751612501927\n",
      "Iteration  265 => Loss: 54.28154653639214188843\n",
      "Iteration  266 => Loss: 54.27715674846115234686\n",
      "Iteration  267 => Loss: 54.27277612359583258694\n",
      "Iteration  268 => Loss: 54.26840464171287692352\n",
      "Iteration  269 => Loss: 54.26404228277308305906\n",
      "Iteration  270 => Loss: 54.25968902678113181537\n",
      "Iteration  271 => Loss: 54.25534485378555871193\n",
      "Iteration  272 => Loss: 54.25100974387864027904\n",
      "Iteration  273 => Loss: 54.24668367719626616008\n",
      "Iteration  274 => Loss: 54.24236663391788226818\n",
      "Iteration  275 => Loss: 54.23805859426643394272\n",
      "Iteration  276 => Loss: 54.23375953850813147028\n",
      "Iteration  277 => Loss: 54.22946944695251403346\n",
      "Iteration  278 => Loss: 54.22518829995226496976\n",
      "Iteration  279 => Loss: 54.22091607790311940107\n",
      "Iteration  280 => Loss: 54.21665276124382870648\n",
      "Iteration  281 => Loss: 54.21239833045597578121\n",
      "Iteration  282 => Loss: 54.20815276606397503656\n",
      "Iteration  283 => Loss: 54.20391604863490897515\n",
      "Iteration  284 => Loss: 54.19968815877845003115\n",
      "Iteration  285 => Loss: 54.19546907714680372692\n",
      "Iteration  286 => Loss: 54.19125878443459498612\n",
      "Iteration  287 => Loss: 54.18705726137874023607\n",
      "Iteration  288 => Loss: 54.18286448875839056427\n",
      "Iteration  289 => Loss: 54.17868044739483224248\n",
      "Iteration  290 => Loss: 54.17450511815142277783\n",
      "Iteration  291 => Loss: 54.17033848193342038257\n",
      "Iteration  292 => Loss: 54.16618051968801239582\n",
      "Iteration  293 => Loss: 54.16203121240403817183\n",
      "Iteration  294 => Loss: 54.15789054111213118858\n",
      "Iteration  295 => Loss: 54.15375848688448456869\n",
      "Iteration  296 => Loss: 54.14963503083471607624\n",
      "Iteration  297 => Loss: 54.14552015411787522225\n",
      "Iteration  298 => Loss: 54.14141383793039352668\n",
      "Iteration  299 => Loss: 54.13731606350982872300\n",
      "Iteration  300 => Loss: 54.13322681213491449626\n",
      "Iteration  301 => Loss: 54.12914606512541837446\n",
      "Iteration  302 => Loss: 54.12507380384203514723\n",
      "Iteration  303 => Loss: 54.12101000968636554944\n",
      "Iteration  304 => Loss: 54.11695466410078125818\n",
      "Iteration  305 => Loss: 54.11290774856825436245\n",
      "Iteration  306 => Loss: 54.10886924461241420659\n",
      "Iteration  307 => Loss: 54.10483913379741238714\n",
      "Iteration  308 => Loss: 54.10081739772775222264\n",
      "Iteration  309 => Loss: 54.09680401804832428070\n",
      "Iteration  310 => Loss: 54.09279897644422163694\n",
      "Iteration  311 => Loss: 54.08880225464066171526\n",
      "Iteration  312 => Loss: 54.08481383440301470955\n",
      "Iteration  313 => Loss: 54.08083369753651936662\n",
      "Iteration  314 => Loss: 54.07686182588632561874\n",
      "Iteration  315 => Loss: 54.07289820133746616193\n",
      "Iteration  316 => Loss: 54.06894280581457934431\n",
      "Iteration  317 => Loss: 54.06499562128195890409\n",
      "Iteration  318 => Loss: 54.06105662974346159899\n",
      "Iteration  319 => Loss: 54.05712581324235799229\n",
      "Iteration  320 => Loss: 54.05320315386132534741\n",
      "Iteration  321 => Loss: 54.04928863372226999218\n",
      "Iteration  322 => Loss: 54.04538223498634863518\n",
      "Iteration  323 => Loss: 54.04148393985375520288\n",
      "Iteration  324 => Loss: 54.03759373056374215594\n",
      "Iteration  325 => Loss: 54.03371158939449969694\n",
      "Iteration  326 => Loss: 54.02983749866304918896\n",
      "Iteration  327 => Loss: 54.02597144072522183933\n",
      "Iteration  328 => Loss: 54.02211339797541000962\n",
      "Iteration  329 => Loss: 54.01826335284676616766\n",
      "Iteration  330 => Loss: 54.01442128781084761613\n",
      "Iteration  331 => Loss: 54.01058718537762359801\n",
      "Iteration  332 => Loss: 54.00676102809546108574\n",
      "Iteration  333 => Loss: 54.00294279855096135634\n",
      "Iteration  334 => Loss: 53.99913247936888893719\n",
      "Iteration  335 => Loss: 53.99533005321208634086\n",
      "Iteration  336 => Loss: 53.99153550278144564345\n",
      "Iteration  337 => Loss: 53.98774881081575927055\n",
      "Iteration  338 => Loss: 53.98396996009163473218\n",
      "Iteration  339 => Loss: 53.98019893342349462273\n",
      "Iteration  340 => Loss: 53.97643571366336345818\n",
      "Iteration  341 => Loss: 53.97268028370088188694\n",
      "Iteration  342 => Loss: 53.96893262646323563558\n",
      "Iteration  343 => Loss: 53.96519272491501340028\n",
      "Iteration  344 => Loss: 53.96146056205809315998\n",
      "Iteration  345 => Loss: 53.95773612093175586324\n",
      "Iteration  346 => Loss: 53.95401938461228752431\n",
      "Iteration  347 => Loss: 53.95031033621320659677\n",
      "Iteration  348 => Loss: 53.94660895888497265105\n",
      "Iteration  349 => Loss: 53.94291523581500769069\n",
      "Iteration  350 => Loss: 53.93922915022762509807\n",
      "Iteration  351 => Loss: 53.93555068538387331500\n",
      "Iteration  352 => Loss: 53.93187982458150031562\n",
      "Iteration  353 => Loss: 53.92821655115483991949\n",
      "Iteration  354 => Loss: 53.92456084847486152967\n",
      "Iteration  355 => Loss: 53.92091269994882196670\n",
      "Iteration  356 => Loss: 53.91727208902050705319\n",
      "Iteration  357 => Loss: 53.91363899916994739669\n",
      "Iteration  358 => Loss: 53.91001341391333312458\n",
      "Iteration  359 => Loss: 53.90639531680304230576\n",
      "Iteration  360 => Loss: 53.90278469142753436927\n",
      "Iteration  361 => Loss: 53.89918152141118667942\n",
      "Iteration  362 => Loss: 53.89558579041428032497\n",
      "Iteration  363 => Loss: 53.89199748213295038113\n",
      "Iteration  364 => Loss: 53.88841658029905090643\n",
      "Iteration  365 => Loss: 53.88484306868013362646\n",
      "Iteration  366 => Loss: 53.88127693107924187643\n",
      "Iteration  367 => Loss: 53.87771815133505270978\n",
      "Iteration  368 => Loss: 53.87416671332153583762\n",
      "Iteration  369 => Loss: 53.87062260094813836986\n",
      "Iteration  370 => Loss: 53.86708579815951480896\n",
      "Iteration  371 => Loss: 53.86355628893550573366\n",
      "Iteration  372 => Loss: 53.86003405729108806099\n",
      "Iteration  373 => Loss: 53.85651908727628267570\n",
      "Iteration  374 => Loss: 53.85301136297609048142\n",
      "Iteration  375 => Loss: 53.84951086851037160841\n",
      "Iteration  376 => Loss: 53.84601758803380988638\n",
      "Iteration  377 => Loss: 53.84253150573582047400\n",
      "Iteration  378 => Loss: 53.83905260584050722628\n",
      "Iteration  379 => Loss: 53.83558087260647795347\n",
      "Iteration  380 => Loss: 53.83211629032692968622\n",
      "Iteration  381 => Loss: 53.82865884332947103985\n",
      "Iteration  382 => Loss: 53.82520851597607958183\n",
      "Iteration  383 => Loss: 53.82176529266294551235\n",
      "Iteration  384 => Loss: 53.81832915782050008602\n",
      "Iteration  385 => Loss: 53.81490009591342271733\n",
      "Iteration  386 => Loss: 53.81147809144024307670\n",
      "Iteration  387 => Loss: 53.80806312893359688587\n",
      "Iteration  388 => Loss: 53.80465519296001986049\n",
      "Iteration  389 => Loss: 53.80125426811984823416\n",
      "Iteration  390 => Loss: 53.79786033904721165300\n",
      "Iteration  391 => Loss: 53.79447339040989106707\n",
      "Iteration  392 => Loss: 53.79109340690927609785\n",
      "Iteration  393 => Loss: 53.78772037328032951109\n",
      "Iteration  394 => Loss: 53.78435427429143800282\n",
      "Iteration  395 => Loss: 53.78099509474441219936\n",
      "Iteration  396 => Loss: 53.77764281947438718134\n",
      "Iteration  397 => Loss: 53.77429743334967326973\n",
      "Iteration  398 => Loss: 53.77095892127181286924\n",
      "Iteration  399 => Loss: 53.76762726817544546520\n",
      "Iteration  400 => Loss: 53.76430245902820814763\n",
      "Iteration  401 => Loss: 53.76098447883070718945\n",
      "Iteration  402 => Loss: 53.75767331261645409768\n",
      "Iteration  403 => Loss: 53.75436894545167376691\n",
      "Iteration  404 => Loss: 53.75107136243546079868\n",
      "Iteration  405 => Loss: 53.74778054869946686267\n",
      "Iteration  406 => Loss: 53.74449648940802859443\n",
      "Iteration  407 => Loss: 53.74121916975793311622\n",
      "Iteration  408 => Loss: 53.73794857497843935334\n",
      "Iteration  409 => Loss: 53.73468469033117145273\n",
      "Iteration  410 => Loss: 53.73142750111010457204\n",
      "Iteration  411 => Loss: 53.72817699264145829829\n",
      "Iteration  412 => Loss: 53.72493315028351190676\n",
      "Iteration  413 => Loss: 53.72169595942677489120\n",
      "Iteration  414 => Loss: 53.71846540549371695761\n",
      "Iteration  415 => Loss: 53.71524147393875381340\n",
      "Iteration  416 => Loss: 53.71202415024824006196\n",
      "Iteration  417 => Loss: 53.70881341994028446152\n",
      "Iteration  418 => Loss: 53.70560926856477124147\n",
      "Iteration  419 => Loss: 53.70241168170328194265\n",
      "Iteration  420 => Loss: 53.69922064496898173047\n",
      "Iteration  421 => Loss: 53.69603614400654834071\n",
      "Iteration  422 => Loss: 53.69285816449220760660\n",
      "Iteration  423 => Loss: 53.68968669213349187430\n",
      "Iteration  424 => Loss: 53.68652171266933237348\n",
      "Iteration  425 => Loss: 53.68336321186988868703\n",
      "Iteration  426 => Loss: 53.68021117553649190768\n",
      "Iteration  427 => Loss: 53.67706558950170148137\n",
      "Iteration  428 => Loss: 53.67392643962900677934\n",
      "Iteration  429 => Loss: 53.67079371181297631210\n",
      "Iteration  430 => Loss: 53.66766739197904456660\n",
      "Iteration  431 => Loss: 53.66454746608352621706\n",
      "Iteration  432 => Loss: 53.66143392011353085991\n",
      "Iteration  433 => Loss: 53.65832674008687774858\n",
      "Iteration  434 => Loss: 53.65522591205198921216\n",
      "Iteration  435 => Loss: 53.65213142208794749877\n",
      "Iteration  436 => Loss: 53.64904325630432424532\n",
      "Iteration  437 => Loss: 53.64596140084113073954\n",
      "Iteration  438 => Loss: 53.64288584186876107651\n",
      "Iteration  439 => Loss: 53.63981656558795663159\n",
      "Iteration  440 => Loss: 53.63675355822964263552\n",
      "Iteration  441 => Loss: 53.63369680605499212334\n",
      "Iteration  442 => Loss: 53.63064629535526250947\n",
      "Iteration  443 => Loss: 53.62760201245180269325\n",
      "Iteration  444 => Loss: 53.62456394369586831772\n",
      "Iteration  445 => Loss: 53.62153207546872835110\n",
      "Iteration  446 => Loss: 53.61850639418147324022\n",
      "Iteration  447 => Loss: 53.61548688627491543457\n",
      "Iteration  448 => Loss: 53.61247353821971017851\n",
      "Iteration  449 => Loss: 53.60946633651604997794\n",
      "Iteration  450 => Loss: 53.60646526769380670885\n",
      "Iteration  451 => Loss: 53.60347031831236819244\n",
      "Iteration  452 => Loss: 53.60048147496055293004\n",
      "Iteration  453 => Loss: 53.59749872425660299768\n",
      "Iteration  454 => Loss: 53.59452205284809167551\n",
      "Iteration  455 => Loss: 53.59155144741187370983\n",
      "Iteration  456 => Loss: 53.58858689465397162621\n",
      "Iteration  457 => Loss: 53.58562838130958994043\n",
      "Iteration  458 => Loss: 53.58267589414300857698\n",
      "Iteration  459 => Loss: 53.57972941994748339312\n",
      "Iteration  460 => Loss: 53.57678894554527460059\n",
      "Iteration  461 => Loss: 53.57385445778749755164\n",
      "Iteration  462 => Loss: 53.57092594355410142271\n",
      "Iteration  463 => Loss: 53.56800338975380526563\n",
      "Iteration  464 => Loss: 53.56508678332398432076\n",
      "Iteration  465 => Loss: 53.56217611123069843870\n",
      "Iteration  466 => Loss: 53.55927136046855707718\n",
      "Iteration  467 => Loss: 53.55637251806071219562\n",
      "Iteration  468 => Loss: 53.55347957105869483030\n",
      "Iteration  469 => Loss: 53.55059250654248614865\n",
      "Iteration  470 => Loss: 53.54771131162036112983\n",
      "Iteration  471 => Loss: 53.54483597342885303760\n",
      "Iteration  472 => Loss: 53.54196647913271789321\n",
      "Iteration  473 => Loss: 53.53910281592480657764\n",
      "Iteration  474 => Loss: 53.53624497102607193710\n",
      "Iteration  475 => Loss: 53.53339293168549772872\n",
      "Iteration  476 => Loss: 53.53054668518001335542\n",
      "Iteration  477 => Loss: 53.52770621881437307366\n",
      "Iteration  478 => Loss: 53.52487151992124125854\n",
      "Iteration  479 => Loss: 53.52204257586103608446\n",
      "Iteration  480 => Loss: 53.51921937402186557620\n",
      "Iteration  481 => Loss: 53.51640190181947787096\n",
      "Iteration  482 => Loss: 53.51359014669723279667\n",
      "Iteration  483 => Loss: 53.51078409612598818512\n",
      "Iteration  484 => Loss: 53.50798373760411408284\n",
      "Iteration  485 => Loss: 53.50518905865735064253\n",
      "Iteration  486 => Loss: 53.50240004683875838509\n",
      "Iteration  487 => Loss: 53.49961668972872530503\n",
      "Iteration  488 => Loss: 53.49683897493484607821\n",
      "Iteration  489 => Loss: 53.49406689009193627271\n",
      "Iteration  490 => Loss: 53.49130042286181918598\n",
      "Iteration  491 => Loss: 53.48853956093341821543\n",
      "Iteration  492 => Loss: 53.48578429202267869869\n",
      "Iteration  493 => Loss: 53.48303460387239027796\n",
      "Iteration  494 => Loss: 53.48029048425230769226\n",
      "Iteration  495 => Loss: 53.47755192095892340376\n",
      "Iteration  496 => Loss: 53.47481890181548891405\n",
      "Iteration  497 => Loss: 53.47209141467201476416\n",
      "Iteration  498 => Loss: 53.46936944740507158258\n",
      "Iteration  499 => Loss: 53.46665298791783271781\n",
      "Iteration  500 => Loss: 53.46394202413999607870\n",
      "Iteration  501 => Loss: 53.46123654402771308014\n",
      "Iteration  502 => Loss: 53.45853653556353179965\n",
      "Iteration  503 => Loss: 53.45584198675635434483\n",
      "Iteration  504 => Loss: 53.45315288564135869365\n",
      "Iteration  505 => Loss: 53.45046922027999158900\n",
      "Iteration  506 => Loss: 53.44779097875979800847\n",
      "Iteration  507 => Loss: 53.44511814919449932404\n",
      "Iteration  508 => Loss: 53.44245071972382277181\n",
      "Iteration  509 => Loss: 53.43978867851357250629\n",
      "Iteration  510 => Loss: 53.43713201375540933213\n",
      "Iteration  511 => Loss: 53.43448071366690044215\n",
      "Iteration  512 => Loss: 53.43183476649149099558\n",
      "Iteration  513 => Loss: 53.42919416049834069327\n",
      "Iteration  514 => Loss: 53.42655888398240193737\n",
      "Iteration  515 => Loss: 53.42392892526417114141\n",
      "Iteration  516 => Loss: 53.42130427268980952249\n",
      "Iteration  517 => Loss: 53.41868491463108625794\n",
      "Iteration  518 => Loss: 53.41607083948515111160\n",
      "Iteration  519 => Loss: 53.41346203567465522610\n",
      "Iteration  520 => Loss: 53.41085849164758769803\n",
      "Iteration  521 => Loss: 53.40826019587733952676\n",
      "Iteration  522 => Loss: 53.40566713686246202997\n",
      "Iteration  523 => Loss: 53.40307930312683737384\n",
      "Iteration  524 => Loss: 53.40049668321938725057\n",
      "Iteration  525 => Loss: 53.39791926571420788150\n",
      "Iteration  526 => Loss: 53.39534703921040659225\n",
      "Iteration  527 => Loss: 53.39277999233215155073\n",
      "Iteration  528 => Loss: 53.39021811372844439347\n",
      "Iteration  529 => Loss: 53.38766139207327654503\n",
      "Iteration  530 => Loss: 53.38510981606537342259\n",
      "Iteration  531 => Loss: 53.38256337442832233364\n",
      "Iteration  532 => Loss: 53.38002205591032378607\n",
      "Iteration  533 => Loss: 53.37748584928434780750\n",
      "Iteration  534 => Loss: 53.37495474334794209881\n",
      "Iteration  535 => Loss: 53.37242872692315387440\n",
      "Iteration  536 => Loss: 53.36990778885664354902\n",
      "Iteration  537 => Loss: 53.36739191801943604787\n",
      "Iteration  538 => Loss: 53.36488110330694922823\n",
      "Iteration  539 => Loss: 53.36237533363901519579\n",
      "Iteration  540 => Loss: 53.35987459795970266896\n",
      "Iteration  541 => Loss: 53.35737888523728855716\n",
      "Iteration  542 => Loss: 53.35488818446433612053\n",
      "Iteration  543 => Loss: 53.35240248465741785822\n",
      "Iteration  544 => Loss: 53.34992177485725761699\n",
      "Iteration  545 => Loss: 53.34744604412862400977\n",
      "Iteration  546 => Loss: 53.34497528156016699086\n",
      "Iteration  547 => Loss: 53.34250947626450312100\n",
      "Iteration  548 => Loss: 53.34004861737817293488\n",
      "Iteration  549 => Loss: 53.33759269406142777825\n",
      "Iteration  550 => Loss: 53.33514169549835770567\n",
      "Iteration  551 => Loss: 53.33269561089674937193\n",
      "Iteration  552 => Loss: 53.33025442948800076692\n",
      "Iteration  553 => Loss: 53.32781814052716384822\n",
      "Iteration  554 => Loss: 53.32538673329286638136\n",
      "Iteration  555 => Loss: 53.32296019708716272589\n",
      "Iteration  556 => Loss: 53.32053852123563331133\n",
      "Iteration  557 => Loss: 53.31812169508720700151\n",
      "Iteration  558 => Loss: 53.31570970801414688367\n",
      "Iteration  559 => Loss: 53.31330254941210000652\n",
      "Iteration  560 => Loss: 53.31090020869991974450\n",
      "Iteration  561 => Loss: 53.30850267531958763811\n",
      "Iteration  562 => Loss: 53.30610993873633418616\n",
      "Iteration  563 => Loss: 53.30372198843841147209\n",
      "Iteration  564 => Loss: 53.30133881393711448027\n",
      "Iteration  565 => Loss: 53.29896040476681662312\n",
      "Iteration  566 => Loss: 53.29658675048472105118\n",
      "Iteration  567 => Loss: 53.29421784067097433990\n",
      "Iteration  568 => Loss: 53.29185366492858832999\n",
      "Iteration  569 => Loss: 53.28949421288333354596\n",
      "Iteration  570 => Loss: 53.28713947418374630161\n",
      "Iteration  571 => Loss: 53.28478943850101501312\n",
      "Iteration  572 => Loss: 53.28244409552899440996\n",
      "Iteration  573 => Loss: 53.28010343498415579688\n",
      "Iteration  574 => Loss: 53.27776744660548757793\n",
      "Iteration  575 => Loss: 53.27543612015445262386\n",
      "Iteration  576 => Loss: 53.27310944541499537763\n",
      "Iteration  577 => Loss: 53.27078741219344948377\n",
      "Iteration  578 => Loss: 53.26847001031846673413\n",
      "Iteration  579 => Loss: 53.26615722964103127879\n",
      "Iteration  580 => Loss: 53.26384906003436725541\n",
      "Iteration  581 => Loss: 53.26154549139385352419\n",
      "Iteration  582 => Loss: 53.25924651363709472207\n",
      "Iteration  583 => Loss: 53.25695211670373652169\n",
      "Iteration  584 => Loss: 53.25466229055552247473\n",
      "Iteration  585 => Loss: 53.25237702517617321973\n",
      "Iteration  586 => Loss: 53.25009631057135095489\n",
      "Iteration  587 => Loss: 53.24782013676868075436\n",
      "Iteration  588 => Loss: 53.24554849381761556515\n",
      "Iteration  589 => Loss: 53.24328137178940778540\n",
      "Iteration  590 => Loss: 53.24101876077708084267\n",
      "Iteration  591 => Loss: 53.23876065089541498310\n",
      "Iteration  592 => Loss: 53.23650703228083358454\n",
      "Iteration  593 => Loss: 53.23425789509136052402\n",
      "Iteration  594 => Loss: 53.23201322950659175604\n",
      "Iteration  595 => Loss: 53.22977302572775215594\n",
      "Iteration  596 => Loss: 53.22753727397738288118\n",
      "Iteration  597 => Loss: 53.22530596449962558836\n",
      "Iteration  598 => Loss: 53.22307908755983874016\n",
      "Iteration  599 => Loss: 53.22085663344486761162\n",
      "Iteration  600 => Loss: 53.21863859246279560011\n",
      "Iteration  601 => Loss: 53.21642495494293001457\n",
      "Iteration  602 => Loss: 53.21421571123578075913\n",
      "Iteration  603 => Loss: 53.21201085171305322774\n",
      "Iteration  604 => Loss: 53.20981036676752040648\n",
      "Iteration  605 => Loss: 53.20761424681306550610\n",
      "Iteration  606 => Loss: 53.20542248228446169378\n",
      "Iteration  607 => Loss: 53.20323506363763499394\n",
      "Iteration  608 => Loss: 53.20105198134928770060\n",
      "Iteration  609 => Loss: 53.19887322591701916963\n",
      "Iteration  610 => Loss: 53.19669878785935424048\n",
      "Iteration  611 => Loss: 53.19452865771549454621\n",
      "Iteration  612 => Loss: 53.19236282604539667318\n",
      "Iteration  613 => Loss: 53.19020128342980058278\n",
      "Iteration  614 => Loss: 53.18804402047000934317\n",
      "Iteration  615 => Loss: 53.18589102778793886728\n",
      "Iteration  616 => Loss: 53.18374229602604685851\n",
      "Iteration  617 => Loss: 53.18159781584739675964\n",
      "Iteration  618 => Loss: 53.17945757793540195735\n",
      "Iteration  619 => Loss: 53.17732157299398920713\n",
      "Iteration  620 => Loss: 53.17518979174740678673\n",
      "Iteration  621 => Loss: 53.17306222494026002323\n",
      "Iteration  622 => Loss: 53.17093886333746866057\n",
      "Iteration  623 => Loss: 53.16881969772412475095\n",
      "Iteration  624 => Loss: 53.16670471890558502537\n",
      "Iteration  625 => Loss: 53.16459391770735720684\n",
      "Iteration  626 => Loss: 53.16248728497503606150\n",
      "Iteration  627 => Loss: 53.16038481157430339863\n",
      "Iteration  628 => Loss: 53.15828648839082859467\n",
      "Iteration  629 => Loss: 53.15619230633030412037\n",
      "Iteration  630 => Loss: 53.15410225631836738103\n",
      "Iteration  631 => Loss: 53.15201632930050124060\n",
      "Iteration  632 => Loss: 53.14993451624204823247\n",
      "Iteration  633 => Loss: 53.14785680812820345409\n",
      "Iteration  634 => Loss: 53.14578319596385114210\n",
      "Iteration  635 => Loss: 53.14371367077364993747\n",
      "Iteration  636 => Loss: 53.14164822360192630413\n",
      "Iteration  637 => Loss: 53.13958684551261058004\n",
      "Iteration  638 => Loss: 53.13752952758925118815\n",
      "Iteration  639 => Loss: 53.13547626093491516031\n",
      "Iteration  640 => Loss: 53.13342703667222366448\n",
      "Iteration  641 => Loss: 53.13138184594315305276\n",
      "Iteration  642 => Loss: 53.12934067990924802416\n",
      "Iteration  643 => Loss: 53.12730352975133030213\n",
      "Iteration  644 => Loss: 53.12527038666953416168\n",
      "Iteration  645 => Loss: 53.12324124188336327279\n",
      "Iteration  646 => Loss: 53.12121608663152017016\n",
      "Iteration  647 => Loss: 53.11919491217192046406\n",
      "Iteration  648 => Loss: 53.11717770978164310236\n",
      "Iteration  649 => Loss: 53.11516447075690905422\n",
      "Iteration  650 => Loss: 53.11315518641298893954\n",
      "Iteration  651 => Loss: 53.11114984808421723983\n",
      "Iteration  652 => Loss: 53.10914844712387861136\n",
      "Iteration  653 => Loss: 53.10715097490429315030\n",
      "Iteration  654 => Loss: 53.10515742281661033530\n",
      "Iteration  655 => Loss: 53.10316778227091560893\n",
      "Iteration  656 => Loss: 53.10118204469609537455\n",
      "Iteration  657 => Loss: 53.09920020153982989086\n",
      "Iteration  658 => Loss: 53.09722224426853642854\n",
      "Iteration  659 => Loss: 53.09524816436734795388\n",
      "Iteration  660 => Loss: 53.09327795334004207461\n",
      "Iteration  661 => Loss: 53.09131160270912630494\n",
      "Iteration  662 => Loss: 53.08934910401551832138\n",
      "Iteration  663 => Loss: 53.08739044881880175808\n",
      "Iteration  664 => Loss: 53.08543562869706988749\n",
      "Iteration  665 => Loss: 53.08348463524676219549\n",
      "Iteration  666 => Loss: 53.08153746008290596592\n",
      "Iteration  667 => Loss: 53.07959409483876100921\n",
      "Iteration  668 => Loss: 53.07765453116600440353\n",
      "Iteration  669 => Loss: 53.07571876073458838619\n",
      "Iteration  670 => Loss: 53.07378677523274745909\n",
      "Iteration  671 => Loss: 53.07185856636691312360\n",
      "Iteration  672 => Loss: 53.06993412586175651313\n",
      "Iteration  673 => Loss: 53.06801344545996101942\n",
      "Iteration  674 => Loss: 53.06609651692245677168\n",
      "Iteration  675 => Loss: 53.06418333202818615746\n",
      "Iteration  676 => Loss: 53.06227388257402566296\n",
      "Iteration  677 => Loss: 53.06036816037495640330\n",
      "Iteration  678 => Loss: 53.05846615726383674883\n",
      "Iteration  679 => Loss: 53.05656786509145206310\n",
      "Iteration  680 => Loss: 53.05467327572647917577\n",
      "Iteration  681 => Loss: 53.05278238105533006319\n",
      "Iteration  682 => Loss: 53.05089517298227974607\n",
      "Iteration  683 => Loss: 53.04901164342933128637\n",
      "Iteration  684 => Loss: 53.04713178433619447105\n",
      "Iteration  685 => Loss: 53.04525558766022186319\n",
      "Iteration  686 => Loss: 53.04338304537647985626\n",
      "Iteration  687 => Loss: 53.04151414947751419504\n",
      "Iteration  688 => Loss: 53.03964889197354182215\n",
      "Iteration  689 => Loss: 53.03778726489215955553\n",
      "Iteration  690 => Loss: 53.03592926027855014581\n",
      "Iteration  691 => Loss: 53.03407487019529042982\n",
      "Iteration  692 => Loss: 53.03222408672239396310\n",
      "Iteration  693 => Loss: 53.03037690195716180597\n",
      "Iteration  694 => Loss: 53.02853330801431042119\n",
      "Iteration  695 => Loss: 53.02669329702575851115\n",
      "Iteration  696 => Loss: 53.02485686114071228303\n",
      "Iteration  697 => Loss: 53.02302399252560860532\n",
      "Iteration  698 => Loss: 53.02119468336402263731\n",
      "Iteration  699 => Loss: 53.01936892585667493449\n",
      "Iteration  700 => Loss: 53.01754671222138171061\n",
      "Iteration  701 => Loss: 53.01572803469304062673\n",
      "Iteration  702 => Loss: 53.01391288552350289365\n",
      "Iteration  703 => Loss: 53.01210125698172248576\n",
      "Iteration  704 => Loss: 53.01029314135346481862\n",
      "Iteration  705 => Loss: 53.00848853094154122800\n",
      "Iteration  706 => Loss: 53.00668741806551054196\n",
      "Iteration  707 => Loss: 53.00488979506185671653\n",
      "Iteration  708 => Loss: 53.00309565428383251628\n",
      "Iteration  709 => Loss: 53.00130498810145240896\n",
      "Iteration  710 => Loss: 52.99951778890144282741\n",
      "Iteration  711 => Loss: 52.99773404908727059137\n",
      "Iteration  712 => Loss: 52.99595376107897948259\n",
      "Iteration  713 => Loss: 52.99417691731330393168\n",
      "Iteration  714 => Loss: 52.99240351024351980413\n",
      "Iteration  715 => Loss: 52.99063353233943729492\n",
      "Iteration  716 => Loss: 52.98886697608737250675\n",
      "Iteration  717 => Loss: 52.98710383399020429351\n",
      "Iteration  718 => Loss: 52.98534409856710425402\n",
      "Iteration  719 => Loss: 52.98358776235369305141\n",
      "Iteration  720 => Loss: 52.98183481790202620232\n",
      "Iteration  721 => Loss: 52.98008525778040223031\n",
      "Iteration  722 => Loss: 52.97833907457345503644\n",
      "Iteration  723 => Loss: 52.97659626088201179073\n",
      "Iteration  724 => Loss: 52.97485680932323504067\n",
      "Iteration  725 => Loss: 52.97312071253036691587\n",
      "Iteration  726 => Loss: 52.97138796315284992033\n",
      "Iteration  727 => Loss: 52.96965855385621324558\n",
      "Iteration  728 => Loss: 52.96793247732206566525\n",
      "Iteration  729 => Loss: 52.96620972624809553508\n",
      "Iteration  730 => Loss: 52.96449029334794289525\n",
      "Iteration  731 => Loss: 52.96277417135129184089\n",
      "Iteration  732 => Loss: 52.96106135300367867558\n",
      "Iteration  733 => Loss: 52.95935183106662691443\n",
      "Iteration  734 => Loss: 52.95764559831746964846\n",
      "Iteration  735 => Loss: 52.95594264754939217710\n",
      "Iteration  736 => Loss: 52.95424297157133253222\n",
      "Iteration  737 => Loss: 52.95254656320813779757\n",
      "Iteration  738 => Loss: 52.95085341530020883738\n",
      "Iteration  739 => Loss: 52.94916352070374898631\n",
      "Iteration  740 => Loss: 52.94747687229056509750\n",
      "Iteration  741 => Loss: 52.94579346294814570228\n",
      "Iteration  742 => Loss: 52.94411328557949047990\n",
      "Iteration  743 => Loss: 52.94243633310325236607\n",
      "Iteration  744 => Loss: 52.94076259845353860101\n",
      "Iteration  745 => Loss: 52.93909207457998888913\n",
      "Iteration  746 => Loss: 52.93742475444764750137\n",
      "Iteration  747 => Loss: 52.93576063103704854029\n",
      "Iteration  748 => Loss: 52.93409969734406672615\n",
      "Iteration  749 => Loss: 52.93244194637991739683\n",
      "Iteration  750 => Loss: 52.93078737117116361333\n",
      "Iteration  751 => Loss: 52.92913596475967352717\n",
      "Iteration  752 => Loss: 52.92748772020252800985\n",
      "Iteration  753 => Loss: 52.92584263057204196912\n",
      "Iteration  754 => Loss: 52.92420068895575724355\n",
      "Iteration  755 => Loss: 52.92256188845629338857\n",
      "Iteration  756 => Loss: 52.92092622219146846874\n",
      "Iteration  757 => Loss: 52.91929368329408589489\n",
      "Iteration  758 => Loss: 52.91766426491212627070\n",
      "Iteration  759 => Loss: 52.91603796020850580817\n",
      "Iteration  760 => Loss: 52.91441476236112606557\n",
      "Iteration  761 => Loss: 52.91279466456294500176\n",
      "Iteration  762 => Loss: 52.91117766002168565365\n",
      "Iteration  763 => Loss: 52.90956374196009903699\n",
      "Iteration  764 => Loss: 52.90795290361568703474\n",
      "Iteration  765 => Loss: 52.90634513824088003275\n",
      "Iteration  766 => Loss: 52.90474043910280244063\n",
      "Iteration  767 => Loss: 52.90313879948342901116\n",
      "Iteration  768 => Loss: 52.90154021267937878292\n",
      "Iteration  769 => Loss: 52.89994467200200034540\n",
      "Iteration  770 => Loss: 52.89835217077730789015\n",
      "Iteration  771 => Loss: 52.89676270234596699993\n",
      "Iteration  772 => Loss: 52.89517626006318096188\n",
      "Iteration  773 => Loss: 52.89359283729879734892\n",
      "Iteration  774 => Loss: 52.89201242743711617322\n",
      "Iteration  775 => Loss: 52.89043502387701778389\n",
      "Iteration  776 => Loss: 52.88886062003179233670\n",
      "Iteration  777 => Loss: 52.88728920932918953213\n",
      "Iteration  778 => Loss: 52.88572078521140440444\n",
      "Iteration  779 => Loss: 52.88415534113494942403\n",
      "Iteration  780 => Loss: 52.88259287057067581372\n",
      "Iteration  781 => Loss: 52.88103336700385170843\n",
      "Iteration  782 => Loss: 52.87947682393388504352\n",
      "Iteration  783 => Loss: 52.87792323487452961217\n",
      "Iteration  784 => Loss: 52.87637259335372164060\n",
      "Iteration  785 => Loss: 52.87482489291360110428\n",
      "Iteration  786 => Loss: 52.87328012711046909544\n",
      "Iteration  787 => Loss: 52.87173828951469545245\n",
      "Iteration  788 => Loss: 52.87019937371081113042\n",
      "Iteration  789 => Loss: 52.86866337329743714690\n",
      "Iteration  790 => Loss: 52.86713028188707852451\n",
      "Iteration  791 => Loss: 52.86560009310644403513\n",
      "Iteration  792 => Loss: 52.86407280059605540146\n",
      "Iteration  793 => Loss: 52.86254839801044624892\n",
      "Iteration  794 => Loss: 52.86102687901804841886\n",
      "Iteration  795 => Loss: 52.85950823730117065224\n",
      "Iteration  796 => Loss: 52.85799246655596306255\n",
      "Iteration  797 => Loss: 52.85647956049239581944\n",
      "Iteration  798 => Loss: 52.85496951283428757051\n",
      "Iteration  799 => Loss: 52.85346231731908517304\n",
      "Iteration  800 => Loss: 52.85195796769810527849\n",
      "Iteration  801 => Loss: 52.85045645773629274800\n",
      "Iteration  802 => Loss: 52.84895778121224196866\n",
      "Iteration  803 => Loss: 52.84746193191820395896\n",
      "Iteration  804 => Loss: 52.84596890366009347417\n",
      "Iteration  805 => Loss: 52.84447869025731847614\n",
      "Iteration  806 => Loss: 52.84299128554287250381\n",
      "Iteration  807 => Loss: 52.84150668336326361896\n",
      "Iteration  808 => Loss: 52.84002487757852861705\n",
      "Iteration  809 => Loss: 52.83854586206207670784\n",
      "Iteration  810 => Loss: 52.83706963070083872935\n",
      "Iteration  811 => Loss: 52.83559617739511082846\n",
      "Iteration  812 => Loss: 52.83412549605854025003\n",
      "Iteration  813 => Loss: 52.83265758061814665325\n",
      "Iteration  814 => Loss: 52.83119242501424395186\n",
      "Iteration  815 => Loss: 52.82973002320039768165\n",
      "Iteration  816 => Loss: 52.82827036914352447639\n",
      "Iteration  817 => Loss: 52.82681345682367890504\n",
      "Iteration  818 => Loss: 52.82535928023416005317\n",
      "Iteration  819 => Loss: 52.82390783338139783609\n",
      "Iteration  820 => Loss: 52.82245911028496720974\n",
      "Iteration  821 => Loss: 52.82101310497758106521\n",
      "Iteration  822 => Loss: 52.81956981150502627997\n",
      "Iteration  823 => Loss: 52.81812922392611397981\n",
      "Iteration  824 => Loss: 52.81669133631272217144\n",
      "Iteration  825 => Loss: 52.81525614274967495021\n",
      "Iteration  826 => Loss: 52.81382363733478513268\n",
      "Iteration  827 => Loss: 52.81239381417883294034\n",
      "Iteration  828 => Loss: 52.81096666740548073449\n",
      "Iteration  829 => Loss: 52.80954219115125169992\n",
      "Iteration  830 => Loss: 52.80812037956555826668\n",
      "Iteration  831 => Loss: 52.80670122681065237202\n",
      "Iteration  832 => Loss: 52.80528472706149756277\n",
      "Iteration  833 => Loss: 52.80387087450594663096\n",
      "Iteration  834 => Loss: 52.80245966334448581847\n",
      "Iteration  835 => Loss: 52.80105108779038403100\n",
      "Iteration  836 => Loss: 52.79964514206957915121\n",
      "Iteration  837 => Loss: 52.79824182042066382792\n",
      "Iteration  838 => Loss: 52.79684111709486415975\n",
      "Iteration  839 => Loss: 52.79544302635596153550\n",
      "Iteration  840 => Loss: 52.79404754248040632092\n",
      "Iteration  841 => Loss: 52.79265465975709048507\n",
      "Iteration  842 => Loss: 52.79126437248751102516\n",
      "Iteration  843 => Loss: 52.78987667498559943624\n",
      "Iteration  844 => Loss: 52.78849156157779276555\n",
      "Iteration  845 => Loss: 52.78710902660296966360\n",
      "Iteration  846 => Loss: 52.78572906441235090824\n",
      "Iteration  847 => Loss: 52.78435166936959888062\n",
      "Iteration  848 => Loss: 52.78297683585073940549\n",
      "Iteration  849 => Loss: 52.78160455824409780234\n",
      "Iteration  850 => Loss: 52.78023483095030599088\n",
      "Iteration  851 => Loss: 52.77886764838226696384\n",
      "Iteration  852 => Loss: 52.77750300496514768156\n",
      "Iteration  853 => Loss: 52.77614089513633643946\n",
      "Iteration  854 => Loss: 52.77478131334540734088\n",
      "Iteration  855 => Loss: 52.77342425405407055905\n",
      "Iteration  856 => Loss: 52.77206971173624339144\n",
      "Iteration  857 => Loss: 52.77071768087789394031\n",
      "Iteration  858 => Loss: 52.76936815597714058867\n",
      "Iteration  859 => Loss: 52.76802113154410278639\n",
      "Iteration  860 => Loss: 52.76667660210093657724\n",
      "Iteration  861 => Loss: 52.76533456218189144238\n",
      "Iteration  862 => Loss: 52.76399500633306161035\n",
      "Iteration  863 => Loss: 52.76265792911262764164\n",
      "Iteration  864 => Loss: 52.76132332509062194958\n",
      "Iteration  865 => Loss: 52.75999118884902117088\n",
      "Iteration  866 => Loss: 52.75866151498163958422\n",
      "Iteration  867 => Loss: 52.75733429809414332112\n",
      "Iteration  868 => Loss: 52.75600953280408589308\n",
      "Iteration  869 => Loss: 52.75468721374075897756\n",
      "Iteration  870 => Loss: 52.75336733554523505063\n",
      "Iteration  871 => Loss: 52.75204989287033896517\n",
      "Iteration  872 => Loss: 52.75073488038065505634\n",
      "Iteration  873 => Loss: 52.74942229275240634934\n",
      "Iteration  874 => Loss: 52.74811212467355403533\n",
      "Iteration  875 => Loss: 52.74680437084357009780\n",
      "Iteration  876 => Loss: 52.74549902597372863511\n",
      "Iteration  877 => Loss: 52.74419608478676479990\n",
      "Iteration  878 => Loss: 52.74289554201705243486\n",
      "Iteration  879 => Loss: 52.74159739241042643698\n",
      "Iteration  880 => Loss: 52.74030163072437460414\n",
      "Iteration  881 => Loss: 52.73900825172771078542\n",
      "Iteration  882 => Loss: 52.73771725020085909819\n",
      "Iteration  883 => Loss: 52.73642862093561234360\n",
      "Iteration  884 => Loss: 52.73514235873519595543\n",
      "Iteration  885 => Loss: 52.73385845841421115665\n",
      "Iteration  886 => Loss: 52.73257691479866338113\n",
      "Iteration  887 => Loss: 52.73129772272585569226\n",
      "Iteration  888 => Loss: 52.73002087704449536432\n",
      "Iteration  889 => Loss: 52.72874637261444519254\n",
      "Iteration  890 => Loss: 52.72747420430692955051\n",
      "Iteration  891 => Loss: 52.72620436700443491418\n",
      "Iteration  892 => Loss: 52.72493685560059617501\n",
      "Iteration  893 => Loss: 52.72367166500026058884\n",
      "Iteration  894 => Loss: 52.72240879011949488131\n",
      "Iteration  895 => Loss: 52.72114822588542182302\n",
      "Iteration  896 => Loss: 52.71988996723640497066\n",
      "Iteration  897 => Loss: 52.71863400912177155533\n",
      "Iteration  898 => Loss: 52.71738034650201143450\n",
      "Iteration  899 => Loss: 52.71612897434867051061\n",
      "Iteration  900 => Loss: 52.71487988764421572796\n",
      "Iteration  901 => Loss: 52.71363308138221981380\n",
      "Iteration  902 => Loss: 52.71238855056716232639\n",
      "Iteration  903 => Loss: 52.71114629021452202551\n",
      "Iteration  904 => Loss: 52.70990629535069871281\n",
      "Iteration  905 => Loss: 52.70866856101295638837\n",
      "Iteration  906 => Loss: 52.70743308224944456697\n",
      "Iteration  907 => Loss: 52.70619985411924091068\n",
      "Iteration  908 => Loss: 52.70496887169215938229\n",
      "Iteration  909 => Loss: 52.70374013004886393219\n",
      "Iteration  910 => Loss: 52.70251362428078323319\n",
      "Iteration  911 => Loss: 52.70128934949017462941\n",
      "Iteration  912 => Loss: 52.70006730078993939514\n",
      "Iteration  913 => Loss: 52.69884747330374352714\n",
      "Iteration  914 => Loss: 52.69762986216591116317\n",
      "Iteration  915 => Loss: 52.69641446252147432006\n",
      "Iteration  916 => Loss: 52.69520126952611605020\n",
      "Iteration  917 => Loss: 52.69399027834603543852\n",
      "Iteration  918 => Loss: 52.69278148415818208150\n",
      "Iteration  919 => Loss: 52.69157488214995055387\n",
      "Iteration  920 => Loss: 52.69037046751932962252\n",
      "Iteration  921 => Loss: 52.68916823547487382484\n",
      "Iteration  922 => Loss: 52.68796818123557557101\n",
      "Iteration  923 => Loss: 52.68677030003094330368\n",
      "Iteration  924 => Loss: 52.68557458710094465459\n",
      "Iteration  925 => Loss: 52.68438103769598512827\n",
      "Iteration  926 => Loss: 52.68318964707685836402\n",
      "Iteration  927 => Loss: 52.68200041051476745224\n",
      "Iteration  928 => Loss: 52.68081332329126809100\n",
      "Iteration  929 => Loss: 52.67962838069826858600\n",
      "Iteration  930 => Loss: 52.67844557803799432349\n",
      "Iteration  931 => Loss: 52.67726491062297355938\n",
      "Iteration  932 => Loss: 52.67608637377603031382\n",
      "Iteration  933 => Loss: 52.67490996283018489521\n",
      "Iteration  934 => Loss: 52.67373567312875337620\n",
      "Iteration  935 => Loss: 52.67256350002518416886\n",
      "Iteration  936 => Loss: 52.67139343888318592235\n",
      "Iteration  937 => Loss: 52.67022548507659962524\n",
      "Iteration  938 => Loss: 52.66905963398943413267\n",
      "Iteration  939 => Loss: 52.66789588101573116319\n",
      "Iteration  940 => Loss: 52.66673422155972872361\n",
      "Iteration  941 => Loss: 52.66557465103572610587\n",
      "Iteration  942 => Loss: 52.66441716486801283281\n",
      "Iteration  943 => Loss: 52.66326175849094681780\n",
      "Iteration  944 => Loss: 52.66210842734891173222\n",
      "Iteration  945 => Loss: 52.66095716689623174034\n",
      "Iteration  946 => Loss: 52.65980797259724255355\n",
      "Iteration  947 => Loss: 52.65866083992622748156\n",
      "Iteration  948 => Loss: 52.65751576436733927267\n",
      "Iteration  949 => Loss: 52.65637274141465695720\n",
      "Iteration  950 => Loss: 52.65523176657215742580\n",
      "Iteration  951 => Loss: 52.65409283535363726969\n",
      "Iteration  952 => Loss: 52.65295594328276962415\n",
      "Iteration  953 => Loss: 52.65182108589298337620\n",
      "Iteration  954 => Loss: 52.65068825872755553519\n",
      "Iteration  955 => Loss: 52.64955745733949754595\n",
      "Iteration  956 => Loss: 52.64842867729157660506\n",
      "Iteration  957 => Loss: 52.64730191415630855545\n",
      "Iteration  958 => Loss: 52.64617716351587262125\n",
      "Iteration  959 => Loss: 52.64505442096221088377\n",
      "Iteration  960 => Loss: 52.64393368209677959157\n",
      "Iteration  961 => Loss: 52.64281494253087601010\n",
      "Iteration  962 => Loss: 52.64169819788526183402\n",
      "Iteration  963 => Loss: 52.64058344379034082294\n",
      "Iteration  964 => Loss: 52.63947067588611616884\n",
      "Iteration  965 => Loss: 52.63835988982215496890\n",
      "Iteration  966 => Loss: 52.63725108125757401467\n",
      "Iteration  967 => Loss: 52.63614424586088347269\n",
      "Iteration  968 => Loss: 52.63503937931027820696\n",
      "Iteration  969 => Loss: 52.63393647729326829676\n",
      "Iteration  970 => Loss: 52.63283553550691351575\n",
      "Iteration  971 => Loss: 52.63173654965765990710\n",
      "Iteration  972 => Loss: 52.63063951546138241611\n",
      "Iteration  973 => Loss: 52.62954442864334936303\n",
      "Iteration  974 => Loss: 52.62845128493819402138\n",
      "Iteration  975 => Loss: 52.62736008008987909079\n",
      "Iteration  976 => Loss: 52.62627080985175354044\n",
      "Iteration  977 => Loss: 52.62518346998640339507\n",
      "Iteration  978 => Loss: 52.62409805626577963267\n",
      "Iteration  979 => Loss: 52.62301456447103475966\n",
      "Iteration  980 => Loss: 52.62193299039259386518\n",
      "Iteration  981 => Loss: 52.62085332983014041019\n",
      "Iteration  982 => Loss: 52.61977557859253096240\n",
      "Iteration  983 => Loss: 52.61869973249780940705\n",
      "Iteration  984 => Loss: 52.61762578737319984157\n",
      "Iteration  985 => Loss: 52.61655373905505683751\n",
      "Iteration  986 => Loss: 52.61548358338890807318\n",
      "Iteration  987 => Loss: 52.61441531622933354129\n",
      "Iteration  988 => Loss: 52.61334893343999397075\n",
      "Iteration  989 => Loss: 52.61228443089373030261\n",
      "Iteration  990 => Loss: 52.61122180447224394584\n",
      "Iteration  991 => Loss: 52.61016105006644494324\n",
      "Iteration  992 => Loss: 52.60910216357613222726\n",
      "Iteration  993 => Loss: 52.60804514091014283395\n",
      "Iteration  994 => Loss: 52.60698997798626663780\n",
      "Iteration  995 => Loss: 52.60593667073128187894\n",
      "Iteration  996 => Loss: 52.60488521508083437084\n",
      "Iteration  997 => Loss: 52.60383560697950144913\n",
      "Iteration  998 => Loss: 52.60278784238078486624\n",
      "Iteration  999 => Loss: 52.60174191724699710448\n",
      "Iteration 1000 => Loss: 52.60069782754935374669\n",
      "Iteration 1001 => Loss: 52.59965556926788110559\n",
      "Iteration 1002 => Loss: 52.59861513839142332927\n",
      "Iteration 1003 => Loss: 52.59757653091759266317\n",
      "Iteration 1004 => Loss: 52.59653974285282629353\n",
      "Iteration 1005 => Loss: 52.59550477021225844965\n",
      "Iteration 1006 => Loss: 52.59447160901979856362\n",
      "Iteration 1007 => Loss: 52.59344025530804600521\n",
      "Iteration 1008 => Loss: 52.59241070511834692525\n",
      "Iteration 1009 => Loss: 52.59138295450065925252\n",
      "Iteration 1010 => Loss: 52.59035699951362374804\n",
      "Iteration 1011 => Loss: 52.58933283622454979422\n",
      "Iteration 1012 => Loss: 52.58831046070934434056\n",
      "Iteration 1013 => Loss: 52.58728986905250479822\n",
      "Iteration 1014 => Loss: 52.58627105734711193463\n",
      "Iteration 1015 => Loss: 52.58525402169485829518\n",
      "Iteration 1016 => Loss: 52.58423875820593451635\n",
      "Iteration 1017 => Loss: 52.58322526299905774749\n",
      "Iteration 1018 => Loss: 52.58221353220146454532\n",
      "Iteration 1019 => Loss: 52.58120356194891797941\n",
      "Iteration 1020 => Loss: 52.58019534838559394530\n",
      "Iteration 1021 => Loss: 52.57918888766413800795\n",
      "Iteration 1022 => Loss: 52.57818417594565829631\n",
      "Iteration 1023 => Loss: 52.57718120939964023819\n",
      "Iteration 1024 => Loss: 52.57617998420399629822\n",
      "Iteration 1025 => Loss: 52.57518049654499492362\n",
      "Iteration 1026 => Loss: 52.57418274261725343877\n",
      "Iteration 1027 => Loss: 52.57318671862378778314\n",
      "Iteration 1028 => Loss: 52.57219242077589882456\n",
      "Iteration 1029 => Loss: 52.57119984529315814825\n",
      "Iteration 1030 => Loss: 52.57020898840350753289\n",
      "Iteration 1031 => Loss: 52.56921984634309552575\n",
      "Iteration 1032 => Loss: 52.56823241535628454812\n",
      "Iteration 1033 => Loss: 52.56724669169582853101\n",
      "Iteration 1034 => Loss: 52.56626267162251053833\n",
      "Iteration 1035 => Loss: 52.56528035140543408943\n",
      "Iteration 1036 => Loss: 52.56429972732180289086\n",
      "Iteration 1037 => Loss: 52.56332079565702031232\n",
      "Iteration 1038 => Loss: 52.56234355270467517585\n",
      "Iteration 1039 => Loss: 52.56136799476637122552\n",
      "Iteration 1040 => Loss: 52.56039411815191186861\n",
      "Iteration 1041 => Loss: 52.55942191917917938326\n",
      "Iteration 1042 => Loss: 52.55845139417409939142\n",
      "Iteration 1043 => Loss: 52.55748253947066217506\n",
      "Iteration 1044 => Loss: 52.55651535141086583280\n",
      "Iteration 1045 => Loss: 52.55554982634478733416\n",
      "Iteration 1046 => Loss: 52.55458596063046883273\n",
      "Iteration 1047 => Loss: 52.55362375063393187702\n",
      "Iteration 1048 => Loss: 52.55266319272920583217\n",
      "Iteration 1049 => Loss: 52.55170428329818577140\n",
      "Iteration 1050 => Loss: 52.55074701873080300629\n",
      "Iteration 1051 => Loss: 52.54979139542477639679\n",
      "Iteration 1052 => Loss: 52.54883740978586814663\n",
      "Iteration 1053 => Loss: 52.54788505822760669162\n",
      "Iteration 1054 => Loss: 52.54693433717142170281\n",
      "Iteration 1055 => Loss: 52.54598524304659434847\n",
      "Iteration 1056 => Loss: 52.54503777229022176698\n",
      "Iteration 1057 => Loss: 52.54409192134720996137\n",
      "Iteration 1058 => Loss: 52.54314768667029511562\n",
      "Iteration 1059 => Loss: 52.54220506471989438069\n",
      "Iteration 1060 => Loss: 52.54126405196431193190\n",
      "Iteration 1061 => Loss: 52.54032464487951159526\n",
      "Iteration 1062 => Loss: 52.53938683994916658548\n",
      "Iteration 1063 => Loss: 52.53845063366477319278\n",
      "Iteration 1064 => Loss: 52.53751602252533814408\n",
      "Iteration 1065 => Loss: 52.53658300303770545270\n",
      "Iteration 1066 => Loss: 52.53565157171630062294\n",
      "Iteration 1067 => Loss: 52.53472172508319459894\n",
      "Iteration 1068 => Loss: 52.53379345966808955382\n",
      "Iteration 1069 => Loss: 52.53286677200834020596\n",
      "Iteration 1070 => Loss: 52.53194165864879749961\n",
      "Iteration 1071 => Loss: 52.53101811614192939714\n",
      "Iteration 1072 => Loss: 52.53009614104779956278\n",
      "Iteration 1073 => Loss: 52.52917572993401762460\n",
      "Iteration 1074 => Loss: 52.52825687937561838226\n",
      "Iteration 1075 => Loss: 52.52733958595523233726\n",
      "Iteration 1076 => Loss: 52.52642384626296490069\n",
      "Iteration 1077 => Loss: 52.52550965689636797151\n",
      "Iteration 1078 => Loss: 52.52459701446049677998\n",
      "Iteration 1079 => Loss: 52.52368591556783172791\n",
      "Iteration 1080 => Loss: 52.52277635683823575619\n",
      "Iteration 1081 => Loss: 52.52186833489906092609\n",
      "Iteration 1082 => Loss: 52.52096184638499209996\n",
      "Iteration 1083 => Loss: 52.52005688793808246828\n",
      "Iteration 1084 => Loss: 52.51915345620784592029\n",
      "Iteration 1085 => Loss: 52.51825154785097282684\n",
      "Iteration 1086 => Loss: 52.51735115953164978464\n",
      "Iteration 1087 => Loss: 52.51645228792129671547\n",
      "Iteration 1088 => Loss: 52.51555492969860949870\n",
      "Iteration 1089 => Loss: 52.51465908154960970933\n",
      "Iteration 1090 => Loss: 52.51376474016758066909\n",
      "Iteration 1091 => Loss: 52.51287190225303191937\n",
      "Iteration 1092 => Loss: 52.51198056451370632658\n",
      "Iteration 1093 => Loss: 52.51109072366458718761\n",
      "Iteration 1094 => Loss: 52.51020237642781296472\n",
      "Iteration 1095 => Loss: 52.50931551953276965605\n",
      "Iteration 1096 => Loss: 52.50843014971597710883\n",
      "Iteration 1097 => Loss: 52.50754626372113875732\n",
      "Iteration 1098 => Loss: 52.50666385829903504145\n",
      "Iteration 1099 => Loss: 52.50578293020760867194\n",
      "Iteration 1100 => Loss: 52.50490347621193620853\n",
      "Iteration 1101 => Loss: 52.50402549308412147866\n",
      "Iteration 1102 => Loss: 52.50314897760340926425\n",
      "Iteration 1103 => Loss: 52.50227392655602898230\n",
      "Iteration 1104 => Loss: 52.50140033673540074233\n",
      "Iteration 1105 => Loss: 52.50052820494177296951\n",
      "Iteration 1106 => Loss: 52.49965752798253504352\n",
      "Iteration 1107 => Loss: 52.49878830267208229543\n",
      "Iteration 1108 => Loss: 52.49792052583175916425\n",
      "Iteration 1109 => Loss: 52.49705419428983077523\n",
      "Iteration 1110 => Loss: 52.49618930488158952130\n",
      "Iteration 1111 => Loss: 52.49532585444926979790\n",
      "Iteration 1112 => Loss: 52.49446383984196273786\n",
      "Iteration 1113 => Loss: 52.49360325791571568743\n",
      "Iteration 1114 => Loss: 52.49274410553345404651\n",
      "Iteration 1115 => Loss: 52.49188637956496705783\n",
      "Iteration 1116 => Loss: 52.49103007688695043953\n",
      "Iteration 1117 => Loss: 52.49017519438289269829\n",
      "Iteration 1118 => Loss: 52.48932172894316749989\n",
      "Iteration 1119 => Loss: 52.48846967746486313899\n",
      "Iteration 1120 => Loss: 52.48761903685201701819\n",
      "Iteration 1121 => Loss: 52.48676980401535274723\n",
      "Iteration 1122 => Loss: 52.48592197587237961898\n",
      "Iteration 1123 => Loss: 52.48507554934742103114\n",
      "Iteration 1124 => Loss: 52.48423052137142263973\n",
      "Iteration 1125 => Loss: 52.48338688888218683815\n",
      "Iteration 1126 => Loss: 52.48254464882417380522\n",
      "Iteration 1127 => Loss: 52.48170379814852282152\n",
      "Iteration 1128 => Loss: 52.48086433381310911273\n",
      "Iteration 1129 => Loss: 52.48002625278240884654\n",
      "Iteration 1130 => Loss: 52.47918955202761992496\n",
      "Iteration 1131 => Loss: 52.47835422852651277026\n",
      "Iteration 1132 => Loss: 52.47752027926355111731\n",
      "Iteration 1133 => Loss: 52.47668770122973569414\n",
      "Iteration 1134 => Loss: 52.47585649142276054135\n",
      "Iteration 1135 => Loss: 52.47502664684678563844\n",
      "Iteration 1136 => Loss: 52.47419816451266427748\n",
      "Iteration 1137 => Loss: 52.47337104143768016229\n",
      "Iteration 1138 => Loss: 52.47254527464573925499\n",
      "Iteration 1139 => Loss: 52.47172086116722056204\n",
      "Iteration 1140 => Loss: 52.47089779803908271560\n",
      "Iteration 1141 => Loss: 52.47007608230467212707\n",
      "Iteration 1142 => Loss: 52.46925571101391483353\n",
      "Iteration 1143 => Loss: 52.46843668122315307301\n",
      "Iteration 1144 => Loss: 52.46761898999523054954\n",
      "Iteration 1145 => Loss: 52.46680263439932190295\n",
      "Iteration 1146 => Loss: 52.46598761151116008250\n",
      "Iteration 1147 => Loss: 52.46517391841280897324\n",
      "Iteration 1148 => Loss: 52.46436155219274866113\n",
      "Iteration 1149 => Loss: 52.46355050994583990587\n",
      "Iteration 1150 => Loss: 52.46274078877331703552\n",
      "Iteration 1151 => Loss: 52.46193238578275241935\n",
      "Iteration 1152 => Loss: 52.46112529808809199494\n",
      "Iteration 1153 => Loss: 52.46031952280956289769\n",
      "Iteration 1154 => Loss: 52.45951505707374451504\n",
      "Iteration 1155 => Loss: 52.45871189801349032678\n",
      "Iteration 1156 => Loss: 52.45791004276796343220\n",
      "Iteration 1157 => Loss: 52.45710948848256549581\n",
      "Iteration 1158 => Loss: 52.45631023230898648535\n",
      "Iteration 1159 => Loss: 52.45551227140516203917\n",
      "Iteration 1160 => Loss: 52.45471560293521662288\n",
      "Iteration 1161 => Loss: 52.45392022406952037272\n",
      "Iteration 1162 => Loss: 52.45312613198470330644\n",
      "Iteration 1163 => Loss: 52.45233332386342794962\n",
      "Iteration 1164 => Loss: 52.45154179689473039616\n",
      "Iteration 1165 => Loss: 52.45075154827360108811\n",
      "Iteration 1166 => Loss: 52.44996257520138271957\n",
      "Iteration 1167 => Loss: 52.44917487488542207075\n",
      "Iteration 1168 => Loss: 52.44838844453923343281\n",
      "Iteration 1169 => Loss: 52.44760328138241334273\n",
      "Iteration 1170 => Loss: 52.44681938264068321587\n",
      "Iteration 1171 => Loss: 52.44603674554581829170\n",
      "Iteration 1172 => Loss: 52.44525536733570447723\n",
      "Iteration 1173 => Loss: 52.44447524525423176556\n",
      "Iteration 1174 => Loss: 52.44369637655135107934\n",
      "Iteration 1175 => Loss: 52.44291875848306716534\n",
      "Iteration 1176 => Loss: 52.44214238831136043473\n",
      "Iteration 1177 => Loss: 52.44136726330423670106\n",
      "Iteration 1178 => Loss: 52.44059338073570586403\n",
      "Iteration 1179 => Loss: 52.43982073788571085515\n",
      "Iteration 1180 => Loss: 52.43904933204016316495\n",
      "Iteration 1181 => Loss: 52.43827916049099258089\n",
      "Iteration 1182 => Loss: 52.43751022053596955175\n",
      "Iteration 1183 => Loss: 52.43674250947883308527\n",
      "Iteration 1184 => Loss: 52.43597602462925522104\n",
      "Iteration 1185 => Loss: 52.43521076330279839794\n",
      "Iteration 1186 => Loss: 52.43444672282085150528\n",
      "Iteration 1187 => Loss: 52.43368390051070093705\n",
      "Iteration 1188 => Loss: 52.43292229370559454082\n",
      "Iteration 1189 => Loss: 52.43216189974445029520\n",
      "Iteration 1190 => Loss: 52.43140271597217605404\n",
      "Iteration 1191 => Loss: 52.43064473973938532936\n",
      "Iteration 1192 => Loss: 52.42988796840258203247\n",
      "Iteration 1193 => Loss: 52.42913239932398994370\n",
      "Iteration 1194 => Loss: 52.42837802987168061009\n",
      "Iteration 1195 => Loss: 52.42762485741950939655\n",
      "Iteration 1196 => Loss: 52.42687287934697337732\n",
      "Iteration 1197 => Loss: 52.42612209303946713135\n",
      "Iteration 1198 => Loss: 52.42537249588797010347\n",
      "Iteration 1199 => Loss: 52.42462408528928818896\n",
      "Iteration 1200 => Loss: 52.42387685864586899243\n",
      "Iteration 1201 => Loss: 52.42313081336592972548\n",
      "Iteration 1202 => Loss: 52.42238594686330088734\n",
      "Iteration 1203 => Loss: 52.42164225655749021371\n",
      "Iteration 1204 => Loss: 52.42089973987366846586\n",
      "Iteration 1205 => Loss: 52.42015839424269074698\n",
      "Iteration 1206 => Loss: 52.41941821710097570985\n",
      "Iteration 1207 => Loss: 52.41867920589062634917\n",
      "Iteration 1208 => Loss: 52.41794135805930210381\n",
      "Iteration 1209 => Loss: 52.41720467106027570026\n",
      "Iteration 1210 => Loss: 52.41646914235243315261\n",
      "Iteration 1211 => Loss: 52.41573476940016007575\n",
      "Iteration 1212 => Loss: 52.41500154967349089929\n",
      "Iteration 1213 => Loss: 52.41426948064793123194\n",
      "Iteration 1214 => Loss: 52.41353855980455733743\n",
      "Iteration 1215 => Loss: 52.41280878462994508027\n",
      "Iteration 1216 => Loss: 52.41208015261621966374\n",
      "Iteration 1217 => Loss: 52.41135266126094904848\n",
      "Iteration 1218 => Loss: 52.41062630806721500676\n",
      "Iteration 1219 => Loss: 52.40990109054362733332\n",
      "Iteration 1220 => Loss: 52.40917700620415331514\n",
      "Iteration 1221 => Loss: 52.40845405256826694540\n",
      "Iteration 1222 => Loss: 52.40773222716086365836\n",
      "Iteration 1223 => Loss: 52.40701152751228164561\n",
      "Iteration 1224 => Loss: 52.40629195115826632900\n",
      "Iteration 1225 => Loss: 52.40557349564001299314\n",
      "Iteration 1226 => Loss: 52.40485615850399625515\n",
      "Iteration 1227 => Loss: 52.40413993730211927868\n",
      "Iteration 1228 => Loss: 52.40342482959172798473\n",
      "Iteration 1229 => Loss: 52.40271083293541209969\n",
      "Iteration 1230 => Loss: 52.40199794490115436929\n",
      "Iteration 1231 => Loss: 52.40128616306230924238\n",
      "Iteration 1232 => Loss: 52.40057548499742523518\n",
      "Iteration 1233 => Loss: 52.39986590829051493756\n",
      "Iteration 1234 => Loss: 52.39915743053077790137\n",
      "Iteration 1235 => Loss: 52.39845004931278538152\n",
      "Iteration 1236 => Loss: 52.39774376223623875148\n",
      "Iteration 1237 => Loss: 52.39703856690625372039\n",
      "Iteration 1238 => Loss: 52.39633446093311164304\n",
      "Iteration 1239 => Loss: 52.39563144193238741764\n",
      "Iteration 1240 => Loss: 52.39492950752480737719\n",
      "Iteration 1241 => Loss: 52.39422865533639139812\n",
      "Iteration 1242 => Loss: 52.39352888299832500252\n",
      "Iteration 1243 => Loss: 52.39283018814695935816\n",
      "Iteration 1244 => Loss: 52.39213256842391075452\n",
      "Iteration 1245 => Loss: 52.39143602147586165074\n",
      "Iteration 1246 => Loss: 52.39074054495473831139\n",
      "Iteration 1247 => Loss: 52.39004613651755448700\n",
      "Iteration 1248 => Loss: 52.38935279382651799551\n",
      "Iteration 1249 => Loss: 52.38866051454893835171\n",
      "Iteration 1250 => Loss: 52.38796929635716992379\n",
      "Iteration 1251 => Loss: 52.38727913692876114737\n",
      "Iteration 1252 => Loss: 52.38659003394634083861\n",
      "Iteration 1253 => Loss: 52.38590198509757556167\n",
      "Iteration 1254 => Loss: 52.38521498807523357755\n",
      "Iteration 1255 => Loss: 52.38452904057714221153\n",
      "Iteration 1256 => Loss: 52.38384414030612390434\n",
      "Iteration 1257 => Loss: 52.38316028497007437181\n",
      "Iteration 1258 => Loss: 52.38247747228197681579\n",
      "Iteration 1259 => Loss: 52.38179569995971718299\n",
      "Iteration 1260 => Loss: 52.38111496572623337897\n",
      "Iteration 1261 => Loss: 52.38043526730948684644\n",
      "Iteration 1262 => Loss: 52.37975660244234887841\n",
      "Iteration 1263 => Loss: 52.37907896886273562131\n",
      "Iteration 1264 => Loss: 52.37840236431348728274\n",
      "Iteration 1265 => Loss: 52.37772678654234681517\n",
      "Iteration 1266 => Loss: 52.37705223330207360277\n",
      "Iteration 1267 => Loss: 52.37637870235031556376\n",
      "Iteration 1268 => Loss: 52.37570619144962336122\n",
      "Iteration 1269 => Loss: 52.37503469836750724653\n",
      "Iteration 1270 => Loss: 52.37436422087627363453\n",
      "Iteration 1271 => Loss: 52.37369475675320984465\n",
      "Iteration 1272 => Loss: 52.37302630378042778148\n",
      "Iteration 1273 => Loss: 52.37235885974493498907\n",
      "Iteration 1274 => Loss: 52.37169242243853517493\n",
      "Iteration 1275 => Loss: 52.37102698965789215890\n",
      "Iteration 1276 => Loss: 52.37036255920453697854\n",
      "Iteration 1277 => Loss: 52.36969912888478972945\n",
      "Iteration 1278 => Loss: 52.36903669650975956529\n",
      "Iteration 1279 => Loss: 52.36837525989545838456\n",
      "Iteration 1280 => Loss: 52.36771481686249529730\n",
      "Iteration 1281 => Loss: 52.36705536523642479096\n",
      "Iteration 1282 => Loss: 52.36639690284751225136\n",
      "Iteration 1283 => Loss: 52.36573942753074817347\n",
      "Iteration 1284 => Loss: 52.36508293712593342661\n",
      "Iteration 1285 => Loss: 52.36442742947753004046\n",
      "Iteration 1286 => Loss: 52.36377290243484594612\n",
      "Iteration 1287 => Loss: 52.36311935385170102109\n",
      "Iteration 1288 => Loss: 52.36246678158684630944\n",
      "Iteration 1289 => Loss: 52.36181518350355901248\n",
      "Iteration 1290 => Loss: 52.36116455746987696784\n",
      "Iteration 1291 => Loss: 52.36051490135851338437\n",
      "Iteration 1292 => Loss: 52.35986621304682131495\n",
      "Iteration 1293 => Loss: 52.35921849041680786740\n",
      "Iteration 1294 => Loss: 52.35857173135513420448\n",
      "Iteration 1295 => Loss: 52.35792593375309422754\n",
      "Iteration 1296 => Loss: 52.35728109550659326032\n",
      "Iteration 1297 => Loss: 52.35663721451616225977\n",
      "Iteration 1298 => Loss: 52.35599428868690807803\n",
      "Iteration 1299 => Loss: 52.35535231592857741134\n",
      "Iteration 1300 => Loss: 52.35471129415543600771\n",
      "Iteration 1301 => Loss: 52.35407122128641788095\n",
      "Iteration 1302 => Loss: 52.35343209524489083151\n",
      "Iteration 1303 => Loss: 52.35279391395890513650\n",
      "Iteration 1304 => Loss: 52.35215667536092354339\n",
      "Iteration 1305 => Loss: 52.35152037738807706546\n",
      "Iteration 1306 => Loss: 52.35088501798188787006\n",
      "Iteration 1307 => Loss: 52.35025059508849665235\n",
      "Iteration 1308 => Loss: 52.34961710665846368329\n",
      "Iteration 1309 => Loss: 52.34898455064692512906\n",
      "Iteration 1310 => Loss: 52.34835292501342962623\n",
      "Iteration 1311 => Loss: 52.34772222772203775776\n",
      "Iteration 1312 => Loss: 52.34709245674122257697\n",
      "Iteration 1313 => Loss: 52.34646361004399750527\n",
      "Iteration 1314 => Loss: 52.34583568560772448564\n",
      "Iteration 1315 => Loss: 52.34520868141429872367\n",
      "Iteration 1316 => Loss: 52.34458259544994263024\n",
      "Iteration 1317 => Loss: 52.34395742570534082461\n",
      "Iteration 1318 => Loss: 52.34333317017557618556\n",
      "Iteration 1319 => Loss: 52.34270982686015116769\n",
      "Iteration 1320 => Loss: 52.34208739376291674716\n",
      "Iteration 1321 => Loss: 52.34146586889210084337\n",
      "Iteration 1322 => Loss: 52.34084525026033674067\n",
      "Iteration 1323 => Loss: 52.34022553588455650697\n",
      "Iteration 1324 => Loss: 52.33960672378607625888\n",
      "Iteration 1325 => Loss: 52.33898881199056773994\n",
      "Iteration 1326 => Loss: 52.33837179852800147728\n",
      "Iteration 1327 => Loss: 52.33775568143266809784\n",
      "Iteration 1328 => Loss: 52.33714045874314280127\n",
      "Iteration 1329 => Loss: 52.33652612850236351960\n",
      "Iteration 1330 => Loss: 52.33591268875752433587\n",
      "Iteration 1331 => Loss: 52.33530013756009680037\n",
      "Iteration 1332 => Loss: 52.33468847296578019268\n",
      "Iteration 1333 => Loss: 52.33407769303466494648\n",
      "Iteration 1334 => Loss: 52.33346779583093422161\n",
      "Iteration 1335 => Loss: 52.33285877942313391031\n",
      "Iteration 1336 => Loss: 52.33225064188402342324\n",
      "Iteration 1337 => Loss: 52.33164338129050463522\n",
      "Iteration 1338 => Loss: 52.33103699572380662630\n",
      "Iteration 1339 => Loss: 52.33043148326929383529\n",
      "Iteration 1340 => Loss: 52.32982684201655132483\n",
      "Iteration 1341 => Loss: 52.32922307005935635971\n",
      "Iteration 1342 => Loss: 52.32862016549562866885\n",
      "Iteration 1343 => Loss: 52.32801812642752281590\n",
      "Iteration 1344 => Loss: 52.32741695096130030151\n",
      "Iteration 1345 => Loss: 52.32681663720740772305\n",
      "Iteration 1346 => Loss: 52.32621718328037019319\n",
      "Iteration 1347 => Loss: 52.32561858729894765929\n",
      "Iteration 1348 => Loss: 52.32502084738595726776\n",
      "Iteration 1349 => Loss: 52.32442396166832310200\n",
      "Iteration 1350 => Loss: 52.32382792827709749872\n",
      "Iteration 1351 => Loss: 52.32323274534745394249\n",
      "Iteration 1352 => Loss: 52.32263841101858758975\n",
      "Iteration 1353 => Loss: 52.32204492343387158826\n",
      "Iteration 1354 => Loss: 52.32145228074062970336\n",
      "Iteration 1355 => Loss: 52.32086048109036369169\n",
      "Iteration 1356 => Loss: 52.32026952263850461122\n",
      "Iteration 1357 => Loss: 52.31967940354466861663\n",
      "Iteration 1358 => Loss: 52.31909012197234432051\n",
      "Iteration 1359 => Loss: 52.31850167608921964302\n",
      "Iteration 1360 => Loss: 52.31791406406688338393\n",
      "Iteration 1361 => Loss: 52.31732728408093890948\n",
      "Iteration 1362 => Loss: 52.31674133431103257408\n",
      "Iteration 1363 => Loss: 52.31615621294076845516\n",
      "Iteration 1364 => Loss: 52.31557191815776519661\n",
      "Iteration 1365 => Loss: 52.31498844815357784910\n",
      "Iteration 1366 => Loss: 52.31440580112376181887\n",
      "Iteration 1367 => Loss: 52.31382397526777339181\n",
      "Iteration 1368 => Loss: 52.31324296878906920938\n",
      "Iteration 1369 => Loss: 52.31266277989504231982\n",
      "Iteration 1370 => Loss: 52.31208340679698665099\n",
      "Iteration 1371 => Loss: 52.31150484771011832663\n",
      "Iteration 1372 => Loss: 52.31092710085359698269\n",
      "Iteration 1373 => Loss: 52.31035016445043339672\n",
      "Iteration 1374 => Loss: 52.30977403672761738562\n",
      "Iteration 1375 => Loss: 52.30919871591592595905\n",
      "Iteration 1376 => Loss: 52.30862420025009384972\n",
      "Iteration 1377 => Loss: 52.30805048796867140481\n",
      "Iteration 1378 => Loss: 52.30747757731411695659\n",
      "Iteration 1379 => Loss: 52.30690546653269734634\n",
      "Iteration 1380 => Loss: 52.30633415387457318957\n",
      "Iteration 1381 => Loss: 52.30576363759370650541\n",
      "Iteration 1382 => Loss: 52.30519391594783940036\n",
      "Iteration 1383 => Loss: 52.30462498719864328223\n",
      "Iteration 1384 => Loss: 52.30405684961154832990\n",
      "Iteration 1385 => Loss: 52.30348950145576480963\n",
      "Iteration 1386 => Loss: 52.30292294100432570758\n",
      "Iteration 1387 => Loss: 52.30235716653398725384\n",
      "Iteration 1388 => Loss: 52.30179217632539945271\n",
      "Iteration 1389 => Loss: 52.30122796866289291984\n",
      "Iteration 1390 => Loss: 52.30066454183457835825\n",
      "Iteration 1391 => Loss: 52.30010189413232524203\n",
      "Iteration 1392 => Loss: 52.29954002385179023804\n",
      "Iteration 1393 => Loss: 52.29897892929225378111\n",
      "Iteration 1394 => Loss: 52.29841860875681902598\n",
      "Iteration 1395 => Loss: 52.29785906055229105505\n",
      "Iteration 1396 => Loss: 52.29730028298919108920\n",
      "Iteration 1397 => Loss: 52.29674227438169964444\n",
      "Iteration 1398 => Loss: 52.29618503304772758611\n",
      "Iteration 1399 => Loss: 52.29562855730890191808\n",
      "Iteration 1400 => Loss: 52.29507284549049472844\n",
      "Iteration 1401 => Loss: 52.29451789592140187324\n",
      "Iteration 1402 => Loss: 52.29396370693427797960\n",
      "Iteration 1403 => Loss: 52.29341027686536591546\n",
      "Iteration 1404 => Loss: 52.29285760405459626554\n",
      "Iteration 1405 => Loss: 52.29230568684552338254\n",
      "Iteration 1406 => Loss: 52.29175452358528985997\n",
      "Iteration 1407 => Loss: 52.29120411262472600811\n",
      "Iteration 1408 => Loss: 52.29065445231825748351\n",
      "Iteration 1409 => Loss: 52.29010554102393371068\n",
      "Iteration 1410 => Loss: 52.28955737710329998436\n",
      "Iteration 1411 => Loss: 52.28900995892165326495\n",
      "Iteration 1412 => Loss: 52.28846328484776506684\n",
      "Iteration 1413 => Loss: 52.28791735325403067236\n",
      "Iteration 1414 => Loss: 52.28737216251639097209\n",
      "Iteration 1415 => Loss: 52.28682771101432535943\n",
      "Iteration 1416 => Loss: 52.28628399713090857404\n",
      "Iteration 1417 => Loss: 52.28574101925274675295\n",
      "Iteration 1418 => Loss: 52.28519877576999164148\n",
      "Iteration 1419 => Loss: 52.28465726507629085518\n",
      "Iteration 1420 => Loss: 52.28411648556886603956\n",
      "Iteration 1421 => Loss: 52.28357643564834944527\n",
      "Iteration 1422 => Loss: 52.28303711371903972349\n",
      "Iteration 1423 => Loss: 52.28249851818858928709\n",
      "Iteration 1424 => Loss: 52.28196064746821747349\n",
      "Iteration 1425 => Loss: 52.28142349997257554151\n",
      "Iteration 1426 => Loss: 52.28088707411986035822\n",
      "Iteration 1427 => Loss: 52.28035136833167939585\n",
      "Iteration 1428 => Loss: 52.27981638103312178600\n",
      "Iteration 1429 => Loss: 52.27928211065270858171\n",
      "Iteration 1430 => Loss: 52.27874855562242828455\n",
      "Iteration 1431 => Loss: 52.27821571437770842294\n",
      "Iteration 1432 => Loss: 52.27768358535738002502\n",
      "Iteration 1433 => Loss: 52.27715216700374156744\n",
      "Iteration 1434 => Loss: 52.27662145776244528861\n",
      "Iteration 1435 => Loss: 52.27609145608261798088\n",
      "Iteration 1436 => Loss: 52.27556216041670467121\n",
      "Iteration 1437 => Loss: 52.27503356922063915135\n",
      "Iteration 1438 => Loss: 52.27450568095365923682\n",
      "Iteration 1439 => Loss: 52.27397849407844176994\n",
      "Iteration 1440 => Loss: 52.27345200706096761678\n",
      "Iteration 1441 => Loss: 52.27292621837063535395\n",
      "Iteration 1442 => Loss: 52.27240112648020442521\n",
      "Iteration 1443 => Loss: 52.27187672986568856004\n",
      "Iteration 1444 => Loss: 52.27135302700659025277\n",
      "Iteration 1445 => Loss: 52.27083001638563075630\n",
      "Iteration 1446 => Loss: 52.27030769648890640156\n",
      "Iteration 1447 => Loss: 52.26978606580576069973\n",
      "Iteration 1448 => Loss: 52.26926512282899750517\n",
      "Iteration 1449 => Loss: 52.26874486605457548194\n",
      "Iteration 1450 => Loss: 52.26822529398184258298\n",
      "Iteration 1451 => Loss: 52.26770640511337262524\n",
      "Iteration 1452 => Loss: 52.26718819795507187109\n",
      "Iteration 1453 => Loss: 52.26667067101607955237\n",
      "Iteration 1454 => Loss: 52.26615382280886024091\n",
      "Iteration 1455 => Loss: 52.26563765184907595085\n",
      "Iteration 1456 => Loss: 52.26512215665568561462\n",
      "Iteration 1457 => Loss: 52.26460733575088113412\n",
      "Iteration 1458 => Loss: 52.26409318766006606438\n",
      "Iteration 1459 => Loss: 52.26357971091195508961\n",
      "Iteration 1460 => Loss: 52.26306690403841059833\n",
      "Iteration 1461 => Loss: 52.26255476557452794850\n",
      "Iteration 1462 => Loss: 52.26204329405865678382\n",
      "Iteration 1463 => Loss: 52.26153248803229445230\n",
      "Iteration 1464 => Loss: 52.26102234604013574426\n",
      "Iteration 1465 => Loss: 52.26051286663015815748\n",
      "Iteration 1466 => Loss: 52.26000404835339452347\n",
      "Iteration 1467 => Loss: 52.25949588976416038122\n",
      "Iteration 1468 => Loss: 52.25898838941985502515\n",
      "Iteration 1469 => Loss: 52.25848154588109650831\n",
      "Iteration 1470 => Loss: 52.25797535771164348262\n",
      "Iteration 1471 => Loss: 52.25746982347840230432\n",
      "Iteration 1472 => Loss: 52.25696494175140571770\n",
      "Iteration 1473 => Loss: 52.25646071110386259306\n",
      "Iteration 1474 => Loss: 52.25595713011203713450\n",
      "Iteration 1475 => Loss: 52.25545419735539809380\n",
      "Iteration 1476 => Loss: 52.25495191141649797828\n",
      "Iteration 1477 => Loss: 52.25445027088093041812\n",
      "Iteration 1478 => Loss: 52.25394927433751490753\n",
      "Iteration 1479 => Loss: 52.25344892037803390394\n",
      "Iteration 1480 => Loss: 52.25294920759746020167\n",
      "Iteration 1481 => Loss: 52.25245013459380061249\n",
      "Iteration 1482 => Loss: 52.25195169996812438740\n",
      "Iteration 1483 => Loss: 52.25145390232462005997\n",
      "Iteration 1484 => Loss: 52.25095674027044623244\n",
      "Iteration 1485 => Loss: 52.25046021241592342221\n",
      "Iteration 1486 => Loss: 52.24996431737429958275\n",
      "Iteration 1487 => Loss: 52.24946905376198458271\n",
      "Iteration 1488 => Loss: 52.24897442019833704308\n",
      "Iteration 1489 => Loss: 52.24848041530577091862\n",
      "Iteration 1490 => Loss: 52.24798703770973418159\n",
      "Iteration 1491 => Loss: 52.24749428603863066201\n",
      "Iteration 1492 => Loss: 52.24700215892392662909\n",
      "Iteration 1493 => Loss: 52.24651065500011526410\n",
      "Iteration 1494 => Loss: 52.24601977290457455183\n",
      "Iteration 1495 => Loss: 52.24552951127779465423\n",
      "Iteration 1496 => Loss: 52.24503986876314343135\n",
      "Iteration 1497 => Loss: 52.24455084400702276071\n",
      "Iteration 1498 => Loss: 52.24406243565878327217\n",
      "Iteration 1499 => Loss: 52.24357464237076698055\n",
      "Iteration 1500 => Loss: 52.24308746279818649327\n",
      "Iteration 1501 => Loss: 52.24260089559928843528\n",
      "Iteration 1502 => Loss: 52.24211493943523265671\n",
      "Iteration 1503 => Loss: 52.24162959297010644377\n",
      "Iteration 1504 => Loss: 52.24114485487092451876\n",
      "Iteration 1505 => Loss: 52.24066072380765746175\n",
      "Iteration 1506 => Loss: 52.24017719845313223459\n",
      "Iteration 1507 => Loss: 52.23969427748311034065\n",
      "Iteration 1508 => Loss: 52.23921195957627361395\n",
      "Iteration 1509 => Loss: 52.23873024341420290284\n",
      "Iteration 1510 => Loss: 52.23824912768134254293\n",
      "Iteration 1511 => Loss: 52.23776861106503588417\n",
      "Iteration 1512 => Loss: 52.23728869225549686917\n",
      "Iteration 1513 => Loss: 52.23680936994583134947\n",
      "Iteration 1514 => Loss: 52.23633064283197313671\n",
      "Iteration 1515 => Loss: 52.23585250961273374060\n",
      "Iteration 1516 => Loss: 52.23537496898980236892\n",
      "Iteration 1517 => Loss: 52.23489801966767487329\n",
      "Iteration 1518 => Loss: 52.23442166035368927623\n",
      "Iteration 1519 => Loss: 52.23394588975808261466\n",
      "Iteration 1520 => Loss: 52.23347070659379909330\n",
      "Iteration 1521 => Loss: 52.23299610957670324751\n",
      "Iteration 1522 => Loss: 52.23252209742545915105\n",
      "Iteration 1523 => Loss: 52.23204866886150909977\n",
      "Iteration 1524 => Loss: 52.23157582260911624417\n",
      "Iteration 1525 => Loss: 52.23110355739534327313\n",
      "Iteration 1526 => Loss: 52.23063187195001688679\n",
      "Iteration 1527 => Loss: 52.23016076500580595621\n",
      "Iteration 1528 => Loss: 52.22969023529808652029\n",
      "Iteration 1529 => Loss: 52.22922028156504126173\n",
      "Iteration 1530 => Loss: 52.22875090254762397990\n",
      "Iteration 1531 => Loss: 52.22828209698959511798\n",
      "Iteration 1532 => Loss: 52.22781386363732991640\n",
      "Iteration 1533 => Loss: 52.22734620124007420827\n",
      "Iteration 1534 => Loss: 52.22687910854982362707\n",
      "Iteration 1535 => Loss: 52.22641258432122413069\n",
      "Iteration 1536 => Loss: 52.22594662731169279368\n",
      "Iteration 1537 => Loss: 52.22548123628137517471\n",
      "Iteration 1538 => Loss: 52.22501640999313110569\n",
      "Iteration 1539 => Loss: 52.22455214721253469179\n",
      "Iteration 1540 => Loss: 52.22408844670787431141\n",
      "Iteration 1541 => Loss: 52.22362530725010287824\n",
      "Iteration 1542 => Loss: 52.22316272761293021176\n",
      "Iteration 1543 => Loss: 52.22270070657267382330\n",
      "Iteration 1544 => Loss: 52.22223924290841523543\n",
      "Iteration 1545 => Loss: 52.22177833540183655714\n",
      "Iteration 1546 => Loss: 52.22131798283736969779\n",
      "Iteration 1547 => Loss: 52.22085818400203294232\n",
      "Iteration 1548 => Loss: 52.22039893768554463804\n",
      "Iteration 1549 => Loss: 52.21994024268027345670\n",
      "Iteration 1550 => Loss: 52.21948209778126681613\n",
      "Iteration 1551 => Loss: 52.21902450178613719345\n",
      "Iteration 1552 => Loss: 52.21856745349519002275\n",
      "Iteration 1553 => Loss: 52.21811095171135974624\n",
      "Iteration 1554 => Loss: 52.21765499524016718169\n",
      "Iteration 1555 => Loss: 52.21719958288982610384\n",
      "Iteration 1556 => Loss: 52.21674471347105139785\n",
      "Iteration 1557 => Loss: 52.21629038579723669500\n",
      "Iteration 1558 => Loss: 52.21583659868440463470\n",
      "Iteration 1559 => Loss: 52.21538335095112159934\n",
      "Iteration 1560 => Loss: 52.21493064141851192517\n",
      "Iteration 1561 => Loss: 52.21447846891036448369\n",
      "Iteration 1562 => Loss: 52.21402683225304741654\n",
      "Iteration 1563 => Loss: 52.21357573027542287036\n",
      "Iteration 1564 => Loss: 52.21312516180896778906\n",
      "Iteration 1565 => Loss: 52.21267512568773128123\n",
      "Iteration 1566 => Loss: 52.21222562074824224965\n",
      "Iteration 1567 => Loss: 52.21177664582975808116\n",
      "Iteration 1568 => Loss: 52.21132819977388805910\n",
      "Iteration 1569 => Loss: 52.21088028142482073690\n",
      "Iteration 1570 => Loss: 52.21043288962940920328\n",
      "Iteration 1571 => Loss: 52.20998602323686554882\n",
      "Iteration 1572 => Loss: 52.20953968109900955596\n",
      "Iteration 1573 => Loss: 52.20909386207020475013\n",
      "Iteration 1574 => Loss: 52.20864856500725181832\n",
      "Iteration 1575 => Loss: 52.20820378876951650682\n",
      "Iteration 1576 => Loss: 52.20775953221883725064\n",
      "Iteration 1577 => Loss: 52.20731579421951806808\n",
      "Iteration 1578 => Loss: 52.20687257363842093127\n",
      "Iteration 1579 => Loss: 52.20642986934487339568\n",
      "Iteration 1580 => Loss: 52.20598768021061886202\n",
      "Iteration 1581 => Loss: 52.20554600510997289575\n",
      "Iteration 1582 => Loss: 52.20510484291963138048\n",
      "Iteration 1583 => Loss: 52.20466419251877709939\n",
      "Iteration 1584 => Loss: 52.20422405278909394610\n",
      "Iteration 1585 => Loss: 52.20378442261469587038\n",
      "Iteration 1586 => Loss: 52.20334530088209845644\n",
      "Iteration 1587 => Loss: 52.20290668648026866094\n",
      "Iteration 1588 => Loss: 52.20246857830070297268\n",
      "Iteration 1589 => Loss: 52.20203097523719293349\n",
      "Iteration 1590 => Loss: 52.20159387618604540648\n",
      "Iteration 1591 => Loss: 52.20115728004596888923\n",
      "Iteration 1592 => Loss: 52.20072118571805219744\n",
      "Iteration 1593 => Loss: 52.20028559210584262473\n",
      "Iteration 1594 => Loss: 52.19985049811524646657\n",
      "Iteration 1595 => Loss: 52.19941590265460007458\n",
      "Iteration 1596 => Loss: 52.19898180463462011858\n",
      "Iteration 1597 => Loss: 52.19854820296838937566\n",
      "Iteration 1598 => Loss: 52.19811509657142067908\n",
      "Iteration 1599 => Loss: 52.19768248436158586401\n",
      "Iteration 1600 => Loss: 52.19725036525910155660\n",
      "Iteration 1601 => Loss: 52.19681873818659312292\n",
      "Iteration 1602 => Loss: 52.19638760206900229832\n",
      "Iteration 1603 => Loss: 52.19595695583367955805\n",
      "Iteration 1604 => Loss: 52.19552679841027043040\n",
      "Iteration 1605 => Loss: 52.19509712873082918350\n",
      "Iteration 1606 => Loss: 52.19466794572966250598\n",
      "Iteration 1607 => Loss: 52.19423924834354266977\n",
      "Iteration 1608 => Loss: 52.19381103551143752384\n",
      "Iteration 1609 => Loss: 52.19338330617470944617\n",
      "Iteration 1610 => Loss: 52.19295605927708692207\n",
      "Iteration 1611 => Loss: 52.19252929376450822474\n",
      "Iteration 1612 => Loss: 52.19210300858528484014\n",
      "Iteration 1613 => Loss: 52.19167720269003041267\n",
      "Iteration 1614 => Loss: 52.19125187503164653435\n",
      "Iteration 1615 => Loss: 52.19082702456535116653\n",
      "Iteration 1616 => Loss: 52.19040265024860048015\n",
      "Iteration 1617 => Loss: 52.18997875104120254264\n",
      "Iteration 1618 => Loss: 52.18955532590522494729\n",
      "Iteration 1619 => Loss: 52.18913237380498770790\n",
      "Iteration 1620 => Loss: 52.18870989370709878585\n",
      "Iteration 1621 => Loss: 52.18828788458039014131\n",
      "Iteration 1622 => Loss: 52.18786634539604563088\n",
      "Iteration 1623 => Loss: 52.18744527512743758280\n",
      "Iteration 1624 => Loss: 52.18702467275017653492\n",
      "Iteration 1625 => Loss: 52.18660453724218939442\n",
      "Iteration 1626 => Loss: 52.18618486758354890753\n",
      "Iteration 1627 => Loss: 52.18576566275664418981\n",
      "Iteration 1628 => Loss: 52.18534692174602440673\n",
      "Iteration 1629 => Loss: 52.18492864353854798765\n",
      "Iteration 1630 => Loss: 52.18451082712323341184\n",
      "Iteration 1631 => Loss: 52.18409347149134447363\n",
      "Iteration 1632 => Loss: 52.18367657563633343898\n",
      "Iteration 1633 => Loss: 52.18326013855386946716\n",
      "Iteration 1634 => Loss: 52.18284415924181018909\n",
      "Iteration 1635 => Loss: 52.18242863670023723444\n",
      "Iteration 1636 => Loss: 52.18201356993141359908\n",
      "Iteration 1637 => Loss: 52.18159895793979075052\n",
      "Iteration 1638 => Loss: 52.18118479973198020616\n",
      "Iteration 1639 => Loss: 52.18077109431680327134\n",
      "Iteration 1640 => Loss: 52.18035784070521998501\n",
      "Iteration 1641 => Loss: 52.17994503791040727947\n",
      "Iteration 1642 => Loss: 52.17953268494765950436\n",
      "Iteration 1643 => Loss: 52.17912078083445237553\n",
      "Iteration 1644 => Loss: 52.17870932459038613160\n",
      "Iteration 1645 => Loss: 52.17829831523727079912\n",
      "Iteration 1646 => Loss: 52.17788775179899829482\n",
      "Iteration 1647 => Loss: 52.17747763330164190165\n",
      "Iteration 1648 => Loss: 52.17706795877335679279\n",
      "Iteration 1649 => Loss: 52.17665872724450792930\n",
      "Iteration 1650 => Loss: 52.17624993774752084619\n",
      "Iteration 1651 => Loss: 52.17584158931695981209\n",
      "Iteration 1652 => Loss: 52.17543368098952782930\n",
      "Iteration 1653 => Loss: 52.17502621180402400114\n",
      "Iteration 1654 => Loss: 52.17461918080132932118\n",
      "Iteration 1655 => Loss: 52.17421258702446351663\n",
      "Iteration 1656 => Loss: 52.17380642951854241574\n",
      "Iteration 1657 => Loss: 52.17340070733072820985\n",
      "Iteration 1658 => Loss: 52.17299541951032892939\n",
      "Iteration 1659 => Loss: 52.17259056510873449497\n",
      "Iteration 1660 => Loss: 52.17218614317936697944\n",
      "Iteration 1661 => Loss: 52.17178215277775166214\n",
      "Iteration 1662 => Loss: 52.17137859296150281807\n",
      "Iteration 1663 => Loss: 52.17097546279025976901\n",
      "Iteration 1664 => Loss: 52.17057276132573662153\n",
      "Iteration 1665 => Loss: 52.17017048763176489956\n",
      "Iteration 1666 => Loss: 52.16976864077412301413\n",
      "Iteration 1667 => Loss: 52.16936721982068547732\n",
      "Iteration 1668 => Loss: 52.16896622384141579687\n",
      "Iteration 1669 => Loss: 52.16856565190825278933\n",
      "Iteration 1670 => Loss: 52.16816550309520295059\n",
      "Iteration 1671 => Loss: 52.16776577647826229622\n",
      "Iteration 1672 => Loss: 52.16736647113554425914\n",
      "Iteration 1673 => Loss: 52.16696758614705231594\n",
      "Iteration 1674 => Loss: 52.16656912059487893885\n",
      "Iteration 1675 => Loss: 52.16617107356317717404\n",
      "Iteration 1676 => Loss: 52.16577344413801853307\n",
      "Iteration 1677 => Loss: 52.16537623140757062856\n",
      "Iteration 1678 => Loss: 52.16497943446184137883\n",
      "Iteration 1679 => Loss: 52.16458305239299875211\n",
      "Iteration 1680 => Loss: 52.16418708429515760372\n",
      "Iteration 1681 => Loss: 52.16379152926437257065\n",
      "Iteration 1682 => Loss: 52.16339638639868070413\n",
      "Iteration 1683 => Loss: 52.16300165479817252390\n",
      "Iteration 1684 => Loss: 52.16260733356482859335\n",
      "Iteration 1685 => Loss: 52.16221342180265452271\n",
      "Iteration 1686 => Loss: 52.16181991861756728213\n",
      "Iteration 1687 => Loss: 52.16142682311750178314\n",
      "Iteration 1688 => Loss: 52.16103413441229719183\n",
      "Iteration 1689 => Loss: 52.16064185161375377220\n",
      "Iteration 1690 => Loss: 52.16024997383569683507\n",
      "Iteration 1691 => Loss: 52.15985850019374936437\n",
      "Iteration 1692 => Loss: 52.15946742980559491798\n",
      "Iteration 1693 => Loss: 52.15907676179079999201\n",
      "Iteration 1694 => Loss: 52.15868649527087086426\n",
      "Iteration 1695 => Loss: 52.15829662936923227790\n",
      "Iteration 1696 => Loss: 52.15790716321126296862\n",
      "Iteration 1697 => Loss: 52.15751809592416776695\n",
      "Iteration 1698 => Loss: 52.15712942663721207737\n",
      "Iteration 1699 => Loss: 52.15674115448141634488\n",
      "Iteration 1700 => Loss: 52.15635327858983316673\n",
      "Iteration 1701 => Loss: 52.15596579809730570787\n",
      "Iteration 1702 => Loss: 52.15557871214070928545\n",
      "Iteration 1703 => Loss: 52.15519201985863162463\n",
      "Iteration 1704 => Loss: 52.15480572039172102450\n",
      "Iteration 1705 => Loss: 52.15441981288238082470\n",
      "Iteration 1706 => Loss: 52.15403429647498256827\n",
      "Iteration 1707 => Loss: 52.15364917031575942019\n",
      "Iteration 1708 => Loss: 52.15326443355273511315\n",
      "Iteration 1709 => Loss: 52.15288008533589447779\n",
      "Iteration 1710 => Loss: 52.15249612481706975586\n",
      "Iteration 1711 => Loss: 52.15211255114992638937\n",
      "Iteration 1712 => Loss: 52.15172936348998433687\n",
      "Iteration 1713 => Loss: 52.15134656099461096801\n",
      "Iteration 1714 => Loss: 52.15096414282308501242\n",
      "Iteration 1715 => Loss: 52.15058210813644024029\n",
      "Iteration 1716 => Loss: 52.15020045609758625460\n",
      "Iteration 1717 => Loss: 52.14981918587126585862\n",
      "Iteration 1718 => Loss: 52.14943829662407637215\n",
      "Iteration 1719 => Loss: 52.14905778752443410440\n",
      "Iteration 1720 => Loss: 52.14867765774251751054\n",
      "Iteration 1721 => Loss: 52.14829790645043061659\n",
      "Iteration 1722 => Loss: 52.14791853282196854025\n",
      "Iteration 1723 => Loss: 52.14753953603284486462\n",
      "Iteration 1724 => Loss: 52.14716091526054242422\n",
      "Iteration 1725 => Loss: 52.14678266968434172668\n",
      "Iteration 1726 => Loss: 52.14640479848529963647\n",
      "Iteration 1727 => Loss: 52.14602730084630621832\n",
      "Iteration 1728 => Loss: 52.14565017595204921008\n",
      "Iteration 1729 => Loss: 52.14527342298894296846\n",
      "Iteration 1730 => Loss: 52.14489704114524215584\n",
      "Iteration 1731 => Loss: 52.14452102961098489686\n",
      "Iteration 1732 => Loss: 52.14414538757791461876\n",
      "Iteration 1733 => Loss: 52.14377011423966479242\n",
      "Iteration 1734 => Loss: 52.14339520879150313704\n",
      "Iteration 1735 => Loss: 52.14302067043059452089\n",
      "Iteration 1736 => Loss: 52.14264649835570253344\n",
      "Iteration 1737 => Loss: 52.14227269176753054580\n",
      "Iteration 1738 => Loss: 52.14189924986840907195\n",
      "Iteration 1739 => Loss: 52.14152617186243787728\n",
      "Iteration 1740 => Loss: 52.14115345695550018945\n",
      "Iteration 1741 => Loss: 52.14078110435515611698\n",
      "Iteration 1742 => Loss: 52.14040911327079896864\n",
      "Iteration 1743 => Loss: 52.14003748291343498522\n",
      "Iteration 1744 => Loss: 52.13966621249591781861\n",
      "Iteration 1745 => Loss: 52.13929530123274247444\n",
      "Iteration 1746 => Loss: 52.13892474834016610430\n",
      "Iteration 1747 => Loss: 52.13855455303615116236\n",
      "Iteration 1748 => Loss: 52.13818471454037251078\n",
      "Iteration 1749 => Loss: 52.13781523207419610344\n",
      "Iteration 1750 => Loss: 52.13744610486077846190\n",
      "Iteration 1751 => Loss: 52.13707733212486772345\n",
      "Iteration 1752 => Loss: 52.13670891309297417138\n",
      "Iteration 1753 => Loss: 52.13634084699329207524\n",
      "Iteration 1754 => Loss: 52.13597313305572811259\n",
      "Iteration 1755 => Loss: 52.13560577051184452557\n",
      "Iteration 1756 => Loss: 52.13523875859487333173\n",
      "Iteration 1757 => Loss: 52.13487209653978737833\n",
      "Iteration 1758 => Loss: 52.13450578358320797179\n",
      "Iteration 1759 => Loss: 52.13413981896337645594\n",
      "Iteration 1760 => Loss: 52.13377420192033184776\n",
      "Iteration 1761 => Loss: 52.13340893169560530396\n",
      "Iteration 1762 => Loss: 52.13304400753254697065\n",
      "Iteration 1763 => Loss: 52.13267942867611282054\n",
      "Iteration 1764 => Loss: 52.13231519437284333662\n",
      "Iteration 1765 => Loss: 52.13195130387106956960\n",
      "Iteration 1766 => Loss: 52.13158775642065023703\n",
      "Iteration 1767 => Loss: 52.13122455127310672651\n",
      "Iteration 1768 => Loss: 52.13086168768170836074\n",
      "Iteration 1769 => Loss: 52.13049916490118107504\n",
      "Iteration 1770 => Loss: 52.13013698218803426698\n",
      "Iteration 1771 => Loss: 52.12977513880035473903\n",
      "Iteration 1772 => Loss: 52.12941363399785643651\n",
      "Iteration 1773 => Loss: 52.12905246704188044760\n",
      "Iteration 1774 => Loss: 52.12869163719533105450\n",
      "Iteration 1775 => Loss: 52.12833114372286047455\n",
      "Iteration 1776 => Loss: 52.12797098589059885398\n",
      "Iteration 1777 => Loss: 52.12761116296635321987\n",
      "Iteration 1778 => Loss: 52.12725167421950800417\n",
      "Iteration 1779 => Loss: 52.12689251892108899256\n",
      "Iteration 1780 => Loss: 52.12653369634365674301\n",
      "Iteration 1781 => Loss: 52.12617520576143448352\n",
      "Iteration 1782 => Loss: 52.12581704645018021438\n",
      "Iteration 1783 => Loss: 52.12545921768728618417\n",
      "Iteration 1784 => Loss: 52.12510171875171494094\n",
      "Iteration 1785 => Loss: 52.12474454892397091044\n",
      "Iteration 1786 => Loss: 52.12438770748618566131\n",
      "Iteration 1787 => Loss: 52.12403119372201132364\n",
      "Iteration 1788 => Loss: 52.12367500691675559210\n",
      "Iteration 1789 => Loss: 52.12331914635721830109\n",
      "Iteration 1790 => Loss: 52.12296361133176247904\n",
      "Iteration 1791 => Loss: 52.12260840113037119181\n",
      "Iteration 1792 => Loss: 52.12225351504451253959\n",
      "Iteration 1793 => Loss: 52.12189895236727465999\n",
      "Iteration 1794 => Loss: 52.12154471239324493581\n",
      "Iteration 1795 => Loss: 52.12119079441857394386\n",
      "Iteration 1796 => Loss: 52.12083719774096834954\n",
      "Iteration 1797 => Loss: 52.12048392165964116884\n",
      "Iteration 1798 => Loss: 52.12013096547536150638\n",
      "Iteration 1799 => Loss: 52.11977832849049718789\n",
      "Iteration 1800 => Loss: 52.11942601000880159745\n",
      "Iteration 1801 => Loss: 52.11907400933564815659\n",
      "Iteration 1802 => Loss: 52.11872232577794505914\n",
      "Iteration 1803 => Loss: 52.11837095864407842782\n",
      "Iteration 1804 => Loss: 52.11801990724396205223\n",
      "Iteration 1805 => Loss: 52.11766917088903738886\n",
      "Iteration 1806 => Loss: 52.11731874889223092850\n",
      "Iteration 1807 => Loss: 52.11696864056798972342\n",
      "Iteration 1808 => Loss: 52.11661884523225296562\n",
      "Iteration 1809 => Loss: 52.11626936220248751397\n",
      "Iteration 1810 => Loss: 52.11592019079763815625\n",
      "Iteration 1811 => Loss: 52.11557133033812760914\n",
      "Iteration 1812 => Loss: 52.11522278014584941275\n",
      "Iteration 1813 => Loss: 52.11487453954430293379\n",
      "Iteration 1814 => Loss: 52.11452660785830914847\n",
      "Iteration 1815 => Loss: 52.11417898441428775413\n",
      "Iteration 1816 => Loss: 52.11383166854005821733\n",
      "Iteration 1817 => Loss: 52.11348465956495346063\n",
      "Iteration 1818 => Loss: 52.11313795681977723007\n",
      "Iteration 1819 => Loss: 52.11279155963678988428\n",
      "Iteration 1820 => Loss: 52.11244546734972260538\n",
      "Iteration 1821 => Loss: 52.11209967929377029350\n",
      "Iteration 1822 => Loss: 52.11175419480554893426\n",
      "Iteration 1823 => Loss: 52.11140901322318086386\n",
      "Iteration 1824 => Loss: 52.11106413388621660943\n",
      "Iteration 1825 => Loss: 52.11071955613563488896\n",
      "Iteration 1826 => Loss: 52.11037527931391366565\n",
      "Iteration 1827 => Loss: 52.11003130276487382844\n",
      "Iteration 1828 => Loss: 52.10968762583388524945\n",
      "Iteration 1829 => Loss: 52.10934424786770335913\n",
      "Iteration 1830 => Loss: 52.10900116821450467341\n",
      "Iteration 1831 => Loss: 52.10865838622394363711\n",
      "Iteration 1832 => Loss: 52.10831590124698209365\n",
      "Iteration 1833 => Loss: 52.10797371263615929138\n",
      "Iteration 1834 => Loss: 52.10763181974532187724\n",
      "Iteration 1835 => Loss: 52.10729022192980863792\n",
      "Iteration 1836 => Loss: 52.10694891854630128591\n",
      "Iteration 1837 => Loss: 52.10660790895293104086\n",
      "Iteration 1838 => Loss: 52.10626719250923599702\n",
      "Iteration 1839 => Loss: 52.10592676857616112329\n",
      "Iteration 1840 => Loss: 52.10558663651603694689\n",
      "Iteration 1841 => Loss: 52.10524679569257955336\n",
      "Iteration 1842 => Loss: 52.10490724547094743002\n",
      "Iteration 1843 => Loss: 52.10456798521764198995\n",
      "Iteration 1844 => Loss: 52.10422901430059994254\n",
      "Iteration 1845 => Loss: 52.10389033208906539585\n",
      "Iteration 1846 => Loss: 52.10355193795378170307\n",
      "Iteration 1847 => Loss: 52.10321383126674987807\n",
      "Iteration 1848 => Loss: 52.10287601140144175815\n",
      "Iteration 1849 => Loss: 52.10253847773267210641\n",
      "Iteration 1850 => Loss: 52.10220122963656308457\n",
      "Iteration 1851 => Loss: 52.10186426649072188866\n",
      "Iteration 1852 => Loss: 52.10152758767402758622\n",
      "Iteration 1853 => Loss: 52.10119119256675190854\n",
      "Iteration 1854 => Loss: 52.10085508055053793441\n",
      "Iteration 1855 => Loss: 52.10051925100838587923\n",
      "Iteration 1856 => Loss: 52.10018370332459625160\n",
      "Iteration 1857 => Loss: 52.09984843688487643476\n",
      "Iteration 1858 => Loss: 52.09951345107624831599\n",
      "Iteration 1859 => Loss: 52.09917874528711934090\n",
      "Iteration 1860 => Loss: 52.09884431890719724834\n",
      "Iteration 1861 => Loss: 52.09851017132749717575\n",
      "Iteration 1862 => Loss: 52.09817630194046955694\n",
      "Iteration 1863 => Loss: 52.09784271013980827547\n",
      "Iteration 1864 => Loss: 52.09750939532059277326\n",
      "Iteration 1865 => Loss: 52.09717635687916725828\n",
      "Iteration 1866 => Loss: 52.09684359421324018058\n",
      "Iteration 1867 => Loss: 52.09651110672186291595\n",
      "Iteration 1868 => Loss: 52.09617889380533739541\n",
      "Iteration 1869 => Loss: 52.09584695486534400288\n",
      "Iteration 1870 => Loss: 52.09551528930485631008\n",
      "Iteration 1871 => Loss: 52.09518389652811265478\n",
      "Iteration 1872 => Loss: 52.09485277594072272223\n",
      "Iteration 1873 => Loss: 52.09452192694953964747\n",
      "Iteration 1874 => Loss: 52.09419134896278791302\n",
      "Iteration 1875 => Loss: 52.09386104138994966206\n",
      "Iteration 1876 => Loss: 52.09353100364175048753\n",
      "Iteration 1877 => Loss: 52.09320123513028732987\n",
      "Iteration 1878 => Loss: 52.09287173526893610642\n",
      "Iteration 1879 => Loss: 52.09254250347230907892\n",
      "Iteration 1880 => Loss: 52.09221353915635432941\n",
      "Iteration 1881 => Loss: 52.09188484173825628432\n",
      "Iteration 1882 => Loss: 52.09155641063649966327\n",
      "Iteration 1883 => Loss: 52.09122824527086947910\n",
      "Iteration 1884 => Loss: 52.09090034506236577272\n",
      "Iteration 1885 => Loss: 52.09057270943328887824\n",
      "Iteration 1886 => Loss: 52.09024533780723231757\n",
      "Iteration 1887 => Loss: 52.08991822960898332440\n",
      "Iteration 1888 => Loss: 52.08959138426467205818\n",
      "Iteration 1889 => Loss: 52.08926480120162239018\n",
      "Iteration 1890 => Loss: 52.08893847984844427401\n",
      "Iteration 1891 => Loss: 52.08861241963497690222\n",
      "Iteration 1892 => Loss: 52.08828661999237397140\n",
      "Iteration 1893 => Loss: 52.08796108035296157368\n",
      "Iteration 1894 => Loss: 52.08763580015030925097\n",
      "Iteration 1895 => Loss: 52.08731077881927973294\n",
      "Iteration 1896 => Loss: 52.08698601579592946109\n",
      "Iteration 1897 => Loss: 52.08666151051762227553\n",
      "Iteration 1898 => Loss: 52.08633726242286599017\n",
      "Iteration 1899 => Loss: 52.08601327095144029045\n",
      "Iteration 1900 => Loss: 52.08568953554436120612\n",
      "Iteration 1901 => Loss: 52.08536605564388111134\n",
      "Iteration 1902 => Loss: 52.08504283069340345946\n",
      "Iteration 1903 => Loss: 52.08471986013763199708\n",
      "Iteration 1904 => Loss: 52.08439714342245707712\n",
      "Iteration 1905 => Loss: 52.08407467999499118605\n",
      "Iteration 1906 => Loss: 52.08375246930354762753\n",
      "Iteration 1907 => Loss: 52.08343051079764052247\n",
      "Iteration 1908 => Loss: 52.08310880392799901983\n",
      "Iteration 1909 => Loss: 52.08278734814660282382\n",
      "Iteration 1910 => Loss: 52.08246614290655429613\n",
      "Iteration 1911 => Loss: 52.08214518766219214285\n",
      "Iteration 1912 => Loss: 52.08182448186906299270\n",
      "Iteration 1913 => Loss: 52.08150402498389297534\n",
      "Iteration 1914 => Loss: 52.08118381646460903767\n",
      "Iteration 1915 => Loss: 52.08086385577033894378\n",
      "Iteration 1916 => Loss: 52.08054414236132600990\n",
      "Iteration 1917 => Loss: 52.08022467569904279117\n",
      "Iteration 1918 => Loss: 52.07990545524618397621\n",
      "Iteration 1919 => Loss: 52.07958648046657401665\n",
      "Iteration 1920 => Loss: 52.07926775082521686500\n",
      "Iteration 1921 => Loss: 52.07894926578831729103\n",
      "Iteration 1922 => Loss: 52.07863102482318851116\n",
      "Iteration 1923 => Loss: 52.07831302739837298077\n",
      "Iteration 1924 => Loss: 52.07799527298355712901\n",
      "Iteration 1925 => Loss: 52.07767776104956425343\n",
      "Iteration 1926 => Loss: 52.07736049106844689049\n",
      "Iteration 1927 => Loss: 52.07704346251335181250\n",
      "Iteration 1928 => Loss: 52.07672667485858397640\n",
      "Iteration 1929 => Loss: 52.07641012757963494550\n",
      "Iteration 1930 => Loss: 52.07609382015309762437\n",
      "Iteration 1931 => Loss: 52.07577775205678705106\n",
      "Iteration 1932 => Loss: 52.07546192276956986689\n",
      "Iteration 1933 => Loss: 52.07514633177152774124\n",
      "Iteration 1934 => Loss: 52.07483097854385789560\n",
      "Iteration 1935 => Loss: 52.07451586256890152526\n",
      "Iteration 1936 => Loss: 52.07420098333010827218\n",
      "Iteration 1937 => Loss: 52.07388634031207885755\n",
      "Iteration 1938 => Loss: 52.07357193300057218721\n",
      "Iteration 1939 => Loss: 52.07325776088240587569\n",
      "Iteration 1940 => Loss: 52.07294382344559835474\n",
      "Iteration 1941 => Loss: 52.07263012017923387020\n",
      "Iteration 1942 => Loss: 52.07231665057351932546\n",
      "Iteration 1943 => Loss: 52.07200341411984823026\n",
      "Iteration 1944 => Loss: 52.07169041031065859215\n",
      "Iteration 1945 => Loss: 52.07137763863950397081\n",
      "Iteration 1946 => Loss: 52.07106509860106058341\n",
      "Iteration 1947 => Loss: 52.07075278969115572636\n",
      "Iteration 1948 => Loss: 52.07044071140663277220\n",
      "Iteration 1949 => Loss: 52.07012886324552880524\n",
      "Iteration 1950 => Loss: 52.06981724470689698592\n",
      "Iteration 1951 => Loss: 52.06950585529097708104\n",
      "Iteration 1952 => Loss: 52.06919469449904624980\n",
      "Iteration 1953 => Loss: 52.06888376183346878179\n",
      "Iteration 1954 => Loss: 52.06857305679774583496\n",
      "Iteration 1955 => Loss: 52.06826257889641595966\n",
      "Iteration 1956 => Loss: 52.06795232763515457464\n",
      "Iteration 1957 => Loss: 52.06764230252064606930\n",
      "Iteration 1958 => Loss: 52.06733250306075433400\n",
      "Iteration 1959 => Loss: 52.06702292876435933522\n",
      "Iteration 1960 => Loss: 52.06671357914142816981\n",
      "Iteration 1961 => Loss: 52.06640445370300085415\n",
      "Iteration 1962 => Loss: 52.06609555196116900788\n",
      "Iteration 1963 => Loss: 52.06578687342915401359\n",
      "Iteration 1964 => Loss: 52.06547841762119332998\n",
      "Iteration 1965 => Loss: 52.06517018405262575698\n",
      "Iteration 1966 => Loss: 52.06486217223980617064\n",
      "Iteration 1967 => Loss: 52.06455438170015526111\n",
      "Iteration 1968 => Loss: 52.06424681195222348151\n",
      "Iteration 1969 => Loss: 52.06393946251550630677\n",
      "Iteration 1970 => Loss: 52.06363233291062897479\n",
      "Iteration 1971 => Loss: 52.06332542265929674841\n",
      "Iteration 1972 => Loss: 52.06301873128414570147\n",
      "Iteration 1973 => Loss: 52.06271225830897009246\n",
      "Iteration 1974 => Loss: 52.06240600325852341257\n",
      "Iteration 1975 => Loss: 52.06209996565869602136\n",
      "Iteration 1976 => Loss: 52.06179414503632330025\n",
      "Iteration 1977 => Loss: 52.06148854091934907729\n",
      "Iteration 1978 => Loss: 52.06118315283668351867\n",
      "Iteration 1979 => Loss: 52.06087798031835944812\n",
      "Iteration 1980 => Loss: 52.06057302289536181661\n",
      "Iteration 1981 => Loss: 52.06026828009970586209\n",
      "Iteration 1982 => Loss: 52.05996375146450105831\n",
      "Iteration 1983 => Loss: 52.05965943652380900630\n",
      "Iteration 1984 => Loss: 52.05935533481273580492\n",
      "Iteration 1985 => Loss: 52.05905144586742494539\n",
      "Iteration 1986 => Loss: 52.05874776922503599508\n",
      "Iteration 1987 => Loss: 52.05844430442368775402\n",
      "Iteration 1988 => Loss: 52.05814105100260036352\n",
      "Iteration 1989 => Loss: 52.05783800850193188126\n",
      "Iteration 1990 => Loss: 52.05753517646287775733\n",
      "Iteration 1991 => Loss: 52.05723255442762820167\n",
      "Iteration 1992 => Loss: 52.05693014193941081658\n",
      "Iteration 1993 => Loss: 52.05662793854240533165\n",
      "Iteration 1994 => Loss: 52.05632594378178623629\n",
      "Iteration 1995 => Loss: 52.05602415720380804487\n",
      "Iteration 1996 => Loss: 52.05572257835561345019\n",
      "Iteration 1997 => Loss: 52.05542120678545359169\n",
      "Iteration 1998 => Loss: 52.05512004204242515470\n",
      "Iteration 1999 => Loss: 52.05481908367674748206\n",
      "Iteration 2000 => Loss: 52.05451833123953520044\n",
      "Iteration 2001 => Loss: 52.05421778428296164520\n",
      "Iteration 2002 => Loss: 52.05391744236010254099\n",
      "Iteration 2003 => Loss: 52.05361730502507811025\n",
      "Iteration 2004 => Loss: 52.05331737183295359728\n",
      "Iteration 2005 => Loss: 52.05301764233980321706\n",
      "Iteration 2006 => Loss: 52.05271811610258225755\n",
      "Iteration 2007 => Loss: 52.05241879267936155884\n",
      "Iteration 2008 => Loss: 52.05211967162904329598\n",
      "Iteration 2009 => Loss: 52.05182075251160256357\n",
      "Iteration 2010 => Loss: 52.05152203488788842378\n",
      "Iteration 2011 => Loss: 52.05122351831980154202\n",
      "Iteration 2012 => Loss: 52.05092520237011655126\n",
      "Iteration 2013 => Loss: 52.05062708660263126603\n",
      "Iteration 2014 => Loss: 52.05032917058206720640\n",
      "Iteration 2015 => Loss: 52.05003145387411223055\n",
      "Iteration 2016 => Loss: 52.04973393604539921853\n",
      "Iteration 2017 => Loss: 52.04943661666352028305\n",
      "Iteration 2018 => Loss: 52.04913949529701255869\n",
      "Iteration 2019 => Loss: 52.04884257151533688557\n",
      "Iteration 2020 => Loss: 52.04854584488893465277\n",
      "Iteration 2021 => Loss: 52.04824931498919937667\n",
      "Iteration 2022 => Loss: 52.04795298138839143576\n",
      "Iteration 2023 => Loss: 52.04765684365976596837\n",
      "Iteration 2024 => Loss: 52.04736090137750181839\n",
      "Iteration 2025 => Loss: 52.04706515411672285154\n",
      "Iteration 2026 => Loss: 52.04676960145346953368\n",
      "Iteration 2027 => Loss: 52.04647424296468471994\n",
      "Iteration 2028 => Loss: 52.04617907822832734155\n",
      "Iteration 2029 => Loss: 52.04588410682317345390\n",
      "Iteration 2030 => Loss: 52.04558932832897255594\n",
      "Iteration 2031 => Loss: 52.04529474232641206299\n",
      "Iteration 2032 => Loss: 52.04500034839708177969\n",
      "Iteration 2033 => Loss: 52.04470614612350232164\n",
      "Iteration 2034 => Loss: 52.04441213508904695573\n",
      "Iteration 2035 => Loss: 52.04411831487811923580\n",
      "Iteration 2036 => Loss: 52.04382468507588299644\n",
      "Iteration 2037 => Loss: 52.04353124526854657006\n",
      "Iteration 2038 => Loss: 52.04323799504319225662\n",
      "Iteration 2039 => Loss: 52.04294493398771948023\n",
      "Iteration 2040 => Loss: 52.04265206169103663569\n",
      "Iteration 2041 => Loss: 52.04235937774295450708\n",
      "Iteration 2042 => Loss: 52.04206688173404415920\n",
      "Iteration 2043 => Loss: 52.04177457325598510351\n",
      "Iteration 2044 => Loss: 52.04148245190115318337\n",
      "Iteration 2045 => Loss: 52.04119051726296163451\n",
      "Iteration 2046 => Loss: 52.04089876893564792226\n",
      "Iteration 2047 => Loss: 52.04060720651432347950\n",
      "Iteration 2048 => Loss: 52.04031582959500923380\n",
      "Iteration 2049 => Loss: 52.04002463777467824002\n",
      "Iteration 2050 => Loss: 52.03973363065107093917\n",
      "Iteration 2051 => Loss: 52.03944280782287989950\n",
      "Iteration 2052 => Loss: 52.03915216888964323516\n",
      "Iteration 2053 => Loss: 52.03886171345181566039\n",
      "Iteration 2054 => Loss: 52.03857144111070454073\n",
      "Iteration 2055 => Loss: 52.03828135146848410386\n",
      "Iteration 2056 => Loss: 52.03799144412822386130\n",
      "Iteration 2057 => Loss: 52.03770171869383176499\n",
      "Iteration 2058 => Loss: 52.03741217477010394532\n",
      "Iteration 2059 => Loss: 52.03712281196273181649\n",
      "Iteration 2060 => Loss: 52.03683362987819549517\n",
      "Iteration 2061 => Loss: 52.03654462812391301441\n",
      "Iteration 2062 => Loss: 52.03625580630812663685\n",
      "Iteration 2063 => Loss: 52.03596716403992417099\n",
      "Iteration 2064 => Loss: 52.03567870092929581460\n",
      "Iteration 2065 => Loss: 52.03539041658702046789\n",
      "Iteration 2066 => Loss: 52.03510231062482205289\n",
      "Iteration 2067 => Loss: 52.03481438265517766695\n",
      "Iteration 2068 => Loss: 52.03452663229150232382\n",
      "Iteration 2069 => Loss: 52.03423905914798552885\n",
      "Iteration 2070 => Loss: 52.03395166283970496579\n",
      "Iteration 2071 => Loss: 52.03366444298256965340\n",
      "Iteration 2072 => Loss: 52.03337739919328441829\n",
      "Iteration 2073 => Loss: 52.03309053108953463607\n",
      "Iteration 2074 => Loss: 52.03280383828968069793\n",
      "Iteration 2075 => Loss: 52.03251732041299248976\n",
      "Iteration 2076 => Loss: 52.03223097707959254876\n",
      "Iteration 2077 => Loss: 52.03194480791040632539\n",
      "Iteration 2078 => Loss: 52.03165881252720481598\n",
      "Iteration 2079 => Loss: 52.03137299055254771929\n",
      "Iteration 2080 => Loss: 52.03108734160990422879\n",
      "Iteration 2081 => Loss: 52.03080186532348250239\n",
      "Iteration 2082 => Loss: 52.03051656131840019270\n",
      "Iteration 2083 => Loss: 52.03023142922047838965\n",
      "Iteration 2084 => Loss: 52.02994646865647609957\n",
      "Iteration 2085 => Loss: 52.02966167925391260951\n",
      "Iteration 2086 => Loss: 52.02937706064115985782\n",
      "Iteration 2087 => Loss: 52.02909261244732874729\n",
      "Iteration 2088 => Loss: 52.02880833430243256998\n",
      "Iteration 2089 => Loss: 52.02852422583725200411\n",
      "Iteration 2090 => Loss: 52.02824028668337064119\n",
      "Iteration 2091 => Loss: 52.02795651647318209143\n",
      "Iteration 2092 => Loss: 52.02767291483993261636\n",
      "Iteration 2093 => Loss: 52.02738948141758612564\n",
      "Iteration 2094 => Loss: 52.02710621584099470738\n",
      "Iteration 2095 => Loss: 52.02682311774574941410\n",
      "Iteration 2096 => Loss: 52.02654018676827263334\n",
      "Iteration 2097 => Loss: 52.02625742254576834966\n",
      "Iteration 2098 => Loss: 52.02597482471627188261\n",
      "Iteration 2099 => Loss: 52.02569239291854330531\n",
      "Iteration 2100 => Loss: 52.02541012679219534220\n",
      "Iteration 2101 => Loss: 52.02512802597759389300\n",
      "Iteration 2102 => Loss: 52.02484609011592908701\n",
      "Iteration 2103 => Loss: 52.02456431884915133423\n",
      "Iteration 2104 => Loss: 52.02428271181999974715\n",
      "Iteration 2105 => Loss: 52.02400126867198082437\n",
      "Iteration 2106 => Loss: 52.02371998904942529407\n",
      "Iteration 2107 => Loss: 52.02343887259740284890\n",
      "Iteration 2108 => Loss: 52.02315791896178609477\n",
      "Iteration 2109 => Loss: 52.02287712778922923462\n",
      "Iteration 2110 => Loss: 52.02259649872712543583\n",
      "Iteration 2111 => Loss: 52.02231603142364235737\n",
      "Iteration 2112 => Loss: 52.02203572552775057147\n",
      "Iteration 2113 => Loss: 52.02175558068921645827\n",
      "Iteration 2114 => Loss: 52.02147559655850983518\n",
      "Iteration 2115 => Loss: 52.02119577278688211663\n",
      "Iteration 2116 => Loss: 52.02091610902636631408\n",
      "Iteration 2117 => Loss: 52.02063660492975571970\n",
      "Iteration 2118 => Loss: 52.02035726015058969551\n",
      "Iteration 2119 => Loss: 52.02007807434318920059\n",
      "Iteration 2120 => Loss: 52.01979904716261415842\n",
      "Iteration 2121 => Loss: 52.01952017826469187867\n",
      "Iteration 2122 => Loss: 52.01924146730600995170\n",
      "Iteration 2123 => Loss: 52.01896291394387361606\n",
      "Iteration 2124 => Loss: 52.01868451783641233988\n",
      "Iteration 2125 => Loss: 52.01840627864239507971\n",
      "Iteration 2126 => Loss: 52.01812819602145765430\n",
      "Iteration 2127 => Loss: 52.01785026963384694909\n",
      "Iteration 2128 => Loss: 52.01757249914074776598\n",
      "Iteration 2129 => Loss: 52.01729488420388491932\n",
      "Iteration 2130 => Loss: 52.01701742448582166389\n",
      "Iteration 2131 => Loss: 52.01674011964989574608\n",
      "Iteration 2132 => Loss: 52.01646296936009861156\n",
      "Iteration 2133 => Loss: 52.01618597328121751389\n",
      "Iteration 2134 => Loss: 52.01590913107876446020\n",
      "Iteration 2135 => Loss: 52.01563244241893357867\n",
      "Iteration 2136 => Loss: 52.01535590696875033245\n",
      "Iteration 2137 => Loss: 52.01507952439586546234\n",
      "Iteration 2138 => Loss: 52.01480329436875393867\n",
      "Iteration 2139 => Loss: 52.01452721655652311483\n",
      "Iteration 2140 => Loss: 52.01425129062906904664\n",
      "Iteration 2141 => Loss: 52.01397551625699833266\n",
      "Iteration 2142 => Loss: 52.01369989311162811418\n",
      "Iteration 2143 => Loss: 52.01342442086503581322\n",
      "Iteration 2144 => Loss: 52.01314909918991702398\n",
      "Iteration 2145 => Loss: 52.01287392775982709736\n",
      "Iteration 2146 => Loss: 52.01259890624888981847\n",
      "Iteration 2147 => Loss: 52.01232403433210293997\n",
      "Iteration 2148 => Loss: 52.01204931168503975414\n",
      "Iteration 2149 => Loss: 52.01177473798401251770\n",
      "Iteration 2150 => Loss: 52.01150031290610087353\n",
      "Iteration 2151 => Loss: 52.01122603612903816384\n",
      "Iteration 2152 => Loss: 52.01095190733131090610\n",
      "Iteration 2153 => Loss: 52.01067792619205221172\n",
      "Iteration 2154 => Loss: 52.01040409239114836737\n",
      "Iteration 2155 => Loss: 52.01013040560916778077\n",
      "Iteration 2156 => Loss: 52.00985686552736808608\n",
      "Iteration 2157 => Loss: 52.00958347182773167106\n",
      "Iteration 2158 => Loss: 52.00931022419288751735\n",
      "Iteration 2159 => Loss: 52.00903712230626041446\n",
      "Iteration 2160 => Loss: 52.00876416585185069152\n",
      "Iteration 2161 => Loss: 52.00849135451440474753\n",
      "Iteration 2162 => Loss: 52.00821868797938662965\n",
      "Iteration 2163 => Loss: 52.00794616593291408435\n",
      "Iteration 2164 => Loss: 52.00767378806180119000\n",
      "Iteration 2165 => Loss: 52.00740155405355835683\n",
      "Iteration 2166 => Loss: 52.00712946359635679983\n",
      "Iteration 2167 => Loss: 52.00685751637909248757\n",
      "Iteration 2168 => Loss: 52.00658571209128666624\n",
      "Iteration 2169 => Loss: 52.00631405042318533560\n",
      "Iteration 2170 => Loss: 52.00604253106571661647\n",
      "Iteration 2171 => Loss: 52.00577115371044811809\n",
      "Iteration 2172 => Loss: 52.00549991804964378161\n",
      "Iteration 2173 => Loss: 52.00522882377627098549\n",
      "Iteration 2174 => Loss: 52.00495787058393659663\n",
      "Iteration 2175 => Loss: 52.00468705816688697041\n",
      "Iteration 2176 => Loss: 52.00441638622014295379\n",
      "Iteration 2177 => Loss: 52.00414585443926540620\n",
      "Iteration 2178 => Loss: 52.00387546252053994067\n",
      "Iteration 2179 => Loss: 52.00360521016102666181\n",
      "Iteration 2180 => Loss: 52.00333509705824752700\n",
      "Iteration 2181 => Loss: 52.00306512291049187979\n",
      "Iteration 2182 => Loss: 52.00279528741673829018\n",
      "Iteration 2183 => Loss: 52.00252559027657639490\n",
      "Iteration 2184 => Loss: 52.00225603119029926802\n",
      "Iteration 2185 => Loss: 52.00198660985878973406\n",
      "Iteration 2186 => Loss: 52.00171732598361273858\n",
      "Iteration 2187 => Loss: 52.00144817926705798072\n",
      "Iteration 2188 => Loss: 52.00117916941196227754\n",
      "Iteration 2189 => Loss: 52.00091029612188719966\n",
      "Iteration 2190 => Loss: 52.00064155910099117364\n",
      "Iteration 2191 => Loss: 52.00037295805411474703\n",
      "Iteration 2192 => Loss: 52.00010449268674506129\n",
      "Iteration 2193 => Loss: 51.99983616270500164092\n",
      "Iteration 2194 => Loss: 51.99956796781564349885\n",
      "Iteration 2195 => Loss: 51.99929990772611176908\n",
      "Iteration 2196 => Loss: 51.99903198214447286318\n",
      "Iteration 2197 => Loss: 51.99876419077936162694\n",
      "Iteration 2198 => Loss: 51.99849653334013765971\n",
      "Iteration 2199 => Loss: 51.99822900953678583846\n",
      "Iteration 2200 => Loss: 51.99796161907990921236\n",
      "Iteration 2201 => Loss: 51.99769436168073610816\n",
      "Iteration 2202 => Loss: 51.99742723705110591936\n",
      "Iteration 2203 => Loss: 51.99716024490362542565\n",
      "Iteration 2204 => Loss: 51.99689338495130641604\n",
      "Iteration 2205 => Loss: 51.99662665690797780371\n",
      "Iteration 2206 => Loss: 51.99636006048804404145\n",
      "Iteration 2207 => Loss: 51.99609359540649933251\n",
      "Iteration 2208 => Loss: 51.99582726137896315777\n",
      "Iteration 2209 => Loss: 51.99556105812173001368\n",
      "Iteration 2210 => Loss: 51.99529498535170546347\n",
      "Iteration 2211 => Loss: 51.99502904278633508284\n",
      "Iteration 2212 => Loss: 51.99476323014378209564\n",
      "Iteration 2213 => Loss: 51.99449754714280658163\n",
      "Iteration 2214 => Loss: 51.99423199350273705477\n",
      "Iteration 2215 => Loss: 51.99396656894358415002\n",
      "Iteration 2216 => Loss: 51.99370127318591272569\n",
      "Iteration 2217 => Loss: 51.99343610595090581228\n",
      "Iteration 2218 => Loss: 51.99317106696044277214\n",
      "Iteration 2219 => Loss: 51.99290615593690034757\n",
      "Iteration 2220 => Loss: 51.99264137260332319102\n",
      "Iteration 2221 => Loss: 51.99237671668331728370\n",
      "Iteration 2222 => Loss: 51.99211218790118493871\n",
      "Iteration 2223 => Loss: 51.99184778598171874364\n",
      "Iteration 2224 => Loss: 51.99158351065042182881\n",
      "Iteration 2225 => Loss: 51.99131936163332312617\n",
      "Iteration 2226 => Loss: 51.99105533865708395069\n",
      "Iteration 2227 => Loss: 51.99079144144892694612\n",
      "Iteration 2228 => Loss: 51.99052766973674266637\n",
      "Iteration 2229 => Loss: 51.99026402324897588869\n",
      "Iteration 2230 => Loss: 51.99000050171464692994\n",
      "Iteration 2231 => Loss: 51.98973710486343691173\n",
      "Iteration 2232 => Loss: 51.98947383242553854643\n",
      "Iteration 2233 => Loss: 51.98921068413178403489\n",
      "Iteration 2234 => Loss: 51.98894765971357401213\n",
      "Iteration 2235 => Loss: 51.98868475890292017993\n",
      "Iteration 2236 => Loss: 51.98842198143240267427\n",
      "Iteration 2237 => Loss: 51.98815932703522690872\n",
      "Iteration 2238 => Loss: 51.98789679544511699305\n",
      "Iteration 2239 => Loss: 51.98763438639641520922\n",
      "Iteration 2240 => Loss: 51.98737209962407490593\n",
      "Iteration 2241 => Loss: 51.98710993486358944438\n",
      "Iteration 2242 => Loss: 51.98684789185102061992\n",
      "Iteration 2243 => Loss: 51.98658597032306261099\n",
      "Iteration 2244 => Loss: 51.98632417001692118674\n",
      "Iteration 2245 => Loss: 51.98606249067048423740\n",
      "Iteration 2246 => Loss: 51.98580093202206597880\n",
      "Iteration 2247 => Loss: 51.98553949381068406410\n",
      "Iteration 2248 => Loss: 51.98527817577585352637\n",
      "Iteration 2249 => Loss: 51.98501697765768625459\n",
      "Iteration 2250 => Loss: 51.98475589919685546647\n",
      "Iteration 2251 => Loss: 51.98449494013461702480\n",
      "Iteration 2252 => Loss: 51.98423410021278101567\n",
      "Iteration 2253 => Loss: 51.98397337917371885396\n",
      "Iteration 2254 => Loss: 51.98371277676042723215\n",
      "Iteration 2255 => Loss: 51.98345229271634337920\n",
      "Iteration 2256 => Loss: 51.98319192678557243426\n",
      "Iteration 2257 => Loss: 51.98293167871274533809\n",
      "Iteration 2258 => Loss: 51.98267154824304014937\n",
      "Iteration 2259 => Loss: 51.98241153512222467725\n",
      "Iteration 2260 => Loss: 51.98215163909659253250\n",
      "Iteration 2261 => Loss: 51.98189185991299154921\n",
      "Iteration 2262 => Loss: 51.98163219731890194453\n",
      "Iteration 2263 => Loss: 51.98137265106225868294\n",
      "Iteration 2264 => Loss: 51.98111322089154384685\n",
      "Iteration 2265 => Loss: 51.98085390655586479625\n",
      "Iteration 2266 => Loss: 51.98059470780489021990\n",
      "Iteration 2267 => Loss: 51.98033562438876487022\n",
      "Iteration 2268 => Loss: 51.98007665605816640664\n",
      "Iteration 2269 => Loss: 51.97981780256441908250\n",
      "Iteration 2270 => Loss: 51.97955906365931610935\n",
      "Iteration 2271 => Loss: 51.97930043909521202750\n",
      "Iteration 2272 => Loss: 51.97904192862502981143\n",
      "Iteration 2273 => Loss: 51.97878353200218981556\n",
      "Iteration 2274 => Loss: 51.97852524898068793391\n",
      "Iteration 2275 => Loss: 51.97826707931503165128\n",
      "Iteration 2276 => Loss: 51.97800902276027557036\n",
      "Iteration 2277 => Loss: 51.97775107907204983348\n",
      "Iteration 2278 => Loss: 51.97749324800644643574\n",
      "Iteration 2279 => Loss: 51.97723552932017554440\n",
      "Iteration 2280 => Loss: 51.97697792277040207409\n",
      "Iteration 2281 => Loss: 51.97672042811487358449\n",
      "Iteration 2282 => Loss: 51.97646304511185633146\n",
      "Iteration 2283 => Loss: 51.97620577352012816164\n",
      "Iteration 2284 => Loss: 51.97594861309903535584\n",
      "Iteration 2285 => Loss: 51.97569156360843578568\n",
      "Iteration 2286 => Loss: 51.97543462480867049180\n",
      "Iteration 2287 => Loss: 51.97517779646067026533\n",
      "Iteration 2288 => Loss: 51.97492107832582775018\n",
      "Iteration 2289 => Loss: 51.97466447016613244614\n",
      "Iteration 2290 => Loss: 51.97440797174400728409\n",
      "Iteration 2291 => Loss: 51.97415158282251468336\n",
      "Iteration 2292 => Loss: 51.97389530316511496721\n",
      "Iteration 2293 => Loss: 51.97363913253584399854\n",
      "Iteration 2294 => Loss: 51.97338307069922791470\n",
      "Iteration 2295 => Loss: 51.97312711742036839269\n",
      "Iteration 2296 => Loss: 51.97287127246485027854\n",
      "Iteration 2297 => Loss: 51.97261553559872737651\n",
      "Iteration 2298 => Loss: 51.97235990658861481961\n",
      "Iteration 2299 => Loss: 51.97210438520165354248\n",
      "Iteration 2300 => Loss: 51.97184897120541080540\n",
      "Iteration 2301 => Loss: 51.97159366436807914624\n",
      "Iteration 2302 => Loss: 51.97133846445829874483\n",
      "Iteration 2303 => Loss: 51.97108337124520716088\n",
      "Iteration 2304 => Loss: 51.97082838449845354489\n",
      "Iteration 2305 => Loss: 51.97057350398821284898\n",
      "Iteration 2306 => Loss: 51.97031872948515029975\n",
      "Iteration 2307 => Loss: 51.97006406076041429287\n",
      "Iteration 2308 => Loss: 51.96980949758570034192\n",
      "Iteration 2309 => Loss: 51.96955503973320134037\n",
      "Iteration 2310 => Loss: 51.96930068697550808565\n",
      "Iteration 2311 => Loss: 51.96904643908585086365\n",
      "Iteration 2312 => Loss: 51.96879229583791470759\n",
      "Iteration 2313 => Loss: 51.96853825700580387092\n",
      "Iteration 2314 => Loss: 51.96828432236422656842\n",
      "Iteration 2315 => Loss: 51.96803049168828181337\n",
      "Iteration 2316 => Loss: 51.96777676475364415865\n",
      "Iteration 2317 => Loss: 51.96752314133643579908\n",
      "Iteration 2318 => Loss: 51.96726962121334025824\n",
      "Iteration 2319 => Loss: 51.96701620416137501479\n",
      "Iteration 2320 => Loss: 51.96676288995823966843\n",
      "Iteration 2321 => Loss: 51.96650967838194645765\n",
      "Iteration 2322 => Loss: 51.96625656921111158226\n",
      "Iteration 2323 => Loss: 51.96600356222480598944\n",
      "Iteration 2324 => Loss: 51.96575065720254826829\n",
      "Iteration 2325 => Loss: 51.96549785392441833665\n",
      "Iteration 2326 => Loss: 51.96524515217090112174\n",
      "Iteration 2327 => Loss: 51.96499255172298603611\n",
      "Iteration 2328 => Loss: 51.96474005236215987225\n",
      "Iteration 2329 => Loss: 51.96448765387036416996\n",
      "Iteration 2330 => Loss: 51.96423535603001653271\n",
      "Iteration 2331 => Loss: 51.96398315862406747101\n",
      "Iteration 2332 => Loss: 51.96373106143590803185\n",
      "Iteration 2333 => Loss: 51.96347906424931295533\n",
      "Iteration 2334 => Loss: 51.96322716684870357540\n",
      "Iteration 2335 => Loss: 51.96297536901884939198\n",
      "Iteration 2336 => Loss: 51.96272367054503860118\n",
      "Iteration 2337 => Loss: 51.96247207121299283017\n",
      "Iteration 2338 => Loss: 51.96222057080897371861\n",
      "Iteration 2339 => Loss: 51.96196916911963370467\n",
      "Iteration 2340 => Loss: 51.96171786593214392269\n",
      "Iteration 2341 => Loss: 51.96146666103410183268\n",
      "Iteration 2342 => Loss: 51.96121555421362359084\n",
      "Iteration 2343 => Loss: 51.96096454525924457357\n",
      "Iteration 2344 => Loss: 51.96071363395998332635\n",
      "Iteration 2345 => Loss: 51.96046282010532735285\n",
      "Iteration 2346 => Loss: 51.96021210348516206068\n",
      "Iteration 2347 => Loss: 51.95996148388997681877\n",
      "Iteration 2348 => Loss: 51.95971096111052389688\n",
      "Iteration 2349 => Loss: 51.95946053493823058034\n",
      "Iteration 2350 => Loss: 51.95921020516478705531\n",
      "Iteration 2351 => Loss: 51.95895997158245904757\n",
      "Iteration 2352 => Loss: 51.95870983398391729224\n",
      "Iteration 2353 => Loss: 51.95845979216230858810\n",
      "Iteration 2354 => Loss: 51.95820984591124158669\n",
      "Iteration 2355 => Loss: 51.95795999502473705434\n",
      "Iteration 2356 => Loss: 51.95771023929732734814\n",
      "Iteration 2357 => Loss: 51.95746057852390009657\n",
      "Iteration 2358 => Loss: 51.95721101249993267857\n",
      "Iteration 2359 => Loss: 51.95696154102118669016\n",
      "Iteration 2360 => Loss: 51.95671216388403479414\n",
      "Iteration 2361 => Loss: 51.95646288088516229209\n",
      "Iteration 2362 => Loss: 51.95621369182176607637\n",
      "Iteration 2363 => Loss: 51.95596459649150489213\n",
      "Iteration 2364 => Loss: 51.95571559469239986129\n",
      "Iteration 2365 => Loss: 51.95546668622301922369\n",
      "Iteration 2366 => Loss: 51.95521787088231491225\n",
      "Iteration 2367 => Loss: 51.95496914846965097468\n",
      "Iteration 2368 => Loss: 51.95472051878490304944\n",
      "Iteration 2369 => Loss: 51.95447198162830204637\n",
      "Iteration 2370 => Loss: 51.95422353680061888781\n",
      "Iteration 2371 => Loss: 51.95397518410296555658\n",
      "Iteration 2372 => Loss: 51.95372692333696562628\n",
      "Iteration 2373 => Loss: 51.95347875430459794188\n",
      "Iteration 2374 => Loss: 51.95323067680833162285\n",
      "Iteration 2375 => Loss: 51.95298269065107632514\n",
      "Iteration 2376 => Loss: 51.95273479563615381949\n",
      "Iteration 2377 => Loss: 51.95248699156729799142\n",
      "Iteration 2378 => Loss: 51.95223927824871168468\n",
      "Iteration 2379 => Loss: 51.95199165548498143608\n",
      "Iteration 2380 => Loss: 51.95174412308116274062\n",
      "Iteration 2381 => Loss: 51.95149668084271610269\n",
      "Iteration 2382 => Loss: 51.95124932857555677401\n",
      "Iteration 2383 => Loss: 51.95100206608598369940\n",
      "Iteration 2384 => Loss: 51.95075489318077188727\n",
      "Iteration 2385 => Loss: 51.95050780966702319574\n",
      "Iteration 2386 => Loss: 51.95026081535240081166\n",
      "Iteration 2387 => Loss: 51.95001391004488766612\n",
      "Iteration 2388 => Loss: 51.94976709355287880499\n",
      "Iteration 2389 => Loss: 51.94952036568530928662\n",
      "Iteration 2390 => Loss: 51.94927372625139128104\n",
      "Iteration 2391 => Loss: 51.94902717506084144361\n",
      "Iteration 2392 => Loss: 51.94878071192372459564\n",
      "Iteration 2393 => Loss: 51.94853433665063136004\n",
      "Iteration 2394 => Loss: 51.94828804905244368229\n",
      "Iteration 2395 => Loss: 51.94804184894056220401\n",
      "Iteration 2396 => Loss: 51.94779573612670020566\n",
      "Iteration 2397 => Loss: 51.94754971042307545304\n",
      "Iteration 2398 => Loss: 51.94730377164227519415\n",
      "Iteration 2399 => Loss: 51.94705791959728458096\n",
      "Iteration 2400 => Loss: 51.94681215410155061818\n",
      "Iteration 2401 => Loss: 51.94656647496884716020\n",
      "Iteration 2402 => Loss: 51.94632088201343833589\n",
      "Iteration 2403 => Loss: 51.94607537504994354549\n",
      "Iteration 2404 => Loss: 51.94582995389341562031\n",
      "Iteration 2405 => Loss: 51.94558461835927687389\n",
      "Iteration 2406 => Loss: 51.94533936826343989424\n",
      "Iteration 2407 => Loss: 51.94509420342210148647\n",
      "Iteration 2408 => Loss: 51.94484912365192741390\n",
      "Iteration 2409 => Loss: 51.94460412877000976550\n",
      "Iteration 2410 => Loss: 51.94435921859380300702\n",
      "Iteration 2411 => Loss: 51.94411439294113819187\n",
      "Iteration 2412 => Loss: 51.94386965163030822623\n",
      "Iteration 2413 => Loss: 51.94362499447994707680\n",
      "Iteration 2414 => Loss: 51.94338042130912214134\n",
      "Iteration 2415 => Loss: 51.94313593193732714326\n",
      "Iteration 2416 => Loss: 51.94289152618434002306\n",
      "Iteration 2417 => Loss: 51.94264720387046452288\n",
      "Iteration 2418 => Loss: 51.94240296481630991821\n",
      "Iteration 2419 => Loss: 51.94215880884291891562\n",
      "Iteration 2420 => Loss: 51.94191473577169659848\n",
      "Iteration 2421 => Loss: 51.94167074542447437580\n",
      "Iteration 2422 => Loss: 51.94142683762345313880\n",
      "Iteration 2423 => Loss: 51.94118301219123878809\n",
      "Iteration 2424 => Loss: 51.94093926895081381190\n",
      "Iteration 2425 => Loss: 51.94069560772553728611\n",
      "Iteration 2426 => Loss: 51.94045202833915908514\n",
      "Iteration 2427 => Loss: 51.94020853061587672528\n",
      "Iteration 2428 => Loss: 51.93996511438017904538\n",
      "Iteration 2429 => Loss: 51.93972177945698120993\n",
      "Iteration 2430 => Loss: 51.93947852567160339277\n",
      "Iteration 2431 => Loss: 51.93923535284971393367\n",
      "Iteration 2432 => Loss: 51.93899226081737907634\n",
      "Iteration 2433 => Loss: 51.93874924940104875759\n",
      "Iteration 2434 => Loss: 51.93850631842754950185\n",
      "Iteration 2435 => Loss: 51.93826346772407021035\n",
      "Iteration 2436 => Loss: 51.93802069711821189912\n",
      "Iteration 2437 => Loss: 51.93777800643795217184\n",
      "Iteration 2438 => Loss: 51.93753539551163100896\n",
      "Iteration 2439 => Loss: 51.93729286416791524061\n",
      "Iteration 2440 => Loss: 51.93705041223596197142\n",
      "Iteration 2441 => Loss: 51.93680803954519120680\n",
      "Iteration 2442 => Loss: 51.93656574592548480496\n",
      "Iteration 2443 => Loss: 51.93632353120699463034\n",
      "Iteration 2444 => Loss: 51.93608139522036282187\n",
      "Iteration 2445 => Loss: 51.93583933779651573559\n",
      "Iteration 2446 => Loss: 51.93559735876679894773\n",
      "Iteration 2447 => Loss: 51.93535545796289909504\n",
      "Iteration 2448 => Loss: 51.93511363521685098021\n",
      "Iteration 2449 => Loss: 51.93487189036115125873\n",
      "Iteration 2450 => Loss: 51.93463022322859501401\n",
      "Iteration 2451 => Loss: 51.93438863365228996827\n",
      "Iteration 2452 => Loss: 51.93414712146579859109\n",
      "Iteration 2453 => Loss: 51.93390568650305993970\n",
      "Iteration 2454 => Loss: 51.93366432859827597213\n",
      "Iteration 2455 => Loss: 51.93342304758610339377\n",
      "Iteration 2456 => Loss: 51.93318184330153286510\n",
      "Iteration 2457 => Loss: 51.93294071557991031796\n",
      "Iteration 2458 => Loss: 51.93269966425695827184\n",
      "Iteration 2459 => Loss: 51.93245868916869767418\n",
      "Iteration 2460 => Loss: 51.93221779015161843063\n",
      "Iteration 2461 => Loss: 51.93197696704248755850\n",
      "Iteration 2462 => Loss: 51.93173621967843445191\n",
      "Iteration 2463 => Loss: 51.93149554789697219803\n",
      "Iteration 2464 => Loss: 51.93125495153599047171\n",
      "Iteration 2465 => Loss: 51.93101443043366316488\n",
      "Iteration 2466 => Loss: 51.93077398442859049510\n",
      "Iteration 2467 => Loss: 51.93053361335970663504\n",
      "Iteration 2468 => Loss: 51.93029331706621576359\n",
      "Iteration 2469 => Loss: 51.93005309538782654499\n",
      "Iteration 2470 => Loss: 51.92981294816449633345\n",
      "Iteration 2471 => Loss: 51.92957287523652354366\n",
      "Iteration 2472 => Loss: 51.92933287644463291599\n",
      "Iteration 2473 => Loss: 51.92909295162983340788\n",
      "Iteration 2474 => Loss: 51.92885310063349635357\n",
      "Iteration 2475 => Loss: 51.92861332329736256952\n",
      "Iteration 2476 => Loss: 51.92837361946351393271\n",
      "Iteration 2477 => Loss: 51.92813398897435206436\n",
      "Iteration 2478 => Loss: 51.92789443167266227874\n",
      "Iteration 2479 => Loss: 51.92765494740152121267\n",
      "Iteration 2480 => Loss: 51.92741553600443182859\n",
      "Iteration 2481 => Loss: 51.92717619732514577890\n",
      "Iteration 2482 => Loss: 51.92693693120781972539\n",
      "Iteration 2483 => Loss: 51.92669773749694428489\n",
      "Iteration 2484 => Loss: 51.92645861603730139677\n",
      "Iteration 2485 => Loss: 51.92621956667411353692\n",
      "Iteration 2486 => Loss: 51.92598058925285187115\n",
      "Iteration 2487 => Loss: 51.92574168361932862581\n",
      "Iteration 2488 => Loss: 51.92550284961979656373\n",
      "Iteration 2489 => Loss: 51.92526408710067897800\n",
      "Iteration 2490 => Loss: 51.92502539590889654164\n",
      "Iteration 2491 => Loss: 51.92478677589158309047\n",
      "Iteration 2492 => Loss: 51.92454822689633431310\n",
      "Iteration 2493 => Loss: 51.92430974877092353381\n",
      "Iteration 2494 => Loss: 51.92407134136361435139\n",
      "Iteration 2495 => Loss: 51.92383300452286931659\n",
      "Iteration 2496 => Loss: 51.92359473809757020035\n",
      "Iteration 2497 => Loss: 51.92335654193691141245\n",
      "Iteration 2498 => Loss: 51.92311841589040000144\n",
      "Iteration 2499 => Loss: 51.92288035980786986556\n",
      "Iteration 2500 => Loss: 51.92264237353951727982\n",
      "Iteration 2501 => Loss: 51.92240445693584405262\n",
      "Iteration 2502 => Loss: 51.92216660984765752573\n",
      "Iteration 2503 => Loss: 51.92192883212614873401\n",
      "Iteration 2504 => Loss: 51.92169112362280003481\n",
      "Iteration 2505 => Loss: 51.92145348418939221347\n",
      "Iteration 2506 => Loss: 51.92121591367806843209\n",
      "Iteration 2507 => Loss: 51.92097841194132001874\n",
      "Iteration 2508 => Loss: 51.92074097883193672942\n",
      "Iteration 2509 => Loss: 51.92050361420293569381\n",
      "Iteration 2510 => Loss: 51.92026631790783852693\n",
      "Iteration 2511 => Loss: 51.92002908980035869035\n",
      "Iteration 2512 => Loss: 51.91979192973455070614\n",
      "Iteration 2513 => Loss: 51.91955483756483147317\n",
      "Iteration 2514 => Loss: 51.91931781314590921284\n",
      "Iteration 2515 => Loss: 51.91908085633278346904\n",
      "Iteration 2516 => Loss: 51.91884396698083747879\n",
      "Iteration 2517 => Loss: 51.91860714494568185273\n",
      "Iteration 2518 => Loss: 51.91837039008332510548\n",
      "Iteration 2519 => Loss: 51.91813370225009549586\n",
      "Iteration 2520 => Loss: 51.91789708130254155094\n",
      "Iteration 2521 => Loss: 51.91766052709760970174\n",
      "Iteration 2522 => Loss: 51.91742403949253059636\n",
      "Iteration 2523 => Loss: 51.91718761834488304885\n",
      "Iteration 2524 => Loss: 51.91695126351249456320\n",
      "Iteration 2525 => Loss: 51.91671497485355502022\n",
      "Iteration 2526 => Loss: 51.91647875222655983407\n",
      "Iteration 2527 => Loss: 51.91624259549025310889\n",
      "Iteration 2528 => Loss: 51.91600650450380527445\n",
      "Iteration 2529 => Loss: 51.91577047912658571249\n",
      "Iteration 2530 => Loss: 51.91553451921834039240\n",
      "Iteration 2531 => Loss: 51.91529862463909239523\n",
      "Iteration 2532 => Loss: 51.91506279524912770285\n",
      "Iteration 2533 => Loss: 51.91482703090917283362\n",
      "Iteration 2534 => Loss: 51.91459133148014615244\n",
      "Iteration 2535 => Loss: 51.91435569682325734675\n",
      "Iteration 2536 => Loss: 51.91412012680008558618\n",
      "Iteration 2537 => Loss: 51.91388462127250136291\n",
      "Iteration 2538 => Loss: 51.91364918010269491333\n",
      "Iteration 2539 => Loss: 51.91341380315304121496\n",
      "Iteration 2540 => Loss: 51.91317849028640551978\n",
      "Iteration 2541 => Loss: 51.91294324136580939921\n",
      "Iteration 2542 => Loss: 51.91270805625460127430\n",
      "Iteration 2543 => Loss: 51.91247293481647062663\n",
      "Iteration 2544 => Loss: 51.91223787691538404943\n",
      "Iteration 2545 => Loss: 51.91200288241561366931\n",
      "Iteration 2546 => Loss: 51.91176795118169451371\n",
      "Iteration 2547 => Loss: 51.91153308307848845971\n",
      "Iteration 2548 => Loss: 51.91129827797117002319\n",
      "Iteration 2549 => Loss: 51.91106353572519083173\n",
      "Iteration 2550 => Loss: 51.91082885620625830825\n",
      "Iteration 2551 => Loss: 51.91059423928043514707\n",
      "Iteration 2552 => Loss: 51.91035968481407536501\n",
      "Iteration 2553 => Loss: 51.91012519267373903631\n",
      "Iteration 2554 => Loss: 51.90989076272643387711\n",
      "Iteration 2555 => Loss: 51.90965639483928129039\n",
      "Iteration 2556 => Loss: 51.90942208887982900478\n",
      "Iteration 2557 => Loss: 51.90918784471588054430\n",
      "Iteration 2558 => Loss: 51.90895366221548812291\n",
      "Iteration 2559 => Loss: 51.90871954124703080424\n",
      "Iteration 2560 => Loss: 51.90848548167915765816\n",
      "Iteration 2561 => Loss: 51.90825148338082328792\n",
      "Iteration 2562 => Loss: 51.90801754622126651384\n",
      "Iteration 2563 => Loss: 51.90778367007001037337\n",
      "Iteration 2564 => Loss: 51.90754985479684791017\n",
      "Iteration 2565 => Loss: 51.90731610027187059586\n",
      "Iteration 2566 => Loss: 51.90708240636546833002\n",
      "Iteration 2567 => Loss: 51.90684877294830812389\n",
      "Iteration 2568 => Loss: 51.90661519989129146779\n",
      "Iteration 2569 => Loss: 51.90638168706567512345\n",
      "Iteration 2570 => Loss: 51.90614823434297164795\n",
      "Iteration 2571 => Loss: 51.90591484159497071005\n",
      "Iteration 2572 => Loss: 51.90568150869373909018\n",
      "Iteration 2573 => Loss: 51.90544823551162778585\n",
      "Iteration 2574 => Loss: 51.90521502192125780084\n",
      "Iteration 2575 => Loss: 51.90498186779556277770\n",
      "Iteration 2576 => Loss: 51.90474877300772504896\n",
      "Iteration 2577 => Loss: 51.90451573743119695337\n",
      "Iteration 2578 => Loss: 51.90428276093976478478\n",
      "Iteration 2579 => Loss: 51.90404984340739247273\n",
      "Iteration 2580 => Loss: 51.90381698470840632353\n",
      "Iteration 2581 => Loss: 51.90358418471738843891\n",
      "Iteration 2582 => Loss: 51.90335144330920513767\n",
      "Iteration 2583 => Loss: 51.90311876035893590142\n",
      "Iteration 2584 => Loss: 51.90288613574199416689\n",
      "Iteration 2585 => Loss: 51.90265356933402074446\n",
      "Iteration 2586 => Loss: 51.90242106101102592675\n",
      "Iteration 2587 => Loss: 51.90218861064916922032\n",
      "Iteration 2588 => Loss: 51.90195621812494408687\n",
      "Iteration 2589 => Loss: 51.90172388331512820514\n",
      "Iteration 2590 => Loss: 51.90149160609671241673\n",
      "Iteration 2591 => Loss: 51.90125938634702151830\n",
      "Iteration 2592 => Loss: 51.90102722394363610192\n",
      "Iteration 2593 => Loss: 51.90079511876434281703\n",
      "Iteration 2594 => Loss: 51.90056307068724805731\n",
      "Iteration 2595 => Loss: 51.90033107959076374982\n",
      "Iteration 2596 => Loss: 51.90009914535348656273\n",
      "Iteration 2597 => Loss: 51.89986726785433290843\n",
      "Iteration 2598 => Loss: 51.89963544697246078385\n",
      "Iteration 2599 => Loss: 51.89940368258729108675\n",
      "Iteration 2600 => Loss: 51.89917197457855024822\n",
      "Iteration 2601 => Loss: 51.89894032282617075680\n",
      "Iteration 2602 => Loss: 51.89870872721037642350\n",
      "Iteration 2603 => Loss: 51.89847718761166106560\n",
      "Iteration 2604 => Loss: 51.89824570391078850662\n",
      "Iteration 2605 => Loss: 51.89801427598872862745\n",
      "Iteration 2606 => Loss: 51.89778290372679236953\n",
      "Iteration 2607 => Loss: 51.89755158700643988823\n",
      "Iteration 2608 => Loss: 51.89732032570954345374\n",
      "Iteration 2609 => Loss: 51.89708911971808191765\n",
      "Iteration 2610 => Loss: 51.89685796891443203549\n",
      "Iteration 2611 => Loss: 51.89662687318106293333\n",
      "Iteration 2612 => Loss: 51.89639583240089848459\n",
      "Iteration 2613 => Loss: 51.89616484645696203870\n",
      "Iteration 2614 => Loss: 51.89593391523258247844\n",
      "Iteration 2615 => Loss: 51.89570303861137290369\n",
      "Iteration 2616 => Loss: 51.89547221647716668258\n",
      "Iteration 2617 => Loss: 51.89524144871407429491\n",
      "Iteration 2618 => Loss: 51.89501073520643359416\n",
      "Iteration 2619 => Loss: 51.89478007583888086174\n",
      "Iteration 2620 => Loss: 51.89454947049624422561\n",
      "Iteration 2621 => Loss: 51.89431891906366445255\n",
      "Iteration 2622 => Loss: 51.89408842142647415585\n",
      "Iteration 2623 => Loss: 51.89385797747033279848\n",
      "Iteration 2624 => Loss: 51.89362758708105616279\n",
      "Iteration 2625 => Loss: 51.89339725014482951337\n",
      "Iteration 2626 => Loss: 51.89316696654794469623\n",
      "Iteration 2627 => Loss: 51.89293673617706303958\n",
      "Iteration 2628 => Loss: 51.89270655891903061274\n",
      "Iteration 2629 => Loss: 51.89247643466098480758\n",
      "Iteration 2630 => Loss: 51.89224636329026196790\n",
      "Iteration 2631 => Loss: 51.89201634469445423292\n",
      "Iteration 2632 => Loss: 51.89178637876145927521\n",
      "Iteration 2633 => Loss: 51.89155646537934529761\n",
      "Iteration 2634 => Loss: 51.89132660443645761461\n",
      "Iteration 2635 => Loss: 51.89109679582139023069\n",
      "Iteration 2636 => Loss: 51.89086703942297162939\n",
      "Iteration 2637 => Loss: 51.89063733513031451139\n",
      "Iteration 2638 => Loss: 51.89040768283266658045\n",
      "Iteration 2639 => Loss: 51.89017808241965923344\n",
      "Iteration 2640 => Loss: 51.88994853378107308117\n",
      "Iteration 2641 => Loss: 51.88971903680692321359\n",
      "Iteration 2642 => Loss: 51.88948959138755157028\n",
      "Iteration 2643 => Loss: 51.88926019741341377767\n",
      "Iteration 2644 => Loss: 51.88903085477538468240\n",
      "Iteration 2645 => Loss: 51.88880156336436044739\n",
      "Iteration 2646 => Loss: 51.88857232307167066665\n",
      "Iteration 2647 => Loss: 51.88834313378875862099\n",
      "Iteration 2648 => Loss: 51.88811399540733049207\n",
      "Iteration 2649 => Loss: 51.88788490781936957319\n",
      "Iteration 2650 => Loss: 51.88765587091708653134\n",
      "Iteration 2651 => Loss: 51.88742688459287677460\n",
      "Iteration 2652 => Loss: 51.88719794873945545532\n",
      "Iteration 2653 => Loss: 51.88696906324967983437\n",
      "Iteration 2654 => Loss: 51.88674022801671270599\n",
      "Iteration 2655 => Loss: 51.88651144293391581641\n",
      "Iteration 2656 => Loss: 51.88628270789491381265\n",
      "Iteration 2657 => Loss: 51.88605402279350897743\n",
      "Iteration 2658 => Loss: 51.88582538752383754854\n",
      "Iteration 2659 => Loss: 51.88559680198012102892\n",
      "Iteration 2660 => Loss: 51.88536826605696461456\n",
      "Iteration 2661 => Loss: 51.88513977964912982088\n",
      "Iteration 2662 => Loss: 51.88491134265154869354\n",
      "Iteration 2663 => Loss: 51.88468295495951565499\n",
      "Iteration 2664 => Loss: 51.88445461646846013082\n",
      "Iteration 2665 => Loss: 51.88422632707411707997\n",
      "Iteration 2666 => Loss: 51.88399808667232093740\n",
      "Iteration 2667 => Loss: 51.88376989515926140939\n",
      "Iteration 2668 => Loss: 51.88354175243133425965\n",
      "Iteration 2669 => Loss: 51.88331365838506314958\n",
      "Iteration 2670 => Loss: 51.88308561291734122278\n",
      "Iteration 2671 => Loss: 51.88285761592518952057\n",
      "Iteration 2672 => Loss: 51.88262966730589909048\n",
      "Iteration 2673 => Loss: 51.88240176695695993203\n",
      "Iteration 2674 => Loss: 51.88217391477611784012\n",
      "Iteration 2675 => Loss: 51.88194611066128913990\n",
      "Iteration 2676 => Loss: 51.88171835451068147904\n",
      "Iteration 2677 => Loss: 51.88149064622266593005\n",
      "Iteration 2678 => Loss: 51.88126298569588357168\n",
      "Iteration 2679 => Loss: 51.88103537282917443463\n",
      "Iteration 2680 => Loss: 51.88080780752160592328\n",
      "Iteration 2681 => Loss: 51.88058028967243018315\n",
      "Iteration 2682 => Loss: 51.88035281918117647137\n",
      "Iteration 2683 => Loss: 51.88012539594760852424\n",
      "Iteration 2684 => Loss: 51.87989801987162508112\n",
      "Iteration 2685 => Loss: 51.87967069085339488765\n",
      "Iteration 2686 => Loss: 51.87944340879332116856\n",
      "Iteration 2687 => Loss: 51.87921617359199899511\n",
      "Iteration 2688 => Loss: 51.87898898515025081224\n",
      "Iteration 2689 => Loss: 51.87876184336909801686\n",
      "Iteration 2690 => Loss: 51.87853474814981780128\n",
      "Iteration 2691 => Loss: 51.87830769939387920431\n",
      "Iteration 2692 => Loss: 51.87808069700295732218\n",
      "Iteration 2693 => Loss: 51.87785374087894751938\n",
      "Iteration 2694 => Loss: 51.87762683092400095575\n",
      "Iteration 2695 => Loss: 51.87739996704043221598\n",
      "Iteration 2696 => Loss: 51.87717314913079036387\n",
      "Iteration 2697 => Loss: 51.87694637709781630974\n",
      "Iteration 2698 => Loss: 51.87671965084451386474\n",
      "Iteration 2699 => Loss: 51.87649297027405737026\n",
      "Iteration 2700 => Loss: 51.87626633528980590881\n",
      "Iteration 2701 => Loss: 51.87603974579544541257\n",
      "Iteration 2702 => Loss: 51.87581320169473286796\n",
      "Iteration 2703 => Loss: 51.87558670289172368939\n",
      "Iteration 2704 => Loss: 51.87536024929067934863\n",
      "Iteration 2705 => Loss: 51.87513384079602474230\n",
      "Iteration 2706 => Loss: 51.87490747731241924612\n",
      "Iteration 2707 => Loss: 51.87468115874476382032\n",
      "Iteration 2708 => Loss: 51.87445488499812284999\n",
      "Iteration 2709 => Loss: 51.87422865597774546131\n",
      "Iteration 2710 => Loss: 51.87400247158919341928\n",
      "Iteration 2711 => Loss: 51.87377633173810664857\n",
      "Iteration 2712 => Loss: 51.87355023633045192355\n",
      "Iteration 2713 => Loss: 51.87332418527230259997\n",
      "Iteration 2714 => Loss: 51.87309817846998782898\n",
      "Iteration 2715 => Loss: 51.87287221583002150282\n",
      "Iteration 2716 => Loss: 51.87264629725915909830\n",
      "Iteration 2717 => Loss: 51.87242042266434083331\n",
      "Iteration 2718 => Loss: 51.87219459195269166685\n",
      "Iteration 2719 => Loss: 51.87196880503154972075\n",
      "Iteration 2720 => Loss: 51.87174306180845206882\n",
      "Iteration 2721 => Loss: 51.87151736219117736937\n",
      "Iteration 2722 => Loss: 51.87129170608765349471\n",
      "Iteration 2723 => Loss: 51.87106609340604990166\n",
      "Iteration 2724 => Loss: 51.87084052405466394475\n",
      "Iteration 2725 => Loss: 51.87061499794215535530\n",
      "Iteration 2726 => Loss: 51.87038951497716965378\n",
      "Iteration 2727 => Loss: 51.87016407506875026456\n",
      "Iteration 2728 => Loss: 51.86993867812599745548\n",
      "Iteration 2729 => Loss: 51.86971332405828860601\n",
      "Iteration 2730 => Loss: 51.86948801277516452046\n",
      "Iteration 2731 => Loss: 51.86926274418637206054\n",
      "Iteration 2732 => Loss: 51.86903751820187835619\n",
      "Iteration 2733 => Loss: 51.86881233473182106763\n",
      "Iteration 2734 => Loss: 51.86858719368654391246\n",
      "Iteration 2735 => Loss: 51.86836209497656113854\n",
      "Iteration 2736 => Loss: 51.86813703851263568367\n",
      "Iteration 2737 => Loss: 51.86791202420571522680\n",
      "Iteration 2738 => Loss: 51.86768705196688244996\n",
      "Iteration 2739 => Loss: 51.86746212170749004144\n",
      "Iteration 2740 => Loss: 51.86723723333903990351\n",
      "Iteration 2741 => Loss: 51.86701238677325420667\n",
      "Iteration 2742 => Loss: 51.86678758192203275712\n",
      "Iteration 2743 => Loss: 51.86656281869745299673\n",
      "Iteration 2744 => Loss: 51.86633809701181263563\n",
      "Iteration 2745 => Loss: 51.86611341677758701962\n",
      "Iteration 2746 => Loss: 51.86588877790747176277\n",
      "Iteration 2747 => Loss: 51.86566418031431169311\n",
      "Iteration 2748 => Loss: 51.86543962391117901234\n",
      "Iteration 2749 => Loss: 51.86521510861130224157\n",
      "Iteration 2750 => Loss: 51.86499063432813017016\n",
      "Iteration 2751 => Loss: 51.86476620097528211772\n",
      "Iteration 2752 => Loss: 51.86454180846656214499\n",
      "Iteration 2753 => Loss: 51.86431745671600879177\n",
      "Iteration 2754 => Loss: 51.86409314563775296847\n",
      "Iteration 2755 => Loss: 51.86386887514623822426\n",
      "Iteration 2756 => Loss: 51.86364464515600758432\n",
      "Iteration 2757 => Loss: 51.86342045558180302578\n",
      "Iteration 2758 => Loss: 51.86319630633859389945\n",
      "Iteration 2759 => Loss: 51.86297219734146324299\n",
      "Iteration 2760 => Loss: 51.86274812850578541656\n",
      "Iteration 2761 => Loss: 51.86252409974702715090\n",
      "Iteration 2762 => Loss: 51.86230011098086833954\n",
      "Iteration 2763 => Loss: 51.86207616212320203886\n",
      "Iteration 2764 => Loss: 51.86185225309007762462\n",
      "Iteration 2765 => Loss: 51.86162838379770789743\n",
      "Iteration 2766 => Loss: 51.86140455416254724241\n",
      "Iteration 2767 => Loss: 51.86118076410120636410\n",
      "Iteration 2768 => Loss: 51.86095701353040965387\n",
      "Iteration 2769 => Loss: 51.86073330236721545816\n",
      "Iteration 2770 => Loss: 51.86050963052871054515\n",
      "Iteration 2771 => Loss: 51.86028599793225168924\n",
      "Iteration 2772 => Loss: 51.86006240449538040593\n",
      "Iteration 2773 => Loss: 51.85983885013572347589\n",
      "Iteration 2774 => Loss: 51.85961533477123452940\n",
      "Iteration 2775 => Loss: 51.85939185831994535647\n",
      "Iteration 2776 => Loss: 51.85916842070004406651\n",
      "Iteration 2777 => Loss: 51.85894502183000298601\n",
      "Iteration 2778 => Loss: 51.85872166162840102288\n",
      "Iteration 2779 => Loss: 51.85849834001403024786\n",
      "Iteration 2780 => Loss: 51.85827505690582484021\n",
      "Iteration 2781 => Loss: 51.85805181222287529863\n",
      "Iteration 2782 => Loss: 51.85782860588454923345\n",
      "Iteration 2783 => Loss: 51.85760543781024267673\n",
      "Iteration 2784 => Loss: 51.85738230791973535361\n",
      "Iteration 2785 => Loss: 51.85715921613279277835\n",
      "Iteration 2786 => Loss: 51.85693616236942204978\n",
      "Iteration 2787 => Loss: 51.85671314654980079695\n",
      "Iteration 2788 => Loss: 51.85649016859430560089\n",
      "Iteration 2789 => Loss: 51.85626722842350488918\n",
      "Iteration 2790 => Loss: 51.85604432595808077622\n",
      "Iteration 2791 => Loss: 51.85582146111889301210\n",
      "Iteration 2792 => Loss: 51.85559863382701450973\n",
      "Iteration 2793 => Loss: 51.85537584400368871229\n",
      "Iteration 2794 => Loss: 51.85515309157032248777\n",
      "Iteration 2795 => Loss: 51.85493037644846481271\n",
      "Iteration 2796 => Loss: 51.85470769855987072106\n",
      "Iteration 2797 => Loss: 51.85448505782647288243\n",
      "Iteration 2798 => Loss: 51.85426245417034607499\n",
      "Iteration 2799 => Loss: 51.85403988751375692345\n",
      "Iteration 2800 => Loss: 51.85381735777911416108\n",
      "Iteration 2801 => Loss: 51.85359486488907521107\n",
      "Iteration 2802 => Loss: 51.85337240876635434006\n",
      "Iteration 2803 => Loss: 51.85314998933390739921\n",
      "Iteration 2804 => Loss: 51.85292760651486787538\n",
      "Iteration 2805 => Loss: 51.85270526023248294223\n",
      "Iteration 2806 => Loss: 51.85248295041020583085\n",
      "Iteration 2807 => Loss: 51.85226067697161767001\n",
      "Iteration 2808 => Loss: 51.85203843984056959471\n",
      "Iteration 2809 => Loss: 51.85181623894094116167\n",
      "Iteration 2810 => Loss: 51.85159407419689614471\n",
      "Iteration 2811 => Loss: 51.85137194553266937191\n",
      "Iteration 2812 => Loss: 51.85114985287275146675\n",
      "Iteration 2813 => Loss: 51.85092779614173252867\n",
      "Iteration 2814 => Loss: 51.85070577526437318738\n",
      "Iteration 2815 => Loss: 51.85048379016564723543\n",
      "Iteration 2816 => Loss: 51.85026184077064925759\n",
      "Iteration 2817 => Loss: 51.85003992700465147436\n",
      "Iteration 2818 => Loss: 51.84981804879306821476\n",
      "Iteration 2819 => Loss: 51.84959620606151986522\n",
      "Iteration 2820 => Loss: 51.84937439873578313154\n",
      "Iteration 2821 => Loss: 51.84915262674172709012\n",
      "Iteration 2822 => Loss: 51.84893089000549082357\n",
      "Iteration 2823 => Loss: 51.84870918845330578506\n",
      "Iteration 2824 => Loss: 51.84848752201156685260\n",
      "Iteration 2825 => Loss: 51.84826589060686785615\n",
      "Iteration 2826 => Loss: 51.84804429416591631252\n",
      "Iteration 2827 => Loss: 51.84782273261561158506\n",
      "Iteration 2828 => Loss: 51.84760120588302356737\n",
      "Iteration 2829 => Loss: 51.84737971389537136702\n",
      "Iteration 2830 => Loss: 51.84715825658000198928\n",
      "Iteration 2831 => Loss: 51.84693683386444718053\n",
      "Iteration 2832 => Loss: 51.84671544567639500656\n",
      "Iteration 2833 => Loss: 51.84649409194371116882\n",
      "Iteration 2834 => Loss: 51.84627277259438216106\n",
      "Iteration 2835 => Loss: 51.84605148755661474524\n",
      "Iteration 2836 => Loss: 51.84583023675867963220\n",
      "Iteration 2837 => Loss: 51.84560902012910332814\n",
      "Iteration 2838 => Loss: 51.84538783759645497184\n",
      "Iteration 2839 => Loss: 51.84516668908960923545\n",
      "Iteration 2840 => Loss: 51.84494557453745500197\n",
      "Iteration 2841 => Loss: 51.84472449386910142266\n",
      "Iteration 2842 => Loss: 51.84450344701383528445\n",
      "Iteration 2843 => Loss: 51.84428243390106416655\n",
      "Iteration 2844 => Loss: 51.84406145446034486213\n",
      "Iteration 2845 => Loss: 51.84384050862139758920\n",
      "Iteration 2846 => Loss: 51.84361959631413441230\n",
      "Iteration 2847 => Loss: 51.84339871746853845025\n",
      "Iteration 2848 => Loss: 51.84317787201483440640\n",
      "Iteration 2849 => Loss: 51.84295705988331803837\n",
      "Iteration 2850 => Loss: 51.84273628100451958289\n",
      "Iteration 2851 => Loss: 51.84251553530909717438\n",
      "Iteration 2852 => Loss: 51.84229482272778000151\n",
      "Iteration 2853 => Loss: 51.84207414319153883753\n",
      "Iteration 2854 => Loss: 51.84185349663148656418\n",
      "Iteration 2855 => Loss: 51.84163288297889948808\n",
      "Iteration 2856 => Loss: 51.84141230216511786466\n",
      "Iteration 2857 => Loss: 51.84119175412173774475\n",
      "Iteration 2858 => Loss: 51.84097123878044754974\n",
      "Iteration 2859 => Loss: 51.84075075607307070413\n",
      "Iteration 2860 => Loss: 51.84053030593161537354\n",
      "Iteration 2861 => Loss: 51.84030988828825314840\n",
      "Iteration 2862 => Loss: 51.84008950307528351686\n",
      "Iteration 2863 => Loss: 51.83986915022510544304\n",
      "Iteration 2864 => Loss: 51.83964882967035237016\n",
      "Iteration 2865 => Loss: 51.83942854134376432285\n",
      "Iteration 2866 => Loss: 51.83920828517823053971\n",
      "Iteration 2867 => Loss: 51.83898806110675394621\n",
      "Iteration 2868 => Loss: 51.83876786906252931431\n",
      "Iteration 2869 => Loss: 51.83854770897891484083\n",
      "Iteration 2870 => Loss: 51.83832758078937530399\n",
      "Iteration 2871 => Loss: 51.83810748442751048515\n",
      "Iteration 2872 => Loss: 51.83788741982709069589\n",
      "Iteration 2873 => Loss: 51.83766738692202835637\n",
      "Iteration 2874 => Loss: 51.83744738564640641698\n",
      "Iteration 2875 => Loss: 51.83722741593437177698\n",
      "Iteration 2876 => Loss: 51.83700747772032713101\n",
      "Iteration 2877 => Loss: 51.83678757093873201711\n",
      "Iteration 2878 => Loss: 51.83656769552422360903\n",
      "Iteration 2879 => Loss: 51.83634785141155276733\n",
      "Iteration 2880 => Loss: 51.83612803853569062085\n",
      "Iteration 2881 => Loss: 51.83590825683164382554\n",
      "Iteration 2882 => Loss: 51.83568850623465351646\n",
      "Iteration 2883 => Loss: 51.83546878668005319923\n",
      "Iteration 2884 => Loss: 51.83524909810332559346\n",
      "Iteration 2885 => Loss: 51.83502944044011684355\n",
      "Iteration 2886 => Loss: 51.83480981362614414820\n",
      "Iteration 2887 => Loss: 51.83459021759738760693\n",
      "Iteration 2888 => Loss: 51.83437065228986995180\n",
      "Iteration 2889 => Loss: 51.83415111763977733972\n",
      "Iteration 2890 => Loss: 51.83393161358343093070\n",
      "Iteration 2891 => Loss: 51.83371214005732241503\n",
      "Iteration 2892 => Loss: 51.83349269699807138068\n",
      "Iteration 2893 => Loss: 51.83327328434236846988\n",
      "Iteration 2894 => Loss: 51.83305390202716012027\n",
      "Iteration 2895 => Loss: 51.83283454998944961289\n",
      "Iteration 2896 => Loss: 51.83261522816638944278\n",
      "Iteration 2897 => Loss: 51.83239593649530974062\n",
      "Iteration 2898 => Loss: 51.83217667491363300769\n",
      "Iteration 2899 => Loss: 51.83195744335892385379\n",
      "Iteration 2900 => Loss: 51.83173824176891031357\n",
      "Iteration 2901 => Loss: 51.83151907008145542477\n",
      "Iteration 2902 => Loss: 51.83129992823450749029\n",
      "Iteration 2903 => Loss: 51.83108081616620665955\n",
      "Iteration 2904 => Loss: 51.83086173381482808509\n",
      "Iteration 2905 => Loss: 51.83064268111875350087\n",
      "Iteration 2906 => Loss: 51.83042365801647122225\n",
      "Iteration 2907 => Loss: 51.83020466444668983286\n",
      "Iteration 2908 => Loss: 51.82998570034819607599\n",
      "Iteration 2909 => Loss: 51.82976676565991880352\n",
      "Iteration 2910 => Loss: 51.82954786032091476500\n",
      "Iteration 2911 => Loss: 51.82932898427039702938\n",
      "Iteration 2912 => Loss: 51.82911013744765682532\n",
      "Iteration 2913 => Loss: 51.82889131979221275515\n",
      "Iteration 2914 => Loss: 51.82867253124363315919\n",
      "Iteration 2915 => Loss: 51.82845377174163559175\n",
      "Iteration 2916 => Loss: 51.82823504122609392653\n",
      "Iteration 2917 => Loss: 51.82801633963703835661\n",
      "Iteration 2918 => Loss: 51.82779766691456302397\n",
      "Iteration 2919 => Loss: 51.82757902299889707365\n",
      "Iteration 2920 => Loss: 51.82736040783045439184\n",
      "Iteration 2921 => Loss: 51.82714182134974123528\n",
      "Iteration 2922 => Loss: 51.82692326349743439096\n",
      "Iteration 2923 => Loss: 51.82670473421429591099\n",
      "Iteration 2924 => Loss: 51.82648623344120153433\n",
      "Iteration 2925 => Loss: 51.82626776111921174106\n",
      "Iteration 2926 => Loss: 51.82604931718951490893\n",
      "Iteration 2927 => Loss: 51.82583090159341310255\n",
      "Iteration 2928 => Loss: 51.82561251427226522992\n",
      "Iteration 2929 => Loss: 51.82539415516766467817\n",
      "Iteration 2930 => Loss: 51.82517582422131852127\n",
      "Iteration 2931 => Loss: 51.82495752137498357115\n",
      "Iteration 2932 => Loss: 51.82473924657064401345\n",
      "Iteration 2933 => Loss: 51.82452099975033377177\n",
      "Iteration 2934 => Loss: 51.82430278085623598372\n",
      "Iteration 2935 => Loss: 51.82408458983069721171\n",
      "Iteration 2936 => Loss: 51.82386642661613507244\n",
      "Iteration 2937 => Loss: 51.82364829115514481828\n",
      "Iteration 2938 => Loss: 51.82343018339037143960\n",
      "Iteration 2939 => Loss: 51.82321210326470861673\n",
      "Iteration 2940 => Loss: 51.82299405072103581915\n",
      "Iteration 2941 => Loss: 51.82277602570246699543\n",
      "Iteration 2942 => Loss: 51.82255802815216583213\n",
      "Iteration 2943 => Loss: 51.82234005801350207321\n",
      "Iteration 2944 => Loss: 51.82212211522984546264\n",
      "Iteration 2945 => Loss: 51.82190419974484996146\n",
      "Iteration 2946 => Loss: 51.82168631150212689818\n",
      "Iteration 2947 => Loss: 51.82146845044555760751\n",
      "Iteration 2948 => Loss: 51.82125061651904474047\n",
      "Iteration 2949 => Loss: 51.82103280966666147833\n",
      "Iteration 2950 => Loss: 51.82081502983259468920\n",
      "Iteration 2951 => Loss: 51.82059727696115203344\n",
      "Iteration 2952 => Loss: 51.82037955099675485826\n",
      "Iteration 2953 => Loss: 51.82016185188394530314\n",
      "Iteration 2954 => Loss: 51.81994417956740761610\n",
      "Iteration 2955 => Loss: 51.81972653399196104829\n",
      "Iteration 2956 => Loss: 51.81950891510246748339\n",
      "Iteration 2957 => Loss: 51.81929132284398775710\n",
      "Iteration 2958 => Loss: 51.81907375716168218105\n",
      "Iteration 2959 => Loss: 51.81885621800083896460\n",
      "Iteration 2960 => Loss: 51.81863870530679605508\n",
      "Iteration 2961 => Loss: 51.81842121902515430065\n",
      "Iteration 2962 => Loss: 51.81820375910148612775\n",
      "Iteration 2963 => Loss: 51.81798632548154159849\n",
      "Iteration 2964 => Loss: 51.81776891811123419984\n",
      "Iteration 2965 => Loss: 51.81755153693652005131\n",
      "Iteration 2966 => Loss: 51.81733418190354711896\n",
      "Iteration 2967 => Loss: 51.81711685295851310684\n",
      "Iteration 2968 => Loss: 51.81689955004777914382\n",
      "Iteration 2969 => Loss: 51.81668227311779162392\n",
      "Iteration 2970 => Loss: 51.81646502211516747138\n",
      "Iteration 2971 => Loss: 51.81624779698653782134\n",
      "Iteration 2972 => Loss: 51.81603059767876828801\n",
      "Iteration 2973 => Loss: 51.81581342413877422359\n",
      "Iteration 2974 => Loss: 51.81559627631364151057\n",
      "Iteration 2975 => Loss: 51.81537915415047734768\n",
      "Iteration 2976 => Loss: 51.81516205759654525309\n",
      "Iteration 2977 => Loss: 51.81494498659933611862\n",
      "Iteration 2978 => Loss: 51.81472794110628399267\n",
      "Iteration 2979 => Loss: 51.81451092106504319190\n",
      "Iteration 2980 => Loss: 51.81429392642332487640\n",
      "Iteration 2981 => Loss: 51.81407695712899652563\n",
      "Iteration 2982 => Loss: 51.81386001313005351676\n",
      "Iteration 2983 => Loss: 51.81364309437454096496\n",
      "Iteration 2984 => Loss: 51.81342620081067451565\n",
      "Iteration 2985 => Loss: 51.81320933238677639565\n",
      "Iteration 2986 => Loss: 51.81299248905125409692\n",
      "Iteration 2987 => Loss: 51.81277567075263590368\n",
      "Iteration 2988 => Loss: 51.81255887743957089242\n",
      "Iteration 2989 => Loss: 51.81234210906084314274\n",
      "Iteration 2990 => Loss: 51.81212536556531489396\n",
      "Iteration 2991 => Loss: 51.81190864690197628306\n",
      "Iteration 2992 => Loss: 51.81169195301990271219\n",
      "Iteration 2993 => Loss: 51.81147528386833300829\n",
      "Iteration 2994 => Loss: 51.81125863939657705259\n",
      "Iteration 2995 => Loss: 51.81104201955406551861\n",
      "Iteration 2996 => Loss: 51.81082542429034276665\n",
      "Iteration 2997 => Loss: 51.81060885355505973848\n",
      "Iteration 2998 => Loss: 51.81039230729796685182\n",
      "Iteration 2999 => Loss: 51.81017578546898505465\n",
      "Iteration 3000 => Loss: 51.80995928801804240038\n",
      "Iteration 3001 => Loss: 51.80974281489526589439\n",
      "Iteration 3002 => Loss: 51.80952636605084649091\n",
      "Iteration 3003 => Loss: 51.80930994143507462013\n",
      "Iteration 3004 => Loss: 51.80909354099841834795\n",
      "Iteration 3005 => Loss: 51.80887716469137416198\n",
      "Iteration 3006 => Loss: 51.80866081246456644749\n",
      "Iteration 3007 => Loss: 51.80844448426876880376\n",
      "Iteration 3008 => Loss: 51.80822818005484720061\n",
      "Iteration 3009 => Loss: 51.80801189977372445128\n",
      "Iteration 3010 => Loss: 51.80779564337652232098\n",
      "Iteration 3011 => Loss: 51.80757941081435546948\n",
      "Iteration 3012 => Loss: 51.80736320203853750854\n",
      "Iteration 3013 => Loss: 51.80714701700046020960\n",
      "Iteration 3014 => Loss: 51.80693085565159350381\n",
      "Iteration 3015 => Loss: 51.80671471794359206342\n",
      "Iteration 3016 => Loss: 51.80649860382812477155\n",
      "Iteration 3017 => Loss: 51.80628251325703104158\n",
      "Iteration 3018 => Loss: 51.80606644618219291942\n",
      "Iteration 3019 => Loss: 51.80585040255567719214\n",
      "Iteration 3020 => Loss: 51.80563438232959327934\n",
      "Iteration 3021 => Loss: 51.80541838545617849832\n",
      "Iteration 3022 => Loss: 51.80520241188779095864\n",
      "Iteration 3023 => Loss: 51.80498646157685982416\n",
      "Iteration 3024 => Loss: 51.80477053447589952384\n",
      "Iteration 3025 => Loss: 51.80455463053763054404\n",
      "Iteration 3026 => Loss: 51.80433874971477337112\n",
      "Iteration 3027 => Loss: 51.80412289196018349458\n",
      "Iteration 3028 => Loss: 51.80390705722683719614\n",
      "Iteration 3029 => Loss: 51.80369124546780312812\n",
      "Iteration 3030 => Loss: 51.80347545663625652423\n",
      "Iteration 3031 => Loss: 51.80325969068545077789\n",
      "Iteration 3032 => Loss: 51.80304394756876007477\n",
      "Iteration 3033 => Loss: 51.80282822723968649825\n",
      "Iteration 3034 => Loss: 51.80261252965178897512\n",
      "Iteration 3035 => Loss: 51.80239685475874722442\n",
      "Iteration 3036 => Loss: 51.80218120251434754664\n",
      "Iteration 3037 => Loss: 51.80196557287246861279\n",
      "Iteration 3038 => Loss: 51.80174996578710278072\n",
      "Iteration 3039 => Loss: 51.80153438121232767344\n",
      "Iteration 3040 => Loss: 51.80131881910234881161\n",
      "Iteration 3041 => Loss: 51.80110327941143566477\n",
      "Iteration 3042 => Loss: 51.80088776209395717842\n",
      "Iteration 3043 => Loss: 51.80067226710442440663\n",
      "Iteration 3044 => Loss: 51.80045679439741945771\n",
      "Iteration 3045 => Loss: 51.80024134392765233770\n",
      "Iteration 3046 => Loss: 51.80002591564984726347\n",
      "Iteration 3047 => Loss: 51.79981050951896293100\n",
      "Iteration 3048 => Loss: 51.79959512548989408742\n",
      "Iteration 3049 => Loss: 51.79937976351781969697\n",
      "Iteration 3050 => Loss: 51.79916442355783345874\n",
      "Iteration 3051 => Loss: 51.79894910556527065637\n",
      "Iteration 3052 => Loss: 51.79873380949548788976\n",
      "Iteration 3053 => Loss: 51.79851853530394834024\n",
      "Iteration 3054 => Loss: 51.79830328294623598140\n",
      "Iteration 3055 => Loss: 51.79808805237804847366\n",
      "Iteration 3056 => Loss: 51.79787284355509768830\n",
      "Iteration 3057 => Loss: 51.79765765643327313228\n",
      "Iteration 3058 => Loss: 51.79744249096854957770\n",
      "Iteration 3059 => Loss: 51.79722734711693732379\n",
      "Iteration 3060 => Loss: 51.79701222483463141089\n",
      "Iteration 3061 => Loss: 51.79679712407789082818\n",
      "Iteration 3062 => Loss: 51.79658204480301009198\n",
      "Iteration 3063 => Loss: 51.79636698696646135431\n",
      "Iteration 3064 => Loss: 51.79615195052480203231\n",
      "Iteration 3065 => Loss: 51.79593693543460375395\n",
      "Iteration 3066 => Loss: 51.79572194165265841548\n",
      "Iteration 3067 => Loss: 51.79550696913572949143\n",
      "Iteration 3068 => Loss: 51.79529201784077230286\n",
      "Iteration 3069 => Loss: 51.79507708772477059256\n",
      "Iteration 3070 => Loss: 51.79486217874484310641\n",
      "Iteration 3071 => Loss: 51.79464729085817253917\n",
      "Iteration 3072 => Loss: 51.79443242402209079955\n",
      "Iteration 3073 => Loss: 51.79421757819392979627\n",
      "Iteration 3074 => Loss: 51.79400275333122749544\n",
      "Iteration 3075 => Loss: 51.79378794939152896859\n",
      "Iteration 3076 => Loss: 51.79357316633245034154\n",
      "Iteration 3077 => Loss: 51.79335840411180669207\n",
      "Iteration 3078 => Loss: 51.79314366268744151967\n",
      "Iteration 3079 => Loss: 51.79292894201729069437\n",
      "Iteration 3080 => Loss: 51.79271424205940377306\n",
      "Iteration 3081 => Loss: 51.79249956277186583975\n",
      "Iteration 3082 => Loss: 51.79228490411294671958\n",
      "Iteration 3083 => Loss: 51.79207026604092334310\n",
      "Iteration 3084 => Loss: 51.79185564851421474941\n",
      "Iteration 3085 => Loss: 51.79164105149130392647\n",
      "Iteration 3086 => Loss: 51.79142647493078044363\n",
      "Iteration 3087 => Loss: 51.79121191879131913538\n",
      "Iteration 3088 => Loss: 51.79099738303167299591\n",
      "Iteration 3089 => Loss: 51.79078286761072291711\n",
      "Iteration 3090 => Loss: 51.79056837248735689627\n",
      "Iteration 3091 => Loss: 51.79035389762068319897\n",
      "Iteration 3092 => Loss: 51.79013944296981009074\n",
      "Iteration 3093 => Loss: 51.78992500849391689144\n",
      "Iteration 3094 => Loss: 51.78971059415234634571\n",
      "Iteration 3095 => Loss: 51.78949619990444830364\n",
      "Iteration 3096 => Loss: 51.78928182570974314558\n",
      "Iteration 3097 => Loss: 51.78906747152777967358\n",
      "Iteration 3098 => Loss: 51.78885313731826300909\n",
      "Iteration 3099 => Loss: 51.78863882304088406272\n",
      "Iteration 3100 => Loss: 51.78842452865552559160\n",
      "Iteration 3101 => Loss: 51.78821025412206324745\n",
      "Iteration 3102 => Loss: 51.78799599940054321223\n",
      "Iteration 3103 => Loss: 51.78778176445106140591\n",
      "Iteration 3104 => Loss: 51.78756754923379190814\n",
      "Iteration 3105 => Loss: 51.78735335370904380170\n",
      "Iteration 3106 => Loss: 51.78713917783714038023\n",
      "Iteration 3107 => Loss: 51.78692502157853994049\n",
      "Iteration 3108 => Loss: 51.78671088489380025521\n",
      "Iteration 3109 => Loss: 51.78649676774350041342\n",
      "Iteration 3110 => Loss: 51.78628267008840424523\n",
      "Iteration 3111 => Loss: 51.78606859188924005366\n",
      "Iteration 3112 => Loss: 51.78585453310697062079\n",
      "Iteration 3113 => Loss: 51.78564049370247346360\n",
      "Iteration 3114 => Loss: 51.78542647363683926187\n",
      "Iteration 3115 => Loss: 51.78521247287123685510\n",
      "Iteration 3116 => Loss: 51.78499849136683508277\n",
      "Iteration 3117 => Loss: 51.78478452908497331464\n",
      "Iteration 3118 => Loss: 51.78457058598699802587\n",
      "Iteration 3119 => Loss: 51.78435666203447595990\n",
      "Iteration 3120 => Loss: 51.78414275718890280586\n",
      "Iteration 3121 => Loss: 51.78392887141190215061\n",
      "Iteration 3122 => Loss: 51.78371500466526100581\n",
      "Iteration 3123 => Loss: 51.78350115691075927771\n",
      "Iteration 3124 => Loss: 51.78328732811030477023\n",
      "Iteration 3125 => Loss: 51.78307351822585502532\n",
      "Iteration 3126 => Loss: 51.78285972721950258801\n",
      "Iteration 3127 => Loss: 51.78264595505336842507\n",
      "Iteration 3128 => Loss: 51.78243220168971561179\n",
      "Iteration 3129 => Loss: 51.78221846709082143434\n",
      "Iteration 3130 => Loss: 51.78200475121910528742\n",
      "Iteration 3131 => Loss: 51.78179105403704340915\n",
      "Iteration 3132 => Loss: 51.78157737550716888109\n",
      "Iteration 3133 => Loss: 51.78136371559215689331\n",
      "Iteration 3134 => Loss: 51.78115007425471105762\n",
      "Iteration 3135 => Loss: 51.78093645145762025095\n",
      "Iteration 3136 => Loss: 51.78072284716380835334\n",
      "Iteration 3137 => Loss: 51.78050926133623477199\n",
      "Iteration 3138 => Loss: 51.78029569393790865206\n",
      "Iteration 3139 => Loss: 51.78008214493203809070\n",
      "Iteration 3140 => Loss: 51.77986861428176723621\n",
      "Iteration 3141 => Loss: 51.77965510195039655628\n",
      "Iteration 3142 => Loss: 51.77944160790132599459\n",
      "Iteration 3143 => Loss: 51.77922813209796970568\n",
      "Iteration 3144 => Loss: 51.77901467450389816349\n",
      "Iteration 3145 => Loss: 51.77880123508269605281\n",
      "Iteration 3146 => Loss: 51.77858781379806174527\n",
      "Iteration 3147 => Loss: 51.77837441061377887763\n",
      "Iteration 3148 => Loss: 51.77816102549368793007\n",
      "Iteration 3149 => Loss: 51.77794765840171464788\n",
      "Iteration 3150 => Loss: 51.77773430930188425236\n",
      "Iteration 3151 => Loss: 51.77752097815828591365\n",
      "Iteration 3152 => Loss: 51.77730766493505143444\n",
      "Iteration 3153 => Loss: 51.77709436959647604226\n",
      "Iteration 3154 => Loss: 51.77688109210683364836\n",
      "Iteration 3155 => Loss: 51.77666783243056158881\n",
      "Iteration 3156 => Loss: 51.77645459053211141054\n",
      "Iteration 3157 => Loss: 51.77624136637606966360\n",
      "Iteration 3158 => Loss: 51.77602815992705842518\n",
      "Iteration 3159 => Loss: 51.77581497114978503760\n",
      "Iteration 3160 => Loss: 51.77560180000906342457\n",
      "Iteration 3161 => Loss: 51.77538864646971461525\n",
      "Iteration 3162 => Loss: 51.77517551049673727448\n",
      "Iteration 3163 => Loss: 51.77496239205510164538\n",
      "Iteration 3164 => Loss: 51.77474929110995560677\n",
      "Iteration 3165 => Loss: 51.77453620762643282660\n",
      "Iteration 3166 => Loss: 51.77432314156980197595\n",
      "Iteration 3167 => Loss: 51.77411009290537435845\n",
      "Iteration 3168 => Loss: 51.77389706159860338630\n",
      "Iteration 3169 => Loss: 51.77368404761488562826\n",
      "Iteration 3170 => Loss: 51.77347105091984502678\n",
      "Iteration 3171 => Loss: 51.77325807147906289174\n",
      "Iteration 3172 => Loss: 51.77304510925828395784\n",
      "Iteration 3173 => Loss: 51.77283216422327427608\n",
      "Iteration 3174 => Loss: 51.77261923633985674087\n",
      "Iteration 3175 => Loss: 51.77240632557399635516\n",
      "Iteration 3176 => Loss: 51.77219343189170785990\n",
      "Iteration 3177 => Loss: 51.77198055525902020690\n",
      "Iteration 3178 => Loss: 51.77176769564216840536\n",
      "Iteration 3179 => Loss: 51.77155485300732351561\n",
      "Iteration 3180 => Loss: 51.77134202732077028486\n",
      "Iteration 3181 => Loss: 51.77112921854890004170\n",
      "Iteration 3182 => Loss: 51.77091642665818937985\n",
      "Iteration 3183 => Loss: 51.77070365161514331476\n",
      "Iteration 3184 => Loss: 51.77049089338634502155\n",
      "Iteration 3185 => Loss: 51.77027815193847004593\n",
      "Iteration 3186 => Loss: 51.77006542723828630415\n",
      "Iteration 3187 => Loss: 51.76985271925256171244\n",
      "Iteration 3188 => Loss: 51.76964002794824892817\n",
      "Iteration 3189 => Loss: 51.76942735329223665985\n",
      "Iteration 3190 => Loss: 51.76921469525159835712\n",
      "Iteration 3191 => Loss: 51.76900205379340746958\n",
      "Iteration 3192 => Loss: 51.76878942888490087171\n",
      "Iteration 3193 => Loss: 51.76857682049327280538\n",
      "Iteration 3194 => Loss: 51.76836422858586672646\n",
      "Iteration 3195 => Loss: 51.76815165313008293424\n",
      "Iteration 3196 => Loss: 51.76793909409335725513\n",
      "Iteration 3197 => Loss: 51.76772655144323209697\n",
      "Iteration 3198 => Loss: 51.76751402514733513271\n",
      "Iteration 3199 => Loss: 51.76730151517335087874\n",
      "Iteration 3200 => Loss: 51.76708902148897806228\n",
      "Iteration 3201 => Loss: 51.76687654406207172997\n",
      "Iteration 3202 => Loss: 51.76666408286050824472\n",
      "Iteration 3203 => Loss: 51.76645163785227765629\n",
      "Iteration 3204 => Loss: 51.76623920900536290901\n",
      "Iteration 3205 => Loss: 51.76602679628788195032\n",
      "Iteration 3206 => Loss: 51.76581439966801667651\n",
      "Iteration 3207 => Loss: 51.76560201911402003816\n",
      "Iteration 3208 => Loss: 51.76538965459413788039\n",
      "Iteration 3209 => Loss: 51.76517730607681500032\n",
      "Iteration 3210 => Loss: 51.76496497353046777334\n",
      "Iteration 3211 => Loss: 51.76475265692362626169\n",
      "Iteration 3212 => Loss: 51.76454035622486316015\n",
      "Iteration 3213 => Loss: 51.76432807140285063952\n",
      "Iteration 3214 => Loss: 51.76411580242628218684\n",
      "Iteration 3215 => Loss: 51.76390354926399339774\n",
      "Iteration 3216 => Loss: 51.76369131188481276240\n",
      "Iteration 3217 => Loss: 51.76347909025769666869\n",
      "Iteration 3218 => Loss: 51.76326688435158018819\n",
      "Iteration 3219 => Loss: 51.76305469413561155534\n",
      "Iteration 3220 => Loss: 51.76284251957886084483\n",
      "Iteration 3221 => Loss: 51.76263036065056155621\n",
      "Iteration 3222 => Loss: 51.76241821731994718903\n",
      "Iteration 3223 => Loss: 51.76220608955638624593\n",
      "Iteration 3224 => Loss: 51.76199397732926854587\n",
      "Iteration 3225 => Loss: 51.76178188060805496207\n",
      "Iteration 3226 => Loss: 51.76156979936230584372\n",
      "Iteration 3227 => Loss: 51.76135773356161706715\n",
      "Iteration 3228 => Loss: 51.76114568317562003585\n",
      "Iteration 3229 => Loss: 51.76093364817410957812\n",
      "Iteration 3230 => Loss: 51.76072162852683788969\n",
      "Iteration 3231 => Loss: 51.76050962420372059114\n",
      "Iteration 3232 => Loss: 51.76029763517464488132\n",
      "Iteration 3233 => Loss: 51.76008566140961875135\n",
      "Iteration 3234 => Loss: 51.75987370287874256292\n",
      "Iteration 3235 => Loss: 51.75966175955212378312\n",
      "Iteration 3236 => Loss: 51.75944983139996224963\n",
      "Iteration 3237 => Loss: 51.75923791839252885438\n",
      "Iteration 3238 => Loss: 51.75902602050012291102\n",
      "Iteration 3239 => Loss: 51.75881413769317873630\n",
      "Iteration 3240 => Loss: 51.75860226994210222529\n",
      "Iteration 3241 => Loss: 51.75839041721748401415\n",
      "Iteration 3242 => Loss: 51.75817857948984368477\n",
      "Iteration 3243 => Loss: 51.75796675672987134931\n",
      "Iteration 3244 => Loss: 51.75775494890827843619\n",
      "Iteration 3245 => Loss: 51.75754315599583321728\n",
      "Iteration 3246 => Loss: 51.75733137796336791325\n",
      "Iteration 3247 => Loss: 51.75711961478182843166\n",
      "Iteration 3248 => Loss: 51.75690786642216068003\n",
      "Iteration 3249 => Loss: 51.75669613285541714731\n",
      "Iteration 3250 => Loss: 51.75648441405266453330\n",
      "Iteration 3251 => Loss: 51.75627270998506901378\n",
      "Iteration 3252 => Loss: 51.75606102062389624052\n",
      "Iteration 3253 => Loss: 51.75584934594039054900\n",
      "Iteration 3254 => Loss: 51.75563768590593838326\n",
      "Iteration 3255 => Loss: 51.75542604049192618731\n",
      "Iteration 3256 => Loss: 51.75521440966982567033\n",
      "Iteration 3257 => Loss: 51.75500279341121512289\n",
      "Iteration 3258 => Loss: 51.75479119168765151926\n",
      "Iteration 3259 => Loss: 51.75457960447081262600\n",
      "Iteration 3260 => Loss: 51.75436803173241884224\n",
      "Iteration 3261 => Loss: 51.75415647344429004306\n",
      "Iteration 3262 => Loss: 51.75394492957824610357\n",
      "Iteration 3263 => Loss: 51.75373340010619926943\n",
      "Iteration 3264 => Loss: 51.75352188500013994599\n",
      "Iteration 3265 => Loss: 51.75331038423207274946\n",
      "Iteration 3266 => Loss: 51.75309889777411598288\n",
      "Iteration 3267 => Loss: 51.75288742559840216018\n",
      "Iteration 3268 => Loss: 51.75267596767717748207\n",
      "Iteration 3269 => Loss: 51.75246452398271657103\n",
      "Iteration 3270 => Loss: 51.75225309448735799833\n",
      "Iteration 3271 => Loss: 51.75204167916346875700\n",
      "Iteration 3272 => Loss: 51.75183027798353663229\n",
      "Iteration 3273 => Loss: 51.75161889092010625291\n",
      "Iteration 3274 => Loss: 51.75140751794569382582\n",
      "Iteration 3275 => Loss: 51.75119615903298608828\n",
      "Iteration 3276 => Loss: 51.75098481415467688294\n",
      "Iteration 3277 => Loss: 51.75077348328353821216\n",
      "Iteration 3278 => Loss: 51.75056216639237760546\n",
      "Iteration 3279 => Loss: 51.75035086345403811947\n",
      "Iteration 3280 => Loss: 51.75013957444152623566\n",
      "Iteration 3281 => Loss: 51.74992829932781290836\n",
      "Iteration 3282 => Loss: 51.74971703808593304075\n",
      "Iteration 3283 => Loss: 51.74950579068904232827\n",
      "Iteration 3284 => Loss: 51.74929455711028225551\n",
      "Iteration 3285 => Loss: 51.74908333732290088847\n",
      "Iteration 3286 => Loss: 51.74887213130019603113\n",
      "Iteration 3287 => Loss: 51.74866093901550101464\n",
      "Iteration 3288 => Loss: 51.74844976044224154066\n",
      "Iteration 3289 => Loss: 51.74823859555390015430\n",
      "Iteration 3290 => Loss: 51.74802744432399492780\n",
      "Iteration 3291 => Loss: 51.74781630672607235510\n",
      "Iteration 3292 => Loss: 51.74760518273380682786\n",
      "Iteration 3293 => Loss: 51.74739407232091537026\n",
      "Iteration 3294 => Loss: 51.74718297546108658480\n",
      "Iteration 3295 => Loss: 51.74697189212823644766\n",
      "Iteration 3296 => Loss: 51.74676082229616724817\n",
      "Iteration 3297 => Loss: 51.74654976593883048963\n",
      "Iteration 3298 => Loss: 51.74633872303021320249\n",
      "Iteration 3299 => Loss: 51.74612769354431662805\n",
      "Iteration 3300 => Loss: 51.74591667745531253786\n",
      "Iteration 3301 => Loss: 51.74570567473733717634\n",
      "Iteration 3302 => Loss: 51.74549468536456942047\n",
      "Iteration 3303 => Loss: 51.74528370931130183408\n",
      "Iteration 3304 => Loss: 51.74507274655186961354\n",
      "Iteration 3305 => Loss: 51.74486179706063637695\n",
      "Iteration 3306 => Loss: 51.74465086081207942925\n",
      "Iteration 3307 => Loss: 51.74443993778066186451\n",
      "Iteration 3308 => Loss: 51.74422902794091072565\n",
      "Iteration 3309 => Loss: 51.74401813126750226957\n",
      "Iteration 3310 => Loss: 51.74380724773504169889\n",
      "Iteration 3311 => Loss: 51.74359637731827632479\n",
      "Iteration 3312 => Loss: 51.74338551999195345843\n",
      "Iteration 3313 => Loss: 51.74317467573091988697\n",
      "Iteration 3314 => Loss: 51.74296384451007213556\n",
      "Iteration 3315 => Loss: 51.74275302630432804563\n",
      "Iteration 3316 => Loss: 51.74254222108866230201\n",
      "Iteration 3317 => Loss: 51.74233142883819169811\n",
      "Iteration 3318 => Loss: 51.74212064952792644590\n",
      "Iteration 3319 => Loss: 51.74190988313311123648\n",
      "Iteration 3320 => Loss: 51.74169912962891970665\n",
      "Iteration 3321 => Loss: 51.74148838899061075836\n",
      "Iteration 3322 => Loss: 51.74127766119352855867\n",
      "Iteration 3323 => Loss: 51.74106694621303148551\n",
      "Iteration 3324 => Loss: 51.74085624402452765480\n",
      "Iteration 3325 => Loss: 51.74064555460353886929\n",
      "Iteration 3326 => Loss: 51.74043487792557272087\n",
      "Iteration 3327 => Loss: 51.74022421396622917200\n",
      "Iteration 3328 => Loss: 51.74001356270117923941\n",
      "Iteration 3329 => Loss: 51.73980292410608683440\n",
      "Iteration 3330 => Loss: 51.73959229815669402797\n",
      "Iteration 3331 => Loss: 51.73938168482884947252\n",
      "Iteration 3332 => Loss: 51.73917108409835918792\n",
      "Iteration 3333 => Loss: 51.73896049594116419712\n",
      "Iteration 3334 => Loss: 51.73874992033321973395\n",
      "Iteration 3335 => Loss: 51.73853935725050945393\n",
      "Iteration 3336 => Loss: 51.73832880666914491030\n",
      "Iteration 3337 => Loss: 51.73811826856523765628\n",
      "Iteration 3338 => Loss: 51.73790774291492056136\n",
      "Iteration 3339 => Loss: 51.73769722969447570904\n",
      "Iteration 3340 => Loss: 51.73748672888013544480\n",
      "Iteration 3341 => Loss: 51.73727624044824580096\n",
      "Iteration 3342 => Loss: 51.73706576437518123157\n",
      "Iteration 3343 => Loss: 51.73685530063738724493\n",
      "Iteration 3344 => Loss: 51.73664484921130224393\n",
      "Iteration 3345 => Loss: 51.73643441007352095085\n",
      "Iteration 3346 => Loss: 51.73622398320060256083\n",
      "Iteration 3347 => Loss: 51.73601356856919153415\n",
      "Iteration 3348 => Loss: 51.73580316615596075280\n",
      "Iteration 3349 => Loss: 51.73559277593767546932\n",
      "Iteration 3350 => Loss: 51.73538239789107961997\n",
      "Iteration 3351 => Loss: 51.73517203199308767125\n",
      "Iteration 3352 => Loss: 51.73496167822051461371\n",
      "Iteration 3353 => Loss: 51.73475133655034596813\n",
      "Iteration 3354 => Loss: 51.73454100695960278244\n",
      "Iteration 3355 => Loss: 51.73433068942526347200\n",
      "Iteration 3356 => Loss: 51.73412038392446987700\n",
      "Iteration 3357 => Loss: 51.73391009043432831049\n",
      "Iteration 3358 => Loss: 51.73369980893207298323\n",
      "Iteration 3359 => Loss: 51.73348953939493100052\n",
      "Iteration 3360 => Loss: 51.73327928180018631110\n",
      "Iteration 3361 => Loss: 51.73306903612521523428\n",
      "Iteration 3362 => Loss: 51.73285880234738698391\n",
      "Iteration 3363 => Loss: 51.73264858044413472271\n",
      "Iteration 3364 => Loss: 51.73243837039295556224\n",
      "Iteration 3365 => Loss: 51.73222817217141766832\n",
      "Iteration 3366 => Loss: 51.73201798575710341765\n",
      "Iteration 3367 => Loss: 51.73180781112763781948\n",
      "Iteration 3368 => Loss: 51.73159764826070983190\n",
      "Iteration 3369 => Loss: 51.73138749713405815100\n",
      "Iteration 3370 => Loss: 51.73117735772548542172\n",
      "Iteration 3371 => Loss: 51.73096723001280849985\n",
      "Iteration 3372 => Loss: 51.73075711397395792801\n",
      "Iteration 3373 => Loss: 51.73054700958679319456\n",
      "Iteration 3374 => Loss: 51.73033691682933721268\n",
      "Iteration 3375 => Loss: 51.73012683567961289555\n",
      "Iteration 3376 => Loss: 51.72991676611571421063\n",
      "Iteration 3377 => Loss: 51.72970670811572801995\n",
      "Iteration 3378 => Loss: 51.72949666165787618866\n",
      "Iteration 3379 => Loss: 51.72928662672031663305\n",
      "Iteration 3380 => Loss: 51.72907660328141332684\n",
      "Iteration 3381 => Loss: 51.72886659131938813516\n",
      "Iteration 3382 => Loss: 51.72865659081263345342\n",
      "Iteration 3383 => Loss: 51.72844660173958430960\n",
      "Iteration 3384 => Loss: 51.72823662407868283708\n",
      "Iteration 3385 => Loss: 51.72802665780844222354\n",
      "Iteration 3386 => Loss: 51.72781670290741118379\n",
      "Iteration 3387 => Loss: 51.72760675935416685434\n",
      "Iteration 3388 => Loss: 51.72739682712740716397\n",
      "Iteration 3389 => Loss: 51.72718690620575898720\n",
      "Iteration 3390 => Loss: 51.72697699656802683421\n",
      "Iteration 3391 => Loss: 51.72676709819297968806\n",
      "Iteration 3392 => Loss: 51.72655721105942916438\n",
      "Iteration 3393 => Loss: 51.72634733514627214390\n",
      "Iteration 3394 => Loss: 51.72613747043239840195\n",
      "Iteration 3395 => Loss: 51.72592761689684692783\n",
      "Iteration 3396 => Loss: 51.72571777451859276198\n",
      "Iteration 3397 => Loss: 51.72550794327670331541\n",
      "Iteration 3398 => Loss: 51.72529812315029573710\n",
      "Iteration 3399 => Loss: 51.72508831411849428150\n",
      "Iteration 3400 => Loss: 51.72487851616057952242\n",
      "Iteration 3401 => Loss: 51.72466872925573255770\n",
      "Iteration 3402 => Loss: 51.72445895338324106660\n",
      "Iteration 3403 => Loss: 51.72424918852248509893\n",
      "Iteration 3404 => Loss: 51.72403943465280917735\n",
      "Iteration 3405 => Loss: 51.72382969175366440595\n",
      "Iteration 3406 => Loss: 51.72361995980451609967\n",
      "Iteration 3407 => Loss: 51.72341023878489352228\n",
      "Iteration 3408 => Loss: 51.72320052867436146471\n",
      "Iteration 3409 => Loss: 51.72299082945250603416\n",
      "Iteration 3410 => Loss: 51.72278114109897728667\n",
      "Iteration 3411 => Loss: 51.72257146359350343801\n",
      "Iteration 3412 => Loss: 51.72236179691581980933\n",
      "Iteration 3413 => Loss: 51.72215214104568303810\n",
      "Iteration 3414 => Loss: 51.72194249596293502691\n",
      "Iteration 3415 => Loss: 51.72173286164751004890\n",
      "Iteration 3416 => Loss: 51.72152323807920737408\n",
      "Iteration 3417 => Loss: 51.72131362523810338416\n",
      "Iteration 3418 => Loss: 51.72110402310412524685\n",
      "Iteration 3419 => Loss: 51.72089443165737066010\n",
      "Iteration 3420 => Loss: 51.72068485087794442734\n",
      "Iteration 3421 => Loss: 51.72047528074592293024\n",
      "Iteration 3422 => Loss: 51.72026572124155308074\n",
      "Iteration 3423 => Loss: 51.72005617234502494739\n",
      "Iteration 3424 => Loss: 51.71984663403657833669\n",
      "Iteration 3425 => Loss: 51.71963710629658095286\n",
      "Iteration 3426 => Loss: 51.71942758910537918382\n",
      "Iteration 3427 => Loss: 51.71921808244334783922\n",
      "Iteration 3428 => Loss: 51.71900858629092567753\n",
      "Iteration 3429 => Loss: 51.71879910062860830067\n",
      "Iteration 3430 => Loss: 51.71858962543691262681\n",
      "Iteration 3431 => Loss: 51.71838016069643373385\n",
      "Iteration 3432 => Loss: 51.71817070638773827795\n",
      "Iteration 3433 => Loss: 51.71796126249149949672\n",
      "Iteration 3434 => Loss: 51.71775182898845457657\n",
      "Iteration 3435 => Loss: 51.71754240585926964968\n",
      "Iteration 3436 => Loss: 51.71733299308477427303\n",
      "Iteration 3437 => Loss: 51.71712359064576958190\n",
      "Iteration 3438 => Loss: 51.71691419852312776584\n",
      "Iteration 3439 => Loss: 51.71670481669775654154\n",
      "Iteration 3440 => Loss: 51.71649544515059915284\n",
      "Iteration 3441 => Loss: 51.71628608386266989783\n",
      "Iteration 3442 => Loss: 51.71607673281496886375\n",
      "Iteration 3443 => Loss: 51.71586739198857429756\n",
      "Iteration 3444 => Loss: 51.71565806136460707876\n",
      "Iteration 3445 => Loss: 51.71544874092422361400\n",
      "Iteration 3446 => Loss: 51.71523943064862294250\n",
      "Iteration 3447 => Loss: 51.71503013051903252517\n",
      "Iteration 3448 => Loss: 51.71482084051673666636\n",
      "Iteration 3449 => Loss: 51.71461156062309072468\n",
      "Iteration 3450 => Loss: 51.71440229081940742617\n",
      "Iteration 3451 => Loss: 51.71419303108708476202\n",
      "Iteration 3452 => Loss: 51.71398378140761309396\n",
      "Iteration 3453 => Loss: 51.71377454176244015116\n",
      "Iteration 3454 => Loss: 51.71356531213312734963\n",
      "Iteration 3455 => Loss: 51.71335609250119347280\n",
      "Iteration 3456 => Loss: 51.71314688284827099096\n",
      "Iteration 3457 => Loss: 51.71293768315600658525\n",
      "Iteration 3458 => Loss: 51.71272849340606114765\n",
      "Iteration 3459 => Loss: 51.71251931358020215157\n",
      "Iteration 3460 => Loss: 51.71231014366014022698\n",
      "Iteration 3461 => Loss: 51.71210098362772811242\n",
      "Iteration 3462 => Loss: 51.71189183346480433556\n",
      "Iteration 3463 => Loss: 51.71168269315325005664\n",
      "Iteration 3464 => Loss: 51.71147356267496064675\n",
      "Iteration 3465 => Loss: 51.71126444201191674210\n",
      "Iteration 3466 => Loss: 51.71105533114617003321\n",
      "Iteration 3467 => Loss: 51.71084623005971536713\n",
      "Iteration 3468 => Loss: 51.71063713873465417237\n",
      "Iteration 3469 => Loss: 51.71042805715308787740\n",
      "Iteration 3470 => Loss: 51.71021898529718185955\n",
      "Iteration 3471 => Loss: 51.71000992314916544501\n",
      "Iteration 3472 => Loss: 51.70980087069125374910\n",
      "Iteration 3473 => Loss: 51.70959182790570451971\n",
      "Iteration 3474 => Loss: 51.70938279477489629699\n",
      "Iteration 3475 => Loss: 51.70917377128112235596\n",
      "Iteration 3476 => Loss: 51.70896475740682518563\n",
      "Iteration 3477 => Loss: 51.70875575313441885328\n",
      "Iteration 3478 => Loss: 51.70854675844637426962\n",
      "Iteration 3479 => Loss: 51.70833777332518366165\n",
      "Iteration 3480 => Loss: 51.70812879775341741606\n",
      "Iteration 3481 => Loss: 51.70791983171366723582\n",
      "Iteration 3482 => Loss: 51.70771087518853903475\n",
      "Iteration 3483 => Loss: 51.70750192816071688640\n",
      "Iteration 3484 => Loss: 51.70729299061285644257\n",
      "Iteration 3485 => Loss: 51.70708406252774125278\n",
      "Iteration 3486 => Loss: 51.70687514388816907740\n",
      "Iteration 3487 => Loss: 51.70666623467688083338\n",
      "Iteration 3488 => Loss: 51.70645733487680928420\n",
      "Iteration 3489 => Loss: 51.70624844447076640108\n",
      "Iteration 3490 => Loss: 51.70603956344172047466\n",
      "Iteration 3491 => Loss: 51.70583069177263979554\n",
      "Iteration 3492 => Loss: 51.70562182944650686522\n",
      "Iteration 3493 => Loss: 51.70541297644640366116\n",
      "Iteration 3494 => Loss: 51.70520413275533400110\n",
      "Iteration 3495 => Loss: 51.70499529835645802223\n",
      "Iteration 3496 => Loss: 51.70478647323292165083\n",
      "Iteration 3497 => Loss: 51.70457765736791344580\n",
      "Iteration 3498 => Loss: 51.70436885074467170398\n",
      "Iteration 3499 => Loss: 51.70416005334641340596\n",
      "Iteration 3500 => Loss: 51.70395126515643369203\n",
      "Iteration 3501 => Loss: 51.70374248615812717844\n",
      "Iteration 3502 => Loss: 51.70353371633481032177\n",
      "Iteration 3503 => Loss: 51.70332495566994168712\n",
      "Iteration 3504 => Loss: 51.70311620414690167991\n",
      "Iteration 3505 => Loss: 51.70290746174921991951\n",
      "Iteration 3506 => Loss: 51.70269872846036207648\n",
      "Iteration 3507 => Loss: 51.70249000426393592988\n",
      "Iteration 3508 => Loss: 51.70228128914350662626\n",
      "Iteration 3509 => Loss: 51.70207258308267483926\n",
      "Iteration 3510 => Loss: 51.70186388606512650767\n",
      "Iteration 3511 => Loss: 51.70165519807455467571\n",
      "Iteration 3512 => Loss: 51.70144651909469502016\n",
      "Iteration 3513 => Loss: 51.70123784910928321779\n",
      "Iteration 3514 => Loss: 51.70102918810214021050\n",
      "Iteration 3515 => Loss: 51.70082053605712246735\n",
      "Iteration 3516 => Loss: 51.70061189295807224653\n",
      "Iteration 3517 => Loss: 51.70040325878890996592\n",
      "Iteration 3518 => Loss: 51.70019463353362709768\n",
      "Iteration 3519 => Loss: 51.69998601717610142714\n",
      "Iteration 3520 => Loss: 51.69977740970044521873\n",
      "Iteration 3521 => Loss: 51.69956881109062862834\n",
      "Iteration 3522 => Loss: 51.69936022133078523666\n",
      "Iteration 3523 => Loss: 51.69915164040503441356\n",
      "Iteration 3524 => Loss: 51.69894306829750263432\n",
      "Iteration 3525 => Loss: 51.69873450499239453393\n",
      "Iteration 3526 => Loss: 51.69852595047392895822\n",
      "Iteration 3527 => Loss: 51.69831740472636028016\n",
      "Iteration 3528 => Loss: 51.69810886773400682159\n",
      "Iteration 3529 => Loss: 51.69790033948114427176\n",
      "Iteration 3530 => Loss: 51.69769181995217621761\n",
      "Iteration 3531 => Loss: 51.69748330913146361354\n",
      "Iteration 3532 => Loss: 51.69727480700350241705\n",
      "Iteration 3533 => Loss: 51.69706631355266779337\n",
      "Iteration 3534 => Loss: 51.69685782876351254345\n",
      "Iteration 3535 => Loss: 51.69664935262054683562\n",
      "Iteration 3536 => Loss: 51.69644088510834478711\n",
      "Iteration 3537 => Loss: 51.69623242621150183140\n",
      "Iteration 3538 => Loss: 51.69602397591464182369\n",
      "Iteration 3539 => Loss: 51.69581553420245256802\n",
      "Iteration 3540 => Loss: 51.69560710105961476302\n",
      "Iteration 3541 => Loss: 51.69539867647088016156\n",
      "Iteration 3542 => Loss: 51.69519026042100762197\n",
      "Iteration 3543 => Loss: 51.69498185289477731885\n",
      "Iteration 3544 => Loss: 51.69477345387702627022\n",
      "Iteration 3545 => Loss: 51.69456506335265544294\n",
      "Iteration 3546 => Loss: 51.69435668130654448760\n",
      "Iteration 3547 => Loss: 51.69414830772362989819\n",
      "Iteration 3548 => Loss: 51.69393994258885527415\n",
      "Iteration 3549 => Loss: 51.69373158588724948004\n",
      "Iteration 3550 => Loss: 51.69352323760383427498\n",
      "Iteration 3551 => Loss: 51.69331489772366694524\n",
      "Iteration 3552 => Loss: 51.69310656623185451508\n",
      "Iteration 3553 => Loss: 51.69289824311351821962\n",
      "Iteration 3554 => Loss: 51.69268992835381482109\n",
      "Iteration 3555 => Loss: 51.69248162193798634689\n",
      "Iteration 3556 => Loss: 51.69227332385117534841\n",
      "Iteration 3557 => Loss: 51.69206503407873043443\n",
      "Iteration 3558 => Loss: 51.69185675260587231605\n",
      "Iteration 3559 => Loss: 51.69164847941794960207\n",
      "Iteration 3560 => Loss: 51.69144021450033932297\n",
      "Iteration 3561 => Loss: 51.69123195783841140383\n",
      "Iteration 3562 => Loss: 51.69102370941759971856\n",
      "Iteration 3563 => Loss: 51.69081546922333103566\n",
      "Iteration 3564 => Loss: 51.69060723724111028332\n",
      "Iteration 3565 => Loss: 51.69039901345644949515\n",
      "Iteration 3566 => Loss: 51.69019079785490333734\n",
      "Iteration 3567 => Loss: 51.68998259042204068692\n",
      "Iteration 3568 => Loss: 51.68977439114345173721\n",
      "Iteration 3569 => Loss: 51.68956620000481905208\n",
      "Iteration 3570 => Loss: 51.68935801699181098456\n",
      "Iteration 3571 => Loss: 51.68914984209010299310\n",
      "Iteration 3572 => Loss: 51.68894167528544159040\n",
      "Iteration 3573 => Loss: 51.68873351656363013262\n",
      "Iteration 3574 => Loss: 51.68852536591042934333\n",
      "Iteration 3575 => Loss: 51.68831722331167810580\n",
      "Iteration 3576 => Loss: 51.68810908875324372502\n",
      "Iteration 3577 => Loss: 51.68790096222100771683\n",
      "Iteration 3578 => Loss: 51.68769284370091554592\n",
      "Iteration 3579 => Loss: 51.68748473317889136069\n",
      "Iteration 3580 => Loss: 51.68727663064094457468\n",
      "Iteration 3581 => Loss: 51.68706853607308460141\n",
      "Iteration 3582 => Loss: 51.68686044946134217071\n",
      "Iteration 3583 => Loss: 51.68665237079179064494\n",
      "Iteration 3584 => Loss: 51.68644430005056733535\n",
      "Iteration 3585 => Loss: 51.68623623722379534229\n",
      "Iteration 3586 => Loss: 51.68602818229762618785\n",
      "Iteration 3587 => Loss: 51.68582013525828955380\n",
      "Iteration 3588 => Loss: 51.68561209609200091109\n",
      "Iteration 3589 => Loss: 51.68540406478500415233\n",
      "Iteration 3590 => Loss: 51.68519604132357159187\n",
      "Iteration 3591 => Loss: 51.68498802569409633634\n",
      "Iteration 3592 => Loss: 51.68478001788285070006\n",
      "Iteration 3593 => Loss: 51.68457201787624200051\n",
      "Iteration 3594 => Loss: 51.68436402566069176601\n",
      "Iteration 3595 => Loss: 51.68415604122261441944\n",
      "Iteration 3596 => Loss: 51.68394806454847412169\n",
      "Iteration 3597 => Loss: 51.68374009562482029878\n",
      "Iteration 3598 => Loss: 51.68353213443811711159\n",
      "Iteration 3599 => Loss: 51.68332418097494951326\n",
      "Iteration 3600 => Loss: 51.68311623522189535151\n",
      "Iteration 3601 => Loss: 51.68290829716556800122\n",
      "Iteration 3602 => Loss: 51.68270036679263057522\n",
      "Iteration 3603 => Loss: 51.68249244408974618636\n",
      "Iteration 3604 => Loss: 51.68228452904360636921\n",
      "Iteration 3605 => Loss: 51.68207662164097371260\n",
      "Iteration 3606 => Loss: 51.68186872186857527822\n",
      "Iteration 3607 => Loss: 51.68166082971320207662\n",
      "Iteration 3608 => Loss: 51.68145294516168775090\n",
      "Iteration 3609 => Loss: 51.68124506820088726045\n",
      "Iteration 3610 => Loss: 51.68103719881766977551\n",
      "Iteration 3611 => Loss: 51.68082933699894709889\n",
      "Iteration 3612 => Loss: 51.68062148273163813883\n",
      "Iteration 3613 => Loss: 51.68041363600270443612\n",
      "Iteration 3614 => Loss: 51.68020579679916437499\n",
      "Iteration 3615 => Loss: 51.67999796510802923422\n",
      "Iteration 3616 => Loss: 51.67979014091631029260\n",
      "Iteration 3617 => Loss: 51.67958232421112541033\n",
      "Iteration 3618 => Loss: 51.67937451497955692048\n",
      "Iteration 3619 => Loss: 51.67916671320879373752\n",
      "Iteration 3620 => Loss: 51.67895891888588977281\n",
      "Iteration 3621 => Loss: 51.67875113199812631137\n",
      "Iteration 3622 => Loss: 51.67854335253267095140\n",
      "Iteration 3623 => Loss: 51.67833558047682629422\n",
      "Iteration 3624 => Loss: 51.67812781581780967599\n",
      "Iteration 3625 => Loss: 51.67792005854294501432\n",
      "Iteration 3626 => Loss: 51.67771230863954201595\n",
      "Iteration 3627 => Loss: 51.67750456609498144189\n",
      "Iteration 3628 => Loss: 51.67729683089664405315\n",
      "Iteration 3629 => Loss: 51.67708910303196034874\n",
      "Iteration 3630 => Loss: 51.67688138248833240596\n",
      "Iteration 3631 => Loss: 51.67667366925322625093\n",
      "Iteration 3632 => Loss: 51.67646596331417896408\n",
      "Iteration 3633 => Loss: 51.67625826465864946613\n",
      "Iteration 3634 => Loss: 51.67605057327428141889\n",
      "Iteration 3635 => Loss: 51.67584288914855505936\n",
      "Iteration 3636 => Loss: 51.67563521226912826023\n",
      "Iteration 3637 => Loss: 51.67542754262363047246\n",
      "Iteration 3638 => Loss: 51.67521988019969114703\n",
      "Iteration 3639 => Loss: 51.67501222498500368374\n",
      "Iteration 3640 => Loss: 51.67480457696730411499\n",
      "Iteration 3641 => Loss: 51.67459693613432136772\n",
      "Iteration 3642 => Loss: 51.67438930247379857974\n",
      "Iteration 3643 => Loss: 51.67418167597356415399\n",
      "Iteration 3644 => Loss: 51.67397405662141096627\n",
      "Iteration 3645 => Loss: 51.67376644440519584123\n",
      "Iteration 3646 => Loss: 51.67355883931280402521\n",
      "Iteration 3647 => Loss: 51.67335124133209944830\n",
      "Iteration 3648 => Loss: 51.67314365045103130569\n",
      "Iteration 3649 => Loss: 51.67293606665756300345\n",
      "Iteration 3650 => Loss: 51.67272848993965084219\n",
      "Iteration 3651 => Loss: 51.67252092028532928225\n",
      "Iteration 3652 => Loss: 51.67231335768258304597\n",
      "Iteration 3653 => Loss: 51.67210580211951054252\n",
      "Iteration 3654 => Loss: 51.67189825358416754852\n",
      "Iteration 3655 => Loss: 51.67169071206470931656\n",
      "Iteration 3656 => Loss: 51.67148317754920583411\n",
      "Iteration 3657 => Loss: 51.67127565002585498632\n",
      "Iteration 3658 => Loss: 51.67106812948285465836\n",
      "Iteration 3659 => Loss: 51.67086061590840984081\n",
      "Iteration 3660 => Loss: 51.67065310929073973512\n",
      "Iteration 3661 => Loss: 51.67044560961812749156\n",
      "Iteration 3662 => Loss: 51.67023811687887757671\n",
      "Iteration 3663 => Loss: 51.67003063106126603543\n",
      "Iteration 3664 => Loss: 51.66982315215367549399\n",
      "Iteration 3665 => Loss: 51.66961568014446726238\n",
      "Iteration 3666 => Loss: 51.66940821502200975601\n",
      "Iteration 3667 => Loss: 51.66920075677472823372\n",
      "Iteration 3668 => Loss: 51.66899330539108348148\n",
      "Iteration 3669 => Loss: 51.66878586085953628526\n",
      "Iteration 3670 => Loss: 51.66857842316856874731\n",
      "Iteration 3671 => Loss: 51.66837099230673402417\n",
      "Iteration 3672 => Loss: 51.66816356826253553436\n",
      "Iteration 3673 => Loss: 51.66795615102455485612\n",
      "Iteration 3674 => Loss: 51.66774874058141620026\n",
      "Iteration 3675 => Loss: 51.66754133692171535586\n",
      "Iteration 3676 => Loss: 51.66733394003409074458\n",
      "Iteration 3677 => Loss: 51.66712654990720210435\n",
      "Iteration 3678 => Loss: 51.66691916652980864910\n",
      "Iteration 3679 => Loss: 51.66671178989054169506\n",
      "Iteration 3680 => Loss: 51.66650441997820308870\n",
      "Iteration 3681 => Loss: 51.66629705678153072768\n",
      "Iteration 3682 => Loss: 51.66608970028935488017\n",
      "Iteration 3683 => Loss: 51.66588235049044186553\n",
      "Iteration 3684 => Loss: 51.66567500737365747909\n",
      "Iteration 3685 => Loss: 51.66546767092790304332\n",
      "Iteration 3686 => Loss: 51.66526034114202303726\n",
      "Iteration 3687 => Loss: 51.66505301800494009967\n",
      "Iteration 3688 => Loss: 51.66484570150561950186\n",
      "Iteration 3689 => Loss: 51.66463839163298388257\n",
      "Iteration 3690 => Loss: 51.66443108837606246198\n",
      "Iteration 3691 => Loss: 51.66422379172383472223\n",
      "Iteration 3692 => Loss: 51.66401650166537251607\n",
      "Iteration 3693 => Loss: 51.66380921818969795822\n",
      "Iteration 3694 => Loss: 51.66360194128589000684\n",
      "Iteration 3695 => Loss: 51.66339467094311288520\n",
      "Iteration 3696 => Loss: 51.66318740715043844602\n",
      "Iteration 3697 => Loss: 51.66298014989706643973\n",
      "Iteration 3698 => Loss: 51.66277289917216819504\n",
      "Iteration 3699 => Loss: 51.66256565496489372435\n",
      "Iteration 3700 => Loss: 51.66235841726454935952\n",
      "Iteration 3701 => Loss: 51.66215118606033485094\n",
      "Iteration 3702 => Loss: 51.66194396134153521416\n",
      "Iteration 3703 => Loss: 51.66173674309745678102\n",
      "Iteration 3704 => Loss: 51.66152953131739167247\n",
      "Iteration 3705 => Loss: 51.66132232599073148549\n",
      "Iteration 3706 => Loss: 51.66111512710678965732\n",
      "Iteration 3707 => Loss: 51.66090793465501462833\n",
      "Iteration 3708 => Loss: 51.66070074862476246835\n",
      "Iteration 3709 => Loss: 51.66049356900551003946\n",
      "Iteration 3710 => Loss: 51.66028639578669867660\n",
      "Iteration 3711 => Loss: 51.66007922895781945272\n",
      "Iteration 3712 => Loss: 51.65987206850837054617\n",
      "Iteration 3713 => Loss: 51.65966491442790697874\n",
      "Iteration 3714 => Loss: 51.65945776670594824509\n",
      "Iteration 3715 => Loss: 51.65925062533209199955\n",
      "Iteration 3716 => Loss: 51.65904349029592168563\n",
      "Iteration 3717 => Loss: 51.65883636158706337937\n",
      "Iteration 3718 => Loss: 51.65862923919516447313\n",
      "Iteration 3719 => Loss: 51.65842212310987235924\n",
      "Iteration 3720 => Loss: 51.65821501332091258973\n",
      "Iteration 3721 => Loss: 51.65800790981797518953\n",
      "Iteration 3722 => Loss: 51.65780081259077860523\n",
      "Iteration 3723 => Loss: 51.65759372162911233772\n",
      "Iteration 3724 => Loss: 51.65738663692270904448\n",
      "Iteration 3725 => Loss: 51.65717955846142217524\n",
      "Iteration 3726 => Loss: 51.65697248623502702003\n",
      "Iteration 3727 => Loss: 51.65676542023341966114\n",
      "Iteration 3728 => Loss: 51.65655836044641802118\n",
      "Iteration 3729 => Loss: 51.65635130686393949873\n",
      "Iteration 3730 => Loss: 51.65614425947589438692\n",
      "Iteration 3731 => Loss: 51.65593721827222140064\n",
      "Iteration 3732 => Loss: 51.65573018324286636016\n",
      "Iteration 3733 => Loss: 51.65552315437781061291\n",
      "Iteration 3734 => Loss: 51.65531613166706392803\n",
      "Iteration 3735 => Loss: 51.65510911510063607466\n",
      "Iteration 3736 => Loss: 51.65490210466856524363\n",
      "Iteration 3737 => Loss: 51.65469510036096068006\n",
      "Iteration 3738 => Loss: 51.65448810216783925853\n",
      "Iteration 3739 => Loss: 51.65428111007935996213\n",
      "Iteration 3740 => Loss: 51.65407412408563203599\n",
      "Iteration 3741 => Loss: 51.65386714417683577949\n",
      "Iteration 3742 => Loss: 51.65366017034311596490\n",
      "Iteration 3743 => Loss: 51.65345320257466710245\n",
      "Iteration 3744 => Loss: 51.65324624086176896753\n",
      "Iteration 3745 => Loss: 51.65303928519455212154\n",
      "Iteration 3746 => Loss: 51.65283233556336739412\n",
      "Iteration 3747 => Loss: 51.65262539195844482265\n",
      "Iteration 3748 => Loss: 51.65241845437012102593\n",
      "Iteration 3749 => Loss: 51.65221152278869709562\n",
      "Iteration 3750 => Loss: 51.65200459720451675594\n",
      "Iteration 3751 => Loss: 51.65179767760796636367\n",
      "Iteration 3752 => Loss: 51.65159076398940385388\n",
      "Iteration 3753 => Loss: 51.65138385633925821594\n",
      "Iteration 3754 => Loss: 51.65117695464795843918\n",
      "Iteration 3755 => Loss: 51.65097005890595482924\n",
      "Iteration 3756 => Loss: 51.65076316910370479718\n",
      "Iteration 3757 => Loss: 51.65055628523173680833\n",
      "Iteration 3758 => Loss: 51.65034940728051537917\n",
      "Iteration 3759 => Loss: 51.65014253524058318590\n",
      "Iteration 3760 => Loss: 51.64993566910252553726\n",
      "Iteration 3761 => Loss: 51.64972880885689932029\n",
      "Iteration 3762 => Loss: 51.64952195449426852747\n",
      "Iteration 3763 => Loss: 51.64931510600530373267\n",
      "Iteration 3764 => Loss: 51.64910826338059735008\n",
      "Iteration 3765 => Loss: 51.64890142661086969156\n",
      "Iteration 3766 => Loss: 51.64869459568672738214\n",
      "Iteration 3767 => Loss: 51.64848777059889783914\n",
      "Iteration 3768 => Loss: 51.64828095133810847983\n",
      "Iteration 3769 => Loss: 51.64807413789508672153\n",
      "Iteration 3770 => Loss: 51.64786733026058129781\n",
      "Iteration 3771 => Loss: 51.64766052842538357481\n",
      "Iteration 3772 => Loss: 51.64745373238027781326\n",
      "Iteration 3773 => Loss: 51.64724694211612643358\n",
      "Iteration 3774 => Loss: 51.64704015762374211818\n",
      "Iteration 3775 => Loss: 51.64683337889396597120\n",
      "Iteration 3776 => Loss: 51.64662660591768172935\n",
      "Iteration 3777 => Loss: 51.64641983868582997275\n",
      "Iteration 3778 => Loss: 51.64621307718929443809\n",
      "Iteration 3779 => Loss: 51.64600632141900149463\n",
      "Iteration 3780 => Loss: 51.64579957136596988221\n",
      "Iteration 3781 => Loss: 51.64559282702111886465\n",
      "Iteration 3782 => Loss: 51.64538608837547428720\n",
      "Iteration 3783 => Loss: 51.64517935542002646798\n",
      "Iteration 3784 => Loss: 51.64497262814586520108\n",
      "Iteration 3785 => Loss: 51.64476590654400922631\n",
      "Iteration 3786 => Loss: 51.64455919060555544320\n",
      "Iteration 3787 => Loss: 51.64435248032155811870\n",
      "Iteration 3788 => Loss: 51.64414577568319941747\n",
      "Iteration 3789 => Loss: 51.64393907668157623903\n",
      "Iteration 3790 => Loss: 51.64373238330785653716\n",
      "Iteration 3791 => Loss: 51.64352569555319405481\n",
      "Iteration 3792 => Loss: 51.64331901340879937834\n",
      "Iteration 3793 => Loss: 51.64311233686587598868\n",
      "Iteration 3794 => Loss: 51.64290566591568421018\n",
      "Iteration 3795 => Loss: 51.64269900054943462919\n",
      "Iteration 3796 => Loss: 51.64249234075843730807\n",
      "Iteration 3797 => Loss: 51.64228568653397388744\n",
      "Iteration 3798 => Loss: 51.64207903786731890250\n",
      "Iteration 3799 => Loss: 51.64187239474983215359\n",
      "Iteration 3800 => Loss: 51.64166575717285212477\n",
      "Iteration 3801 => Loss: 51.64145912512777414349\n",
      "Iteration 3802 => Loss: 51.64125249860591537754\n",
      "Iteration 3803 => Loss: 51.64104587759874220865\n",
      "Iteration 3804 => Loss: 51.64083926209762864801\n",
      "Iteration 3805 => Loss: 51.64063265209406239364\n",
      "Iteration 3806 => Loss: 51.64042604757948140559\n",
      "Iteration 3807 => Loss: 51.64021944854535206559\n",
      "Iteration 3808 => Loss: 51.64001285498319759881\n",
      "Iteration 3809 => Loss: 51.63980626688453412498\n",
      "Iteration 3810 => Loss: 51.63959968424087065841\n",
      "Iteration 3811 => Loss: 51.63939310704374463512\n",
      "Iteration 3812 => Loss: 51.63918653528478586168\n",
      "Iteration 3813 => Loss: 51.63897996895557440666\n",
      "Iteration 3814 => Loss: 51.63877340804766902238\n",
      "Iteration 3815 => Loss: 51.63856685255272083168\n",
      "Iteration 3816 => Loss: 51.63836030246240937913\n",
      "Iteration 3817 => Loss: 51.63815375776835736588\n",
      "Iteration 3818 => Loss: 51.63794721846223723105\n",
      "Iteration 3819 => Loss: 51.63774068453579957350\n",
      "Iteration 3820 => Loss: 51.63753415598070972692\n",
      "Iteration 3821 => Loss: 51.63732763278872539559\n",
      "Iteration 3822 => Loss: 51.63712111495162560004\n",
      "Iteration 3823 => Loss: 51.63691460246114672827\n",
      "Iteration 3824 => Loss: 51.63670809530909622254\n",
      "Iteration 3825 => Loss: 51.63650159348726020880\n",
      "Iteration 3826 => Loss: 51.63629509698749586732\n",
      "Iteration 3827 => Loss: 51.63608860580163195664\n",
      "Iteration 3828 => Loss: 51.63588211992153276242\n",
      "Iteration 3829 => Loss: 51.63567563933908388663\n",
      "Iteration 3830 => Loss: 51.63546916404617803664\n",
      "Iteration 3831 => Loss: 51.63526269403470081443\n",
      "Iteration 3832 => Loss: 51.63505622929665861420\n",
      "Iteration 3833 => Loss: 51.63484976982393703793\n",
      "Iteration 3834 => Loss: 51.63464331560852116354\n",
      "Iteration 3835 => Loss: 51.63443686664238896356\n",
      "Iteration 3836 => Loss: 51.63423042291755393762\n",
      "Iteration 3837 => Loss: 51.63402398442605800710\n",
      "Iteration 3838 => Loss: 51.63381755115990756622\n",
      "Iteration 3839 => Loss: 51.63361112311118716889\n",
      "Iteration 3840 => Loss: 51.63340470027193163105\n",
      "Iteration 3841 => Loss: 51.63319828263426103376\n",
      "Iteration 3842 => Loss: 51.63299187019028124723\n",
      "Iteration 3843 => Loss: 51.63278546293207682538\n",
      "Iteration 3844 => Loss: 51.63257906085186021983\n",
      "Iteration 3845 => Loss: 51.63237266394173730077\n",
      "Iteration 3846 => Loss: 51.63216627219390630898\n",
      "Iteration 3847 => Loss: 51.63195988560057259065\n",
      "Iteration 3848 => Loss: 51.63175350415389885939\n",
      "Iteration 3849 => Loss: 51.63154712784618993737\n",
      "Iteration 3850 => Loss: 51.63134075666961564366\n",
      "Iteration 3851 => Loss: 51.63113439061645948414\n",
      "Iteration 3852 => Loss: 51.63092802967902628097\n",
      "Iteration 3853 => Loss: 51.63072167384959954006\n",
      "Iteration 3854 => Loss: 51.63051532312047697815\n",
      "Iteration 3855 => Loss: 51.63030897748399894454\n",
      "Iteration 3856 => Loss: 51.63010263693249868311\n",
      "Iteration 3857 => Loss: 51.62989630145835917574\n",
      "Iteration 3858 => Loss: 51.62968997105397761516\n",
      "Iteration 3859 => Loss: 51.62948364571169435067\n",
      "Iteration 3860 => Loss: 51.62927732542397762927\n",
      "Iteration 3861 => Loss: 51.62907101018321753827\n",
      "Iteration 3862 => Loss: 51.62886469998186811381\n",
      "Iteration 3863 => Loss: 51.62865839481240470832\n",
      "Iteration 3864 => Loss: 51.62845209466730267422\n",
      "Iteration 3865 => Loss: 51.62824579953904446938\n",
      "Iteration 3866 => Loss: 51.62803950942018360593\n",
      "Iteration 3867 => Loss: 51.62783322430318122542\n",
      "Iteration 3868 => Loss: 51.62762694418064768342\n",
      "Iteration 3869 => Loss: 51.62742066904510807035\n",
      "Iteration 3870 => Loss: 51.62721439888914432004\n",
      "Iteration 3871 => Loss: 51.62700813370537389346\n",
      "Iteration 3872 => Loss: 51.62680187348636451361\n",
      "Iteration 3873 => Loss: 51.62659561822474074688\n",
      "Iteration 3874 => Loss: 51.62638936791321242481\n",
      "Iteration 3875 => Loss: 51.62618312254436148123\n",
      "Iteration 3876 => Loss: 51.62597688211090485311\n",
      "Iteration 3877 => Loss: 51.62577064660553105568\n",
      "Iteration 3878 => Loss: 51.62556441602092860421\n",
      "Iteration 3879 => Loss: 51.62535819034982154108\n",
      "Iteration 3880 => Loss: 51.62515196958495522495\n",
      "Iteration 3881 => Loss: 51.62494575371911054162\n",
      "Iteration 3882 => Loss: 51.62473954274500442807\n",
      "Iteration 3883 => Loss: 51.62453333665546040265\n",
      "Iteration 3884 => Loss: 51.62432713544325224575\n",
      "Iteration 3885 => Loss: 51.62412093910122479201\n",
      "Iteration 3886 => Loss: 51.62391474762220866523\n",
      "Iteration 3887 => Loss: 51.62370856099904159464\n",
      "Iteration 3888 => Loss: 51.62350237922458973117\n",
      "Iteration 3889 => Loss: 51.62329620229171212031\n",
      "Iteration 3890 => Loss: 51.62309003019336017815\n",
      "Iteration 3891 => Loss: 51.62288386292238584474\n",
      "Iteration 3892 => Loss: 51.62267770047174764159\n",
      "Iteration 3893 => Loss: 51.62247154283437566846\n",
      "Iteration 3894 => Loss: 51.62226539000323555229\n",
      "Iteration 3895 => Loss: 51.62205924197130002540\n",
      "Iteration 3896 => Loss: 51.62185309873155603100\n",
      "Iteration 3897 => Loss: 51.62164696027699761771\n",
      "Iteration 3898 => Loss: 51.62144082660070409929\n",
      "Iteration 3899 => Loss: 51.62123469769558425924\n",
      "Iteration 3900 => Loss: 51.62102857355480267643\n",
      "Iteration 3901 => Loss: 51.62082245417135339949\n",
      "Iteration 3902 => Loss: 51.62061633953837258559\n",
      "Iteration 3903 => Loss: 51.62041022964891112679\n",
      "Iteration 3904 => Loss: 51.62020412449611228567\n",
      "Iteration 3905 => Loss: 51.61999802407307669228\n",
      "Iteration 3906 => Loss: 51.61979192837295471463\n",
      "Iteration 3907 => Loss: 51.61958583738891803705\n",
      "Iteration 3908 => Loss: 51.61937975111408150042\n",
      "Iteration 3909 => Loss: 51.61917366954168784332\n",
      "Iteration 3910 => Loss: 51.61896759266493717178\n",
      "Iteration 3911 => Loss: 51.61876152047698695924\n",
      "Iteration 3912 => Loss: 51.61855545297113678771\n",
      "Iteration 3913 => Loss: 51.61834939014057255235\n",
      "Iteration 3914 => Loss: 51.61814333197860804603\n",
      "Iteration 3915 => Loss: 51.61793727847848600732\n",
      "Iteration 3916 => Loss: 51.61773122963349891279\n",
      "Iteration 3917 => Loss: 51.61752518543693923903\n",
      "Iteration 3918 => Loss: 51.61731914588213498973\n",
      "Iteration 3919 => Loss: 51.61711311096243548491\n",
      "Iteration 3920 => Loss: 51.61690708067115451740\n",
      "Iteration 3921 => Loss: 51.61670105500169825063\n",
      "Iteration 3922 => Loss: 51.61649503394741600459\n",
      "Iteration 3923 => Loss: 51.61628901750168552098\n",
      "Iteration 3924 => Loss: 51.61608300565792006864\n",
      "Iteration 3925 => Loss: 51.61587699840956844355\n",
      "Iteration 3926 => Loss: 51.61567099575003680911\n",
      "Iteration 3927 => Loss: 51.61546499767277396131\n",
      "Iteration 3928 => Loss: 51.61525900417127132869\n",
      "Iteration 3929 => Loss: 51.61505301523894928550\n",
      "Iteration 3930 => Loss: 51.61484703086937742000\n",
      "Iteration 3931 => Loss: 51.61464105105600452816\n",
      "Iteration 3932 => Loss: 51.61443507579235756566\n",
      "Iteration 3933 => Loss: 51.61422910507197059360\n",
      "Iteration 3934 => Loss: 51.61402313888841320022\n",
      "Iteration 3935 => Loss: 51.61381717723523365748\n",
      "Iteration 3936 => Loss: 51.61361122010600865906\n",
      "Iteration 3937 => Loss: 51.61340526749432200404\n",
      "Iteration 3938 => Loss: 51.61319931939380722952\n",
      "Iteration 3939 => Loss: 51.61299337579803392373\n",
      "Iteration 3940 => Loss: 51.61278743670067825633\n",
      "Iteration 3941 => Loss: 51.61258150209538086983\n",
      "Iteration 3942 => Loss: 51.61237557197579661761\n",
      "Iteration 3943 => Loss: 51.61216964633556614217\n",
      "Iteration 3944 => Loss: 51.61196372516842956202\n",
      "Iteration 3945 => Loss: 51.61175780846804173052\n",
      "Iteration 3946 => Loss: 51.61155189622814276618\n",
      "Iteration 3947 => Loss: 51.61134598844249410377\n",
      "Iteration 3948 => Loss: 51.61114008510479322922\n",
      "Iteration 3949 => Loss: 51.61093418620880868275\n",
      "Iteration 3950 => Loss: 51.61072829174830900456\n",
      "Iteration 3951 => Loss: 51.61052240171711957828\n",
      "Iteration 3952 => Loss: 51.61031651610894499527\n",
      "Iteration 3953 => Loss: 51.61011063491768879885\n",
      "Iteration 3954 => Loss: 51.60990475813712663467\n",
      "Iteration 3955 => Loss: 51.60969888576109809719\n",
      "Iteration 3956 => Loss: 51.60949301778347830805\n",
      "Iteration 3957 => Loss: 51.60928715419814949428\n",
      "Iteration 3958 => Loss: 51.60908129499892282865\n",
      "Iteration 3959 => Loss: 51.60887544017975869792\n",
      "Iteration 3960 => Loss: 51.60866958973451090742\n",
      "Iteration 3961 => Loss: 51.60846374365712563304\n",
      "Iteration 3962 => Loss: 51.60825790194153483981\n",
      "Iteration 3963 => Loss: 51.60805206458168470363\n",
      "Iteration 3964 => Loss: 51.60784623157152850581\n",
      "Iteration 3965 => Loss: 51.60764040290504084396\n",
      "Iteration 3966 => Loss: 51.60743457857620342111\n",
      "Iteration 3967 => Loss: 51.60722875857900504570\n",
      "Iteration 3968 => Loss: 51.60702294290747005334\n",
      "Iteration 3969 => Loss: 51.60681713155562277962\n",
      "Iteration 3970 => Loss: 51.60661132451750177097\n",
      "Iteration 3971 => Loss: 51.60640552178715978471\n",
      "Iteration 3972 => Loss: 51.60619972335863536728\n",
      "Iteration 3973 => Loss: 51.60599392922605233025\n",
      "Iteration 3974 => Loss: 51.60578813938345632550\n",
      "Iteration 3975 => Loss: 51.60558235382497116461\n",
      "Iteration 3976 => Loss: 51.60537657254469223744\n",
      "Iteration 3977 => Loss: 51.60517079553677888271\n",
      "Iteration 3978 => Loss: 51.60496502279533359570\n",
      "Iteration 3979 => Loss: 51.60475925431455834769\n",
      "Iteration 3980 => Loss: 51.60455349008856984483\n",
      "Iteration 3981 => Loss: 51.60434773011159137468\n",
      "Iteration 3982 => Loss: 51.60414197437778938138\n",
      "Iteration 3983 => Loss: 51.60393622288137294163\n",
      "Iteration 3984 => Loss: 51.60373047561655823756\n",
      "Iteration 3985 => Loss: 51.60352473257757566216\n",
      "Iteration 3986 => Loss: 51.60331899375869824098\n",
      "Iteration 3987 => Loss: 51.60311325915410662901\n",
      "Iteration 3988 => Loss: 51.60290752875813069522\n",
      "Iteration 3989 => Loss: 51.60270180256506478145\n",
      "Iteration 3990 => Loss: 51.60249608056914638610\n",
      "Iteration 3991 => Loss: 51.60229036276471958899\n",
      "Iteration 3992 => Loss: 51.60208464914608583740\n",
      "Iteration 3993 => Loss: 51.60187893970758210571\n",
      "Iteration 3994 => Loss: 51.60167323444354536832\n",
      "Iteration 3995 => Loss: 51.60146753334833391591\n",
      "Iteration 3996 => Loss: 51.60126183641632735544\n",
      "Iteration 3997 => Loss: 51.60105614364190529386\n",
      "Iteration 3998 => Loss: 51.60085045501942602186\n",
      "Iteration 3999 => Loss: 51.60064477054331177897\n",
      "Iteration 4000 => Loss: 51.60043909020802033183\n",
      "Iteration 4001 => Loss: 51.60023341400790286571\n",
      "Iteration 4002 => Loss: 51.60002774193747399067\n",
      "Iteration 4003 => Loss: 51.59982207399112752455\n",
      "Iteration 4004 => Loss: 51.59961641016337807741\n",
      "Iteration 4005 => Loss: 51.59941075044866209964\n",
      "Iteration 4006 => Loss: 51.59920509484148709589\n",
      "Iteration 4007 => Loss: 51.59899944333636057081\n",
      "Iteration 4008 => Loss: 51.59879379592781134534\n",
      "Iteration 4009 => Loss: 51.59858815261031850241\n",
      "Iteration 4010 => Loss: 51.59838251337847481182\n",
      "Iteration 4011 => Loss: 51.59817687822678777820\n",
      "Iteration 4012 => Loss: 51.59797124714981464422\n",
      "Iteration 4013 => Loss: 51.59776562014215528507\n",
      "Iteration 4014 => Loss: 51.59755999719838115425\n",
      "Iteration 4015 => Loss: 51.59735437831312054868\n",
      "Iteration 4016 => Loss: 51.59714876348091650016\n",
      "Iteration 4017 => Loss: 51.59694315269646835986\n",
      "Iteration 4018 => Loss: 51.59673754595435468673\n",
      "Iteration 4019 => Loss: 51.59653194324921088310\n",
      "Iteration 4020 => Loss: 51.59632634457573630016\n",
      "Iteration 4021 => Loss: 51.59612074992856634026\n",
      "Iteration 4022 => Loss: 51.59591515930240746002\n",
      "Iteration 4023 => Loss: 51.59570957269192348349\n",
      "Iteration 4024 => Loss: 51.59550399009184218357\n",
      "Iteration 4025 => Loss: 51.59529841149684870061\n",
      "Iteration 4026 => Loss: 51.59509283690167791292\n",
      "Iteration 4027 => Loss: 51.59488726630107180426\n",
      "Iteration 4028 => Loss: 51.59468169968979367468\n",
      "Iteration 4029 => Loss: 51.59447613706257840249\n",
      "Iteration 4030 => Loss: 51.59427057841421770945\n",
      "Iteration 4031 => Loss: 51.59406502373949621187\n",
      "Iteration 4032 => Loss: 51.59385947303317010437\n",
      "Iteration 4033 => Loss: 51.59365392629008795211\n",
      "Iteration 4034 => Loss: 51.59344838350505568769\n",
      "Iteration 4035 => Loss: 51.59324284467289345457\n",
      "Iteration 4036 => Loss: 51.59303730978844981792\n",
      "Iteration 4037 => Loss: 51.59283177884655913203\n",
      "Iteration 4038 => Loss: 51.59262625184210548923\n",
      "Iteration 4039 => Loss: 51.59242072876994456010\n",
      "Iteration 4040 => Loss: 51.59221520962498175322\n",
      "Iteration 4041 => Loss: 51.59200969440208695005\n",
      "Iteration 4042 => Loss: 51.59180418309617266459\n",
      "Iteration 4043 => Loss: 51.59159867570220825428\n",
      "Iteration 4044 => Loss: 51.59139317221504228428\n",
      "Iteration 4045 => Loss: 51.59118767262967253373\n",
      "Iteration 4046 => Loss: 51.59098217694101151665\n",
      "Iteration 4047 => Loss: 51.59077668514406411759\n",
      "Iteration 4048 => Loss: 51.59057119723376416687\n",
      "Iteration 4049 => Loss: 51.59036571320512365446\n",
      "Iteration 4050 => Loss: 51.59016023305314035952\n",
      "Iteration 4051 => Loss: 51.58995475677278363946\n",
      "Iteration 4052 => Loss: 51.58974928435910811686\n",
      "Iteration 4053 => Loss: 51.58954381580713288713\n",
      "Iteration 4054 => Loss: 51.58933835111187704570\n",
      "Iteration 4055 => Loss: 51.58913289026843074225\n",
      "Iteration 4056 => Loss: 51.58892743327181307222\n",
      "Iteration 4057 => Loss: 51.58872198011714260701\n",
      "Iteration 4058 => Loss: 51.58851653079944554747\n",
      "Iteration 4059 => Loss: 51.58831108531384757043\n",
      "Iteration 4060 => Loss: 51.58810564365546014187\n",
      "Iteration 4061 => Loss: 51.58790020581936630606\n",
      "Iteration 4062 => Loss: 51.58769477180072726696\n",
      "Iteration 4063 => Loss: 51.58748934159466159599\n",
      "Iteration 4064 => Loss: 51.58728391519631628626\n",
      "Iteration 4065 => Loss: 51.58707849260085254173\n",
      "Iteration 4066 => Loss: 51.58687307380341735552\n",
      "Iteration 4067 => Loss: 51.58666765879922166960\n",
      "Iteration 4068 => Loss: 51.58646224758342668792\n",
      "Iteration 4069 => Loss: 51.58625684015127887960\n",
      "Iteration 4070 => Loss: 51.58605143649791813232\n",
      "Iteration 4071 => Loss: 51.58584603661861223145\n",
      "Iteration 4072 => Loss: 51.58564064050857922439\n",
      "Iteration 4073 => Loss: 51.58543524816305847480\n",
      "Iteration 4074 => Loss: 51.58522985957731066264\n",
      "Iteration 4075 => Loss: 51.58502447474658225701\n",
      "Iteration 4076 => Loss: 51.58481909366616235957\n",
      "Iteration 4077 => Loss: 51.58461371633131875569\n",
      "Iteration 4078 => Loss: 51.58440834273736186333\n",
      "Iteration 4079 => Loss: 51.58420297287959499499\n",
      "Iteration 4080 => Loss: 51.58399760675331435777\n",
      "Iteration 4081 => Loss: 51.58379224435383747505\n",
      "Iteration 4082 => Loss: 51.58358688567651739731\n",
      "Iteration 4083 => Loss: 51.58338153071670717509\n",
      "Iteration 4084 => Loss: 51.58317617946972433174\n",
      "Iteration 4085 => Loss: 51.58297083193099297205\n",
      "Iteration 4086 => Loss: 51.58276548809581640853\n",
      "Iteration 4087 => Loss: 51.58256014795962585140\n",
      "Iteration 4088 => Loss: 51.58235481151781698372\n",
      "Iteration 4089 => Loss: 51.58214947876576417229\n",
      "Iteration 4090 => Loss: 51.58194414969890573275\n",
      "Iteration 4091 => Loss: 51.58173882431267287529\n",
      "Iteration 4092 => Loss: 51.58153350260248970471\n",
      "Iteration 4093 => Loss: 51.58132818456379453664\n",
      "Iteration 4094 => Loss: 51.58112287019206121386\n",
      "Iteration 4095 => Loss: 51.58091755948273515742\n",
      "Iteration 4096 => Loss: 51.58071225243129021010\n",
      "Iteration 4097 => Loss: 51.58050694903324995266\n",
      "Iteration 4098 => Loss: 51.58030164928404559532\n",
      "Iteration 4099 => Loss: 51.58009635317922914055\n",
      "Iteration 4100 => Loss: 51.57989106071430285283\n",
      "Iteration 4101 => Loss: 51.57968577188477610207\n",
      "Iteration 4102 => Loss: 51.57948048668621510160\n",
      "Iteration 4103 => Loss: 51.57927520511413632676\n",
      "Iteration 4104 => Loss: 51.57906992716409178001\n",
      "Iteration 4105 => Loss: 51.57886465283167609641\n",
      "Iteration 4106 => Loss: 51.57865938211241285671\n",
      "Iteration 4107 => Loss: 51.57845411500193222309\n",
      "Iteration 4108 => Loss: 51.57824885149580040888\n",
      "Iteration 4109 => Loss: 51.57804359158964757626\n",
      "Iteration 4110 => Loss: 51.57783833527902572769\n",
      "Iteration 4111 => Loss: 51.57763308255960055249\n",
      "Iteration 4112 => Loss: 51.57742783342698800197\n",
      "Iteration 4113 => Loss: 51.57722258787687508175\n",
      "Iteration 4114 => Loss: 51.57701734590482800513\n",
      "Iteration 4115 => Loss: 51.57681210750656219943\n",
      "Iteration 4116 => Loss: 51.57660687267772914311\n",
      "Iteration 4117 => Loss: 51.57640164141401584175\n",
      "Iteration 4118 => Loss: 51.57619641371110930095\n",
      "Iteration 4119 => Loss: 51.57599118956470363173\n",
      "Iteration 4120 => Loss: 51.57578596897049294512\n",
      "Iteration 4121 => Loss: 51.57558075192420687927\n",
      "Iteration 4122 => Loss: 51.57537553842158217776\n",
      "Iteration 4123 => Loss: 51.57517032845832005705\n",
      "Iteration 4124 => Loss: 51.57496512203019278786\n",
      "Iteration 4125 => Loss: 51.57475991913295132463\n",
      "Iteration 4126 => Loss: 51.57455471976233241094\n",
      "Iteration 4127 => Loss: 51.57434952391414384465\n",
      "Iteration 4128 => Loss: 51.57414433158412947478\n",
      "Iteration 4129 => Loss: 51.57393914276810420461\n",
      "Iteration 4130 => Loss: 51.57373395746186872657\n",
      "Iteration 4131 => Loss: 51.57352877566121662767\n",
      "Iteration 4132 => Loss: 51.57332359736198412747\n",
      "Iteration 4133 => Loss: 51.57311842255998612927\n",
      "Iteration 4134 => Loss: 51.57291325125105174720\n",
      "Iteration 4135 => Loss: 51.57270808343103141169\n",
      "Iteration 4136 => Loss: 51.57250291909578976401\n",
      "Iteration 4137 => Loss: 51.57229775824117723459\n",
      "Iteration 4138 => Loss: 51.57209260086306557014\n",
      "Iteration 4139 => Loss: 51.57188744695736914991\n",
      "Iteration 4140 => Loss: 51.57168229651992419349\n",
      "Iteration 4141 => Loss: 51.57147714954667350185\n",
      "Iteration 4142 => Loss: 51.57127200603348882169\n",
      "Iteration 4143 => Loss: 51.57106686597632005942\n",
      "Iteration 4144 => Loss: 51.57086172937106738345\n",
      "Iteration 4145 => Loss: 51.57065659621368780563\n",
      "Iteration 4146 => Loss: 51.57045146650010991607\n",
      "Iteration 4147 => Loss: 51.57024634022631914831\n",
      "Iteration 4148 => Loss: 51.57004121738820145993\n",
      "Iteration 4149 => Loss: 51.56983609798179202244\n",
      "Iteration 4150 => Loss: 51.56963098200307626939\n",
      "Iteration 4151 => Loss: 51.56942586944800410720\n",
      "Iteration 4152 => Loss: 51.56922076031258939111\n",
      "Iteration 4153 => Loss: 51.56901565459281755466\n",
      "Iteration 4154 => Loss: 51.56881055228475929653\n",
      "Iteration 4155 => Loss: 51.56860545338437162854\n",
      "Iteration 4156 => Loss: 51.56840035788772524938\n",
      "Iteration 4157 => Loss: 51.56819526579085533058\n",
      "Iteration 4158 => Loss: 51.56799017708978283281\n",
      "Iteration 4159 => Loss: 51.56778509178061398188\n",
      "Iteration 4160 => Loss: 51.56758000985936973848\n",
      "Iteration 4161 => Loss: 51.56737493132213501212\n",
      "Iteration 4162 => Loss: 51.56716985616501602863\n",
      "Iteration 4163 => Loss: 51.56696478438409059208\n",
      "Iteration 4164 => Loss: 51.56675971597545782288\n",
      "Iteration 4165 => Loss: 51.56655465093521684139\n",
      "Iteration 4166 => Loss: 51.56634958925950229514\n",
      "Iteration 4167 => Loss: 51.56614453094443462078\n",
      "Iteration 4168 => Loss: 51.56593947598614136041\n",
      "Iteration 4169 => Loss: 51.56573442438078558325\n",
      "Iteration 4170 => Loss: 51.56552937612450193683\n",
      "Iteration 4171 => Loss: 51.56532433121343927951\n",
      "Iteration 4172 => Loss: 51.56511928964381041851\n",
      "Iteration 4173 => Loss: 51.56491425141171447422\n",
      "Iteration 4174 => Loss: 51.56470921651340688641\n",
      "Iteration 4175 => Loss: 51.56450418494505782974\n",
      "Iteration 4176 => Loss: 51.56429915670286590057\n",
      "Iteration 4177 => Loss: 51.56409413178302258984\n",
      "Iteration 4178 => Loss: 51.56388911018179754819\n",
      "Iteration 4179 => Loss: 51.56368409189536095028\n",
      "Iteration 4180 => Loss: 51.56347907691996113044\n",
      "Iteration 4181 => Loss: 51.56327406525188195019\n",
      "Iteration 4182 => Loss: 51.56306905688733621673\n",
      "Iteration 4183 => Loss: 51.56286405182258647528\n",
      "Iteration 4184 => Loss: 51.56265905005390237648\n",
      "Iteration 4185 => Loss: 51.56245405157756778181\n",
      "Iteration 4186 => Loss: 51.56224905638985944734\n",
      "Iteration 4187 => Loss: 51.56204406448703991828\n",
      "Iteration 4188 => Loss: 51.56183907586547121582\n",
      "Iteration 4189 => Loss: 51.56163409052143009603\n",
      "Iteration 4190 => Loss: 51.56142910845122884211\n",
      "Iteration 4191 => Loss: 51.56122412965117263184\n",
      "Iteration 4192 => Loss: 51.56101915411763059183\n",
      "Iteration 4193 => Loss: 51.56081418184694342699\n",
      "Iteration 4194 => Loss: 51.56060921283542342053\n",
      "Iteration 4195 => Loss: 51.56040424707943969906\n",
      "Iteration 4196 => Loss: 51.56019928457538270550\n",
      "Iteration 4197 => Loss: 51.55999432531958603931\n",
      "Iteration 4198 => Loss: 51.55978936930846145970\n",
      "Iteration 4199 => Loss: 51.55958441653837809326\n",
      "Iteration 4200 => Loss: 51.55937946700574059378\n",
      "Iteration 4201 => Loss: 51.55917452070693940414\n",
      "Iteration 4202 => Loss: 51.55896957763839338895\n",
      "Iteration 4203 => Loss: 51.55876463779652851827\n",
      "Iteration 4204 => Loss: 51.55855970117779207840\n",
      "Iteration 4205 => Loss: 51.55835476777856740682\n",
      "Iteration 4206 => Loss: 51.55814983759533021157\n",
      "Iteration 4207 => Loss: 51.55794491062452777896\n",
      "Iteration 4208 => Loss: 51.55773998686262160618\n",
      "Iteration 4209 => Loss: 51.55753506630606608496\n",
      "Iteration 4210 => Loss: 51.55733014895134402877\n",
      "Iteration 4211 => Loss: 51.55712523479492404022\n",
      "Iteration 4212 => Loss: 51.55692032383331024903\n",
      "Iteration 4213 => Loss: 51.55671541606299967953\n",
      "Iteration 4214 => Loss: 51.55651051148046803974\n",
      "Iteration 4215 => Loss: 51.55630561008226919739\n",
      "Iteration 4216 => Loss: 51.55610071186489307138\n",
      "Iteration 4217 => Loss: 51.55589581682489352943\n",
      "Iteration 4218 => Loss: 51.55569092495877470128\n",
      "Iteration 4219 => Loss: 51.55548603626309756010\n",
      "Iteration 4220 => Loss: 51.55528115073443728988\n",
      "Iteration 4221 => Loss: 51.55507626836928380953\n",
      "Iteration 4222 => Loss: 51.55487138916424783019\n",
      "Iteration 4223 => Loss: 51.55466651311591164131\n",
      "Iteration 4224 => Loss: 51.55446164022081489975\n",
      "Iteration 4225 => Loss: 51.55425677047558252752\n",
      "Iteration 4226 => Loss: 51.55405190387678970865\n",
      "Iteration 4227 => Loss: 51.55384704042105425970\n",
      "Iteration 4228 => Loss: 51.55364218010499399725\n",
      "Iteration 4229 => Loss: 51.55343732292516278903\n",
      "Iteration 4230 => Loss: 51.55323246887826371676\n",
      "Iteration 4231 => Loss: 51.55302761796086485901\n",
      "Iteration 4232 => Loss: 51.55282277016967640293\n",
      "Iteration 4233 => Loss: 51.55261792550128063795\n",
      "Iteration 4234 => Loss: 51.55241308395235932949\n",
      "Iteration 4235 => Loss: 51.55220824551958003212\n",
      "Iteration 4236 => Loss: 51.55200341019960319500\n",
      "Iteration 4237 => Loss: 51.55179857798906795097\n",
      "Iteration 4238 => Loss: 51.55159374888472001430\n",
      "Iteration 4239 => Loss: 51.55138892288322693958\n",
      "Iteration 4240 => Loss: 51.55118409998127049221\n",
      "Iteration 4241 => Loss: 51.55097928017558217562\n",
      "Iteration 4242 => Loss: 51.55077446346285796608\n",
      "Iteration 4243 => Loss: 51.55056964983980094530\n",
      "Iteration 4244 => Loss: 51.55036483930314972213\n",
      "Iteration 4245 => Loss: 51.55016003184967843254\n",
      "Iteration 4246 => Loss: 51.54995522747605463110\n",
      "Iteration 4247 => Loss: 51.54975042617906666464\n",
      "Iteration 4248 => Loss: 51.54954562795548156373\n",
      "Iteration 4249 => Loss: 51.54934083280203083177\n",
      "Iteration 4250 => Loss: 51.54913604071550992103\n",
      "Iteration 4251 => Loss: 51.54893125169269296748\n",
      "Iteration 4252 => Loss: 51.54872646573034700168\n",
      "Iteration 4253 => Loss: 51.54852168282523194875\n",
      "Iteration 4254 => Loss: 51.54831690297423563152\n",
      "Iteration 4255 => Loss: 51.54811212617406823711\n",
      "Iteration 4256 => Loss: 51.54790735242158916662\n",
      "Iteration 4257 => Loss: 51.54770258171361518862\n",
      "Iteration 4258 => Loss: 51.54749781404697017706\n",
      "Iteration 4259 => Loss: 51.54729304941846379506\n",
      "Iteration 4260 => Loss: 51.54708828782496965459\n",
      "Iteration 4261 => Loss: 51.54688352926329031334\n",
      "Iteration 4262 => Loss: 51.54667877373031359411\n",
      "Iteration 4263 => Loss: 51.54647402122288468718\n",
      "Iteration 4264 => Loss: 51.54626927173787720449\n",
      "Iteration 4265 => Loss: 51.54606452527215765258\n",
      "Iteration 4266 => Loss: 51.54585978182261385427\n",
      "Iteration 4267 => Loss: 51.54565504138611942153\n",
      "Iteration 4268 => Loss: 51.54545030395959059888\n",
      "Iteration 4269 => Loss: 51.54524556953990810371\n",
      "Iteration 4270 => Loss: 51.54504083812397396969\n",
      "Iteration 4271 => Loss: 51.54483610970872575763\n",
      "Iteration 4272 => Loss: 51.54463138429105839577\n",
      "Iteration 4273 => Loss: 51.54442666186792365579\n",
      "Iteration 4274 => Loss: 51.54422194243623067678\n",
      "Iteration 4275 => Loss: 51.54401722599294544125\n",
      "Iteration 4276 => Loss: 51.54381251253500551002\n",
      "Iteration 4277 => Loss: 51.54360780205936265475\n",
      "Iteration 4278 => Loss: 51.54340309456298285795\n",
      "Iteration 4279 => Loss: 51.54319839004281789130\n",
      "Iteration 4280 => Loss: 51.54299368849584794816\n",
      "Iteration 4281 => Loss: 51.54278898991905322191\n",
      "Iteration 4282 => Loss: 51.54258429430944232763\n",
      "Iteration 4283 => Loss: 51.54237960166400256412\n",
      "Iteration 4284 => Loss: 51.54217491197972123018\n",
      "Iteration 4285 => Loss: 51.54197022525358562461\n",
      "Iteration 4286 => Loss: 51.54176554148263988964\n",
      "Iteration 4287 => Loss: 51.54156086066392106204\n",
      "Iteration 4288 => Loss: 51.54135618279440222977\n",
      "Iteration 4289 => Loss: 51.54115150787116306219\n",
      "Iteration 4290 => Loss: 51.54094683589122638523\n",
      "Iteration 4291 => Loss: 51.54074216685161502483\n",
      "Iteration 4292 => Loss: 51.54053750074943707205\n",
      "Iteration 4293 => Loss: 51.54033283758167272026\n",
      "Iteration 4294 => Loss: 51.54012817734549400939\n",
      "Iteration 4295 => Loss: 51.53992352003787402737\n",
      "Iteration 4296 => Loss: 51.53971886565592086527\n",
      "Iteration 4297 => Loss: 51.53951421419672840329\n",
      "Iteration 4298 => Loss: 51.53930956565740473252\n",
      "Iteration 4299 => Loss: 51.53910492003502241687\n",
      "Iteration 4300 => Loss: 51.53890027732666112570\n",
      "Iteration 4301 => Loss: 51.53869563752947158264\n",
      "Iteration 4302 => Loss: 51.53849100064056898418\n",
      "Iteration 4303 => Loss: 51.53828636665708984310\n",
      "Iteration 4304 => Loss: 51.53808173557608540705\n",
      "Iteration 4305 => Loss: 51.53787710739474192678\n",
      "Iteration 4306 => Loss: 51.53767248211023854765\n",
      "Iteration 4307 => Loss: 51.53746785971964072814\n",
      "Iteration 4308 => Loss: 51.53726324022019866788\n",
      "Iteration 4309 => Loss: 51.53705862360899203622\n",
      "Iteration 4310 => Loss: 51.53685400988323550564\n",
      "Iteration 4311 => Loss: 51.53664939904005848348\n",
      "Iteration 4312 => Loss: 51.53644479107666143136\n",
      "Iteration 4313 => Loss: 51.53624018599025902176\n",
      "Iteration 4314 => Loss: 51.53603558377797355661\n",
      "Iteration 4315 => Loss: 51.53583098443704102465\n",
      "Iteration 4316 => Loss: 51.53562638796468320379\n",
      "Iteration 4317 => Loss: 51.53542179435807213395\n",
      "Iteration 4318 => Loss: 51.53521720361446512015\n",
      "Iteration 4319 => Loss: 51.53501261573104841318\n",
      "Iteration 4320 => Loss: 51.53480803070504379093\n",
      "Iteration 4321 => Loss: 51.53460344853372276930\n",
      "Iteration 4322 => Loss: 51.53439886921429291533\n",
      "Iteration 4323 => Loss: 51.53419429274401863950\n",
      "Iteration 4324 => Loss: 51.53398971912014303598\n",
      "Iteration 4325 => Loss: 51.53378514833990919897\n",
      "Iteration 4326 => Loss: 51.53358058040058864435\n",
      "Iteration 4327 => Loss: 51.53337601529945999346\n",
      "Iteration 4328 => Loss: 51.53317145303382318389\n",
      "Iteration 4329 => Loss: 51.53296689360089288812\n",
      "Iteration 4330 => Loss: 51.53276233699802588717\n",
      "Iteration 4331 => Loss: 51.53255778322245816980\n",
      "Iteration 4332 => Loss: 51.53235323227152520076\n",
      "Iteration 4333 => Loss: 51.53214868414252691764\n",
      "Iteration 4334 => Loss: 51.53194413883276325805\n",
      "Iteration 4335 => Loss: 51.53173959633954126502\n",
      "Iteration 4336 => Loss: 51.53153505666021061415\n",
      "Iteration 4337 => Loss: 51.53133051979209966476\n",
      "Iteration 4338 => Loss: 51.53112598573250835443\n",
      "Iteration 4339 => Loss: 51.53092145447882188591\n",
      "Iteration 4340 => Loss: 51.53071692602835440766\n",
      "Iteration 4341 => Loss: 51.53051240037846270070\n",
      "Iteration 4342 => Loss: 51.53030787752649644062\n",
      "Iteration 4343 => Loss: 51.53010335746984793559\n",
      "Iteration 4344 => Loss: 51.52989884020586686120\n",
      "Iteration 4345 => Loss: 51.52969432573191710389\n",
      "Iteration 4346 => Loss: 51.52948981404539097184\n",
      "Iteration 4347 => Loss: 51.52928530514368077320\n",
      "Iteration 4348 => Loss: 51.52908079902417171070\n",
      "Iteration 4349 => Loss: 51.52887629568427030335\n",
      "Iteration 4350 => Loss: 51.52867179512136175390\n",
      "Iteration 4351 => Loss: 51.52846729733285968678\n",
      "Iteration 4352 => Loss: 51.52826280231619904271\n",
      "Iteration 4353 => Loss: 51.52805831006877212985\n",
      "Iteration 4354 => Loss: 51.52785382058800678351\n",
      "Iteration 4355 => Loss: 51.52764933387137347154\n",
      "Iteration 4356 => Loss: 51.52744484991627160753\n",
      "Iteration 4357 => Loss: 51.52724036872011481591\n",
      "Iteration 4358 => Loss: 51.52703589028043040798\n",
      "Iteration 4359 => Loss: 51.52683141459462490275\n",
      "Iteration 4360 => Loss: 51.52662694166014745178\n",
      "Iteration 4361 => Loss: 51.52642247147449694467\n",
      "Iteration 4362 => Loss: 51.52621800403510832211\n",
      "Iteration 4363 => Loss: 51.52601353933950178998\n",
      "Iteration 4364 => Loss: 51.52580907738509807814\n",
      "Iteration 4365 => Loss: 51.52560461816941739244\n",
      "Iteration 4366 => Loss: 51.52540016168996572787\n",
      "Iteration 4367 => Loss: 51.52519570794423486859\n",
      "Iteration 4368 => Loss: 51.52499125692972370416\n",
      "Iteration 4369 => Loss: 51.52478680864391691330\n",
      "Iteration 4370 => Loss: 51.52458236308435601813\n",
      "Iteration 4371 => Loss: 51.52437792024854701367\n",
      "Iteration 4372 => Loss: 51.52417348013402431661\n",
      "Iteration 4373 => Loss: 51.52396904273831523824\n",
      "Iteration 4374 => Loss: 51.52376460805898972239\n",
      "Iteration 4375 => Loss: 51.52356017609352534237\n",
      "Iteration 4376 => Loss: 51.52335574683949914743\n",
      "Iteration 4377 => Loss: 51.52315132029446687056\n",
      "Iteration 4378 => Loss: 51.52294689645599135019\n",
      "Iteration 4379 => Loss: 51.52274247532159279217\n",
      "Iteration 4380 => Loss: 51.52253805688890508918\n",
      "Iteration 4381 => Loss: 51.52233364115544844708\n",
      "Iteration 4382 => Loss: 51.52212922811884254770\n",
      "Iteration 4383 => Loss: 51.52192481777662180775\n",
      "Iteration 4384 => Loss: 51.52172041012640590907\n",
      "Iteration 4385 => Loss: 51.52151600516580032263\n",
      "Iteration 4386 => Loss: 51.52131160289236788685\n",
      "Iteration 4387 => Loss: 51.52110720330376381071\n",
      "Iteration 4388 => Loss: 51.52090280639755093262\n",
      "Iteration 4389 => Loss: 51.52069841217137025069\n",
      "Iteration 4390 => Loss: 51.52049402062284855219\n",
      "Iteration 4391 => Loss: 51.52028963174956288640\n",
      "Iteration 4392 => Loss: 51.52008524554921109484\n",
      "Iteration 4393 => Loss: 51.51988086201936312136\n",
      "Iteration 4394 => Loss: 51.51967648115771680750\n",
      "Iteration 4395 => Loss: 51.51947210296189894052\n",
      "Iteration 4396 => Loss: 51.51926772742954341311\n",
      "Iteration 4397 => Loss: 51.51906335455832675052\n",
      "Iteration 4398 => Loss: 51.51885898434591126716\n",
      "Iteration 4399 => Loss: 51.51865461678993796113\n",
      "Iteration 4400 => Loss: 51.51845025188811177941\n",
      "Iteration 4401 => Loss: 51.51824588963810924724\n",
      "Iteration 4402 => Loss: 51.51804153003755715190\n",
      "Iteration 4403 => Loss: 51.51783717308421017833\n",
      "Iteration 4404 => Loss: 51.51763281877572353551\n",
      "Iteration 4405 => Loss: 51.51742846710981638125\n",
      "Iteration 4406 => Loss: 51.51722411808417234624\n",
      "Iteration 4407 => Loss: 51.51701977169650348287\n",
      "Iteration 4408 => Loss: 51.51681542794452184353\n",
      "Iteration 4409 => Loss: 51.51661108682594658603\n",
      "Iteration 4410 => Loss: 51.51640674833850397363\n",
      "Iteration 4411 => Loss: 51.51620241247991316413\n",
      "Iteration 4412 => Loss: 51.51599807924789331537\n",
      "Iteration 4413 => Loss: 51.51579374864021332314\n",
      "Iteration 4414 => Loss: 51.51558942065459234527\n",
      "Iteration 4415 => Loss: 51.51538509528879217214\n",
      "Iteration 4416 => Loss: 51.51518077254053906699\n",
      "Iteration 4417 => Loss: 51.51497645240761613650\n",
      "Iteration 4418 => Loss: 51.51477213488777096018\n",
      "Iteration 4419 => Loss: 51.51456781997877953927\n",
      "Iteration 4420 => Loss: 51.51436350767839655873\n",
      "Iteration 4421 => Loss: 51.51415919798441223065\n",
      "Iteration 4422 => Loss: 51.51395489089460966170\n",
      "Iteration 4423 => Loss: 51.51375058640675774768\n",
      "Iteration 4424 => Loss: 51.51354628451865380612\n",
      "Iteration 4425 => Loss: 51.51334198522813778709\n",
      "Iteration 4426 => Loss: 51.51313768853292174299\n",
      "Iteration 4427 => Loss: 51.51293339443086694018\n",
      "Iteration 4428 => Loss: 51.51272910291982043418\n",
      "Iteration 4429 => Loss: 51.51252481399749427737\n",
      "Iteration 4430 => Loss: 51.51232052766177105241\n",
      "Iteration 4431 => Loss: 51.51211624391049070937\n",
      "Iteration 4432 => Loss: 51.51191196274145056577\n",
      "Iteration 4433 => Loss: 51.51170768415249767713\n",
      "Iteration 4434 => Loss: 51.51150340814145067725\n",
      "Iteration 4435 => Loss: 51.51129913470618504334\n",
      "Iteration 4436 => Loss: 51.51109486384453362007\n",
      "Iteration 4437 => Loss: 51.51089059555432925208\n",
      "Iteration 4438 => Loss: 51.51068632983345452203\n",
      "Iteration 4439 => Loss: 51.51048206667974227457\n",
      "Iteration 4440 => Loss: 51.51027780609108219778\n",
      "Iteration 4441 => Loss: 51.51007354806536397973\n",
      "Iteration 4442 => Loss: 51.50986929260042757051\n",
      "Iteration 4443 => Loss: 51.50966503969416976361\n",
      "Iteration 4444 => Loss: 51.50946078934448024711\n",
      "Iteration 4445 => Loss: 51.50925654154923449823\n",
      "Iteration 4446 => Loss: 51.50905229630634352134\n",
      "Iteration 4447 => Loss: 51.50884805361367568821\n",
      "Iteration 4448 => Loss: 51.50864381346915621407\n",
      "Iteration 4449 => Loss: 51.50843957587069610327\n",
      "Iteration 4450 => Loss: 51.50823534081620636016\n",
      "Iteration 4451 => Loss: 51.50803110830359798911\n",
      "Iteration 4452 => Loss: 51.50782687833078909989\n",
      "Iteration 4453 => Loss: 51.50762265089571911858\n",
      "Iteration 4454 => Loss: 51.50741842599631326038\n",
      "Iteration 4455 => Loss: 51.50721420363049674052\n",
      "Iteration 4456 => Loss: 51.50700998379622319590\n",
      "Iteration 4457 => Loss: 51.50680576649141073631\n",
      "Iteration 4458 => Loss: 51.50660155171404852581\n",
      "Iteration 4459 => Loss: 51.50639733946206177961\n",
      "Iteration 4460 => Loss: 51.50619312973340413464\n",
      "Iteration 4461 => Loss: 51.50598892252607186037\n",
      "Iteration 4462 => Loss: 51.50578471783799017203\n",
      "Iteration 4463 => Loss: 51.50558051566714112823\n",
      "Iteration 4464 => Loss: 51.50537631601151389305\n",
      "Iteration 4465 => Loss: 51.50517211886907631424\n",
      "Iteration 4466 => Loss: 51.50496792423781755588\n",
      "Iteration 4467 => Loss: 51.50476373211571257116\n",
      "Iteration 4468 => Loss: 51.50455954250077184042\n",
      "Iteration 4469 => Loss: 51.50435535539097742230\n",
      "Iteration 4470 => Loss: 51.50415117078436821885\n",
      "Iteration 4471 => Loss: 51.50394698867889786698\n",
      "Iteration 4472 => Loss: 51.50374280907261947959\n",
      "Iteration 4473 => Loss: 51.50353863196350800990\n",
      "Iteration 4474 => Loss: 51.50333445734961657081\n",
      "Iteration 4475 => Loss: 51.50313028522894853722\n",
      "Iteration 4476 => Loss: 51.50292611559954281120\n",
      "Iteration 4477 => Loss: 51.50272194845942408392\n",
      "Iteration 4478 => Loss: 51.50251778380660994117\n",
      "Iteration 4479 => Loss: 51.50231362163918902297\n",
      "Iteration 4480 => Loss: 51.50210946195515759882\n",
      "Iteration 4481 => Loss: 51.50190530475259720333\n",
      "Iteration 4482 => Loss: 51.50170115002953963312\n",
      "Iteration 4483 => Loss: 51.50149699778407352824\n",
      "Iteration 4484 => Loss: 51.50129284801420226358\n",
      "Iteration 4485 => Loss: 51.50108870071805711177\n",
      "Iteration 4486 => Loss: 51.50088455589366276399\n",
      "Iteration 4487 => Loss: 51.50068041353913628200\n",
      "Iteration 4488 => Loss: 51.50047627365248814613\n",
      "Iteration 4489 => Loss: 51.50027213623185673441\n",
      "Iteration 4490 => Loss: 51.50006800127531647604\n",
      "Iteration 4491 => Loss: 51.49986386878095601105\n",
      "Iteration 4492 => Loss: 51.49965973874687108491\n",
      "Iteration 4493 => Loss: 51.49945561117117165395\n",
      "Iteration 4494 => Loss: 51.49925148605194635820\n",
      "Iteration 4495 => Loss: 51.49904736338729094314\n",
      "Iteration 4496 => Loss: 51.49884324317532957593\n",
      "Iteration 4497 => Loss: 51.49863912541419352920\n",
      "Iteration 4498 => Loss: 51.49843501010197854839\n",
      "Iteration 4499 => Loss: 51.49823089723681590613\n",
      "Iteration 4500 => Loss: 51.49802678681685819129\n",
      "Iteration 4501 => Loss: 51.49782267884020114934\n",
      "Iteration 4502 => Loss: 51.49761857330501158003\n",
      "Iteration 4503 => Loss: 51.49741447020940654511\n",
      "Iteration 4504 => Loss: 51.49721036955153863346\n",
      "Iteration 4505 => Loss: 51.49700627132954622311\n",
      "Iteration 4506 => Loss: 51.49680217554160321924\n",
      "Iteration 4507 => Loss: 51.49659808218584799988\n",
      "Iteration 4508 => Loss: 51.49639399126046157562\n",
      "Iteration 4509 => Loss: 51.49618990276358232450\n",
      "Iteration 4510 => Loss: 51.49598581669337704625\n",
      "Iteration 4511 => Loss: 51.49578173304806227861\n",
      "Iteration 4512 => Loss: 51.49557765182576929419\n",
      "Iteration 4513 => Loss: 51.49537357302469331444\n",
      "Iteration 4514 => Loss: 51.49516949664299403366\n",
      "Iteration 4515 => Loss: 51.49496542267892351674\n",
      "Iteration 4516 => Loss: 51.49476135113061303628\n",
      "Iteration 4517 => Loss: 51.49455728199627913000\n",
      "Iteration 4518 => Loss: 51.49435321527413123022\n",
      "Iteration 4519 => Loss: 51.49414915096236455838\n",
      "Iteration 4520 => Loss: 51.49394508905918144137\n",
      "Iteration 4521 => Loss: 51.49374102956278420606\n",
      "Iteration 4522 => Loss: 51.49353697247145333904\n",
      "Iteration 4523 => Loss: 51.49333291778329879662\n",
      "Iteration 4524 => Loss: 51.49312886549665080338\n",
      "Iteration 4525 => Loss: 51.49292481560965484277\n",
      "Iteration 4526 => Loss: 51.49272076812060561224\n",
      "Iteration 4527 => Loss: 51.49251672302769833323\n",
      "Iteration 4528 => Loss: 51.49231268032919928146\n",
      "Iteration 4529 => Loss: 51.49210864002330367839\n",
      "Iteration 4530 => Loss: 51.49190460210830622145\n",
      "Iteration 4531 => Loss: 51.49170056658244476466\n",
      "Iteration 4532 => Loss: 51.49149653344395005661\n",
      "Iteration 4533 => Loss: 51.49129250269110968929\n",
      "Iteration 4534 => Loss: 51.49108847432220414930\n",
      "Iteration 4535 => Loss: 51.49088444833542865808\n",
      "Iteration 4536 => Loss: 51.49068042472912054563\n",
      "Iteration 4537 => Loss: 51.49047640350151056055\n",
      "Iteration 4538 => Loss: 51.49027238465090761110\n",
      "Iteration 4539 => Loss: 51.49006836817556376218\n",
      "Iteration 4540 => Loss: 51.48986435407376660578\n",
      "Iteration 4541 => Loss: 51.48966034234381794477\n",
      "Iteration 4542 => Loss: 51.48945633298401247657\n",
      "Iteration 4543 => Loss: 51.48925232599264489863\n",
      "Iteration 4544 => Loss: 51.48904832136800280296\n",
      "Iteration 4545 => Loss: 51.48884431910838088697\n",
      "Iteration 4546 => Loss: 51.48864031921210937526\n",
      "Iteration 4547 => Loss: 51.48843632167747585981\n",
      "Iteration 4548 => Loss: 51.48823232650281767064\n",
      "Iteration 4549 => Loss: 51.48802833368643661061\n",
      "Iteration 4550 => Loss: 51.48782434322664869342\n",
      "Iteration 4551 => Loss: 51.48762035512181256536\n",
      "Iteration 4552 => Loss: 51.48741636937020160758\n",
      "Iteration 4553 => Loss: 51.48721238597020999350\n",
      "Iteration 4554 => Loss: 51.48700840492011820970\n",
      "Iteration 4555 => Loss: 51.48680442621831332417\n",
      "Iteration 4556 => Loss: 51.48660044986309713977\n",
      "Iteration 4557 => Loss: 51.48639647585283540820\n",
      "Iteration 4558 => Loss: 51.48619250418588677576\n",
      "Iteration 4559 => Loss: 51.48598853486058857243\n",
      "Iteration 4560 => Loss: 51.48578456787530654992\n",
      "Iteration 4561 => Loss: 51.48558060322839935452\n",
      "Iteration 4562 => Loss: 51.48537664091823273793\n",
      "Iteration 4563 => Loss: 51.48517268094318666272\n",
      "Iteration 4564 => Loss: 51.48496872330161266973\n",
      "Iteration 4565 => Loss: 51.48476476799188361611\n",
      "Iteration 4566 => Loss: 51.48456081501240788612\n",
      "Iteration 4567 => Loss: 51.48435686436153702061\n",
      "Iteration 4568 => Loss: 51.48415291603767229844\n",
      "Iteration 4569 => Loss: 51.48394897003921499845\n",
      "Iteration 4570 => Loss: 51.48374502636452376692\n",
      "Iteration 4571 => Loss: 51.48354108501201409354\n",
      "Iteration 4572 => Loss: 51.48333714598006594088\n",
      "Iteration 4573 => Loss: 51.48313320926713743120\n",
      "Iteration 4574 => Loss: 51.48292927487158010535\n",
      "Iteration 4575 => Loss: 51.48272534279183076933\n",
      "Iteration 4576 => Loss: 51.48252141302629780739\n",
      "Iteration 4577 => Loss: 51.48231748557340381467\n",
      "Iteration 4578 => Loss: 51.48211356043155717543\n",
      "Iteration 4579 => Loss: 51.48190963759916627396\n",
      "Iteration 4580 => Loss: 51.48170571707468923250\n",
      "Iteration 4581 => Loss: 51.48150179885657706791\n",
      "Iteration 4582 => Loss: 51.48129788294320263731\n",
      "Iteration 4583 => Loss: 51.48109396933305959010\n",
      "Iteration 4584 => Loss: 51.48089005802454920513\n",
      "Iteration 4585 => Loss: 51.48068614901613671009\n",
      "Iteration 4586 => Loss: 51.48048224230625891096\n",
      "Iteration 4587 => Loss: 51.48027833789338103543\n",
      "Iteration 4588 => Loss: 51.48007443577596831119\n",
      "Iteration 4589 => Loss: 51.47987053595241491166\n",
      "Iteration 4590 => Loss: 51.47966663842126422423\n",
      "Iteration 4591 => Loss: 51.47946274318091042232\n",
      "Iteration 4592 => Loss: 51.47925885022986847162\n",
      "Iteration 4593 => Loss: 51.47905495956661781065\n",
      "Iteration 4594 => Loss: 51.47885107118959524541\n",
      "Iteration 4595 => Loss: 51.47864718509730863616\n",
      "Iteration 4596 => Loss: 51.47844330128820189429\n",
      "Iteration 4597 => Loss: 51.47823941976078998550\n",
      "Iteration 4598 => Loss: 51.47803554051354524290\n",
      "Iteration 4599 => Loss: 51.47783166354498973760\n",
      "Iteration 4600 => Loss: 51.47762778885358869729\n",
      "Iteration 4601 => Loss: 51.47742391643783577138\n",
      "Iteration 4602 => Loss: 51.47722004629624592553\n",
      "Iteration 4603 => Loss: 51.47701617842736254715\n",
      "Iteration 4604 => Loss: 51.47681231282958691509\n",
      "Iteration 4605 => Loss: 51.47660844950154057642\n",
      "Iteration 4606 => Loss: 51.47640458844165323171\n",
      "Iteration 4607 => Loss: 51.47620072964851090092\n",
      "Iteration 4608 => Loss: 51.47599687312060723343\n",
      "Iteration 4609 => Loss: 51.47579301885642166781\n",
      "Iteration 4610 => Loss: 51.47558916685453311857\n",
      "Iteration 4611 => Loss: 51.47538531711349207853\n",
      "Iteration 4612 => Loss: 51.47518146963178509168\n",
      "Iteration 4613 => Loss: 51.47497762440794843997\n",
      "Iteration 4614 => Loss: 51.47477378144056103793\n",
      "Iteration 4615 => Loss: 51.47456994072811653496\n",
      "Iteration 4616 => Loss: 51.47436610226921516187\n",
      "Iteration 4617 => Loss: 51.47416226606232214635\n",
      "Iteration 4618 => Loss: 51.47395843210610166807\n",
      "Iteration 4619 => Loss: 51.47375460039901184928\n",
      "Iteration 4620 => Loss: 51.47355077093966713164\n",
      "Iteration 4621 => Loss: 51.47334694372661090256\n",
      "Iteration 4622 => Loss: 51.47314311875841497113\n",
      "Iteration 4623 => Loss: 51.47293929603364404102\n",
      "Iteration 4624 => Loss: 51.47273547555083439420\n",
      "Iteration 4625 => Loss: 51.47253165730864310490\n",
      "Iteration 4626 => Loss: 51.47232784130555671709\n",
      "Iteration 4627 => Loss: 51.47212402754022519957\n",
      "Iteration 4628 => Loss: 51.47192021601117772889\n",
      "Iteration 4629 => Loss: 51.47171640671703585213\n",
      "Iteration 4630 => Loss: 51.47151259965638558924\n",
      "Iteration 4631 => Loss: 51.47130879482781296019\n",
      "Iteration 4632 => Loss: 51.47110499222989687951\n",
      "Iteration 4633 => Loss: 51.47090119186128021056\n",
      "Iteration 4634 => Loss: 51.47069739372050634074\n",
      "Iteration 4635 => Loss: 51.47049359780622523886\n",
      "Iteration 4636 => Loss: 51.47028980411704424114\n",
      "Iteration 4637 => Loss: 51.47008601265155647297\n",
      "Iteration 4638 => Loss: 51.46988222340838348146\n",
      "Iteration 4639 => Loss: 51.46967843638611128654\n",
      "Iteration 4640 => Loss: 51.46947465158342538416\n",
      "Iteration 4641 => Loss: 51.46927086899887626714\n",
      "Iteration 4642 => Loss: 51.46906708863114943142\n",
      "Iteration 4643 => Loss: 51.46886331047883800238\n",
      "Iteration 4644 => Loss: 51.46865953454059905425\n",
      "Iteration 4645 => Loss: 51.46845576081503281785\n",
      "Iteration 4646 => Loss: 51.46825198930081057824\n",
      "Iteration 4647 => Loss: 51.46804821999653256626\n",
      "Iteration 4648 => Loss: 51.46784445290091269953\n",
      "Iteration 4649 => Loss: 51.46764068801252989260\n",
      "Iteration 4650 => Loss: 51.46743692533006253598\n",
      "Iteration 4651 => Loss: 51.46723316485216059846\n",
      "Iteration 4652 => Loss: 51.46702940657748115427\n",
      "Iteration 4653 => Loss: 51.46682565050467417223\n",
      "Iteration 4654 => Loss: 51.46662189663241093740\n",
      "Iteration 4655 => Loss: 51.46641814495933431317\n",
      "Iteration 4656 => Loss: 51.46621439548414400633\n",
      "Iteration 4657 => Loss: 51.46601064820551130197\n",
      "Iteration 4658 => Loss: 51.46580690312206485260\n",
      "Iteration 4659 => Loss: 51.46560316023252568129\n",
      "Iteration 4660 => Loss: 51.46539941953553665144\n",
      "Iteration 4661 => Loss: 51.46519568102980457525\n",
      "Iteration 4662 => Loss: 51.46499194471399363238\n",
      "Iteration 4663 => Loss: 51.46478821058682484590\n",
      "Iteration 4664 => Loss: 51.46458447864696239549\n",
      "Iteration 4665 => Loss: 51.46438074889311309335\n",
      "Iteration 4666 => Loss: 51.46417702132393401371\n",
      "Iteration 4667 => Loss: 51.46397329593817460136\n",
      "Iteration 4668 => Loss: 51.46376957273452035224\n",
      "Iteration 4669 => Loss: 51.46356585171165676229\n",
      "Iteration 4670 => Loss: 51.46336213286829774916\n",
      "Iteration 4671 => Loss: 51.46315841620317854677\n",
      "Iteration 4672 => Loss: 51.46295470171499886192\n",
      "Iteration 4673 => Loss: 51.46275098940243708512\n",
      "Iteration 4674 => Loss: 51.46254727926426397744\n",
      "Iteration 4675 => Loss: 51.46234357129917214024\n",
      "Iteration 4676 => Loss: 51.46213986550591101832\n",
      "Iteration 4677 => Loss: 51.46193616188317321303\n",
      "Iteration 4678 => Loss: 51.46173246042969395830\n",
      "Iteration 4679 => Loss: 51.46152876114422269893\n",
      "Iteration 4680 => Loss: 51.46132506402548045799\n",
      "Iteration 4681 => Loss: 51.46112136907224510196\n",
      "Iteration 4682 => Loss: 51.46091767628320212680\n",
      "Iteration 4683 => Loss: 51.46071398565710097728\n",
      "Iteration 4684 => Loss: 51.46051029719270530904\n",
      "Iteration 4685 => Loss: 51.46030661088876456688\n",
      "Iteration 4686 => Loss: 51.46010292674403530100\n",
      "Iteration 4687 => Loss: 51.45989924475727406161\n",
      "Iteration 4688 => Loss: 51.45969556492720187180\n",
      "Iteration 4689 => Loss: 51.45949188725258949262\n",
      "Iteration 4690 => Loss: 51.45928821173222189600\n",
      "Iteration 4691 => Loss: 51.45908453836486273758\n",
      "Iteration 4692 => Loss: 51.45888086714925435672\n",
      "Iteration 4693 => Loss: 51.45867719808420304162\n",
      "Iteration 4694 => Loss: 51.45847353116845113163\n",
      "Iteration 4695 => Loss: 51.45826986640077649326\n",
      "Iteration 4696 => Loss: 51.45806620377996409843\n",
      "Iteration 4697 => Loss: 51.45786254330481312991\n",
      "Iteration 4698 => Loss: 51.45765888497406592705\n",
      "Iteration 4699 => Loss: 51.45745522878653588350\n",
      "Iteration 4700 => Loss: 51.45725157474102928745\n",
      "Iteration 4701 => Loss: 51.45704792283628847827\n",
      "Iteration 4702 => Loss: 51.45684427307112684957\n",
      "Iteration 4703 => Loss: 51.45664062544437200586\n",
      "Iteration 4704 => Loss: 51.45643697995479470819\n",
      "Iteration 4705 => Loss: 51.45623333660120124478\n",
      "Iteration 4706 => Loss: 51.45602969538237658753\n",
      "Iteration 4707 => Loss: 51.45582605629716965723\n",
      "Iteration 4708 => Loss: 51.45562241934435832036\n",
      "Iteration 4709 => Loss: 51.45541878452277728684\n",
      "Iteration 4710 => Loss: 51.45521515183120442316\n",
      "Iteration 4711 => Loss: 51.45501152126848154467\n",
      "Iteration 4712 => Loss: 51.45480789283344336127\n",
      "Iteration 4713 => Loss: 51.45460426652488905575\n",
      "Iteration 4714 => Loss: 51.45440064234164623258\n",
      "Iteration 4715 => Loss: 51.45419702028255670712\n",
      "Iteration 4716 => Loss: 51.45399340034641966213\n",
      "Iteration 4717 => Loss: 51.45378978253211244009\n",
      "Iteration 4718 => Loss: 51.45358616683842001294\n",
      "Iteration 4719 => Loss: 51.45338255326422682856\n",
      "Iteration 4720 => Loss: 51.45317894180835338602\n",
      "Iteration 4721 => Loss: 51.45297533246961307896\n",
      "Iteration 4722 => Loss: 51.45277172524690456612\n",
      "Iteration 4723 => Loss: 51.45256812013904124115\n",
      "Iteration 4724 => Loss: 51.45236451714487202480\n",
      "Iteration 4725 => Loss: 51.45216091626327425956\n",
      "Iteration 4726 => Loss: 51.45195731749310397163\n",
      "Iteration 4727 => Loss: 51.45175372083316744920\n",
      "Iteration 4728 => Loss: 51.45155012628239177275\n",
      "Iteration 4729 => Loss: 51.45134653383958323047\n",
      "Iteration 4730 => Loss: 51.45114294350364758657\n",
      "Iteration 4731 => Loss: 51.45093935527342665637\n",
      "Iteration 4732 => Loss: 51.45073576914779778235\n",
      "Iteration 4733 => Loss: 51.45053218512563830700\n",
      "Iteration 4734 => Loss: 51.45032860320583267821\n",
      "Iteration 4735 => Loss: 51.45012502338721560591\n",
      "Iteration 4736 => Loss: 51.44992144566873548683\n",
      "Iteration 4737 => Loss: 51.44971787004922703090\n",
      "Iteration 4738 => Loss: 51.44951429652757468602\n",
      "Iteration 4739 => Loss: 51.44931072510265579467\n",
      "Iteration 4740 => Loss: 51.44910715577341164817\n",
      "Iteration 4741 => Loss: 51.44890358853868406186\n",
      "Iteration 4742 => Loss: 51.44870002339740011621\n",
      "Iteration 4743 => Loss: 51.44849646034843004827\n",
      "Iteration 4744 => Loss: 51.44829289939067251680\n",
      "Iteration 4745 => Loss: 51.44808934052305460227\n",
      "Iteration 4746 => Loss: 51.44788578374446075259\n",
      "Iteration 4747 => Loss: 51.44768222905379673193\n",
      "Iteration 4748 => Loss: 51.44747867644997540992\n",
      "Iteration 4749 => Loss: 51.44727512593192386703\n",
      "Iteration 4750 => Loss: 51.44707157749851944573\n",
      "Iteration 4751 => Loss: 51.44686803114870343734\n",
      "Iteration 4752 => Loss: 51.44666448688139581691\n",
      "Iteration 4753 => Loss: 51.44646094469551655948\n",
      "Iteration 4754 => Loss: 51.44625740458996432380\n",
      "Iteration 4755 => Loss: 51.44605386656368750664\n",
      "Iteration 4756 => Loss: 51.44585033061561318846\n",
      "Iteration 4757 => Loss: 51.44564679674464713344\n",
      "Iteration 4758 => Loss: 51.44544326494975194919\n",
      "Iteration 4759 => Loss: 51.44523973522984050533\n",
      "Iteration 4760 => Loss: 51.44503620758386830403\n",
      "Iteration 4761 => Loss: 51.44483268201076242576\n",
      "Iteration 4762 => Loss: 51.44462915850944995100\n",
      "Iteration 4763 => Loss: 51.44442563707890769820\n",
      "Iteration 4764 => Loss: 51.44422211771804853697\n",
      "Iteration 4765 => Loss: 51.44401860042583507493\n",
      "Iteration 4766 => Loss: 51.44381508520124413053\n",
      "Iteration 4767 => Loss: 51.44361157204317436253\n",
      "Iteration 4768 => Loss: 51.44340806095061680026\n",
      "Iteration 4769 => Loss: 51.44320455192251984045\n",
      "Iteration 4770 => Loss: 51.44300104495783898528\n",
      "Iteration 4771 => Loss: 51.44279754005554394780\n",
      "Iteration 4772 => Loss: 51.44259403721458312475\n",
      "Iteration 4773 => Loss: 51.44239053643392622917\n",
      "Iteration 4774 => Loss: 51.44218703771257850121\n",
      "Iteration 4775 => Loss: 51.44198354104945281051\n",
      "Iteration 4776 => Loss: 51.44178004644356150266\n",
      "Iteration 4777 => Loss: 51.44157655389389560696\n",
      "Iteration 4778 => Loss: 51.44137306339936799304\n",
      "Iteration 4779 => Loss: 51.44116957495901232278\n",
      "Iteration 4780 => Loss: 51.44096608857179830920\n",
      "Iteration 4781 => Loss: 51.44076260423669566535\n",
      "Iteration 4782 => Loss: 51.44055912195269542053\n",
      "Iteration 4783 => Loss: 51.44035564171879570949\n",
      "Iteration 4784 => Loss: 51.44015216353398045612\n",
      "Iteration 4785 => Loss: 51.43994868739724779516\n",
      "Iteration 4786 => Loss: 51.43974521330757454507\n",
      "Iteration 4787 => Loss: 51.43954174126398015687\n",
      "Iteration 4788 => Loss: 51.43933827126547697617\n",
      "Iteration 4789 => Loss: 51.43913480331100629428\n",
      "Iteration 4790 => Loss: 51.43893133739962308937\n",
      "Iteration 4791 => Loss: 51.43872787353031839075\n",
      "Iteration 4792 => Loss: 51.43852441170209743859\n",
      "Iteration 4793 => Loss: 51.43832095191399389478\n",
      "Iteration 4794 => Loss: 51.43811749416499168319\n",
      "Iteration 4795 => Loss: 51.43791403845409604401\n",
      "Iteration 4796 => Loss: 51.43771058478035484995\n",
      "Iteration 4797 => Loss: 51.43750713314277334121\n",
      "Iteration 4798 => Loss: 51.43730368354037096879\n",
      "Iteration 4799 => Loss: 51.43710023597216718372\n",
      "Iteration 4800 => Loss: 51.43689679043719564788\n",
      "Iteration 4801 => Loss: 51.43669334693447581230\n",
      "Iteration 4802 => Loss: 51.43648990546304133886\n",
      "Iteration 4803 => Loss: 51.43628646602192588944\n",
      "Iteration 4804 => Loss: 51.43608302861014891505\n",
      "Iteration 4805 => Loss: 51.43587959322674407758\n",
      "Iteration 4806 => Loss: 51.43567615987076635520\n",
      "Iteration 4807 => Loss: 51.43547272854127072605\n",
      "Iteration 4808 => Loss: 51.43526929923724111404\n",
      "Iteration 4809 => Loss: 51.43506587195778223531\n",
      "Iteration 4810 => Loss: 51.43486244670190643546\n",
      "Iteration 4811 => Loss: 51.43465902346866158723\n",
      "Iteration 4812 => Loss: 51.43445560225712398505\n",
      "Iteration 4813 => Loss: 51.43425218306631307996\n",
      "Iteration 4814 => Loss: 51.43404876589530516640\n",
      "Iteration 4815 => Loss: 51.43384535074315522252\n",
      "Iteration 4816 => Loss: 51.43364193760891112106\n",
      "Iteration 4817 => Loss: 51.43343852649161362933\n",
      "Iteration 4818 => Loss: 51.43323511739037456891\n",
      "Iteration 4819 => Loss: 51.43303171030421339083\n",
      "Iteration 4820 => Loss: 51.43282830523221349495\n",
      "Iteration 4821 => Loss: 51.43262490217345117571\n",
      "Iteration 4822 => Loss: 51.43242150112699562214\n",
      "Iteration 4823 => Loss: 51.43221810209188760155\n",
      "Iteration 4824 => Loss: 51.43201470506725314635\n",
      "Iteration 4825 => Loss: 51.43181131005213302387\n",
      "Iteration 4826 => Loss: 51.43160791704561773940\n",
      "Iteration 4827 => Loss: 51.43140452604679069282\n",
      "Iteration 4828 => Loss: 51.43120113705471396770\n",
      "Iteration 4829 => Loss: 51.43099775006847096392\n",
      "Iteration 4830 => Loss: 51.43079436508718060850\n",
      "Iteration 4831 => Loss: 51.43059098210991919586\n",
      "Iteration 4832 => Loss: 51.43038760113576302047\n",
      "Iteration 4833 => Loss: 51.43018422216382390388\n",
      "Iteration 4834 => Loss: 51.42998084519315682428\n",
      "Iteration 4835 => Loss: 51.42977747022288781409\n",
      "Iteration 4836 => Loss: 51.42957409725212869489\n",
      "Iteration 4837 => Loss: 51.42937072627995576113\n",
      "Iteration 4838 => Loss: 51.42916735730548793981\n",
      "Iteration 4839 => Loss: 51.42896399032780152538\n",
      "Iteration 4840 => Loss: 51.42876062534600833942\n",
      "Iteration 4841 => Loss: 51.42855726235924862522\n",
      "Iteration 4842 => Loss: 51.42835390136661288807\n",
      "Iteration 4843 => Loss: 51.42815054236720584413\n",
      "Iteration 4844 => Loss: 51.42794718536013931498\n",
      "Iteration 4845 => Loss: 51.42774383034453222763\n",
      "Iteration 4846 => Loss: 51.42754047731953193079\n",
      "Iteration 4847 => Loss: 51.42733712628420050805\n",
      "Iteration 4848 => Loss: 51.42713377723770662442\n",
      "Iteration 4849 => Loss: 51.42693043017913367976\n",
      "Iteration 4850 => Loss: 51.42672708510764323364\n",
      "Iteration 4851 => Loss: 51.42652374202236131850\n",
      "Iteration 4852 => Loss: 51.42632040092238554507\n",
      "Iteration 4853 => Loss: 51.42611706180685615664\n",
      "Iteration 4854 => Loss: 51.42591372467492050191\n",
      "Iteration 4855 => Loss: 51.42571038952571882419\n",
      "Iteration 4856 => Loss: 51.42550705635834873419\n",
      "Iteration 4857 => Loss: 51.42530372517199310778\n",
      "Iteration 4858 => Loss: 51.42510039596576376653\n",
      "Iteration 4859 => Loss: 51.42489706873882227001\n",
      "Iteration 4860 => Loss: 51.42469374349029465066\n",
      "Iteration 4861 => Loss: 51.42449042021931404634\n",
      "Iteration 4862 => Loss: 51.42428709892507043833\n",
      "Iteration 4863 => Loss: 51.42408377960668275364\n",
      "Iteration 4864 => Loss: 51.42388046226331255184\n",
      "Iteration 4865 => Loss: 51.42367714689408586537\n",
      "Iteration 4866 => Loss: 51.42347383349821399179\n",
      "Iteration 4867 => Loss: 51.42327052207480875268\n",
      "Iteration 4868 => Loss: 51.42306721262303170761\n",
      "Iteration 4869 => Loss: 51.42286390514204441615\n",
      "Iteration 4870 => Loss: 51.42266059963101554331\n",
      "Iteration 4871 => Loss: 51.42245729608913507036\n",
      "Iteration 4872 => Loss: 51.42225399451551481889\n",
      "Iteration 4873 => Loss: 51.42205069490935187559\n",
      "Iteration 4874 => Loss: 51.42184739726980780006\n",
      "Iteration 4875 => Loss: 51.42164410159608678441\n",
      "Iteration 4876 => Loss: 51.42144080788730065024\n",
      "Iteration 4877 => Loss: 51.42123751614268201138\n",
      "Iteration 4878 => Loss: 51.42103422636134979484\n",
      "Iteration 4879 => Loss: 51.42083093854255082533\n",
      "Iteration 4880 => Loss: 51.42062765268541113528\n",
      "Iteration 4881 => Loss: 51.42042436878914202225\n",
      "Iteration 4882 => Loss: 51.42022108685289083496\n",
      "Iteration 4883 => Loss: 51.42001780687588308183\n",
      "Iteration 4884 => Loss: 51.41981452885728032243\n",
      "Iteration 4885 => Loss: 51.41961125279627964346\n",
      "Iteration 4886 => Loss: 51.41940797869206392079\n",
      "Iteration 4887 => Loss: 51.41920470654383734654\n",
      "Iteration 4888 => Loss: 51.41900143635081121829\n",
      "Iteration 4889 => Loss: 51.41879816811213288474\n",
      "Iteration 4890 => Loss: 51.41859490182704206518\n",
      "Iteration 4891 => Loss: 51.41839163749472163545\n",
      "Iteration 4892 => Loss: 51.41818837511436157683\n",
      "Iteration 4893 => Loss: 51.41798511468516608147\n",
      "Iteration 4894 => Loss: 51.41778185620638907949\n",
      "Iteration 4895 => Loss: 51.41757859967716370875\n",
      "Iteration 4896 => Loss: 51.41737534509676521566\n",
      "Iteration 4897 => Loss: 51.41717209246431963265\n",
      "Iteration 4898 => Loss: 51.41696884177911641700\n",
      "Iteration 4899 => Loss: 51.41676559304035265541\n",
      "Iteration 4900 => Loss: 51.41656234624720411830\n",
      "Iteration 4901 => Loss: 51.41635910139891763038\n",
      "Iteration 4902 => Loss: 51.41615585849471159463\n",
      "Iteration 4903 => Loss: 51.41595261753379730862\n",
      "Iteration 4904 => Loss: 51.41574937851539317535\n",
      "Iteration 4905 => Loss: 51.41554614143873891408\n",
      "Iteration 4906 => Loss: 51.41534290630304582237\n",
      "Iteration 4907 => Loss: 51.41513967310753230322\n",
      "Iteration 4908 => Loss: 51.41493644185145939218\n",
      "Iteration 4909 => Loss: 51.41473321253400996511\n",
      "Iteration 4910 => Loss: 51.41452998515445926841\n",
      "Iteration 4911 => Loss: 51.41432675971201149423\n",
      "Iteration 4912 => Loss: 51.41412353620588504555\n",
      "Iteration 4913 => Loss: 51.41392031463537648506\n",
      "Iteration 4914 => Loss: 51.41371709499966868862\n",
      "Iteration 4915 => Loss: 51.41351387729803690263\n",
      "Iteration 4916 => Loss: 51.41331066152968531924\n",
      "Iteration 4917 => Loss: 51.41310744769390339570\n",
      "Iteration 4918 => Loss: 51.41290423578990242959\n",
      "Iteration 4919 => Loss: 51.41270102581693635102\n",
      "Iteration 4920 => Loss: 51.41249781777425198470\n",
      "Iteration 4921 => Loss: 51.41229461166108904990\n",
      "Iteration 4922 => Loss: 51.41209140747670858218\n",
      "Iteration 4923 => Loss: 51.41188820522037872252\n",
      "Iteration 4924 => Loss: 51.41168500489133208475\n",
      "Iteration 4925 => Loss: 51.41148180648882970445\n",
      "Iteration 4926 => Loss: 51.41127861001214682801\n",
      "Iteration 4927 => Loss: 51.41107541546051606929\n",
      "Iteration 4928 => Loss: 51.41087222283319135840\n",
      "Iteration 4929 => Loss: 51.41066903212946925805\n",
      "Iteration 4930 => Loss: 51.41046584334858948750\n",
      "Iteration 4931 => Loss: 51.41026265648984150403\n",
      "Iteration 4932 => Loss: 51.41005947155245081603\n",
      "Iteration 4933 => Loss: 51.40985628853573530250\n",
      "Iteration 4934 => Loss: 51.40965310743892047185\n",
      "Iteration 4935 => Loss: 51.40944992826128157049\n",
      "Iteration 4936 => Loss: 51.40924675100214358281\n",
      "Iteration 4937 => Loss: 51.40904357566074622810\n",
      "Iteration 4938 => Loss: 51.40884040223631501476\n",
      "Iteration 4939 => Loss: 51.40863723072822466520\n",
      "Iteration 4940 => Loss: 51.40843406113569358240\n",
      "Iteration 4941 => Loss: 51.40823089345801832906\n",
      "Iteration 4942 => Loss: 51.40802772769448125700\n",
      "Iteration 4943 => Loss: 51.40782456384437892893\n",
      "Iteration 4944 => Loss: 51.40762140190696527497\n",
      "Iteration 4945 => Loss: 51.40741824188155817410\n",
      "Iteration 4946 => Loss: 51.40721508376745418900\n",
      "Iteration 4947 => Loss: 51.40701192756389303895\n",
      "Iteration 4948 => Loss: 51.40680877327020681378\n",
      "Iteration 4949 => Loss: 51.40660562088564944361\n",
      "Iteration 4950 => Loss: 51.40640247040958143998\n",
      "Iteration 4951 => Loss: 51.40619932184125673302\n",
      "Iteration 4952 => Loss: 51.40599617517997899085\n",
      "Iteration 4953 => Loss: 51.40579303042505898702\n",
      "Iteration 4954 => Loss: 51.40558988757577907336\n",
      "Iteration 4955 => Loss: 51.40538674663143581256\n",
      "Iteration 4956 => Loss: 51.40518360759137550531\n",
      "Iteration 4957 => Loss: 51.40498047045486629258\n",
      "Iteration 4958 => Loss: 51.40477733522121184251\n",
      "Iteration 4959 => Loss: 51.40457420188973713948\n",
      "Iteration 4960 => Loss: 51.40437107045974585162\n",
      "Iteration 4961 => Loss: 51.40416794093056296333\n",
      "Iteration 4962 => Loss: 51.40396481330148503730\n",
      "Iteration 4963 => Loss: 51.40376168757182995250\n",
      "Iteration 4964 => Loss: 51.40355856374090848249\n",
      "Iteration 4965 => Loss: 51.40335544180806692793\n",
      "Iteration 4966 => Loss: 51.40315232177258053525\n",
      "Iteration 4967 => Loss: 51.40294920363380981598\n",
      "Iteration 4968 => Loss: 51.40274608739103712196\n",
      "Iteration 4969 => Loss: 51.40254297304363007015\n",
      "Iteration 4970 => Loss: 51.40233986059087811782\n",
      "Iteration 4971 => Loss: 51.40213675003211335479\n",
      "Iteration 4972 => Loss: 51.40193364136667497633\n",
      "Iteration 4973 => Loss: 51.40173053459387375597\n",
      "Iteration 4974 => Loss: 51.40152742971305599440\n",
      "Iteration 4975 => Loss: 51.40132432672356088688\n",
      "Iteration 4976 => Loss: 51.40112122562469920695\n",
      "Iteration 4977 => Loss: 51.40091812641581725529\n",
      "Iteration 4978 => Loss: 51.40071502909625422717\n",
      "Iteration 4979 => Loss: 51.40051193366534221241\n",
      "Iteration 4980 => Loss: 51.40030884012244882797\n",
      "Iteration 4981 => Loss: 51.40010574846683510941\n",
      "Iteration 4982 => Loss: 51.39990265869793262254\n",
      "Iteration 4983 => Loss: 51.39969957081502371921\n",
      "Iteration 4984 => Loss: 51.39949648481749022721\n",
      "Iteration 4985 => Loss: 51.39929340070469265811\n",
      "Iteration 4986 => Loss: 51.39909031847592046915\n",
      "Iteration 4987 => Loss: 51.39888723813054127731\n",
      "Iteration 4988 => Loss: 51.39868415966794401584\n",
      "Iteration 4989 => Loss: 51.39848108308744656370\n",
      "Iteration 4990 => Loss: 51.39827800838838811615\n",
      "Iteration 4991 => Loss: 51.39807493557017892272\n",
      "Iteration 4992 => Loss: 51.39787186463212265153\n",
      "Iteration 4993 => Loss: 51.39766879557360113040\n",
      "Iteration 4994 => Loss: 51.39746572839396066001\n",
      "Iteration 4995 => Loss: 51.39726266309255464648\n",
      "Iteration 4996 => Loss: 51.39705959966877912848\n",
      "Iteration 4997 => Loss: 51.39685653812195909040\n",
      "Iteration 4998 => Loss: 51.39665347845149057093\n",
      "Iteration 4999 => Loss: 51.39645042065669144904\n",
      "Iteration 5000 => Loss: 51.39624736473697907968\n",
      "Iteration 5001 => Loss: 51.39604431069169265811\n",
      "Iteration 5002 => Loss: 51.39584125852022111758\n",
      "Iteration 5003 => Loss: 51.39563820822193207505\n",
      "Iteration 5004 => Loss: 51.39543515979617183120\n",
      "Iteration 5005 => Loss: 51.39523211324233642472\n",
      "Iteration 5006 => Loss: 51.39502906855981478884\n",
      "Iteration 5007 => Loss: 51.39482602574796032968\n",
      "Iteration 5008 => Loss: 51.39462298480614066420\n",
      "Iteration 5009 => Loss: 51.39441994573376604194\n",
      "Iteration 5010 => Loss: 51.39421690853021118528\n",
      "Iteration 5011 => Loss: 51.39401387319483660576\n",
      "Iteration 5012 => Loss: 51.39381083972702413121\n",
      "Iteration 5013 => Loss: 51.39360780812619822200\n",
      "Iteration 5014 => Loss: 51.39340477839168386254\n",
      "Iteration 5015 => Loss: 51.39320175052291261864\n",
      "Iteration 5016 => Loss: 51.39299872451928052897\n",
      "Iteration 5017 => Loss: 51.39279570038013389421\n",
      "Iteration 5018 => Loss: 51.39259267810491138562\n",
      "Iteration 5019 => Loss: 51.39238965769295930386\n",
      "Iteration 5020 => Loss: 51.39218663914372342560\n",
      "Iteration 5021 => Loss: 51.39198362245653584068\n",
      "Iteration 5022 => Loss: 51.39178060763082811491\n",
      "Iteration 5023 => Loss: 51.39157759466603181409\n",
      "Iteration 5024 => Loss: 51.39137458356145060634\n",
      "Iteration 5025 => Loss: 51.39117157431658000633\n",
      "Iteration 5026 => Loss: 51.39096856693078763101\n",
      "Iteration 5027 => Loss: 51.39076556140346951906\n",
      "Iteration 5028 => Loss: 51.39056255773402170917\n",
      "Iteration 5029 => Loss: 51.39035955592185445084\n",
      "Iteration 5030 => Loss: 51.39015655596642062619\n",
      "Iteration 5031 => Loss: 51.38995355786704521961\n",
      "Iteration 5032 => Loss: 51.38975056162320242947\n",
      "Iteration 5033 => Loss: 51.38954756723426697818\n",
      "Iteration 5034 => Loss: 51.38934457469966332610\n",
      "Iteration 5035 => Loss: 51.38914158401880172278\n",
      "Iteration 5036 => Loss: 51.38893859519109952316\n",
      "Iteration 5037 => Loss: 51.38873560821597408221\n",
      "Iteration 5038 => Loss: 51.38853262309283564946\n",
      "Iteration 5039 => Loss: 51.38832963982112289614\n",
      "Iteration 5040 => Loss: 51.38812665840021054464\n",
      "Iteration 5041 => Loss: 51.38792367882953726621\n",
      "Iteration 5042 => Loss: 51.38772070110855594294\n",
      "Iteration 5043 => Loss: 51.38751772523666261350\n",
      "Iteration 5044 => Loss: 51.38731475121327463285\n",
      "Iteration 5045 => Loss: 51.38711177903784488308\n",
      "Iteration 5046 => Loss: 51.38690880870976940287\n",
      "Iteration 5047 => Loss: 51.38670584022849396888\n",
      "Iteration 5048 => Loss: 51.38650287359345014693\n",
      "Iteration 5049 => Loss: 51.38629990880404108111\n",
      "Iteration 5050 => Loss: 51.38609694585973386438\n",
      "Iteration 5051 => Loss: 51.38589398475993164084\n",
      "Iteration 5052 => Loss: 51.38569102550408018715\n",
      "Iteration 5053 => Loss: 51.38548806809161817455\n",
      "Iteration 5054 => Loss: 51.38528511252197716885\n",
      "Iteration 5055 => Loss: 51.38508215879460294673\n",
      "Iteration 5056 => Loss: 51.38487920690892707398\n",
      "Iteration 5057 => Loss: 51.38467625686438111643\n",
      "Iteration 5058 => Loss: 51.38447330866041795616\n",
      "Iteration 5059 => Loss: 51.38427036229648336985\n",
      "Iteration 5060 => Loss: 51.38406741777200892329\n",
      "Iteration 5061 => Loss: 51.38386447508644749860\n",
      "Iteration 5062 => Loss: 51.38366153423923776700\n",
      "Iteration 5063 => Loss: 51.38345859522984682144\n",
      "Iteration 5064 => Loss: 51.38325565805770622774\n",
      "Iteration 5065 => Loss: 51.38305272272224044627\n",
      "Iteration 5066 => Loss: 51.38284978922293078085\n",
      "Iteration 5067 => Loss: 51.38264685755923011357\n",
      "Iteration 5068 => Loss: 51.38244392773059843194\n",
      "Iteration 5069 => Loss: 51.38224099973646730177\n",
      "Iteration 5070 => Loss: 51.38203807357628960517\n",
      "Iteration 5071 => Loss: 51.38183514924956085679\n",
      "Iteration 5072 => Loss: 51.38163222675569130615\n",
      "Iteration 5073 => Loss: 51.38142930609415515164\n",
      "Iteration 5074 => Loss: 51.38122638726441948620\n",
      "Iteration 5075 => Loss: 51.38102347026597982449\n",
      "Iteration 5076 => Loss: 51.38082055509820378347\n",
      "Iteration 5077 => Loss: 51.38061764176065082665\n",
      "Iteration 5078 => Loss: 51.38041473025271699271\n",
      "Iteration 5079 => Loss: 51.38021182057391200715\n",
      "Iteration 5080 => Loss: 51.38000891272371717378\n",
      "Iteration 5081 => Loss: 51.37980600670152853127\n",
      "Iteration 5082 => Loss: 51.37960310250687712141\n",
      "Iteration 5083 => Loss: 51.37940020013922293174\n",
      "Iteration 5084 => Loss: 51.37919729959803305519\n",
      "Iteration 5085 => Loss: 51.37899440088274616301\n",
      "Iteration 5086 => Loss: 51.37879150399288619155\n",
      "Iteration 5087 => Loss: 51.37858860892790602293\n",
      "Iteration 5088 => Loss: 51.37838571568728696093\n",
      "Iteration 5089 => Loss: 51.37818282427048188765\n",
      "Iteration 5090 => Loss: 51.37797993467700052861\n",
      "Iteration 5091 => Loss: 51.37777704690630287132\n",
      "Iteration 5092 => Loss: 51.37757416095790574673\n",
      "Iteration 5093 => Loss: 51.37737127683122650978\n",
      "Iteration 5094 => Loss: 51.37716839452581041314\n",
      "Iteration 5095 => Loss: 51.37696551404109612804\n",
      "Iteration 5096 => Loss: 51.37676263537659337999\n",
      "Iteration 5097 => Loss: 51.37655975853176926194\n",
      "Iteration 5098 => Loss: 51.37635688350614060482\n",
      "Iteration 5099 => Loss: 51.37615401029915318531\n",
      "Iteration 5100 => Loss: 51.37595113891035936149\n",
      "Iteration 5101 => Loss: 51.37574826933916227745\n",
      "Iteration 5102 => Loss: 51.37554540158512850212\n",
      "Iteration 5103 => Loss: 51.37534253564771802303\n",
      "Iteration 5104 => Loss: 51.37513967152642635483\n",
      "Iteration 5105 => Loss: 51.37493680922077743389\n",
      "Iteration 5106 => Loss: 51.37473394873020993145\n",
      "Iteration 5107 => Loss: 51.37453109005425488931\n",
      "Iteration 5108 => Loss: 51.37432823319241492754\n",
      "Iteration 5109 => Loss: 51.37412537814417845539\n",
      "Iteration 5110 => Loss: 51.37392252490902677664\n",
      "Iteration 5111 => Loss: 51.37371967348651935481\n",
      "Iteration 5112 => Loss: 51.37351682387609486113\n",
      "Iteration 5113 => Loss: 51.37331397607729144283\n",
      "Iteration 5114 => Loss: 51.37311113008959750914\n",
      "Iteration 5115 => Loss: 51.37290828591254410185\n",
      "Iteration 5116 => Loss: 51.37270544354559831390\n",
      "Iteration 5117 => Loss: 51.37250260298828408168\n",
      "Iteration 5118 => Loss: 51.37229976424013955238\n",
      "Iteration 5119 => Loss: 51.37209692730062471355\n",
      "Iteration 5120 => Loss: 51.37189409216929902868\n",
      "Iteration 5121 => Loss: 51.37169125884562248530\n",
      "Iteration 5122 => Loss: 51.37148842732915454690\n",
      "Iteration 5123 => Loss: 51.37128559761937651729\n",
      "Iteration 5124 => Loss: 51.37108276971581233283\n",
      "Iteration 5125 => Loss: 51.37087994361798592990\n",
      "Iteration 5126 => Loss: 51.37067711932542124487\n",
      "Iteration 5127 => Loss: 51.37047429683760668695\n",
      "Iteration 5128 => Loss: 51.37027147615407329795\n",
      "Iteration 5129 => Loss: 51.37006865727437343594\n",
      "Iteration 5130 => Loss: 51.36986584019796708844\n",
      "Iteration 5131 => Loss: 51.36966302492444924610\n",
      "Iteration 5132 => Loss: 51.36946021145325858015\n",
      "Iteration 5133 => Loss: 51.36925739978397587038\n",
      "Iteration 5134 => Loss: 51.36905458991615347486\n",
      "Iteration 5135 => Loss: 51.36885178184923006484\n",
      "Iteration 5136 => Loss: 51.36864897558280773637\n",
      "Iteration 5137 => Loss: 51.36844617111637489870\n",
      "Iteration 5138 => Loss: 51.36824336844947680447\n",
      "Iteration 5139 => Loss: 51.36804056758164449548\n",
      "Iteration 5140 => Loss: 51.36783776851238059180\n",
      "Iteration 5141 => Loss: 51.36763497124125876780\n",
      "Iteration 5142 => Loss: 51.36743217576780295985\n",
      "Iteration 5143 => Loss: 51.36722938209152999889\n",
      "Iteration 5144 => Loss: 51.36702659021198513756\n",
      "Iteration 5145 => Loss: 51.36682380012870652308\n",
      "Iteration 5146 => Loss: 51.36662101184122519726\n",
      "Iteration 5147 => Loss: 51.36641822534907930731\n",
      "Iteration 5148 => Loss: 51.36621544065179278959\n",
      "Iteration 5149 => Loss: 51.36601265774894642391\n",
      "Iteration 5150 => Loss: 51.36580987664006414661\n",
      "Iteration 5151 => Loss: 51.36560709732465568322\n",
      "Iteration 5152 => Loss: 51.36540431980230891895\n",
      "Iteration 5153 => Loss: 51.36520154407253357931\n",
      "Iteration 5154 => Loss: 51.36499877013490333866\n",
      "Iteration 5155 => Loss: 51.36479599798892081708\n",
      "Iteration 5156 => Loss: 51.36459322763421653235\n",
      "Iteration 5157 => Loss: 51.36439045907022205029\n",
      "Iteration 5158 => Loss: 51.36418769229658920494\n",
      "Iteration 5159 => Loss: 51.36398492731282772183\n",
      "Iteration 5160 => Loss: 51.36378216411845443190\n",
      "Iteration 5161 => Loss: 51.36357940271309274749\n",
      "Iteration 5162 => Loss: 51.36337664309623107783\n",
      "Iteration 5163 => Loss: 51.36317388526743599186\n",
      "Iteration 5164 => Loss: 51.36297112922629537479\n",
      "Iteration 5165 => Loss: 51.36276837497233316299\n",
      "Iteration 5166 => Loss: 51.36256562250513724166\n",
      "Iteration 5167 => Loss: 51.36236287182422444175\n",
      "Iteration 5168 => Loss: 51.36216012292916133219\n",
      "Iteration 5169 => Loss: 51.36195737581955000906\n",
      "Iteration 5170 => Loss: 51.36175463049488598699\n",
      "Iteration 5171 => Loss: 51.36155188695476425664\n",
      "Iteration 5172 => Loss: 51.36134914519878691408\n",
      "Iteration 5173 => Loss: 51.36114640522642105225\n",
      "Iteration 5174 => Loss: 51.36094366703731850521\n",
      "Iteration 5175 => Loss: 51.36074093063100320933\n",
      "Iteration 5176 => Loss: 51.36053819600705594439\n",
      "Iteration 5177 => Loss: 51.36033546316501485762\n",
      "Iteration 5178 => Loss: 51.36013273210446783423\n",
      "Iteration 5179 => Loss: 51.35993000282498854858\n",
      "Iteration 5180 => Loss: 51.35972727532616488588\n",
      "Iteration 5181 => Loss: 51.35952454960750657165\n",
      "Iteration 5182 => Loss: 51.35932182566865122908\n",
      "Iteration 5183 => Loss: 51.35911910350913700540\n",
      "Iteration 5184 => Loss: 51.35891638312852336412\n",
      "Iteration 5185 => Loss: 51.35871366452642661216\n",
      "Iteration 5186 => Loss: 51.35851094770239200216\n",
      "Iteration 5187 => Loss: 51.35830823265598610305\n",
      "Iteration 5188 => Loss: 51.35810551938682522177\n",
      "Iteration 5189 => Loss: 51.35790280789444750553\n",
      "Iteration 5190 => Loss: 51.35770009817843373412\n",
      "Iteration 5191 => Loss: 51.35749739023838600360\n",
      "Iteration 5192 => Loss: 51.35729468407389219919\n",
      "Iteration 5193 => Loss: 51.35709197968449757354\n",
      "Iteration 5194 => Loss: 51.35688927706981132815\n",
      "Iteration 5195 => Loss: 51.35668657622940003193\n",
      "Iteration 5196 => Loss: 51.35648387716286578097\n",
      "Iteration 5197 => Loss: 51.35628117986976093334\n",
      "Iteration 5198 => Loss: 51.35607848434970179596\n",
      "Iteration 5199 => Loss: 51.35587579060228335948\n",
      "Iteration 5200 => Loss: 51.35567309862706508738\n",
      "Iteration 5201 => Loss: 51.35547040842363486490\n",
      "Iteration 5202 => Loss: 51.35526771999160899895\n",
      "Iteration 5203 => Loss: 51.35506503333053984761\n",
      "Iteration 5204 => Loss: 51.35486234844006503408\n",
      "Iteration 5205 => Loss: 51.35465966531974402187\n",
      "Iteration 5206 => Loss: 51.35445698396915048534\n",
      "Iteration 5207 => Loss: 51.35425430438794336396\n",
      "Iteration 5208 => Loss: 51.35405162657563948869\n",
      "Iteration 5209 => Loss: 51.35384895053191911529\n",
      "Iteration 5210 => Loss: 51.35364627625629196928\n",
      "Iteration 5211 => Loss: 51.35344360374838146299\n",
      "Iteration 5212 => Loss: 51.35324093300783232507\n",
      "Iteration 5213 => Loss: 51.35303826403420401903\n",
      "Iteration 5214 => Loss: 51.35283559682709864092\n",
      "Iteration 5215 => Loss: 51.35263293138610407595\n",
      "Iteration 5216 => Loss: 51.35243026771085794735\n",
      "Iteration 5217 => Loss: 51.35222760580092682403\n",
      "Iteration 5218 => Loss: 51.35202494565592701292\n",
      "Iteration 5219 => Loss: 51.35182228727547482094\n",
      "Iteration 5220 => Loss: 51.35161963065915102788\n",
      "Iteration 5221 => Loss: 51.35141697580656483524\n",
      "Iteration 5222 => Loss: 51.35121432271734676078\n",
      "Iteration 5223 => Loss: 51.35101167139107758430\n",
      "Iteration 5224 => Loss: 51.35080902182738782358\n",
      "Iteration 5225 => Loss: 51.35060637402586536382\n",
      "Iteration 5226 => Loss: 51.35040372798612651195\n",
      "Iteration 5227 => Loss: 51.35020108370777336404\n",
      "Iteration 5228 => Loss: 51.34999844119043643786\n",
      "Iteration 5229 => Loss: 51.34979580043372493492\n",
      "Iteration 5230 => Loss: 51.34959316143723384585\n",
      "Iteration 5231 => Loss: 51.34939052420058658299\n",
      "Iteration 5232 => Loss: 51.34918788872340655871\n",
      "Iteration 5233 => Loss: 51.34898525500530297450\n",
      "Iteration 5234 => Loss: 51.34878262304588503184\n",
      "Iteration 5235 => Loss: 51.34857999284479035396\n",
      "Iteration 5236 => Loss: 51.34837736440159261520\n",
      "Iteration 5237 => Loss: 51.34817473771595786047\n",
      "Iteration 5238 => Loss: 51.34797211278748108043\n",
      "Iteration 5239 => Loss: 51.34776948961581410913\n",
      "Iteration 5240 => Loss: 51.34756686820051641007\n",
      "Iteration 5241 => Loss: 51.34736424854125402817\n",
      "Iteration 5242 => Loss: 51.34716163063765037577\n",
      "Iteration 5243 => Loss: 51.34695901448931465438\n",
      "Iteration 5244 => Loss: 51.34675640009587738177\n",
      "Iteration 5245 => Loss: 51.34655378745696197029\n",
      "Iteration 5246 => Loss: 51.34635117657218472687\n",
      "Iteration 5247 => Loss: 51.34614856744121169640\n",
      "Iteration 5248 => Loss: 51.34594596006360944784\n",
      "Iteration 5249 => Loss: 51.34574335443905113152\n",
      "Iteration 5250 => Loss: 51.34554075056713884351\n",
      "Iteration 5251 => Loss: 51.34533814844753152329\n",
      "Iteration 5252 => Loss: 51.34513554807983837236\n",
      "Iteration 5253 => Loss: 51.34493294946368990850\n",
      "Iteration 5254 => Loss: 51.34473035259873086034\n",
      "Iteration 5255 => Loss: 51.34452775748458464022\n",
      "Iteration 5256 => Loss: 51.34432516412089597679\n",
      "Iteration 5257 => Loss: 51.34412257250728828240\n",
      "Iteration 5258 => Loss: 51.34391998264339918023\n",
      "Iteration 5259 => Loss: 51.34371739452885918809\n",
      "Iteration 5260 => Loss: 51.34351480816332014001\n",
      "Iteration 5261 => Loss: 51.34331222354639834293\n",
      "Iteration 5262 => Loss: 51.34310964067775273634\n",
      "Iteration 5263 => Loss: 51.34290705955701383800\n",
      "Iteration 5264 => Loss: 51.34270448018381216571\n",
      "Iteration 5265 => Loss: 51.34250190255779955351\n",
      "Iteration 5266 => Loss: 51.34229932667862073004\n",
      "Iteration 5267 => Loss: 51.34209675254590621307\n",
      "Iteration 5268 => Loss: 51.34189418015932204753\n",
      "Iteration 5269 => Loss: 51.34169160951847743490\n",
      "Iteration 5270 => Loss: 51.34148904062303842011\n",
      "Iteration 5271 => Loss: 51.34128647347264973178\n",
      "Iteration 5272 => Loss: 51.34108390806694188768\n",
      "Iteration 5273 => Loss: 51.34088134440559514360\n",
      "Iteration 5274 => Loss: 51.34067878248822580645\n",
      "Iteration 5275 => Loss: 51.34047622231448571029\n",
      "Iteration 5276 => Loss: 51.34027366388402668917\n",
      "Iteration 5277 => Loss: 51.34007110719650768260\n",
      "Iteration 5278 => Loss: 51.33986855225155210292\n",
      "Iteration 5279 => Loss: 51.33966599904884731131\n",
      "Iteration 5280 => Loss: 51.33946344758803803643\n",
      "Iteration 5281 => Loss: 51.33926089786876190146\n",
      "Iteration 5282 => Loss: 51.33905834989065652962\n",
      "Iteration 5283 => Loss: 51.33885580365341638753\n",
      "Iteration 5284 => Loss: 51.33865325915668620382\n",
      "Iteration 5285 => Loss: 51.33845071640008939085\n",
      "Iteration 5286 => Loss: 51.33824817538332752065\n",
      "Iteration 5287 => Loss: 51.33804563610602400558\n",
      "Iteration 5288 => Loss: 51.33784309856783778514\n",
      "Iteration 5289 => Loss: 51.33764056276844911508\n",
      "Iteration 5290 => Loss: 51.33743802870750272405\n",
      "Iteration 5291 => Loss: 51.33723549638465044609\n",
      "Iteration 5292 => Loss: 51.33703296579958674783\n",
      "Iteration 5293 => Loss: 51.33683043695193504163\n",
      "Iteration 5294 => Loss: 51.33662790984136847783\n",
      "Iteration 5295 => Loss: 51.33642538446754599590\n",
      "Iteration 5296 => Loss: 51.33622286083016206248\n",
      "Iteration 5297 => Loss: 51.33602033892883298449\n",
      "Iteration 5298 => Loss: 51.33581781876326033398\n",
      "Iteration 5299 => Loss: 51.33561530033308173415\n",
      "Iteration 5300 => Loss: 51.33541278363798454620\n",
      "Iteration 5301 => Loss: 51.33521026867764192048\n",
      "Iteration 5302 => Loss: 51.33500775545171279646\n",
      "Iteration 5303 => Loss: 51.33480524395984190278\n",
      "Iteration 5304 => Loss: 51.33460273420173791692\n",
      "Iteration 5305 => Loss: 51.33440022617701714580\n",
      "Iteration 5306 => Loss: 51.33419771988540247776\n",
      "Iteration 5307 => Loss: 51.33399521532654574685\n",
      "Iteration 5308 => Loss: 51.33379271250013431427\n",
      "Iteration 5309 => Loss: 51.33359021140580580322\n",
      "Iteration 5310 => Loss: 51.33338771204325468034\n",
      "Iteration 5311 => Loss: 51.33318521441216120138\n",
      "Iteration 5312 => Loss: 51.33298271851217720041\n",
      "Iteration 5313 => Loss: 51.33278022434300424948\n",
      "Iteration 5314 => Loss: 51.33257773190432970978\n",
      "Iteration 5315 => Loss: 51.33237524119578409909\n",
      "Iteration 5316 => Loss: 51.33217275221705477861\n",
      "Iteration 5317 => Loss: 51.33197026496784332039\n",
      "Iteration 5318 => Loss: 51.33176777944780866392\n",
      "Iteration 5319 => Loss: 51.33156529565665948667\n",
      "Iteration 5320 => Loss: 51.33136281359405472813\n",
      "Iteration 5321 => Loss: 51.33116033325966043321\n",
      "Iteration 5322 => Loss: 51.33095785465317817398\n",
      "Iteration 5323 => Loss: 51.33075537777430241704\n",
      "Iteration 5324 => Loss: 51.33055290262267789103\n",
      "Iteration 5325 => Loss: 51.33035042919802748429\n",
      "Iteration 5326 => Loss: 51.33014795750000303087\n",
      "Iteration 5327 => Loss: 51.32994548752830610283\n",
      "Iteration 5328 => Loss: 51.32974301928260985051\n",
      "Iteration 5329 => Loss: 51.32954055276261584595\n",
      "Iteration 5330 => Loss: 51.32933808796803987207\n",
      "Iteration 5331 => Loss: 51.32913562489847691950\n",
      "Iteration 5332 => Loss: 51.32893316355371382542\n",
      "Iteration 5333 => Loss: 51.32873070393336689676\n",
      "Iteration 5334 => Loss: 51.32852824603718033813\n",
      "Iteration 5335 => Loss: 51.32832578986479887817\n",
      "Iteration 5336 => Loss: 51.32812333541594540520\n",
      "Iteration 5337 => Loss: 51.32792088269032149128\n",
      "Iteration 5338 => Loss: 51.32771843168756475961\n",
      "Iteration 5339 => Loss: 51.32751598240740520396\n",
      "Iteration 5340 => Loss: 51.32731353484955150179\n",
      "Iteration 5341 => Loss: 51.32711108901366259261\n",
      "Iteration 5342 => Loss: 51.32690864489945425930\n",
      "Iteration 5343 => Loss: 51.32670620250660675765\n",
      "Iteration 5344 => Loss: 51.32650376183482876513\n",
      "Iteration 5345 => Loss: 51.32630132288380764294\n",
      "Iteration 5346 => Loss: 51.32609888565325917398\n",
      "Iteration 5347 => Loss: 51.32589645014284940316\n",
      "Iteration 5348 => Loss: 51.32569401635230121883\n",
      "Iteration 5349 => Loss: 51.32549158428131619303\n",
      "Iteration 5350 => Loss: 51.32528915392957458153\n",
      "Iteration 5351 => Loss: 51.32508672529677085095\n",
      "Iteration 5352 => Loss: 51.32488429838265631133\n",
      "Iteration 5353 => Loss: 51.32468187318688990217\n",
      "Iteration 5354 => Loss: 51.32447944970915898466\n",
      "Iteration 5355 => Loss: 51.32427702794921486884\n",
      "Iteration 5356 => Loss: 51.32407460790671649420\n",
      "Iteration 5357 => Loss: 51.32387218958139385450\n",
      "Iteration 5358 => Loss: 51.32366977297294141636\n",
      "Iteration 5359 => Loss: 51.32346735808108206811\n",
      "Iteration 5360 => Loss: 51.32326494490551027639\n",
      "Iteration 5361 => Loss: 51.32306253344589919152\n",
      "Iteration 5362 => Loss: 51.32286012370197880728\n",
      "Iteration 5363 => Loss: 51.32265771567351464455\n",
      "Iteration 5364 => Loss: 51.32245530936013011569\n",
      "Iteration 5365 => Loss: 51.32225290476159074160\n",
      "Iteration 5366 => Loss: 51.32205050187756256719\n",
      "Iteration 5367 => Loss: 51.32184810070777558622\n",
      "Iteration 5368 => Loss: 51.32164570125195979244\n",
      "Iteration 5369 => Loss: 51.32144330350978123079\n",
      "Iteration 5370 => Loss: 51.32124090748101963300\n",
      "Iteration 5371 => Loss: 51.32103851316532683313\n",
      "Iteration 5372 => Loss: 51.32083612056241861410\n",
      "Iteration 5373 => Loss: 51.32063372967206049680\n",
      "Iteration 5374 => Loss: 51.32043134049389010443\n",
      "Iteration 5375 => Loss: 51.32022895302770848502\n",
      "Iteration 5376 => Loss: 51.32002656727316747265\n",
      "Iteration 5377 => Loss: 51.31982418323001837734\n",
      "Iteration 5378 => Loss: 51.31962180089796277116\n",
      "Iteration 5379 => Loss: 51.31941942027670222615\n",
      "Iteration 5380 => Loss: 51.31921704136596673607\n",
      "Iteration 5381 => Loss: 51.31901466416549340011\n",
      "Iteration 5382 => Loss: 51.31881228867498379032\n",
      "Iteration 5383 => Loss: 51.31860991489416790046\n",
      "Iteration 5384 => Loss: 51.31840754282274730258\n",
      "Iteration 5385 => Loss: 51.31820517246045909587\n",
      "Iteration 5386 => Loss: 51.31800280380704037952\n",
      "Iteration 5387 => Loss: 51.31780043686219272558\n",
      "Iteration 5388 => Loss: 51.31759807162561060068\n",
      "Iteration 5389 => Loss: 51.31739570809706663113\n",
      "Iteration 5390 => Loss: 51.31719334627626238898\n",
      "Iteration 5391 => Loss: 51.31699098616290655173\n",
      "Iteration 5392 => Loss: 51.31678862775677174568\n",
      "Iteration 5393 => Loss: 51.31658627105751691033\n",
      "Iteration 5394 => Loss: 51.31638391606493598829\n",
      "Iteration 5395 => Loss: 51.31618156277872344617\n",
      "Iteration 5396 => Loss: 51.31597921119860927774\n",
      "Iteration 5397 => Loss: 51.31577686132430216048\n",
      "Iteration 5398 => Loss: 51.31557451315556050986\n",
      "Iteration 5399 => Loss: 51.31537216669210010878\n",
      "Iteration 5400 => Loss: 51.31516982193362963471\n",
      "Iteration 5401 => Loss: 51.31496747887993592485\n",
      "Iteration 5402 => Loss: 51.31476513753069212953\n",
      "Iteration 5403 => Loss: 51.31456279788566376965\n",
      "Iteration 5404 => Loss: 51.31436045994457373354\n",
      "Iteration 5405 => Loss: 51.31415812370715912039\n",
      "Iteration 5406 => Loss: 51.31395578917312150224\n",
      "Iteration 5407 => Loss: 51.31375345634221218916\n",
      "Iteration 5408 => Loss: 51.31355112521420380745\n",
      "Iteration 5409 => Loss: 51.31334879578878371831\n",
      "Iteration 5410 => Loss: 51.31314646806568902093\n",
      "Iteration 5411 => Loss: 51.31294414204467102536\n",
      "Iteration 5412 => Loss: 51.31274181772548104163\n",
      "Iteration 5413 => Loss: 51.31253949510782774723\n",
      "Iteration 5414 => Loss: 51.31233717419145534677\n",
      "Iteration 5415 => Loss: 51.31213485497612936115\n",
      "Iteration 5416 => Loss: 51.31193253746153004613\n",
      "Iteration 5417 => Loss: 51.31173022164745134432\n",
      "Iteration 5418 => Loss: 51.31152790753359482778\n",
      "Iteration 5419 => Loss: 51.31132559511974733368\n",
      "Iteration 5420 => Loss: 51.31112328440558911780\n",
      "Iteration 5421 => Loss: 51.31092097539090701730\n",
      "Iteration 5422 => Loss: 51.31071866807542392053\n",
      "Iteration 5423 => Loss: 51.31051636245888403209\n",
      "Iteration 5424 => Loss: 51.31031405854104576747\n",
      "Iteration 5425 => Loss: 51.31011175632162490956\n",
      "Iteration 5426 => Loss: 51.30990945580037987384\n",
      "Iteration 5427 => Loss: 51.30970715697704775948\n",
      "Iteration 5428 => Loss: 51.30950485985140119283\n",
      "Iteration 5429 => Loss: 51.30930256442315595677\n",
      "Iteration 5430 => Loss: 51.30910027069206336137\n",
      "Iteration 5431 => Loss: 51.30889797865786761122\n",
      "Iteration 5432 => Loss: 51.30869568832033422723\n",
      "Iteration 5433 => Loss: 51.30849339967918609773\n",
      "Iteration 5434 => Loss: 51.30829111273418163819\n",
      "Iteration 5435 => Loss: 51.30808882748508636951\n",
      "Iteration 5436 => Loss: 51.30788654393161607459\n",
      "Iteration 5437 => Loss: 51.30768426207355048518\n",
      "Iteration 5438 => Loss: 51.30748198191064091134\n",
      "Iteration 5439 => Loss: 51.30727970344260313595\n",
      "Iteration 5440 => Loss: 51.30707742666920267993\n",
      "Iteration 5441 => Loss: 51.30687515159021927502\n",
      "Iteration 5442 => Loss: 51.30667287820539002041\n",
      "Iteration 5443 => Loss: 51.30647060651444490986\n",
      "Iteration 5444 => Loss: 51.30626833651714946427\n",
      "Iteration 5445 => Loss: 51.30606606821329052082\n",
      "Iteration 5446 => Loss: 51.30586380160256965155\n",
      "Iteration 5447 => Loss: 51.30566153668478790451\n",
      "Iteration 5448 => Loss: 51.30545927345965395716\n",
      "Iteration 5449 => Loss: 51.30525701192695464670\n",
      "Iteration 5450 => Loss: 51.30505475208646259944\n",
      "Iteration 5451 => Loss: 51.30485249393788649286\n",
      "Iteration 5452 => Loss: 51.30465023748103448042\n",
      "Iteration 5453 => Loss: 51.30444798271562945047\n",
      "Iteration 5454 => Loss: 51.30424572964143692388\n",
      "Iteration 5455 => Loss: 51.30404347825820821072\n",
      "Iteration 5456 => Loss: 51.30384122856571593729\n",
      "Iteration 5457 => Loss: 51.30363898056374694079\n",
      "Iteration 5458 => Loss: 51.30343673425201700411\n",
      "Iteration 5459 => Loss: 51.30323448963028454273\n",
      "Iteration 5460 => Loss: 51.30303224669835771010\n",
      "Iteration 5461 => Loss: 51.30283000545595939457\n",
      "Iteration 5462 => Loss: 51.30262776590285511702\n",
      "Iteration 5463 => Loss: 51.30242552803883171464\n",
      "Iteration 5464 => Loss: 51.30222329186361918119\n",
      "Iteration 5465 => Loss: 51.30202105737699724841\n",
      "Iteration 5466 => Loss: 51.30181882457874564807\n",
      "Iteration 5467 => Loss: 51.30161659346860147934\n",
      "Iteration 5468 => Loss: 51.30141436404633736856\n",
      "Iteration 5469 => Loss: 51.30121213631174725833\n",
      "Iteration 5470 => Loss: 51.30100991026456824784\n",
      "Iteration 5471 => Loss: 51.30080768590455875255\n",
      "Iteration 5472 => Loss: 51.30060546323151982051\n",
      "Iteration 5473 => Loss: 51.30040324224519565632\n",
      "Iteration 5474 => Loss: 51.30020102294534467546\n",
      "Iteration 5475 => Loss: 51.29999880533175371511\n",
      "Iteration 5476 => Loss: 51.29979658940420250701\n",
      "Iteration 5477 => Loss: 51.29959437516244946664\n",
      "Iteration 5478 => Loss: 51.29939216260623879862\n",
      "Iteration 5479 => Loss: 51.29918995173539997268\n",
      "Iteration 5480 => Loss: 51.29898774254964877173\n",
      "Iteration 5481 => Loss: 51.29878553504876492752\n",
      "Iteration 5482 => Loss: 51.29858332923253527724\n",
      "Iteration 5483 => Loss: 51.29838112510075376349\n",
      "Iteration 5484 => Loss: 51.29817892265314327460\n",
      "Iteration 5485 => Loss: 51.29797672188950485861\n",
      "Iteration 5486 => Loss: 51.29777452280961824727\n",
      "Iteration 5487 => Loss: 51.29757232541326317232\n",
      "Iteration 5488 => Loss: 51.29737012970017673297\n",
      "Iteration 5489 => Loss: 51.29716793567017418809\n",
      "Iteration 5490 => Loss: 51.29696574332302105859\n",
      "Iteration 5491 => Loss: 51.29676355265846154907\n",
      "Iteration 5492 => Loss: 51.29656136367631802386\n",
      "Iteration 5493 => Loss: 51.29635917637636310928\n",
      "Iteration 5494 => Loss: 51.29615699075833390452\n",
      "Iteration 5495 => Loss: 51.29595480682203856304\n",
      "Iteration 5496 => Loss: 51.29575262456727813287\n",
      "Iteration 5497 => Loss: 51.29555044399376839692\n",
      "Iteration 5498 => Loss: 51.29534826510134593036\n",
      "Iteration 5499 => Loss: 51.29514608788978335951\n",
      "Iteration 5500 => Loss: 51.29494391235883909985\n",
      "Iteration 5501 => Loss: 51.29474173850829998855\n",
      "Iteration 5502 => Loss: 51.29453956633794575737\n",
      "Iteration 5503 => Loss: 51.29433739584757034891\n",
      "Iteration 5504 => Loss: 51.29413522703694638949\n",
      "Iteration 5505 => Loss: 51.29393305990586071630\n",
      "Iteration 5506 => Loss: 51.29373089445409306109\n",
      "Iteration 5507 => Loss: 51.29352873068143026103\n",
      "Iteration 5508 => Loss: 51.29332656858763073160\n",
      "Iteration 5509 => Loss: 51.29312440817254525882\n",
      "Iteration 5510 => Loss: 51.29292224943590383646\n",
      "Iteration 5511 => Loss: 51.29272009237749330168\n",
      "Iteration 5512 => Loss: 51.29251793699711470254\n",
      "Iteration 5513 => Loss: 51.29231578329455487619\n",
      "Iteration 5514 => Loss: 51.29211363126959355441\n",
      "Iteration 5515 => Loss: 51.29191148092200336350\n",
      "Iteration 5516 => Loss: 51.29170933225160666780\n",
      "Iteration 5517 => Loss: 51.29150718525817609361\n",
      "Iteration 5518 => Loss: 51.29130503994148426727\n",
      "Iteration 5519 => Loss: 51.29110289630135355310\n",
      "Iteration 5520 => Loss: 51.29090075433752815570\n",
      "Iteration 5521 => Loss: 51.29069861404983754483\n",
      "Iteration 5522 => Loss: 51.29049647543804013594\n",
      "Iteration 5523 => Loss: 51.29029433850195829336\n",
      "Iteration 5524 => Loss: 51.29009220324138595970\n",
      "Iteration 5525 => Loss: 51.28989006965606733957\n",
      "Iteration 5526 => Loss: 51.28968793774581769185\n",
      "Iteration 5527 => Loss: 51.28948580751045227544\n",
      "Iteration 5528 => Loss: 51.28928367894974371666\n",
      "Iteration 5529 => Loss: 51.28908155206349306354\n",
      "Iteration 5530 => Loss: 51.28887942685146583699\n",
      "Iteration 5531 => Loss: 51.28867730331350571760\n",
      "Iteration 5532 => Loss: 51.28847518144937822626\n",
      "Iteration 5533 => Loss: 51.28827306125886309474\n",
      "Iteration 5534 => Loss: 51.28807094274180400362\n",
      "Iteration 5535 => Loss: 51.28786882589793805209\n",
      "Iteration 5536 => Loss: 51.28766671072708049905\n",
      "Iteration 5537 => Loss: 51.28746459722906791967\n",
      "Iteration 5538 => Loss: 51.28726248540364451856\n",
      "Iteration 5539 => Loss: 51.28706037525062555460\n",
      "Iteration 5540 => Loss: 51.28685826676983339212\n",
      "Iteration 5541 => Loss: 51.28665615996104776286\n",
      "Iteration 5542 => Loss: 51.28645405482405550401\n",
      "Iteration 5543 => Loss: 51.28625195135865055818\n",
      "Iteration 5544 => Loss: 51.28604984956465528967\n",
      "Iteration 5545 => Loss: 51.28584774944185653567\n",
      "Iteration 5546 => Loss: 51.28564565099008376592\n",
      "Iteration 5547 => Loss: 51.28544355420908829046\n",
      "Iteration 5548 => Loss: 51.28524145909869247362\n",
      "Iteration 5549 => Loss: 51.28503936565872578512\n",
      "Iteration 5550 => Loss: 51.28483727388896795674\n",
      "Iteration 5551 => Loss: 51.28463518378919872021\n",
      "Iteration 5552 => Loss: 51.28443309535925465070\n",
      "Iteration 5553 => Loss: 51.28423100859891547998\n",
      "Iteration 5554 => Loss: 51.28402892350798225607\n",
      "Iteration 5555 => Loss: 51.28382684008629155414\n",
      "Iteration 5556 => Loss: 51.28362475833360889510\n",
      "Iteration 5557 => Loss: 51.28342267824978506496\n",
      "Iteration 5558 => Loss: 51.28322059983456426835\n",
      "Iteration 5559 => Loss: 51.28301852308781150214\n",
      "Iteration 5560 => Loss: 51.28281644800930649808\n",
      "Iteration 5561 => Loss: 51.28261437459885740964\n",
      "Iteration 5562 => Loss: 51.28241230285624396856\n",
      "Iteration 5563 => Loss: 51.28221023278131696088\n",
      "Iteration 5564 => Loss: 51.28200816437386322377\n",
      "Iteration 5565 => Loss: 51.28180609763371222698\n",
      "Iteration 5566 => Loss: 51.28160403256063659683\n",
      "Iteration 5567 => Loss: 51.28140196915447290849\n",
      "Iteration 5568 => Loss: 51.28119990741500799913\n",
      "Iteration 5569 => Loss: 51.28099784734207133852\n",
      "Iteration 5570 => Loss: 51.28079578893544976381\n",
      "Iteration 5571 => Loss: 51.28059373219497274476\n",
      "Iteration 5572 => Loss: 51.28039167712045554026\n",
      "Iteration 5573 => Loss: 51.28018962371169209291\n",
      "Iteration 5574 => Loss: 51.27998757196849766160\n",
      "Iteration 5575 => Loss: 51.27978552189070171607\n",
      "Iteration 5576 => Loss: 51.27958347347811240979\n",
      "Iteration 5577 => Loss: 51.27938142673049526366\n",
      "Iteration 5578 => Loss: 51.27917938164772237997\n",
      "Iteration 5579 => Loss: 51.27897733822959480676\n",
      "Iteration 5580 => Loss: 51.27877529647589938122\n",
      "Iteration 5581 => Loss: 51.27857325638647978394\n",
      "Iteration 5582 => Loss: 51.27837121796114416838\n",
      "Iteration 5583 => Loss: 51.27816918119967937173\n",
      "Iteration 5584 => Loss: 51.27796714610195039086\n",
      "Iteration 5585 => Loss: 51.27776511266772985209\n",
      "Iteration 5586 => Loss: 51.27756308089686854146\n",
      "Iteration 5587 => Loss: 51.27736105078914619071\n",
      "Iteration 5588 => Loss: 51.27715902234438516416\n",
      "Iteration 5589 => Loss: 51.27695699556243624784\n",
      "Iteration 5590 => Loss: 51.27675497044307917349\n",
      "Iteration 5591 => Loss: 51.27655294698618604343\n",
      "Iteration 5592 => Loss: 51.27635092519150816770\n",
      "Iteration 5593 => Loss: 51.27614890505889633232\n",
      "Iteration 5594 => Loss: 51.27594688658816579618\n",
      "Iteration 5595 => Loss: 51.27574486977912471275\n",
      "Iteration 5596 => Loss: 51.27554285463162386804\n",
      "Iteration 5597 => Loss: 51.27534084114545720468\n",
      "Iteration 5598 => Loss: 51.27513882932043998153\n",
      "Iteration 5599 => Loss: 51.27493681915643719549\n",
      "Iteration 5600 => Loss: 51.27473481065321436745\n",
      "Iteration 5601 => Loss: 51.27453280381062938886\n",
      "Iteration 5602 => Loss: 51.27433079862849041319\n",
      "Iteration 5603 => Loss: 51.27412879510660559390\n",
      "Iteration 5604 => Loss: 51.27392679324481861158\n",
      "Iteration 5605 => Loss: 51.27372479304297314684\n",
      "Iteration 5606 => Loss: 51.27352279450085603685\n",
      "Iteration 5607 => Loss: 51.27332079761828254050\n",
      "Iteration 5608 => Loss: 51.27311880239511054924\n",
      "Iteration 5609 => Loss: 51.27291680883114821654\n",
      "Iteration 5610 => Loss: 51.27271481692621080128\n",
      "Iteration 5611 => Loss: 51.27251282668015619493\n",
      "Iteration 5612 => Loss: 51.27231083809277123464\n",
      "Iteration 5613 => Loss: 51.27210885116392091732\n",
      "Iteration 5614 => Loss: 51.27190686589339208012\n",
      "Iteration 5615 => Loss: 51.27170488228102840367\n",
      "Iteration 5616 => Loss: 51.27150290032668067397\n",
      "Iteration 5617 => Loss: 51.27130092003011441193\n",
      "Iteration 5618 => Loss: 51.27109894139123014156\n",
      "Iteration 5619 => Loss: 51.27089696440980048919\n",
      "Iteration 5620 => Loss: 51.27069498908565492457\n",
      "Iteration 5621 => Loss: 51.27049301541870107712\n",
      "Iteration 5622 => Loss: 51.27029104340867604606\n",
      "Iteration 5623 => Loss: 51.27008907305543061739\n",
      "Iteration 5624 => Loss: 51.26988710435882268257\n",
      "Iteration 5625 => Loss: 51.26968513731866750049\n",
      "Iteration 5626 => Loss: 51.26948317193477322462\n",
      "Iteration 5627 => Loss: 51.26928120820700485183\n",
      "Iteration 5628 => Loss: 51.26907924613518474644\n",
      "Iteration 5629 => Loss: 51.26887728571914948361\n",
      "Iteration 5630 => Loss: 51.26867532695870721682\n",
      "Iteration 5631 => Loss: 51.26847336985369452123\n",
      "Iteration 5632 => Loss: 51.26827141440396928829\n",
      "Iteration 5633 => Loss: 51.26806946060935388232\n",
      "Iteration 5634 => Loss: 51.26786750846966356221\n",
      "Iteration 5635 => Loss: 51.26766555798475621941\n",
      "Iteration 5636 => Loss: 51.26746360915444000739\n",
      "Iteration 5637 => Loss: 51.26726166197855860673\n",
      "Iteration 5638 => Loss: 51.26705971645698411976\n",
      "Iteration 5639 => Loss: 51.26685777258949627821\n",
      "Iteration 5640 => Loss: 51.26665583037593876270\n",
      "Iteration 5641 => Loss: 51.26645388981617657009\n",
      "Iteration 5642 => Loss: 51.26625195091002495928\n",
      "Iteration 5643 => Loss: 51.26605001365733471630\n",
      "Iteration 5644 => Loss: 51.26584807805792110003\n",
      "Iteration 5645 => Loss: 51.26564614411163489649\n",
      "Iteration 5646 => Loss: 51.26544421181831268086\n",
      "Iteration 5647 => Loss: 51.26524228117780523917\n",
      "Iteration 5648 => Loss: 51.26504035218990651401\n",
      "Iteration 5649 => Loss: 51.26483842485448860771\n",
      "Iteration 5650 => Loss: 51.26463649917139520085\n",
      "Iteration 5651 => Loss: 51.26443457514045576318\n",
      "Iteration 5652 => Loss: 51.26423265276150686987\n",
      "Iteration 5653 => Loss: 51.26403073203440641237\n",
      "Iteration 5654 => Loss: 51.26382881295894833329\n",
      "Iteration 5655 => Loss: 51.26362689553501184037\n",
      "Iteration 5656 => Loss: 51.26342497976244061419\n",
      "Iteration 5657 => Loss: 51.26322306564105701909\n",
      "Iteration 5658 => Loss: 51.26302115317069052480\n",
      "Iteration 5659 => Loss: 51.26281924235120612821\n",
      "Iteration 5660 => Loss: 51.26261733318244040447\n",
      "Iteration 5661 => Loss: 51.26241542566424413963\n",
      "Iteration 5662 => Loss: 51.26221351979644680341\n",
      "Iteration 5663 => Loss: 51.26201161557889918186\n",
      "Iteration 5664 => Loss: 51.26180971301143074470\n",
      "Iteration 5665 => Loss: 51.26160781209388517254\n",
      "Iteration 5666 => Loss: 51.26140591282613456769\n",
      "Iteration 5667 => Loss: 51.26120401520798708361\n",
      "Iteration 5668 => Loss: 51.26100211923928640090\n",
      "Iteration 5669 => Loss: 51.26080022491991883271\n",
      "Iteration 5670 => Loss: 51.26059833224971384880\n",
      "Iteration 5671 => Loss: 51.26039644122847960261\n",
      "Iteration 5672 => Loss: 51.26019455185610240733\n",
      "Iteration 5673 => Loss: 51.25999266413241173268\n",
      "Iteration 5674 => Loss: 51.25979077805725125927\n",
      "Iteration 5675 => Loss: 51.25958889363047887855\n",
      "Iteration 5676 => Loss: 51.25938701085194537654\n",
      "Iteration 5677 => Loss: 51.25918512972147311757\n",
      "Iteration 5678 => Loss: 51.25898325023892709851\n",
      "Iteration 5679 => Loss: 51.25878137240413678910\n",
      "Iteration 5680 => Loss: 51.25857949621698139708\n",
      "Iteration 5681 => Loss: 51.25837762167728328677\n",
      "Iteration 5682 => Loss: 51.25817574878490745505\n",
      "Iteration 5683 => Loss: 51.25797387753970468793\n",
      "Iteration 5684 => Loss: 51.25777200794150445518\n",
      "Iteration 5685 => Loss: 51.25757013999017175365\n",
      "Iteration 5686 => Loss: 51.25736827368555736939\n",
      "Iteration 5687 => Loss: 51.25716640902749077213\n",
      "Iteration 5688 => Loss: 51.25696454601585116961\n",
      "Iteration 5689 => Loss: 51.25676268465046092615\n",
      "Iteration 5690 => Loss: 51.25656082493120635490\n",
      "Iteration 5691 => Loss: 51.25635896685790982019\n",
      "Iteration 5692 => Loss: 51.25615711043042921347\n",
      "Iteration 5693 => Loss: 51.25595525564862953161\n",
      "Iteration 5694 => Loss: 51.25575340251232603350\n",
      "Iteration 5695 => Loss: 51.25555155102142634860\n",
      "Iteration 5696 => Loss: 51.25534970117574573578\n",
      "Iteration 5697 => Loss: 51.25514785297515629736\n",
      "Iteration 5698 => Loss: 51.25494600641948750308\n",
      "Iteration 5699 => Loss: 51.25474416150860434982\n",
      "Iteration 5700 => Loss: 51.25454231824237893989\n",
      "Iteration 5701 => Loss: 51.25434047662063363759\n",
      "Iteration 5702 => Loss: 51.25413863664324054525\n",
      "Iteration 5703 => Loss: 51.25393679831005755432\n",
      "Iteration 5704 => Loss: 51.25373496162094255624\n",
      "Iteration 5705 => Loss: 51.25353312657573923161\n",
      "Iteration 5706 => Loss: 51.25333129317429836647\n",
      "Iteration 5707 => Loss: 51.25312946141652048482\n",
      "Iteration 5708 => Loss: 51.25292763130219952927\n",
      "Iteration 5709 => Loss: 51.25272580283122181299\n",
      "Iteration 5710 => Loss: 51.25252397600344522743\n",
      "Iteration 5711 => Loss: 51.25232215081872055862\n",
      "Iteration 5712 => Loss: 51.25212032727691990885\n",
      "Iteration 5713 => Loss: 51.25191850537787274789\n",
      "Iteration 5714 => Loss: 51.25171668512147249430\n",
      "Iteration 5715 => Loss: 51.25151486650752730156\n",
      "Iteration 5716 => Loss: 51.25131304953597322083\n",
      "Iteration 5717 => Loss: 51.25111123420661130012\n",
      "Iteration 5718 => Loss: 51.25090942051929232548\n",
      "Iteration 5719 => Loss: 51.25070760847391682091\n",
      "Iteration 5720 => Loss: 51.25050579807032136159\n",
      "Iteration 5721 => Loss: 51.25030398930836383897\n",
      "Iteration 5722 => Loss: 51.25010218218790924993\n",
      "Iteration 5723 => Loss: 51.24990037670885101306\n",
      "Iteration 5724 => Loss: 51.24969857287094754383\n",
      "Iteration 5725 => Loss: 51.24949677067418463139\n",
      "Iteration 5726 => Loss: 51.24929497011836332376\n",
      "Iteration 5727 => Loss: 51.24909317120334861784\n",
      "Iteration 5728 => Loss: 51.24889137392899129964\n",
      "Iteration 5729 => Loss: 51.24868957829518478775\n",
      "Iteration 5730 => Loss: 51.24848778430176565735\n",
      "Iteration 5731 => Loss: 51.24828599194860601074\n",
      "Iteration 5732 => Loss: 51.24808420123555663395\n",
      "Iteration 5733 => Loss: 51.24788241216251094556\n",
      "Iteration 5734 => Loss: 51.24768062472931262619\n",
      "Iteration 5735 => Loss: 51.24747883893583377812\n",
      "Iteration 5736 => Loss: 51.24727705478191097654\n",
      "Iteration 5737 => Loss: 51.24707527226743053461\n",
      "Iteration 5738 => Loss: 51.24687349139228587092\n",
      "Iteration 5739 => Loss: 51.24667171215627092806\n",
      "Iteration 5740 => Loss: 51.24646993455932886263\n",
      "Iteration 5741 => Loss: 51.24626815860126782809\n",
      "Iteration 5742 => Loss: 51.24606638428197413759\n",
      "Iteration 5743 => Loss: 51.24586461160133410431\n",
      "Iteration 5744 => Loss: 51.24566284055918430340\n",
      "Iteration 5745 => Loss: 51.24546107115538973176\n",
      "Iteration 5746 => Loss: 51.24525930338983670254\n",
      "Iteration 5747 => Loss: 51.24505753726237600176\n",
      "Iteration 5748 => Loss: 51.24485577277288683717\n",
      "Iteration 5749 => Loss: 51.24465400992123420565\n",
      "Iteration 5750 => Loss: 51.24445224870729020950\n",
      "Iteration 5751 => Loss: 51.24425048913091984559\n",
      "Iteration 5752 => Loss: 51.24404873119197389997\n",
      "Iteration 5753 => Loss: 51.24384697489036000206\n",
      "Iteration 5754 => Loss: 51.24364522022590051620\n",
      "Iteration 5755 => Loss: 51.24344346719850307181\n",
      "Iteration 5756 => Loss: 51.24324171580801845494\n",
      "Iteration 5757 => Loss: 51.24303996605432587330\n",
      "Iteration 5758 => Loss: 51.24283821793724769122\n",
      "Iteration 5759 => Loss: 51.24263647145674838157\n",
      "Iteration 5760 => Loss: 51.24243472661262899237\n",
      "Iteration 5761 => Loss: 51.24223298340476162593\n",
      "Iteration 5762 => Loss: 51.24203124183304680628\n",
      "Iteration 5763 => Loss: 51.24182950189735663571\n",
      "Iteration 5764 => Loss: 51.24162776359752058397\n",
      "Iteration 5765 => Loss: 51.24142602693346049136\n",
      "Iteration 5766 => Loss: 51.24122429190501293306\n",
      "Iteration 5767 => Loss: 51.24102255851206422221\n",
      "Iteration 5768 => Loss: 51.24082082675449356657\n",
      "Iteration 5769 => Loss: 51.24061909663214464672\n",
      "Iteration 5770 => Loss: 51.24041736814493219754\n",
      "Iteration 5771 => Loss: 51.24021564129267858334\n",
      "Iteration 5772 => Loss: 51.24001391607531274985\n",
      "Iteration 5773 => Loss: 51.23981219249267837768\n",
      "Iteration 5774 => Loss: 51.23961047054466888540\n",
      "Iteration 5775 => Loss: 51.23940875023112795361\n",
      "Iteration 5776 => Loss: 51.23920703155196321177\n",
      "Iteration 5777 => Loss: 51.23900531450701123504\n",
      "Iteration 5778 => Loss: 51.23880359909616544201\n",
      "Iteration 5779 => Loss: 51.23860188531931214584\n",
      "Iteration 5780 => Loss: 51.23840017317633765970\n",
      "Iteration 5781 => Loss: 51.23819846266706434790\n",
      "Iteration 5782 => Loss: 51.23799675379142115617\n",
      "Iteration 5783 => Loss: 51.23779504654925887053\n",
      "Iteration 5784 => Loss: 51.23759334094047801500\n",
      "Iteration 5785 => Loss: 51.23739163696492227018\n",
      "Iteration 5786 => Loss: 51.23718993462248505466\n",
      "Iteration 5787 => Loss: 51.23698823391305268160\n",
      "Iteration 5788 => Loss: 51.23678653483649014788\n",
      "Iteration 5789 => Loss: 51.23658483739267666124\n",
      "Iteration 5790 => Loss: 51.23638314158147721855\n",
      "Iteration 5791 => Loss: 51.23618144740279234384\n",
      "Iteration 5792 => Loss: 51.23597975485651545569\n",
      "Iteration 5793 => Loss: 51.23577806394246891841\n",
      "Iteration 5794 => Loss: 51.23557637466058167774\n",
      "Iteration 5795 => Loss: 51.23537468701072583599\n",
      "Iteration 5796 => Loss: 51.23517300099274507375\n",
      "Iteration 5797 => Loss: 51.23497131660656833674\n",
      "Iteration 5798 => Loss: 51.23476963385203930557\n",
      "Iteration 5799 => Loss: 51.23456795272905850425\n",
      "Iteration 5800 => Loss: 51.23436627323749092966\n",
      "Iteration 5801 => Loss: 51.23416459537724421125\n",
      "Iteration 5802 => Loss: 51.23396291914817624047\n",
      "Iteration 5803 => Loss: 51.23376124455015911963\n",
      "Iteration 5804 => Loss: 51.23355957158308626731\n",
      "Iteration 5805 => Loss: 51.23335790024685110211\n",
      "Iteration 5806 => Loss: 51.23315623054130441005\n",
      "Iteration 5807 => Loss: 51.23295456246634671515\n",
      "Iteration 5808 => Loss: 51.23275289602189275229\n",
      "Iteration 5809 => Loss: 51.23255123120776488577\n",
      "Iteration 5810 => Loss: 51.23234956802386363961\n",
      "Iteration 5811 => Loss: 51.23214790647013927583\n",
      "Iteration 5812 => Loss: 51.23194624654637863159\n",
      "Iteration 5813 => Loss: 51.23174458825249644178\n",
      "Iteration 5814 => Loss: 51.23154293158841454670\n",
      "Iteration 5815 => Loss: 51.23134127655395531065\n",
      "Iteration 5816 => Loss: 51.23113962314906899564\n",
      "Iteration 5817 => Loss: 51.23093797137357086058\n",
      "Iteration 5818 => Loss: 51.23073632122739695660\n",
      "Iteration 5819 => Loss: 51.23053467271042649145\n",
      "Iteration 5820 => Loss: 51.23033302582251025115\n",
      "Iteration 5821 => Loss: 51.23013138056355586514\n",
      "Iteration 5822 => Loss: 51.22992973693344254116\n",
      "Iteration 5823 => Loss: 51.22972809493208501408\n",
      "Iteration 5824 => Loss: 51.22952645455932696450\n",
      "Iteration 5825 => Loss: 51.22932481581509733815\n",
      "Iteration 5826 => Loss: 51.22912317869923981561\n",
      "Iteration 5827 => Loss: 51.22892154321166913178\n",
      "Iteration 5828 => Loss: 51.22871990935227159980\n",
      "Iteration 5829 => Loss: 51.22851827712090511113\n",
      "Iteration 5830 => Loss: 51.22831664651747729522\n",
      "Iteration 5831 => Loss: 51.22811501754188157065\n",
      "Iteration 5832 => Loss: 51.22791339019399003973\n",
      "Iteration 5833 => Loss: 51.22771176447372454277\n",
      "Iteration 5834 => Loss: 51.22751014038094297121\n",
      "Iteration 5835 => Loss: 51.22730851791552453278\n",
      "Iteration 5836 => Loss: 51.22710689707736975151\n",
      "Iteration 5837 => Loss: 51.22690527786637204599\n",
      "Iteration 5838 => Loss: 51.22670366028243194023\n",
      "Iteration 5839 => Loss: 51.22650204432542153654\n",
      "Iteration 5840 => Loss: 51.22630042999522004266\n",
      "Iteration 5841 => Loss: 51.22609881729174219345\n",
      "Iteration 5842 => Loss: 51.22589720621486009122\n",
      "Iteration 5843 => Loss: 51.22569559676447426000\n",
      "Iteration 5844 => Loss: 51.22549398894045680208\n",
      "Iteration 5845 => Loss: 51.22529238274272955778\n",
      "Iteration 5846 => Loss: 51.22509077817116462938\n",
      "Iteration 5847 => Loss: 51.22488917522564122464\n",
      "Iteration 5848 => Loss: 51.22468757390606697300\n",
      "Iteration 5849 => Loss: 51.22448597421232818760\n",
      "Iteration 5850 => Loss: 51.22428437614430407621\n",
      "Iteration 5851 => Loss: 51.22408277970192358453\n",
      "Iteration 5852 => Loss: 51.22388118488505881487\n",
      "Iteration 5853 => Loss: 51.22367959169356765869\n",
      "Iteration 5854 => Loss: 51.22347800012740037801\n",
      "Iteration 5855 => Loss: 51.22327641018641486426\n",
      "Iteration 5856 => Loss: 51.22307482187048321975\n",
      "Iteration 5857 => Loss: 51.22287323517955570651\n",
      "Iteration 5858 => Loss: 51.22267165011347600512\n",
      "Iteration 5859 => Loss: 51.22247006667217306131\n",
      "Iteration 5860 => Loss: 51.22226848485552608281\n",
      "Iteration 5861 => Loss: 51.22206690466339296108\n",
      "Iteration 5862 => Loss: 51.22186532609574527442\n",
      "Iteration 5863 => Loss: 51.22166374915241249255\n",
      "Iteration 5864 => Loss: 51.22146217383330224493\n",
      "Iteration 5865 => Loss: 51.22126060013832926643\n",
      "Iteration 5866 => Loss: 51.22105902806735144850\n",
      "Iteration 5867 => Loss: 51.22085745762033326400\n",
      "Iteration 5868 => Loss: 51.22065588879709707726\n",
      "Iteration 5869 => Loss: 51.22045432159758604485\n",
      "Iteration 5870 => Loss: 51.22025275602165805822\n",
      "Iteration 5871 => Loss: 51.22005119206921364139\n",
      "Iteration 5872 => Loss: 51.21984962974017463466\n",
      "Iteration 5873 => Loss: 51.21964806903442024577\n",
      "Iteration 5874 => Loss: 51.21944650995186520959\n",
      "Iteration 5875 => Loss: 51.21924495249238873384\n",
      "Iteration 5876 => Loss: 51.21904339665589134256\n",
      "Iteration 5877 => Loss: 51.21884184244226645433\n",
      "Iteration 5878 => Loss: 51.21864028985140748773\n",
      "Iteration 5879 => Loss: 51.21843873888324338850\n",
      "Iteration 5880 => Loss: 51.21823718953762494266\n",
      "Iteration 5881 => Loss: 51.21803564181448109593\n",
      "Iteration 5882 => Loss: 51.21783409571368395063\n",
      "Iteration 5883 => Loss: 51.21763255123516955791\n",
      "Iteration 5884 => Loss: 51.21743100837881712550\n",
      "Iteration 5885 => Loss: 51.21722946714450586114\n",
      "Iteration 5886 => Loss: 51.21702792753215049970\n",
      "Iteration 5887 => Loss: 51.21682638954167288148\n",
      "Iteration 5888 => Loss: 51.21662485317295931964\n",
      "Iteration 5889 => Loss: 51.21642331842586060020\n",
      "Iteration 5890 => Loss: 51.21622178530034830146\n",
      "Iteration 5891 => Loss: 51.21602025379626610402\n",
      "Iteration 5892 => Loss: 51.21581872391359979702\n",
      "Iteration 5893 => Loss: 51.21561719565212200678\n",
      "Iteration 5894 => Loss: 51.21541566901180431159\n",
      "Iteration 5895 => Loss: 51.21521414399256855177\n",
      "Iteration 5896 => Loss: 51.21501262059429393503\n",
      "Iteration 5897 => Loss: 51.21481109881685256369\n",
      "Iteration 5898 => Loss: 51.21460957866018759432\n",
      "Iteration 5899 => Loss: 51.21440806012416402382\n",
      "Iteration 5900 => Loss: 51.21420654320873211418\n",
      "Iteration 5901 => Loss: 51.21400502791373554601\n",
      "Iteration 5902 => Loss: 51.21380351423909615960\n",
      "Iteration 5903 => Loss: 51.21360200218476421696\n",
      "Iteration 5904 => Loss: 51.21340049175056208242\n",
      "Iteration 5905 => Loss: 51.21319898293645422882\n",
      "Iteration 5906 => Loss: 51.21299747574230565306\n",
      "Iteration 5907 => Loss: 51.21279597016804530085\n",
      "Iteration 5908 => Loss: 51.21259446621355237994\n",
      "Iteration 5909 => Loss: 51.21239296387875583605\n",
      "Iteration 5910 => Loss: 51.21219146316352777148\n",
      "Iteration 5911 => Loss: 51.21198996406779713197\n",
      "Iteration 5912 => Loss: 51.21178846659146444154\n",
      "Iteration 5913 => Loss: 51.21158697073443022418\n",
      "Iteration 5914 => Loss: 51.21138547649660210936\n",
      "Iteration 5915 => Loss: 51.21118398387786641024\n",
      "Iteration 5916 => Loss: 51.21098249287817338882\n",
      "Iteration 5917 => Loss: 51.21078100349737383112\n",
      "Iteration 5918 => Loss: 51.21057951573538247203\n",
      "Iteration 5919 => Loss: 51.21037802959212115184\n",
      "Iteration 5920 => Loss: 51.21017654506749749999\n",
      "Iteration 5921 => Loss: 51.20997506216139782964\n",
      "Iteration 5922 => Loss: 51.20977358087375108653\n",
      "Iteration 5923 => Loss: 51.20957210120445779467\n",
      "Iteration 5924 => Loss: 51.20937062315341137264\n",
      "Iteration 5925 => Loss: 51.20916914672051234447\n",
      "Iteration 5926 => Loss: 51.20896767190567544503\n",
      "Iteration 5927 => Loss: 51.20876619870883672547\n",
      "Iteration 5928 => Loss: 51.20856472712983986639\n",
      "Iteration 5929 => Loss: 51.20836325716866355151\n",
      "Iteration 5930 => Loss: 51.20816178882515146142\n",
      "Iteration 5931 => Loss: 51.20796032209924675271\n",
      "Iteration 5932 => Loss: 51.20775885699083573854\n",
      "Iteration 5933 => Loss: 51.20755739349984736464\n",
      "Iteration 5934 => Loss: 51.20735593162619636587\n",
      "Iteration 5935 => Loss: 51.20715447136977616083\n",
      "Iteration 5936 => Loss: 51.20695301273047306267\n",
      "Iteration 5937 => Loss: 51.20675155570821601714\n",
      "Iteration 5938 => Loss: 51.20655010030290554823\n",
      "Iteration 5939 => Loss: 51.20634864651448481254\n",
      "Iteration 5940 => Loss: 51.20614719434283301780\n",
      "Iteration 5941 => Loss: 51.20594574378783647717\n",
      "Iteration 5942 => Loss: 51.20574429484945255808\n",
      "Iteration 5943 => Loss: 51.20554284752752494114\n",
      "Iteration 5944 => Loss: 51.20534140182205362635\n",
      "Iteration 5945 => Loss: 51.20513995773288939972\n",
      "Iteration 5946 => Loss: 51.20493851525992567986\n",
      "Iteration 5947 => Loss: 51.20473707440312693961\n",
      "Iteration 5948 => Loss: 51.20453563516236528130\n",
      "Iteration 5949 => Loss: 51.20433419753756254522\n",
      "Iteration 5950 => Loss: 51.20413276152861214996\n",
      "Iteration 5951 => Loss: 51.20393132713546435753\n",
      "Iteration 5952 => Loss: 51.20372989435800548108\n",
      "Iteration 5953 => Loss: 51.20352846319612893922\n",
      "Iteration 5954 => Loss: 51.20332703364978499394\n",
      "Iteration 5955 => Loss: 51.20312560571883153671\n",
      "Iteration 5956 => Loss: 51.20292417940323304038\n",
      "Iteration 5957 => Loss: 51.20272275470286871268\n",
      "Iteration 5958 => Loss: 51.20252133161767460479\n",
      "Iteration 5959 => Loss: 51.20231991014754413527\n",
      "Iteration 5960 => Loss: 51.20211849029239203901\n",
      "Iteration 5961 => Loss: 51.20191707205214726173\n",
      "Iteration 5962 => Loss: 51.20171565542670322202\n",
      "Iteration 5963 => Loss: 51.20151424041596044390\n",
      "Iteration 5964 => Loss: 51.20131282701985497852\n",
      "Iteration 5965 => Loss: 51.20111141523830866618\n",
      "Iteration 5966 => Loss: 51.20091000507121492547\n",
      "Iteration 5967 => Loss: 51.20070859651848849126\n",
      "Iteration 5968 => Loss: 51.20050718958002988757\n",
      "Iteration 5969 => Loss: 51.20030578425580358726\n",
      "Iteration 5970 => Loss: 51.20010438054565327093\n",
      "Iteration 5971 => Loss: 51.19990297844953630602\n",
      "Iteration 5972 => Loss: 51.19970157796738874367\n",
      "Iteration 5973 => Loss: 51.19950017909906136993\n",
      "Iteration 5974 => Loss: 51.19929878184453286849\n",
      "Iteration 5975 => Loss: 51.19909738620366113082\n",
      "Iteration 5976 => Loss: 51.19889599217640352435\n",
      "Iteration 5977 => Loss: 51.19869459976263925682\n",
      "Iteration 5978 => Loss: 51.19849320896230437938\n",
      "Iteration 5979 => Loss: 51.19829181977529941605\n",
      "Iteration 5980 => Loss: 51.19809043220158173426\n",
      "Iteration 5981 => Loss: 51.19788904624101633090\n",
      "Iteration 5982 => Loss: 51.19768766189356057339\n",
      "Iteration 5983 => Loss: 51.19748627915907945862\n",
      "Iteration 5984 => Loss: 51.19728489803757298660\n",
      "Iteration 5985 => Loss: 51.19708351852887062705\n",
      "Iteration 5986 => Loss: 51.19688214063290132572\n",
      "Iteration 5987 => Loss: 51.19668076434961534460\n",
      "Iteration 5988 => Loss: 51.19647938967893452400\n",
      "Iteration 5989 => Loss: 51.19627801662073096622\n",
      "Iteration 5990 => Loss: 51.19607664517495493328\n",
      "Iteration 5991 => Loss: 51.19587527534154958175\n",
      "Iteration 5992 => Loss: 51.19567390712033727596\n",
      "Iteration 5993 => Loss: 51.19547254051133222674\n",
      "Iteration 5994 => Loss: 51.19527117551442074728\n",
      "Iteration 5995 => Loss: 51.19506981212950336158\n",
      "Iteration 5996 => Loss: 51.19486845035651612079\n",
      "Iteration 5997 => Loss: 51.19466709019536665437\n",
      "Iteration 5998 => Loss: 51.19446573164597680261\n",
      "Iteration 5999 => Loss: 51.19426437470827551124\n",
      "Iteration 6000 => Loss: 51.19406301938217040970\n",
      "Iteration 6001 => Loss: 51.19386166566757623286\n",
      "Iteration 6002 => Loss: 51.19366031356440771560\n",
      "Iteration 6003 => Loss: 51.19345896307262222535\n",
      "Iteration 6004 => Loss: 51.19325761419209186442\n",
      "Iteration 6005 => Loss: 51.19305626692273847311\n",
      "Iteration 6006 => Loss: 51.19285492126451941886\n",
      "Iteration 6007 => Loss: 51.19265357721733522567\n",
      "Iteration 6008 => Loss: 51.19245223478108641757\n",
      "Iteration 6009 => Loss: 51.19225089395570194029\n",
      "Iteration 6010 => Loss: 51.19204955474111784497\n",
      "Iteration 6011 => Loss: 51.19184821713724176107\n",
      "Iteration 6012 => Loss: 51.19164688114400263430\n",
      "Iteration 6013 => Loss: 51.19144554676132941040\n",
      "Iteration 6014 => Loss: 51.19124421398909419167\n",
      "Iteration 6015 => Loss: 51.19104288282726855641\n",
      "Iteration 6016 => Loss: 51.19084155327575302863\n",
      "Iteration 6017 => Loss: 51.19064022533446234320\n",
      "Iteration 6018 => Loss: 51.19043889900333965670\n",
      "Iteration 6019 => Loss: 51.19023757428229259858\n",
      "Iteration 6020 => Loss: 51.19003625117125011457\n",
      "Iteration 6021 => Loss: 51.18983492967012693953\n",
      "Iteration 6022 => Loss: 51.18963360977883070291\n",
      "Iteration 6023 => Loss: 51.18943229149729745586\n",
      "Iteration 6024 => Loss: 51.18923097482546324954\n",
      "Iteration 6025 => Loss: 51.18902965976322150254\n",
      "Iteration 6026 => Loss: 51.18882834631052958230\n",
      "Iteration 6027 => Loss: 51.18862703446728090739\n",
      "Iteration 6028 => Loss: 51.18842572423340442356\n",
      "Iteration 6029 => Loss: 51.18822441560880065481\n",
      "Iteration 6030 => Loss: 51.18802310859346249572\n",
      "Iteration 6031 => Loss: 51.18782180318726204860\n",
      "Iteration 6032 => Loss: 51.18762049939009983746\n",
      "Iteration 6033 => Loss: 51.18741919720194033516\n",
      "Iteration 6034 => Loss: 51.18721789662269827659\n",
      "Iteration 6035 => Loss: 51.18701659765228839660\n",
      "Iteration 6036 => Loss: 51.18681530029063964093\n",
      "Iteration 6037 => Loss: 51.18661400453767384988\n",
      "Iteration 6038 => Loss: 51.18641271039331996917\n",
      "Iteration 6039 => Loss: 51.18621141785749273367\n",
      "Iteration 6040 => Loss: 51.18601012693013529997\n",
      "Iteration 6041 => Loss: 51.18580883761115529751\n",
      "Iteration 6042 => Loss: 51.18560754990047456658\n",
      "Iteration 6043 => Loss: 51.18540626379801494750\n",
      "Iteration 6044 => Loss: 51.18520497930373380768\n",
      "Iteration 6045 => Loss: 51.18500369641751746030\n",
      "Iteration 6046 => Loss: 51.18480241513930906194\n",
      "Iteration 6047 => Loss: 51.18460113546903045290\n",
      "Iteration 6048 => Loss: 51.18439985740661057889\n",
      "Iteration 6049 => Loss: 51.18419858095196417480\n",
      "Iteration 6050 => Loss: 51.18399730610504150263\n",
      "Iteration 6051 => Loss: 51.18379603286574308640\n",
      "Iteration 6052 => Loss: 51.18359476123400497727\n",
      "Iteration 6053 => Loss: 51.18339349120974191010\n",
      "Iteration 6054 => Loss: 51.18319222279289704147\n",
      "Iteration 6055 => Loss: 51.18299095598338510626\n",
      "Iteration 6056 => Loss: 51.18278969078115636648\n",
      "Iteration 6057 => Loss: 51.18258842718610424072\n",
      "Iteration 6058 => Loss: 51.18238716519815056927\n",
      "Iteration 6059 => Loss: 51.18218590481726693042\n",
      "Iteration 6060 => Loss: 51.18198464604333963734\n",
      "Iteration 6061 => Loss: 51.18178338887631895204\n",
      "Iteration 6062 => Loss: 51.18158213331611960939\n",
      "Iteration 6063 => Loss: 51.18138087936267766054\n",
      "Iteration 6064 => Loss: 51.18117962701589362950\n",
      "Iteration 6065 => Loss: 51.18097837627575330544\n",
      "Iteration 6066 => Loss: 51.18077712714213589607\n",
      "Iteration 6067 => Loss: 51.18057587961498455797\n",
      "Iteration 6068 => Loss: 51.18037463369419981518\n",
      "Iteration 6069 => Loss: 51.18017338937975324598\n",
      "Iteration 6070 => Loss: 51.17997214667156669066\n",
      "Iteration 6071 => Loss: 51.17977090556954067324\n",
      "Iteration 6072 => Loss: 51.17956966607360413946\n",
      "Iteration 6073 => Loss: 51.17936842818374287845\n",
      "Iteration 6074 => Loss: 51.17916719189981478166\n",
      "Iteration 6075 => Loss: 51.17896595722180563826\n",
      "Iteration 6076 => Loss: 51.17876472414958044510\n",
      "Iteration 6077 => Loss: 51.17856349268312499134\n",
      "Iteration 6078 => Loss: 51.17836226282233980101\n",
      "Iteration 6079 => Loss: 51.17816103456717513609\n",
      "Iteration 6080 => Loss: 51.17795980791755283690\n",
      "Iteration 6081 => Loss: 51.17775858287338763830\n",
      "Iteration 6082 => Loss: 51.17755735943462269688\n",
      "Iteration 6083 => Loss: 51.17735613760119406379\n",
      "Iteration 6084 => Loss: 51.17715491737300936848\n",
      "Iteration 6085 => Loss: 51.17695369875001887294\n",
      "Iteration 6086 => Loss: 51.17675248173214441749\n",
      "Iteration 6087 => Loss: 51.17655126631932915870\n",
      "Iteration 6088 => Loss: 51.17635005251148072603\n",
      "Iteration 6089 => Loss: 51.17614884030855648689\n",
      "Iteration 6090 => Loss: 51.17594762971045696531\n",
      "Iteration 6091 => Loss: 51.17574642071713242331\n",
      "Iteration 6092 => Loss: 51.17554521332853312288\n",
      "Iteration 6093 => Loss: 51.17534400754454537719\n",
      "Iteration 6094 => Loss: 51.17514280336512655367\n",
      "Iteration 6095 => Loss: 51.17494160079020559806\n",
      "Iteration 6096 => Loss: 51.17474039981971145608\n",
      "Iteration 6097 => Loss: 51.17453920045358017887\n",
      "Iteration 6098 => Loss: 51.17433800269175492303\n",
      "Iteration 6099 => Loss: 51.17413680653414331800\n",
      "Iteration 6100 => Loss: 51.17393561198070273122\n",
      "Iteration 6101 => Loss: 51.17373441903131947583\n",
      "Iteration 6102 => Loss: 51.17353322768597223558\n",
      "Iteration 6103 => Loss: 51.17333203794459706160\n",
      "Iteration 6104 => Loss: 51.17313084980708026706\n",
      "Iteration 6105 => Loss: 51.17292966327340764110\n",
      "Iteration 6106 => Loss: 51.17272847834347260232\n",
      "Iteration 6107 => Loss: 51.17252729501721120187\n",
      "Iteration 6108 => Loss: 51.17232611329460212346\n",
      "Iteration 6109 => Loss: 51.17212493317551746941\n",
      "Iteration 6110 => Loss: 51.17192375465991460715\n",
      "Iteration 6111 => Loss: 51.17172257774773669325\n",
      "Iteration 6112 => Loss: 51.17152140243890556803\n",
      "Iteration 6113 => Loss: 51.17132022873336438806\n",
      "Iteration 6114 => Loss: 51.17111905663104209907\n",
      "Iteration 6115 => Loss: 51.17091788613189606849\n",
      "Iteration 6116 => Loss: 51.17071671723579129321\n",
      "Iteration 6117 => Loss: 51.17051554994272777321\n",
      "Iteration 6118 => Loss: 51.17031438425263445424\n",
      "Iteration 6119 => Loss: 51.17011322016539764945\n",
      "Iteration 6120 => Loss: 51.16991205768101025342\n",
      "Iteration 6121 => Loss: 51.16971089679937989558\n",
      "Iteration 6122 => Loss: 51.16950973752042131082\n",
      "Iteration 6123 => Loss: 51.16930857984410607742\n",
      "Iteration 6124 => Loss: 51.16910742377034182482\n",
      "Iteration 6125 => Loss: 51.16890626929908592047\n",
      "Iteration 6126 => Loss: 51.16870511643028152093\n",
      "Iteration 6127 => Loss: 51.16850396516382204481\n",
      "Iteration 6128 => Loss: 51.16830281549966485954\n",
      "Iteration 6129 => Loss: 51.16810166743776733256\n",
      "Iteration 6130 => Loss: 51.16790052097802288245\n",
      "Iteration 6131 => Loss: 51.16769937612040308750\n",
      "Iteration 6132 => Loss: 51.16749823286482268259\n",
      "Iteration 6133 => Loss: 51.16729709121122482429\n",
      "Iteration 6134 => Loss: 51.16709595115953845834\n",
      "Iteration 6135 => Loss: 51.16689481270972805760\n",
      "Iteration 6136 => Loss: 51.16669367586169414608\n",
      "Iteration 6137 => Loss: 51.16649254061538698579\n",
      "Iteration 6138 => Loss: 51.16629140697074973332\n",
      "Iteration 6139 => Loss: 51.16609027492771133439\n",
      "Iteration 6140 => Loss: 51.16588914448620784015\n",
      "Iteration 6141 => Loss: 51.16568801564616819633\n",
      "Iteration 6142 => Loss: 51.16548688840755687579\n",
      "Iteration 6143 => Loss: 51.16528576277026019170\n",
      "Iteration 6144 => Loss: 51.16508463873428524948\n",
      "Iteration 6145 => Loss: 51.16488351629953967858\n",
      "Iteration 6146 => Loss: 51.16468239546593821387\n",
      "Iteration 6147 => Loss: 51.16448127623344532822\n",
      "Iteration 6148 => Loss: 51.16428015860196865106\n",
      "Iteration 6149 => Loss: 51.16407904257146554983\n",
      "Iteration 6150 => Loss: 51.16387792814190049739\n",
      "Iteration 6151 => Loss: 51.16367681531315980692\n",
      "Iteration 6152 => Loss: 51.16347570408522926755\n",
      "Iteration 6153 => Loss: 51.16327459445798808702\n",
      "Iteration 6154 => Loss: 51.16307348643142205447\n",
      "Iteration 6155 => Loss: 51.16287238000547432648\n",
      "Iteration 6156 => Loss: 51.16267127518003832165\n",
      "Iteration 6157 => Loss: 51.16247017195512114540\n",
      "Iteration 6158 => Loss: 51.16226907033060200547\n",
      "Iteration 6159 => Loss: 51.16206797030645248014\n",
      "Iteration 6160 => Loss: 51.16186687188258019887\n",
      "Iteration 6161 => Loss: 51.16166577505895673994\n",
      "Iteration 6162 => Loss: 51.16146467983548973280\n",
      "Iteration 6163 => Loss: 51.16126358621213654487\n",
      "Iteration 6164 => Loss: 51.16106249418884033275\n",
      "Iteration 6165 => Loss: 51.16086140376555846387\n",
      "Iteration 6166 => Loss: 51.16066031494219856768\n",
      "Iteration 6167 => Loss: 51.16045922771868958989\n",
      "Iteration 6168 => Loss: 51.16025814209501021423\n",
      "Iteration 6169 => Loss: 51.16005705807107517558\n",
      "Iteration 6170 => Loss: 51.15985597564683473593\n",
      "Iteration 6171 => Loss: 51.15965489482221784101\n",
      "Iteration 6172 => Loss: 51.15945381559717475284\n",
      "Iteration 6173 => Loss: 51.15925273797166283885\n",
      "Iteration 6174 => Loss: 51.15905166194558262305\n",
      "Iteration 6175 => Loss: 51.15885058751889147288\n",
      "Iteration 6176 => Loss: 51.15864951469155386121\n",
      "Iteration 6177 => Loss: 51.15844844346346320663\n",
      "Iteration 6178 => Loss: 51.15824737383460529827\n",
      "Iteration 6179 => Loss: 51.15804630580489487102\n",
      "Iteration 6180 => Loss: 51.15784523937428929230\n",
      "Iteration 6181 => Loss: 51.15764417454272461327\n",
      "Iteration 6182 => Loss: 51.15744311131012977967\n",
      "Iteration 6183 => Loss: 51.15724204967646926434\n",
      "Iteration 6184 => Loss: 51.15704098964165069674\n",
      "Iteration 6185 => Loss: 51.15683993120564565515\n",
      "Iteration 6186 => Loss: 51.15663887436837597988\n",
      "Iteration 6187 => Loss: 51.15643781912980614379\n",
      "Iteration 6188 => Loss: 51.15623676548985088175\n",
      "Iteration 6189 => Loss: 51.15603571344848887748\n",
      "Iteration 6190 => Loss: 51.15583466300560644413\n",
      "Iteration 6191 => Loss: 51.15563361416121779257\n",
      "Iteration 6192 => Loss: 51.15543256691520213053\n",
      "Iteration 6193 => Loss: 51.15523152126753814173\n",
      "Iteration 6194 => Loss: 51.15503047721814056104\n",
      "Iteration 6195 => Loss: 51.15482943476697386131\n",
      "Iteration 6196 => Loss: 51.15462839391397409372\n",
      "Iteration 6197 => Loss: 51.15442735465909152026\n",
      "Iteration 6198 => Loss: 51.15422631700226219209\n",
      "Iteration 6199 => Loss: 51.15402528094340794951\n",
      "Iteration 6200 => Loss: 51.15382424648252168708\n",
      "Iteration 6201 => Loss: 51.15362321361948971798\n",
      "Iteration 6202 => Loss: 51.15342218235430493678\n",
      "Iteration 6203 => Loss: 51.15322115268688207834\n",
      "Iteration 6204 => Loss: 51.15302012461717851011\n",
      "Iteration 6205 => Loss: 51.15281909814510896695\n",
      "Iteration 6206 => Loss: 51.15261807327064502715\n",
      "Iteration 6207 => Loss: 51.15241704999372984730\n",
      "Iteration 6208 => Loss: 51.15221602831430658398\n",
      "Iteration 6209 => Loss: 51.15201500823230418291\n",
      "Iteration 6210 => Loss: 51.15181398974767290611\n",
      "Iteration 6211 => Loss: 51.15161297286036301557\n",
      "Iteration 6212 => Loss: 51.15141195757033898417\n",
      "Iteration 6213 => Loss: 51.15121094387747291421\n",
      "Iteration 6214 => Loss: 51.15100993178180033283\n",
      "Iteration 6215 => Loss: 51.15080892128322176404\n",
      "Iteration 6216 => Loss: 51.15060791238167325901\n",
      "Iteration 6217 => Loss: 51.15040690507711218515\n",
      "Iteration 6218 => Loss: 51.15020589936946748821\n",
      "Iteration 6219 => Loss: 51.15000489525871074648\n",
      "Iteration 6220 => Loss: 51.14980389274477801109\n",
      "Iteration 6221 => Loss: 51.14960289182760533322\n",
      "Iteration 6222 => Loss: 51.14940189250712876401\n",
      "Iteration 6223 => Loss: 51.14920089478331277633\n",
      "Iteration 6224 => Loss: 51.14899989865610763218\n",
      "Iteration 6225 => Loss: 51.14879890412544227729\n",
      "Iteration 6226 => Loss: 51.14859791119130250081\n",
      "Iteration 6227 => Loss: 51.14839691985353198334\n",
      "Iteration 6228 => Loss: 51.14819593011220177914\n",
      "Iteration 6229 => Loss: 51.14799494196716977967\n",
      "Iteration 6230 => Loss: 51.14779395541841466866\n",
      "Iteration 6231 => Loss: 51.14759297046590091895\n",
      "Iteration 6232 => Loss: 51.14739198710952905458\n",
      "Iteration 6233 => Loss: 51.14719100534928486468\n",
      "Iteration 6234 => Loss: 51.14699002518510440041\n",
      "Iteration 6235 => Loss: 51.14678904661692371292\n",
      "Iteration 6236 => Loss: 51.14658806964466464251\n",
      "Iteration 6237 => Loss: 51.14638709426834140004\n",
      "Iteration 6238 => Loss: 51.14618612048784029867\n",
      "Iteration 6239 => Loss: 51.14598514830314712754\n",
      "Iteration 6240 => Loss: 51.14578417771419793780\n",
      "Iteration 6241 => Loss: 51.14558320872090746434\n",
      "Iteration 6242 => Loss: 51.14538224132327570715\n",
      "Iteration 6243 => Loss: 51.14518127552122450652\n",
      "Iteration 6244 => Loss: 51.14498031131466859733\n",
      "Iteration 6245 => Loss: 51.14477934870360087416\n",
      "Iteration 6246 => Loss: 51.14457838768795738815\n",
      "Iteration 6247 => Loss: 51.14437742826767419047\n",
      "Iteration 6248 => Loss: 51.14417647044272285939\n",
      "Iteration 6249 => Loss: 51.14397551421302523522\n",
      "Iteration 6250 => Loss: 51.14377455957853157997\n",
      "Iteration 6251 => Loss: 51.14357360653921347193\n",
      "Iteration 6252 => Loss: 51.14337265509499275140\n",
      "Iteration 6253 => Loss: 51.14317170524583389124\n",
      "Iteration 6254 => Loss: 51.14297075699166583718\n",
      "Iteration 6255 => Loss: 51.14276981033246016750\n",
      "Iteration 6256 => Loss: 51.14256886526815293337\n",
      "Iteration 6257 => Loss: 51.14236792179868018593\n",
      "Iteration 6258 => Loss: 51.14216697992400639805\n",
      "Iteration 6259 => Loss: 51.14196603964408893717\n",
      "Iteration 6260 => Loss: 51.14176510095884253815\n",
      "Iteration 6261 => Loss: 51.14156416386825299014\n",
      "Iteration 6262 => Loss: 51.14136322837226344973\n",
      "Iteration 6263 => Loss: 51.14116229447080996806\n",
      "Iteration 6264 => Loss: 51.14096136216382149087\n",
      "Iteration 6265 => Loss: 51.14076043145127670186\n",
      "Iteration 6266 => Loss: 51.14055950233312586306\n",
      "Iteration 6267 => Loss: 51.14035857480930502561\n",
      "Iteration 6268 => Loss: 51.14015764887977155695\n",
      "Iteration 6269 => Loss: 51.13995672454448992994\n",
      "Iteration 6270 => Loss: 51.13975580180333935232\n",
      "Iteration 6271 => Loss: 51.13955488065636245665\n",
      "Iteration 6272 => Loss: 51.13935396110345266152\n",
      "Iteration 6273 => Loss: 51.13915304314458865065\n",
      "Iteration 6274 => Loss: 51.13895212677970647519\n",
      "Iteration 6275 => Loss: 51.13875121200873508087\n",
      "Iteration 6276 => Loss: 51.13855029883165315141\n",
      "Iteration 6277 => Loss: 51.13834938724842515967\n",
      "Iteration 6278 => Loss: 51.13814847725895873509\n",
      "Iteration 6279 => Loss: 51.13794756886323256140\n",
      "Iteration 6280 => Loss: 51.13774666206115426803\n",
      "Iteration 6281 => Loss: 51.13754575685273096042\n",
      "Iteration 6282 => Loss: 51.13734485323789158429\n",
      "Iteration 6283 => Loss: 51.13714395121657929622\n",
      "Iteration 6284 => Loss: 51.13694305078875146364\n",
      "Iteration 6285 => Loss: 51.13674215195436545400\n",
      "Iteration 6286 => Loss: 51.13654125471335021302\n",
      "Iteration 6287 => Loss: 51.13634035906569152985\n",
      "Iteration 6288 => Loss: 51.13613946501128992850\n",
      "Iteration 6289 => Loss: 51.13593857255014540897\n",
      "Iteration 6290 => Loss: 51.13573768168217981156\n",
      "Iteration 6291 => Loss: 51.13553679240735050371\n",
      "Iteration 6292 => Loss: 51.13533590472562906371\n",
      "Iteration 6293 => Loss: 51.13513501863693733185\n",
      "Iteration 6294 => Loss: 51.13493413414122557015\n",
      "Iteration 6295 => Loss: 51.13473325123848667317\n",
      "Iteration 6296 => Loss: 51.13453236992862827037\n",
      "Iteration 6297 => Loss: 51.13433149021160772918\n",
      "Iteration 6298 => Loss: 51.13413061208739662789\n",
      "Iteration 6299 => Loss: 51.13392973555593812307\n",
      "Iteration 6300 => Loss: 51.13372886061718958217\n",
      "Iteration 6301 => Loss: 51.13352798727108705634\n",
      "Iteration 6302 => Loss: 51.13332711551760212387\n",
      "Iteration 6303 => Loss: 51.13312624535664951964\n",
      "Iteration 6304 => Loss: 51.13292537678821503278\n",
      "Iteration 6305 => Loss: 51.13272450981227024158\n",
      "Iteration 6306 => Loss: 51.13252364442872277550\n",
      "Iteration 6307 => Loss: 51.13232278063753710740\n",
      "Iteration 6308 => Loss: 51.13212191843867771013\n",
      "Iteration 6309 => Loss: 51.13192105783209484571\n",
      "Iteration 6310 => Loss: 51.13172019881772456529\n",
      "Iteration 6311 => Loss: 51.13151934139555976344\n",
      "Iteration 6312 => Loss: 51.13131848556549385876\n",
      "Iteration 6313 => Loss: 51.13111763132752685124\n",
      "Iteration 6314 => Loss: 51.13091677868160189746\n",
      "Iteration 6315 => Loss: 51.13071592762765504858\n",
      "Iteration 6316 => Loss: 51.13051507816565788289\n",
      "Iteration 6317 => Loss: 51.13031423029556066240\n",
      "Iteration 6318 => Loss: 51.13011338401730654368\n",
      "Iteration 6319 => Loss: 51.12991253933085289418\n",
      "Iteration 6320 => Loss: 51.12971169623613576505\n",
      "Iteration 6321 => Loss: 51.12951085473316226171\n",
      "Iteration 6322 => Loss: 51.12931001482184001361\n",
      "Iteration 6323 => Loss: 51.12910917650213349361\n",
      "Iteration 6324 => Loss: 51.12890833977399296373\n",
      "Iteration 6325 => Loss: 51.12870750463739710767\n",
      "Iteration 6326 => Loss: 51.12850667109226776574\n",
      "Iteration 6327 => Loss: 51.12830583913854098910\n",
      "Iteration 6328 => Loss: 51.12810500877622388316\n",
      "Iteration 6329 => Loss: 51.12790418000525960451\n",
      "Iteration 6330 => Loss: 51.12770335282555578260\n",
      "Iteration 6331 => Loss: 51.12750252723712662828\n",
      "Iteration 6332 => Loss: 51.12730170323989398184\n",
      "Iteration 6333 => Loss: 51.12710088083380810531\n",
      "Iteration 6334 => Loss: 51.12690006001881926068\n",
      "Iteration 6335 => Loss: 51.12669924079494165881\n",
      "Iteration 6336 => Loss: 51.12649842316206871828\n",
      "Iteration 6337 => Loss: 51.12629760712014359569\n",
      "Iteration 6338 => Loss: 51.12609679266916629103\n",
      "Iteration 6339 => Loss: 51.12589597980904443375\n",
      "Iteration 6340 => Loss: 51.12569516853981355098\n",
      "Iteration 6341 => Loss: 51.12549435886135995588\n",
      "Iteration 6342 => Loss: 51.12529355077364101589\n",
      "Iteration 6343 => Loss: 51.12509274427662830931\n",
      "Iteration 6344 => Loss: 51.12489193937027920356\n",
      "Iteration 6345 => Loss: 51.12469113605453685523\n",
      "Iteration 6346 => Loss: 51.12449033432935863175\n",
      "Iteration 6347 => Loss: 51.12428953419471611141\n",
      "Iteration 6348 => Loss: 51.12408873565055245081\n",
      "Iteration 6349 => Loss: 51.12388793869681080650\n",
      "Iteration 6350 => Loss: 51.12368714333347696765\n",
      "Iteration 6351 => Loss: 51.12348634956048698541\n",
      "Iteration 6352 => Loss: 51.12328555737781243806\n",
      "Iteration 6353 => Loss: 51.12308476678538937676\n",
      "Iteration 6354 => Loss: 51.12288397778316095810\n",
      "Iteration 6355 => Loss: 51.12268319037109876035\n",
      "Iteration 6356 => Loss: 51.12248240454920988896\n",
      "Iteration 6357 => Loss: 51.12228162031735934079\n",
      "Iteration 6358 => Loss: 51.12208083767556132671\n",
      "Iteration 6359 => Loss: 51.12188005662374479243\n",
      "Iteration 6360 => Loss: 51.12167927716188842169\n",
      "Iteration 6361 => Loss: 51.12147849928995668733\n",
      "Iteration 6362 => Loss: 51.12127772300787142967\n",
      "Iteration 6363 => Loss: 51.12107694831561133242\n",
      "Iteration 6364 => Loss: 51.12087617521313376301\n",
      "Iteration 6365 => Loss: 51.12067540370037477260\n",
      "Iteration 6366 => Loss: 51.12047463377730593947\n",
      "Iteration 6367 => Loss: 51.12027386544387042022\n",
      "Iteration 6368 => Loss: 51.12007309870005400398\n",
      "Iteration 6369 => Loss: 51.11987233354581405820\n",
      "Iteration 6370 => Loss: 51.11967156998107242316\n",
      "Iteration 6371 => Loss: 51.11947080800580778259\n",
      "Iteration 6372 => Loss: 51.11927004761997039850\n",
      "Iteration 6373 => Loss: 51.11906928882351763832\n",
      "Iteration 6374 => Loss: 51.11886853161642108034\n",
      "Iteration 6375 => Loss: 51.11866777599863098658\n",
      "Iteration 6376 => Loss: 51.11846702197007630275\n",
      "Iteration 6377 => Loss: 51.11826626953075702886\n",
      "Iteration 6378 => Loss: 51.11806551868061632149\n",
      "Iteration 6379 => Loss: 51.11786476941959733722\n",
      "Iteration 6380 => Loss: 51.11766402174766454891\n",
      "Iteration 6381 => Loss: 51.11746327566481085114\n",
      "Iteration 6382 => Loss: 51.11726253117092966249\n",
      "Iteration 6383 => Loss: 51.11706178826603519383\n",
      "Iteration 6384 => Loss: 51.11686104695003507459\n",
      "Iteration 6385 => Loss: 51.11666030722292930477\n",
      "Iteration 6386 => Loss: 51.11645956908467525182\n",
      "Iteration 6387 => Loss: 51.11625883253518054516\n",
      "Iteration 6388 => Loss: 51.11605809757447360653\n",
      "Iteration 6389 => Loss: 51.11585736420246206535\n",
      "Iteration 6390 => Loss: 51.11565663241911039449\n",
      "Iteration 6391 => Loss: 51.11545590222439017225\n",
      "Iteration 6392 => Loss: 51.11525517361827297691\n",
      "Iteration 6393 => Loss: 51.11505444660070196505\n",
      "Iteration 6394 => Loss: 51.11485372117161318783\n",
      "Iteration 6395 => Loss: 51.11465299733098532897\n",
      "Iteration 6396 => Loss: 51.11445227507880417761\n",
      "Iteration 6397 => Loss: 51.11425155441498446862\n",
      "Iteration 6398 => Loss: 51.11405083533950488572\n",
      "Iteration 6399 => Loss: 51.11385011785232279635\n",
      "Iteration 6400 => Loss: 51.11364940195339556794\n",
      "Iteration 6401 => Loss: 51.11344868764268767336\n",
      "Iteration 6402 => Loss: 51.11324797492014226918\n",
      "Iteration 6403 => Loss: 51.11304726378575224999\n",
      "Iteration 6404 => Loss: 51.11284655423943945607\n",
      "Iteration 6405 => Loss: 51.11264584628118257115\n",
      "Iteration 6406 => Loss: 51.11244513991091054095\n",
      "Iteration 6407 => Loss: 51.11224443512863047090\n",
      "Iteration 6408 => Loss: 51.11204373193429262301\n",
      "Iteration 6409 => Loss: 51.11184303032784015386\n",
      "Iteration 6410 => Loss: 51.11164233030920911460\n",
      "Iteration 6411 => Loss: 51.11144163187839239981\n",
      "Iteration 6412 => Loss: 51.11124093503535448235\n",
      "Iteration 6413 => Loss: 51.11104023978004562423\n",
      "Iteration 6414 => Loss: 51.11083954611242319288\n",
      "Iteration 6415 => Loss: 51.11063885403243745031\n",
      "Iteration 6416 => Loss: 51.11043816354007418568\n",
      "Iteration 6417 => Loss: 51.11023747463526234469\n",
      "Iteration 6418 => Loss: 51.11003678731798061108\n",
      "Iteration 6419 => Loss: 51.10983610158818635227\n",
      "Iteration 6420 => Loss: 51.10963541744583693571\n",
      "Iteration 6421 => Loss: 51.10943473489089683426\n",
      "Iteration 6422 => Loss: 51.10923405392332341535\n",
      "Iteration 6423 => Loss: 51.10903337454308115184\n",
      "Iteration 6424 => Loss: 51.10883269675013451661\n",
      "Iteration 6425 => Loss: 51.10863202054440534994\n",
      "Iteration 6426 => Loss: 51.10843134592590786269\n",
      "Iteration 6427 => Loss: 51.10823067289459231688\n",
      "Iteration 6428 => Loss: 51.10803000145039476365\n",
      "Iteration 6429 => Loss: 51.10782933159326546502\n",
      "Iteration 6430 => Loss: 51.10762866332321152640\n",
      "Iteration 6431 => Loss: 51.10742799664016189354\n",
      "Iteration 6432 => Loss: 51.10722733154410946099\n",
      "Iteration 6433 => Loss: 51.10702666803494054193\n",
      "Iteration 6434 => Loss: 51.10682600611271908519\n",
      "Iteration 6435 => Loss: 51.10662534577731719310\n",
      "Iteration 6436 => Loss: 51.10642468702873486563\n",
      "Iteration 6437 => Loss: 51.10622402986696499738\n",
      "Iteration 6438 => Loss: 51.10602337429190811235\n",
      "Iteration 6439 => Loss: 51.10582272030355710513\n",
      "Iteration 6440 => Loss: 51.10562206790186223770\n",
      "Iteration 6441 => Loss: 51.10542141708678798295\n",
      "Iteration 6442 => Loss: 51.10522076785831302459\n",
      "Iteration 6443 => Loss: 51.10502012021635920291\n",
      "Iteration 6444 => Loss: 51.10481947416094072878\n",
      "Iteration 6445 => Loss: 51.10461882969197944249\n",
      "Iteration 6446 => Loss: 51.10441818680944692233\n",
      "Iteration 6447 => Loss: 51.10421754551331474659\n",
      "Iteration 6448 => Loss: 51.10401690580353317728\n",
      "Iteration 6449 => Loss: 51.10381626768006668726\n",
      "Iteration 6450 => Loss: 51.10361563114285843312\n",
      "Iteration 6451 => Loss: 51.10341499619191552028\n",
      "Iteration 6452 => Loss: 51.10321436282718821076\n",
      "Iteration 6453 => Loss: 51.10301373104859123941\n",
      "Iteration 6454 => Loss: 51.10281310085616013339\n",
      "Iteration 6455 => Loss: 51.10261247224978120585\n",
      "Iteration 6456 => Loss: 51.10241184522946866764\n",
      "Iteration 6457 => Loss: 51.10221121979517278078\n",
      "Iteration 6458 => Loss: 51.10201059594684380727\n",
      "Iteration 6459 => Loss: 51.10180997368444621998\n",
      "Iteration 6460 => Loss: 51.10160935300795159719\n",
      "Iteration 6461 => Loss: 51.10140873391733862263\n",
      "Iteration 6462 => Loss: 51.10120811641254334745\n",
      "Iteration 6463 => Loss: 51.10100750049352313908\n",
      "Iteration 6464 => Loss: 51.10080688616026378668\n",
      "Iteration 6465 => Loss: 51.10060627341270134139\n",
      "Iteration 6466 => Loss: 51.10040566225082159235\n",
      "Iteration 6467 => Loss: 51.10020505267458901244\n",
      "Iteration 6468 => Loss: 51.10000444468396807451\n",
      "Iteration 6469 => Loss: 51.09980383827888772430\n",
      "Iteration 6470 => Loss: 51.09960323345935506723\n",
      "Iteration 6471 => Loss: 51.09940263022530615444\n",
      "Iteration 6472 => Loss: 51.09920202857670545882\n",
      "Iteration 6473 => Loss: 51.09900142851353166407\n",
      "Iteration 6474 => Loss: 51.09880083003572792677\n",
      "Iteration 6475 => Loss: 51.09860023314327293065\n",
      "Iteration 6476 => Loss: 51.09839963783613114856\n",
      "Iteration 6477 => Loss: 51.09819904411423863166\n",
      "Iteration 6478 => Loss: 51.09799845197760248539\n",
      "Iteration 6479 => Loss: 51.09779786142615876088\n",
      "Iteration 6480 => Loss: 51.09759727245987903643\n",
      "Iteration 6481 => Loss: 51.09739668507870646863\n",
      "Iteration 6482 => Loss: 51.09719609928263395204\n",
      "Iteration 6483 => Loss: 51.09699551507160464325\n",
      "Iteration 6484 => Loss: 51.09679493244560433141\n",
      "Iteration 6485 => Loss: 51.09659435140457617308\n",
      "Iteration 6486 => Loss: 51.09639377194849174657\n",
      "Iteration 6487 => Loss: 51.09619319407732973559\n",
      "Iteration 6488 => Loss: 51.09599261779099776959\n",
      "Iteration 6489 => Loss: 51.09579204308953848113\n",
      "Iteration 6490 => Loss: 51.09559146997284528879\n",
      "Iteration 6491 => Loss: 51.09539089844093240345\n",
      "Iteration 6492 => Loss: 51.09519032849375719252\n",
      "Iteration 6493 => Loss: 51.09498976013126281259\n",
      "Iteration 6494 => Loss: 51.09478919335342084196\n",
      "Iteration 6495 => Loss: 51.09458862816022417519\n",
      "Iteration 6496 => Loss: 51.09438806455157333630\n",
      "Iteration 6497 => Loss: 51.09418750252751095786\n",
      "Iteration 6498 => Loss: 51.09398694208793045846\n",
      "Iteration 6499 => Loss: 51.09378638323282473266\n",
      "Iteration 6500 => Loss: 51.09358582596217246419\n",
      "Iteration 6501 => Loss: 51.09338527027593102048\n",
      "Iteration 6502 => Loss: 51.09318471617405066354\n",
      "Iteration 6503 => Loss: 51.09298416365652428794\n",
      "Iteration 6504 => Loss: 51.09278361272328794485\n",
      "Iteration 6505 => Loss: 51.09258306337430610711\n",
      "Iteration 6506 => Loss: 51.09238251560957877473\n",
      "Iteration 6507 => Loss: 51.09218196942903489344\n",
      "Iteration 6508 => Loss: 51.09198142483264604152\n",
      "Iteration 6509 => Loss: 51.09178088182039090270\n",
      "Iteration 6510 => Loss: 51.09158034039221263356\n",
      "Iteration 6511 => Loss: 51.09137980054811123409\n",
      "Iteration 6512 => Loss: 51.09117926228801565003\n",
      "Iteration 6513 => Loss: 51.09097872561192588137\n",
      "Iteration 6514 => Loss: 51.09077819051976376841\n",
      "Iteration 6515 => Loss: 51.09057765701152220572\n",
      "Iteration 6516 => Loss: 51.09037712508717987703\n",
      "Iteration 6517 => Loss: 51.09017659474667993891\n",
      "Iteration 6518 => Loss: 51.08997606598998686422\n",
      "Iteration 6519 => Loss: 51.08977553881707933670\n",
      "Iteration 6520 => Loss: 51.08957501322788630205\n",
      "Iteration 6521 => Loss: 51.08937448922242907656\n",
      "Iteration 6522 => Loss: 51.08917396680065081682\n",
      "Iteration 6523 => Loss: 51.08897344596251599569\n",
      "Iteration 6524 => Loss: 51.08877292670793934803\n",
      "Iteration 6525 => Loss: 51.08857240903699903356\n",
      "Iteration 6526 => Loss: 51.08837189294957426000\n",
      "Iteration 6527 => Loss: 51.08817137844565792193\n",
      "Iteration 6528 => Loss: 51.08797086552521449221\n",
      "Iteration 6529 => Loss: 51.08777035418817291657\n",
      "Iteration 6530 => Loss: 51.08756984443459714385\n",
      "Iteration 6531 => Loss: 51.08736933626433796007\n",
      "Iteration 6532 => Loss: 51.08716882967742378696\n",
      "Iteration 6533 => Loss: 51.08696832467381909737\n",
      "Iteration 6534 => Loss: 51.08676782125347415331\n",
      "Iteration 6535 => Loss: 51.08656731941638184935\n",
      "Iteration 6536 => Loss: 51.08636681916245692037\n",
      "Iteration 6537 => Loss: 51.08616632049172778807\n",
      "Iteration 6538 => Loss: 51.08596582340411629275\n",
      "Iteration 6539 => Loss: 51.08576532789959401271\n",
      "Iteration 6540 => Loss: 51.08556483397815384251\n",
      "Iteration 6541 => Loss: 51.08536434163974604417\n",
      "Iteration 6542 => Loss: 51.08516385088432798511\n",
      "Iteration 6543 => Loss: 51.08496336171187124364\n",
      "Iteration 6544 => Loss: 51.08476287412235450347\n",
      "Iteration 6545 => Loss: 51.08456238811572802661\n",
      "Iteration 6546 => Loss: 51.08436190369198470762\n",
      "Iteration 6547 => Loss: 51.08416142085106059767\n",
      "Iteration 6548 => Loss: 51.08396093959294148590\n",
      "Iteration 6549 => Loss: 51.08376045991757763431\n",
      "Iteration 6550 => Loss: 51.08355998182496193749\n",
      "Iteration 6551 => Loss: 51.08335950531503044658\n",
      "Iteration 6552 => Loss: 51.08315903038779737244\n",
      "Iteration 6553 => Loss: 51.08295855704317744994\n",
      "Iteration 6554 => Loss: 51.08275808528113515194\n",
      "Iteration 6555 => Loss: 51.08255761510169890016\n",
      "Iteration 6556 => Loss: 51.08235714650477632404\n",
      "Iteration 6557 => Loss: 51.08215667949038163442\n",
      "Iteration 6558 => Loss: 51.08195621405841535534\n",
      "Iteration 6559 => Loss: 51.08175575020892722478\n",
      "Iteration 6560 => Loss: 51.08155528794181776675\n",
      "Iteration 6561 => Loss: 51.08135482725708698126\n",
      "Iteration 6562 => Loss: 51.08115436815469223575\n",
      "Iteration 6563 => Loss: 51.08095391063465484649\n",
      "Iteration 6564 => Loss: 51.08075345469683270494\n",
      "Iteration 6565 => Loss: 51.08055300034128265452\n",
      "Iteration 6566 => Loss: 51.08035254756794785180\n",
      "Iteration 6567 => Loss: 51.08015209637675013710\n",
      "Iteration 6568 => Loss: 51.07995164676773214296\n",
      "Iteration 6569 => Loss: 51.07975119874083702598\n",
      "Iteration 6570 => Loss: 51.07955075229599373188\n",
      "Iteration 6571 => Loss: 51.07935030743322357694\n",
      "Iteration 6572 => Loss: 51.07914986415246261231\n",
      "Iteration 6573 => Loss: 51.07894942245369662714\n",
      "Iteration 6574 => Loss: 51.07874898233687588345\n",
      "Iteration 6575 => Loss: 51.07854854380197195951\n",
      "Iteration 6576 => Loss: 51.07834810684894222277\n",
      "Iteration 6577 => Loss: 51.07814767147780088408\n",
      "Iteration 6578 => Loss: 51.07794723768850531087\n",
      "Iteration 6579 => Loss: 51.07774680548094892174\n",
      "Iteration 6580 => Loss: 51.07754637485519566553\n",
      "Iteration 6581 => Loss: 51.07734594581113896083\n",
      "Iteration 6582 => Loss: 51.07714551834881433479\n",
      "Iteration 6583 => Loss: 51.07694509246815073311\n",
      "Iteration 6584 => Loss: 51.07674466816913394496\n",
      "Iteration 6585 => Loss: 51.07654424545170002148\n",
      "Iteration 6586 => Loss: 51.07634382431584896267\n",
      "Iteration 6587 => Loss: 51.07614340476154524140\n",
      "Iteration 6588 => Loss: 51.07594298678873201425\n",
      "Iteration 6589 => Loss: 51.07574257039741638664\n",
      "Iteration 6590 => Loss: 51.07554215558753440973\n",
      "Iteration 6591 => Loss: 51.07534174235910739981\n",
      "Iteration 6592 => Loss: 51.07514133071202167002\n",
      "Iteration 6593 => Loss: 51.07494092064631274752\n",
      "Iteration 6594 => Loss: 51.07474051216193089431\n",
      "Iteration 6595 => Loss: 51.07454010525883347782\n",
      "Iteration 6596 => Loss: 51.07433969993698497092\n",
      "Iteration 6597 => Loss: 51.07413929619639247903\n",
      "Iteration 6598 => Loss: 51.07393889403697784246\n",
      "Iteration 6599 => Loss: 51.07373849345874816663\n",
      "Iteration 6600 => Loss: 51.07353809446163950270\n",
      "Iteration 6601 => Loss: 51.07333769704564474523\n",
      "Iteration 6602 => Loss: 51.07313730121072126167\n",
      "Iteration 6603 => Loss: 51.07293690695687615744\n",
      "Iteration 6604 => Loss: 51.07273651428399574570\n",
      "Iteration 6605 => Loss: 51.07253612319213686987\n",
      "Iteration 6606 => Loss: 51.07233573368121426483\n",
      "Iteration 6607 => Loss: 51.07213534575119950887\n",
      "Iteration 6608 => Loss: 51.07193495940211391826\n",
      "Iteration 6609 => Loss: 51.07173457463386512245\n",
      "Iteration 6610 => Loss: 51.07153419144644601602\n",
      "Iteration 6611 => Loss: 51.07133380983982817725\n",
      "Iteration 6612 => Loss: 51.07113342981399028986\n",
      "Iteration 6613 => Loss: 51.07093305136888972129\n",
      "Iteration 6614 => Loss: 51.07073267450449804983\n",
      "Iteration 6615 => Loss: 51.07053229922079395919\n",
      "Iteration 6616 => Loss: 51.07033192551772060597\n",
      "Iteration 6617 => Loss: 51.07013155339528509558\n",
      "Iteration 6618 => Loss: 51.06993118285341637375\n",
      "Iteration 6619 => Loss: 51.06973081389212865133\n",
      "Iteration 6620 => Loss: 51.06953044651135087406\n",
      "Iteration 6621 => Loss: 51.06933008071107593651\n",
      "Iteration 6622 => Loss: 51.06912971649129673324\n",
      "Iteration 6623 => Loss: 51.06892935385192799913\n",
      "Iteration 6624 => Loss: 51.06872899279296262876\n",
      "Iteration 6625 => Loss: 51.06852863331440772754\n",
      "Iteration 6626 => Loss: 51.06832827541616381950\n",
      "Iteration 6627 => Loss: 51.06812791909825932635\n",
      "Iteration 6628 => Loss: 51.06792756436064451009\n",
      "Iteration 6629 => Loss: 51.06772721120326963273\n",
      "Iteration 6630 => Loss: 51.06752685962615601056\n",
      "Iteration 6631 => Loss: 51.06732650962923969473\n",
      "Iteration 6632 => Loss: 51.06712616121247805268\n",
      "Iteration 6633 => Loss: 51.06692581437585687354\n",
      "Iteration 6634 => Loss: 51.06672546911934773561\n",
      "Iteration 6635 => Loss: 51.06652512544292221719\n",
      "Iteration 6636 => Loss: 51.06632478334655189656\n",
      "Iteration 6637 => Loss: 51.06612444283020835201\n",
      "Iteration 6638 => Loss: 51.06592410389386316183\n",
      "Iteration 6639 => Loss: 51.06572376653748079889\n",
      "Iteration 6640 => Loss: 51.06552343076101152519\n",
      "Iteration 6641 => Loss: 51.06532309656446955159\n",
      "Iteration 6642 => Loss: 51.06512276394780514011\n",
      "Iteration 6643 => Loss: 51.06492243291098986901\n",
      "Iteration 6644 => Loss: 51.06472210345398110576\n",
      "Iteration 6645 => Loss: 51.06452177557675753405\n",
      "Iteration 6646 => Loss: 51.06432144927930494305\n",
      "Iteration 6647 => Loss: 51.06412112456158070017\n",
      "Iteration 6648 => Loss: 51.06392080142357059458\n",
      "Iteration 6649 => Loss: 51.06372047986520357199\n",
      "Iteration 6650 => Loss: 51.06352015988650094869\n",
      "Iteration 6651 => Loss: 51.06331984148740588125\n",
      "Iteration 6652 => Loss: 51.06311952466791126426\n",
      "Iteration 6653 => Loss: 51.06291920942796735972\n",
      "Iteration 6654 => Loss: 51.06271889576754574591\n",
      "Iteration 6655 => Loss: 51.06251858368664642285\n",
      "Iteration 6656 => Loss: 51.06231827318519123082\n",
      "Iteration 6657 => Loss: 51.06211796426316595898\n",
      "Iteration 6658 => Loss: 51.06191765692059192361\n",
      "Iteration 6659 => Loss: 51.06171735115738385957\n",
      "Iteration 6660 => Loss: 51.06151704697353466145\n",
      "Iteration 6661 => Loss: 51.06131674436903011838\n",
      "Iteration 6662 => Loss: 51.06111644334379207066\n",
      "Iteration 6663 => Loss: 51.06091614389785604544\n",
      "Iteration 6664 => Loss: 51.06071584603114388301\n",
      "Iteration 6665 => Loss: 51.06051554974364847794\n",
      "Iteration 6666 => Loss: 51.06031525503533430310\n",
      "Iteration 6667 => Loss: 51.06011496190618714763\n",
      "Iteration 6668 => Loss: 51.05991467035616437897\n",
      "Iteration 6669 => Loss: 51.05971438038524468084\n",
      "Iteration 6670 => Loss: 51.05951409199340673695\n",
      "Iteration 6671 => Loss: 51.05931380518060080931\n",
      "Iteration 6672 => Loss: 51.05911351994681268707\n",
      "Iteration 6673 => Loss: 51.05891323629201394851\n",
      "Iteration 6674 => Loss: 51.05871295421618327737\n",
      "Iteration 6675 => Loss: 51.05851267371929225192\n",
      "Iteration 6676 => Loss: 51.05831239480129113417\n",
      "Iteration 6677 => Loss: 51.05811211746216571328\n",
      "Iteration 6678 => Loss: 51.05791184170186625124\n",
      "Iteration 6679 => Loss: 51.05771156752042827520\n",
      "Iteration 6680 => Loss: 51.05751129491776652003\n",
      "Iteration 6681 => Loss: 51.05731102389386677487\n",
      "Iteration 6682 => Loss: 51.05711075444869351259\n",
      "Iteration 6683 => Loss: 51.05691048658226804946\n",
      "Iteration 6684 => Loss: 51.05671022029446959323\n",
      "Iteration 6685 => Loss: 51.05650995558536209273\n",
      "Iteration 6686 => Loss: 51.05630969245487449371\n",
      "Iteration 6687 => Loss: 51.05610943090297126901\n",
      "Iteration 6688 => Loss: 51.05590917092965952406\n",
      "Iteration 6689 => Loss: 51.05570891253487531003\n",
      "Iteration 6690 => Loss: 51.05550865571861862691\n",
      "Iteration 6691 => Loss: 51.05530840048083973670\n",
      "Iteration 6692 => Loss: 51.05510814682153153399\n",
      "Iteration 6693 => Loss: 51.05490789474065138620\n",
      "Iteration 6694 => Loss: 51.05470764423814244992\n",
      "Iteration 6695 => Loss: 51.05450739531406156857\n",
      "Iteration 6696 => Loss: 51.05430714796830216073\n",
      "Iteration 6697 => Loss: 51.05410690220088554270\n",
      "Iteration 6698 => Loss: 51.05390665801176197647\n",
      "Iteration 6699 => Loss: 51.05370641540088882948\n",
      "Iteration 6700 => Loss: 51.05350617436828031259\n",
      "Iteration 6701 => Loss: 51.05330593491387958238\n",
      "Iteration 6702 => Loss: 51.05310569703766532257\n",
      "Iteration 6703 => Loss: 51.05290546073962332230\n",
      "Iteration 6704 => Loss: 51.05270522601967542187\n",
      "Iteration 6705 => Loss: 51.05250499287787846470\n",
      "Iteration 6706 => Loss: 51.05230476131413297480\n",
      "Iteration 6707 => Loss: 51.05210453132844605761\n",
      "Iteration 6708 => Loss: 51.05190430292080350227\n",
      "Iteration 6709 => Loss: 51.05170407609114135994\n",
      "Iteration 6710 => Loss: 51.05150385083945252518\n",
      "Iteration 6711 => Loss: 51.05130362716570147086\n",
      "Iteration 6712 => Loss: 51.05110340506986688069\n",
      "Iteration 6713 => Loss: 51.05090318455195586012\n",
      "Iteration 6714 => Loss: 51.05070296561187603857\n",
      "Iteration 6715 => Loss: 51.05050274824965583775\n",
      "Iteration 6716 => Loss: 51.05030253246521709798\n",
      "Iteration 6717 => Loss: 51.05010231825857403010\n",
      "Iteration 6718 => Loss: 51.04990210562969821240\n",
      "Iteration 6719 => Loss: 51.04970189457855411774\n",
      "Iteration 6720 => Loss: 51.04950168510510621900\n",
      "Iteration 6721 => Loss: 51.04930147720934030531\n",
      "Iteration 6722 => Loss: 51.04910127089122084953\n",
      "Iteration 6723 => Loss: 51.04890106615073364082\n",
      "Iteration 6724 => Loss: 51.04870086298784315204\n",
      "Iteration 6725 => Loss: 51.04850066140252096147\n",
      "Iteration 6726 => Loss: 51.04830046139475285827\n",
      "Iteration 6727 => Loss: 51.04810026296448910443\n",
      "Iteration 6728 => Loss: 51.04790006611172969997\n",
      "Iteration 6729 => Loss: 51.04769987083642490688\n",
      "Iteration 6730 => Loss: 51.04749967713858893603\n",
      "Iteration 6731 => Loss: 51.04729948501812231143\n",
      "Iteration 6732 => Loss: 51.04709929447508187650\n",
      "Iteration 6733 => Loss: 51.04689910550940368239\n",
      "Iteration 6734 => Loss: 51.04669891812103088569\n",
      "Iteration 6735 => Loss: 51.04649873230999190810\n",
      "Iteration 6736 => Loss: 51.04629854807621569535\n",
      "Iteration 6737 => Loss: 51.04609836541973777457\n",
      "Iteration 6738 => Loss: 51.04589818434043735351\n",
      "Iteration 6739 => Loss: 51.04569800483839259186\n",
      "Iteration 6740 => Loss: 51.04549782691349690822\n",
      "Iteration 6741 => Loss: 51.04529765056575740800\n",
      "Iteration 6742 => Loss: 51.04509747579514566951\n",
      "Iteration 6743 => Loss: 51.04489730260164748188\n",
      "Iteration 6744 => Loss: 51.04469713098521310712\n",
      "Iteration 6745 => Loss: 51.04449696094582833439\n",
      "Iteration 6746 => Loss: 51.04429679248347895282\n",
      "Iteration 6747 => Loss: 51.04409662559812943528\n",
      "Iteration 6748 => Loss: 51.04389646028974425462\n",
      "Iteration 6749 => Loss: 51.04369629655830920001\n",
      "Iteration 6750 => Loss: 51.04349613440378163887\n",
      "Iteration 6751 => Loss: 51.04329597382616157120\n",
      "Iteration 6752 => Loss: 51.04309581482540636443\n",
      "Iteration 6753 => Loss: 51.04289565740149470230\n",
      "Iteration 6754 => Loss: 51.04269550155441947936\n",
      "Iteration 6755 => Loss: 51.04249534728414516849\n",
      "Iteration 6756 => Loss: 51.04229519459058650455\n",
      "Iteration 6757 => Loss: 51.04209504347382875267\n",
      "Iteration 6758 => Loss: 51.04189489393377243687\n",
      "Iteration 6759 => Loss: 51.04169474597038203001\n",
      "Iteration 6760 => Loss: 51.04149459958367884838\n",
      "Iteration 6761 => Loss: 51.04129445477362736483\n",
      "Iteration 6762 => Loss: 51.04109431154017073595\n",
      "Iteration 6763 => Loss: 51.04089416988332317260\n",
      "Iteration 6764 => Loss: 51.04069402980302072592\n",
      "Iteration 6765 => Loss: 51.04049389129927050135\n",
      "Iteration 6766 => Loss: 51.04029375437203697174\n",
      "Iteration 6767 => Loss: 51.04009361902128460997\n",
      "Iteration 6768 => Loss: 51.03989348524699209975\n",
      "Iteration 6769 => Loss: 51.03969335304915944107\n",
      "Iteration 6770 => Loss: 51.03949322242770136882\n",
      "Iteration 6771 => Loss: 51.03929309338268183183\n",
      "Iteration 6772 => Loss: 51.03909296591400845955\n",
      "Iteration 6773 => Loss: 51.03889284002167414656\n",
      "Iteration 6774 => Loss: 51.03869271570564336571\n",
      "Iteration 6775 => Loss: 51.03849259296592322244\n",
      "Iteration 6776 => Loss: 51.03829247180245687332\n",
      "Iteration 6777 => Loss: 51.03809235221520879122\n",
      "Iteration 6778 => Loss: 51.03789223420420739785\n",
      "Iteration 6779 => Loss: 51.03769211776936032265\n",
      "Iteration 6780 => Loss: 51.03749200291073151448\n",
      "Iteration 6781 => Loss: 51.03729188962820728648\n",
      "Iteration 6782 => Loss: 51.03709177792180184952\n",
      "Iteration 6783 => Loss: 51.03689166779150099273\n",
      "Iteration 6784 => Loss: 51.03669155923724076729\n",
      "Iteration 6785 => Loss: 51.03649145225902827860\n",
      "Iteration 6786 => Loss: 51.03629134685685642125\n",
      "Iteration 6787 => Loss: 51.03609124303064703554\n",
      "Iteration 6788 => Loss: 51.03589114078040722688\n",
      "Iteration 6789 => Loss: 51.03569104010613699529\n",
      "Iteration 6790 => Loss: 51.03549094100775818106\n",
      "Iteration 6791 => Loss: 51.03529084348529920589\n",
      "Iteration 6792 => Loss: 51.03509074753870322638\n",
      "Iteration 6793 => Loss: 51.03489065316792760996\n",
      "Iteration 6794 => Loss: 51.03469056037298656747\n",
      "Iteration 6795 => Loss: 51.03449046915385167722\n",
      "Iteration 6796 => Loss: 51.03429037951048030664\n",
      "Iteration 6797 => Loss: 51.03409029144285113944\n",
      "Iteration 6798 => Loss: 51.03389020495096417562\n",
      "Iteration 6799 => Loss: 51.03369012003476257178\n",
      "Iteration 6800 => Loss: 51.03349003669423211704\n",
      "Iteration 6801 => Loss: 51.03328995492933728428\n",
      "Iteration 6802 => Loss: 51.03308987474010649521\n",
      "Iteration 6803 => Loss: 51.03288979612645448469\n",
      "Iteration 6804 => Loss: 51.03268971908838125273\n",
      "Iteration 6805 => Loss: 51.03248964362586548305\n",
      "Iteration 6806 => Loss: 51.03228956973887875392\n",
      "Iteration 6807 => Loss: 51.03208949742740685451\n",
      "Iteration 6808 => Loss: 51.03188942669139294139\n",
      "Iteration 6809 => Loss: 51.03168935753084411999\n",
      "Iteration 6810 => Loss: 51.03148928994574617946\n",
      "Iteration 6811 => Loss: 51.03128922393603517094\n",
      "Iteration 6812 => Loss: 51.03108915950171109444\n",
      "Iteration 6813 => Loss: 51.03088909664277394995\n",
      "Iteration 6814 => Loss: 51.03068903535915978864\n",
      "Iteration 6815 => Loss: 51.03048897565086150507\n",
      "Iteration 6816 => Loss: 51.03028891751784357211\n",
      "Iteration 6817 => Loss: 51.03008886096009888433\n",
      "Iteration 6818 => Loss: 51.02988880597756349289\n",
      "Iteration 6819 => Loss: 51.02968875257028713577\n",
      "Iteration 6820 => Loss: 51.02948870073822007498\n",
      "Iteration 6821 => Loss: 51.02928865048128415083\n",
      "Iteration 6822 => Loss: 51.02908860179952199587\n",
      "Iteration 6823 => Loss: 51.02888855469286255584\n",
      "Iteration 6824 => Loss: 51.02868850916131293616\n",
      "Iteration 6825 => Loss: 51.02848846520483050426\n",
      "Iteration 6826 => Loss: 51.02828842282340104930\n",
      "Iteration 6827 => Loss: 51.02808838201701746584\n",
      "Iteration 6828 => Loss: 51.02788834278563001590\n",
      "Iteration 6829 => Loss: 51.02768830512922448861\n",
      "Iteration 6830 => Loss: 51.02748826904777246227\n",
      "Iteration 6831 => Loss: 51.02728823454125972603\n",
      "Iteration 6832 => Loss: 51.02708820160966496360\n",
      "Iteration 6833 => Loss: 51.02688817025295264784\n",
      "Iteration 6834 => Loss: 51.02668814047109435705\n",
      "Iteration 6835 => Loss: 51.02648811226408298580\n",
      "Iteration 6836 => Loss: 51.02628808563191853409\n",
      "Iteration 6837 => Loss: 51.02608806057450863136\n",
      "Iteration 6838 => Loss: 51.02588803709187459390\n",
      "Iteration 6839 => Loss: 51.02568801518402352713\n",
      "Iteration 6840 => Loss: 51.02548799485083463878\n",
      "Iteration 6841 => Loss: 51.02528797609240740485\n",
      "Iteration 6842 => Loss: 51.02508795890862103306\n",
      "Iteration 6843 => Loss: 51.02488794329953236684\n",
      "Iteration 6844 => Loss: 51.02468792926502771934\n",
      "Iteration 6845 => Loss: 51.02448791680513551228\n",
      "Iteration 6846 => Loss: 51.02428790591986285108\n",
      "Iteration 6847 => Loss: 51.02408789660914578690\n",
      "Iteration 6848 => Loss: 51.02388788887295589802\n",
      "Iteration 6849 => Loss: 51.02368788271126476275\n",
      "Iteration 6850 => Loss: 51.02348787812410080278\n",
      "Iteration 6851 => Loss: 51.02328787511137164756\n",
      "Iteration 6852 => Loss: 51.02308787367314124594\n",
      "Iteration 6853 => Loss: 51.02288787380928880566\n",
      "Iteration 6854 => Loss: 51.02268787551987827555\n",
      "Iteration 6855 => Loss: 51.02248787880479596879\n",
      "Iteration 6856 => Loss: 51.02228788366411293964\n",
      "Iteration 6857 => Loss: 51.02208789009773681755\n",
      "Iteration 6858 => Loss: 51.02188789810568891880\n",
      "Iteration 6859 => Loss: 51.02168790768790529455\n",
      "Iteration 6860 => Loss: 51.02148791884440726108\n",
      "Iteration 6861 => Loss: 51.02128793157511665868\n",
      "Iteration 6862 => Loss: 51.02108794588008322535\n",
      "Iteration 6863 => Loss: 51.02088796175924301224\n",
      "Iteration 6864 => Loss: 51.02068797921256049221\n",
      "Iteration 6865 => Loss: 51.02048799824004277070\n",
      "Iteration 6866 => Loss: 51.02028801884164010971\n",
      "Iteration 6867 => Loss: 51.02008804101735250924\n",
      "Iteration 6868 => Loss: 51.01988806476713023130\n",
      "Iteration 6869 => Loss: 51.01968809009099459217\n",
      "Iteration 6870 => Loss: 51.01948811698888874844\n",
      "Iteration 6871 => Loss: 51.01928814546077717296\n",
      "Iteration 6872 => Loss: 51.01908817550666697116\n",
      "Iteration 6873 => Loss: 51.01888820712655103762\n",
      "Iteration 6874 => Loss: 51.01868824032037252891\n",
      "Iteration 6875 => Loss: 51.01848827508812433962\n",
      "Iteration 6876 => Loss: 51.01828831142974962631\n",
      "Iteration 6877 => Loss: 51.01808834934526970528\n",
      "Iteration 6878 => Loss: 51.01788838883467747110\n",
      "Iteration 6879 => Loss: 51.01768842989788055320\n",
      "Iteration 6880 => Loss: 51.01748847253491447873\n",
      "Iteration 6881 => Loss: 51.01728851674572240427\n",
      "Iteration 6882 => Loss: 51.01708856253032564609\n",
      "Iteration 6883 => Loss: 51.01688860988866025536\n",
      "Iteration 6884 => Loss: 51.01668865882071912665\n",
      "Iteration 6885 => Loss: 51.01648870932649515453\n",
      "Iteration 6886 => Loss: 51.01628876140592439015\n",
      "Iteration 6887 => Loss: 51.01608881505902814979\n",
      "Iteration 6888 => Loss: 51.01588887028578511718\n",
      "Iteration 6889 => Loss: 51.01568892708611713260\n",
      "Iteration 6890 => Loss: 51.01548898546005261778\n",
      "Iteration 6891 => Loss: 51.01528904540756315100\n",
      "Iteration 6892 => Loss: 51.01508910692861320513\n",
      "Iteration 6893 => Loss: 51.01488917002320988558\n",
      "Iteration 6894 => Loss: 51.01468923469128924353\n",
      "Iteration 6895 => Loss: 51.01448930093287259524\n",
      "Iteration 6896 => Loss: 51.01428936874788888645\n",
      "Iteration 6897 => Loss: 51.01408943813635232800\n",
      "Iteration 6898 => Loss: 51.01388950909822028734\n",
      "Iteration 6899 => Loss: 51.01368958163351408075\n",
      "Iteration 6900 => Loss: 51.01348965574212712681\n",
      "Iteration 6901 => Loss: 51.01328973142413047981\n",
      "Iteration 6902 => Loss: 51.01308980867945308546\n",
      "Iteration 6903 => Loss: 51.01288988750808073291\n",
      "Iteration 6904 => Loss: 51.01268996790997078961\n",
      "Iteration 6905 => Loss: 51.01249004988514457182\n",
      "Iteration 6906 => Loss: 51.01229013343354523613\n",
      "Iteration 6907 => Loss: 51.01209021855518699340\n",
      "Iteration 6908 => Loss: 51.01189030525001300020\n",
      "Iteration 6909 => Loss: 51.01169039351798062398\n",
      "Iteration 6910 => Loss: 51.01149048335915381358\n",
      "Iteration 6911 => Loss: 51.01129057477343309301\n",
      "Iteration 6912 => Loss: 51.01109066776084688399\n",
      "Iteration 6913 => Loss: 51.01089076232130281596\n",
      "Iteration 6914 => Loss: 51.01069085845487194320\n",
      "Iteration 6915 => Loss: 51.01049095616146189514\n",
      "Iteration 6916 => Loss: 51.01029105544107267178\n",
      "Iteration 6917 => Loss: 51.01009115629368295686\n",
      "Iteration 6918 => Loss: 51.00989125871927853950\n",
      "Iteration 6919 => Loss: 51.00969136271784520886\n",
      "Iteration 6920 => Loss: 51.00949146828935454323\n",
      "Iteration 6921 => Loss: 51.00929157543375680461\n",
      "Iteration 6922 => Loss: 51.00909168415106620387\n",
      "Iteration 6923 => Loss: 51.00889179444124010843\n",
      "Iteration 6924 => Loss: 51.00869190630428562372\n",
      "Iteration 6925 => Loss: 51.00849201974014590633\n",
      "Iteration 6926 => Loss: 51.00829213474879963997\n",
      "Iteration 6927 => Loss: 51.00809225133026814092\n",
      "Iteration 6928 => Loss: 51.00789236948448746034\n",
      "Iteration 6929 => Loss: 51.00769248921145759823\n",
      "Iteration 6930 => Loss: 51.00749261051114302745\n",
      "Iteration 6931 => Loss: 51.00729273338355085343\n",
      "Iteration 6932 => Loss: 51.00709285782862423275\n",
      "Iteration 6933 => Loss: 51.00689298384636316541\n",
      "Iteration 6934 => Loss: 51.00669311143672501885\n",
      "Iteration 6935 => Loss: 51.00649324059974532020\n",
      "Iteration 6936 => Loss: 51.00629337133531038262\n",
      "Iteration 6937 => Loss: 51.00609350364349126039\n",
      "Iteration 6938 => Loss: 51.00589363752418137210\n",
      "Iteration 6939 => Loss: 51.00569377297743756117\n",
      "Iteration 6940 => Loss: 51.00549391000319587874\n",
      "Iteration 6941 => Loss: 51.00529404860144921940\n",
      "Iteration 6942 => Loss: 51.00509418877216916144\n",
      "Iteration 6943 => Loss: 51.00489433051534859942\n",
      "Iteration 6944 => Loss: 51.00469447383093068993\n",
      "Iteration 6945 => Loss: 51.00449461871895096010\n",
      "Iteration 6946 => Loss: 51.00429476517935256652\n",
      "Iteration 6947 => Loss: 51.00409491321208577119\n",
      "Iteration 6948 => Loss: 51.00389506281719320668\n",
      "Iteration 6949 => Loss: 51.00369521399461802957\n",
      "Iteration 6950 => Loss: 51.00349536674433181815\n",
      "Iteration 6951 => Loss: 51.00329552106633457242\n",
      "Iteration 6952 => Loss: 51.00309567696059787067\n",
      "Iteration 6953 => Loss: 51.00289583442710750205\n",
      "Iteration 6954 => Loss: 51.00269599346581372856\n",
      "Iteration 6955 => Loss: 51.00249615407675207734\n",
      "Iteration 6956 => Loss: 51.00229631625983017784\n",
      "Iteration 6957 => Loss: 51.00209648001508355719\n",
      "Iteration 6958 => Loss: 51.00189664534247668826\n",
      "Iteration 6959 => Loss: 51.00169681224197404390\n",
      "Iteration 6960 => Loss: 51.00149698071356851869\n",
      "Iteration 6961 => Loss: 51.00129715075723169093\n",
      "Iteration 6962 => Loss: 51.00109732237294934976\n",
      "Iteration 6963 => Loss: 51.00089749556069307346\n",
      "Iteration 6964 => Loss: 51.00069767032046286204\n",
      "Iteration 6965 => Loss: 51.00049784665222318836\n",
      "Iteration 6966 => Loss: 51.00029802455594563071\n",
      "Iteration 6967 => Loss: 51.00009820403161597824\n",
      "Iteration 6968 => Loss: 50.99989838507922712552\n",
      "Iteration 6969 => Loss: 50.99969856769875775626\n",
      "Iteration 6970 => Loss: 50.99949875189013681620\n",
      "Iteration 6971 => Loss: 50.99929893765339272704\n",
      "Iteration 6972 => Loss: 50.99909912498850417251\n",
      "Iteration 6973 => Loss: 50.99889931389544273088\n",
      "Iteration 6974 => Loss: 50.99869950437417287503\n",
      "Iteration 6975 => Loss: 50.99849969642471592124\n",
      "Iteration 6976 => Loss: 50.99829989004702213151\n",
      "Iteration 6977 => Loss: 50.99810008524105597871\n",
      "Iteration 6978 => Loss: 50.99790028200681035742\n",
      "Iteration 6979 => Loss: 50.99770048034427105677\n",
      "Iteration 6980 => Loss: 50.99750068025343807676\n",
      "Iteration 6981 => Loss: 50.99730088173423325770\n",
      "Iteration 6982 => Loss: 50.99710108478669212673\n",
      "Iteration 6983 => Loss: 50.99690128941076494584\n",
      "Iteration 6984 => Loss: 50.99670149560644460962\n",
      "Iteration 6985 => Loss: 50.99650170337370980178\n",
      "Iteration 6986 => Loss: 50.99630191271253210061\n",
      "Iteration 6987 => Loss: 50.99610212362291150612\n",
      "Iteration 6988 => Loss: 50.99590233610478406945\n",
      "Iteration 6989 => Loss: 50.99570255015817110689\n",
      "Iteration 6990 => Loss: 50.99550276578303709130\n",
      "Iteration 6991 => Loss: 50.99530298297935360097\n",
      "Iteration 6992 => Loss: 50.99510320174712063590\n",
      "Iteration 6993 => Loss: 50.99490342208631687981\n",
      "Iteration 6994 => Loss: 50.99470364399688548929\n",
      "Iteration 6995 => Loss: 50.99450386747886909689\n",
      "Iteration 6996 => Loss: 50.99430409253218954291\n",
      "Iteration 6997 => Loss: 50.99410431915686814364\n",
      "Iteration 6998 => Loss: 50.99390454735284095023\n",
      "Iteration 6999 => Loss: 50.99370477712014348981\n",
      "Iteration 7000 => Loss: 50.99350500845870470812\n",
      "Iteration 7001 => Loss: 50.99330524136853171058\n",
      "Iteration 7002 => Loss: 50.99310547584958186462\n",
      "Iteration 7003 => Loss: 50.99290571190188359196\n",
      "Iteration 7004 => Loss: 50.99270594952538004918\n",
      "Iteration 7005 => Loss: 50.99250618872005702542\n",
      "Iteration 7006 => Loss: 50.99230642948587188812\n",
      "Iteration 7007 => Loss: 50.99210667182282463727\n",
      "Iteration 7008 => Loss: 50.99190691573091527289\n",
      "Iteration 7009 => Loss: 50.99170716121010116240\n",
      "Iteration 7010 => Loss: 50.99150740826036098952\n",
      "Iteration 7011 => Loss: 50.99130765688170185967\n",
      "Iteration 7012 => Loss: 50.99110790707408824574\n",
      "Iteration 7013 => Loss: 50.99090815883747040971\n",
      "Iteration 7014 => Loss: 50.99070841217186966787\n",
      "Iteration 7015 => Loss: 50.99050866707724338767\n",
      "Iteration 7016 => Loss: 50.99030892355357025281\n",
      "Iteration 7017 => Loss: 50.99010918160085026329\n",
      "Iteration 7018 => Loss: 50.98990944121906210285\n",
      "Iteration 7019 => Loss: 50.98970970240817734975\n",
      "Iteration 7020 => Loss: 50.98950996516815337145\n",
      "Iteration 7021 => Loss: 50.98931022949901148422\n",
      "Iteration 7022 => Loss: 50.98911049540070905550\n",
      "Iteration 7023 => Loss: 50.98891076287321766358\n",
      "Iteration 7024 => Loss: 50.98871103191657283560\n",
      "Iteration 7025 => Loss: 50.98851130253066799014\n",
      "Iteration 7026 => Loss: 50.98831157471555997063\n",
      "Iteration 7027 => Loss: 50.98811184847116351193\n",
      "Iteration 7028 => Loss: 50.98791212379750703576\n",
      "Iteration 7029 => Loss: 50.98771240069456922583\n",
      "Iteration 7030 => Loss: 50.98751267916230744959\n",
      "Iteration 7031 => Loss: 50.98731295920072170702\n",
      "Iteration 7032 => Loss: 50.98711324080979068185\n",
      "Iteration 7033 => Loss: 50.98691352398947884694\n",
      "Iteration 7034 => Loss: 50.98671380873975067516\n",
      "Iteration 7035 => Loss: 50.98651409506066300992\n",
      "Iteration 7036 => Loss: 50.98631438295211637524\n",
      "Iteration 7037 => Loss: 50.98611467241411787654\n",
      "Iteration 7038 => Loss: 50.98591496344666751384\n",
      "Iteration 7039 => Loss: 50.98571525604972975998\n",
      "Iteration 7040 => Loss: 50.98551555022326198241\n",
      "Iteration 7041 => Loss: 50.98531584596727839198\n",
      "Iteration 7042 => Loss: 50.98511614328175767241\n",
      "Iteration 7043 => Loss: 50.98491644216668561285\n",
      "Iteration 7044 => Loss: 50.98471674262201247529\n",
      "Iteration 7045 => Loss: 50.98451704464773115433\n",
      "Iteration 7046 => Loss: 50.98431734824383454452\n",
      "Iteration 7047 => Loss: 50.98411765341028711873\n",
      "Iteration 7048 => Loss: 50.98391796014708887697\n",
      "Iteration 7049 => Loss: 50.98371826845419008123\n",
      "Iteration 7050 => Loss: 50.98351857833162625866\n",
      "Iteration 7051 => Loss: 50.98331888977932635498\n",
      "Iteration 7052 => Loss: 50.98311920279727615934\n",
      "Iteration 7053 => Loss: 50.98291951738547567174\n",
      "Iteration 7054 => Loss: 50.98271983354393910304\n",
      "Iteration 7055 => Loss: 50.98252015127255276639\n",
      "Iteration 7056 => Loss: 50.98232047057137350521\n",
      "Iteration 7057 => Loss: 50.98212079144035158151\n",
      "Iteration 7058 => Loss: 50.98192111387949410073\n",
      "Iteration 7059 => Loss: 50.98172143788872290315\n",
      "Iteration 7060 => Loss: 50.98152176346812325392\n",
      "Iteration 7061 => Loss: 50.98132209061756014989\n",
      "Iteration 7062 => Loss: 50.98112241933709753994\n",
      "Iteration 7063 => Loss: 50.98092274962667858063\n",
      "Iteration 7064 => Loss: 50.98072308148629616653\n",
      "Iteration 7065 => Loss: 50.98052341491592898137\n",
      "Iteration 7066 => Loss: 50.98032374991554860344\n",
      "Iteration 7067 => Loss: 50.98012408648514792731\n",
      "Iteration 7068 => Loss: 50.97992442462471274212\n",
      "Iteration 7069 => Loss: 50.97972476433422173159\n",
      "Iteration 7070 => Loss: 50.97952510561364647401\n",
      "Iteration 7071 => Loss: 50.97932544846294433682\n",
      "Iteration 7072 => Loss: 50.97912579288217216344\n",
      "Iteration 7073 => Loss: 50.97892613887120916161\n",
      "Iteration 7074 => Loss: 50.97872648643011928016\n",
      "Iteration 7075 => Loss: 50.97852683555885988653\n",
      "Iteration 7076 => Loss: 50.97832718625738834817\n",
      "Iteration 7077 => Loss: 50.97812753852573308677\n",
      "Iteration 7078 => Loss: 50.97792789236382304807\n",
      "Iteration 7079 => Loss: 50.97772824777166533750\n",
      "Iteration 7080 => Loss: 50.97752860474923863876\n",
      "Iteration 7081 => Loss: 50.97732896329653584644\n",
      "Iteration 7082 => Loss: 50.97712932341350011711\n",
      "Iteration 7083 => Loss: 50.97692968510017408335\n",
      "Iteration 7084 => Loss: 50.97673004835647248001\n",
      "Iteration 7085 => Loss: 50.97653041318243793967\n",
      "Iteration 7086 => Loss: 50.97633077957799940805\n",
      "Iteration 7087 => Loss: 50.97613114754317109600\n",
      "Iteration 7088 => Loss: 50.97593151707793879268\n",
      "Iteration 7089 => Loss: 50.97573188818225986552\n",
      "Iteration 7090 => Loss: 50.97553226085609878737\n",
      "Iteration 7091 => Loss: 50.97533263509949108538\n",
      "Iteration 7092 => Loss: 50.97513301091239412699\n",
      "Iteration 7093 => Loss: 50.97493338829476527962\n",
      "Iteration 7094 => Loss: 50.97473376724663296500\n",
      "Iteration 7095 => Loss: 50.97453414776793323426\n",
      "Iteration 7096 => Loss: 50.97433452985865898199\n",
      "Iteration 7097 => Loss: 50.97413491351881020819\n",
      "Iteration 7098 => Loss: 50.97393529874837270199\n",
      "Iteration 7099 => Loss: 50.97373568554729672542\n",
      "Iteration 7100 => Loss: 50.97353607391558227846\n",
      "Iteration 7101 => Loss: 50.97333646385320093941\n",
      "Iteration 7102 => Loss: 50.97313685536015981370\n",
      "Iteration 7103 => Loss: 50.97293724843641626876\n",
      "Iteration 7104 => Loss: 50.97273764308194188288\n",
      "Iteration 7105 => Loss: 50.97253803929673665607\n",
      "Iteration 7106 => Loss: 50.97233843708082190460\n",
      "Iteration 7107 => Loss: 50.97213883643409104707\n",
      "Iteration 7108 => Loss: 50.97193923735657961060\n",
      "Iteration 7109 => Loss: 50.97173963984825917350\n",
      "Iteration 7110 => Loss: 50.97154004390912973577\n",
      "Iteration 7111 => Loss: 50.97134044953916287568\n",
      "Iteration 7112 => Loss: 50.97114085673830885526\n",
      "Iteration 7113 => Loss: 50.97094126550658899077\n",
      "Iteration 7114 => Loss: 50.97074167584397486053\n",
      "Iteration 7115 => Loss: 50.97054208775043093738\n",
      "Iteration 7116 => Loss: 50.97034250122597853760\n",
      "Iteration 7117 => Loss: 50.97014291627052529066\n",
      "Iteration 7118 => Loss: 50.96994333288413514538\n",
      "Iteration 7119 => Loss: 50.96974375106675836378\n",
      "Iteration 7120 => Loss: 50.96954417081837362957\n",
      "Iteration 7121 => Loss: 50.96934459213894541563\n",
      "Iteration 7122 => Loss: 50.96914501502850214365\n",
      "Iteration 7123 => Loss: 50.96894543948696565394\n",
      "Iteration 7124 => Loss: 50.96874586551435726278\n",
      "Iteration 7125 => Loss: 50.96854629311066275932\n",
      "Iteration 7126 => Loss: 50.96834672227583240556\n",
      "Iteration 7127 => Loss: 50.96814715300987330693\n",
      "Iteration 7128 => Loss: 50.96794758531277835800\n",
      "Iteration 7129 => Loss: 50.96774801918449071536\n",
      "Iteration 7130 => Loss: 50.96754845462502458986\n",
      "Iteration 7131 => Loss: 50.96734889163435155979\n",
      "Iteration 7132 => Loss: 50.96714933021245030886\n",
      "Iteration 7133 => Loss: 50.96694977035929241538\n",
      "Iteration 7134 => Loss: 50.96675021207489919561\n",
      "Iteration 7135 => Loss: 50.96655065535922091158\n",
      "Iteration 7136 => Loss: 50.96635110021222914156\n",
      "Iteration 7137 => Loss: 50.96615154663393099099\n",
      "Iteration 7138 => Loss: 50.96595199462431935444\n",
      "Iteration 7139 => Loss: 50.96575244418331607221\n",
      "Iteration 7140 => Loss: 50.96555289531097088229\n",
      "Iteration 7141 => Loss: 50.96535334800724115212\n",
      "Iteration 7142 => Loss: 50.96515380227209135455\n",
      "Iteration 7143 => Loss: 50.96495425810552859502\n",
      "Iteration 7144 => Loss: 50.96475471550752445182\n",
      "Iteration 7145 => Loss: 50.96455517447806471409\n",
      "Iteration 7146 => Loss: 50.96435563501711385470\n",
      "Iteration 7147 => Loss: 50.96415609712469318993\n",
      "Iteration 7148 => Loss: 50.96395656080073877092\n",
      "Iteration 7149 => Loss: 50.96375702604527191397\n",
      "Iteration 7150 => Loss: 50.96355749285822867023\n",
      "Iteration 7151 => Loss: 50.96335796123965167226\n",
      "Iteration 7152 => Loss: 50.96315843118946276036\n",
      "Iteration 7153 => Loss: 50.96295890270769035624\n",
      "Iteration 7154 => Loss: 50.96275937579429893276\n",
      "Iteration 7155 => Loss: 50.96255985044925296279\n",
      "Iteration 7156 => Loss: 50.96236032667257376261\n",
      "Iteration 7157 => Loss: 50.96216080446420448880\n",
      "Iteration 7158 => Loss: 50.96196128382415935221\n",
      "Iteration 7159 => Loss: 50.96176176475240993113\n",
      "Iteration 7160 => Loss: 50.96156224724891359301\n",
      "Iteration 7161 => Loss: 50.96136273131367744327\n",
      "Iteration 7162 => Loss: 50.96116321694670148190\n",
      "Iteration 7163 => Loss: 50.96096370414792886550\n",
      "Iteration 7164 => Loss: 50.96076419291737380490\n",
      "Iteration 7165 => Loss: 50.96056468325497945671\n",
      "Iteration 7166 => Loss: 50.96036517516076713719\n",
      "Iteration 7167 => Loss: 50.96016566863471553006\n",
      "Iteration 7168 => Loss: 50.95996616367678200277\n",
      "Iteration 7169 => Loss: 50.95976666028697366073\n",
      "Iteration 7170 => Loss: 50.95956715846525497682\n",
      "Iteration 7171 => Loss: 50.95936765821161884560\n",
      "Iteration 7172 => Loss: 50.95916815952605105622\n",
      "Iteration 7173 => Loss: 50.95896866240852318697\n",
      "Iteration 7174 => Loss: 50.95876916685902813242\n",
      "Iteration 7175 => Loss: 50.95856967287752326001\n",
      "Iteration 7176 => Loss: 50.95837018046405830773\n",
      "Iteration 7177 => Loss: 50.95817068961851248332\n",
      "Iteration 7178 => Loss: 50.95797120034096394647\n",
      "Iteration 7179 => Loss: 50.95777171263132743206\n",
      "Iteration 7180 => Loss: 50.95757222648963136180\n",
      "Iteration 7181 => Loss: 50.95737274191584731398\n",
      "Iteration 7182 => Loss: 50.95717325890994686688\n",
      "Iteration 7183 => Loss: 50.95697377747188738795\n",
      "Iteration 7184 => Loss: 50.95677429760171150974\n",
      "Iteration 7185 => Loss: 50.95657481929937659970\n",
      "Iteration 7186 => Loss: 50.95637534256484002526\n",
      "Iteration 7187 => Loss: 50.95617586739810178642\n",
      "Iteration 7188 => Loss: 50.95597639379914767233\n",
      "Iteration 7189 => Loss: 50.95577692176797768298\n",
      "Iteration 7190 => Loss: 50.95557745130452786952\n",
      "Iteration 7191 => Loss: 50.95537798240883375911\n",
      "Iteration 7192 => Loss: 50.95517851508083850831\n",
      "Iteration 7193 => Loss: 50.95497904932055632798\n",
      "Iteration 7194 => Loss: 50.95477958512795169099\n",
      "Iteration 7195 => Loss: 50.95458012250299617563\n",
      "Iteration 7196 => Loss: 50.95438066144566846560\n",
      "Iteration 7197 => Loss: 50.95418120195600408806\n",
      "Iteration 7198 => Loss: 50.95398174403392488330\n",
      "Iteration 7199 => Loss: 50.95378228767945927302\n",
      "Iteration 7200 => Loss: 50.95358283289255041382\n",
      "Iteration 7201 => Loss: 50.95338337967319830568\n",
      "Iteration 7202 => Loss: 50.95318392802141005404\n",
      "Iteration 7203 => Loss: 50.95298447793712171006\n",
      "Iteration 7204 => Loss: 50.95278502942035459000\n",
      "Iteration 7205 => Loss: 50.95258558247108737760\n",
      "Iteration 7206 => Loss: 50.95238613708926322943\n",
      "Iteration 7207 => Loss: 50.95218669327491056720\n",
      "Iteration 7208 => Loss: 50.95198725102800096920\n",
      "Iteration 7209 => Loss: 50.95178781034849180287\n",
      "Iteration 7210 => Loss: 50.95158837123640438449\n",
      "Iteration 7211 => Loss: 50.95138893369170318692\n",
      "Iteration 7212 => Loss: 50.95118949771435978846\n",
      "Iteration 7213 => Loss: 50.95099006330436708367\n",
      "Iteration 7214 => Loss: 50.95079063046173217799\n",
      "Iteration 7215 => Loss: 50.95059119918639112257\n",
      "Iteration 7216 => Loss: 50.95039176947834391740\n",
      "Iteration 7217 => Loss: 50.95019234133761187877\n",
      "Iteration 7218 => Loss: 50.94999291476413105784\n",
      "Iteration 7219 => Loss: 50.94979348975790145460\n",
      "Iteration 7220 => Loss: 50.94959406631889464734\n",
      "Iteration 7221 => Loss: 50.94939464444711774149\n",
      "Iteration 7222 => Loss: 50.94919522414252810449\n",
      "Iteration 7223 => Loss: 50.94899580540513284177\n",
      "Iteration 7224 => Loss: 50.94879638823488932076\n",
      "Iteration 7225 => Loss: 50.94859697263179754145\n",
      "Iteration 7226 => Loss: 50.94839755859584329301\n",
      "Iteration 7227 => Loss: 50.94819814612699104828\n",
      "Iteration 7228 => Loss: 50.94799873522526212355\n",
      "Iteration 7229 => Loss: 50.94779932589055704284\n",
      "Iteration 7230 => Loss: 50.94759991812296107128\n",
      "Iteration 7231 => Loss: 50.94740051192240315459\n",
      "Iteration 7232 => Loss: 50.94720110728886197649\n",
      "Iteration 7233 => Loss: 50.94700170422235174783\n",
      "Iteration 7234 => Loss: 50.94680230272282273063\n",
      "Iteration 7235 => Loss: 50.94660290279028203031\n",
      "Iteration 7236 => Loss: 50.94640350442470833059\n",
      "Iteration 7237 => Loss: 50.94620410762605899890\n",
      "Iteration 7238 => Loss: 50.94600471239434824611\n",
      "Iteration 7239 => Loss: 50.94580531872954765049\n",
      "Iteration 7240 => Loss: 50.94560592663164300120\n",
      "Iteration 7241 => Loss: 50.94540653610062008738\n",
      "Iteration 7242 => Loss: 50.94520714713642917104\n",
      "Iteration 7243 => Loss: 50.94500775973909867389\n",
      "Iteration 7244 => Loss: 50.94480837390862859593\n",
      "Iteration 7245 => Loss: 50.94460898964492656660\n",
      "Iteration 7246 => Loss: 50.94440960694804232389\n",
      "Iteration 7247 => Loss: 50.94421022581791902439\n",
      "Iteration 7248 => Loss: 50.94401084625456377353\n",
      "Iteration 7249 => Loss: 50.94381146825794814958\n",
      "Iteration 7250 => Loss: 50.94361209182804373086\n",
      "Iteration 7251 => Loss: 50.94341271696487893905\n",
      "Iteration 7252 => Loss: 50.94321334366838982532\n",
      "Iteration 7253 => Loss: 50.94301397193858349510\n",
      "Iteration 7254 => Loss: 50.94281460177542442125\n",
      "Iteration 7255 => Loss: 50.94261523317892681462\n",
      "Iteration 7256 => Loss: 50.94241586614904093722\n",
      "Iteration 7257 => Loss: 50.94221650068577389447\n",
      "Iteration 7258 => Loss: 50.94201713678907594840\n",
      "Iteration 7259 => Loss: 50.94181777445898973156\n",
      "Iteration 7260 => Loss: 50.94161841369544418967\n",
      "Iteration 7261 => Loss: 50.94141905449845353360\n",
      "Iteration 7262 => Loss: 50.94121969686798934163\n",
      "Iteration 7263 => Loss: 50.94102034080400187577\n",
      "Iteration 7264 => Loss: 50.94082098630652666316\n",
      "Iteration 7265 => Loss: 50.94062163337554238751\n",
      "Iteration 7266 => Loss: 50.94042228201100641627\n",
      "Iteration 7267 => Loss: 50.94022293221294006571\n",
      "Iteration 7268 => Loss: 50.94002358398125807071\n",
      "Iteration 7269 => Loss: 50.93982423731599595840\n",
      "Iteration 7270 => Loss: 50.93962489221714662335\n",
      "Iteration 7271 => Loss: 50.93942554868466032758\n",
      "Iteration 7272 => Loss: 50.93922620671855128194\n",
      "Iteration 7273 => Loss: 50.93902686631875553758\n",
      "Iteration 7274 => Loss: 50.93882752748531572706\n",
      "Iteration 7275 => Loss: 50.93862819021816790155\n",
      "Iteration 7276 => Loss: 50.93842885451732627189\n",
      "Iteration 7277 => Loss: 50.93822952038276952180\n",
      "Iteration 7278 => Loss: 50.93803018781447633501\n",
      "Iteration 7279 => Loss: 50.93783085681239697351\n",
      "Iteration 7280 => Loss: 50.93763152737658828073\n",
      "Iteration 7281 => Loss: 50.93743219950695788611\n",
      "Iteration 7282 => Loss: 50.93723287320355552765\n",
      "Iteration 7283 => Loss: 50.93703354846631015107\n",
      "Iteration 7284 => Loss: 50.93683422529522886180\n",
      "Iteration 7285 => Loss: 50.93663490369031876526\n",
      "Iteration 7286 => Loss: 50.93643558365151591261\n",
      "Iteration 7287 => Loss: 50.93623626517881319842\n",
      "Iteration 7288 => Loss: 50.93603694827221772812\n",
      "Iteration 7289 => Loss: 50.93583763293172950171\n",
      "Iteration 7290 => Loss: 50.93563831915728457034\n",
      "Iteration 7291 => Loss: 50.93543900694889714487\n",
      "Iteration 7292 => Loss: 50.93523969630653880358\n",
      "Iteration 7293 => Loss: 50.93504038723018112478\n",
      "Iteration 7294 => Loss: 50.93484107971981700302\n",
      "Iteration 7295 => Loss: 50.93464177377548196546\n",
      "Iteration 7296 => Loss: 50.93444246939709074695\n",
      "Iteration 7297 => Loss: 50.93424316658464334751\n",
      "Iteration 7298 => Loss: 50.93404386533812555626\n",
      "Iteration 7299 => Loss: 50.93384456565753737323\n",
      "Iteration 7300 => Loss: 50.93364526754286458754\n",
      "Iteration 7301 => Loss: 50.93344597099405746121\n",
      "Iteration 7302 => Loss: 50.93324667601112309967\n",
      "Iteration 7303 => Loss: 50.93304738259404018663\n",
      "Iteration 7304 => Loss: 50.93284809074280872210\n",
      "Iteration 7305 => Loss: 50.93264880045739317893\n",
      "Iteration 7306 => Loss: 50.93244951173777224085\n",
      "Iteration 7307 => Loss: 50.93225022458393880243\n",
      "Iteration 7308 => Loss: 50.93205093899589286366\n",
      "Iteration 7309 => Loss: 50.93185165497359179199\n",
      "Iteration 7310 => Loss: 50.93165237251703558741\n",
      "Iteration 7311 => Loss: 50.93145309162620293364\n",
      "Iteration 7312 => Loss: 50.93125381230105119812\n",
      "Iteration 7313 => Loss: 50.93105453454162301341\n",
      "Iteration 7314 => Loss: 50.93085525834786153609\n",
      "Iteration 7315 => Loss: 50.93065598371975966074\n",
      "Iteration 7316 => Loss: 50.93045671065730317650\n",
      "Iteration 7317 => Loss: 50.93025743916047076709\n",
      "Iteration 7318 => Loss: 50.93005816922923401080\n",
      "Iteration 7319 => Loss: 50.92985890086361422391\n",
      "Iteration 7320 => Loss: 50.92965963406356877385\n",
      "Iteration 7321 => Loss: 50.92946036882909055521\n",
      "Iteration 7322 => Loss: 50.92926110516014404084\n",
      "Iteration 7323 => Loss: 50.92906184305672212531\n",
      "Iteration 7324 => Loss: 50.92886258251881770320\n",
      "Iteration 7325 => Loss: 50.92866332354643077451\n",
      "Iteration 7326 => Loss: 50.92846406613953291753\n",
      "Iteration 7327 => Loss: 50.92826481029807439427\n",
      "Iteration 7328 => Loss: 50.92806555602207652100\n",
      "Iteration 7329 => Loss: 50.92786630331149666517\n",
      "Iteration 7330 => Loss: 50.92766705216636324849\n",
      "Iteration 7331 => Loss: 50.92746780258663363838\n",
      "Iteration 7332 => Loss: 50.92726855457225809687\n",
      "Iteration 7333 => Loss: 50.92706930812326504565\n",
      "Iteration 7334 => Loss: 50.92687006323964027388\n",
      "Iteration 7335 => Loss: 50.92667081992134825441\n",
      "Iteration 7336 => Loss: 50.92647157816837477640\n",
      "Iteration 7337 => Loss: 50.92627233798071273441\n",
      "Iteration 7338 => Loss: 50.92607309935831949588\n",
      "Iteration 7339 => Loss: 50.92587386230123769337\n",
      "Iteration 7340 => Loss: 50.92567462680938916719\n",
      "Iteration 7341 => Loss: 50.92547539288277391734\n",
      "Iteration 7342 => Loss: 50.92527616052140615466\n",
      "Iteration 7343 => Loss: 50.92507692972525745745\n",
      "Iteration 7344 => Loss: 50.92487770049428519314\n",
      "Iteration 7345 => Loss: 50.92467847282851067803\n",
      "Iteration 7346 => Loss: 50.92447924672787706868\n",
      "Iteration 7347 => Loss: 50.92428002219237725967\n",
      "Iteration 7348 => Loss: 50.92408079922203967271\n",
      "Iteration 7349 => Loss: 50.92388157781680746439\n",
      "Iteration 7350 => Loss: 50.92368235797668774012\n",
      "Iteration 7351 => Loss: 50.92348313970163076192\n",
      "Iteration 7352 => Loss: 50.92328392299166495150\n",
      "Iteration 7353 => Loss: 50.92308470784674767629\n",
      "Iteration 7354 => Loss: 50.92288549426684340915\n",
      "Iteration 7355 => Loss: 50.92268628225196636095\n",
      "Iteration 7356 => Loss: 50.92248707180210232082\n",
      "Iteration 7357 => Loss: 50.92228786291722286705\n",
      "Iteration 7358 => Loss: 50.92208865559732799966\n",
      "Iteration 7359 => Loss: 50.92188944984238929692\n",
      "Iteration 7360 => Loss: 50.92169024565238544255\n",
      "Iteration 7361 => Loss: 50.92149104302728801486\n",
      "Iteration 7362 => Loss: 50.92129184196713964639\n",
      "Iteration 7363 => Loss: 50.92109264247186928287\n",
      "Iteration 7364 => Loss: 50.92089344454146981889\n",
      "Iteration 7365 => Loss: 50.92069424817594835986\n",
      "Iteration 7366 => Loss: 50.92049505337525516779\n",
      "Iteration 7367 => Loss: 50.92029586013940445355\n",
      "Iteration 7368 => Loss: 50.92009666846837490084\n",
      "Iteration 7369 => Loss: 50.91989747836213808796\n",
      "Iteration 7370 => Loss: 50.91969828982068690948\n",
      "Iteration 7371 => Loss: 50.91949910284400004912\n",
      "Iteration 7372 => Loss: 50.91929991743206329602\n",
      "Iteration 7373 => Loss: 50.91910073358486954476\n",
      "Iteration 7374 => Loss: 50.91890155130240458448\n",
      "Iteration 7375 => Loss: 50.91870237058463999347\n",
      "Iteration 7376 => Loss: 50.91850319143157577173\n",
      "Iteration 7377 => Loss: 50.91830401384316928670\n",
      "Iteration 7378 => Loss: 50.91810483781943474924\n",
      "Iteration 7379 => Loss: 50.91790566336035794848\n",
      "Iteration 7380 => Loss: 50.91770649046586072473\n",
      "Iteration 7381 => Loss: 50.91750731913600702683\n",
      "Iteration 7382 => Loss: 50.91730814937075422222\n",
      "Iteration 7383 => Loss: 50.91710898117008810004\n",
      "Iteration 7384 => Loss: 50.91690981453397313317\n",
      "Iteration 7385 => Loss: 50.91671064946241642701\n",
      "Iteration 7386 => Loss: 50.91651148595538245445\n",
      "Iteration 7387 => Loss: 50.91631232401287832090\n",
      "Iteration 7388 => Loss: 50.91611316363488271008\n",
      "Iteration 7389 => Loss: 50.91591400482134588401\n",
      "Iteration 7390 => Loss: 50.91571484757231047524\n",
      "Iteration 7391 => Loss: 50.91551569188773385122\n",
      "Iteration 7392 => Loss: 50.91531653776757337937\n",
      "Iteration 7393 => Loss: 50.91511738521185037598\n",
      "Iteration 7394 => Loss: 50.91491823422055063020\n",
      "Iteration 7395 => Loss: 50.91471908479363150946\n",
      "Iteration 7396 => Loss: 50.91451993693110011918\n",
      "Iteration 7397 => Loss: 50.91432079063292803767\n",
      "Iteration 7398 => Loss: 50.91412164589910815948\n",
      "Iteration 7399 => Loss: 50.91392250272961206292\n",
      "Iteration 7400 => Loss: 50.91372336112444685341\n",
      "Iteration 7401 => Loss: 50.91352422108357700381\n",
      "Iteration 7402 => Loss: 50.91332508260698830327\n",
      "Iteration 7403 => Loss: 50.91312594569465943550\n",
      "Iteration 7404 => Loss: 50.91292681034661882222\n",
      "Iteration 7405 => Loss: 50.91272767656278830373\n",
      "Iteration 7406 => Loss: 50.91252854434319630172\n",
      "Iteration 7407 => Loss: 50.91232941368782149993\n",
      "Iteration 7408 => Loss: 50.91213028459663547665\n",
      "Iteration 7409 => Loss: 50.91193115706961691558\n",
      "Iteration 7410 => Loss: 50.91173203110677292216\n",
      "Iteration 7411 => Loss: 50.91153290670807507468\n",
      "Iteration 7412 => Loss: 50.91133378387350916228\n",
      "Iteration 7413 => Loss: 50.91113466260305386868\n",
      "Iteration 7414 => Loss: 50.91093554289668787760\n",
      "Iteration 7415 => Loss: 50.91073642475443961075\n",
      "Iteration 7416 => Loss: 50.91053730817624511928\n",
      "Iteration 7417 => Loss: 50.91033819316211150863\n",
      "Iteration 7418 => Loss: 50.91013907971201035707\n",
      "Iteration 7419 => Loss: 50.90993996782593455919\n",
      "Iteration 7420 => Loss: 50.90974085750388411498\n",
      "Iteration 7421 => Loss: 50.90954174874580218102\n",
      "Iteration 7422 => Loss: 50.90934264155169586274\n",
      "Iteration 7423 => Loss: 50.90914353592160068729\n",
      "Iteration 7424 => Loss: 50.90894443185541717867\n",
      "Iteration 7425 => Loss: 50.90874532935315244231\n",
      "Iteration 7426 => Loss: 50.90854622841483489992\n",
      "Iteration 7427 => Loss: 50.90834712904041481352\n",
      "Iteration 7428 => Loss: 50.90814803122987086681\n",
      "Iteration 7429 => Loss: 50.90794893498319595437\n",
      "Iteration 7430 => Loss: 50.90774984030039718164\n",
      "Iteration 7431 => Loss: 50.90755074718143191603\n",
      "Iteration 7432 => Loss: 50.90735165562629305214\n",
      "Iteration 7433 => Loss: 50.90715256563496637909\n",
      "Iteration 7434 => Loss: 50.90695347720740215891\n",
      "Iteration 7435 => Loss: 50.90675439034366434043\n",
      "Iteration 7436 => Loss: 50.90655530504366765854\n",
      "Iteration 7437 => Loss: 50.90635622130741921865\n",
      "Iteration 7438 => Loss: 50.90615713913492612619\n",
      "Iteration 7439 => Loss: 50.90595805852613153775\n",
      "Iteration 7440 => Loss: 50.90575897948104966417\n",
      "Iteration 7441 => Loss: 50.90555990199965918919\n",
      "Iteration 7442 => Loss: 50.90536082608194590193\n",
      "Iteration 7443 => Loss: 50.90516175172788138070\n",
      "Iteration 7444 => Loss: 50.90496267893746562549\n",
      "Iteration 7445 => Loss: 50.90476360771067021460\n",
      "Iteration 7446 => Loss: 50.90456453804748804259\n",
      "Iteration 7447 => Loss: 50.90436546994791200405\n",
      "Iteration 7448 => Loss: 50.90416640341191367725\n",
      "Iteration 7449 => Loss: 50.90396733843950727305\n",
      "Iteration 7450 => Loss: 50.90376827503063594804\n",
      "Iteration 7451 => Loss: 50.90356921318527838594\n",
      "Iteration 7452 => Loss: 50.90337015290348432472\n",
      "Iteration 7453 => Loss: 50.90317109418516139385\n",
      "Iteration 7454 => Loss: 50.90297203703037354217\n",
      "Iteration 7455 => Loss: 50.90277298143902839911\n",
      "Iteration 7456 => Loss: 50.90257392741114017554\n",
      "Iteration 7457 => Loss: 50.90237487494672308230\n",
      "Iteration 7458 => Loss: 50.90217582404571317056\n",
      "Iteration 7459 => Loss: 50.90197677470816728373\n",
      "Iteration 7460 => Loss: 50.90177772693395752412\n",
      "Iteration 7461 => Loss: 50.90157868072318336772\n",
      "Iteration 7462 => Loss: 50.90137963607575954939\n",
      "Iteration 7463 => Loss: 50.90118059299170738541\n",
      "Iteration 7464 => Loss: 50.90098155147099845408\n",
      "Iteration 7465 => Loss: 50.90078251151359722826\n",
      "Iteration 7466 => Loss: 50.90058347311951081338\n",
      "Iteration 7467 => Loss: 50.90038443628871789315\n",
      "Iteration 7468 => Loss: 50.90018540102121846758\n",
      "Iteration 7469 => Loss: 50.89998636731699832580\n",
      "Iteration 7470 => Loss: 50.89978733517600062441\n",
      "Iteration 7471 => Loss: 50.89958830459823957426\n",
      "Iteration 7472 => Loss: 50.89938927558372938620\n",
      "Iteration 7473 => Loss: 50.89919024813239900595\n",
      "Iteration 7474 => Loss: 50.89899122224425553895\n",
      "Iteration 7475 => Loss: 50.89879219791930609063\n",
      "Iteration 7476 => Loss: 50.89859317515752934469\n",
      "Iteration 7477 => Loss: 50.89839415395888266858\n",
      "Iteration 7478 => Loss: 50.89819513432338027314\n",
      "Iteration 7479 => Loss: 50.89799611625096531498\n",
      "Iteration 7480 => Loss: 50.89779709974168753206\n",
      "Iteration 7481 => Loss: 50.89759808479545455384\n",
      "Iteration 7482 => Loss: 50.89739907141232322374\n",
      "Iteration 7483 => Loss: 50.89720005959225801462\n",
      "Iteration 7484 => Loss: 50.89700104933521629391\n",
      "Iteration 7485 => Loss: 50.89680204064119806162\n",
      "Iteration 7486 => Loss: 50.89660303351018910689\n",
      "Iteration 7487 => Loss: 50.89640402794219653515\n",
      "Iteration 7488 => Loss: 50.89620502393718481926\n",
      "Iteration 7489 => Loss: 50.89600602149513264294\n",
      "Iteration 7490 => Loss: 50.89580702061603290076\n",
      "Iteration 7491 => Loss: 50.89560802129987848730\n",
      "Iteration 7492 => Loss: 50.89540902354663387541\n",
      "Iteration 7493 => Loss: 50.89521002735630617053\n",
      "Iteration 7494 => Loss: 50.89501103272886695095\n",
      "Iteration 7495 => Loss: 50.89481203966431621666\n",
      "Iteration 7496 => Loss: 50.89461304816261133510\n",
      "Iteration 7497 => Loss: 50.89441405822378072799\n",
      "Iteration 7498 => Loss: 50.89421506984776044646\n",
      "Iteration 7499 => Loss: 50.89401608303457180682\n",
      "Iteration 7500 => Loss: 50.89381709778420770363\n",
      "Iteration 7501 => Loss: 50.89361811409658287175\n",
      "Iteration 7502 => Loss: 50.89341913197176126005\n",
      "Iteration 7503 => Loss: 50.89322015140968602509\n",
      "Iteration 7504 => Loss: 50.89302117241036427231\n",
      "Iteration 7505 => Loss: 50.89282219497378179085\n",
      "Iteration 7506 => Loss: 50.89262321909991015900\n",
      "Iteration 7507 => Loss: 50.89242424478873516591\n",
      "Iteration 7508 => Loss: 50.89222527204023549530\n",
      "Iteration 7509 => Loss: 50.89202630085441825258\n",
      "Iteration 7510 => Loss: 50.89182733123124791064\n",
      "Iteration 7511 => Loss: 50.89162836317073157488\n",
      "Iteration 7512 => Loss: 50.89142939667284792904\n",
      "Iteration 7513 => Loss: 50.89123043173756855140\n",
      "Iteration 7514 => Loss: 50.89103146836487923110\n",
      "Iteration 7515 => Loss: 50.89083250655477996816\n",
      "Iteration 7516 => Loss: 50.89063354630723523542\n",
      "Iteration 7517 => Loss: 50.89043458762225924374\n",
      "Iteration 7518 => Loss: 50.89023563049980936057\n",
      "Iteration 7519 => Loss: 50.89003667493989269133\n",
      "Iteration 7520 => Loss: 50.88983772094246660345\n",
      "Iteration 7521 => Loss: 50.88963876850757372949\n",
      "Iteration 7522 => Loss: 50.88943981763512880434\n",
      "Iteration 7523 => Loss: 50.88924086832514603884\n",
      "Iteration 7524 => Loss: 50.88904192057761832757\n",
      "Iteration 7525 => Loss: 50.88884297439253145967\n",
      "Iteration 7526 => Loss: 50.88864402976987832972\n",
      "Iteration 7527 => Loss: 50.88844508670961630514\n",
      "Iteration 7528 => Loss: 50.88824614521174538595\n",
      "Iteration 7529 => Loss: 50.88804720527624425586\n",
      "Iteration 7530 => Loss: 50.88784826690313423114\n",
      "Iteration 7531 => Loss: 50.88764933009233004668\n",
      "Iteration 7532 => Loss: 50.88745039484387433504\n",
      "Iteration 7533 => Loss: 50.88725146115773867450\n",
      "Iteration 7534 => Loss: 50.88705252903391595964\n",
      "Iteration 7535 => Loss: 50.88685359847237776876\n",
      "Iteration 7536 => Loss: 50.88665466947310989099\n",
      "Iteration 7537 => Loss: 50.88645574203609101005\n",
      "Iteration 7538 => Loss: 50.88625681616131402052\n",
      "Iteration 7539 => Loss: 50.88605789184877892239\n",
      "Iteration 7540 => Loss: 50.88585896909846439939\n",
      "Iteration 7541 => Loss: 50.88566004791035624066\n",
      "Iteration 7542 => Loss: 50.88546112828444023535\n",
      "Iteration 7543 => Loss: 50.88526221022067375088\n",
      "Iteration 7544 => Loss: 50.88506329371907099812\n",
      "Iteration 7545 => Loss: 50.88486437877961066079\n",
      "Iteration 7546 => Loss: 50.88466546540229273887\n",
      "Iteration 7547 => Loss: 50.88446655358707459982\n",
      "Iteration 7548 => Loss: 50.88426764333394203277\n",
      "Iteration 7549 => Loss: 50.88406873464291635401\n",
      "Iteration 7550 => Loss: 50.88386982751394782554\n",
      "Iteration 7551 => Loss: 50.88367092194704355279\n",
      "Iteration 7552 => Loss: 50.88347201794216800863\n",
      "Iteration 7553 => Loss: 50.88327311549932119306\n",
      "Iteration 7554 => Loss: 50.88307421461850310607\n",
      "Iteration 7555 => Loss: 50.88287531529967822053\n",
      "Iteration 7556 => Loss: 50.88267641754281100930\n",
      "Iteration 7557 => Loss: 50.88247752134792278866\n",
      "Iteration 7558 => Loss: 50.88227862671501355862\n",
      "Iteration 7559 => Loss: 50.88207973364402647576\n",
      "Iteration 7560 => Loss: 50.88188084213496864550\n",
      "Iteration 7561 => Loss: 50.88168195218777611899\n",
      "Iteration 7562 => Loss: 50.88148306380252705594\n",
      "Iteration 7563 => Loss: 50.88128417697916461293\n",
      "Iteration 7564 => Loss: 50.88108529171764615739\n",
      "Iteration 7565 => Loss: 50.88088640801797879476\n",
      "Iteration 7566 => Loss: 50.88068752588016252503\n",
      "Iteration 7567 => Loss: 50.88048864530416892649\n",
      "Iteration 7568 => Loss: 50.88028976628996957743\n",
      "Iteration 7569 => Loss: 50.88009088883757868871\n",
      "Iteration 7570 => Loss: 50.87989201294696783862\n",
      "Iteration 7571 => Loss: 50.87969313861810150001\n",
      "Iteration 7572 => Loss: 50.87949426585101520004\n",
      "Iteration 7573 => Loss: 50.87929539464565920071\n",
      "Iteration 7574 => Loss: 50.87909652500201929115\n",
      "Iteration 7575 => Loss: 50.87889765692007415510\n",
      "Iteration 7576 => Loss: 50.87869879039985221425\n",
      "Iteration 7577 => Loss: 50.87849992544127530891\n",
      "Iteration 7578 => Loss: 50.87830106204437186079\n",
      "Iteration 7579 => Loss: 50.87810220020912055361\n",
      "Iteration 7580 => Loss: 50.87790333993552138736\n",
      "Iteration 7581 => Loss: 50.87770448122353883491\n",
      "Iteration 7582 => Loss: 50.87750562407314447455\n",
      "Iteration 7583 => Loss: 50.87730676848435962256\n",
      "Iteration 7584 => Loss: 50.87710791445713454095\n",
      "Iteration 7585 => Loss: 50.87690906199149765143\n",
      "Iteration 7586 => Loss: 50.87671021108739211058\n",
      "Iteration 7587 => Loss: 50.87651136174483212926\n",
      "Iteration 7588 => Loss: 50.87631251396377507490\n",
      "Iteration 7589 => Loss: 50.87611366774422094750\n",
      "Iteration 7590 => Loss: 50.87591482308619106334\n",
      "Iteration 7591 => Loss: 50.87571597998964278986\n",
      "Iteration 7592 => Loss: 50.87551713845451217821\n",
      "Iteration 7593 => Loss: 50.87531829848085607182\n",
      "Iteration 7594 => Loss: 50.87511946006863183811\n",
      "Iteration 7595 => Loss: 50.87492062321783237167\n",
      "Iteration 7596 => Loss: 50.87472178792842214534\n",
      "Iteration 7597 => Loss: 50.87452295420042247542\n",
      "Iteration 7598 => Loss: 50.87432412203379072935\n",
      "Iteration 7599 => Loss: 50.87412529142851980168\n",
      "Iteration 7600 => Loss: 50.87392646238461679786\n",
      "Iteration 7601 => Loss: 50.87372763490201066361\n",
      "Iteration 7602 => Loss: 50.87352880898075113691\n",
      "Iteration 7603 => Loss: 50.87332998462080979607\n",
      "Iteration 7604 => Loss: 50.87313116182212269223\n",
      "Iteration 7605 => Loss: 50.87293234058473245796\n",
      "Iteration 7606 => Loss: 50.87273352090861777697\n",
      "Iteration 7607 => Loss: 50.87253470279374312213\n",
      "Iteration 7608 => Loss: 50.87233588624008717716\n",
      "Iteration 7609 => Loss: 50.87213707124765704748\n",
      "Iteration 7610 => Loss: 50.87193825781643141681\n",
      "Iteration 7611 => Loss: 50.87173944594641028516\n",
      "Iteration 7612 => Loss: 50.87154063563756523081\n",
      "Iteration 7613 => Loss: 50.87134182688986072662\n",
      "Iteration 7614 => Loss: 50.87114301970332519431\n",
      "Iteration 7615 => Loss: 50.87094421407791600132\n",
      "Iteration 7616 => Loss: 50.87074541001362604220\n",
      "Iteration 7617 => Loss: 50.87054660751045531697\n",
      "Iteration 7618 => Loss: 50.87034780656836829849\n",
      "Iteration 7619 => Loss: 50.87014900718734367047\n",
      "Iteration 7620 => Loss: 50.86995020936739564377\n",
      "Iteration 7621 => Loss: 50.86975141310851000753\n",
      "Iteration 7622 => Loss: 50.86955261841062991834\n",
      "Iteration 7623 => Loss: 50.86935382527379800877\n",
      "Iteration 7624 => Loss: 50.86915503369795743538\n",
      "Iteration 7625 => Loss: 50.86895624368310819818\n",
      "Iteration 7626 => Loss: 50.86875745522922898090\n",
      "Iteration 7627 => Loss: 50.86855866833631978352\n",
      "Iteration 7628 => Loss: 50.86835988300438771148\n",
      "Iteration 7629 => Loss: 50.86816109923336881593\n",
      "Iteration 7630 => Loss: 50.86796231702327730773\n",
      "Iteration 7631 => Loss: 50.86776353637407765973\n",
      "Iteration 7632 => Loss: 50.86756475728577697737\n",
      "Iteration 7633 => Loss: 50.86736597975834683893\n",
      "Iteration 7634 => Loss: 50.86716720379180145528\n",
      "Iteration 7635 => Loss: 50.86696842938611951013\n",
      "Iteration 7636 => Loss: 50.86676965654122994920\n",
      "Iteration 7637 => Loss: 50.86657088525719672134\n",
      "Iteration 7638 => Loss: 50.86637211553394877228\n",
      "Iteration 7639 => Loss: 50.86617334737152162916\n",
      "Iteration 7640 => Loss: 50.86597458076983713227\n",
      "Iteration 7641 => Loss: 50.86577581572893791417\n",
      "Iteration 7642 => Loss: 50.86557705224880976402\n",
      "Iteration 7643 => Loss: 50.86537829032939583840\n",
      "Iteration 7644 => Loss: 50.86517952997071745358\n",
      "Iteration 7645 => Loss: 50.86498077117272487158\n",
      "Iteration 7646 => Loss: 50.86478201393545361952\n",
      "Iteration 7647 => Loss: 50.86458325825883264315\n",
      "Iteration 7648 => Loss: 50.86438450414290457502\n",
      "Iteration 7649 => Loss: 50.86418575158761257171\n",
      "Iteration 7650 => Loss: 50.86398700059297084408\n",
      "Iteration 7651 => Loss: 50.86378825115895807585\n",
      "Iteration 7652 => Loss: 50.86358950328556005616\n",
      "Iteration 7653 => Loss: 50.86339075697273415244\n",
      "Iteration 7654 => Loss: 50.86319201222050168099\n",
      "Iteration 7655 => Loss: 50.86299326902883422008\n",
      "Iteration 7656 => Loss: 50.86279452739775308601\n",
      "Iteration 7657 => Loss: 50.86259578732716590821\n",
      "Iteration 7658 => Loss: 50.86239704881712953011\n",
      "Iteration 7659 => Loss: 50.86219831186759421371\n",
      "Iteration 7660 => Loss: 50.86199957647855995901\n",
      "Iteration 7661 => Loss: 50.86180084265002676602\n",
      "Iteration 7662 => Loss: 50.86160211038193779132\n",
      "Iteration 7663 => Loss: 50.86140337967433566746\n",
      "Iteration 7664 => Loss: 50.86120465052714934018\n",
      "Iteration 7665 => Loss: 50.86100592294037170404\n",
      "Iteration 7666 => Loss: 50.86080719691405249705\n",
      "Iteration 7667 => Loss: 50.86060847244810645407\n",
      "Iteration 7668 => Loss: 50.86040974954254778595\n",
      "Iteration 7669 => Loss: 50.86021102819736938727\n",
      "Iteration 7670 => Loss: 50.86001230841255704718\n",
      "Iteration 7671 => Loss: 50.85981359018805392225\n",
      "Iteration 7672 => Loss: 50.85961487352391685590\n",
      "Iteration 7673 => Loss: 50.85941615842008189929\n",
      "Iteration 7674 => Loss: 50.85921744487654905242\n",
      "Iteration 7675 => Loss: 50.85901873289330410444\n",
      "Iteration 7676 => Loss: 50.85882002247031863362\n",
      "Iteration 7677 => Loss: 50.85862131360760685084\n",
      "Iteration 7678 => Loss: 50.85842260630515454523\n",
      "Iteration 7679 => Loss: 50.85822390056291197880\n",
      "Iteration 7680 => Loss: 50.85802519638089336240\n",
      "Iteration 7681 => Loss: 50.85782649375907737976\n",
      "Iteration 7682 => Loss: 50.85762779269745692545\n",
      "Iteration 7683 => Loss: 50.85742909319601068319\n",
      "Iteration 7684 => Loss: 50.85723039525471733668\n",
      "Iteration 7685 => Loss: 50.85703169887359820223\n",
      "Iteration 7686 => Loss: 50.85683300405257512011\n",
      "Iteration 7687 => Loss: 50.85663431079169782834\n",
      "Iteration 7688 => Loss: 50.85643561909093079976\n",
      "Iteration 7689 => Loss: 50.85623692895023850724\n",
      "Iteration 7690 => Loss: 50.85603824036962095079\n",
      "Iteration 7691 => Loss: 50.85583955334906391954\n",
      "Iteration 7692 => Loss: 50.85564086788859583521\n",
      "Iteration 7693 => Loss: 50.85544218398812432724\n",
      "Iteration 7694 => Loss: 50.85524350164767781735\n",
      "Iteration 7695 => Loss: 50.85504482086725630552\n",
      "Iteration 7696 => Loss: 50.85484614164683137005\n",
      "Iteration 7697 => Loss: 50.85464746398638169467\n",
      "Iteration 7698 => Loss: 50.85444878788590727936\n",
      "Iteration 7699 => Loss: 50.85425011334537259700\n",
      "Iteration 7700 => Loss: 50.85405144036479185843\n",
      "Iteration 7701 => Loss: 50.85385276894410822024\n",
      "Iteration 7702 => Loss: 50.85365409908337142042\n",
      "Iteration 7703 => Loss: 50.85345543078248198299\n",
      "Iteration 7704 => Loss: 50.85325676404153938392\n",
      "Iteration 7705 => Loss: 50.85305809886042283097\n",
      "Iteration 7706 => Loss: 50.85285943523918206211\n",
      "Iteration 7707 => Loss: 50.85266077317778155020\n",
      "Iteration 7708 => Loss: 50.85246211267619997898\n",
      "Iteration 7709 => Loss: 50.85226345373444445386\n",
      "Iteration 7710 => Loss: 50.85206479635247944771\n",
      "Iteration 7711 => Loss: 50.85186614053030496052\n",
      "Iteration 7712 => Loss: 50.85166748626789967602\n",
      "Iteration 7713 => Loss: 50.85146883356525648878\n",
      "Iteration 7714 => Loss: 50.85127018242233987166\n",
      "Iteration 7715 => Loss: 50.85107153283919245723\n",
      "Iteration 7716 => Loss: 50.85087288481572898036\n",
      "Iteration 7717 => Loss: 50.85067423835198496818\n",
      "Iteration 7718 => Loss: 50.85047559344794620984\n",
      "Iteration 7719 => Loss: 50.85027695010354875649\n",
      "Iteration 7720 => Loss: 50.85007830831880681899\n",
      "Iteration 7721 => Loss: 50.84987966809374881905\n",
      "Iteration 7722 => Loss: 50.84968102942830370239\n",
      "Iteration 7723 => Loss: 50.84948239232249278530\n",
      "Iteration 7724 => Loss: 50.84928375677628764606\n",
      "Iteration 7725 => Loss: 50.84908512278966696840\n",
      "Iteration 7726 => Loss: 50.84888649036262364689\n",
      "Iteration 7727 => Loss: 50.84868785949516478695\n",
      "Iteration 7728 => Loss: 50.84848923018724065059\n",
      "Iteration 7729 => Loss: 50.84829060243885834325\n",
      "Iteration 7730 => Loss: 50.84809197624999654863\n",
      "Iteration 7731 => Loss: 50.84789335162065526674\n",
      "Iteration 7732 => Loss: 50.84769472855081318130\n",
      "Iteration 7733 => Loss: 50.84749610704042765974\n",
      "Iteration 7734 => Loss: 50.84729748708952712377\n",
      "Iteration 7735 => Loss: 50.84709886869809025711\n",
      "Iteration 7736 => Loss: 50.84690025186607442720\n",
      "Iteration 7737 => Loss: 50.84670163659350095031\n",
      "Iteration 7738 => Loss: 50.84650302288034140474\n",
      "Iteration 7739 => Loss: 50.84630441072658868507\n",
      "Iteration 7740 => Loss: 50.84610580013221436957\n",
      "Iteration 7741 => Loss: 50.84590719109719714197\n",
      "Iteration 7742 => Loss: 50.84570858362155121313\n",
      "Iteration 7743 => Loss: 50.84550997770526947761\n",
      "Iteration 7744 => Loss: 50.84531137334830219743\n",
      "Iteration 7745 => Loss: 50.84511277055064226715\n",
      "Iteration 7746 => Loss: 50.84491416931229679221\n",
      "Iteration 7747 => Loss: 50.84471556963323024547\n",
      "Iteration 7748 => Loss: 50.84451697151344973236\n",
      "Iteration 7749 => Loss: 50.84431837495293393658\n",
      "Iteration 7750 => Loss: 50.84411977995168996358\n",
      "Iteration 7751 => Loss: 50.84392118650963965365\n",
      "Iteration 7752 => Loss: 50.84372259462683985021\n",
      "Iteration 7753 => Loss: 50.84352400430322660441\n",
      "Iteration 7754 => Loss: 50.84332541553881412710\n",
      "Iteration 7755 => Loss: 50.84312682833358820744\n",
      "Iteration 7756 => Loss: 50.84292824268752752914\n",
      "Iteration 7757 => Loss: 50.84272965860062498678\n",
      "Iteration 7758 => Loss: 50.84253107607283084235\n",
      "Iteration 7759 => Loss: 50.84233249510418772843\n",
      "Iteration 7760 => Loss: 50.84213391569467432873\n",
      "Iteration 7761 => Loss: 50.84193533784424090527\n",
      "Iteration 7762 => Loss: 50.84173676155288745804\n",
      "Iteration 7763 => Loss: 50.84153818682060688161\n",
      "Iteration 7764 => Loss: 50.84133961364739917599\n",
      "Iteration 7765 => Loss: 50.84114104203321460318\n",
      "Iteration 7766 => Loss: 50.84094247197807447947\n",
      "Iteration 7767 => Loss: 50.84074390348192906686\n",
      "Iteration 7768 => Loss: 50.84054533654482810334\n",
      "Iteration 7769 => Loss: 50.84034677116667211294\n",
      "Iteration 7770 => Loss: 50.84014820734751083364\n",
      "Iteration 7771 => Loss: 50.83994964508732294917\n",
      "Iteration 7772 => Loss: 50.83975108438605872152\n",
      "Iteration 7773 => Loss: 50.83955252524374657241\n",
      "Iteration 7774 => Loss: 50.83935396766034386928\n",
      "Iteration 7775 => Loss: 50.83915541163584350670\n",
      "Iteration 7776 => Loss: 50.83895685717025259009\n",
      "Iteration 7777 => Loss: 50.83875830426352138147\n",
      "Iteration 7778 => Loss: 50.83855975291567830254\n",
      "Iteration 7779 => Loss: 50.83836120312670203703\n",
      "Iteration 7780 => Loss: 50.83816265489651442522\n",
      "Iteration 7781 => Loss: 50.83796410822520073225\n",
      "Iteration 7782 => Loss: 50.83776556311266148214\n",
      "Iteration 7783 => Loss: 50.83756701955895351830\n",
      "Iteration 7784 => Loss: 50.83736847756402710274\n",
      "Iteration 7785 => Loss: 50.83716993712785381376\n",
      "Iteration 7786 => Loss: 50.83697139825043365136\n",
      "Iteration 7787 => Loss: 50.83677286093178082638\n",
      "Iteration 7788 => Loss: 50.83657432517183849541\n",
      "Iteration 7789 => Loss: 50.83637579097059955302\n",
      "Iteration 7790 => Loss: 50.83617725832809952635\n",
      "Iteration 7791 => Loss: 50.83597872724426025570\n",
      "Iteration 7792 => Loss: 50.83578019771910305735\n",
      "Iteration 7793 => Loss: 50.83558166975263503673\n",
      "Iteration 7794 => Loss: 50.83538314334480645584\n",
      "Iteration 7795 => Loss: 50.83518461849558178756\n",
      "Iteration 7796 => Loss: 50.83498609520499655900\n",
      "Iteration 7797 => Loss: 50.83478757347301524305\n",
      "Iteration 7798 => Loss: 50.83458905329962362885\n",
      "Iteration 7799 => Loss: 50.83439053468482882181\n",
      "Iteration 7800 => Loss: 50.83419201762860950566\n",
      "Iteration 7801 => Loss: 50.83399350213090883699\n",
      "Iteration 7802 => Loss: 50.83379498819179076463\n",
      "Iteration 7803 => Loss: 50.83359647581117002346\n",
      "Iteration 7804 => Loss: 50.83339796498906792976\n",
      "Iteration 7805 => Loss: 50.83319945572548448354\n",
      "Iteration 7806 => Loss: 50.83300094802035573593\n",
      "Iteration 7807 => Loss: 50.83280244187370300324\n",
      "Iteration 7808 => Loss: 50.83260393728554049630\n",
      "Iteration 7809 => Loss: 50.83240543425578295000\n",
      "Iteration 7810 => Loss: 50.83220693278448720775\n",
      "Iteration 7811 => Loss: 50.83200843287160353157\n",
      "Iteration 7812 => Loss: 50.83180993451710349973\n",
      "Iteration 7813 => Loss: 50.83161143772101553395\n",
      "Iteration 7814 => Loss: 50.83141294248331121253\n",
      "Iteration 7815 => Loss: 50.83121444880398343003\n",
      "Iteration 7816 => Loss: 50.83101595668294692132\n",
      "Iteration 7817 => Loss: 50.83081746612030826782\n",
      "Iteration 7818 => Loss: 50.83061897711597509897\n",
      "Iteration 7819 => Loss: 50.83042048966994741477\n",
      "Iteration 7820 => Loss: 50.83022200378220389894\n",
      "Iteration 7821 => Loss: 50.83002351945277297318\n",
      "Iteration 7822 => Loss: 50.82982503668159068866\n",
      "Iteration 7823 => Loss: 50.82962655546864993994\n",
      "Iteration 7824 => Loss: 50.82942807581400046502\n",
      "Iteration 7825 => Loss: 50.82922959771753568248\n",
      "Iteration 7826 => Loss: 50.82903112117931954117\n",
      "Iteration 7827 => Loss: 50.82883264619928809225\n",
      "Iteration 7828 => Loss: 50.82863417277744133571\n",
      "Iteration 7829 => Loss: 50.82843570091377927156\n",
      "Iteration 7830 => Loss: 50.82823723060826637266\n",
      "Iteration 7831 => Loss: 50.82803876186091684986\n",
      "Iteration 7832 => Loss: 50.82784029467170938688\n",
      "Iteration 7833 => Loss: 50.82764182904059424573\n",
      "Iteration 7834 => Loss: 50.82744336496759984811\n",
      "Iteration 7835 => Loss: 50.82724490245271908861\n",
      "Iteration 7836 => Loss: 50.82704644149589512381\n",
      "Iteration 7837 => Loss: 50.82684798209713505912\n",
      "Iteration 7838 => Loss: 50.82664952425646731626\n",
      "Iteration 7839 => Loss: 50.82645106797379241925\n",
      "Iteration 7840 => Loss: 50.82625261324917431693\n",
      "Iteration 7841 => Loss: 50.82605416008257037674\n",
      "Iteration 7842 => Loss: 50.82585570847396638783\n",
      "Iteration 7843 => Loss: 50.82565725842333392848\n",
      "Iteration 7844 => Loss: 50.82545880993069431497\n",
      "Iteration 7845 => Loss: 50.82526036299599780932\n",
      "Iteration 7846 => Loss: 50.82506191761925151695\n",
      "Iteration 7847 => Loss: 50.82486347380044833244\n",
      "Iteration 7848 => Loss: 50.82466503153953851779\n",
      "Iteration 7849 => Loss: 50.82446659083656470557\n",
      "Iteration 7850 => Loss: 50.82426815169147005236\n",
      "Iteration 7851 => Loss: 50.82406971410426876901\n",
      "Iteration 7852 => Loss: 50.82387127807493243381\n",
      "Iteration 7853 => Loss: 50.82367284360343973049\n",
      "Iteration 7854 => Loss: 50.82347441068979065903\n",
      "Iteration 7855 => Loss: 50.82327597933397100860\n",
      "Iteration 7856 => Loss: 50.82307754953595235747\n",
      "Iteration 7857 => Loss: 50.82287912129575602194\n",
      "Iteration 7858 => Loss: 50.82268069461330384229\n",
      "Iteration 7859 => Loss: 50.82248226948865976738\n",
      "Iteration 7860 => Loss: 50.82228384592176695378\n",
      "Iteration 7861 => Loss: 50.82208542391261119064\n",
      "Iteration 7862 => Loss: 50.82188700346119247797\n",
      "Iteration 7863 => Loss: 50.82168858456749660490\n",
      "Iteration 7864 => Loss: 50.82149016723149514974\n",
      "Iteration 7865 => Loss: 50.82129175145319521789\n",
      "Iteration 7866 => Loss: 50.82109333723258259852\n",
      "Iteration 7867 => Loss: 50.82089492456962886990\n",
      "Iteration 7868 => Loss: 50.82069651346429850491\n",
      "Iteration 7869 => Loss: 50.82049810391665545239\n",
      "Iteration 7870 => Loss: 50.82029969592661444722\n",
      "Iteration 7871 => Loss: 50.82010128949418259481\n",
      "Iteration 7872 => Loss: 50.81990288461935989517\n",
      "Iteration 7873 => Loss: 50.81970448130211792659\n",
      "Iteration 7874 => Loss: 50.81950607954244958364\n",
      "Iteration 7875 => Loss: 50.81930767934032644462\n",
      "Iteration 7876 => Loss: 50.81910928069576272037\n",
      "Iteration 7877 => Loss: 50.81891088360872998919\n",
      "Iteration 7878 => Loss: 50.81871248807919982937\n",
      "Iteration 7879 => Loss: 50.81851409410718645177\n",
      "Iteration 7880 => Loss: 50.81831570169266143466\n",
      "Iteration 7881 => Loss: 50.81811731083563188349\n",
      "Iteration 7882 => Loss: 50.81791892153605516569\n",
      "Iteration 7883 => Loss: 50.81772053379393128125\n",
      "Iteration 7884 => Loss: 50.81752214760923891390\n",
      "Iteration 7885 => Loss: 50.81732376298199227449\n",
      "Iteration 7886 => Loss: 50.81712537991213451960\n",
      "Iteration 7887 => Loss: 50.81692699839969407094\n",
      "Iteration 7888 => Loss: 50.81672861844462829595\n",
      "Iteration 7889 => Loss: 50.81653024004692298377\n",
      "Iteration 7890 => Loss: 50.81633186320658523982\n",
      "Iteration 7891 => Loss: 50.81613348792360795869\n",
      "Iteration 7892 => Loss: 50.81593511419795561324\n",
      "Iteration 7893 => Loss: 50.81573674202960688717\n",
      "Iteration 7894 => Loss: 50.81553837141857599136\n",
      "Iteration 7895 => Loss: 50.81534000236484871493\n",
      "Iteration 7896 => Loss: 50.81514163486836821448\n",
      "Iteration 7897 => Loss: 50.81494326892917712257\n",
      "Iteration 7898 => Loss: 50.81474490454722570121\n",
      "Iteration 7899 => Loss: 50.81454654172252816124\n",
      "Iteration 7900 => Loss: 50.81434818045505608097\n",
      "Iteration 7901 => Loss: 50.81414982074477393326\n",
      "Iteration 7902 => Loss: 50.81395146259171724523\n",
      "Iteration 7903 => Loss: 50.81375310599584338433\n",
      "Iteration 7904 => Loss: 50.81355475095713103428\n",
      "Iteration 7905 => Loss: 50.81335639747558019508\n",
      "Iteration 7906 => Loss: 50.81315804555119086672\n",
      "Iteration 7907 => Loss: 50.81295969518392041664\n",
      "Iteration 7908 => Loss: 50.81276134637374752856\n",
      "Iteration 7909 => Loss: 50.81256299912070772962\n",
      "Iteration 7910 => Loss: 50.81236465342475838725\n",
      "Iteration 7911 => Loss: 50.81216630928589239602\n",
      "Iteration 7912 => Loss: 50.81196796670409554508\n",
      "Iteration 7913 => Loss: 50.81176962567933941273\n",
      "Iteration 7914 => Loss: 50.81157128621160978810\n",
      "Iteration 7915 => Loss: 50.81137294830094219833\n",
      "Iteration 7916 => Loss: 50.81117461194725848372\n",
      "Iteration 7917 => Loss: 50.81097627715057996056\n",
      "Iteration 7918 => Loss: 50.81077794391090662884\n",
      "Iteration 7919 => Loss: 50.81057961222818875058\n",
      "Iteration 7920 => Loss: 50.81038128210244764205\n",
      "Iteration 7921 => Loss: 50.81018295353364067068\n",
      "Iteration 7922 => Loss: 50.80998462652178204735\n",
      "Iteration 7923 => Loss: 50.80978630106681492862\n",
      "Iteration 7924 => Loss: 50.80958797716878905248\n",
      "Iteration 7925 => Loss: 50.80938965482764757553\n",
      "Iteration 7926 => Loss: 50.80919133404336207605\n",
      "Iteration 7927 => Loss: 50.80899301481596097574\n",
      "Iteration 7928 => Loss: 50.80879469714542295833\n",
      "Iteration 7929 => Loss: 50.80859638103171249668\n",
      "Iteration 7930 => Loss: 50.80839806647483669622\n",
      "Iteration 7931 => Loss: 50.80819975347479555694\n",
      "Iteration 7932 => Loss: 50.80800144203153223543\n",
      "Iteration 7933 => Loss: 50.80780313214506804798\n",
      "Iteration 7934 => Loss: 50.80760482381538878371\n",
      "Iteration 7935 => Loss: 50.80740651704245181008\n",
      "Iteration 7936 => Loss: 50.80720821182627133794\n",
      "Iteration 7937 => Loss: 50.80700990816682605100\n",
      "Iteration 7938 => Loss: 50.80681160606410173841\n",
      "Iteration 7939 => Loss: 50.80661330551807708389\n",
      "Iteration 7940 => Loss: 50.80641500652878761457\n",
      "Iteration 7941 => Loss: 50.80621670909612674905\n",
      "Iteration 7942 => Loss: 50.80601841322017264702\n",
      "Iteration 7943 => Loss: 50.80582011890087557049\n",
      "Iteration 7944 => Loss: 50.80562182613819999233\n",
      "Iteration 7945 => Loss: 50.80542353493218143967\n",
      "Iteration 7946 => Loss: 50.80522524528274885824\n",
      "Iteration 7947 => Loss: 50.80502695718993066976\n",
      "Iteration 7948 => Loss: 50.80482867065371976878\n",
      "Iteration 7949 => Loss: 50.80463038567406641732\n",
      "Iteration 7950 => Loss: 50.80443210225099903710\n",
      "Iteration 7951 => Loss: 50.80423382038446789011\n",
      "Iteration 7952 => Loss: 50.80403554007447297636\n",
      "Iteration 7953 => Loss: 50.80383726132100719042\n",
      "Iteration 7954 => Loss: 50.80363898412404211058\n",
      "Iteration 7955 => Loss: 50.80344070848359194770\n",
      "Iteration 7956 => Loss: 50.80324243439962117463\n",
      "Iteration 7957 => Loss: 50.80304416187211558054\n",
      "Iteration 7958 => Loss: 50.80284589090109648168\n",
      "Iteration 7959 => Loss: 50.80264762148650703466\n",
      "Iteration 7960 => Loss: 50.80244935362834723946\n",
      "Iteration 7961 => Loss: 50.80225108732661709610\n",
      "Iteration 7962 => Loss: 50.80205282258127397199\n",
      "Iteration 7963 => Loss: 50.80185455939232497258\n",
      "Iteration 7964 => Loss: 50.80165629775976299243\n",
      "Iteration 7965 => Loss: 50.80145803768357382069\n",
      "Iteration 7966 => Loss: 50.80125977916375745735\n",
      "Iteration 7967 => Loss: 50.80106152220023574273\n",
      "Iteration 7968 => Loss: 50.80086326679307262566\n",
      "Iteration 7969 => Loss: 50.80066501294222547358\n",
      "Iteration 7970 => Loss: 50.80046676064765875935\n",
      "Iteration 7971 => Loss: 50.80026850990940090469\n",
      "Iteration 7972 => Loss: 50.80007026072741638245\n",
      "Iteration 7973 => Loss: 50.79987201310169098178\n",
      "Iteration 7974 => Loss: 50.79967376703221049183\n",
      "Iteration 7975 => Loss: 50.79947552251897491260\n",
      "Iteration 7976 => Loss: 50.79927727956194871695\n",
      "Iteration 7977 => Loss: 50.79907903816114611573\n",
      "Iteration 7978 => Loss: 50.79888079831651737095\n",
      "Iteration 7979 => Loss: 50.79868256002809090432\n",
      "Iteration 7980 => Loss: 50.79848432329583829414\n",
      "Iteration 7981 => Loss: 50.79828608811971690784\n",
      "Iteration 7982 => Loss: 50.79808785449977648341\n",
      "Iteration 7983 => Loss: 50.79788962243593175572\n",
      "Iteration 7984 => Loss: 50.79769139192821114648\n",
      "Iteration 7985 => Loss: 50.79749316297662176112\n",
      "Iteration 7986 => Loss: 50.79729493558110675622\n",
      "Iteration 7987 => Loss: 50.79709670974167323720\n",
      "Iteration 7988 => Loss: 50.79689848545830699322\n",
      "Iteration 7989 => Loss: 50.79670026273099381342\n",
      "Iteration 7990 => Loss: 50.79650204155972659237\n",
      "Iteration 7991 => Loss: 50.79630382194445559207\n",
      "Iteration 7992 => Loss: 50.79610560388520923425\n",
      "Iteration 7993 => Loss: 50.79590738738198041347\n",
      "Iteration 7994 => Loss: 50.79570917243474781344\n",
      "Iteration 7995 => Loss: 50.79551095904344748533\n",
      "Iteration 7996 => Loss: 50.79531274720815758883\n",
      "Iteration 7997 => Loss: 50.79511453692877864796\n",
      "Iteration 7998 => Loss: 50.79491632820534618986\n",
      "Iteration 7999 => Loss: 50.79471812103783179282\n",
      "Iteration 8000 => Loss: 50.79451991542622835141\n",
      "Iteration 8001 => Loss: 50.79432171137051454934\n",
      "Iteration 8002 => Loss: 50.79412350887068328120\n",
      "Iteration 8003 => Loss: 50.79392530792673454698\n",
      "Iteration 8004 => Loss: 50.79372710853862571412\n",
      "Iteration 8005 => Loss: 50.79352891070638520432\n",
      "Iteration 8006 => Loss: 50.79333071442994906874\n",
      "Iteration 8007 => Loss: 50.79313251970934572910\n",
      "Iteration 8008 => Loss: 50.79293432654453965824\n",
      "Iteration 8009 => Loss: 50.79273613493553085618\n",
      "Iteration 8010 => Loss: 50.79253794488229090121\n",
      "Iteration 8011 => Loss: 50.79233975638484110959\n",
      "Iteration 8012 => Loss: 50.79214156944310332165\n",
      "Iteration 8013 => Loss: 50.79194338405712727536\n",
      "Iteration 8014 => Loss: 50.79174520022687033816\n",
      "Iteration 8015 => Loss: 50.79154701795233961548\n",
      "Iteration 8016 => Loss: 50.79134883723349247475\n",
      "Iteration 8017 => Loss: 50.79115065807035023226\n",
      "Iteration 8018 => Loss: 50.79095248046286315002\n",
      "Iteration 8019 => Loss: 50.79075430441103833346\n",
      "Iteration 8020 => Loss: 50.79055612991486867713\n",
      "Iteration 8021 => Loss: 50.79035795697432575935\n",
      "Iteration 8022 => Loss: 50.79015978558941668553\n",
      "Iteration 8023 => Loss: 50.78996161576011303396\n",
      "Iteration 8024 => Loss: 50.78976344748639348836\n",
      "Iteration 8025 => Loss: 50.78956528076827936502\n",
      "Iteration 8026 => Loss: 50.78936711560570671509\n",
      "Iteration 8027 => Loss: 50.78916895199872527655\n",
      "Iteration 8028 => Loss: 50.78897078994725688972\n",
      "Iteration 8029 => Loss: 50.78877262945131576544\n",
      "Iteration 8030 => Loss: 50.78857447051092321999\n",
      "Iteration 8031 => Loss: 50.78837631312602240996\n",
      "Iteration 8032 => Loss: 50.78817815729658491364\n",
      "Iteration 8033 => Loss: 50.78798000302266046901\n",
      "Iteration 8034 => Loss: 50.78778185030417802182\n",
      "Iteration 8035 => Loss: 50.78758369914117309918\n",
      "Iteration 8036 => Loss: 50.78738554953358175226\n",
      "Iteration 8037 => Loss: 50.78718740148143950819\n",
      "Iteration 8038 => Loss: 50.78698925498469662898\n",
      "Iteration 8039 => Loss: 50.78679111004336022006\n",
      "Iteration 8040 => Loss: 50.78659296665742317600\n",
      "Iteration 8041 => Loss: 50.78639482482683575881\n",
      "Iteration 8042 => Loss: 50.78619668455161928478\n",
      "Iteration 8043 => Loss: 50.78599854583176664846\n",
      "Iteration 8044 => Loss: 50.78580040866723521731\n",
      "Iteration 8045 => Loss: 50.78560227305803209674\n",
      "Iteration 8046 => Loss: 50.78540413900413597048\n",
      "Iteration 8047 => Loss: 50.78520600650552552224\n",
      "Iteration 8048 => Loss: 50.78500787556222206831\n",
      "Iteration 8049 => Loss: 50.78480974617416165984\n",
      "Iteration 8050 => Loss: 50.78461161834135850768\n",
      "Iteration 8051 => Loss: 50.78441349206382682269\n",
      "Iteration 8052 => Loss: 50.78421536734152397230\n",
      "Iteration 8053 => Loss: 50.78401724417442864024\n",
      "Iteration 8054 => Loss: 50.78381912256252661564\n",
      "Iteration 8055 => Loss: 50.78362100250585342565\n",
      "Iteration 8056 => Loss: 50.78342288400433801598\n",
      "Iteration 8057 => Loss: 50.78322476705798038665\n",
      "Iteration 8058 => Loss: 50.78302665166678053765\n",
      "Iteration 8059 => Loss: 50.78282853783073846898\n",
      "Iteration 8060 => Loss: 50.78263042554981865351\n",
      "Iteration 8061 => Loss: 50.78243231482401398580\n",
      "Iteration 8062 => Loss: 50.78223420565330314957\n",
      "Iteration 8063 => Loss: 50.78203609803767193398\n",
      "Iteration 8064 => Loss: 50.78183799197714165530\n",
      "Iteration 8065 => Loss: 50.78163988747167678639\n",
      "Iteration 8066 => Loss: 50.78144178452124890555\n",
      "Iteration 8067 => Loss: 50.78124368312585090735\n",
      "Iteration 8068 => Loss: 50.78104558328548989721\n",
      "Iteration 8069 => Loss: 50.78084748500013745343\n",
      "Iteration 8070 => Loss: 50.78064938826978647057\n",
      "Iteration 8071 => Loss: 50.78045129309440142151\n",
      "Iteration 8072 => Loss: 50.78025319947402493881\n",
      "Iteration 8073 => Loss: 50.78005510740857175733\n",
      "Iteration 8074 => Loss: 50.77985701689809161508\n",
      "Iteration 8075 => Loss: 50.77965892794254187947\n",
      "Iteration 8076 => Loss: 50.77946084054189412882\n",
      "Iteration 8077 => Loss: 50.77926275469616967939\n",
      "Iteration 8078 => Loss: 50.77906467040534721491\n",
      "Iteration 8079 => Loss: 50.77886658766939831366\n",
      "Iteration 8080 => Loss: 50.77866850648832297566\n",
      "Iteration 8081 => Loss: 50.77847042686209988460\n",
      "Iteration 8082 => Loss: 50.77827234879071482965\n",
      "Iteration 8083 => Loss: 50.77807427227417491622\n",
      "Iteration 8084 => Loss: 50.77787619731244461718\n",
      "Iteration 8085 => Loss: 50.77767812390551682711\n",
      "Iteration 8086 => Loss: 50.77748005205338444057\n",
      "Iteration 8087 => Loss: 50.77728198175601193043\n",
      "Iteration 8088 => Loss: 50.77708391301344192925\n",
      "Iteration 8089 => Loss: 50.77688584582560338276\n",
      "Iteration 8090 => Loss: 50.77668778019248208011\n",
      "Iteration 8091 => Loss: 50.77648971611413486471\n",
      "Iteration 8092 => Loss: 50.77629165359049068229\n",
      "Iteration 8093 => Loss: 50.77609359262152821657\n",
      "Iteration 8094 => Loss: 50.77589553320726878383\n",
      "Iteration 8095 => Loss: 50.77569747534767685693\n",
      "Iteration 8096 => Loss: 50.77549941904274533044\n",
      "Iteration 8097 => Loss: 50.77530136429248130980\n",
      "Iteration 8098 => Loss: 50.77510331109684216244\n",
      "Iteration 8099 => Loss: 50.77490525945584209921\n",
      "Iteration 8100 => Loss: 50.77470720936943848756\n",
      "Iteration 8101 => Loss: 50.77450916083762422204\n",
      "Iteration 8102 => Loss: 50.77431111386041351352\n",
      "Iteration 8103 => Loss: 50.77411306843777794029\n",
      "Iteration 8104 => Loss: 50.77391502456968908064\n",
      "Iteration 8105 => Loss: 50.77371698225615403999\n",
      "Iteration 8106 => Loss: 50.77351894149715150206\n",
      "Iteration 8107 => Loss: 50.77332090229264593972\n",
      "Iteration 8108 => Loss: 50.77312286464270130182\n",
      "Iteration 8109 => Loss: 50.77292482854721100693\n",
      "Iteration 8110 => Loss: 50.77272679400620347678\n",
      "Iteration 8111 => Loss: 50.77252876101969292222\n",
      "Iteration 8112 => Loss: 50.77233072958762249982\n",
      "Iteration 8113 => Loss: 50.77213269971001352587\n",
      "Iteration 8114 => Loss: 50.77193467138680205153\n",
      "Iteration 8115 => Loss: 50.77173664461803070935\n",
      "Iteration 8116 => Loss: 50.77153861940365686678\n",
      "Iteration 8117 => Loss: 50.77134059574367341838\n",
      "Iteration 8118 => Loss: 50.77114257363808036416\n",
      "Iteration 8119 => Loss: 50.77094455308683507155\n",
      "Iteration 8120 => Loss: 50.77074653408995885684\n",
      "Iteration 8121 => Loss: 50.77054851664742329831\n",
      "Iteration 8122 => Loss: 50.77035050075922839596\n",
      "Iteration 8123 => Loss: 50.77015248642533862267\n",
      "Iteration 8124 => Loss: 50.76995447364576108384\n",
      "Iteration 8125 => Loss: 50.76975646242043893608\n",
      "Iteration 8126 => Loss: 50.76955845274940770651\n",
      "Iteration 8127 => Loss: 50.76936044463266028970\n",
      "Iteration 8128 => Loss: 50.76916243807015405309\n",
      "Iteration 8129 => Loss: 50.76896443306189610212\n",
      "Iteration 8130 => Loss: 50.76876642960783669878\n",
      "Iteration 8131 => Loss: 50.76856842770800426479\n",
      "Iteration 8132 => Loss: 50.76837042736237037843\n",
      "Iteration 8133 => Loss: 50.76817242857093503972\n",
      "Iteration 8134 => Loss: 50.76797443133366272150\n",
      "Iteration 8135 => Loss: 50.76777643565055342378\n",
      "Iteration 8136 => Loss: 50.76757844152158583029\n",
      "Iteration 8137 => Loss: 50.76738044894676704644\n",
      "Iteration 8138 => Loss: 50.76718245792606865052\n",
      "Iteration 8139 => Loss: 50.76698446845946932626\n",
      "Iteration 8140 => Loss: 50.76678648054696907366\n",
      "Iteration 8141 => Loss: 50.76658849418856789271\n",
      "Iteration 8142 => Loss: 50.76639050938422315085\n",
      "Iteration 8143 => Loss: 50.76619252613394905893\n",
      "Iteration 8144 => Loss: 50.76599454443769587897\n",
      "Iteration 8145 => Loss: 50.76579656429550624352\n",
      "Iteration 8146 => Loss: 50.76559858570733041461\n",
      "Iteration 8147 => Loss: 50.76540060867316128679\n",
      "Iteration 8148 => Loss: 50.76520263319296333293\n",
      "Iteration 8149 => Loss: 50.76500465926677208017\n",
      "Iteration 8150 => Loss: 50.76480668689454489595\n",
      "Iteration 8151 => Loss: 50.76460871607627467483\n",
      "Iteration 8152 => Loss: 50.76441074681192588969\n",
      "Iteration 8153 => Loss: 50.76421277910153406765\n",
      "Iteration 8154 => Loss: 50.76401481294506368158\n",
      "Iteration 8155 => Loss: 50.76381684834247920435\n",
      "Iteration 8156 => Loss: 50.76361888529380195223\n",
      "Iteration 8157 => Loss: 50.76342092379898218724\n",
      "Iteration 8158 => Loss: 50.76322296385805543650\n",
      "Iteration 8159 => Loss: 50.76302500547095775119\n",
      "Iteration 8160 => Loss: 50.76282704863771044757\n",
      "Iteration 8161 => Loss: 50.76262909335829220936\n",
      "Iteration 8162 => Loss: 50.76243113963269593114\n",
      "Iteration 8163 => Loss: 50.76223318746090029663\n",
      "Iteration 8164 => Loss: 50.76203523684289109497\n",
      "Iteration 8165 => Loss: 50.76183728777867543158\n",
      "Iteration 8166 => Loss: 50.76163934026819646306\n",
      "Iteration 8167 => Loss: 50.76144139431149682196\n",
      "Iteration 8168 => Loss: 50.76124344990851966486\n",
      "Iteration 8169 => Loss: 50.76104550705925788634\n",
      "Iteration 8170 => Loss: 50.76084756576373280268\n",
      "Iteration 8171 => Loss: 50.76064962602189467589\n",
      "Iteration 8172 => Loss: 50.76045168783373640053\n",
      "Iteration 8173 => Loss: 50.76025375119925797662\n",
      "Iteration 8174 => Loss: 50.76005581611845229872\n",
      "Iteration 8175 => Loss: 50.75985788259129094513\n",
      "Iteration 8176 => Loss: 50.75965995061776681041\n",
      "Iteration 8177 => Loss: 50.75946202019785857829\n",
      "Iteration 8178 => Loss: 50.75926409133155203790\n",
      "Iteration 8179 => Loss: 50.75906616401886850554\n",
      "Iteration 8180 => Loss: 50.75886823825975824320\n",
      "Iteration 8181 => Loss: 50.75867031405422125090\n",
      "Iteration 8182 => Loss: 50.75847239140222910692\n",
      "Iteration 8183 => Loss: 50.75827447030381733839\n",
      "Iteration 8184 => Loss: 50.75807655075890068019\n",
      "Iteration 8185 => Loss: 50.75787863276753597574\n",
      "Iteration 8186 => Loss: 50.75768071632965927620\n",
      "Iteration 8187 => Loss: 50.75748280144531321412\n",
      "Iteration 8188 => Loss: 50.75728488811440541895\n",
      "Iteration 8189 => Loss: 50.75708697633699273410\n",
      "Iteration 8190 => Loss: 50.75688906611303252703\n",
      "Iteration 8191 => Loss: 50.75669115744251769229\n",
      "Iteration 8192 => Loss: 50.75649325032543401903\n",
      "Iteration 8193 => Loss: 50.75629534476177440183\n",
      "Iteration 8194 => Loss: 50.75609744075153173526\n",
      "Iteration 8195 => Loss: 50.75589953829467759761\n",
      "Iteration 8196 => Loss: 50.75570163739119777802\n",
      "Iteration 8197 => Loss: 50.75550373804106385478\n",
      "Iteration 8198 => Loss: 50.75530584024432556589\n",
      "Iteration 8199 => Loss: 50.75510794400091896250\n",
      "Iteration 8200 => Loss: 50.75491004931084404461\n",
      "Iteration 8201 => Loss: 50.75471215617406528509\n",
      "Iteration 8202 => Loss: 50.75451426459059689478\n",
      "Iteration 8203 => Loss: 50.75431637456043887369\n",
      "Iteration 8204 => Loss: 50.75411848608354148382\n",
      "Iteration 8205 => Loss: 50.75392059915994025232\n",
      "Iteration 8206 => Loss: 50.75372271378954991405\n",
      "Iteration 8207 => Loss: 50.75352482997243441787\n",
      "Iteration 8208 => Loss: 50.75332694770851560406\n",
      "Iteration 8209 => Loss: 50.75312906699785031606\n",
      "Iteration 8210 => Loss: 50.75293118784036749958\n",
      "Iteration 8211 => Loss: 50.75273331023607426005\n",
      "Iteration 8212 => Loss: 50.75253543418495638662\n",
      "Iteration 8213 => Loss: 50.75233755968699966843\n",
      "Iteration 8214 => Loss: 50.75213968674222542177\n",
      "Iteration 8215 => Loss: 50.75194181535056259236\n",
      "Iteration 8216 => Loss: 50.75174394551202539105\n",
      "Iteration 8217 => Loss: 50.75154607722660671243\n",
      "Iteration 8218 => Loss: 50.75134821049429945106\n",
      "Iteration 8219 => Loss: 50.75115034531506097437\n",
      "Iteration 8220 => Loss: 50.75095248168892680951\n",
      "Iteration 8221 => Loss: 50.75075461961583300763\n",
      "Iteration 8222 => Loss: 50.75055675909577956872\n",
      "Iteration 8223 => Loss: 50.75035890012878780908\n",
      "Iteration 8224 => Loss: 50.75016104271481509613\n",
      "Iteration 8225 => Loss: 50.74996318685384721903\n",
      "Iteration 8226 => Loss: 50.74976533254587707233\n",
      "Iteration 8227 => Loss: 50.74956747979091176148\n",
      "Iteration 8228 => Loss: 50.74936962858890865391\n",
      "Iteration 8229 => Loss: 50.74917177893985353876\n",
      "Iteration 8230 => Loss: 50.74897393084375352146\n",
      "Iteration 8231 => Loss: 50.74877608430060860201\n",
      "Iteration 8232 => Loss: 50.74857823931037614784\n",
      "Iteration 8233 => Loss: 50.74838039587304194811\n",
      "Iteration 8234 => Loss: 50.74818255398861310823\n",
      "Iteration 8235 => Loss: 50.74798471365707541736\n",
      "Iteration 8236 => Loss: 50.74778687487840755921\n",
      "Iteration 8237 => Loss: 50.74758903765259532292\n",
      "Iteration 8238 => Loss: 50.74739120197965291936\n",
      "Iteration 8239 => Loss: 50.74719336785951639968\n",
      "Iteration 8240 => Loss: 50.74699553529220708015\n",
      "Iteration 8241 => Loss: 50.74679770427770364449\n",
      "Iteration 8242 => Loss: 50.74659987481601319814\n",
      "Iteration 8243 => Loss: 50.74640204690709310853\n",
      "Iteration 8244 => Loss: 50.74620422055093627023\n",
      "Iteration 8245 => Loss: 50.74600639574754268324\n",
      "Iteration 8246 => Loss: 50.74580857249690524213\n",
      "Iteration 8247 => Loss: 50.74561075079898131435\n",
      "Iteration 8248 => Loss: 50.74541293065379221616\n",
      "Iteration 8249 => Loss: 50.74521511206132373673\n",
      "Iteration 8250 => Loss: 50.74501729502153324347\n",
      "Iteration 8251 => Loss: 50.74481947953441363097\n",
      "Iteration 8252 => Loss: 50.74462166559999332094\n",
      "Iteration 8253 => Loss: 50.74442385321819415367\n",
      "Iteration 8254 => Loss: 50.74422604238907297258\n",
      "Iteration 8255 => Loss: 50.74402823311258003969\n",
      "Iteration 8256 => Loss: 50.74383042538868693327\n",
      "Iteration 8257 => Loss: 50.74363261921738654792\n",
      "Iteration 8258 => Loss: 50.74343481459870019989\n",
      "Iteration 8259 => Loss: 50.74323701153261367836\n",
      "Iteration 8260 => Loss: 50.74303921001907013988\n",
      "Iteration 8261 => Loss: 50.74284141005808379532\n",
      "Iteration 8262 => Loss: 50.74264361164963332840\n",
      "Iteration 8263 => Loss: 50.74244581479371873911\n",
      "Iteration 8264 => Loss: 50.74224801949034713289\n",
      "Iteration 8265 => Loss: 50.74205022573946166631\n",
      "Iteration 8266 => Loss: 50.74185243354106233937\n",
      "Iteration 8267 => Loss: 50.74165464289514204665\n",
      "Iteration 8268 => Loss: 50.74145685380169368273\n",
      "Iteration 8269 => Loss: 50.74125906626069593131\n",
      "Iteration 8270 => Loss: 50.74106128027214879239\n",
      "Iteration 8271 => Loss: 50.74086349583601673885\n",
      "Iteration 8272 => Loss: 50.74066571295231398153\n",
      "Iteration 8273 => Loss: 50.74046793162101920416\n",
      "Iteration 8274 => Loss: 50.74027015184207556331\n",
      "Iteration 8275 => Loss: 50.74007237361553990240\n",
      "Iteration 8276 => Loss: 50.73987459694137669430\n",
      "Iteration 8277 => Loss: 50.73967682181956462273\n",
      "Iteration 8278 => Loss: 50.73947904825007526597\n",
      "Iteration 8279 => Loss: 50.73928127623292994031\n",
      "Iteration 8280 => Loss: 50.73908350576810732946\n",
      "Iteration 8281 => Loss: 50.73888573685555059001\n",
      "Iteration 8282 => Loss: 50.73868796949531656537\n",
      "Iteration 8283 => Loss: 50.73849020368735551756\n",
      "Iteration 8284 => Loss: 50.73829243943164613029\n",
      "Iteration 8285 => Loss: 50.73809467672818129813\n",
      "Iteration 8286 => Loss: 50.73789691557698944280\n",
      "Iteration 8287 => Loss: 50.73769915597799240459\n",
      "Iteration 8288 => Loss: 50.73750139793123281606\n",
      "Iteration 8289 => Loss: 50.73730364143665383381\n",
      "Iteration 8290 => Loss: 50.73710588649426256325\n",
      "Iteration 8291 => Loss: 50.73690813310407321524\n",
      "Iteration 8292 => Loss: 50.73671038126600763007\n",
      "Iteration 8293 => Loss: 50.73651263098012265118\n",
      "Iteration 8294 => Loss: 50.73631488224638985685\n",
      "Iteration 8295 => Loss: 50.73611713506473108737\n",
      "Iteration 8296 => Loss: 50.73591938943523871330\n",
      "Iteration 8297 => Loss: 50.73572164535779904782\n",
      "Iteration 8298 => Loss: 50.73552390283248314518\n",
      "Iteration 8299 => Loss: 50.73532616185922705654\n",
      "Iteration 8300 => Loss: 50.73512842243802367648\n",
      "Iteration 8301 => Loss: 50.73493068456888011042\n",
      "Iteration 8302 => Loss: 50.73473294825178925294\n",
      "Iteration 8303 => Loss: 50.73453521348670136604\n",
      "Iteration 8304 => Loss: 50.73433748027364487143\n",
      "Iteration 8305 => Loss: 50.73413974861254871485\n",
      "Iteration 8306 => Loss: 50.73394201850349105598\n",
      "Iteration 8307 => Loss: 50.73374428994636531343\n",
      "Iteration 8308 => Loss: 50.73354656294121411975\n",
      "Iteration 8309 => Loss: 50.73334883748802326409\n",
      "Iteration 8310 => Loss: 50.73315111358676432474\n",
      "Iteration 8311 => Loss: 50.73295339123742309084\n",
      "Iteration 8312 => Loss: 50.73275567043999245698\n",
      "Iteration 8313 => Loss: 50.73255795119447242314\n",
      "Iteration 8314 => Loss: 50.73236023350082035677\n",
      "Iteration 8315 => Loss: 50.73216251735906467957\n",
      "Iteration 8316 => Loss: 50.73196480276912723184\n",
      "Iteration 8317 => Loss: 50.73176708973107196243\n",
      "Iteration 8318 => Loss: 50.73156937824484202793\n",
      "Iteration 8319 => Loss: 50.73137166831043742832\n",
      "Iteration 8320 => Loss: 50.73117395992783684733\n",
      "Iteration 8321 => Loss: 50.73097625309702607410\n",
      "Iteration 8322 => Loss: 50.73077854781803353035\n",
      "Iteration 8323 => Loss: 50.73058084409078816179\n",
      "Iteration 8324 => Loss: 50.73038314191529707387\n",
      "Iteration 8325 => Loss: 50.73018544129157447742\n",
      "Iteration 8326 => Loss: 50.72998774221956352903\n",
      "Iteration 8327 => Loss: 50.72979004469929265042\n",
      "Iteration 8328 => Loss: 50.72959234873071210359\n",
      "Iteration 8329 => Loss: 50.72939465431385031025\n",
      "Iteration 8330 => Loss: 50.72919696144865753240\n",
      "Iteration 8331 => Loss: 50.72899927013513377005\n",
      "Iteration 8332 => Loss: 50.72880158037327191778\n",
      "Iteration 8333 => Loss: 50.72860389216306487015\n",
      "Iteration 8334 => Loss: 50.72840620550450552173\n",
      "Iteration 8335 => Loss: 50.72820852039752281826\n",
      "Iteration 8336 => Loss: 50.72801083684216649772\n",
      "Iteration 8337 => Loss: 50.72781315483843656011\n",
      "Iteration 8338 => Loss: 50.72761547438625484574\n",
      "Iteration 8339 => Loss: 50.72741779548565688174\n",
      "Iteration 8340 => Loss: 50.72722011813660714097\n",
      "Iteration 8341 => Loss: 50.72702244233911272886\n",
      "Iteration 8342 => Loss: 50.72682476809315232913\n",
      "Iteration 8343 => Loss: 50.72662709539872594178\n",
      "Iteration 8344 => Loss: 50.72642942425579093424\n",
      "Iteration 8345 => Loss: 50.72623175466433309566\n",
      "Iteration 8346 => Loss: 50.72603408662438084775\n",
      "Iteration 8347 => Loss: 50.72583642013587734709\n",
      "Iteration 8348 => Loss: 50.72563875519885812082\n",
      "Iteration 8349 => Loss: 50.72544109181327343094\n",
      "Iteration 8350 => Loss: 50.72524342997913038289\n",
      "Iteration 8351 => Loss: 50.72504576969640055495\n",
      "Iteration 8352 => Loss: 50.72484811096506263084\n",
      "Iteration 8353 => Loss: 50.72465045378515924313\n",
      "Iteration 8354 => Loss: 50.72445279815658381040\n",
      "Iteration 8355 => Loss: 50.72425514407940028150\n",
      "Iteration 8356 => Loss: 50.72405749155359444558\n",
      "Iteration 8357 => Loss: 50.72385984057910945921\n",
      "Iteration 8358 => Loss: 50.72366219115596663869\n",
      "Iteration 8359 => Loss: 50.72346454328415177315\n",
      "Iteration 8360 => Loss: 50.72326689696363644089\n",
      "Iteration 8361 => Loss: 50.72306925219439932562\n",
      "Iteration 8362 => Loss: 50.72287160897646174362\n",
      "Iteration 8363 => Loss: 50.72267396730978106234\n",
      "Iteration 8364 => Loss: 50.72247632719436438720\n",
      "Iteration 8365 => Loss: 50.72227868863020461276\n",
      "Iteration 8366 => Loss: 50.72208105161725200105\n",
      "Iteration 8367 => Loss: 50.72188341615552786834\n",
      "Iteration 8368 => Loss: 50.72168578224501800378\n",
      "Iteration 8369 => Loss: 50.72148814988569398565\n",
      "Iteration 8370 => Loss: 50.72129051907754160311\n",
      "Iteration 8371 => Loss: 50.72109288982055375072\n",
      "Iteration 8372 => Loss: 50.72089526211475174478\n",
      "Iteration 8373 => Loss: 50.72069763596006453099\n",
      "Iteration 8374 => Loss: 50.72050001135652053108\n",
      "Iteration 8375 => Loss: 50.72030238830410553419\n",
      "Iteration 8376 => Loss: 50.72010476680278401318\n",
      "Iteration 8377 => Loss: 50.71990714685254886263\n",
      "Iteration 8378 => Loss: 50.71970952845341429338\n",
      "Iteration 8379 => Loss: 50.71951191160535188374\n",
      "Iteration 8380 => Loss: 50.71931429630831189570\n",
      "Iteration 8381 => Loss: 50.71911668256235117269\n",
      "Iteration 8382 => Loss: 50.71891907036740576586\n",
      "Iteration 8383 => Loss: 50.71872145972346146436\n",
      "Iteration 8384 => Loss: 50.71852385063053247904\n",
      "Iteration 8385 => Loss: 50.71832624308859749362\n",
      "Iteration 8386 => Loss: 50.71812863709765650810\n",
      "Iteration 8387 => Loss: 50.71793103265766688992\n",
      "Iteration 8388 => Loss: 50.71773342976863574449\n",
      "Iteration 8389 => Loss: 50.71753582843055596641\n",
      "Iteration 8390 => Loss: 50.71733822864339913394\n",
      "Iteration 8391 => Loss: 50.71714063040717235253\n",
      "Iteration 8392 => Loss: 50.71694303372185430590\n",
      "Iteration 8393 => Loss: 50.71674543858739525604\n",
      "Iteration 8394 => Loss: 50.71654784500381651924\n",
      "Iteration 8395 => Loss: 50.71635025297115362264\n",
      "Iteration 8396 => Loss: 50.71615266248932130111\n",
      "Iteration 8397 => Loss: 50.71595507355832666008\n",
      "Iteration 8398 => Loss: 50.71575748617815548869\n",
      "Iteration 8399 => Loss: 50.71555990034881489237\n",
      "Iteration 8400 => Loss: 50.71536231607026223855\n",
      "Iteration 8401 => Loss: 50.71516473334251173810\n",
      "Iteration 8402 => Loss: 50.71496715216554918015\n",
      "Iteration 8403 => Loss: 50.71476957253935324843\n",
      "Iteration 8404 => Loss: 50.71457199446391683750\n",
      "Iteration 8405 => Loss: 50.71437441793918310395\n",
      "Iteration 8406 => Loss: 50.71417684296523020748\n",
      "Iteration 8407 => Loss: 50.71397926954196577753\n",
      "Iteration 8408 => Loss: 50.71378169766941823582\n",
      "Iteration 8409 => Loss: 50.71358412734754494977\n",
      "Iteration 8410 => Loss: 50.71338655857636723567\n",
      "Iteration 8411 => Loss: 50.71318899135585667182\n",
      "Iteration 8412 => Loss: 50.71299142568599904735\n",
      "Iteration 8413 => Loss: 50.71279386156679436226\n",
      "Iteration 8414 => Loss: 50.71259629899821419485\n",
      "Iteration 8415 => Loss: 50.71239873798022301798\n",
      "Iteration 8416 => Loss: 50.71220117851287056965\n",
      "Iteration 8417 => Loss: 50.71200362059610000642\n",
      "Iteration 8418 => Loss: 50.71180606422989711746\n",
      "Iteration 8419 => Loss: 50.71160850941427611360\n",
      "Iteration 8420 => Loss: 50.71141095614921567858\n",
      "Iteration 8421 => Loss: 50.71121340443465896897\n",
      "Iteration 8422 => Loss: 50.71101585427068414447\n",
      "Iteration 8423 => Loss: 50.71081830565718462367\n",
      "Iteration 8424 => Loss: 50.71062075859422435542\n",
      "Iteration 8425 => Loss: 50.71042321308173228545\n",
      "Iteration 8426 => Loss: 50.71022566911972973003\n",
      "Iteration 8427 => Loss: 50.71002812670818826746\n",
      "Iteration 8428 => Loss: 50.70983058584710079231\n",
      "Iteration 8429 => Loss: 50.70963304653646019915\n",
      "Iteration 8430 => Loss: 50.70943550877625938256\n",
      "Iteration 8431 => Loss: 50.70923797256644860454\n",
      "Iteration 8432 => Loss: 50.70904043790706339223\n",
      "Iteration 8433 => Loss: 50.70884290479806111307\n",
      "Iteration 8434 => Loss: 50.70864537323944176705\n",
      "Iteration 8435 => Loss: 50.70844784323119824876\n",
      "Iteration 8436 => Loss: 50.70825031477328792562\n",
      "Iteration 8437 => Loss: 50.70805278786574632477\n",
      "Iteration 8438 => Loss: 50.70785526250853081365\n",
      "Iteration 8439 => Loss: 50.70765773870161297054\n",
      "Iteration 8440 => Loss: 50.70746021644501411174\n",
      "Iteration 8441 => Loss: 50.70726269573868449925\n",
      "Iteration 8442 => Loss: 50.70706517658266676563\n",
      "Iteration 8443 => Loss: 50.70686765897688275118\n",
      "Iteration 8444 => Loss: 50.70667014292138929932\n",
      "Iteration 8445 => Loss: 50.70647262841611535578\n",
      "Iteration 8446 => Loss: 50.70627511546107513141\n",
      "Iteration 8447 => Loss: 50.70607760405625441535\n",
      "Iteration 8448 => Loss: 50.70588009420163899676\n",
      "Iteration 8449 => Loss: 50.70568258589722177021\n",
      "Iteration 8450 => Loss: 50.70548507914294589227\n",
      "Iteration 8451 => Loss: 50.70528757393888952265\n",
      "Iteration 8452 => Loss: 50.70509007028498160707\n",
      "Iteration 8453 => Loss: 50.70489256818120082926\n",
      "Iteration 8454 => Loss: 50.70469506762754008378\n",
      "Iteration 8455 => Loss: 50.70449756862402779234\n",
      "Iteration 8456 => Loss: 50.70430007117058579524\n",
      "Iteration 8457 => Loss: 50.70410257526723540877\n",
      "Iteration 8458 => Loss: 50.70390508091397663293\n",
      "Iteration 8459 => Loss: 50.70370758811080946771\n",
      "Iteration 8460 => Loss: 50.70351009685766996427\n",
      "Iteration 8461 => Loss: 50.70331260715457943888\n",
      "Iteration 8462 => Loss: 50.70311511900152368071\n",
      "Iteration 8463 => Loss: 50.70291763239847426803\n",
      "Iteration 8464 => Loss: 50.70272014734542409542\n",
      "Iteration 8465 => Loss: 50.70252266384239447916\n",
      "Iteration 8466 => Loss: 50.70232518188932857583\n",
      "Iteration 8467 => Loss: 50.70212770148621928001\n",
      "Iteration 8468 => Loss: 50.70193022263308080255\n",
      "Iteration 8469 => Loss: 50.70173274532987761631\n",
      "Iteration 8470 => Loss: 50.70153526957662393215\n",
      "Iteration 8471 => Loss: 50.70133779537325580122\n",
      "Iteration 8472 => Loss: 50.70114032271981585609\n",
      "Iteration 8473 => Loss: 50.70094285161625435876\n",
      "Iteration 8474 => Loss: 50.70074538206259262552\n",
      "Iteration 8475 => Loss: 50.70054791405877381294\n",
      "Iteration 8476 => Loss: 50.70035044760481923731\n",
      "Iteration 8477 => Loss: 50.70015298270071468778\n",
      "Iteration 8478 => Loss: 50.69995551934645305892\n",
      "Iteration 8479 => Loss: 50.69975805754199171815\n",
      "Iteration 8480 => Loss: 50.69956059728733066549\n",
      "Iteration 8481 => Loss: 50.69936313858246990094\n",
      "Iteration 8482 => Loss: 50.69916568142739521363\n",
      "Iteration 8483 => Loss: 50.69896822582207107644\n",
      "Iteration 8484 => Loss: 50.69877077176651880563\n",
      "Iteration 8485 => Loss: 50.69857331926070287409\n",
      "Iteration 8486 => Loss: 50.69837586830464459808\n",
      "Iteration 8487 => Loss: 50.69817841889824450163\n",
      "Iteration 8488 => Loss: 50.69798097104160916615\n",
      "Iteration 8489 => Loss: 50.69778352473463201022\n",
      "Iteration 8490 => Loss: 50.69758607997736987727\n",
      "Iteration 8491 => Loss: 50.69738863676974460759\n",
      "Iteration 8492 => Loss: 50.69719119511178462290\n",
      "Iteration 8493 => Loss: 50.69699375500347571233\n",
      "Iteration 8494 => Loss: 50.69679631644479655961\n",
      "Iteration 8495 => Loss: 50.69659887943571874303\n",
      "Iteration 8496 => Loss: 50.69640144397625647343\n",
      "Iteration 8497 => Loss: 50.69620401006640264541\n",
      "Iteration 8498 => Loss: 50.69600657770611462638\n",
      "Iteration 8499 => Loss: 50.69580914689541373264\n",
      "Iteration 8500 => Loss: 50.69561171763424312076\n",
      "Iteration 8501 => Loss: 50.69541428992263121245\n",
      "Iteration 8502 => Loss: 50.69521686376055669143\n",
      "Iteration 8503 => Loss: 50.69501943914799113600\n",
      "Iteration 8504 => Loss: 50.69482201608494165157\n",
      "Iteration 8505 => Loss: 50.69462459457135850016\n",
      "Iteration 8506 => Loss: 50.69442717460728431433\n",
      "Iteration 8507 => Loss: 50.69422975619268356695\n",
      "Iteration 8508 => Loss: 50.69403233932754204716\n",
      "Iteration 8509 => Loss: 50.69383492401181712239\n",
      "Iteration 8510 => Loss: 50.69363751024555142521\n",
      "Iteration 8511 => Loss: 50.69344009802867390135\n",
      "Iteration 8512 => Loss: 50.69324268736122007795\n",
      "Iteration 8513 => Loss: 50.69304527824318995499\n",
      "Iteration 8514 => Loss: 50.69284787067449826736\n",
      "Iteration 8515 => Loss: 50.69265046465519475305\n",
      "Iteration 8516 => Loss: 50.69245306018525099034\n",
      "Iteration 8517 => Loss: 50.69225565726466697924\n",
      "Iteration 8518 => Loss: 50.69205825589337877091\n",
      "Iteration 8519 => Loss: 50.69186085607145031418\n",
      "Iteration 8520 => Loss: 50.69166345779879634392\n",
      "Iteration 8521 => Loss: 50.69146606107545949271\n",
      "Iteration 8522 => Loss: 50.69126866590139002255\n",
      "Iteration 8523 => Loss: 50.69107127227660924973\n",
      "Iteration 8524 => Loss: 50.69087388020106743625\n",
      "Iteration 8525 => Loss: 50.69067648967478589839\n",
      "Iteration 8526 => Loss: 50.69047910069772200359\n",
      "Iteration 8527 => Loss: 50.69028171326987575185\n",
      "Iteration 8528 => Loss: 50.69008432739126135402\n",
      "Iteration 8529 => Loss: 50.68988694306183617755\n",
      "Iteration 8530 => Loss: 50.68968956028158601157\n",
      "Iteration 8531 => Loss: 50.68949217905051085609\n",
      "Iteration 8532 => Loss: 50.68929479936859650024\n",
      "Iteration 8533 => Loss: 50.68909742123583583862\n",
      "Iteration 8534 => Loss: 50.68890004465219334406\n",
      "Iteration 8535 => Loss: 50.68870266961767612202\n",
      "Iteration 8536 => Loss: 50.68850529613226285619\n",
      "Iteration 8537 => Loss: 50.68830792419596065201\n",
      "Iteration 8538 => Loss: 50.68811055380871977150\n",
      "Iteration 8539 => Loss: 50.68791318497059705805\n",
      "Iteration 8540 => Loss: 50.68771581768147882485\n",
      "Iteration 8541 => Loss: 50.68751845194142902074\n",
      "Iteration 8542 => Loss: 50.68732108775042632942\n",
      "Iteration 8543 => Loss: 50.68712372510843522377\n",
      "Iteration 8544 => Loss: 50.68692636401544859837\n",
      "Iteration 8545 => Loss: 50.68672900447145224234\n",
      "Iteration 8546 => Loss: 50.68653164647645326113\n",
      "Iteration 8547 => Loss: 50.68633429003043033845\n",
      "Iteration 8548 => Loss: 50.68613693513335505259\n",
      "Iteration 8549 => Loss: 50.68593958178523450897\n",
      "Iteration 8550 => Loss: 50.68574222998606160218\n",
      "Iteration 8551 => Loss: 50.68554487973579369964\n",
      "Iteration 8552 => Loss: 50.68534753103443790678\n",
      "Iteration 8553 => Loss: 50.68515018388199422361\n",
      "Iteration 8554 => Loss: 50.68495283827842001756\n",
      "Iteration 8555 => Loss: 50.68475549422372949948\n",
      "Iteration 8556 => Loss: 50.68455815171789424767\n",
      "Iteration 8557 => Loss: 50.68436081076090005126\n",
      "Iteration 8558 => Loss: 50.68416347135276112112\n",
      "Iteration 8559 => Loss: 50.68396613349340640298\n",
      "Iteration 8560 => Loss: 50.68376879718290695109\n",
      "Iteration 8561 => Loss: 50.68357146242118460577\n",
      "Iteration 8562 => Loss: 50.68337412920825357787\n",
      "Iteration 8563 => Loss: 50.68317679754409255111\n",
      "Iteration 8564 => Loss: 50.68297946742869442005\n",
      "Iteration 8565 => Loss: 50.68278213886203786842\n",
      "Iteration 8566 => Loss: 50.68258481184413000165\n",
      "Iteration 8567 => Loss: 50.68238748637494239802\n",
      "Iteration 8568 => Loss: 50.68219016245446795210\n",
      "Iteration 8569 => Loss: 50.68199284008269245305\n",
      "Iteration 8570 => Loss: 50.68179551925959458458\n",
      "Iteration 8571 => Loss: 50.68159819998519566298\n",
      "Iteration 8572 => Loss: 50.68140088225943884481\n",
      "Iteration 8573 => Loss: 50.68120356608231702467\n",
      "Iteration 8574 => Loss: 50.68100625145387283510\n",
      "Iteration 8575 => Loss: 50.68080893837402101099\n",
      "Iteration 8576 => Loss: 50.68061162684279707946\n",
      "Iteration 8577 => Loss: 50.68041431686017972424\n",
      "Iteration 8578 => Loss: 50.68021700842614052362\n",
      "Iteration 8579 => Loss: 50.68001970154067947760\n",
      "Iteration 8580 => Loss: 50.67982239620376816447\n",
      "Iteration 8581 => Loss: 50.67962509241539237337\n",
      "Iteration 8582 => Loss: 50.67942779017559473687\n",
      "Iteration 8583 => Loss: 50.67923048948432551697\n",
      "Iteration 8584 => Loss: 50.67903319034155629197\n",
      "Iteration 8585 => Loss: 50.67883589274727285101\n",
      "Iteration 8586 => Loss: 50.67863859670149651038\n",
      "Iteration 8587 => Loss: 50.67844130220418463750\n",
      "Iteration 8588 => Loss: 50.67824400925534433782\n",
      "Iteration 8589 => Loss: 50.67804671785495429503\n",
      "Iteration 8590 => Loss: 50.67784942800300029830\n",
      "Iteration 8591 => Loss: 50.67765213969946813677\n",
      "Iteration 8592 => Loss: 50.67745485294435781043\n",
      "Iteration 8593 => Loss: 50.67725756773764800300\n",
      "Iteration 8594 => Loss: 50.67706028407932450364\n",
      "Iteration 8595 => Loss: 50.67686300196939441776\n",
      "Iteration 8596 => Loss: 50.67666572140780800737\n",
      "Iteration 8597 => Loss: 50.67646844239457948333\n",
      "Iteration 8598 => Loss: 50.67627116492971595108\n",
      "Iteration 8599 => Loss: 50.67607388901315346175\n",
      "Iteration 8600 => Loss: 50.67587661464489201535\n",
      "Iteration 8601 => Loss: 50.67567934182496003359\n",
      "Iteration 8602 => Loss: 50.67548207055330777848\n",
      "Iteration 8603 => Loss: 50.67528480082995656630\n",
      "Iteration 8604 => Loss: 50.67508753265484244821\n",
      "Iteration 8605 => Loss: 50.67489026602798674048\n",
      "Iteration 8606 => Loss: 50.67469300094937523227\n",
      "Iteration 8607 => Loss: 50.67449573741899371271\n",
      "Iteration 8608 => Loss: 50.67429847543684928723\n",
      "Iteration 8609 => Loss: 50.67410121500286379614\n",
      "Iteration 8610 => Loss: 50.67390395611710829371\n",
      "Iteration 8611 => Loss: 50.67370669877950462023\n",
      "Iteration 8612 => Loss: 50.67350944299008830285\n",
      "Iteration 8613 => Loss: 50.67331218874883091985\n",
      "Iteration 8614 => Loss: 50.67311493605569694409\n",
      "Iteration 8615 => Loss: 50.67291768491070058644\n",
      "Iteration 8616 => Loss: 50.67272043531380631975\n",
      "Iteration 8617 => Loss: 50.67252318726503546031\n",
      "Iteration 8618 => Loss: 50.67232594076435248098\n",
      "Iteration 8619 => Loss: 50.67212869581177159262\n",
      "Iteration 8620 => Loss: 50.67193145240722174094\n",
      "Iteration 8621 => Loss: 50.67173421055071713681\n",
      "Iteration 8622 => Loss: 50.67153697024230751822\n",
      "Iteration 8623 => Loss: 50.67133973148189340918\n",
      "Iteration 8624 => Loss: 50.67114249426951033684\n",
      "Iteration 8625 => Loss: 50.67094525860513698490\n",
      "Iteration 8626 => Loss: 50.67074802448875203709\n",
      "Iteration 8627 => Loss: 50.67055079192033417712\n",
      "Iteration 8628 => Loss: 50.67035356089990472128\n",
      "Iteration 8629 => Loss: 50.67015633142740682615\n",
      "Iteration 8630 => Loss: 50.66995910350288312429\n",
      "Iteration 8631 => Loss: 50.66976187712626966686\n",
      "Iteration 8632 => Loss: 50.66956465229758777014\n",
      "Iteration 8633 => Loss: 50.66936742901681611784\n",
      "Iteration 8634 => Loss: 50.66917020728393339368\n",
      "Iteration 8635 => Loss: 50.66897298709893249224\n",
      "Iteration 8636 => Loss: 50.66877576846178499181\n",
      "Iteration 8637 => Loss: 50.66857855137253352495\n",
      "Iteration 8638 => Loss: 50.66838133583109282654\n",
      "Iteration 8639 => Loss: 50.66818412183749131827\n",
      "Iteration 8640 => Loss: 50.66798690939170768388\n",
      "Iteration 8641 => Loss: 50.66778969849376323964\n",
      "Iteration 8642 => Loss: 50.66759248914359403670\n",
      "Iteration 8643 => Loss: 50.66739528134121428593\n",
      "Iteration 8644 => Loss: 50.66719807508659556561\n",
      "Iteration 8645 => Loss: 50.66700087037971655946\n",
      "Iteration 8646 => Loss: 50.66680366722060568918\n",
      "Iteration 8647 => Loss: 50.66660646560923453308\n",
      "Iteration 8648 => Loss: 50.66640926554558177486\n",
      "Iteration 8649 => Loss: 50.66621206702964030910\n",
      "Iteration 8650 => Loss: 50.66601487006138881952\n",
      "Iteration 8651 => Loss: 50.66581767464082020069\n",
      "Iteration 8652 => Loss: 50.66562048076794155804\n",
      "Iteration 8653 => Loss: 50.66542328844271025901\n",
      "Iteration 8654 => Loss: 50.66522609766512630358\n",
      "Iteration 8655 => Loss: 50.66502890843517548092\n",
      "Iteration 8656 => Loss: 50.66483172075285068559\n",
      "Iteration 8657 => Loss: 50.66463453461813770673\n",
      "Iteration 8658 => Loss: 50.66443735003101522807\n",
      "Iteration 8659 => Loss: 50.66424016699149035503\n",
      "Iteration 8660 => Loss: 50.66404298549952756048\n",
      "Iteration 8661 => Loss: 50.66384580555511973898\n",
      "Iteration 8662 => Loss: 50.66364862715828820683\n",
      "Iteration 8663 => Loss: 50.66345145030897612060\n",
      "Iteration 8664 => Loss: 50.66325427500719769114\n",
      "Iteration 8665 => Loss: 50.66305710125290318047\n",
      "Iteration 8666 => Loss: 50.66285992904612811571\n",
      "Iteration 8667 => Loss: 50.66266275838684407518\n",
      "Iteration 8668 => Loss: 50.66246558927502974257\n",
      "Iteration 8669 => Loss: 50.66226842171066380160\n",
      "Iteration 8670 => Loss: 50.66207125569378177943\n",
      "Iteration 8671 => Loss: 50.66187409122431972719\n",
      "Iteration 8672 => Loss: 50.66167692830229185574\n",
      "Iteration 8673 => Loss: 50.66147976692764842710\n",
      "Iteration 8674 => Loss: 50.66128260710044628468\n",
      "Iteration 8675 => Loss: 50.66108544882059305792\n",
      "Iteration 8676 => Loss: 50.66088829208814559024\n",
      "Iteration 8677 => Loss: 50.66069113690304703823\n",
      "Iteration 8678 => Loss: 50.66049398326530450731\n",
      "Iteration 8679 => Loss: 50.66029683117488247035\n",
      "Iteration 8680 => Loss: 50.66009968063180224362\n",
      "Iteration 8681 => Loss: 50.65990253163606382714\n",
      "Iteration 8682 => Loss: 50.65970538418759616661\n",
      "Iteration 8683 => Loss: 50.65950823828642057833\n",
      "Iteration 8684 => Loss: 50.65931109393252285145\n",
      "Iteration 8685 => Loss: 50.65911395112590298595\n",
      "Iteration 8686 => Loss: 50.65891680986651124385\n",
      "Iteration 8687 => Loss: 50.65871967015439736315\n",
      "Iteration 8688 => Loss: 50.65852253198947607871\n",
      "Iteration 8689 => Loss: 50.65832539537177581224\n",
      "Iteration 8690 => Loss: 50.65812826030128945831\n",
      "Iteration 8691 => Loss: 50.65793112677798148979\n",
      "Iteration 8692 => Loss: 50.65773399480189453925\n",
      "Iteration 8693 => Loss: 50.65753686437291491984\n",
      "Iteration 8694 => Loss: 50.65733973549112079127\n",
      "Iteration 8695 => Loss: 50.65714260815646952096\n",
      "Iteration 8696 => Loss: 50.65694548236892558180\n",
      "Iteration 8697 => Loss: 50.65674835812853160633\n",
      "Iteration 8698 => Loss: 50.65655123543522364571\n",
      "Iteration 8699 => Loss: 50.65635411428901591080\n",
      "Iteration 8700 => Loss: 50.65615699468987287446\n",
      "Iteration 8701 => Loss: 50.65595987663780164212\n",
      "Iteration 8702 => Loss: 50.65576276013279510835\n",
      "Iteration 8703 => Loss: 50.65556564517482485144\n",
      "Iteration 8704 => Loss: 50.65536853176389087139\n",
      "Iteration 8705 => Loss: 50.65517141989997895735\n",
      "Iteration 8706 => Loss: 50.65497430958305358217\n",
      "Iteration 8707 => Loss: 50.65477720081314316758\n",
      "Iteration 8708 => Loss: 50.65458009359021218643\n",
      "Iteration 8709 => Loss: 50.65438298791423221701\n",
      "Iteration 8710 => Loss: 50.65418588378525299731\n",
      "Iteration 8711 => Loss: 50.65398878120318215679\n",
      "Iteration 8712 => Loss: 50.65379168016805522257\n",
      "Iteration 8713 => Loss: 50.65359458067982956209\n",
      "Iteration 8714 => Loss: 50.65339748273851228078\n",
      "Iteration 8715 => Loss: 50.65320038634411048406\n",
      "Iteration 8716 => Loss: 50.65300329149658864480\n",
      "Iteration 8717 => Loss: 50.65280619819593255215\n",
      "Iteration 8718 => Loss: 50.65260910644210667897\n",
      "Iteration 8719 => Loss: 50.65241201623516786867\n",
      "Iteration 8720 => Loss: 50.65221492757506638327\n",
      "Iteration 8721 => Loss: 50.65201784046175959020\n",
      "Iteration 8722 => Loss: 50.65182075489526880574\n",
      "Iteration 8723 => Loss: 50.65162367087557981904\n",
      "Iteration 8724 => Loss: 50.65142658840267131382\n",
      "Iteration 8725 => Loss: 50.65122950747654329007\n",
      "Iteration 8726 => Loss: 50.65103242809716022066\n",
      "Iteration 8727 => Loss: 50.65083535026453631644\n",
      "Iteration 8728 => Loss: 50.65063827397863605029\n",
      "Iteration 8729 => Loss: 50.65044119923946652762\n",
      "Iteration 8730 => Loss: 50.65024412604702774843\n",
      "Iteration 8731 => Loss: 50.65004705440126286931\n",
      "Iteration 8732 => Loss: 50.64984998430217899568\n",
      "Iteration 8733 => Loss: 50.64965291574979033840\n",
      "Iteration 8734 => Loss: 50.64945584874404715947\n",
      "Iteration 8735 => Loss: 50.64925878328495656433\n",
      "Iteration 8736 => Loss: 50.64906171937249013126\n",
      "Iteration 8737 => Loss: 50.64886465700668338741\n",
      "Iteration 8738 => Loss: 50.64866759618744396221\n",
      "Iteration 8739 => Loss: 50.64847053691482869908\n",
      "Iteration 8740 => Loss: 50.64827347918880917632\n",
      "Iteration 8741 => Loss: 50.64807642300936407764\n",
      "Iteration 8742 => Loss: 50.64787936837645787591\n",
      "Iteration 8743 => Loss: 50.64768231529012609826\n",
      "Iteration 8744 => Loss: 50.64748526375033321756\n",
      "Iteration 8745 => Loss: 50.64728821375703660124\n",
      "Iteration 8746 => Loss: 50.64709116531027888186\n",
      "Iteration 8747 => Loss: 50.64689411841002453230\n",
      "Iteration 8748 => Loss: 50.64669707305625934168\n",
      "Iteration 8749 => Loss: 50.64650002924894778289\n",
      "Iteration 8750 => Loss: 50.64630298698811827762\n",
      "Iteration 8751 => Loss: 50.64610594627374240417\n",
      "Iteration 8752 => Loss: 50.64590890710580595169\n",
      "Iteration 8753 => Loss: 50.64571186948429470931\n",
      "Iteration 8754 => Loss: 50.64551483340918025533\n",
      "Iteration 8755 => Loss: 50.64531779888050522231\n",
      "Iteration 8756 => Loss: 50.64512076589820566141\n",
      "Iteration 8757 => Loss: 50.64492373446226736178\n",
      "Iteration 8758 => Loss: 50.64472670457272585054\n",
      "Iteration 8759 => Loss: 50.64452967622950296800\n",
      "Iteration 8760 => Loss: 50.64433264943263424129\n",
      "Iteration 8761 => Loss: 50.64413562418211256499\n",
      "Iteration 8762 => Loss: 50.64393860047790241197\n",
      "Iteration 8763 => Loss: 50.64374157831998957136\n",
      "Iteration 8764 => Loss: 50.64354455770836693773\n",
      "Iteration 8765 => Loss: 50.64334753864302740567\n",
      "Iteration 8766 => Loss: 50.64315052112394965889\n",
      "Iteration 8767 => Loss: 50.64295350515113369738\n",
      "Iteration 8768 => Loss: 50.64275649072457241573\n",
      "Iteration 8769 => Loss: 50.64255947784423739222\n",
      "Iteration 8770 => Loss: 50.64236246651011441600\n",
      "Iteration 8771 => Loss: 50.64216545672218927621\n",
      "Iteration 8772 => Loss: 50.64196844848046907828\n",
      "Iteration 8773 => Loss: 50.64177144178491118964\n",
      "Iteration 8774 => Loss: 50.64157443663552982116\n",
      "Iteration 8775 => Loss: 50.64137743303231786740\n",
      "Iteration 8776 => Loss: 50.64118043097526111751\n",
      "Iteration 8777 => Loss: 50.64098343046430983350\n",
      "Iteration 8778 => Loss: 50.64078643149947822621\n",
      "Iteration 8779 => Loss: 50.64058943408080892823\n",
      "Iteration 8780 => Loss: 50.64039243820816693642\n",
      "Iteration 8781 => Loss: 50.64019544388164462134\n",
      "Iteration 8782 => Loss: 50.63999845110117803415\n",
      "Iteration 8783 => Loss: 50.63980145986677428027\n",
      "Iteration 8784 => Loss: 50.63960447017839783257\n",
      "Iteration 8785 => Loss: 50.63940748203609132361\n",
      "Iteration 8786 => Loss: 50.63921049543980501539\n",
      "Iteration 8787 => Loss: 50.63901351038951759165\n",
      "Iteration 8788 => Loss: 50.63881652688521484151\n",
      "Iteration 8789 => Loss: 50.63861954492691808127\n",
      "Iteration 8790 => Loss: 50.63842256451457046751\n",
      "Iteration 8791 => Loss: 50.63822558564820042193\n",
      "Iteration 8792 => Loss: 50.63802860832780083911\n",
      "Iteration 8793 => Loss: 50.63783163255330066477\n",
      "Iteration 8794 => Loss: 50.63763465832470700434\n",
      "Iteration 8795 => Loss: 50.63743768564207670124\n",
      "Iteration 8796 => Loss: 50.63724071450531738492\n",
      "Iteration 8797 => Loss: 50.63704374491444326623\n",
      "Iteration 8798 => Loss: 50.63684677686944013431\n",
      "Iteration 8799 => Loss: 50.63664981037031509459\n",
      "Iteration 8800 => Loss: 50.63645284541702551451\n",
      "Iteration 8801 => Loss: 50.63625588200959271035\n",
      "Iteration 8802 => Loss: 50.63605892014797404954\n",
      "Iteration 8803 => Loss: 50.63586195983215532124\n",
      "Iteration 8804 => Loss: 50.63566500106215784172\n",
      "Iteration 8805 => Loss: 50.63546804383794608384\n",
      "Iteration 8806 => Loss: 50.63527108815951294218\n",
      "Iteration 8807 => Loss: 50.63507413402682288961\n",
      "Iteration 8808 => Loss: 50.63487718143991145325\n",
      "Iteration 8809 => Loss: 50.63468023039870047342\n",
      "Iteration 8810 => Loss: 50.63448328090326810980\n",
      "Iteration 8811 => Loss: 50.63428633295350778099\n",
      "Iteration 8812 => Loss: 50.63408938654947633040\n",
      "Iteration 8813 => Loss: 50.63389244169110980920\n",
      "Iteration 8814 => Loss: 50.63369549837845795537\n",
      "Iteration 8815 => Loss: 50.63349855661144971464\n",
      "Iteration 8816 => Loss: 50.63330161639009929786\n",
      "Iteration 8817 => Loss: 50.63310467771438538875\n",
      "Iteration 8818 => Loss: 50.63290774058431509275\n",
      "Iteration 8819 => Loss: 50.63271080499983867185\n",
      "Iteration 8820 => Loss: 50.63251387096098454776\n",
      "Iteration 8821 => Loss: 50.63231693846770298251\n",
      "Iteration 8822 => Loss: 50.63212000752000108150\n",
      "Iteration 8823 => Loss: 50.63192307811790016103\n",
      "Iteration 8824 => Loss: 50.63172615026134337768\n",
      "Iteration 8825 => Loss: 50.63152922395030230973\n",
      "Iteration 8826 => Loss: 50.63133229918481958975\n",
      "Iteration 8827 => Loss: 50.63113537596485258518\n",
      "Iteration 8828 => Loss: 50.63093845429038708517\n",
      "Iteration 8829 => Loss: 50.63074153416140177342\n",
      "Iteration 8830 => Loss: 50.63054461557791086079\n",
      "Iteration 8831 => Loss: 50.63034769853988592558\n",
      "Iteration 8832 => Loss: 50.63015078304731275693\n",
      "Iteration 8833 => Loss: 50.62995386910020556570\n",
      "Iteration 8834 => Loss: 50.62975695669852171932\n",
      "Iteration 8835 => Loss: 50.62956004584226121779\n",
      "Iteration 8836 => Loss: 50.62936313653139563939\n",
      "Iteration 8837 => Loss: 50.62916622876595340585\n",
      "Iteration 8838 => Loss: 50.62896932254584925204\n",
      "Iteration 8839 => Loss: 50.62877241787114712679\n",
      "Iteration 8840 => Loss: 50.62857551474179729212\n",
      "Iteration 8841 => Loss: 50.62837861315780685345\n",
      "Iteration 8842 => Loss: 50.62818171311910475652\n",
      "Iteration 8843 => Loss: 50.62798481462577626644\n",
      "Iteration 8844 => Loss: 50.62778791767774322352\n",
      "Iteration 8845 => Loss: 50.62759102227501983862\n",
      "Iteration 8846 => Loss: 50.62739412841756347916\n",
      "Iteration 8847 => Loss: 50.62719723610538125058\n",
      "Iteration 8848 => Loss: 50.62700034533846604745\n",
      "Iteration 8849 => Loss: 50.62680345611680365892\n",
      "Iteration 8850 => Loss: 50.62660656844035855784\n",
      "Iteration 8851 => Loss: 50.62640968230915206050\n",
      "Iteration 8852 => Loss: 50.62621279772316285062\n",
      "Iteration 8853 => Loss: 50.62601591468236961191\n",
      "Iteration 8854 => Loss: 50.62581903318676523895\n",
      "Iteration 8855 => Loss: 50.62562215323632841546\n",
      "Iteration 8856 => Loss: 50.62542527483108045772\n",
      "Iteration 8857 => Loss: 50.62522839797096452230\n",
      "Iteration 8858 => Loss: 50.62503152265595218751\n",
      "Iteration 8859 => Loss: 50.62483464888611450760\n",
      "Iteration 8860 => Loss: 50.62463777666138753375\n",
      "Iteration 8861 => Loss: 50.62444090598172152795\n",
      "Iteration 8862 => Loss: 50.62424403684718043905\n",
      "Iteration 8863 => Loss: 50.62404716925769321278\n",
      "Iteration 8864 => Loss: 50.62385030321330248171\n",
      "Iteration 8865 => Loss: 50.62365343871395140241\n",
      "Iteration 8866 => Loss: 50.62345657575961155317\n",
      "Iteration 8867 => Loss: 50.62325971435031846113\n",
      "Iteration 8868 => Loss: 50.62306285448608633715\n",
      "Iteration 8869 => Loss: 50.62286599616680859981\n",
      "Iteration 8870 => Loss: 50.62266913939252077625\n",
      "Iteration 8871 => Loss: 50.62247228416322997191\n",
      "Iteration 8872 => Loss: 50.62227543047890776506\n",
      "Iteration 8873 => Loss: 50.62207857833953283944\n",
      "Iteration 8874 => Loss: 50.62188172774509808960\n",
      "Iteration 8875 => Loss: 50.62168487869559641013\n",
      "Iteration 8876 => Loss: 50.62148803119101359016\n",
      "Iteration 8877 => Loss: 50.62129118523133541885\n",
      "Iteration 8878 => Loss: 50.62109434081656189619\n",
      "Iteration 8879 => Loss: 50.62089749794662907334\n",
      "Iteration 8880 => Loss: 50.62070065662161511000\n",
      "Iteration 8881 => Loss: 50.62050381684144895189\n",
      "Iteration 8882 => Loss: 50.62030697860609507188\n",
      "Iteration 8883 => Loss: 50.62011014191558899711\n",
      "Iteration 8884 => Loss: 50.61991330676993072757\n",
      "Iteration 8885 => Loss: 50.61971647316903499814\n",
      "Iteration 8886 => Loss: 50.61951964111295154680\n",
      "Iteration 8887 => Loss: 50.61932281060168037357\n",
      "Iteration 8888 => Loss: 50.61912598163513621330\n",
      "Iteration 8889 => Loss: 50.61892915421336880399\n",
      "Iteration 8890 => Loss: 50.61873232833634972394\n",
      "Iteration 8891 => Loss: 50.61853550400406476228\n",
      "Iteration 8892 => Loss: 50.61833868121649970817\n",
      "Iteration 8893 => Loss: 50.61814185997364745617\n",
      "Iteration 8894 => Loss: 50.61794504027549379543\n",
      "Iteration 8895 => Loss: 50.61774822212201030425\n",
      "Iteration 8896 => Loss: 50.61755140551321829889\n",
      "Iteration 8897 => Loss: 50.61735459044908225223\n",
      "Iteration 8898 => Loss: 50.61715777692959505885\n",
      "Iteration 8899 => Loss: 50.61696096495474250787\n",
      "Iteration 8900 => Loss: 50.61676415452451749388\n",
      "Iteration 8901 => Loss: 50.61656734563891291145\n",
      "Iteration 8902 => Loss: 50.61637053829788612802\n",
      "Iteration 8903 => Loss: 50.61617373250145135444\n",
      "Iteration 8904 => Loss: 50.61597692824961569613\n",
      "Iteration 8905 => Loss: 50.61578012554230099340\n",
      "Iteration 8906 => Loss: 50.61558332437956408967\n",
      "Iteration 8907 => Loss: 50.61538652476136235236\n",
      "Iteration 8908 => Loss: 50.61518972668769578149\n",
      "Iteration 8909 => Loss: 50.61499293015853595534\n",
      "Iteration 8910 => Loss: 50.61479613517385445220\n",
      "Iteration 8911 => Loss: 50.61459934173370101007\n",
      "Iteration 8912 => Loss: 50.61440254983798325839\n",
      "Iteration 8913 => Loss: 50.61420575948675804057\n",
      "Iteration 8914 => Loss: 50.61400897067998272405\n",
      "Iteration 8915 => Loss: 50.61381218341764309798\n",
      "Iteration 8916 => Loss: 50.61361539769974626779\n",
      "Iteration 8917 => Loss: 50.61341861352624249548\n",
      "Iteration 8918 => Loss: 50.61322183089715309734\n",
      "Iteration 8919 => Loss: 50.61302504981246386251\n",
      "Iteration 8920 => Loss: 50.61282827027215347471\n",
      "Iteration 8921 => Loss: 50.61263149227617930137\n",
      "Iteration 8922 => Loss: 50.61243471582459108049\n",
      "Iteration 8923 => Loss: 50.61223794091733196865\n",
      "Iteration 8924 => Loss: 50.61204116755441617670\n",
      "Iteration 8925 => Loss: 50.61184439573579396665\n",
      "Iteration 8926 => Loss: 50.61164762546150086564\n",
      "Iteration 8927 => Loss: 50.61145085673150134653\n",
      "Iteration 8928 => Loss: 50.61125408954578119847\n",
      "Iteration 8929 => Loss: 50.61105732390432621060\n",
      "Iteration 8930 => Loss: 50.61086055980713638291\n",
      "Iteration 8931 => Loss: 50.61066379725417618829\n",
      "Iteration 8932 => Loss: 50.61046703624546694300\n",
      "Iteration 8933 => Loss: 50.61027027678095180363\n",
      "Iteration 8934 => Loss: 50.61007351886065208646\n",
      "Iteration 8935 => Loss: 50.60987676248456068606\n",
      "Iteration 8936 => Loss: 50.60968000765264918073\n",
      "Iteration 8937 => Loss: 50.60948325436487493789\n",
      "Iteration 8938 => Loss: 50.60928650262133032811\n",
      "Iteration 8939 => Loss: 50.60908975242188034827\n",
      "Iteration 8940 => Loss: 50.60889300376656052549\n",
      "Iteration 8941 => Loss: 50.60869625665539928150\n",
      "Iteration 8942 => Loss: 50.60849951108832556201\n",
      "Iteration 8943 => Loss: 50.60830276706535357789\n",
      "Iteration 8944 => Loss: 50.60810602458648332913\n",
      "Iteration 8945 => Loss: 50.60790928365166507774\n",
      "Iteration 8946 => Loss: 50.60771254426089882372\n",
      "Iteration 8947 => Loss: 50.60751580641420588336\n",
      "Iteration 8948 => Loss: 50.60731907011154362408\n",
      "Iteration 8949 => Loss: 50.60712233535288362418\n",
      "Iteration 8950 => Loss: 50.60692560213827562166\n",
      "Iteration 8951 => Loss: 50.60672887046764856223\n",
      "Iteration 8952 => Loss: 50.60653214034099534047\n",
      "Iteration 8953 => Loss: 50.60633541175834437809\n",
      "Iteration 8954 => Loss: 50.60613868471963883167\n",
      "Iteration 8955 => Loss: 50.60594195922490001749\n",
      "Iteration 8956 => Loss: 50.60574523527407819756\n",
      "Iteration 8957 => Loss: 50.60554851286720179360\n",
      "Iteration 8958 => Loss: 50.60535179200424948931\n",
      "Iteration 8959 => Loss: 50.60515507268516444128\n",
      "Iteration 8960 => Loss: 50.60495835490998928208\n",
      "Iteration 8961 => Loss: 50.60476163867868848456\n",
      "Iteration 8962 => Loss: 50.60456492399124783788\n",
      "Iteration 8963 => Loss: 50.60436821084767444745\n",
      "Iteration 8964 => Loss: 50.60417149924794699700\n",
      "Iteration 8965 => Loss: 50.60397478919203706482\n",
      "Iteration 8966 => Loss: 50.60377808067993754548\n",
      "Iteration 8967 => Loss: 50.60358137371166975527\n",
      "Iteration 8968 => Loss: 50.60338466828716263990\n",
      "Iteration 8969 => Loss: 50.60318796440644462109\n",
      "Iteration 8970 => Loss: 50.60299126206951569884\n",
      "Iteration 8971 => Loss: 50.60279456127631902973\n",
      "Iteration 8972 => Loss: 50.60259786202687593004\n",
      "Iteration 8973 => Loss: 50.60240116432115797807\n",
      "Iteration 8974 => Loss: 50.60220446815916517380\n",
      "Iteration 8975 => Loss: 50.60200777354089041182\n",
      "Iteration 8976 => Loss: 50.60181108046628395414\n",
      "Iteration 8977 => Loss: 50.60161438893537422246\n",
      "Iteration 8978 => Loss: 50.60141769894813279507\n",
      "Iteration 8979 => Loss: 50.60122101050454546112\n",
      "Iteration 8980 => Loss: 50.60102432360461222061\n",
      "Iteration 8981 => Loss: 50.60082763824829044097\n",
      "Iteration 8982 => Loss: 50.60063095443563696563\n",
      "Iteration 8983 => Loss: 50.60043427216653100231\n",
      "Iteration 8984 => Loss: 50.60023759144105781616\n",
      "Iteration 8985 => Loss: 50.60004091225918188002\n",
      "Iteration 8986 => Loss: 50.59984423462085345591\n",
      "Iteration 8987 => Loss: 50.59964755852610807096\n",
      "Iteration 8988 => Loss: 50.59945088397488888177\n",
      "Iteration 8989 => Loss: 50.59925421096722431002\n",
      "Iteration 8990 => Loss: 50.59905753950306461775\n",
      "Iteration 8991 => Loss: 50.59886086958239559408\n",
      "Iteration 8992 => Loss: 50.59866420120529539872\n",
      "Iteration 8993 => Loss: 50.59846753437162902856\n",
      "Iteration 8994 => Loss: 50.59827086908144622157\n",
      "Iteration 8995 => Loss: 50.59807420533472566149\n",
      "Iteration 8996 => Loss: 50.59787754313148155916\n",
      "Iteration 8997 => Loss: 50.59768088247164286031\n",
      "Iteration 8998 => Loss: 50.59748422335524509208\n",
      "Iteration 8999 => Loss: 50.59728756578226693819\n",
      "Iteration 9000 => Loss: 50.59709090975268708235\n",
      "Iteration 9001 => Loss: 50.59689425526649131371\n",
      "Iteration 9002 => Loss: 50.59669760232365121055\n",
      "Iteration 9003 => Loss: 50.59650095092420940546\n",
      "Iteration 9004 => Loss: 50.59630430106810194957\n",
      "Iteration 9005 => Loss: 50.59610765275532884289\n",
      "Iteration 9006 => Loss: 50.59591100598590429627\n",
      "Iteration 9007 => Loss: 50.59571436075980699343\n",
      "Iteration 9008 => Loss: 50.59551771707698009095\n",
      "Iteration 9009 => Loss: 50.59532107493747332683\n",
      "Iteration 9010 => Loss: 50.59512443434122985764\n",
      "Iteration 9011 => Loss: 50.59492779528824257795\n",
      "Iteration 9012 => Loss: 50.59473115777853280406\n",
      "Iteration 9013 => Loss: 50.59453452181205790339\n",
      "Iteration 9014 => Loss: 50.59433788738883208680\n",
      "Iteration 9015 => Loss: 50.59414125450879851087\n",
      "Iteration 9016 => Loss: 50.59394462317197849188\n",
      "Iteration 9017 => Loss: 50.59374799337834360813\n",
      "Iteration 9018 => Loss: 50.59355136512790807046\n",
      "Iteration 9019 => Loss: 50.59335473842062214089\n",
      "Iteration 9020 => Loss: 50.59315811325651424113\n",
      "Iteration 9021 => Loss: 50.59296148963554884403\n",
      "Iteration 9022 => Loss: 50.59276486755771884418\n",
      "Iteration 9023 => Loss: 50.59256824702297450358\n",
      "Iteration 9024 => Loss: 50.59237162803137977107\n",
      "Iteration 9025 => Loss: 50.59217501058287780324\n",
      "Iteration 9026 => Loss: 50.59197839467744728381\n",
      "Iteration 9027 => Loss: 50.59178178031509531820\n",
      "Iteration 9028 => Loss: 50.59158516749579348470\n",
      "Iteration 9029 => Loss: 50.59138855621954888875\n",
      "Iteration 9030 => Loss: 50.59119194648634731948\n",
      "Iteration 9031 => Loss: 50.59099533829614614433\n",
      "Iteration 9032 => Loss: 50.59079873164896667959\n",
      "Iteration 9033 => Loss: 50.59060212654478050354\n",
      "Iteration 9034 => Loss: 50.59040552298361603789\n",
      "Iteration 9035 => Loss: 50.59020892096538091209\n",
      "Iteration 9036 => Loss: 50.59001232049014618042\n",
      "Iteration 9037 => Loss: 50.58981572155781947231\n",
      "Iteration 9038 => Loss: 50.58961912416847184204\n",
      "Iteration 9039 => Loss: 50.58942252832201802448\n",
      "Iteration 9040 => Loss: 50.58922593401848644135\n",
      "Iteration 9041 => Loss: 50.58902934125787709263\n",
      "Iteration 9042 => Loss: 50.58883275004013313492\n",
      "Iteration 9043 => Loss: 50.58863616036527588449\n",
      "Iteration 9044 => Loss: 50.58843957223329113049\n",
      "Iteration 9045 => Loss: 50.58824298564415045121\n",
      "Iteration 9046 => Loss: 50.58804640059783963579\n",
      "Iteration 9047 => Loss: 50.58784981709435868424\n",
      "Iteration 9048 => Loss: 50.58765323513371470199\n",
      "Iteration 9049 => Loss: 50.58745665471583663475\n",
      "Iteration 9050 => Loss: 50.58726007584079553681\n",
      "Iteration 9051 => Loss: 50.58706349850851324845\n",
      "Iteration 9052 => Loss: 50.58686692271899687512\n",
      "Iteration 9053 => Loss: 50.58667034847224641680\n",
      "Iteration 9054 => Loss: 50.58647377576821924094\n",
      "Iteration 9055 => Loss: 50.58627720460692955839\n",
      "Iteration 9056 => Loss: 50.58608063498836315830\n",
      "Iteration 9057 => Loss: 50.58588406691250582981\n",
      "Iteration 9058 => Loss: 50.58568750037933625663\n",
      "Iteration 9059 => Loss: 50.58549093538884733334\n",
      "Iteration 9060 => Loss: 50.58529437194103195452\n",
      "Iteration 9061 => Loss: 50.58509781003586169845\n",
      "Iteration 9062 => Loss: 50.58490124967336498685\n",
      "Iteration 9063 => Loss: 50.58470469085347076543\n",
      "Iteration 9064 => Loss: 50.58450813357622166677\n",
      "Iteration 9065 => Loss: 50.58431157784156084745\n",
      "Iteration 9066 => Loss: 50.58411502364950251831\n",
      "Iteration 9067 => Loss: 50.58391847100003957394\n",
      "Iteration 9068 => Loss: 50.58372191989312938176\n",
      "Iteration 9069 => Loss: 50.58352537032880036350\n",
      "Iteration 9070 => Loss: 50.58332882230700988657\n",
      "Iteration 9071 => Loss: 50.58313227582777216185\n",
      "Iteration 9072 => Loss: 50.58293573089103034590\n",
      "Iteration 9073 => Loss: 50.58273918749681286045\n",
      "Iteration 9074 => Loss: 50.58254264564508417834\n",
      "Iteration 9075 => Loss: 50.58234610533585140502\n",
      "Iteration 9076 => Loss: 50.58214956656909322419\n",
      "Iteration 9077 => Loss: 50.58195302934481674129\n",
      "Iteration 9078 => Loss: 50.58175649366296511289\n",
      "Iteration 9079 => Loss: 50.58155995952353123357\n",
      "Iteration 9080 => Loss: 50.58136342692656484132\n",
      "Iteration 9081 => Loss: 50.58116689587200198730\n",
      "Iteration 9082 => Loss: 50.58097036635982846065\n",
      "Iteration 9083 => Loss: 50.58077383839005136679\n",
      "Iteration 9084 => Loss: 50.58057731196264938944\n",
      "Iteration 9085 => Loss: 50.58038078707762963404\n",
      "Iteration 9086 => Loss: 50.58018426373493525716\n",
      "Iteration 9087 => Loss: 50.57998774193458757509\n",
      "Iteration 9088 => Loss: 50.57979122167660790410\n",
      "Iteration 9089 => Loss: 50.57959470296086834651\n",
      "Iteration 9090 => Loss: 50.57939818578750390543\n",
      "Iteration 9091 => Loss: 50.57920167015640089403\n",
      "Iteration 9092 => Loss: 50.57900515606757352316\n",
      "Iteration 9093 => Loss: 50.57880864352102889825\n",
      "Iteration 9094 => Loss: 50.57861213251672438673\n",
      "Iteration 9095 => Loss: 50.57841562305467419947\n",
      "Iteration 9096 => Loss: 50.57821911513483570388\n",
      "Iteration 9097 => Loss: 50.57802260875725863798\n",
      "Iteration 9098 => Loss: 50.57782610392185063120\n",
      "Iteration 9099 => Loss: 50.57762960062862589439\n",
      "Iteration 9100 => Loss: 50.57743309887760574384\n",
      "Iteration 9101 => Loss: 50.57723659866878307412\n",
      "Iteration 9102 => Loss: 50.57704010000207262010\n",
      "Iteration 9103 => Loss: 50.57684360287753122520\n",
      "Iteration 9104 => Loss: 50.57664710729510204601\n",
      "Iteration 9105 => Loss: 50.57645061325481350423\n",
      "Iteration 9106 => Loss: 50.57625412075663717815\n",
      "Iteration 9107 => Loss: 50.57605762980053043520\n",
      "Iteration 9108 => Loss: 50.57586114038654301339\n",
      "Iteration 9109 => Loss: 50.57566465251462517472\n",
      "Iteration 9110 => Loss: 50.57546816618474849747\n",
      "Iteration 9111 => Loss: 50.57527168139693429794\n",
      "Iteration 9112 => Loss: 50.57507519815115415440\n",
      "Iteration 9113 => Loss: 50.57487871644739385601\n",
      "Iteration 9114 => Loss: 50.57468223628564629735\n",
      "Iteration 9115 => Loss: 50.57448575766588305669\n",
      "Iteration 9116 => Loss: 50.57428928058812545032\n",
      "Iteration 9117 => Loss: 50.57409280505233084568\n",
      "Iteration 9118 => Loss: 50.57389633105852766448\n",
      "Iteration 9119 => Loss: 50.57369985860665195787\n",
      "Iteration 9120 => Loss: 50.57350338769671083128\n",
      "Iteration 9121 => Loss: 50.57330691832871849556\n",
      "Iteration 9122 => Loss: 50.57311045050262521272\n",
      "Iteration 9123 => Loss: 50.57291398421844519362\n",
      "Iteration 9124 => Loss: 50.57271751947613580569\n",
      "Iteration 9125 => Loss: 50.57252105627571836521\n",
      "Iteration 9126 => Loss: 50.57232459461716445048\n",
      "Iteration 9127 => Loss: 50.57212813450045274521\n",
      "Iteration 9128 => Loss: 50.57193167592559035484\n",
      "Iteration 9129 => Loss: 50.57173521889257017392\n",
      "Iteration 9130 => Loss: 50.57153876340134956990\n",
      "Iteration 9131 => Loss: 50.57134230945194275364\n",
      "Iteration 9132 => Loss: 50.57114585704432130342\n",
      "Iteration 9133 => Loss: 50.57094940617847811382\n",
      "Iteration 9134 => Loss: 50.57075295685441318483\n",
      "Iteration 9135 => Loss: 50.57055650907211230560\n",
      "Iteration 9136 => Loss: 50.57036006283154705443\n",
      "Iteration 9137 => Loss: 50.57016361813271743131\n",
      "Iteration 9138 => Loss: 50.56996717497558080368\n",
      "Iteration 9139 => Loss: 50.56977073336017980409\n",
      "Iteration 9140 => Loss: 50.56957429328645758915\n",
      "Iteration 9141 => Loss: 50.56937785475443547512\n",
      "Iteration 9142 => Loss: 50.56918141776407082943\n",
      "Iteration 9143 => Loss: 50.56898498231537786296\n",
      "Iteration 9144 => Loss: 50.56878854840832815398\n",
      "Iteration 9145 => Loss: 50.56859211604289328079\n",
      "Iteration 9146 => Loss: 50.56839568521908745424\n",
      "Iteration 9147 => Loss: 50.56819925593693909605\n",
      "Iteration 9148 => Loss: 50.56800282819633451936\n",
      "Iteration 9149 => Loss: 50.56780640199734477847\n",
      "Iteration 9150 => Loss: 50.56760997733989171365\n",
      "Iteration 9151 => Loss: 50.56741355422401795749\n",
      "Iteration 9152 => Loss: 50.56721713264970929913\n",
      "Iteration 9153 => Loss: 50.56702071261692310600\n",
      "Iteration 9154 => Loss: 50.56682429412567358895\n",
      "Iteration 9155 => Loss: 50.56662787717593232628\n",
      "Iteration 9156 => Loss: 50.56643146176768510713\n",
      "Iteration 9157 => Loss: 50.56623504790093193151\n",
      "Iteration 9158 => Loss: 50.56603863557567279940\n",
      "Iteration 9159 => Loss: 50.56584222479186507826\n",
      "Iteration 9160 => Loss: 50.56564581554947324094\n",
      "Iteration 9161 => Loss: 50.56544940784856834171\n",
      "Iteration 9162 => Loss: 50.56525300168907222087\n",
      "Iteration 9163 => Loss: 50.56505659707099908928\n",
      "Iteration 9164 => Loss: 50.56486019399431341981\n",
      "Iteration 9165 => Loss: 50.56466379245903652873\n",
      "Iteration 9166 => Loss: 50.56446739246512578347\n",
      "Iteration 9167 => Loss: 50.56427099401258118405\n",
      "Iteration 9168 => Loss: 50.56407459710140983589\n",
      "Iteration 9169 => Loss: 50.56387820173155489556\n",
      "Iteration 9170 => Loss: 50.56368180790304478478\n",
      "Iteration 9171 => Loss: 50.56348541561586529269\n",
      "Iteration 9172 => Loss: 50.56328902486995957588\n",
      "Iteration 9173 => Loss: 50.56309263566538447776\n",
      "Iteration 9174 => Loss: 50.56289624800208315492\n",
      "Iteration 9175 => Loss: 50.56269986188004139649\n",
      "Iteration 9176 => Loss: 50.56250347729923788620\n",
      "Iteration 9177 => Loss: 50.56230709425970104576\n",
      "Iteration 9178 => Loss: 50.56211071276140955888\n",
      "Iteration 9179 => Loss: 50.56191433280431368757\n",
      "Iteration 9180 => Loss: 50.56171795438843474813\n",
      "Iteration 9181 => Loss: 50.56152157751374431882\n",
      "Iteration 9182 => Loss: 50.56132520218026371595\n",
      "Iteration 9183 => Loss: 50.56112882838795030693\n",
      "Iteration 9184 => Loss: 50.56093245613678988093\n",
      "Iteration 9185 => Loss: 50.56073608542677533251\n",
      "Iteration 9186 => Loss: 50.56053971625788534539\n",
      "Iteration 9187 => Loss: 50.56034334863013413042\n",
      "Iteration 9188 => Loss: 50.56014698254350037132\n",
      "Iteration 9189 => Loss: 50.55995061799794854096\n",
      "Iteration 9190 => Loss: 50.55975425499348574476\n",
      "Iteration 9191 => Loss: 50.55955789353011198273\n",
      "Iteration 9192 => Loss: 50.55936153360779172772\n",
      "Iteration 9193 => Loss: 50.55916517522653919059\n",
      "Iteration 9194 => Loss: 50.55896881838629042250\n",
      "Iteration 9195 => Loss: 50.55877246308708095057\n",
      "Iteration 9196 => Loss: 50.55857610932891077482\n",
      "Iteration 9197 => Loss: 50.55837975711170884097\n",
      "Iteration 9198 => Loss: 50.55818340643553199243\n",
      "Iteration 9199 => Loss: 50.55798705730030917493\n",
      "Iteration 9200 => Loss: 50.55779070970604038848\n",
      "Iteration 9201 => Loss: 50.55759436365275405478\n",
      "Iteration 9202 => Loss: 50.55739801914037911956\n",
      "Iteration 9203 => Loss: 50.55720167616895821538\n",
      "Iteration 9204 => Loss: 50.55700533473842028798\n",
      "Iteration 9205 => Loss: 50.55680899484883639161\n",
      "Iteration 9206 => Loss: 50.55661265650012126116\n",
      "Iteration 9207 => Loss: 50.55641631969226779120\n",
      "Iteration 9208 => Loss: 50.55621998442532571971\n",
      "Iteration 9209 => Loss: 50.55602365069920978158\n",
      "Iteration 9210 => Loss: 50.55582731851393418765\n",
      "Iteration 9211 => Loss: 50.55563098786952735963\n",
      "Iteration 9212 => Loss: 50.55543465876589692698\n",
      "Iteration 9213 => Loss: 50.55523833120308552225\n",
      "Iteration 9214 => Loss: 50.55504200518109314544\n",
      "Iteration 9215 => Loss: 50.55484568069985584771\n",
      "Iteration 9216 => Loss: 50.55464935775938783991\n",
      "Iteration 9217 => Loss: 50.55445303635968912204\n",
      "Iteration 9218 => Loss: 50.55425671650075258867\n",
      "Iteration 9219 => Loss: 50.55406039818252850182\n",
      "Iteration 9220 => Loss: 50.55386408140503817776\n",
      "Iteration 9221 => Loss: 50.55366776616826030022\n",
      "Iteration 9222 => Loss: 50.55347145247218065833\n",
      "Iteration 9223 => Loss: 50.55327514031677083040\n",
      "Iteration 9224 => Loss: 50.55307882970204502726\n",
      "Iteration 9225 => Loss: 50.55288252062799614350\n",
      "Iteration 9226 => Loss: 50.55268621309456733570\n",
      "Iteration 9227 => Loss: 50.55248990710179413099\n",
      "Iteration 9228 => Loss: 50.55229360264965521310\n",
      "Iteration 9229 => Loss: 50.55209729973810084402\n",
      "Iteration 9230 => Loss: 50.55190099836716655091\n",
      "Iteration 9231 => Loss: 50.55170469853683812289\n",
      "Iteration 9232 => Loss: 50.55150840024705871656\n",
      "Iteration 9233 => Loss: 50.55131210349786385905\n",
      "Iteration 9234 => Loss: 50.55111580828920381236\n",
      "Iteration 9235 => Loss: 50.55091951462109278737\n",
      "Iteration 9236 => Loss: 50.55072322249349525691\n",
      "Iteration 9237 => Loss: 50.55052693190643253729\n",
      "Iteration 9238 => Loss: 50.55033064285986910136\n",
      "Iteration 9239 => Loss: 50.55013435535380494912\n",
      "Iteration 9240 => Loss: 50.54993806938820455343\n",
      "Iteration 9241 => Loss: 50.54974178496308212516\n",
      "Iteration 9242 => Loss: 50.54954550207841634801\n",
      "Iteration 9243 => Loss: 50.54934922073417880029\n",
      "Iteration 9244 => Loss: 50.54915294093039790368\n",
      "Iteration 9245 => Loss: 50.54895666266700970937\n",
      "Iteration 9246 => Loss: 50.54876038594403553361\n",
      "Iteration 9247 => Loss: 50.54856411076146116557\n",
      "Iteration 9248 => Loss: 50.54836783711927239438\n",
      "Iteration 9249 => Loss: 50.54817156501744790376\n",
      "Iteration 9250 => Loss: 50.54797529445598769371\n",
      "Iteration 9251 => Loss: 50.54777902543486334253\n",
      "Iteration 9252 => Loss: 50.54758275795406063935\n",
      "Iteration 9253 => Loss: 50.54738649201360800589\n",
      "Iteration 9254 => Loss: 50.54719022761346280959\n",
      "Iteration 9255 => Loss: 50.54699396475361083958\n",
      "Iteration 9256 => Loss: 50.54679770343404499044\n",
      "Iteration 9257 => Loss: 50.54660144365472973504\n",
      "Iteration 9258 => Loss: 50.54640518541570060052\n",
      "Iteration 9259 => Loss: 50.54620892871691495429\n",
      "Iteration 9260 => Loss: 50.54601267355835148010\n",
      "Iteration 9261 => Loss: 50.54581641994003859963\n",
      "Iteration 9262 => Loss: 50.54562016786191236406\n",
      "Iteration 9263 => Loss: 50.54542391732400119508\n",
      "Iteration 9264 => Loss: 50.54522766832627667100\n",
      "Iteration 9265 => Loss: 50.54503142086873879180\n",
      "Iteration 9266 => Loss: 50.54483517495135203035\n",
      "Iteration 9267 => Loss: 50.54463893057411638665\n",
      "Iteration 9268 => Loss: 50.54444268773700343900\n",
      "Iteration 9269 => Loss: 50.54424644644004871452\n",
      "Iteration 9270 => Loss: 50.54405020668320247523\n",
      "Iteration 9271 => Loss: 50.54385396846645051028\n",
      "Iteration 9272 => Loss: 50.54365773178979992508\n",
      "Iteration 9273 => Loss: 50.54346149665321519251\n",
      "Iteration 9274 => Loss: 50.54326526305669631256\n",
      "Iteration 9275 => Loss: 50.54306903100026460152\n",
      "Iteration 9276 => Loss: 50.54287280048384189968\n",
      "Iteration 9277 => Loss: 50.54267657150745662875\n",
      "Iteration 9278 => Loss: 50.54248034407108747246\n",
      "Iteration 9279 => Loss: 50.54228411817473443080\n",
      "Iteration 9280 => Loss: 50.54208789381834066035\n",
      "Iteration 9281 => Loss: 50.54189167100199142624\n",
      "Iteration 9282 => Loss: 50.54169544972555883078\n",
      "Iteration 9283 => Loss: 50.54149922998909971739\n",
      "Iteration 9284 => Loss: 50.54130301179259987521\n",
      "Iteration 9285 => Loss: 50.54110679513601667168\n",
      "Iteration 9286 => Loss: 50.54091058001935721222\n",
      "Iteration 9287 => Loss: 50.54071436644261439142\n",
      "Iteration 9288 => Loss: 50.54051815440575268212\n",
      "Iteration 9289 => Loss: 50.54032194390879340062\n",
      "Iteration 9290 => Loss: 50.54012573495170101978\n",
      "Iteration 9291 => Loss: 50.53992952753445422331\n",
      "Iteration 9292 => Loss: 50.53973332165708853836\n",
      "Iteration 9293 => Loss: 50.53953711731953291064\n",
      "Iteration 9294 => Loss: 50.53934091452180865645\n",
      "Iteration 9295 => Loss: 50.53914471326388735406\n",
      "Iteration 9296 => Loss: 50.53894851354579742519\n",
      "Iteration 9297 => Loss: 50.53875231536745360472\n",
      "Iteration 9298 => Loss: 50.53855611872890563063\n",
      "Iteration 9299 => Loss: 50.53835992363011797579\n",
      "Iteration 9300 => Loss: 50.53816373007109064019\n",
      "Iteration 9301 => Loss: 50.53796753805178099128\n",
      "Iteration 9302 => Loss: 50.53777134757222455619\n",
      "Iteration 9303 => Loss: 50.53757515863237159692\n",
      "Iteration 9304 => Loss: 50.53737897123222921891\n",
      "Iteration 9305 => Loss: 50.53718278537175478959\n",
      "Iteration 9306 => Loss: 50.53698660105097673068\n",
      "Iteration 9307 => Loss: 50.53679041826985240959\n",
      "Iteration 9308 => Loss: 50.53659423702839603720\n",
      "Iteration 9309 => Loss: 50.53639805732657919179\n",
      "Iteration 9310 => Loss: 50.53620187916438055709\n",
      "Iteration 9311 => Loss: 50.53600570254181434393\n",
      "Iteration 9312 => Loss: 50.53580952745883791977\n",
      "Iteration 9313 => Loss: 50.53561335391547260087\n",
      "Iteration 9314 => Loss: 50.53541718191167575469\n",
      "Iteration 9315 => Loss: 50.53522101144744738122\n",
      "Iteration 9316 => Loss: 50.53502484252279458588\n",
      "Iteration 9317 => Loss: 50.53482867513767473611\n",
      "Iteration 9318 => Loss: 50.53463250929208783191\n",
      "Iteration 9319 => Loss: 50.53443634498602676786\n",
      "Iteration 9320 => Loss: 50.53424018221947022766\n",
      "Iteration 9321 => Loss: 50.53404402099240400048\n",
      "Iteration 9322 => Loss: 50.53384786130482098088\n",
      "Iteration 9323 => Loss: 50.53365170315672116885\n",
      "Iteration 9324 => Loss: 50.53345554654806193184\n",
      "Iteration 9325 => Loss: 50.53325939147887879699\n",
      "Iteration 9326 => Loss: 50.53306323794912202629\n",
      "Iteration 9327 => Loss: 50.53286708595877740891\n",
      "Iteration 9328 => Loss: 50.53267093550784494482\n",
      "Iteration 9329 => Loss: 50.53247478659632463405\n",
      "Iteration 9330 => Loss: 50.53227863922418094944\n",
      "Iteration 9331 => Loss: 50.53208249339142099643\n",
      "Iteration 9332 => Loss: 50.53188634909803056416\n",
      "Iteration 9333 => Loss: 50.53169020634398833636\n",
      "Iteration 9334 => Loss: 50.53149406512923746959\n",
      "Iteration 9335 => Loss: 50.53129792545387743985\n",
      "Iteration 9336 => Loss: 50.53110178731781587658\n",
      "Iteration 9337 => Loss: 50.53090565072103146349\n",
      "Iteration 9338 => Loss: 50.53070951566356683315\n",
      "Iteration 9339 => Loss: 50.53051338214535803672\n",
      "Iteration 9340 => Loss: 50.53031725016644060133\n",
      "Iteration 9341 => Loss: 50.53012111972676478899\n",
      "Iteration 9342 => Loss: 50.52992499082631638885\n",
      "Iteration 9343 => Loss: 50.52972886346510961175\n",
      "Iteration 9344 => Loss: 50.52953273764314445771\n",
      "Iteration 9345 => Loss: 50.52933661336034276701\n",
      "Iteration 9346 => Loss: 50.52914049061675427765\n",
      "Iteration 9347 => Loss: 50.52894436941235056793\n",
      "Iteration 9348 => Loss: 50.52874824974711742698\n",
      "Iteration 9349 => Loss: 50.52855213162100511681\n",
      "Iteration 9350 => Loss: 50.52835601503409179713\n",
      "Iteration 9351 => Loss: 50.52815989998628509738\n",
      "Iteration 9352 => Loss: 50.52796378647757791214\n",
      "Iteration 9353 => Loss: 50.52776767450801287396\n",
      "Iteration 9354 => Loss: 50.52757156407752603400\n",
      "Iteration 9355 => Loss: 50.52737545518614581397\n",
      "Iteration 9356 => Loss: 50.52717934783381537045\n",
      "Iteration 9357 => Loss: 50.52698324202055601972\n",
      "Iteration 9358 => Loss: 50.52678713774632512923\n",
      "Iteration 9359 => Loss: 50.52659103501115822610\n",
      "Iteration 9360 => Loss: 50.52639493381499136149\n",
      "Iteration 9361 => Loss: 50.52619883415785295711\n",
      "Iteration 9362 => Loss: 50.52600273603971459124\n",
      "Iteration 9363 => Loss: 50.52580663946054784219\n",
      "Iteration 9364 => Loss: 50.52561054442035981538\n",
      "Iteration 9365 => Loss: 50.52541445091914340537\n",
      "Iteration 9366 => Loss: 50.52521835895687729590\n",
      "Iteration 9367 => Loss: 50.52502226853354017067\n",
      "Iteration 9368 => Loss: 50.52482617964913913511\n",
      "Iteration 9369 => Loss: 50.52463009230364576752\n",
      "Iteration 9370 => Loss: 50.52443400649706006789\n",
      "Iteration 9371 => Loss: 50.52423792222936071994\n",
      "Iteration 9372 => Loss: 50.52404183950054772367\n",
      "Iteration 9373 => Loss: 50.52384575831057844653\n",
      "Iteration 9374 => Loss: 50.52364967865949552106\n",
      "Iteration 9375 => Loss: 50.52345360054723499843\n",
      "Iteration 9376 => Loss: 50.52325752397381819492\n",
      "Iteration 9377 => Loss: 50.52306144893920247796\n",
      "Iteration 9378 => Loss: 50.52286537544339495298\n",
      "Iteration 9379 => Loss: 50.52266930348638140913\n",
      "Iteration 9380 => Loss: 50.52247323306816184640\n",
      "Iteration 9381 => Loss: 50.52227716418870073767\n",
      "Iteration 9382 => Loss: 50.52208109684798387207\n",
      "Iteration 9383 => Loss: 50.52188503104602546045\n",
      "Iteration 9384 => Loss: 50.52168896678280418655\n",
      "Iteration 9385 => Loss: 50.52149290405830583950\n",
      "Iteration 9386 => Loss: 50.52129684287250199759\n",
      "Iteration 9387 => Loss: 50.52110078322541397711\n",
      "Iteration 9388 => Loss: 50.52090472511697782920\n",
      "Iteration 9389 => Loss: 50.52070866854723618644\n",
      "Iteration 9390 => Loss: 50.52051261351614641626\n",
      "Iteration 9391 => Loss: 50.52031656002372272951\n",
      "Iteration 9392 => Loss: 50.52012050806992249363\n",
      "Iteration 9393 => Loss: 50.51992445765473860320\n",
      "Iteration 9394 => Loss: 50.51972840877817105820\n",
      "Iteration 9395 => Loss: 50.51953236144021275322\n",
      "Iteration 9396 => Loss: 50.51933631564083526655\n",
      "Iteration 9397 => Loss: 50.51914027138002438733\n",
      "Iteration 9398 => Loss: 50.51894422865778011555\n",
      "Iteration 9399 => Loss: 50.51874818747410955666\n",
      "Iteration 9400 => Loss: 50.51855214782896297265\n",
      "Iteration 9401 => Loss: 50.51835610972232615268\n",
      "Iteration 9402 => Loss: 50.51816007315422751844\n",
      "Iteration 9403 => Loss: 50.51796403812461022653\n",
      "Iteration 9404 => Loss: 50.51776800463350269865\n",
      "Iteration 9405 => Loss: 50.51757197268086940767\n",
      "Iteration 9406 => Loss: 50.51737594226668193187\n",
      "Iteration 9407 => Loss: 50.51717991339096869297\n",
      "Iteration 9408 => Loss: 50.51698388605369416382\n",
      "Iteration 9409 => Loss: 50.51678786025485123901\n",
      "Iteration 9410 => Loss: 50.51659183599443991852\n",
      "Iteration 9411 => Loss: 50.51639581327241046438\n",
      "Iteration 9412 => Loss: 50.51619979208878419286\n",
      "Iteration 9413 => Loss: 50.51600377244352557682\n",
      "Iteration 9414 => Loss: 50.51580775433665593255\n",
      "Iteration 9415 => Loss: 50.51561173776812552205\n",
      "Iteration 9416 => Loss: 50.51541572273796276704\n",
      "Iteration 9417 => Loss: 50.51521970924612503495\n",
      "Iteration 9418 => Loss: 50.51502369729261232578\n",
      "Iteration 9419 => Loss: 50.51482768687739621782\n",
      "Iteration 9420 => Loss: 50.51463167800047671108\n",
      "Iteration 9421 => Loss: 50.51443567066183959469\n",
      "Iteration 9422 => Loss: 50.51423966486148486865\n",
      "Iteration 9423 => Loss: 50.51404366059939121669\n",
      "Iteration 9424 => Loss: 50.51384765787552311167\n",
      "Iteration 9425 => Loss: 50.51365165668991608072\n",
      "Iteration 9426 => Loss: 50.51345565704252749128\n",
      "Iteration 9427 => Loss: 50.51325965893335734336\n",
      "Iteration 9428 => Loss: 50.51306366236236300438\n",
      "Iteration 9429 => Loss: 50.51286766732957289605\n",
      "Iteration 9430 => Loss: 50.51267167383497280753\n",
      "Iteration 9431 => Loss: 50.51247568187851300081\n",
      "Iteration 9432 => Loss: 50.51227969146022189761\n",
      "Iteration 9433 => Loss: 50.51208370258004265452\n",
      "Iteration 9434 => Loss: 50.51188771523803211494\n",
      "Iteration 9435 => Loss: 50.51169172943409790832\n",
      "Iteration 9436 => Loss: 50.51149574516829687809\n",
      "Iteration 9437 => Loss: 50.51129976244055796997\n",
      "Iteration 9438 => Loss: 50.51110378125093092194\n",
      "Iteration 9439 => Loss: 50.51090780159933046889\n",
      "Iteration 9440 => Loss: 50.51071182348579924337\n",
      "Iteration 9441 => Loss: 50.51051584691033013996\n",
      "Iteration 9442 => Loss: 50.51031987187288763153\n",
      "Iteration 9443 => Loss: 50.51012389837343619092\n",
      "Iteration 9444 => Loss: 50.50992792641202555615\n",
      "Iteration 9445 => Loss: 50.50973195598858467292\n",
      "Iteration 9446 => Loss: 50.50953598710312064668\n",
      "Iteration 9447 => Loss: 50.50934001975564058284\n",
      "Iteration 9448 => Loss: 50.50914405394613027056\n",
      "Iteration 9449 => Loss: 50.50894808967454707727\n",
      "Iteration 9450 => Loss: 50.50875212694090521381\n",
      "Iteration 9451 => Loss: 50.50855616574516204764\n",
      "Iteration 9452 => Loss: 50.50836020608734600046\n",
      "Iteration 9453 => Loss: 50.50816424796743575598\n",
      "Iteration 9454 => Loss: 50.50796829138541710336\n",
      "Iteration 9455 => Loss: 50.50777233634125451545\n",
      "Iteration 9456 => Loss: 50.50757638283494799225\n",
      "Iteration 9457 => Loss: 50.50738043086647621749\n",
      "Iteration 9458 => Loss: 50.50718448043588182372\n",
      "Iteration 9459 => Loss: 50.50698853154307954583\n",
      "Iteration 9460 => Loss: 50.50679258418811912179\n",
      "Iteration 9461 => Loss: 50.50659663837092239191\n",
      "Iteration 9462 => Loss: 50.50640069409153909419\n",
      "Iteration 9463 => Loss: 50.50620475134994080690\n",
      "Iteration 9464 => Loss: 50.50600881014606358121\n",
      "Iteration 9465 => Loss: 50.50581287047996426054\n",
      "Iteration 9466 => Loss: 50.50561693235163573945\n",
      "Iteration 9467 => Loss: 50.50542099576099985825\n",
      "Iteration 9468 => Loss: 50.50522506070809214407\n",
      "Iteration 9469 => Loss: 50.50502912719287706977\n",
      "Iteration 9470 => Loss: 50.50483319521536174079\n",
      "Iteration 9471 => Loss: 50.50463726477551773542\n",
      "Iteration 9472 => Loss: 50.50444133587333794821\n",
      "Iteration 9473 => Loss: 50.50424540850880816834\n",
      "Iteration 9474 => Loss: 50.50404948268193550120\n",
      "Iteration 9475 => Loss: 50.50385355839271284140\n",
      "Iteration 9476 => Loss: 50.50365763564107624006\n",
      "Iteration 9477 => Loss: 50.50346171442706832977\n",
      "Iteration 9478 => Loss: 50.50326579475064647795\n",
      "Iteration 9479 => Loss: 50.50306987661180357918\n",
      "Iteration 9480 => Loss: 50.50287396001051831718\n",
      "Iteration 9481 => Loss: 50.50267804494682621907\n",
      "Iteration 9482 => Loss: 50.50248213142064912518\n",
      "Iteration 9483 => Loss: 50.50228621943201545719\n",
      "Iteration 9484 => Loss: 50.50209030898088968797\n",
      "Iteration 9485 => Loss: 50.50189440006730734467\n",
      "Iteration 9486 => Loss: 50.50169849269119737301\n",
      "Iteration 9487 => Loss: 50.50150258685258108926\n",
      "Iteration 9488 => Loss: 50.50130668255143717715\n",
      "Iteration 9489 => Loss: 50.50111077978774432040\n",
      "Iteration 9490 => Loss: 50.50091487856153094071\n",
      "Iteration 9491 => Loss: 50.50071897887274019467\n",
      "Iteration 9492 => Loss: 50.50052308072135787143\n",
      "Iteration 9493 => Loss: 50.50032718410739107640\n",
      "Iteration 9494 => Loss: 50.50013128903084691501\n",
      "Iteration 9495 => Loss: 50.49993539549166854385\n",
      "Iteration 9496 => Loss: 50.49973950348986306835\n",
      "Iteration 9497 => Loss: 50.49954361302546601564\n",
      "Iteration 9498 => Loss: 50.49934772409838501517\n",
      "Iteration 9499 => Loss: 50.49915183670864138321\n",
      "Iteration 9500 => Loss: 50.49895595085624933063\n",
      "Iteration 9501 => Loss: 50.49876006654114490857\n",
      "Iteration 9502 => Loss: 50.49856418376337074960\n",
      "Iteration 9503 => Loss: 50.49836830252287001031\n",
      "Iteration 9504 => Loss: 50.49817242281965690154\n",
      "Iteration 9505 => Loss: 50.49797654465371721244\n",
      "Iteration 9506 => Loss: 50.49778066802504383759\n",
      "Iteration 9507 => Loss: 50.49758479293358703899\n",
      "Iteration 9508 => Loss: 50.49738891937938944920\n",
      "Iteration 9509 => Loss: 50.49719304736237290854\n",
      "Iteration 9510 => Loss: 50.49699717688258715498\n",
      "Iteration 9511 => Loss: 50.49680130793998955596\n",
      "Iteration 9512 => Loss: 50.49660544053460853320\n",
      "Iteration 9513 => Loss: 50.49640957466635171613\n",
      "Iteration 9514 => Loss: 50.49621371033529015904\n",
      "Iteration 9515 => Loss: 50.49601784754135280764\n",
      "Iteration 9516 => Loss: 50.49582198628456808365\n",
      "Iteration 9517 => Loss: 50.49562612656487914364\n",
      "Iteration 9518 => Loss: 50.49543026838232862019\n",
      "Iteration 9519 => Loss: 50.49523441173685256445\n",
      "Iteration 9520 => Loss: 50.49503855662847229269\n",
      "Iteration 9521 => Loss: 50.49484270305716648863\n",
      "Iteration 9522 => Loss: 50.49464685102293515229\n",
      "Iteration 9523 => Loss: 50.49445100052573565108\n",
      "Iteration 9524 => Loss: 50.49425515156557509044\n",
      "Iteration 9525 => Loss: 50.49405930414246057580\n",
      "Iteration 9526 => Loss: 50.49386345825636368545\n",
      "Iteration 9527 => Loss: 50.49366761390724178682\n",
      "Iteration 9528 => Loss: 50.49347177109511619619\n",
      "Iteration 9529 => Loss: 50.49327592981997980814\n",
      "Iteration 9530 => Loss: 50.49308009008180420096\n",
      "Iteration 9531 => Loss: 50.49288425188058226922\n",
      "Iteration 9532 => Loss: 50.49268841521629980207\n",
      "Iteration 9533 => Loss: 50.49249258008894258865\n",
      "Iteration 9534 => Loss: 50.49229674649850352353\n",
      "Iteration 9535 => Loss: 50.49210091444496839586\n",
      "Iteration 9536 => Loss: 50.49190508392834431106\n",
      "Iteration 9537 => Loss: 50.49170925494857442573\n",
      "Iteration 9538 => Loss: 50.49151342750570137241\n",
      "Iteration 9539 => Loss: 50.49131760159966120227\n",
      "Iteration 9540 => Loss: 50.49112177723046812616\n",
      "Iteration 9541 => Loss: 50.49092595439811503866\n",
      "Iteration 9542 => Loss: 50.49073013310257351804\n",
      "Iteration 9543 => Loss: 50.49053431334387198604\n",
      "Iteration 9544 => Loss: 50.49033849512192517750\n",
      "Iteration 9545 => Loss: 50.49014267843676861958\n",
      "Iteration 9546 => Loss: 50.48994686328840941769\n",
      "Iteration 9547 => Loss: 50.48975104967680493928\n",
      "Iteration 9548 => Loss: 50.48955523760192676264\n",
      "Iteration 9549 => Loss: 50.48935942706379620404\n",
      "Iteration 9550 => Loss: 50.48916361806239905263\n",
      "Iteration 9551 => Loss: 50.48896781059771399214\n",
      "Iteration 9552 => Loss: 50.48877200466968417913\n",
      "Iteration 9553 => Loss: 50.48857620027838777332\n",
      "Iteration 9554 => Loss: 50.48838039742378924757\n",
      "Iteration 9555 => Loss: 50.48818459610581754760\n",
      "Iteration 9556 => Loss: 50.48798879632448688426\n",
      "Iteration 9557 => Loss: 50.48779299807981857384\n",
      "Iteration 9558 => Loss: 50.48759720137177708921\n",
      "Iteration 9559 => Loss: 50.48740140620031269236\n",
      "Iteration 9560 => Loss: 50.48720561256548222673\n",
      "Iteration 9561 => Loss: 50.48700982046724305974\n",
      "Iteration 9562 => Loss: 50.48681402990558808597\n",
      "Iteration 9563 => Loss: 50.48661824088047467285\n",
      "Iteration 9564 => Loss: 50.48642245339195255838\n",
      "Iteration 9565 => Loss: 50.48622666743994358285\n",
      "Iteration 9566 => Loss: 50.48603088302448327340\n",
      "Iteration 9567 => Loss: 50.48583510014553610290\n",
      "Iteration 9568 => Loss: 50.48563931880309496592\n",
      "Iteration 9569 => Loss: 50.48544353899713854616\n",
      "Iteration 9570 => Loss: 50.48524776072766684365\n",
      "Iteration 9571 => Loss: 50.48505198399467275294\n",
      "Iteration 9572 => Loss: 50.48485620879813495776\n",
      "Iteration 9573 => Loss: 50.48466043513802503639\n",
      "Iteration 9574 => Loss: 50.48446466301438562141\n",
      "Iteration 9575 => Loss: 50.48426889242713144768\n",
      "Iteration 9576 => Loss: 50.48407312337631935861\n",
      "Iteration 9577 => Loss: 50.48387735586186408909\n",
      "Iteration 9578 => Loss: 50.48368158988382248253\n",
      "Iteration 9579 => Loss: 50.48348582544215190637\n",
      "Iteration 9580 => Loss: 50.48329006253681683347\n",
      "Iteration 9581 => Loss: 50.48309430116785989640\n",
      "Iteration 9582 => Loss: 50.48289854133523135715\n",
      "Iteration 9583 => Loss: 50.48270278303893832117\n",
      "Iteration 9584 => Loss: 50.48250702627894526131\n",
      "Iteration 9585 => Loss: 50.48231127105525928300\n",
      "Iteration 9586 => Loss: 50.48211551736784485911\n",
      "Iteration 9587 => Loss: 50.48191976521673751677\n",
      "Iteration 9588 => Loss: 50.48172401460188751798\n",
      "Iteration 9589 => Loss: 50.48152826552328065191\n",
      "Iteration 9590 => Loss: 50.48133251798091691853\n",
      "Iteration 9591 => Loss: 50.48113677197476079073\n",
      "Iteration 9592 => Loss: 50.48094102750484779563\n",
      "Iteration 9593 => Loss: 50.48074528457112108981\n",
      "Iteration 9594 => Loss: 50.48054954317360198957\n",
      "Iteration 9595 => Loss: 50.48035380331224786232\n",
      "Iteration 9596 => Loss: 50.48015806498707291894\n",
      "Iteration 9597 => Loss: 50.47996232819807005399\n",
      "Iteration 9598 => Loss: 50.47976659294518242405\n",
      "Iteration 9599 => Loss: 50.47957085922842423997\n",
      "Iteration 9600 => Loss: 50.47937512704780971262\n",
      "Iteration 9601 => Loss: 50.47917939640328199857\n",
      "Iteration 9602 => Loss: 50.47898366729485530868\n",
      "Iteration 9603 => Loss: 50.47878793972251543209\n",
      "Iteration 9604 => Loss: 50.47859221368624815796\n",
      "Iteration 9605 => Loss: 50.47839648918603927541\n",
      "Iteration 9606 => Loss: 50.47820076622187457360\n",
      "Iteration 9607 => Loss: 50.47800504479374694711\n",
      "Iteration 9608 => Loss: 50.47780932490163507964\n",
      "Iteration 9609 => Loss: 50.47761360654554607663\n",
      "Iteration 9610 => Loss: 50.47741788972545151637\n",
      "Iteration 9611 => Loss: 50.47722217444134429343\n",
      "Iteration 9612 => Loss: 50.47702646069320309152\n",
      "Iteration 9613 => Loss: 50.47683074848102791066\n",
      "Iteration 9614 => Loss: 50.47663503780480453997\n",
      "Iteration 9615 => Loss: 50.47643932866451876862\n",
      "Iteration 9616 => Loss: 50.47624362106016349117\n",
      "Iteration 9617 => Loss: 50.47604791499171028590\n",
      "Iteration 9618 => Loss: 50.47585221045918046912\n",
      "Iteration 9619 => Loss: 50.47565650746253140824\n",
      "Iteration 9620 => Loss: 50.47546080600173468156\n",
      "Iteration 9621 => Loss: 50.47526510607684713250\n",
      "Iteration 9622 => Loss: 50.47506940768779770679\n",
      "Iteration 9623 => Loss: 50.47487371083460061527\n",
      "Iteration 9624 => Loss: 50.47467801551720611997\n",
      "Iteration 9625 => Loss: 50.47448232173562843172\n",
      "Iteration 9626 => Loss: 50.47428662948986044512\n",
      "Iteration 9627 => Loss: 50.47409093877990926558\n",
      "Iteration 9628 => Loss: 50.47389524960571804968\n",
      "Iteration 9629 => Loss: 50.47369956196729390285\n",
      "Iteration 9630 => Loss: 50.47350387586462971967\n",
      "Iteration 9631 => Loss: 50.47330819129773260556\n",
      "Iteration 9632 => Loss: 50.47311250826655282253\n",
      "Iteration 9633 => Loss: 50.47291682677111879229\n",
      "Iteration 9634 => Loss: 50.47272114681133814429\n",
      "Iteration 9635 => Loss: 50.47252546838729614365\n",
      "Iteration 9636 => Loss: 50.47232979149892884152\n",
      "Iteration 9637 => Loss: 50.47213411614620781620\n",
      "Iteration 9638 => Loss: 50.47193844232917570025\n",
      "Iteration 9639 => Loss: 50.47174277004779696654\n",
      "Iteration 9640 => Loss: 50.47154709930205740420\n",
      "Iteration 9641 => Loss: 50.47135143009192859154\n",
      "Iteration 9642 => Loss: 50.47115576241740342311\n",
      "Iteration 9643 => Loss: 50.47096009627850321522\n",
      "Iteration 9644 => Loss: 50.47076443167515691357\n",
      "Iteration 9645 => Loss: 50.47056876860741425617\n",
      "Iteration 9646 => Loss: 50.47037310707522550501\n",
      "Iteration 9647 => Loss: 50.47017744707858355468\n",
      "Iteration 9648 => Loss: 50.46998178861750261603\n",
      "Iteration 9649 => Loss: 50.46978613169193295107\n",
      "Iteration 9650 => Loss: 50.46959047630188166522\n",
      "Iteration 9651 => Loss: 50.46939482244732033678\n",
      "Iteration 9652 => Loss: 50.46919917012827028202\n",
      "Iteration 9653 => Loss: 50.46900351934468886839\n",
      "Iteration 9654 => Loss: 50.46880787009657609588\n",
      "Iteration 9655 => Loss: 50.46861222238393196449\n",
      "Iteration 9656 => Loss: 50.46841657620672805251\n",
      "Iteration 9657 => Loss: 50.46822093156493593824\n",
      "Iteration 9658 => Loss: 50.46802528845857693796\n",
      "Iteration 9659 => Loss: 50.46782964688762262995\n",
      "Iteration 9660 => Loss: 50.46763400685208011964\n",
      "Iteration 9661 => Loss: 50.46743836835189256362\n",
      "Iteration 9662 => Loss: 50.46724273138708127817\n",
      "Iteration 9663 => Loss: 50.46704709595764626329\n",
      "Iteration 9664 => Loss: 50.46685146206353778098\n",
      "Iteration 9665 => Loss: 50.46665582970478425295\n",
      "Iteration 9666 => Loss: 50.46646019888134304665\n",
      "Iteration 9667 => Loss: 50.46626456959319284579\n",
      "Iteration 9668 => Loss: 50.46606894184038338835\n",
      "Iteration 9669 => Loss: 50.46587331562282940922\n",
      "Iteration 9670 => Loss: 50.46567769094054511925\n",
      "Iteration 9671 => Loss: 50.46548206779353051843\n",
      "Iteration 9672 => Loss: 50.46528644618176429049\n",
      "Iteration 9673 => Loss: 50.46509082610523932999\n",
      "Iteration 9674 => Loss: 50.46489520756395563694\n",
      "Iteration 9675 => Loss: 50.46469959055787057878\n",
      "Iteration 9676 => Loss: 50.46450397508698415550\n",
      "Iteration 9677 => Loss: 50.46430836115130347252\n",
      "Iteration 9678 => Loss: 50.46411274875077879187\n",
      "Iteration 9679 => Loss: 50.46391713788543142982\n",
      "Iteration 9680 => Loss: 50.46372152855523296466\n",
      "Iteration 9681 => Loss: 50.46352592076018339640\n",
      "Iteration 9682 => Loss: 50.46333031450025430331\n",
      "Iteration 9683 => Loss: 50.46313470977546700169\n",
      "Iteration 9684 => Loss: 50.46293910658574333183\n",
      "Iteration 9685 => Loss: 50.46274350493113303173\n",
      "Iteration 9686 => Loss: 50.46254790481160057425\n",
      "Iteration 9687 => Loss: 50.46235230622716727567\n",
      "Iteration 9688 => Loss: 50.46215670917776208171\n",
      "Iteration 9689 => Loss: 50.46196111366339920323\n",
      "Iteration 9690 => Loss: 50.46176551968406442938\n",
      "Iteration 9691 => Loss: 50.46156992723977907644\n",
      "Iteration 9692 => Loss: 50.46137433633047209014\n",
      "Iteration 9693 => Loss: 50.46117874695617899761\n",
      "Iteration 9694 => Loss: 50.46098315911687137714\n",
      "Iteration 9695 => Loss: 50.46078757281253501787\n",
      "Iteration 9696 => Loss: 50.46059198804315570897\n",
      "Iteration 9697 => Loss: 50.46039640480872634498\n",
      "Iteration 9698 => Loss: 50.46020082310921850421\n",
      "Iteration 9699 => Loss: 50.46000524294463929209\n",
      "Iteration 9700 => Loss: 50.45980966431498870861\n",
      "Iteration 9701 => Loss: 50.45961408722022412121\n",
      "Iteration 9702 => Loss: 50.45941851166036684617\n",
      "Iteration 9703 => Loss: 50.45922293763537425093\n",
      "Iteration 9704 => Loss: 50.45902736514522501921\n",
      "Iteration 9705 => Loss: 50.45883179418996178356\n",
      "Iteration 9706 => Loss: 50.45863622476951348972\n",
      "Iteration 9707 => Loss: 50.45844065688388724311\n",
      "Iteration 9708 => Loss: 50.45824509053311146545\n",
      "Iteration 9709 => Loss: 50.45804952571710799702\n",
      "Iteration 9710 => Loss: 50.45785396243591236498\n",
      "Iteration 9711 => Loss: 50.45765840068947483132\n",
      "Iteration 9712 => Loss: 50.45746284047783092319\n",
      "Iteration 9713 => Loss: 50.45726728180093800802\n",
      "Iteration 9714 => Loss: 50.45707172465877476952\n",
      "Iteration 9715 => Loss: 50.45687616905134831313\n",
      "Iteration 9716 => Loss: 50.45668061497865153342\n",
      "Iteration 9717 => Loss: 50.45648506244063469239\n",
      "Iteration 9718 => Loss: 50.45628951143732621176\n",
      "Iteration 9719 => Loss: 50.45609396196872609153\n",
      "Iteration 9720 => Loss: 50.45589841403478459370\n",
      "Iteration 9721 => Loss: 50.45570286763547329656\n",
      "Iteration 9722 => Loss: 50.45550732277082772725\n",
      "Iteration 9723 => Loss: 50.45531177944084078035\n",
      "Iteration 9724 => Loss: 50.45511623764542719073\n",
      "Iteration 9725 => Loss: 50.45492069738467932893\n",
      "Iteration 9726 => Loss: 50.45472515865849061356\n",
      "Iteration 9727 => Loss: 50.45452962146689657175\n",
      "Iteration 9728 => Loss: 50.45433408580987588721\n",
      "Iteration 9729 => Loss: 50.45413855168741434909\n",
      "Iteration 9730 => Loss: 50.45394301909951906282\n",
      "Iteration 9731 => Loss: 50.45374748804614029041\n",
      "Iteration 9732 => Loss: 50.45355195852732776984\n",
      "Iteration 9733 => Loss: 50.45335643054298202514\n",
      "Iteration 9734 => Loss: 50.45316090409315279430\n",
      "Iteration 9735 => Loss: 50.45296537917781876104\n",
      "Iteration 9736 => Loss: 50.45276985579697281992\n",
      "Iteration 9737 => Loss: 50.45257433395056523295\n",
      "Iteration 9738 => Loss: 50.45237881363863152728\n",
      "Iteration 9739 => Loss: 50.45218329486114328120\n",
      "Iteration 9740 => Loss: 50.45198777761809338926\n",
      "Iteration 9741 => Loss: 50.45179226190942500807\n",
      "Iteration 9742 => Loss: 50.45159674773518077018\n",
      "Iteration 9743 => Loss: 50.45140123509532514845\n",
      "Iteration 9744 => Loss: 50.45120572398985814289\n",
      "Iteration 9745 => Loss: 50.45101021441877975349\n",
      "Iteration 9746 => Loss: 50.45081470638202603141\n",
      "Iteration 9747 => Loss: 50.45061919987964671463\n",
      "Iteration 9748 => Loss: 50.45042369491157074890\n",
      "Iteration 9749 => Loss: 50.45022819147784076677\n",
      "Iteration 9750 => Loss: 50.45003268957837860853\n",
      "Iteration 9751 => Loss: 50.44983718921324822304\n",
      "Iteration 9752 => Loss: 50.44964169038240697773\n",
      "Iteration 9753 => Loss: 50.44944619308582645090\n",
      "Iteration 9754 => Loss: 50.44925069732351374796\n",
      "Iteration 9755 => Loss: 50.44905520309544755264\n",
      "Iteration 9756 => Loss: 50.44885971040160654866\n",
      "Iteration 9757 => Loss: 50.44866421924200494686\n",
      "Iteration 9758 => Loss: 50.44846872961661432555\n",
      "Iteration 9759 => Loss: 50.44827324152542047386\n",
      "Iteration 9760 => Loss: 50.44807775496842339180\n",
      "Iteration 9761 => Loss: 50.44788226994558755223\n",
      "Iteration 9762 => Loss: 50.44768678645690584972\n",
      "Iteration 9763 => Loss: 50.44749130450237828427\n",
      "Iteration 9764 => Loss: 50.44729582408201196131\n",
      "Iteration 9765 => Loss: 50.44710034519577135370\n",
      "Iteration 9766 => Loss: 50.44690486784363514516\n",
      "Iteration 9767 => Loss: 50.44670939202562465198\n",
      "Iteration 9768 => Loss: 50.44651391774169724158\n",
      "Iteration 9769 => Loss: 50.44631844499183159769\n",
      "Iteration 9770 => Loss: 50.44612297377606324744\n",
      "Iteration 9771 => Loss: 50.44592750409431403114\n",
      "Iteration 9772 => Loss: 50.44573203594663368676\n",
      "Iteration 9773 => Loss: 50.44553656933297247633\n",
      "Iteration 9774 => Loss: 50.44534110425335171612\n",
      "Iteration 9775 => Loss: 50.44514564070770035187\n",
      "Iteration 9776 => Loss: 50.44495017869608233241\n",
      "Iteration 9777 => Loss: 50.44475471821842660347\n",
      "Iteration 9778 => Loss: 50.44455925927476869219\n",
      "Iteration 9779 => Loss: 50.44436380186504464973\n",
      "Iteration 9780 => Loss: 50.44416834598926868694\n",
      "Iteration 9781 => Loss: 50.44397289164744790924\n",
      "Iteration 9782 => Loss: 50.44377743883953257864\n",
      "Iteration 9783 => Loss: 50.44358198756553690600\n",
      "Iteration 9784 => Loss: 50.44338653782543246962\n",
      "Iteration 9785 => Loss: 50.44319108961921216405\n",
      "Iteration 9786 => Loss: 50.44299564294686177846\n",
      "Iteration 9787 => Loss: 50.44280019780838841825\n",
      "Iteration 9788 => Loss: 50.44260475420378497802\n",
      "Iteration 9789 => Loss: 50.44240931213299461433\n",
      "Iteration 9790 => Loss: 50.44221387159601732719\n",
      "Iteration 9791 => Loss: 50.44201843259288153831\n",
      "Iteration 9792 => Loss: 50.44182299512353750970\n",
      "Iteration 9793 => Loss: 50.44162755918799234678\n",
      "Iteration 9794 => Loss: 50.44143212478621762784\n",
      "Iteration 9795 => Loss: 50.44123669191820624746\n",
      "Iteration 9796 => Loss: 50.44104126058394399479\n",
      "Iteration 9797 => Loss: 50.44084583078344508067\n",
      "Iteration 9798 => Loss: 50.44065040251665976712\n",
      "Iteration 9799 => Loss: 50.44045497578359515956\n",
      "Iteration 9800 => Loss: 50.44025955058423704713\n",
      "Iteration 9801 => Loss: 50.44006412691857121899\n",
      "Iteration 9802 => Loss: 50.43986870478659056971\n",
      "Iteration 9803 => Loss: 50.43967328418830220471\n",
      "Iteration 9804 => Loss: 50.43947786512364928058\n",
      "Iteration 9805 => Loss: 50.43928244759264600816\n",
      "Iteration 9806 => Loss: 50.43908703159527107118\n",
      "Iteration 9807 => Loss: 50.43889161713151025879\n",
      "Iteration 9808 => Loss: 50.43869620420139199268\n",
      "Iteration 9809 => Loss: 50.43850079280483100774\n",
      "Iteration 9810 => Loss: 50.43830538294186283110\n",
      "Iteration 9811 => Loss: 50.43810997461247325191\n",
      "Iteration 9812 => Loss: 50.43791456781666227016\n",
      "Iteration 9813 => Loss: 50.43771916255440146415\n",
      "Iteration 9814 => Loss: 50.43752375882564820131\n",
      "Iteration 9815 => Loss: 50.43732835663045221963\n",
      "Iteration 9816 => Loss: 50.43713295596874957027\n",
      "Iteration 9817 => Loss: 50.43693755684057578037\n",
      "Iteration 9818 => Loss: 50.43674215924586690107\n",
      "Iteration 9819 => Loss: 50.43654676318461582696\n",
      "Iteration 9820 => Loss: 50.43635136865687229601\n",
      "Iteration 9821 => Loss: 50.43615597566255104311\n",
      "Iteration 9822 => Loss: 50.43596058420169470082\n",
      "Iteration 9823 => Loss: 50.43576519427425353115\n",
      "Iteration 9824 => Loss: 50.43556980588022753409\n",
      "Iteration 9825 => Loss: 50.43537441901961670965\n",
      "Iteration 9826 => Loss: 50.43517903369239974154\n",
      "Iteration 9827 => Loss: 50.43498364989854110263\n",
      "Iteration 9828 => Loss: 50.43478826763807632005\n",
      "Iteration 9829 => Loss: 50.43459288691094855039\n",
      "Iteration 9830 => Loss: 50.43439750771716489908\n",
      "Iteration 9831 => Loss: 50.43420213005673957696\n",
      "Iteration 9832 => Loss: 50.43400675392962995147\n",
      "Iteration 9833 => Loss: 50.43381137933578628463\n",
      "Iteration 9834 => Loss: 50.43361600627529384155\n",
      "Iteration 9835 => Loss: 50.43342063474806025170\n",
      "Iteration 9836 => Loss: 50.43322526475410683133\n",
      "Iteration 9837 => Loss: 50.43302989629339094790\n",
      "Iteration 9838 => Loss: 50.43283452936594812854\n",
      "Iteration 9839 => Loss: 50.43263916397172863526\n",
      "Iteration 9840 => Loss: 50.43244380011073957348\n",
      "Iteration 9841 => Loss: 50.43224843778296673236\n",
      "Iteration 9842 => Loss: 50.43205307698840300645\n",
      "Iteration 9843 => Loss: 50.43185771772701286864\n",
      "Iteration 9844 => Loss: 50.43166235999879631891\n",
      "Iteration 9845 => Loss: 50.43146700380373914641\n",
      "Iteration 9846 => Loss: 50.43127164914183424571\n",
      "Iteration 9847 => Loss: 50.43107629601309582767\n",
      "Iteration 9848 => Loss: 50.43088094441745283802\n",
      "Iteration 9849 => Loss: 50.43068559435494080390\n",
      "Iteration 9850 => Loss: 50.43049024582553130358\n",
      "Iteration 9851 => Loss: 50.43029489882921012622\n",
      "Iteration 9852 => Loss: 50.43009955336597016640\n",
      "Iteration 9853 => Loss: 50.42990420943579010782\n",
      "Iteration 9854 => Loss: 50.42970886703869837220\n",
      "Iteration 9855 => Loss: 50.42951352617460258898\n",
      "Iteration 9856 => Loss: 50.42931818684358091787\n",
      "Iteration 9857 => Loss: 50.42912284904554098830\n",
      "Iteration 9858 => Loss: 50.42892751278053253827\n",
      "Iteration 9859 => Loss: 50.42873217804851293522\n",
      "Iteration 9860 => Loss: 50.42853684484948217914\n",
      "Iteration 9861 => Loss: 50.42834151318340474290\n",
      "Iteration 9862 => Loss: 50.42814618305029483736\n",
      "Iteration 9863 => Loss: 50.42795085445013825165\n",
      "Iteration 9864 => Loss: 50.42775552738292788035\n",
      "Iteration 9865 => Loss: 50.42756020184861398548\n",
      "Iteration 9866 => Loss: 50.42736487784722498873\n",
      "Iteration 9867 => Loss: 50.42716955537873957383\n",
      "Iteration 9868 => Loss: 50.42697423444314352992\n",
      "Iteration 9869 => Loss: 50.42677891504040843529\n",
      "Iteration 9870 => Loss: 50.42658359717054139537\n",
      "Iteration 9871 => Loss: 50.42638828083352819931\n",
      "Iteration 9872 => Loss: 50.42619296602934042539\n",
      "Iteration 9873 => Loss: 50.42599765275799938991\n",
      "Iteration 9874 => Loss: 50.42580234101946956571\n",
      "Iteration 9875 => Loss: 50.42560703081373674195\n",
      "Iteration 9876 => Loss: 50.42541172214079381320\n",
      "Iteration 9877 => Loss: 50.42521641500063367403\n",
      "Iteration 9878 => Loss: 50.42502110939321369187\n",
      "Iteration 9879 => Loss: 50.42482580531859781559\n",
      "Iteration 9880 => Loss: 50.42463050277669367460\n",
      "Iteration 9881 => Loss: 50.42443520176751547979\n",
      "Iteration 9882 => Loss: 50.42423990229105612570\n",
      "Iteration 9883 => Loss: 50.42404460434733692864\n",
      "Iteration 9884 => Loss: 50.42384930793627262346\n",
      "Iteration 9885 => Loss: 50.42365401305791294817\n",
      "Iteration 9886 => Loss: 50.42345871971219395391\n",
      "Iteration 9887 => Loss: 50.42326342789915116782\n",
      "Iteration 9888 => Loss: 50.42306813761876327362\n",
      "Iteration 9889 => Loss: 50.42287284887100184960\n",
      "Iteration 9890 => Loss: 50.42267756165585979033\n",
      "Iteration 9891 => Loss: 50.42248227597333709582\n",
      "Iteration 9892 => Loss: 50.42228699182340534435\n",
      "Iteration 9893 => Loss: 50.42209170920605743049\n",
      "Iteration 9894 => Loss: 50.42189642812129335425\n",
      "Iteration 9895 => Loss: 50.42170114856907758849\n",
      "Iteration 9896 => Loss: 50.42150587054942434406\n",
      "Iteration 9897 => Loss: 50.42131059406228388298\n",
      "Iteration 9898 => Loss: 50.42111531910769173237\n",
      "Iteration 9899 => Loss: 50.42092004568561947053\n",
      "Iteration 9900 => Loss: 50.42072477379603157033\n",
      "Iteration 9901 => Loss: 50.42052950343894224261\n",
      "Iteration 9902 => Loss: 50.42033423461433017110\n",
      "Iteration 9903 => Loss: 50.42013896732219535579\n",
      "Iteration 9904 => Loss: 50.41994370156247384784\n",
      "Iteration 9905 => Loss: 50.41974843733521538525\n",
      "Iteration 9906 => Loss: 50.41955317464039154629\n",
      "Iteration 9907 => Loss: 50.41935791347800233098\n",
      "Iteration 9908 => Loss: 50.41916265384798379046\n",
      "Iteration 9909 => Loss: 50.41896739575038566272\n",
      "Iteration 9910 => Loss: 50.41877213918515110436\n",
      "Iteration 9911 => Loss: 50.41857688415230143164\n",
      "Iteration 9912 => Loss: 50.41838163065179401201\n",
      "Iteration 9913 => Loss: 50.41818637868363595089\n",
      "Iteration 9914 => Loss: 50.41799112824779882658\n",
      "Iteration 9915 => Loss: 50.41779587934429684992\n",
      "Iteration 9916 => Loss: 50.41760063197312291550\n",
      "Iteration 9917 => Loss: 50.41740538613422728531\n",
      "Iteration 9918 => Loss: 50.41721014182760995936\n",
      "Iteration 9919 => Loss: 50.41701489905326383223\n",
      "Iteration 9920 => Loss: 50.41681965781118890391\n",
      "Iteration 9921 => Loss: 50.41662441810136385811\n",
      "Iteration 9922 => Loss: 50.41642917992376027314\n",
      "Iteration 9923 => Loss: 50.41623394327838525442\n",
      "Iteration 9924 => Loss: 50.41603870816525301279\n",
      "Iteration 9925 => Loss: 50.41584347458427117772\n",
      "Iteration 9926 => Loss: 50.41564824253551080346\n",
      "Iteration 9927 => Loss: 50.41545301201894346832\n",
      "Iteration 9928 => Loss: 50.41525778303448390716\n",
      "Iteration 9929 => Loss: 50.41506255558222449054\n",
      "Iteration 9930 => Loss: 50.41486732966207995332\n",
      "Iteration 9931 => Loss: 50.41467210527408582266\n",
      "Iteration 9932 => Loss: 50.41447688241818525512\n",
      "Iteration 9933 => Loss: 50.41428166109441377785\n",
      "Iteration 9934 => Loss: 50.41408644130272875827\n",
      "Iteration 9935 => Loss: 50.41389122304310177469\n",
      "Iteration 9936 => Loss: 50.41369600631556124881\n",
      "Iteration 9937 => Loss: 50.41350079112007875892\n",
      "Iteration 9938 => Loss: 50.41330557745661877789\n",
      "Iteration 9939 => Loss: 50.41311036532521683284\n",
      "Iteration 9940 => Loss: 50.41291515472580897494\n",
      "Iteration 9941 => Loss: 50.41271994565844494218\n",
      "Iteration 9942 => Loss: 50.41252473812307499657\n",
      "Iteration 9943 => Loss: 50.41232953211964229467\n",
      "Iteration 9944 => Loss: 50.41213432764821789078\n",
      "Iteration 9945 => Loss: 50.41193912470873783604\n",
      "Iteration 9946 => Loss: 50.41174392330121634132\n",
      "Iteration 9947 => Loss: 50.41154872342563209031\n",
      "Iteration 9948 => Loss: 50.41135352508197087218\n",
      "Iteration 9949 => Loss: 50.41115832827023268692\n",
      "Iteration 9950 => Loss: 50.41096313299034648026\n",
      "Iteration 9951 => Loss: 50.41076793924240462275\n",
      "Iteration 9952 => Loss: 50.41057274702630053298\n",
      "Iteration 9953 => Loss: 50.41037755634208394895\n",
      "Iteration 9954 => Loss: 50.41018236718969802723\n",
      "Iteration 9955 => Loss: 50.40998717956917118954\n",
      "Iteration 9956 => Loss: 50.40979199348046790874\n",
      "Iteration 9957 => Loss: 50.40959680892358107940\n",
      "Iteration 9958 => Loss: 50.40940162589847517438\n",
      "Iteration 9959 => Loss: 50.40920644440518572083\n",
      "Iteration 9960 => Loss: 50.40901126444367719159\n",
      "Iteration 9961 => Loss: 50.40881608601392116498\n",
      "Iteration 9962 => Loss: 50.40862090911591764097\n",
      "Iteration 9963 => Loss: 50.40842573374966661959\n",
      "Iteration 9964 => Loss: 50.40823055991516099539\n",
      "Iteration 9965 => Loss: 50.40803538761234392496\n",
      "Iteration 9966 => Loss: 50.40784021684125093543\n",
      "Iteration 9967 => Loss: 50.40764504760184649967\n",
      "Iteration 9968 => Loss: 50.40744987989412351226\n",
      "Iteration 9969 => Loss: 50.40725471371808907861\n",
      "Iteration 9970 => Loss: 50.40705954907369346074\n",
      "Iteration 9971 => Loss: 50.40686438596095797493\n",
      "Iteration 9972 => Loss: 50.40666922437986841032\n",
      "Iteration 9973 => Loss: 50.40647406433038213436\n",
      "Iteration 9974 => Loss: 50.40627890581250625246\n",
      "Iteration 9975 => Loss: 50.40608374882624076463\n",
      "Iteration 9976 => Loss: 50.40588859337157146001\n",
      "Iteration 9977 => Loss: 50.40569343944845570604\n",
      "Iteration 9978 => Loss: 50.40549828705690060815\n",
      "Iteration 9979 => Loss: 50.40530313619690616633\n",
      "Iteration 9980 => Loss: 50.40510798686842974803\n",
      "Iteration 9981 => Loss: 50.40491283907151398580\n",
      "Iteration 9982 => Loss: 50.40471769280608782537\n",
      "Iteration 9983 => Loss: 50.40452254807218679389\n",
      "Iteration 9984 => Loss: 50.40432740486976825878\n",
      "Iteration 9985 => Loss: 50.40413226319880379833\n",
      "Iteration 9986 => Loss: 50.40393712305934315054\n",
      "Iteration 9987 => Loss: 50.40374198445131526114\n",
      "Iteration 9988 => Loss: 50.40354684737472723555\n",
      "Iteration 9989 => Loss: 50.40335171182957907376\n",
      "Iteration 9990 => Loss: 50.40315657781585656494\n",
      "Iteration 9991 => Loss: 50.40296144533354549822\n",
      "Iteration 9992 => Loss: 50.40276631438258903017\n",
      "Iteration 9993 => Loss: 50.40257118496303689881\n",
      "Iteration 9994 => Loss: 50.40237605707486778783\n",
      "Iteration 9995 => Loss: 50.40218093071803195926\n",
      "Iteration 9996 => Loss: 50.40198580589256494022\n",
      "Iteration 9997 => Loss: 50.40179068259841699273\n",
      "Iteration 9998 => Loss: 50.40159556083561653850\n",
      "Iteration 9999 => Loss: 50.40140044060409252324\n",
      "Iteration 10000 => Loss: 50.40120532190389468497\n",
      "Iteration 10001 => Loss: 50.40101020473495907481\n",
      "Iteration 10002 => Loss: 50.40081508909732121992\n",
      "Iteration 10003 => Loss: 50.40061997499093138231\n",
      "Iteration 10004 => Loss: 50.40042486241578956196\n",
      "Iteration 10005 => Loss: 50.40022975137188154804\n",
      "Iteration 10006 => Loss: 50.40003464185921444596\n",
      "Iteration 10007 => Loss: 50.39983953387776693944\n",
      "Iteration 10008 => Loss: 50.39964442742748929049\n",
      "Iteration 10009 => Loss: 50.39944932250842413168\n",
      "Iteration 10010 => Loss: 50.39925421912054304130\n",
      "Iteration 10011 => Loss: 50.39905911726380338678\n",
      "Iteration 10012 => Loss: 50.39886401693824069525\n",
      "Iteration 10013 => Loss: 50.39866891814381233416\n",
      "Iteration 10014 => Loss: 50.39847382088052540894\n",
      "Iteration 10015 => Loss: 50.39827872514834439244\n",
      "Iteration 10016 => Loss: 50.39808363094726217923\n",
      "Iteration 10017 => Loss: 50.39788853827727166390\n",
      "Iteration 10018 => Loss: 50.39769344713837995187\n",
      "Iteration 10019 => Loss: 50.39749835753055151599\n",
      "Iteration 10020 => Loss: 50.39730326945378635628\n",
      "Iteration 10021 => Loss: 50.39710818290805605102\n",
      "Iteration 10022 => Loss: 50.39691309789336060021\n",
      "Iteration 10023 => Loss: 50.39671801440969289843\n",
      "Iteration 10024 => Loss: 50.39652293245702452396\n",
      "Iteration 10025 => Loss: 50.39632785203535547680\n",
      "Iteration 10026 => Loss: 50.39613277314466444068\n",
      "Iteration 10027 => Loss: 50.39593769578496562644\n",
      "Iteration 10028 => Loss: 50.39574261995620219068\n",
      "Iteration 10029 => Loss: 50.39554754565843097680\n",
      "Iteration 10030 => Loss: 50.39535247289155961425\n",
      "Iteration 10031 => Loss: 50.39515740165565205189\n",
      "Iteration 10032 => Loss: 50.39496233195060881371\n",
      "Iteration 10033 => Loss: 50.39476726377649384858\n",
      "Iteration 10034 => Loss: 50.39457219713326452393\n",
      "Iteration 10035 => Loss: 50.39437713202090662890\n",
      "Iteration 10036 => Loss: 50.39418206843942016349\n",
      "Iteration 10037 => Loss: 50.39398700638879802227\n",
      "Iteration 10038 => Loss: 50.39379194586899757269\n",
      "Iteration 10039 => Loss: 50.39359688688003302559\n",
      "Iteration 10040 => Loss: 50.39340182942187595927\n",
      "Iteration 10041 => Loss: 50.39320677349456190086\n",
      "Iteration 10042 => Loss: 50.39301171909801269067\n",
      "Iteration 10043 => Loss: 50.39281666623224253954\n",
      "Iteration 10044 => Loss: 50.39262161489723723662\n",
      "Iteration 10045 => Loss: 50.39242656509300388734\n",
      "Iteration 10046 => Loss: 50.39223151681950696457\n",
      "Iteration 10047 => Loss: 50.39203647007674646829\n",
      "Iteration 10048 => Loss: 50.39184142486468687139\n",
      "Iteration 10049 => Loss: 50.39164638118336370098\n",
      "Iteration 10050 => Loss: 50.39145133903272721909\n",
      "Iteration 10051 => Loss: 50.39125629841275610943\n",
      "Iteration 10052 => Loss: 50.39106125932350010999\n",
      "Iteration 10053 => Loss: 50.39086622176487395564\n",
      "Iteration 10054 => Loss: 50.39067118573689896266\n",
      "Iteration 10055 => Loss: 50.39047615123956802563\n",
      "Iteration 10056 => Loss: 50.39028111827285982827\n",
      "Iteration 10057 => Loss: 50.39008608683676015971\n",
      "Iteration 10058 => Loss: 50.38989105693126191454\n",
      "Iteration 10059 => Loss: 50.38969602855635798733\n",
      "Iteration 10060 => Loss: 50.38950100171201995636\n",
      "Iteration 10061 => Loss: 50.38930597639826913792\n",
      "Iteration 10062 => Loss: 50.38911095261506289944\n",
      "Iteration 10063 => Loss: 50.38891593036238703007\n",
      "Iteration 10064 => Loss: 50.38872090964023442439\n",
      "Iteration 10065 => Loss: 50.38852589044861218781\n",
      "Iteration 10066 => Loss: 50.38833087278748479321\n",
      "Iteration 10067 => Loss: 50.38813585665685934600\n",
      "Iteration 10068 => Loss: 50.38794084205670742449\n",
      "Iteration 10069 => Loss: 50.38774582898704323952\n",
      "Iteration 10070 => Loss: 50.38755081744780284225\n",
      "Iteration 10071 => Loss: 50.38735580743902886525\n",
      "Iteration 10072 => Loss: 50.38716079896067867594\n",
      "Iteration 10073 => Loss: 50.38696579201277359061\n",
      "Iteration 10074 => Loss: 50.38677078659523544957\n",
      "Iteration 10075 => Loss: 50.38657578270812820165\n",
      "Iteration 10076 => Loss: 50.38638078035138079258\n",
      "Iteration 10077 => Loss: 50.38618577952502874950\n",
      "Iteration 10078 => Loss: 50.38599078022900101814\n",
      "Iteration 10079 => Loss: 50.38579578246334733649\n",
      "Iteration 10080 => Loss: 50.38560078622801086112\n",
      "Iteration 10081 => Loss: 50.38540579152304133004\n",
      "Iteration 10082 => Loss: 50.38521079834833926725\n",
      "Iteration 10083 => Loss: 50.38501580670396151618\n",
      "Iteration 10084 => Loss: 50.38482081658985833883\n",
      "Iteration 10085 => Loss: 50.38462582800602973521\n",
      "Iteration 10086 => Loss: 50.38443084095248991616\n",
      "Iteration 10087 => Loss: 50.38423585542917493285\n",
      "Iteration 10088 => Loss: 50.38404087143611320698\n",
      "Iteration 10089 => Loss: 50.38384588897327631685\n",
      "Iteration 10090 => Loss: 50.38365090804066426244\n",
      "Iteration 10091 => Loss: 50.38345592863824151664\n",
      "Iteration 10092 => Loss: 50.38326095076602939571\n",
      "Iteration 10093 => Loss: 50.38306597442398526709\n",
      "Iteration 10094 => Loss: 50.38287099961210913079\n",
      "Iteration 10095 => Loss: 50.38267602633037967053\n",
      "Iteration 10096 => Loss: 50.38248105457880399172\n",
      "Iteration 10097 => Loss: 50.38228608435736788351\n",
      "Iteration 10098 => Loss: 50.38209111566604292420\n",
      "Iteration 10099 => Loss: 50.38189614850482911379\n",
      "Iteration 10100 => Loss: 50.38170118287371934684\n",
      "Iteration 10101 => Loss: 50.38150621877267809623\n",
      "Iteration 10102 => Loss: 50.38131125620171957280\n",
      "Iteration 10103 => Loss: 50.38111629516080824942\n",
      "Iteration 10104 => Loss: 50.38092133564995123152\n",
      "Iteration 10105 => Loss: 50.38072637766913430823\n",
      "Iteration 10106 => Loss: 50.38053142121833616329\n",
      "Iteration 10107 => Loss: 50.38033646629754969126\n",
      "Iteration 10108 => Loss: 50.38014151290676778672\n",
      "Iteration 10109 => Loss: 50.37994656104596913337\n",
      "Iteration 10110 => Loss: 50.37975161071513952038\n",
      "Iteration 10111 => Loss: 50.37955666191429315859\n",
      "Iteration 10112 => Loss: 50.37936171464338741544\n",
      "Iteration 10113 => Loss: 50.37916676890240097464\n",
      "Iteration 10114 => Loss: 50.37897182469136225791\n",
      "Iteration 10115 => Loss: 50.37877688201024994896\n",
      "Iteration 10116 => Loss: 50.37858194085902141524\n",
      "Iteration 10117 => Loss: 50.37838700123769086758\n",
      "Iteration 10118 => Loss: 50.37819206314624409515\n",
      "Iteration 10119 => Loss: 50.37799712658466688708\n",
      "Iteration 10120 => Loss: 50.37780219155293792710\n",
      "Iteration 10121 => Loss: 50.37760725805105721520\n",
      "Iteration 10122 => Loss: 50.37741232607901764595\n",
      "Iteration 10123 => Loss: 50.37721739563677658680\n",
      "Iteration 10124 => Loss: 50.37702246672435535402\n",
      "Iteration 10125 => Loss: 50.37682753934172552590\n",
      "Iteration 10126 => Loss: 50.37663261348889420788\n",
      "Iteration 10127 => Loss: 50.37643768916581876738\n",
      "Iteration 10128 => Loss: 50.37624276637249920441\n",
      "Iteration 10129 => Loss: 50.37604784510894262439\n",
      "Iteration 10130 => Loss: 50.37585292537509928934\n",
      "Iteration 10131 => Loss: 50.37565800717100472639\n",
      "Iteration 10132 => Loss: 50.37546309049658788126\n",
      "Iteration 10133 => Loss: 50.37526817535190559738\n",
      "Iteration 10134 => Loss: 50.37507326173687971504\n",
      "Iteration 10135 => Loss: 50.37487834965154576139\n",
      "Iteration 10136 => Loss: 50.37468343909588952556\n",
      "Iteration 10137 => Loss: 50.37448853006988258585\n",
      "Iteration 10138 => Loss: 50.37429362257349652054\n",
      "Iteration 10139 => Loss: 50.37409871660673843508\n",
      "Iteration 10140 => Loss: 50.37390381216960122401\n",
      "Iteration 10141 => Loss: 50.37370890926206357108\n",
      "Iteration 10142 => Loss: 50.37351400788413258169\n",
      "Iteration 10143 => Loss: 50.37331910803576562330\n",
      "Iteration 10144 => Loss: 50.37312420971695559047\n",
      "Iteration 10145 => Loss: 50.37292931292770248319\n",
      "Iteration 10146 => Loss: 50.37273441766802761776\n",
      "Iteration 10147 => Loss: 50.37253952393785283448\n",
      "Iteration 10148 => Loss: 50.37234463173721366047\n",
      "Iteration 10149 => Loss: 50.37214974106608167403\n",
      "Iteration 10150 => Loss: 50.37195485192442845346\n",
      "Iteration 10151 => Loss: 50.37175996431227531502\n",
      "Iteration 10152 => Loss: 50.37156507822959383702\n",
      "Iteration 10153 => Loss: 50.37137019367635559774\n",
      "Iteration 10154 => Loss: 50.37117531065256059719\n",
      "Iteration 10155 => Loss: 50.37098042915823015164\n",
      "Iteration 10156 => Loss: 50.37078554919330031225\n",
      "Iteration 10157 => Loss: 50.37059067075777818445\n",
      "Iteration 10158 => Loss: 50.37039579385169218995\n",
      "Iteration 10159 => Loss: 50.37020091847494285275\n",
      "Iteration 10160 => Loss: 50.37000604462759412172\n",
      "Iteration 10161 => Loss: 50.36981117230960336428\n",
      "Iteration 10162 => Loss: 50.36961630152097058044\n",
      "Iteration 10163 => Loss: 50.36942143226166734848\n",
      "Iteration 10164 => Loss: 50.36922656453168656299\n",
      "Iteration 10165 => Loss: 50.36903169833102111852\n",
      "Iteration 10166 => Loss: 50.36883683365966390966\n",
      "Iteration 10167 => Loss: 50.36864197051761493640\n",
      "Iteration 10168 => Loss: 50.36844710890481735532\n",
      "Iteration 10169 => Loss: 50.36825224882132090443\n",
      "Iteration 10170 => Loss: 50.36805739026704742400\n",
      "Iteration 10171 => Loss: 50.36786253324203954662\n",
      "Iteration 10172 => Loss: 50.36766767774622621801\n",
      "Iteration 10173 => Loss: 50.36747282377966428157\n",
      "Iteration 10174 => Loss: 50.36727797134231110476\n",
      "Iteration 10175 => Loss: 50.36708312043413116044\n",
      "Iteration 10176 => Loss: 50.36688827105515287030\n",
      "Iteration 10177 => Loss: 50.36669342320534070723\n",
      "Iteration 10178 => Loss: 50.36649857688468046035\n",
      "Iteration 10179 => Loss: 50.36630373209318634053\n",
      "Iteration 10180 => Loss: 50.36610888883078729350\n",
      "Iteration 10181 => Loss: 50.36591404709754016267\n",
      "Iteration 10182 => Loss: 50.36571920689340942090\n",
      "Iteration 10183 => Loss: 50.36552436821836664649\n",
      "Iteration 10184 => Loss: 50.36532953107243315571\n",
      "Iteration 10185 => Loss: 50.36513469545552368345\n",
      "Iteration 10186 => Loss: 50.36493986136773770568\n",
      "Iteration 10187 => Loss: 50.36474502880896153556\n",
      "Iteration 10188 => Loss: 50.36455019777922359481\n",
      "Iteration 10189 => Loss: 50.36435536827853098885\n",
      "Iteration 10190 => Loss: 50.36416054030685529597\n",
      "Iteration 10191 => Loss: 50.36396571386416809446\n",
      "Iteration 10192 => Loss: 50.36377088895049070061\n",
      "Iteration 10193 => Loss: 50.36357606556576627099\n",
      "Iteration 10194 => Loss: 50.36338124371002322732\n",
      "Iteration 10195 => Loss: 50.36318642338323314789\n",
      "Iteration 10196 => Loss: 50.36299160458538182183\n",
      "Iteration 10197 => Loss: 50.36279678731646214374\n",
      "Iteration 10198 => Loss: 50.36260197157645279731\n",
      "Iteration 10199 => Loss: 50.36240715736537509883\n",
      "Iteration 10200 => Loss: 50.36221234468317931032\n",
      "Iteration 10201 => Loss: 50.36201753352986543177\n",
      "Iteration 10202 => Loss: 50.36182272390541925233\n",
      "Iteration 10203 => Loss: 50.36162791580984787743\n",
      "Iteration 10204 => Loss: 50.36143310924310156906\n",
      "Iteration 10205 => Loss: 50.36123830420520874895\n",
      "Iteration 10206 => Loss: 50.36104350069612678453\n",
      "Iteration 10207 => Loss: 50.36084869871586278123\n",
      "Iteration 10208 => Loss: 50.36065389826439542276\n",
      "Iteration 10209 => Loss: 50.36045909934170339284\n",
      "Iteration 10210 => Loss: 50.36026430194780800775\n",
      "Iteration 10211 => Loss: 50.36006950608265242408\n",
      "Iteration 10212 => Loss: 50.35987471174624374726\n",
      "Iteration 10213 => Loss: 50.35967991893858197727\n",
      "Iteration 10214 => Loss: 50.35948512765964579785\n",
      "Iteration 10215 => Loss: 50.35929033790944941984\n",
      "Iteration 10216 => Loss: 50.35909554968792889440\n",
      "Iteration 10217 => Loss: 50.35890076299511974867\n",
      "Iteration 10218 => Loss: 50.35870597783096513922\n",
      "Iteration 10219 => Loss: 50.35851119419548638234\n",
      "Iteration 10220 => Loss: 50.35831641208865505632\n",
      "Iteration 10221 => Loss: 50.35812163151049958287\n",
      "Iteration 10222 => Loss: 50.35792685246095601315\n",
      "Iteration 10223 => Loss: 50.35773207494001724172\n",
      "Iteration 10224 => Loss: 50.35753729894768326858\n",
      "Iteration 10225 => Loss: 50.35734252448397541002\n",
      "Iteration 10226 => Loss: 50.35714775154879419006\n",
      "Iteration 10227 => Loss: 50.35695298014225329553\n",
      "Iteration 10228 => Loss: 50.35675821026421772331\n",
      "Iteration 10229 => Loss: 50.35656344191473721139\n",
      "Iteration 10230 => Loss: 50.35636867509380465435\n",
      "Iteration 10231 => Loss: 50.35617390980140584134\n",
      "Iteration 10232 => Loss: 50.35597914603751235063\n",
      "Iteration 10233 => Loss: 50.35578438380209576053\n",
      "Iteration 10234 => Loss: 50.35558962309518449274\n",
      "Iteration 10235 => Loss: 50.35539486391675012555\n",
      "Iteration 10236 => Loss: 50.35520010626677844812\n",
      "Iteration 10237 => Loss: 50.35500535014524814414\n",
      "Iteration 10238 => Loss: 50.35481059555214500278\n",
      "Iteration 10239 => Loss: 50.35461584248749034032\n",
      "Iteration 10240 => Loss: 50.35442109095123441875\n",
      "Iteration 10241 => Loss: 50.35422634094339144895\n",
      "Iteration 10242 => Loss: 50.35403159246394011461\n",
      "Iteration 10243 => Loss: 50.35383684551285909947\n",
      "Iteration 10244 => Loss: 50.35364210009015550895\n",
      "Iteration 10245 => Loss: 50.35344735619578671049\n",
      "Iteration 10246 => Loss: 50.35325261382978112579\n",
      "Iteration 10247 => Loss: 50.35305787299209612229\n",
      "Iteration 10248 => Loss: 50.35286313368271748914\n",
      "Iteration 10249 => Loss: 50.35266839590168075347\n",
      "Iteration 10250 => Loss: 50.35247365964891486101\n",
      "Iteration 10251 => Loss: 50.35227892492444112804\n",
      "Iteration 10252 => Loss: 50.35208419172822402743\n",
      "Iteration 10253 => Loss: 50.35188946006027066460\n",
      "Iteration 10254 => Loss: 50.35169472992057393412\n",
      "Iteration 10255 => Loss: 50.35150000130909830887\n",
      "Iteration 10256 => Loss: 50.35130527422586510511\n",
      "Iteration 10257 => Loss: 50.35111054867081747943\n",
      "Iteration 10258 => Loss: 50.35091582464399095898\n",
      "Iteration 10259 => Loss: 50.35072110214533580574\n",
      "Iteration 10260 => Loss: 50.35052638117485912517\n",
      "Iteration 10261 => Loss: 50.35033166173255381182\n",
      "Iteration 10262 => Loss: 50.35013694381838433856\n",
      "Iteration 10263 => Loss: 50.34994222743237202167\n",
      "Iteration 10264 => Loss: 50.34974751257445291230\n",
      "Iteration 10265 => Loss: 50.34955279924467674846\n",
      "Iteration 10266 => Loss: 50.34935808744298668671\n",
      "Iteration 10267 => Loss: 50.34916337716941114877\n",
      "Iteration 10268 => Loss: 50.34896866842389329122\n",
      "Iteration 10269 => Loss: 50.34877396120644732491\n",
      "Iteration 10270 => Loss: 50.34857925551706614442\n",
      "Iteration 10271 => Loss: 50.34838455135572843346\n",
      "Iteration 10272 => Loss: 50.34818984872239155948\n",
      "Iteration 10273 => Loss: 50.34799514761708394417\n",
      "Iteration 10274 => Loss: 50.34780044803981269297\n",
      "Iteration 10275 => Loss: 50.34760574999050675160\n",
      "Iteration 10276 => Loss: 50.34741105346918743635\n",
      "Iteration 10277 => Loss: 50.34721635847584053636\n",
      "Iteration 10278 => Loss: 50.34702166501046605163\n",
      "Iteration 10279 => Loss: 50.34682697307304266587\n",
      "Iteration 10280 => Loss: 50.34663228266352774654\n",
      "Iteration 10281 => Loss: 50.34643759378194260989\n",
      "Iteration 10282 => Loss: 50.34624290642830146680\n",
      "Iteration 10283 => Loss: 50.34604822060251905214\n",
      "Iteration 10284 => Loss: 50.34585353630464510388\n",
      "Iteration 10285 => Loss: 50.34565885353461567320\n",
      "Iteration 10286 => Loss: 50.34546417229248049807\n",
      "Iteration 10287 => Loss: 50.34526949257818984051\n",
      "Iteration 10288 => Loss: 50.34507481439173659510\n",
      "Iteration 10289 => Loss: 50.34488013773308523469\n",
      "Iteration 10290 => Loss: 50.34468546260229970812\n",
      "Iteration 10291 => Loss: 50.34449078899926632857\n",
      "Iteration 10292 => Loss: 50.34429611692404193946\n",
      "Iteration 10293 => Loss: 50.34410144637659101363\n",
      "Iteration 10294 => Loss: 50.34390677735692776196\n",
      "Iteration 10295 => Loss: 50.34371210986500955187\n",
      "Iteration 10296 => Loss: 50.34351744390082927794\n",
      "Iteration 10297 => Loss: 50.34332277946435851845\n",
      "Iteration 10298 => Loss: 50.34312811655563990598\n",
      "Iteration 10299 => Loss: 50.34293345517461659711\n",
      "Iteration 10300 => Loss: 50.34273879532128148639\n",
      "Iteration 10301 => Loss: 50.34254413699564878470\n",
      "Iteration 10302 => Loss: 50.34234948019766164862\n",
      "Iteration 10303 => Loss: 50.34215482492734849984\n",
      "Iteration 10304 => Loss: 50.34196017118467381124\n",
      "Iteration 10305 => Loss: 50.34176551896966600452\n",
      "Iteration 10306 => Loss: 50.34157086828223981456\n",
      "Iteration 10307 => Loss: 50.34137621912243787392\n",
      "Iteration 10308 => Loss: 50.34118157149023886632\n",
      "Iteration 10309 => Loss: 50.34098692538562147547\n",
      "Iteration 10310 => Loss: 50.34079228080858570138\n",
      "Iteration 10311 => Loss: 50.34059763775911733319\n",
      "Iteration 10312 => Loss: 50.34040299623717373834\n",
      "Iteration 10313 => Loss: 50.34020835624279044396\n",
      "Iteration 10314 => Loss: 50.34001371777592481749\n",
      "Iteration 10315 => Loss: 50.33981908083658396436\n",
      "Iteration 10316 => Loss: 50.33962444542473946285\n",
      "Iteration 10317 => Loss: 50.33942981154038420755\n",
      "Iteration 10318 => Loss: 50.33923517918351109302\n",
      "Iteration 10319 => Loss: 50.33904054835409880297\n",
      "Iteration 10320 => Loss: 50.33884591905216154828\n",
      "Iteration 10321 => Loss: 50.33865129127764248551\n",
      "Iteration 10322 => Loss: 50.33845666503057003638\n",
      "Iteration 10323 => Loss: 50.33826204031091577917\n",
      "Iteration 10324 => Loss: 50.33806741711865129218\n",
      "Iteration 10325 => Loss: 50.33787279545379789170\n",
      "Iteration 10326 => Loss: 50.33767817531633426142\n",
      "Iteration 10327 => Loss: 50.33748355670621066338\n",
      "Iteration 10328 => Loss: 50.33728893962347683555\n",
      "Iteration 10329 => Loss: 50.33709432406809014537\n",
      "Iteration 10330 => Loss: 50.33689971004000796029\n",
      "Iteration 10331 => Loss: 50.33670509753929422914\n",
      "Iteration 10332 => Loss: 50.33651048656586368679\n",
      "Iteration 10333 => Loss: 50.33631587711970922783\n",
      "Iteration 10334 => Loss: 50.33612126920088059023\n",
      "Iteration 10335 => Loss: 50.33592666280932093059\n",
      "Iteration 10336 => Loss: 50.33573205794500893262\n",
      "Iteration 10337 => Loss: 50.33553745460795170175\n",
      "Iteration 10338 => Loss: 50.33534285279813502711\n",
      "Iteration 10339 => Loss: 50.33514825251555180330\n",
      "Iteration 10340 => Loss: 50.33495365376018071402\n",
      "Iteration 10341 => Loss: 50.33475905653200754841\n",
      "Iteration 10342 => Loss: 50.33456446083103941191\n",
      "Iteration 10343 => Loss: 50.33436986665724077739\n",
      "Iteration 10344 => Loss: 50.33417527401060453940\n",
      "Iteration 10345 => Loss: 50.33398068289111648710\n",
      "Iteration 10346 => Loss: 50.33378609329879793677\n",
      "Iteration 10347 => Loss: 50.33359150523357783413\n",
      "Iteration 10348 => Loss: 50.33339691869551302261\n",
      "Iteration 10349 => Loss: 50.33320233368453244793\n",
      "Iteration 10350 => Loss: 50.33300775020065032095\n",
      "Iteration 10351 => Loss: 50.33281316824384532538\n",
      "Iteration 10352 => Loss: 50.33261858781412456665\n",
      "Iteration 10353 => Loss: 50.33242400891145962305\n",
      "Iteration 10354 => Loss: 50.33222943153583628373\n",
      "Iteration 10355 => Loss: 50.33203485568724744326\n",
      "Iteration 10356 => Loss: 50.33184028136569310163\n",
      "Iteration 10357 => Loss: 50.33164570857112352087\n",
      "Iteration 10358 => Loss: 50.33145113730357422810\n",
      "Iteration 10359 => Loss: 50.33125656756301680161\n",
      "Iteration 10360 => Loss: 50.33106199934943703056\n",
      "Iteration 10361 => Loss: 50.33086743266280649323\n",
      "Iteration 10362 => Loss: 50.33067286750313229504\n",
      "Iteration 10363 => Loss: 50.33047830387039311972\n",
      "Iteration 10364 => Loss: 50.33028374176460317813\n",
      "Iteration 10365 => Loss: 50.33008918118570562683\n",
      "Iteration 10366 => Loss: 50.32989462213371467669\n",
      "Iteration 10367 => Loss: 50.32970006460860901143\n",
      "Iteration 10368 => Loss: 50.32950550861038863104\n",
      "Iteration 10369 => Loss: 50.32931095413902511382\n",
      "Iteration 10370 => Loss: 50.32911640119454688147\n",
      "Iteration 10371 => Loss: 50.32892184977688998515\n",
      "Iteration 10372 => Loss: 50.32872729988606863571\n",
      "Iteration 10373 => Loss: 50.32853275152208283316\n",
      "Iteration 10374 => Loss: 50.32833820468486862865\n",
      "Iteration 10375 => Loss: 50.32814365937448286559\n",
      "Iteration 10376 => Loss: 50.32794911559084738428\n",
      "Iteration 10377 => Loss: 50.32775457333401192273\n",
      "Iteration 10378 => Loss: 50.32756003260392674292\n",
      "Iteration 10379 => Loss: 50.32736549340059184487\n",
      "Iteration 10380 => Loss: 50.32717095572399301773\n",
      "Iteration 10381 => Loss: 50.32697641957410894520\n",
      "Iteration 10382 => Loss: 50.32678188495095383814\n",
      "Iteration 10383 => Loss: 50.32658735185448506400\n",
      "Iteration 10384 => Loss: 50.32639282028470972818\n",
      "Iteration 10385 => Loss: 50.32619829024159230357\n",
      "Iteration 10386 => Loss: 50.32600376172516121187\n",
      "Iteration 10387 => Loss: 50.32580923473536671509\n",
      "Iteration 10388 => Loss: 50.32561470927222302407\n",
      "Iteration 10389 => Loss: 50.32542018533570171712\n",
      "Iteration 10390 => Loss: 50.32522566292578858338\n",
      "Iteration 10391 => Loss: 50.32503114204249072827\n",
      "Iteration 10392 => Loss: 50.32483662268577262466\n",
      "Iteration 10393 => Loss: 50.32464210485565558884\n",
      "Iteration 10394 => Loss: 50.32444758855209698822\n",
      "Iteration 10395 => Loss: 50.32425307377506840112\n",
      "Iteration 10396 => Loss: 50.32405856052461246009\n",
      "Iteration 10397 => Loss: 50.32386404880068653256\n",
      "Iteration 10398 => Loss: 50.32366953860327640768\n",
      "Iteration 10399 => Loss: 50.32347502993238208546\n",
      "Iteration 10400 => Loss: 50.32328052278796803876\n",
      "Iteration 10401 => Loss: 50.32308601717004137299\n",
      "Iteration 10402 => Loss: 50.32289151307858787732\n",
      "Iteration 10403 => Loss: 50.32269701051360755173\n",
      "Iteration 10404 => Loss: 50.32250250947505776367\n",
      "Iteration 10405 => Loss: 50.32230800996294561855\n",
      "Iteration 10406 => Loss: 50.32211351197726401097\n",
      "Iteration 10407 => Loss: 50.32191901551799873005\n",
      "Iteration 10408 => Loss: 50.32172452058512135409\n",
      "Iteration 10409 => Loss: 50.32153002717863188309\n",
      "Iteration 10410 => Loss: 50.32133553529851610620\n",
      "Iteration 10411 => Loss: 50.32114104494478112883\n",
      "Iteration 10412 => Loss: 50.32094655611740563472\n",
      "Iteration 10413 => Loss: 50.32075206881634699130\n",
      "Iteration 10414 => Loss: 50.32055758304160519856\n",
      "Iteration 10415 => Loss: 50.32036309879320157279\n",
      "Iteration 10416 => Loss: 50.32016861607109348142\n",
      "Iteration 10417 => Loss: 50.31997413487528092446\n",
      "Iteration 10418 => Loss: 50.31977965520574969105\n",
      "Iteration 10419 => Loss: 50.31958517706248557033\n",
      "Iteration 10420 => Loss: 50.31939070044547435145\n",
      "Iteration 10421 => Loss: 50.31919622535470182356\n",
      "Iteration 10422 => Loss: 50.31900175179018219751\n",
      "Iteration 10423 => Loss: 50.31880727975188705159\n",
      "Iteration 10424 => Loss: 50.31861280923975243695\n",
      "Iteration 10425 => Loss: 50.31841834025385651330\n",
      "Iteration 10426 => Loss: 50.31822387279413533179\n",
      "Iteration 10427 => Loss: 50.31802940686058178699\n",
      "Iteration 10428 => Loss: 50.31783494245320298432\n",
      "Iteration 10429 => Loss: 50.31764047957197050209\n",
      "Iteration 10430 => Loss: 50.31744601821684170773\n",
      "Iteration 10431 => Loss: 50.31725155838785923379\n",
      "Iteration 10432 => Loss: 50.31705710008500176400\n",
      "Iteration 10433 => Loss: 50.31686264330823377122\n",
      "Iteration 10434 => Loss: 50.31666818805754104460\n",
      "Iteration 10435 => Loss: 50.31647373433292358413\n",
      "Iteration 10436 => Loss: 50.31627928213440270611\n",
      "Iteration 10437 => Loss: 50.31608483146192156710\n",
      "Iteration 10438 => Loss: 50.31589038231547306168\n",
      "Iteration 10439 => Loss: 50.31569593469504297900\n",
      "Iteration 10440 => Loss: 50.31550148860065263534\n",
      "Iteration 10441 => Loss: 50.31530704403225229271\n",
      "Iteration 10442 => Loss: 50.31511260098985616196\n",
      "Iteration 10443 => Loss: 50.31491815947342871596\n",
      "Iteration 10444 => Loss: 50.31472371948296284927\n",
      "Iteration 10445 => Loss: 50.31452928101847277276\n",
      "Iteration 10446 => Loss: 50.31433484407992295928\n",
      "Iteration 10447 => Loss: 50.31414040866729919799\n",
      "Iteration 10448 => Loss: 50.31394597478059438345\n",
      "Iteration 10449 => Loss: 50.31375154241980851566\n",
      "Iteration 10450 => Loss: 50.31355711158489185664\n",
      "Iteration 10451 => Loss: 50.31336268227588703894\n",
      "Iteration 10452 => Loss: 50.31316825449275853543\n",
      "Iteration 10453 => Loss: 50.31297382823549213526\n",
      "Iteration 10454 => Loss: 50.31277940350405941672\n",
      "Iteration 10455 => Loss: 50.31258498029846748523\n",
      "Iteration 10456 => Loss: 50.31239055861869502451\n",
      "Iteration 10457 => Loss: 50.31219613846474913998\n",
      "Iteration 10458 => Loss: 50.31200171983659430452\n",
      "Iteration 10459 => Loss: 50.31180730273423051813\n",
      "Iteration 10460 => Loss: 50.31161288715764356994\n",
      "Iteration 10461 => Loss: 50.31141847310681924910\n",
      "Iteration 10462 => Loss: 50.31122406058175045018\n",
      "Iteration 10463 => Loss: 50.31102964958241585691\n",
      "Iteration 10464 => Loss: 50.31083524010884389099\n",
      "Iteration 10465 => Loss: 50.31064083216094218187\n",
      "Iteration 10466 => Loss: 50.31044642573875336211\n",
      "Iteration 10467 => Loss: 50.31025202084227743171\n",
      "Iteration 10468 => Loss: 50.31005761747148596896\n",
      "Iteration 10469 => Loss: 50.30986321562633634130\n",
      "Iteration 10470 => Loss: 50.30966881530685697044\n",
      "Iteration 10471 => Loss: 50.30947441651302654009\n",
      "Iteration 10472 => Loss: 50.30928001924484505025\n",
      "Iteration 10473 => Loss: 50.30908562350225565751\n",
      "Iteration 10474 => Loss: 50.30889122928530099443\n",
      "Iteration 10475 => Loss: 50.30869683659391000674\n",
      "Iteration 10476 => Loss: 50.30850244542813953785\n",
      "Iteration 10477 => Loss: 50.30830805578791142807\n",
      "Iteration 10478 => Loss: 50.30811366767329673166\n",
      "Iteration 10479 => Loss: 50.30791928108417465637\n",
      "Iteration 10480 => Loss: 50.30772489602059494018\n",
      "Iteration 10481 => Loss: 50.30753051248257179395\n",
      "Iteration 10482 => Loss: 50.30733613047004837426\n",
      "Iteration 10483 => Loss: 50.30714174998302468111\n",
      "Iteration 10484 => Loss: 50.30694737102150071451\n",
      "Iteration 10485 => Loss: 50.30675299358542673644\n",
      "Iteration 10486 => Loss: 50.30655861767486669578\n",
      "Iteration 10487 => Loss: 50.30636424328971401110\n",
      "Iteration 10488 => Loss: 50.30616987043001842039\n",
      "Iteration 10489 => Loss: 50.30597549909574439653\n",
      "Iteration 10490 => Loss: 50.30578112928691325578\n",
      "Iteration 10491 => Loss: 50.30558676100345394389\n",
      "Iteration 10492 => Loss: 50.30539239424542330426\n",
      "Iteration 10493 => Loss: 50.30519802901275028262\n",
      "Iteration 10494 => Loss: 50.30500366530544908983\n",
      "Iteration 10495 => Loss: 50.30480930312349840960\n",
      "Iteration 10496 => Loss: 50.30461494246691955823\n",
      "Iteration 10497 => Loss: 50.30442058333563437600\n",
      "Iteration 10498 => Loss: 50.30422622572970681176\n",
      "Iteration 10499 => Loss: 50.30403186964909423295\n",
      "Iteration 10500 => Loss: 50.30383751509372558530\n",
      "Iteration 10501 => Loss: 50.30364316206370034479\n",
      "Iteration 10502 => Loss: 50.30344881055893324628\n",
      "Iteration 10503 => Loss: 50.30325446057944560607\n",
      "Iteration 10504 => Loss: 50.30306011212516636988\n",
      "Iteration 10505 => Loss: 50.30286576519615238112\n",
      "Iteration 10506 => Loss: 50.30267141979236100724\n",
      "Iteration 10507 => Loss: 50.30247707591379224823\n",
      "Iteration 10508 => Loss: 50.30228273356040347153\n",
      "Iteration 10509 => Loss: 50.30208839273220178256\n",
      "Iteration 10510 => Loss: 50.30189405342920849762\n",
      "Iteration 10511 => Loss: 50.30169971565135256242\n",
      "Iteration 10512 => Loss: 50.30150537939866239867\n",
      "Iteration 10513 => Loss: 50.30131104467112379552\n",
      "Iteration 10514 => Loss: 50.30111671146869412041\n",
      "Iteration 10515 => Loss: 50.30092237979140179505\n",
      "Iteration 10516 => Loss: 50.30072804963920418686\n",
      "Iteration 10517 => Loss: 50.30053372101210840128\n",
      "Iteration 10518 => Loss: 50.30033939391009312203\n",
      "Iteration 10519 => Loss: 50.30014506833314413825\n",
      "Iteration 10520 => Loss: 50.29995074428126855537\n",
      "Iteration 10521 => Loss: 50.29975642175441663539\n",
      "Iteration 10522 => Loss: 50.29956210075262390546\n",
      "Iteration 10523 => Loss: 50.29936778127584062759\n",
      "Iteration 10524 => Loss: 50.29917346332405259091\n",
      "Iteration 10525 => Loss: 50.29897914689728821713\n",
      "Iteration 10526 => Loss: 50.29878483199550487370\n",
      "Iteration 10527 => Loss: 50.29859051861868834976\n",
      "Iteration 10528 => Loss: 50.29839620676685285616\n",
      "Iteration 10529 => Loss: 50.29820189643994865492\n",
      "Iteration 10530 => Loss: 50.29800758763796864059\n",
      "Iteration 10531 => Loss: 50.29781328036095544576\n",
      "Iteration 10532 => Loss: 50.29761897460882380528\n",
      "Iteration 10533 => Loss: 50.29742467038160924631\n",
      "Iteration 10534 => Loss: 50.29723036767929755797\n",
      "Iteration 10535 => Loss: 50.29703606650182479143\n",
      "Iteration 10536 => Loss: 50.29684176684924068468\n",
      "Iteration 10537 => Loss: 50.29664746872153102686\n",
      "Iteration 10538 => Loss: 50.29645317211863897455\n",
      "Iteration 10539 => Loss: 50.29625887704061426575\n",
      "Iteration 10540 => Loss: 50.29606458348735742447\n",
      "Iteration 10541 => Loss: 50.29587029145893950499\n",
      "Iteration 10542 => Loss: 50.29567600095531076931\n",
      "Iteration 10543 => Loss: 50.29548171197647832287\n",
      "Iteration 10544 => Loss: 50.29528742452237821681\n",
      "Iteration 10545 => Loss: 50.29509313859306018912\n",
      "Iteration 10546 => Loss: 50.29489885418851002896\n",
      "Iteration 10547 => Loss: 50.29470457130867089290\n",
      "Iteration 10548 => Loss: 50.29451028995355699180\n",
      "Iteration 10549 => Loss: 50.29431601012314700938\n",
      "Iteration 10550 => Loss: 50.29412173181746226192\n",
      "Iteration 10551 => Loss: 50.29392745503645301142\n",
      "Iteration 10552 => Loss: 50.29373317978011925788\n",
      "Iteration 10553 => Loss: 50.29353890604841836875\n",
      "Iteration 10554 => Loss: 50.29334463384140718745\n",
      "Iteration 10555 => Loss: 50.29315036315902887054\n",
      "Iteration 10556 => Loss: 50.29295609400126210176\n",
      "Iteration 10557 => Loss: 50.29276182636812819737\n",
      "Iteration 10558 => Loss: 50.29256756025959873568\n",
      "Iteration 10559 => Loss: 50.29237329567566661126\n",
      "Iteration 10560 => Loss: 50.29217903261626787526\n",
      "Iteration 10561 => Loss: 50.29198477108148068737\n",
      "Iteration 10562 => Loss: 50.29179051107124109876\n",
      "Iteration 10563 => Loss: 50.29159625258553489857\n",
      "Iteration 10564 => Loss: 50.29140199562437629766\n",
      "Iteration 10565 => Loss: 50.29120774018772976888\n",
      "Iteration 10566 => Loss: 50.29101348627558820681\n",
      "Iteration 10567 => Loss: 50.29081923388794450602\n",
      "Iteration 10568 => Loss: 50.29062498302477024481\n",
      "Iteration 10569 => Loss: 50.29043073368610805574\n",
      "Iteration 10570 => Loss: 50.29023648587186556824\n",
      "Iteration 10571 => Loss: 50.29004223958209252032\n",
      "Iteration 10572 => Loss: 50.28984799481673917398\n",
      "Iteration 10573 => Loss: 50.28965375157584105636\n",
      "Iteration 10574 => Loss: 50.28945950985931290234\n",
      "Iteration 10575 => Loss: 50.28926526966721155532\n",
      "Iteration 10576 => Loss: 50.28907103099949438274\n",
      "Iteration 10577 => Loss: 50.28887679385616138461\n",
      "Iteration 10578 => Loss: 50.28868255823716992836\n",
      "Iteration 10579 => Loss: 50.28848832414254843570\n",
      "Iteration 10580 => Loss: 50.28829409157226848492\n",
      "Iteration 10581 => Loss: 50.28809986052631586517\n",
      "Iteration 10582 => Loss: 50.28790563100465504931\n",
      "Iteration 10583 => Loss: 50.28771140300732156447\n",
      "Iteration 10584 => Loss: 50.28751717653429409438\n",
      "Iteration 10585 => Loss: 50.28732295158550869019\n",
      "Iteration 10586 => Loss: 50.28712872816102219531\n",
      "Iteration 10587 => Loss: 50.28693450626077776633\n",
      "Iteration 10588 => Loss: 50.28674028588478250867\n",
      "Iteration 10589 => Loss: 50.28654606703302931692\n",
      "Iteration 10590 => Loss: 50.28635184970548266392\n",
      "Iteration 10591 => Loss: 50.28615763390215676054\n",
      "Iteration 10592 => Loss: 50.28596341962303029050\n",
      "Iteration 10593 => Loss: 50.28576920686805351579\n",
      "Iteration 10594 => Loss: 50.28557499563729038528\n",
      "Iteration 10595 => Loss: 50.28538078593067695010\n",
      "Iteration 10596 => Loss: 50.28518657774820610484\n",
      "Iteration 10597 => Loss: 50.28499237108986363864\n",
      "Iteration 10598 => Loss: 50.28479816595568507864\n",
      "Iteration 10599 => Loss: 50.28460396234556384343\n",
      "Iteration 10600 => Loss: 50.28440976025959230356\n",
      "Iteration 10601 => Loss: 50.28421555969768519390\n",
      "Iteration 10602 => Loss: 50.28402136065983540902\n",
      "Iteration 10603 => Loss: 50.28382716314608558150\n",
      "Iteration 10604 => Loss: 50.28363296715636465706\n",
      "Iteration 10605 => Loss: 50.28343877269071526825\n",
      "Iteration 10606 => Loss: 50.28324457974906636082\n",
      "Iteration 10607 => Loss: 50.28305038833144635646\n",
      "Iteration 10608 => Loss: 50.28285619843783393890\n",
      "Iteration 10609 => Loss: 50.28266201006821489727\n",
      "Iteration 10610 => Loss: 50.28246782322257502074\n",
      "Iteration 10611 => Loss: 50.28227363790088588757\n",
      "Iteration 10612 => Loss: 50.28207945410319013035\n",
      "Iteration 10613 => Loss: 50.28188527182941669480\n",
      "Iteration 10614 => Loss: 50.28169109107957268634\n",
      "Iteration 10615 => Loss: 50.28149691185367942126\n",
      "Iteration 10616 => Loss: 50.28130273415166584527\n",
      "Iteration 10617 => Loss: 50.28110855797356748553\n",
      "Iteration 10618 => Loss: 50.28091438331934170947\n",
      "Iteration 10619 => Loss: 50.28072021018898851707\n",
      "Iteration 10620 => Loss: 50.28052603858250080293\n",
      "Iteration 10621 => Loss: 50.28033186849986435618\n",
      "Iteration 10622 => Loss: 50.28013769994105786054\n",
      "Iteration 10623 => Loss: 50.27994353290609552687\n",
      "Iteration 10624 => Loss: 50.27974936739494893345\n",
      "Iteration 10625 => Loss: 50.27955520340757544773\n",
      "Iteration 10626 => Loss: 50.27936104094401770226\n",
      "Iteration 10627 => Loss: 50.27916688000424016991\n",
      "Iteration 10628 => Loss: 50.27897272058820021812\n",
      "Iteration 10629 => Loss: 50.27877856269593337402\n",
      "Iteration 10630 => Loss: 50.27858440632741121590\n",
      "Iteration 10631 => Loss: 50.27839025148261953291\n",
      "Iteration 10632 => Loss: 50.27819609816152990334\n",
      "Iteration 10633 => Loss: 50.27800194636417785432\n",
      "Iteration 10634 => Loss: 50.27780779609049233159\n",
      "Iteration 10635 => Loss: 50.27761364734049465142\n",
      "Iteration 10636 => Loss: 50.27741950011416349753\n",
      "Iteration 10637 => Loss: 50.27722535441151308078\n",
      "Iteration 10638 => Loss: 50.27703121023247234689\n",
      "Iteration 10639 => Loss: 50.27683706757709813928\n",
      "Iteration 10640 => Loss: 50.27664292644534071997\n",
      "Iteration 10641 => Loss: 50.27644878683719298351\n",
      "Iteration 10642 => Loss: 50.27625464875264071907\n",
      "Iteration 10643 => Loss: 50.27606051219166971578\n",
      "Iteration 10644 => Loss: 50.27586637715428707907\n",
      "Iteration 10645 => Loss: 50.27567224364045728180\n",
      "Iteration 10646 => Loss: 50.27547811165017321855\n",
      "Iteration 10647 => Loss: 50.27528398118342067846\n",
      "Iteration 10648 => Loss: 50.27508985224021387239\n",
      "Iteration 10649 => Loss: 50.27489572482051727320\n",
      "Iteration 10650 => Loss: 50.27470159892432377546\n",
      "Iteration 10651 => Loss: 50.27450747455162627375\n",
      "Iteration 10652 => Loss: 50.27431335170241055721\n",
      "Iteration 10653 => Loss: 50.27411923037665530956\n",
      "Iteration 10654 => Loss: 50.27392511057433921451\n",
      "Iteration 10655 => Loss: 50.27373099229550490463\n",
      "Iteration 10656 => Loss: 50.27353687554004579852\n",
      "Iteration 10657 => Loss: 50.27334276030804005586\n",
      "Iteration 10658 => Loss: 50.27314864659943083325\n",
      "Iteration 10659 => Loss: 50.27295453441422523611\n",
      "Iteration 10660 => Loss: 50.27276042375240905358\n",
      "Iteration 10661 => Loss: 50.27256631461394675853\n",
      "Iteration 10662 => Loss: 50.27237220699885256181\n",
      "Iteration 10663 => Loss: 50.27217810090711935800\n",
      "Iteration 10664 => Loss: 50.27198399633869030367\n",
      "Iteration 10665 => Loss: 50.27178989329360803140\n",
      "Iteration 10666 => Loss: 50.27159579177186543575\n",
      "Iteration 10667 => Loss: 50.27140169177337014617\n",
      "Iteration 10668 => Loss: 50.27120759329817900607\n",
      "Iteration 10669 => Loss: 50.27101349634627780461\n",
      "Iteration 10670 => Loss: 50.27081940091763101464\n",
      "Iteration 10671 => Loss: 50.27062530701223863616\n",
      "Iteration 10672 => Loss: 50.27043121463009356376\n",
      "Iteration 10673 => Loss: 50.27023712377114605943\n",
      "Iteration 10674 => Loss: 50.27004303443543875574\n",
      "Iteration 10675 => Loss: 50.26984894662292191470\n",
      "Iteration 10676 => Loss: 50.26965486033361685259\n",
      "Iteration 10677 => Loss: 50.26946077556745962056\n",
      "Iteration 10678 => Loss: 50.26926669232452127289\n",
      "Iteration 10679 => Loss: 50.26907261060469522818\n",
      "Iteration 10680 => Loss: 50.26887853040802411897\n",
      "Iteration 10681 => Loss: 50.26868445173449373442\n",
      "Iteration 10682 => Loss: 50.26849037458407565282\n",
      "Iteration 10683 => Loss: 50.26829629895677697959\n",
      "Iteration 10684 => Loss: 50.26810222485256929303\n",
      "Iteration 10685 => Loss: 50.26790815227141706600\n",
      "Iteration 10686 => Loss: 50.26771408121336293107\n",
      "Iteration 10687 => Loss: 50.26752001167837846651\n",
      "Iteration 10688 => Loss: 50.26732594366643525063\n",
      "Iteration 10689 => Loss: 50.26713187717754038886\n",
      "Iteration 10690 => Loss: 50.26693781221165124862\n",
      "Iteration 10691 => Loss: 50.26674374876878204077\n",
      "Iteration 10692 => Loss: 50.26654968684890434361\n",
      "Iteration 10693 => Loss: 50.26635562645201105170\n",
      "Iteration 10694 => Loss: 50.26616156757812348133\n",
      "Iteration 10695 => Loss: 50.26596751022718478907\n",
      "Iteration 10696 => Loss: 50.26577345439919497494\n",
      "Iteration 10697 => Loss: 50.26557940009412561722\n",
      "Iteration 10698 => Loss: 50.26538534731204066475\n",
      "Iteration 10699 => Loss: 50.26519129605284064155\n",
      "Iteration 10700 => Loss: 50.26499724631653975848\n",
      "Iteration 10701 => Loss: 50.26480319810314512097\n",
      "Iteration 10702 => Loss: 50.26460915141261409644\n",
      "Iteration 10703 => Loss: 50.26441510624497510662\n",
      "Iteration 10704 => Loss: 50.26422106260017130808\n",
      "Iteration 10705 => Loss: 50.26402702047822401710\n",
      "Iteration 10706 => Loss: 50.26383297987910481197\n",
      "Iteration 10707 => Loss: 50.26363894080280658727\n",
      "Iteration 10708 => Loss: 50.26344490324933644843\n",
      "Iteration 10709 => Loss: 50.26325086721863755201\n",
      "Iteration 10710 => Loss: 50.26305683271075253060\n",
      "Iteration 10711 => Loss: 50.26286279972561743534\n",
      "Iteration 10712 => Loss: 50.26266876826324647709\n",
      "Iteration 10713 => Loss: 50.26247473832362544499\n",
      "Iteration 10714 => Loss: 50.26228070990675433904\n",
      "Iteration 10715 => Loss: 50.26208668301259763211\n",
      "Iteration 10716 => Loss: 50.26189265764116242963\n",
      "Iteration 10717 => Loss: 50.26169863379242030987\n",
      "Iteration 10718 => Loss: 50.26150461146637127285\n",
      "Iteration 10719 => Loss: 50.26131059066300821314\n",
      "Iteration 10720 => Loss: 50.26111657138232402531\n",
      "Iteration 10721 => Loss: 50.26092255362424054965\n",
      "Iteration 10722 => Loss: 50.26072853738885015673\n",
      "Iteration 10723 => Loss: 50.26053452267607468684\n",
      "Iteration 10724 => Loss: 50.26034050948590703456\n",
      "Iteration 10725 => Loss: 50.26014649781836851616\n",
      "Iteration 10726 => Loss: 50.25995248767340228824\n",
      "Iteration 10727 => Loss: 50.25975847905102966706\n",
      "Iteration 10728 => Loss: 50.25956447195124354721\n",
      "Iteration 10729 => Loss: 50.25937046637397287441\n",
      "Iteration 10730 => Loss: 50.25917646231927449207\n",
      "Iteration 10731 => Loss: 50.25898245978711287307\n",
      "Iteration 10732 => Loss: 50.25878845877747380655\n",
      "Iteration 10733 => Loss: 50.25859445929034308165\n",
      "Iteration 10734 => Loss: 50.25840046132570648751\n",
      "Iteration 10735 => Loss: 50.25820646488357112958\n",
      "Iteration 10736 => Loss: 50.25801246996388726984\n",
      "Iteration 10737 => Loss: 50.25781847656668333002\n",
      "Iteration 10738 => Loss: 50.25762448469191667755\n",
      "Iteration 10739 => Loss: 50.25743049433962283956\n",
      "Iteration 10740 => Loss: 50.25723650550972365636\n",
      "Iteration 10741 => Loss: 50.25704251820221912794\n",
      "Iteration 10742 => Loss: 50.25684853241715899230\n",
      "Iteration 10743 => Loss: 50.25665454815449351145\n",
      "Iteration 10744 => Loss: 50.25646056541418005281\n",
      "Iteration 10745 => Loss: 50.25626658419623282725\n",
      "Iteration 10746 => Loss: 50.25607260450065183477\n",
      "Iteration 10747 => Loss: 50.25587862632741575908\n",
      "Iteration 10748 => Loss: 50.25568464967651749475\n",
      "Iteration 10749 => Loss: 50.25549067454792151466\n",
      "Iteration 10750 => Loss: 50.25529670094167045136\n",
      "Iteration 10751 => Loss: 50.25510272885767193429\n",
      "Iteration 10752 => Loss: 50.25490875829598280689\n",
      "Iteration 10753 => Loss: 50.25471478925652490943\n",
      "Iteration 10754 => Loss: 50.25452082173937640164\n",
      "Iteration 10755 => Loss: 50.25432685574445201837\n",
      "Iteration 10756 => Loss: 50.25413289127178018134\n",
      "Iteration 10757 => Loss: 50.25393892832132536341\n",
      "Iteration 10758 => Loss: 50.25374496689306624830\n",
      "Iteration 10759 => Loss: 50.25355100698701704687\n",
      "Iteration 10760 => Loss: 50.25335704860313512654\n",
      "Iteration 10761 => Loss: 50.25316309174147733074\n",
      "Iteration 10762 => Loss: 50.25296913640195128892\n",
      "Iteration 10763 => Loss: 50.25277518258459252820\n",
      "Iteration 10764 => Loss: 50.25258123028932999432\n",
      "Iteration 10765 => Loss: 50.25238727951623474155\n",
      "Iteration 10766 => Loss: 50.25219333026527834818\n",
      "Iteration 10767 => Loss: 50.25199938253637554908\n",
      "Iteration 10768 => Loss: 50.25180543632959739853\n",
      "Iteration 10769 => Loss: 50.25161149164488705310\n",
      "Iteration 10770 => Loss: 50.25141754848225161822\n",
      "Iteration 10771 => Loss: 50.25122360684166977762\n",
      "Iteration 10772 => Loss: 50.25102966672312732044\n",
      "Iteration 10773 => Loss: 50.25083572812665266838\n",
      "Iteration 10774 => Loss: 50.25064179105215345089\n",
      "Iteration 10775 => Loss: 50.25044785549965808968\n",
      "Iteration 10776 => Loss: 50.25025392146920211189\n",
      "Iteration 10777 => Loss: 50.25005998896070735782\n",
      "Iteration 10778 => Loss: 50.24986605797418803832\n",
      "Iteration 10779 => Loss: 50.24967212850961573167\n",
      "Iteration 10780 => Loss: 50.24947820056701885960\n",
      "Iteration 10781 => Loss: 50.24928427414634057868\n",
      "Iteration 10782 => Loss: 50.24909034924760220520\n",
      "Iteration 10783 => Loss: 50.24889642587077531743\n",
      "Iteration 10784 => Loss: 50.24870250401583859912\n",
      "Iteration 10785 => Loss: 50.24850858368278494481\n",
      "Iteration 10786 => Loss: 50.24831466487162856538\n",
      "Iteration 10787 => Loss: 50.24812074758232682825\n",
      "Iteration 10788 => Loss: 50.24792683181488683886\n",
      "Iteration 10789 => Loss: 50.24773291756925885920\n",
      "Iteration 10790 => Loss: 50.24753900484550683814\n",
      "Iteration 10791 => Loss: 50.24734509364353129968\n",
      "Iteration 10792 => Loss: 50.24715118396341040352\n",
      "Iteration 10793 => Loss: 50.24695727580504467369\n",
      "Iteration 10794 => Loss: 50.24676336916846253189\n",
      "Iteration 10795 => Loss: 50.24656946405366397812\n",
      "Iteration 10796 => Loss: 50.24637556046060637982\n",
      "Iteration 10797 => Loss: 50.24618165838930394784\n",
      "Iteration 10798 => Loss: 50.24598775783972826048\n",
      "Iteration 10799 => Loss: 50.24579385881188642315\n",
      "Iteration 10800 => Loss: 50.24559996130575001416\n",
      "Iteration 10801 => Loss: 50.24540606532131903350\n",
      "Iteration 10802 => Loss: 50.24521217085856505946\n",
      "Iteration 10803 => Loss: 50.24501827791748809204\n",
      "Iteration 10804 => Loss: 50.24482438649807392039\n",
      "Iteration 10805 => Loss: 50.24463049660030833365\n",
      "Iteration 10806 => Loss: 50.24443660822419133183\n",
      "Iteration 10807 => Loss: 50.24424272136968028235\n",
      "Iteration 10808 => Loss: 50.24404883603680360693\n",
      "Iteration 10809 => Loss: 50.24385495222551867300\n",
      "Iteration 10810 => Loss: 50.24366106993583258600\n",
      "Iteration 10811 => Loss: 50.24346718916770981878\n",
      "Iteration 10812 => Loss: 50.24327330992117879305\n",
      "Iteration 10813 => Loss: 50.24307943219617555997\n",
      "Iteration 10814 => Loss: 50.24288555599273564667\n",
      "Iteration 10815 => Loss: 50.24269168131081642059\n",
      "Iteration 10816 => Loss: 50.24249780815041077631\n",
      "Iteration 10817 => Loss: 50.24230393651152581924\n",
      "Iteration 10818 => Loss: 50.24211006639412602226\n",
      "Iteration 10819 => Loss: 50.24191619779821849079\n",
      "Iteration 10820 => Loss: 50.24172233072379611940\n",
      "Iteration 10821 => Loss: 50.24152846517080917010\n",
      "Iteration 10822 => Loss: 50.24133460113926474833\n",
      "Iteration 10823 => Loss: 50.24114073862916995949\n",
      "Iteration 10824 => Loss: 50.24094687764048927647\n",
      "Iteration 10825 => Loss: 50.24075301817322269926\n",
      "Iteration 10826 => Loss: 50.24055916022736312243\n",
      "Iteration 10827 => Loss: 50.24036530380291054598\n",
      "Iteration 10828 => Loss: 50.24017144889978681022\n",
      "Iteration 10829 => Loss: 50.23997759551806296940\n",
      "Iteration 10830 => Loss: 50.23978374365766796927\n",
      "Iteration 10831 => Loss: 50.23958989331863023153\n",
      "Iteration 10832 => Loss: 50.23939604450091422905\n",
      "Iteration 10833 => Loss: 50.23920219720451285639\n",
      "Iteration 10834 => Loss: 50.23900835142941900813\n",
      "Iteration 10835 => Loss: 50.23881450717562557884\n",
      "Iteration 10836 => Loss: 50.23862066444308283053\n",
      "Iteration 10837 => Loss: 50.23842682323184050119\n",
      "Iteration 10838 => Loss: 50.23823298354184174741\n",
      "Iteration 10839 => Loss: 50.23803914537308656918\n",
      "Iteration 10840 => Loss: 50.23784530872556075565\n",
      "Iteration 10841 => Loss: 50.23765147359926430681\n",
      "Iteration 10842 => Loss: 50.23745763999415459011\n",
      "Iteration 10843 => Loss: 50.23726380791027423811\n",
      "Iteration 10844 => Loss: 50.23706997734757351282\n",
      "Iteration 10845 => Loss: 50.23687614830602399252\n",
      "Iteration 10846 => Loss: 50.23668232078563278264\n",
      "Iteration 10847 => Loss: 50.23648849478642119948\n",
      "Iteration 10848 => Loss: 50.23629467030833239960\n",
      "Iteration 10849 => Loss: 50.23610084735135927758\n",
      "Iteration 10850 => Loss: 50.23590702591551604428\n",
      "Iteration 10851 => Loss: 50.23571320600076717255\n",
      "Iteration 10852 => Loss: 50.23551938760710555698\n",
      "Iteration 10853 => Loss: 50.23532557073453119756\n",
      "Iteration 10854 => Loss: 50.23513175538298014544\n",
      "Iteration 10855 => Loss: 50.23493794155252345490\n",
      "Iteration 10856 => Loss: 50.23474412924309717710\n",
      "Iteration 10857 => Loss: 50.23455031845471552288\n",
      "Iteration 10858 => Loss: 50.23435650918732164882\n",
      "Iteration 10859 => Loss: 50.23416270144095818750\n",
      "Iteration 10860 => Loss: 50.23396889521556829550\n",
      "Iteration 10861 => Loss: 50.23377509051117328909\n",
      "Iteration 10862 => Loss: 50.23358128732775895742\n",
      "Iteration 10863 => Loss: 50.23338748566529687878\n",
      "Iteration 10864 => Loss: 50.23319368552376573689\n",
      "Iteration 10865 => Loss: 50.23299988690315842632\n",
      "Iteration 10866 => Loss: 50.23280608980348915793\n",
      "Iteration 10867 => Loss: 50.23261229422474372086\n",
      "Iteration 10868 => Loss: 50.23241850016689369340\n",
      "Iteration 10869 => Loss: 50.23222470762990354842\n",
      "Iteration 10870 => Loss: 50.23203091661380881305\n",
      "Iteration 10871 => Loss: 50.23183712711858106559\n",
      "Iteration 10872 => Loss: 50.23164333914420609517\n",
      "Iteration 10873 => Loss: 50.23144955269064837466\n",
      "Iteration 10874 => Loss: 50.23125576775791500950\n",
      "Iteration 10875 => Loss: 50.23106198434603442138\n",
      "Iteration 10876 => Loss: 50.23086820245491423975\n",
      "Iteration 10877 => Loss: 50.23067442208459709718\n",
      "Iteration 10878 => Loss: 50.23048064323506878281\n",
      "Iteration 10879 => Loss: 50.23028686590630087494\n",
      "Iteration 10880 => Loss: 50.23009309009829337356\n",
      "Iteration 10881 => Loss: 50.22989931581103206781\n",
      "Iteration 10882 => Loss: 50.22970554304450985228\n",
      "Iteration 10883 => Loss: 50.22951177179867698896\n",
      "Iteration 10884 => Loss: 50.22931800207356189958\n",
      "Iteration 10885 => Loss: 50.22912423386915037327\n",
      "Iteration 10886 => Loss: 50.22893046718539977746\n",
      "Iteration 10887 => Loss: 50.22873670202234563931\n",
      "Iteration 10888 => Loss: 50.22854293837995243166\n",
      "Iteration 10889 => Loss: 50.22834917625820594367\n",
      "Iteration 10890 => Loss: 50.22815541565707064819\n",
      "Iteration 10891 => Loss: 50.22796165657658207238\n",
      "Iteration 10892 => Loss: 50.22776789901671179450\n",
      "Iteration 10893 => Loss: 50.22757414297742428744\n",
      "Iteration 10894 => Loss: 50.22738038845871955118\n",
      "Iteration 10895 => Loss: 50.22718663546060469116\n",
      "Iteration 10896 => Loss: 50.22699288398305128567\n",
      "Iteration 10897 => Loss: 50.22679913402602380756\n",
      "Iteration 10898 => Loss: 50.22660538558957910027\n",
      "Iteration 10899 => Loss: 50.22641163867363900408\n",
      "Iteration 10900 => Loss: 50.22621789327822483529\n",
      "Iteration 10901 => Loss: 50.22602414940330817217\n",
      "Iteration 10902 => Loss: 50.22583040704891033101\n",
      "Iteration 10903 => Loss: 50.22563666621493894127\n",
      "Iteration 10904 => Loss: 50.22544292690149347891\n",
      "Iteration 10905 => Loss: 50.22524918910846025710\n",
      "Iteration 10906 => Loss: 50.22505545283588190841\n",
      "Iteration 10907 => Loss: 50.22486171808375843284\n",
      "Iteration 10908 => Loss: 50.22466798485204009239\n",
      "Iteration 10909 => Loss: 50.22447425314074820335\n",
      "Iteration 10910 => Loss: 50.22428052294980460601\n",
      "Iteration 10911 => Loss: 50.22408679427928746009\n",
      "Iteration 10912 => Loss: 50.22389306712913992214\n",
      "Iteration 10913 => Loss: 50.22369934149931935963\n",
      "Iteration 10914 => Loss: 50.22350561738989682681\n",
      "Iteration 10915 => Loss: 50.22331189480077284770\n",
      "Iteration 10916 => Loss: 50.22311817373201137116\n",
      "Iteration 10917 => Loss: 50.22292445418354134290\n",
      "Iteration 10918 => Loss: 50.22273073615536986836\n",
      "Iteration 10919 => Loss: 50.22253701964748984210\n",
      "Iteration 10920 => Loss: 50.22234330465990836956\n",
      "Iteration 10921 => Loss: 50.22214959119256860731\n",
      "Iteration 10922 => Loss: 50.22195587924549187164\n",
      "Iteration 10923 => Loss: 50.22176216881865684627\n",
      "Iteration 10924 => Loss: 50.22156845991204221491\n",
      "Iteration 10925 => Loss: 50.22137475252564797756\n",
      "Iteration 10926 => Loss: 50.22118104665946702880\n",
      "Iteration 10927 => Loss: 50.22098734231347805235\n",
      "Iteration 10928 => Loss: 50.22079363948765973191\n",
      "Iteration 10929 => Loss: 50.22059993818202627835\n",
      "Iteration 10930 => Loss: 50.22040623839654926996\n",
      "Iteration 10931 => Loss: 50.22021254013121449589\n",
      "Iteration 10932 => Loss: 50.22001884338600774527\n",
      "Iteration 10933 => Loss: 50.21982514816092901810\n",
      "Iteration 10934 => Loss: 50.21963145445596410354\n",
      "Iteration 10935 => Loss: 50.21943776227110589616\n",
      "Iteration 10936 => Loss: 50.21924407160632597424\n",
      "Iteration 10937 => Loss: 50.21905038246161723237\n",
      "Iteration 10938 => Loss: 50.21885669483696545967\n",
      "Iteration 10939 => Loss: 50.21866300873237065616\n",
      "Iteration 10940 => Loss: 50.21846932414780440013\n",
      "Iteration 10941 => Loss: 50.21827564108330221870\n",
      "Iteration 10942 => Loss: 50.21808195953879305762\n",
      "Iteration 10943 => Loss: 50.21788827951428402230\n",
      "Iteration 10944 => Loss: 50.21769460100974669103\n",
      "Iteration 10945 => Loss: 50.21750092402521659096\n",
      "Iteration 10946 => Loss: 50.21730724856065819495\n",
      "Iteration 10947 => Loss: 50.21711357461605018671\n",
      "Iteration 10948 => Loss: 50.21691990219136414453\n",
      "Iteration 10949 => Loss: 50.21672623128662138470\n",
      "Iteration 10950 => Loss: 50.21653256190180769636\n",
      "Iteration 10951 => Loss: 50.21633889403690176323\n",
      "Iteration 10952 => Loss: 50.21614522769186805817\n",
      "Iteration 10953 => Loss: 50.21595156286674210833\n",
      "Iteration 10954 => Loss: 50.21575789956148838655\n",
      "Iteration 10955 => Loss: 50.21556423777608557657\n",
      "Iteration 10956 => Loss: 50.21537057751052657295\n",
      "Iteration 10957 => Loss: 50.21517691876480427027\n",
      "Iteration 10958 => Loss: 50.21498326153892577395\n",
      "Iteration 10959 => Loss: 50.21478960583284134600\n",
      "Iteration 10960 => Loss: 50.21459595164657230271\n",
      "Iteration 10961 => Loss: 50.21440229898007601150\n",
      "Iteration 10962 => Loss: 50.21420864783335247239\n",
      "Iteration 10963 => Loss: 50.21401499820642300165\n",
      "Iteration 10964 => Loss: 50.21382135009921654500\n",
      "Iteration 10965 => Loss: 50.21362770351174020789\n",
      "Iteration 10966 => Loss: 50.21343405844404372829\n",
      "Iteration 10967 => Loss: 50.21324041489600631394\n",
      "Iteration 10968 => Loss: 50.21304677286771322997\n",
      "Iteration 10969 => Loss: 50.21285313235909342211\n",
      "Iteration 10970 => Loss: 50.21265949337017531207\n",
      "Iteration 10971 => Loss: 50.21246585590090205642\n",
      "Iteration 10972 => Loss: 50.21227221995129497145\n",
      "Iteration 10973 => Loss: 50.21207858552133274088\n",
      "Iteration 10974 => Loss: 50.21188495261100115385\n",
      "Iteration 10975 => Loss: 50.21169132122030731580\n",
      "Iteration 10976 => Loss: 50.21149769134920148872\n",
      "Iteration 10977 => Loss: 50.21130406299771209433\n",
      "Iteration 10978 => Loss: 50.21111043616578939464\n",
      "Iteration 10979 => Loss: 50.21091681085345470592\n",
      "Iteration 10980 => Loss: 50.21072318706068671190\n",
      "Iteration 10981 => Loss: 50.21052956478744988544\n",
      "Iteration 10982 => Loss: 50.21033594403375843740\n",
      "Iteration 10983 => Loss: 50.21014232479959105149\n",
      "Iteration 10984 => Loss: 50.20994870708495483314\n",
      "Iteration 10985 => Loss: 50.20975509088979293892\n",
      "Iteration 10986 => Loss: 50.20956147621415510685\n",
      "Iteration 10987 => Loss: 50.20936786305794896634\n",
      "Iteration 10988 => Loss: 50.20917425142125267712\n",
      "Iteration 10989 => Loss: 50.20898064130400229033\n",
      "Iteration 10990 => Loss: 50.20878703270616938426\n",
      "Iteration 10991 => Loss: 50.20859342562779659147\n",
      "Iteration 10992 => Loss: 50.20839982006884127941\n",
      "Iteration 10993 => Loss: 50.20820621602928213179\n",
      "Iteration 10994 => Loss: 50.20801261350911204318\n",
      "Iteration 10995 => Loss: 50.20781901250833811901\n",
      "Iteration 10996 => Loss: 50.20762541302693904299\n",
      "Iteration 10997 => Loss: 50.20743181506486507715\n",
      "Iteration 10998 => Loss: 50.20723821862216595946\n",
      "Iteration 10999 => Loss: 50.20704462369880616279\n",
      "Iteration 11000 => Loss: 50.20685103029474305458\n",
      "Iteration 11001 => Loss: 50.20665743841002637282\n",
      "Iteration 11002 => Loss: 50.20646384804459216866\n",
      "Iteration 11003 => Loss: 50.20627025919842623125\n",
      "Iteration 11004 => Loss: 50.20607667187156408772\n",
      "Iteration 11005 => Loss: 50.20588308606396310552\n",
      "Iteration 11006 => Loss: 50.20568950177560907377\n",
      "Iteration 11007 => Loss: 50.20549591900648067622\n",
      "Iteration 11008 => Loss: 50.20530233775660633455\n",
      "Iteration 11009 => Loss: 50.20510875802592920536\n",
      "Iteration 11010 => Loss: 50.20491517981447060492\n",
      "Iteration 11011 => Loss: 50.20472160312218079525\n",
      "Iteration 11012 => Loss: 50.20452802794910240891\n",
      "Iteration 11013 => Loss: 50.20433445429515728620\n",
      "Iteration 11014 => Loss: 50.20414088216038805967\n",
      "Iteration 11015 => Loss: 50.20394731154476630763\n",
      "Iteration 11016 => Loss: 50.20375374244826360837\n",
      "Iteration 11017 => Loss: 50.20356017487088706730\n",
      "Iteration 11018 => Loss: 50.20336660881262247358\n",
      "Iteration 11019 => Loss: 50.20317304427346272178\n",
      "Iteration 11020 => Loss: 50.20297948125338649561\n",
      "Iteration 11021 => Loss: 50.20278591975237247880\n",
      "Iteration 11022 => Loss: 50.20259235977042067134\n",
      "Iteration 11023 => Loss: 50.20239880130748844067\n",
      "Iteration 11024 => Loss: 50.20220524436366815735\n",
      "Iteration 11025 => Loss: 50.20201168893881771282\n",
      "Iteration 11026 => Loss: 50.20181813503298684509\n",
      "Iteration 11027 => Loss: 50.20162458264618265957\n",
      "Iteration 11028 => Loss: 50.20143103177832699657\n",
      "Iteration 11029 => Loss: 50.20123748242946959408\n",
      "Iteration 11030 => Loss: 50.20104393459958913581\n",
      "Iteration 11031 => Loss: 50.20085038828865720006\n",
      "Iteration 11032 => Loss: 50.20065684349665247055\n",
      "Iteration 11033 => Loss: 50.20046330022358205269\n",
      "Iteration 11034 => Loss: 50.20026975846943884108\n",
      "Iteration 11035 => Loss: 50.20007621823418730855\n",
      "Iteration 11036 => Loss: 50.19988267951786298227\n",
      "Iteration 11037 => Loss: 50.19968914232037349166\n",
      "Iteration 11038 => Loss: 50.19949560664177568015\n",
      "Iteration 11039 => Loss: 50.19930207248204823145\n",
      "Iteration 11040 => Loss: 50.19910853984116272386\n",
      "Iteration 11041 => Loss: 50.19891500871909073567\n",
      "Iteration 11042 => Loss: 50.19872147911586068858\n",
      "Iteration 11043 => Loss: 50.19852795103145126632\n",
      "Iteration 11044 => Loss: 50.19833442446581983631\n",
      "Iteration 11045 => Loss: 50.19814089941898771485\n",
      "Iteration 11046 => Loss: 50.19794737589091226937\n",
      "Iteration 11047 => Loss: 50.19775385388160771072\n",
      "Iteration 11048 => Loss: 50.19756033339107403890\n",
      "Iteration 11049 => Loss: 50.19736681441926151592\n",
      "Iteration 11050 => Loss: 50.19717329696617724721\n",
      "Iteration 11051 => Loss: 50.19697978103180702192\n",
      "Iteration 11052 => Loss: 50.19678626661614373461\n",
      "Iteration 11053 => Loss: 50.19659275371919449071\n",
      "Iteration 11054 => Loss: 50.19639924234088113053\n",
      "Iteration 11055 => Loss: 50.19620573248125339205\n",
      "Iteration 11056 => Loss: 50.19601222414028285357\n",
      "Iteration 11057 => Loss: 50.19581871731794819880\n",
      "Iteration 11058 => Loss: 50.19562521201427074402\n",
      "Iteration 11059 => Loss: 50.19543170822920075125\n",
      "Iteration 11060 => Loss: 50.19523820596273822048\n",
      "Iteration 11061 => Loss: 50.19504470521484051915\n",
      "Iteration 11062 => Loss: 50.19485120598558580696\n",
      "Iteration 11063 => Loss: 50.19465770827486750250\n",
      "Iteration 11064 => Loss: 50.19446421208269271119\n",
      "Iteration 11065 => Loss: 50.19427071740909696018\n",
      "Iteration 11066 => Loss: 50.19407722425403051147\n",
      "Iteration 11067 => Loss: 50.19388373261750047050\n",
      "Iteration 11068 => Loss: 50.19369024249944999383\n",
      "Iteration 11069 => Loss: 50.19349675389991460861\n",
      "Iteration 11070 => Loss: 50.19330326681888010398\n",
      "Iteration 11071 => Loss: 50.19310978125631805824\n",
      "Iteration 11072 => Loss: 50.19291629721220715510\n",
      "Iteration 11073 => Loss: 50.19272281468656871084\n",
      "Iteration 11074 => Loss: 50.19252933367936009290\n",
      "Iteration 11075 => Loss: 50.19233585419057419585\n",
      "Iteration 11076 => Loss: 50.19214237622021101970\n",
      "Iteration 11077 => Loss: 50.19194889976826345901\n",
      "Iteration 11078 => Loss: 50.19175542483471730293\n",
      "Iteration 11079 => Loss: 50.19156195141951570804\n",
      "Iteration 11080 => Loss: 50.19136847952271551776\n",
      "Iteration 11081 => Loss: 50.19117500914425988867\n",
      "Iteration 11082 => Loss: 50.19098154028414882077\n",
      "Iteration 11083 => Loss: 50.19078807294238231407\n",
      "Iteration 11084 => Loss: 50.19059460711892484142\n",
      "Iteration 11085 => Loss: 50.19040114281379061367\n",
      "Iteration 11086 => Loss: 50.19020768002695120913\n",
      "Iteration 11087 => Loss: 50.19001421875840662779\n",
      "Iteration 11088 => Loss: 50.18982075900812134250\n",
      "Iteration 11089 => Loss: 50.18962730077610245871\n",
      "Iteration 11090 => Loss: 50.18943384406232866013\n",
      "Iteration 11091 => Loss: 50.18924038886680705218\n",
      "Iteration 11092 => Loss: 50.18904693518949500231\n",
      "Iteration 11093 => Loss: 50.18885348303040672135\n",
      "Iteration 11094 => Loss: 50.18866003238952089305\n",
      "Iteration 11095 => Loss: 50.18846658326682330653\n",
      "Iteration 11096 => Loss: 50.18827313566229264552\n",
      "Iteration 11097 => Loss: 50.18807968957595733173\n",
      "Iteration 11098 => Loss: 50.18788624500776762716\n",
      "Iteration 11099 => Loss: 50.18769280195769511010\n",
      "Iteration 11100 => Loss: 50.18749936042577530770\n",
      "Iteration 11101 => Loss: 50.18730592041200821996\n",
      "Iteration 11102 => Loss: 50.18711248191630858173\n",
      "Iteration 11103 => Loss: 50.18691904493869060389\n",
      "Iteration 11104 => Loss: 50.18672560947919691898\n",
      "Iteration 11105 => Loss: 50.18653217553774936732\n",
      "Iteration 11106 => Loss: 50.18633874311437637061\n",
      "Iteration 11107 => Loss: 50.18614531220902819086\n",
      "Iteration 11108 => Loss: 50.18595188282174035521\n",
      "Iteration 11109 => Loss: 50.18575845495246312566\n",
      "Iteration 11110 => Loss: 50.18556502860119650222\n",
      "Iteration 11111 => Loss: 50.18537160376794048489\n",
      "Iteration 11112 => Loss: 50.18517818045266665195\n",
      "Iteration 11113 => Loss: 50.18498475865536789797\n",
      "Iteration 11114 => Loss: 50.18479133837603711754\n",
      "Iteration 11115 => Loss: 50.18459791961465299437\n",
      "Iteration 11116 => Loss: 50.18440450237121552846\n",
      "Iteration 11117 => Loss: 50.18421108664570340352\n",
      "Iteration 11118 => Loss: 50.18401767243809530328\n",
      "Iteration 11119 => Loss: 50.18382425974841964944\n",
      "Iteration 11120 => Loss: 50.18363084857661249316\n",
      "Iteration 11121 => Loss: 50.18343743892270936158\n",
      "Iteration 11122 => Loss: 50.18324403078666051670\n",
      "Iteration 11123 => Loss: 50.18305062416846595852\n",
      "Iteration 11124 => Loss: 50.18285721906813989790\n",
      "Iteration 11125 => Loss: 50.18266381548562549142\n",
      "Iteration 11126 => Loss: 50.18247041342094405536\n",
      "Iteration 11127 => Loss: 50.18227701287406006259\n",
      "Iteration 11128 => Loss: 50.18208361384498772395\n",
      "Iteration 11129 => Loss: 50.18189021633367730146\n",
      "Iteration 11130 => Loss: 50.18169682034015721683\n",
      "Iteration 11131 => Loss: 50.18150342586439904835\n",
      "Iteration 11132 => Loss: 50.18131003290639569059\n",
      "Iteration 11133 => Loss: 50.18111664146611872184\n",
      "Iteration 11134 => Loss: 50.18092325154356814210\n",
      "Iteration 11135 => Loss: 50.18072986313875105679\n",
      "Iteration 11136 => Loss: 50.18053647625161772794\n",
      "Iteration 11137 => Loss: 50.18034309088218236639\n",
      "Iteration 11138 => Loss: 50.18014970703041655042\n",
      "Iteration 11139 => Loss: 50.17995632469632738548\n",
      "Iteration 11140 => Loss: 50.17976294387987934442\n",
      "Iteration 11141 => Loss: 50.17956956458110084895\n",
      "Iteration 11142 => Loss: 50.17937618679994216109\n",
      "Iteration 11143 => Loss: 50.17918281053638196454\n",
      "Iteration 11144 => Loss: 50.17898943579045578645\n",
      "Iteration 11145 => Loss: 50.17879606256210678339\n",
      "Iteration 11146 => Loss: 50.17860269085135627165\n",
      "Iteration 11147 => Loss: 50.17840932065815451324\n",
      "Iteration 11148 => Loss: 50.17821595198254414072\n",
      "Iteration 11149 => Loss: 50.17802258482446120524\n",
      "Iteration 11150 => Loss: 50.17782921918390570681\n",
      "Iteration 11151 => Loss: 50.17763585506088475086\n",
      "Iteration 11152 => Loss: 50.17744249245537702109\n",
      "Iteration 11153 => Loss: 50.17724913136738962294\n",
      "Iteration 11154 => Loss: 50.17705577179685860756\n",
      "Iteration 11155 => Loss: 50.17686241374380529123\n",
      "Iteration 11156 => Loss: 50.17666905720821546311\n",
      "Iteration 11157 => Loss: 50.17647570219008912318\n",
      "Iteration 11158 => Loss: 50.17628234868941916602\n",
      "Iteration 11159 => Loss: 50.17608899670614874822\n",
      "Iteration 11160 => Loss: 50.17589564624029918605\n",
      "Iteration 11161 => Loss: 50.17570229729185626866\n",
      "Iteration 11162 => Loss: 50.17550894986082710147\n",
      "Iteration 11163 => Loss: 50.17531560394715484108\n",
      "Iteration 11164 => Loss: 50.17512225955086790918\n",
      "Iteration 11165 => Loss: 50.17492891667192367322\n",
      "Iteration 11166 => Loss: 50.17473557531032923862\n",
      "Iteration 11167 => Loss: 50.17454223546605618367\n",
      "Iteration 11168 => Loss: 50.17434889713914003551\n",
      "Iteration 11169 => Loss: 50.17415556032948842358\n",
      "Iteration 11170 => Loss: 50.17396222503715108587\n",
      "Iteration 11171 => Loss: 50.17376889126210670611\n",
      "Iteration 11172 => Loss: 50.17357555900436238971\n",
      "Iteration 11173 => Loss: 50.17338222826383287156\n",
      "Iteration 11174 => Loss: 50.17318889904057499507\n",
      "Iteration 11175 => Loss: 50.17299557133455323310\n",
      "Iteration 11176 => Loss: 50.17280224514575337480\n",
      "Iteration 11177 => Loss: 50.17260892047415410389\n",
      "Iteration 11178 => Loss: 50.17241559731977673664\n",
      "Iteration 11179 => Loss: 50.17222227568259285135\n",
      "Iteration 11180 => Loss: 50.17202895556259534260\n",
      "Iteration 11181 => Loss: 50.17183563695973447238\n",
      "Iteration 11182 => Loss: 50.17164231987404576785\n",
      "Iteration 11183 => Loss: 50.17144900430550080728\n",
      "Iteration 11184 => Loss: 50.17125569025406406354\n",
      "Iteration 11185 => Loss: 50.17106237771977816919\n",
      "Iteration 11186 => Loss: 50.17086906670256496454\n",
      "Iteration 11187 => Loss: 50.17067575720249550386\n",
      "Iteration 11188 => Loss: 50.17048244921945610031\n",
      "Iteration 11189 => Loss: 50.17028914275352491359\n",
      "Iteration 11190 => Loss: 50.17009583780463799485\n",
      "Iteration 11191 => Loss: 50.16990253437281666038\n",
      "Iteration 11192 => Loss: 50.16970923245798985590\n",
      "Iteration 11193 => Loss: 50.16951593206022863569\n",
      "Iteration 11194 => Loss: 50.16932263317946194547\n",
      "Iteration 11195 => Loss: 50.16912933581568267982\n",
      "Iteration 11196 => Loss: 50.16893603996892636587\n",
      "Iteration 11197 => Loss: 50.16874274563911484393\n",
      "Iteration 11198 => Loss: 50.16854945282627653569\n",
      "Iteration 11199 => Loss: 50.16835616153039012488\n",
      "Iteration 11200 => Loss: 50.16816287175144140065\n",
      "Iteration 11201 => Loss: 50.16796958348943746842\n",
      "Iteration 11202 => Loss: 50.16777629674433569562\n",
      "Iteration 11203 => Loss: 50.16758301151613608226\n",
      "Iteration 11204 => Loss: 50.16738972780482441749\n",
      "Iteration 11205 => Loss: 50.16719644561040780673\n",
      "Iteration 11206 => Loss: 50.16700316493285072283\n",
      "Iteration 11207 => Loss: 50.16680988577215316582\n",
      "Iteration 11208 => Loss: 50.16661660812830092482\n",
      "Iteration 11209 => Loss: 50.16642333200129399984\n",
      "Iteration 11210 => Loss: 50.16623005739108975831\n",
      "Iteration 11211 => Loss: 50.16603678429768820024\n",
      "Iteration 11212 => Loss: 50.16584351272110353648\n",
      "Iteration 11213 => Loss: 50.16565024266130023989\n",
      "Iteration 11214 => Loss: 50.16545697411826409962\n",
      "Iteration 11215 => Loss: 50.16526370709198801023\n",
      "Iteration 11216 => Loss: 50.16507044158247197174\n",
      "Iteration 11217 => Loss: 50.16487717758969466786\n",
      "Iteration 11218 => Loss: 50.16468391511363478230\n",
      "Iteration 11219 => Loss: 50.16449065415430652592\n",
      "Iteration 11220 => Loss: 50.16429739471164594988\n",
      "Iteration 11221 => Loss: 50.16410413678570279217\n",
      "Iteration 11222 => Loss: 50.16391088037642731479\n",
      "Iteration 11223 => Loss: 50.16371762548383372859\n",
      "Iteration 11224 => Loss: 50.16352437210786519017\n",
      "Iteration 11225 => Loss: 50.16333112024857143751\n",
      "Iteration 11226 => Loss: 50.16313786990588852177\n",
      "Iteration 11227 => Loss: 50.16294462107981644294\n",
      "Iteration 11228 => Loss: 50.16275137377036941189\n",
      "Iteration 11229 => Loss: 50.16255812797751900689\n",
      "Iteration 11230 => Loss: 50.16236488370124391167\n",
      "Iteration 11231 => Loss: 50.16217164094153702081\n",
      "Iteration 11232 => Loss: 50.16197839969839833429\n",
      "Iteration 11233 => Loss: 50.16178515997180653585\n",
      "Iteration 11234 => Loss: 50.16159192176174741462\n",
      "Iteration 11235 => Loss: 50.16139868506820675975\n",
      "Iteration 11236 => Loss: 50.16120544989118457124\n",
      "Iteration 11237 => Loss: 50.16101221623065953281\n",
      "Iteration 11238 => Loss: 50.16081898408660322275\n",
      "Iteration 11239 => Loss: 50.16062575345906537905\n",
      "Iteration 11240 => Loss: 50.16043252434796073658\n",
      "Iteration 11241 => Loss: 50.16023929675333192790\n",
      "Iteration 11242 => Loss: 50.16004607067510789875\n",
      "Iteration 11243 => Loss: 50.15985284611333838711\n",
      "Iteration 11244 => Loss: 50.15965962306797365500\n",
      "Iteration 11245 => Loss: 50.15946640153902080783\n",
      "Iteration 11246 => Loss: 50.15927318152645142391\n",
      "Iteration 11247 => Loss: 50.15907996303027260865\n",
      "Iteration 11248 => Loss: 50.15888674605044883492\n",
      "Iteration 11249 => Loss: 50.15869353058700852444\n",
      "Iteration 11250 => Loss: 50.15850031663988772834\n",
      "Iteration 11251 => Loss: 50.15830710420912907921\n",
      "Iteration 11252 => Loss: 50.15811389329466862819\n",
      "Iteration 11253 => Loss: 50.15792068389651348070\n",
      "Iteration 11254 => Loss: 50.15772747601464942591\n",
      "Iteration 11255 => Loss: 50.15753426964909778007\n",
      "Iteration 11256 => Loss: 50.15734106479980169979\n",
      "Iteration 11257 => Loss: 50.15714786146678250134\n",
      "Iteration 11258 => Loss: 50.15695465965000465758\n",
      "Iteration 11259 => Loss: 50.15676145934946106308\n",
      "Iteration 11260 => Loss: 50.15656826056514461243\n",
      "Iteration 11261 => Loss: 50.15637506329704109476\n",
      "Iteration 11262 => Loss: 50.15618186754514340464\n",
      "Iteration 11263 => Loss: 50.15598867330943733123\n",
      "Iteration 11264 => Loss: 50.15579548058990155823\n",
      "Iteration 11265 => Loss: 50.15560228938653608566\n",
      "Iteration 11266 => Loss: 50.15540909969931959722\n",
      "Iteration 11267 => Loss: 50.15521591152827340920\n",
      "Iteration 11268 => Loss: 50.15502272487334067819\n",
      "Iteration 11269 => Loss: 50.15482953973452850960\n",
      "Iteration 11270 => Loss: 50.15463635611182979801\n",
      "Iteration 11271 => Loss: 50.15444317400521612171\n",
      "Iteration 11272 => Loss: 50.15424999341467326985\n",
      "Iteration 11273 => Loss: 50.15405681434021545329\n",
      "Iteration 11274 => Loss: 50.15386363678183556658\n",
      "Iteration 11275 => Loss: 50.15367046073949097718\n",
      "Iteration 11276 => Loss: 50.15347728621316036879\n",
      "Iteration 11277 => Loss: 50.15328411320285084685\n",
      "Iteration 11278 => Loss: 50.15309094170857662220\n",
      "Iteration 11279 => Loss: 50.15289777173030927315\n",
      "Iteration 11280 => Loss: 50.15270460326802748341\n",
      "Iteration 11281 => Loss: 50.15251143632169572584\n",
      "Iteration 11282 => Loss: 50.15231827089133531672\n",
      "Iteration 11283 => Loss: 50.15212510697692493977\n",
      "Iteration 11284 => Loss: 50.15193194457850012213\n",
      "Iteration 11285 => Loss: 50.15173878369596138782\n",
      "Iteration 11286 => Loss: 50.15154562432935136940\n",
      "Iteration 11287 => Loss: 50.15135246647864164515\n",
      "Iteration 11288 => Loss: 50.15115931014382510966\n",
      "Iteration 11289 => Loss: 50.15096615532489465750\n",
      "Iteration 11290 => Loss: 50.15077300202181476152\n",
      "Iteration 11291 => Loss: 50.15057985023462094887\n",
      "Iteration 11292 => Loss: 50.15038669996324927070\n",
      "Iteration 11293 => Loss: 50.15019355120772814871\n",
      "Iteration 11294 => Loss: 50.15000040396801495035\n",
      "Iteration 11295 => Loss: 50.14980725824411678104\n",
      "Iteration 11296 => Loss: 50.14961411403602653536\n",
      "Iteration 11297 => Loss: 50.14942097134370158074\n",
      "Iteration 11298 => Loss: 50.14922783016716323345\n",
      "Iteration 11299 => Loss: 50.14903469050639017723\n",
      "Iteration 11300 => Loss: 50.14884155236136109579\n",
      "Iteration 11301 => Loss: 50.14864841573206888370\n",
      "Iteration 11302 => Loss: 50.14845528061851354096\n",
      "Iteration 11303 => Loss: 50.14826214702065954043\n",
      "Iteration 11304 => Loss: 50.14806901493849977669\n",
      "Iteration 11305 => Loss: 50.14787588437205556602\n",
      "Iteration 11306 => Loss: 50.14768275532127006500\n",
      "Iteration 11307 => Loss: 50.14748962778617880076\n",
      "Iteration 11308 => Loss: 50.14729650176670361361\n",
      "Iteration 11309 => Loss: 50.14710337726290845239\n",
      "Iteration 11310 => Loss: 50.14691025427472226283\n",
      "Iteration 11311 => Loss: 50.14671713280216636122\n",
      "Iteration 11312 => Loss: 50.14652401284521232583\n",
      "Iteration 11313 => Loss: 50.14633089440386015667\n",
      "Iteration 11314 => Loss: 50.14613777747808143204\n",
      "Iteration 11315 => Loss: 50.14594466206785483564\n",
      "Iteration 11316 => Loss: 50.14575154817322300005\n",
      "Iteration 11317 => Loss: 50.14555843579415039812\n",
      "Iteration 11318 => Loss: 50.14536532493057308102\n",
      "Iteration 11319 => Loss: 50.14517221558254078673\n",
      "Iteration 11320 => Loss: 50.14497910775001798811\n",
      "Iteration 11321 => Loss: 50.14478600143299047431\n",
      "Iteration 11322 => Loss: 50.14459289663146535077\n",
      "Iteration 11323 => Loss: 50.14439979334539287947\n",
      "Iteration 11324 => Loss: 50.14420669157480148215\n",
      "Iteration 11325 => Loss: 50.14401359131966273708\n",
      "Iteration 11326 => Loss: 50.14382049257996243341\n",
      "Iteration 11327 => Loss: 50.14362739535570767657\n",
      "Iteration 11328 => Loss: 50.14343429964684872857\n",
      "Iteration 11329 => Loss: 50.14324120545338558941\n",
      "Iteration 11330 => Loss: 50.14304811277534668079\n",
      "Iteration 11331 => Loss: 50.14285502161268937016\n",
      "Iteration 11332 => Loss: 50.14266193196537102494\n",
      "Iteration 11333 => Loss: 50.14246884383342717229\n",
      "Iteration 11334 => Loss: 50.14227575721681517962\n",
      "Iteration 11335 => Loss: 50.14208267211554215237\n",
      "Iteration 11336 => Loss: 50.14188958852962230139\n",
      "Iteration 11337 => Loss: 50.14169650645897746699\n",
      "Iteration 11338 => Loss: 50.14150342590365738715\n",
      "Iteration 11339 => Loss: 50.14131034686359100760\n",
      "Iteration 11340 => Loss: 50.14111726933881385548\n",
      "Iteration 11341 => Loss: 50.14092419332930461451\n",
      "Iteration 11342 => Loss: 50.14073111883504907382\n",
      "Iteration 11343 => Loss: 50.14053804585602591715\n",
      "Iteration 11344 => Loss: 50.14034497439221382820\n",
      "Iteration 11345 => Loss: 50.14015190444364122868\n",
      "Iteration 11346 => Loss: 50.13995883601026548604\n",
      "Iteration 11347 => Loss: 50.13976576909206528398\n",
      "Iteration 11348 => Loss: 50.13957270368907614966\n",
      "Iteration 11349 => Loss: 50.13937963980121992336\n",
      "Iteration 11350 => Loss: 50.13918657742853213222\n",
      "Iteration 11351 => Loss: 50.13899351657099145996\n",
      "Iteration 11352 => Loss: 50.13880045722857659030\n",
      "Iteration 11353 => Loss: 50.13860739940130883951\n",
      "Iteration 11354 => Loss: 50.13841434308909583706\n",
      "Iteration 11355 => Loss: 50.13822128829200863720\n",
      "Iteration 11356 => Loss: 50.13802823501001881823\n",
      "Iteration 11357 => Loss: 50.13783518324308374758\n",
      "Iteration 11358 => Loss: 50.13764213299121763612\n",
      "Iteration 11359 => Loss: 50.13744908425438495669\n",
      "Iteration 11360 => Loss: 50.13725603703260702559\n",
      "Iteration 11361 => Loss: 50.13706299132585542111\n",
      "Iteration 11362 => Loss: 50.13686994713410882696\n",
      "Iteration 11363 => Loss: 50.13667690445736013771\n",
      "Iteration 11364 => Loss: 50.13648386329560224794\n",
      "Iteration 11365 => Loss: 50.13629082364882805223\n",
      "Iteration 11366 => Loss: 50.13609778551700912885\n",
      "Iteration 11367 => Loss: 50.13590474890013837239\n",
      "Iteration 11368 => Loss: 50.13571171379822288827\n",
      "Iteration 11369 => Loss: 50.13551868021124136021\n",
      "Iteration 11370 => Loss: 50.13532564813915115565\n",
      "Iteration 11371 => Loss: 50.13513261758198069629\n",
      "Iteration 11372 => Loss: 50.13493958853972287670\n",
      "Iteration 11373 => Loss: 50.13474656101232795891\n",
      "Iteration 11374 => Loss: 50.13455353499981015375\n",
      "Iteration 11375 => Loss: 50.13436051050215525038\n",
      "Iteration 11376 => Loss: 50.13416748751932772166\n",
      "Iteration 11377 => Loss: 50.13397446605133467301\n",
      "Iteration 11378 => Loss: 50.13378144609819742072\n",
      "Iteration 11379 => Loss: 50.13358842765982359424\n",
      "Iteration 11380 => Loss: 50.13339541073627714241\n",
      "Iteration 11381 => Loss: 50.13320239532752253808\n",
      "Iteration 11382 => Loss: 50.13300938143353135956\n",
      "Iteration 11383 => Loss: 50.13281636905428939599\n",
      "Iteration 11384 => Loss: 50.13262335818983217450\n",
      "Iteration 11385 => Loss: 50.13243034884009574625\n",
      "Iteration 11386 => Loss: 50.13223734100510853295\n",
      "Iteration 11387 => Loss: 50.13204433468479948033\n",
      "Iteration 11388 => Loss: 50.13185132987919701009\n",
      "Iteration 11389 => Loss: 50.13165832658830112223\n",
      "Iteration 11390 => Loss: 50.13146532481209050047\n",
      "Iteration 11391 => Loss: 50.13127232455053672311\n",
      "Iteration 11392 => Loss: 50.13107932580366110642\n",
      "Iteration 11393 => Loss: 50.13088632857139970156\n",
      "Iteration 11394 => Loss: 50.13069333285377382481\n",
      "Iteration 11395 => Loss: 50.13050033865079768702\n",
      "Iteration 11396 => Loss: 50.13030734596240733936\n",
      "Iteration 11397 => Loss: 50.13011435478861699266\n",
      "Iteration 11398 => Loss: 50.12992136512941243609\n",
      "Iteration 11399 => Loss: 50.12972837698478656421\n",
      "Iteration 11400 => Loss: 50.12953539035470384988\n",
      "Iteration 11401 => Loss: 50.12934240523917850396\n",
      "Iteration 11402 => Loss: 50.12914942163820342103\n",
      "Iteration 11403 => Loss: 50.12895643955174307393\n",
      "Iteration 11404 => Loss: 50.12876345897977614641\n",
      "Iteration 11405 => Loss: 50.12857047992233816558\n",
      "Iteration 11406 => Loss: 50.12837750237937939346\n",
      "Iteration 11407 => Loss: 50.12818452635090693548\n",
      "Iteration 11408 => Loss: 50.12799155183690658077\n",
      "Iteration 11409 => Loss: 50.12779857883734990764\n",
      "Iteration 11410 => Loss: 50.12760560735222270523\n",
      "Iteration 11411 => Loss: 50.12741263738153918439\n",
      "Iteration 11412 => Loss: 50.12721966892527092341\n",
      "Iteration 11413 => Loss: 50.12702670198340371144\n",
      "Iteration 11414 => Loss: 50.12683373655595175933\n",
      "Iteration 11415 => Loss: 50.12664077264287243452\n",
      "Iteration 11416 => Loss: 50.12644781024414442072\n",
      "Iteration 11417 => Loss: 50.12625484935981745593\n",
      "Iteration 11418 => Loss: 50.12606188998979206417\n",
      "Iteration 11419 => Loss: 50.12586893213412508885\n",
      "Iteration 11420 => Loss: 50.12567597579277389741\n",
      "Iteration 11421 => Loss: 50.12548302096573848985\n",
      "Iteration 11422 => Loss: 50.12529006765300465531\n",
      "Iteration 11423 => Loss: 50.12509711585455818295\n",
      "Iteration 11424 => Loss: 50.12490416557038486189\n",
      "Iteration 11425 => Loss: 50.12471121680047758673\n",
      "Iteration 11426 => Loss: 50.12451826954480793574\n",
      "Iteration 11427 => Loss: 50.12432532380340433065\n",
      "Iteration 11428 => Loss: 50.12413237957621703345\n",
      "Iteration 11429 => Loss: 50.12393943686323893871\n",
      "Iteration 11430 => Loss: 50.12374649566449136273\n",
      "Iteration 11431 => Loss: 50.12355355597988904037\n",
      "Iteration 11432 => Loss: 50.12336061780951723676\n",
      "Iteration 11433 => Loss: 50.12316768115326937050\n",
      "Iteration 11434 => Loss: 50.12297474601119517956\n",
      "Iteration 11435 => Loss: 50.12278181238328045310\n",
      "Iteration 11436 => Loss: 50.12258888026948255856\n",
      "Iteration 11437 => Loss: 50.12239594966982281221\n",
      "Iteration 11438 => Loss: 50.12220302058426568692\n",
      "Iteration 11439 => Loss: 50.12201009301279697183\n",
      "Iteration 11440 => Loss: 50.12181716695540245610\n",
      "Iteration 11441 => Loss: 50.12162424241211766685\n",
      "Iteration 11442 => Loss: 50.12143131938288576066\n",
      "Iteration 11443 => Loss: 50.12123839786768542126\n",
      "Iteration 11444 => Loss: 50.12104547786653085950\n",
      "Iteration 11445 => Loss: 50.12085255937940075910\n",
      "Iteration 11446 => Loss: 50.12065964240628801463\n",
      "Iteration 11447 => Loss: 50.12046672694717841523\n",
      "Iteration 11448 => Loss: 50.12027381300205775005\n",
      "Iteration 11449 => Loss: 50.12008090057091180825\n",
      "Iteration 11450 => Loss: 50.11988798965375480066\n",
      "Iteration 11451 => Loss: 50.11969508025052277844\n",
      "Iteration 11452 => Loss: 50.11950217236125126874\n",
      "Iteration 11453 => Loss: 50.11930926598589763898\n",
      "Iteration 11454 => Loss: 50.11911636112446899460\n",
      "Iteration 11455 => Loss: 50.11892345777694401932\n",
      "Iteration 11456 => Loss: 50.11873055594332981855\n",
      "Iteration 11457 => Loss: 50.11853765562356954888\n",
      "Iteration 11458 => Loss: 50.11834475681771294830\n",
      "Iteration 11459 => Loss: 50.11815185952571738426\n",
      "Iteration 11460 => Loss: 50.11795896374754732960\n",
      "Iteration 11461 => Loss: 50.11776606948321699520\n",
      "Iteration 11462 => Loss: 50.11757317673272638103\n",
      "Iteration 11463 => Loss: 50.11738028549603995998\n",
      "Iteration 11464 => Loss: 50.11718739577315062661\n",
      "Iteration 11465 => Loss: 50.11699450756405838092\n",
      "Iteration 11466 => Loss: 50.11680162086874190663\n",
      "Iteration 11467 => Loss: 50.11660873568717988746\n",
      "Iteration 11468 => Loss: 50.11641585201936521798\n",
      "Iteration 11469 => Loss: 50.11622296986531921448\n",
      "Iteration 11470 => Loss: 50.11603008922498503352\n",
      "Iteration 11471 => Loss: 50.11583721009835556970\n",
      "Iteration 11472 => Loss: 50.11564433248545924471\n",
      "Iteration 11473 => Loss: 50.11545145638623210971\n",
      "Iteration 11474 => Loss: 50.11525858180068837555\n",
      "Iteration 11475 => Loss: 50.11506570872882093681\n",
      "Iteration 11476 => Loss: 50.11487283717060137178\n",
      "Iteration 11477 => Loss: 50.11467996712605810217\n",
      "Iteration 11478 => Loss: 50.11448709859512717912\n",
      "Iteration 11479 => Loss: 50.11429423157782991893\n",
      "Iteration 11480 => Loss: 50.11410136607413789989\n",
      "Iteration 11481 => Loss: 50.11390850208402270027\n",
      "Iteration 11482 => Loss: 50.11371563960753405809\n",
      "Iteration 11483 => Loss: 50.11352277864458670820\n",
      "Iteration 11484 => Loss: 50.11332991919520196689\n",
      "Iteration 11485 => Loss: 50.11313706125940115044\n",
      "Iteration 11486 => Loss: 50.11294420483712741543\n",
      "Iteration 11487 => Loss: 50.11275134992836655101\n",
      "Iteration 11488 => Loss: 50.11255849653311145175\n",
      "Iteration 11489 => Loss: 50.11236564465138343394\n",
      "Iteration 11490 => Loss: 50.11217279428312565415\n",
      "Iteration 11491 => Loss: 50.11197994542837363952\n",
      "Iteration 11492 => Loss: 50.11178709808709186291\n",
      "Iteration 11493 => Loss: 50.11159425225923769176\n",
      "Iteration 11494 => Loss: 50.11140140794482533693\n",
      "Iteration 11495 => Loss: 50.11120856514386190383\n",
      "Iteration 11496 => Loss: 50.11101572385631186535\n",
      "Iteration 11497 => Loss: 50.11082288408219653775\n",
      "Iteration 11498 => Loss: 50.11063004582143776133\n",
      "Iteration 11499 => Loss: 50.11043720907409237952\n",
      "Iteration 11500 => Loss: 50.11024437384011065433\n",
      "Iteration 11501 => Loss: 50.11005154011949969117\n",
      "Iteration 11502 => Loss: 50.10985870791220264664\n",
      "Iteration 11503 => Loss: 50.10966587721826215329\n",
      "Iteration 11504 => Loss: 50.10947304803767821113\n",
      "Iteration 11505 => Loss: 50.10928022037038687131\n",
      "Iteration 11506 => Loss: 50.10908739421638102840\n",
      "Iteration 11507 => Loss: 50.10889456957566778783\n",
      "Iteration 11508 => Loss: 50.10870174644826136046\n",
      "Iteration 11509 => Loss: 50.10850892483409069200\n",
      "Iteration 11510 => Loss: 50.10831610473315578247\n",
      "Iteration 11511 => Loss: 50.10812328614551347528\n",
      "Iteration 11512 => Loss: 50.10793046907107850529\n",
      "Iteration 11513 => Loss: 50.10773765350986508338\n",
      "Iteration 11514 => Loss: 50.10754483946185899867\n",
      "Iteration 11515 => Loss: 50.10735202692705314576\n",
      "Iteration 11516 => Loss: 50.10715921590541910291\n",
      "Iteration 11517 => Loss: 50.10696640639694265928\n",
      "Iteration 11518 => Loss: 50.10677359840163802573\n",
      "Iteration 11519 => Loss: 50.10658079191947678055\n",
      "Iteration 11520 => Loss: 50.10638798695047313458\n",
      "Iteration 11521 => Loss: 50.10619518349457024442\n",
      "Iteration 11522 => Loss: 50.10600238155176811006\n",
      "Iteration 11523 => Loss: 50.10580958112208804778\n",
      "Iteration 11524 => Loss: 50.10561678220550163587\n",
      "Iteration 11525 => Loss: 50.10542398480197334720\n",
      "Iteration 11526 => Loss: 50.10523118891152449805\n",
      "Iteration 11527 => Loss: 50.10503839453412666671\n",
      "Iteration 11528 => Loss: 50.10484560166974432605\n",
      "Iteration 11529 => Loss: 50.10465281031840589776\n",
      "Iteration 11530 => Loss: 50.10446002048010427643\n",
      "Iteration 11531 => Loss: 50.10426723215478261864\n",
      "Iteration 11532 => Loss: 50.10407444534246934609\n",
      "Iteration 11533 => Loss: 50.10388166004310761537\n",
      "Iteration 11534 => Loss: 50.10368887625673295361\n",
      "Iteration 11535 => Loss: 50.10349609398333114996\n",
      "Iteration 11536 => Loss: 50.10330331322285957185\n",
      "Iteration 11537 => Loss: 50.10311053397532532472\n",
      "Iteration 11538 => Loss: 50.10291775624069998685\n",
      "Iteration 11539 => Loss: 50.10272498001899066367\n",
      "Iteration 11540 => Loss: 50.10253220531019024975\n",
      "Iteration 11541 => Loss: 50.10233943211425611253\n",
      "Iteration 11542 => Loss: 50.10214666043121667371\n",
      "Iteration 11543 => Loss: 50.10195389026103640617\n",
      "Iteration 11544 => Loss: 50.10176112160369399362\n",
      "Iteration 11545 => Loss: 50.10156835445919654148\n",
      "Iteration 11546 => Loss: 50.10137558882751562805\n",
      "Iteration 11547 => Loss: 50.10118282470866546419\n",
      "Iteration 11548 => Loss: 50.10099006210261052274\n",
      "Iteration 11549 => Loss: 50.10079730100935080372\n",
      "Iteration 11550 => Loss: 50.10060454142886499085\n",
      "Iteration 11551 => Loss: 50.10041178336114597869\n",
      "Iteration 11552 => Loss: 50.10021902680618666182\n",
      "Iteration 11553 => Loss: 50.10002627176397282938\n",
      "Iteration 11554 => Loss: 50.09983351823449027052\n",
      "Iteration 11555 => Loss: 50.09964076621771056352\n",
      "Iteration 11556 => Loss: 50.09944801571364791926\n",
      "Iteration 11557 => Loss: 50.09925526672228812686\n",
      "Iteration 11558 => Loss: 50.09906251924362408090\n",
      "Iteration 11559 => Loss: 50.09886977327762025425\n",
      "Iteration 11560 => Loss: 50.09867702882426954147\n",
      "Iteration 11561 => Loss: 50.09848428588357194258\n",
      "Iteration 11562 => Loss: 50.09829154445552745756\n",
      "Iteration 11563 => Loss: 50.09809880454007924300\n",
      "Iteration 11564 => Loss: 50.09790606613726282603\n",
      "Iteration 11565 => Loss: 50.09771332924703557410\n",
      "Iteration 11566 => Loss: 50.09752059386940459262\n",
      "Iteration 11567 => Loss: 50.09732786000435567075\n",
      "Iteration 11568 => Loss: 50.09713512765187459763\n",
      "Iteration 11569 => Loss: 50.09694239681192584612\n",
      "Iteration 11570 => Loss: 50.09674966748450941623\n",
      "Iteration 11571 => Loss: 50.09655693966966083508\n",
      "Iteration 11572 => Loss: 50.09636421336730194298\n",
      "Iteration 11573 => Loss: 50.09617148857746116164\n",
      "Iteration 11574 => Loss: 50.09597876530011717477\n",
      "Iteration 11575 => Loss: 50.09578604353526287696\n",
      "Iteration 11576 => Loss: 50.09559332328288405733\n",
      "Iteration 11577 => Loss: 50.09540060454292387249\n",
      "Iteration 11578 => Loss: 50.09520788731543206040\n",
      "Iteration 11579 => Loss: 50.09501517160038019938\n",
      "Iteration 11580 => Loss: 50.09482245739775407856\n",
      "Iteration 11581 => Loss: 50.09462974470752527623\n",
      "Iteration 11582 => Loss: 50.09443703352970089782\n",
      "Iteration 11583 => Loss: 50.09424432386428804875\n",
      "Iteration 11584 => Loss: 50.09405161571120856934\n",
      "Iteration 11585 => Loss: 50.09385890907052640841\n",
      "Iteration 11586 => Loss: 50.09366620394217761714\n",
      "Iteration 11587 => Loss: 50.09347350032616930093\n",
      "Iteration 11588 => Loss: 50.09328079822250145980\n",
      "Iteration 11589 => Loss: 50.09308809763114567204\n",
      "Iteration 11590 => Loss: 50.09289539855209483221\n",
      "Iteration 11591 => Loss: 50.09270270098531341318\n",
      "Iteration 11592 => Loss: 50.09251000493082983667\n",
      "Iteration 11593 => Loss: 50.09231731038862989180\n",
      "Iteration 11594 => Loss: 50.09212461735866384061\n",
      "Iteration 11595 => Loss: 50.09193192584096721021\n",
      "Iteration 11596 => Loss: 50.09173923583546894633\n",
      "Iteration 11597 => Loss: 50.09154654734220457613\n",
      "Iteration 11598 => Loss: 50.09135386036118120501\n",
      "Iteration 11599 => Loss: 50.09116117489232777871\n",
      "Iteration 11600 => Loss: 50.09096849093565140265\n",
      "Iteration 11601 => Loss: 50.09077580849115207684\n",
      "Iteration 11602 => Loss: 50.09058312755883690670\n",
      "Iteration 11603 => Loss: 50.09039044813865615424\n",
      "Iteration 11604 => Loss: 50.09019777023060271404\n",
      "Iteration 11605 => Loss: 50.09000509383467658608\n",
      "Iteration 11606 => Loss: 50.08981241895088487581\n",
      "Iteration 11607 => Loss: 50.08961974557919205608\n",
      "Iteration 11608 => Loss: 50.08942707371959102147\n",
      "Iteration 11609 => Loss: 50.08923440337206045569\n",
      "Iteration 11610 => Loss: 50.08904173453657904247\n",
      "Iteration 11611 => Loss: 50.08884906721317520351\n",
      "Iteration 11612 => Loss: 50.08865640140182762252\n",
      "Iteration 11613 => Loss: 50.08846373710247945610\n",
      "Iteration 11614 => Loss: 50.08827107431515912594\n",
      "Iteration 11615 => Loss: 50.08807841303986663206\n",
      "Iteration 11616 => Loss: 50.08788575327656644731\n",
      "Iteration 11617 => Loss: 50.08769309502523014999\n",
      "Iteration 11618 => Loss: 50.08750043828588616179\n",
      "Iteration 11619 => Loss: 50.08730778305847763932\n",
      "Iteration 11620 => Loss: 50.08711512934302589883\n",
      "Iteration 11621 => Loss: 50.08692247713952383492\n",
      "Iteration 11622 => Loss: 50.08672982644792881501\n",
      "Iteration 11623 => Loss: 50.08653717726826926082\n",
      "Iteration 11624 => Loss: 50.08634452960048832892\n",
      "Iteration 11625 => Loss: 50.08615188344461444103\n",
      "Iteration 11626 => Loss: 50.08595923880061207001\n",
      "Iteration 11627 => Loss: 50.08576659566845279414\n",
      "Iteration 11628 => Loss: 50.08557395404817214057\n",
      "Iteration 11629 => Loss: 50.08538131393971326588\n",
      "Iteration 11630 => Loss: 50.08518867534311169720\n",
      "Iteration 11631 => Loss: 50.08499603825831059112\n",
      "Iteration 11632 => Loss: 50.08480340268531705306\n",
      "Iteration 11633 => Loss: 50.08461076862411687216\n",
      "Iteration 11634 => Loss: 50.08441813607469583758\n",
      "Iteration 11635 => Loss: 50.08422550503703973845\n",
      "Iteration 11636 => Loss: 50.08403287551116278564\n",
      "Iteration 11637 => Loss: 50.08384024749702945201\n",
      "Iteration 11638 => Loss: 50.08364762099462552669\n",
      "Iteration 11639 => Loss: 50.08345499600392258799\n",
      "Iteration 11640 => Loss: 50.08326237252494905761\n",
      "Iteration 11641 => Loss: 50.08306975055766940841\n",
      "Iteration 11642 => Loss: 50.08287713010209074582\n",
      "Iteration 11643 => Loss: 50.08268451115817754271\n",
      "Iteration 11644 => Loss: 50.08249189372592269365\n",
      "Iteration 11645 => Loss: 50.08229927780532619863\n",
      "Iteration 11646 => Loss: 50.08210666339637384681\n",
      "Iteration 11647 => Loss: 50.08191405049903011104\n",
      "Iteration 11648 => Loss: 50.08172143911333762389\n",
      "Iteration 11649 => Loss: 50.08152882923918269853\n",
      "Iteration 11650 => Loss: 50.08133622087669323264\n",
      "Iteration 11651 => Loss: 50.08114361402574843396\n",
      "Iteration 11652 => Loss: 50.08095100868640514591\n",
      "Iteration 11653 => Loss: 50.08075840485856389250\n",
      "Iteration 11654 => Loss: 50.08056580254230993887\n",
      "Iteration 11655 => Loss: 50.08037320173757223074\n",
      "Iteration 11656 => Loss: 50.08018060244436497896\n",
      "Iteration 11657 => Loss: 50.07998800466265976183\n",
      "Iteration 11658 => Loss: 50.07979540839244947392\n",
      "Iteration 11659 => Loss: 50.07960281363373411523\n",
      "Iteration 11660 => Loss: 50.07941022038648526404\n",
      "Iteration 11661 => Loss: 50.07921762865068870951\n",
      "Iteration 11662 => Loss: 50.07902503842637287335\n",
      "Iteration 11663 => Loss: 50.07883244971345959584\n",
      "Iteration 11664 => Loss: 50.07863986251198440414\n",
      "Iteration 11665 => Loss: 50.07844727682195440366\n",
      "Iteration 11666 => Loss: 50.07825469264330564556\n",
      "Iteration 11667 => Loss: 50.07806210997602391899\n",
      "Iteration 11668 => Loss: 50.07786952882014475108\n",
      "Iteration 11669 => Loss: 50.07767694917562550927\n",
      "Iteration 11670 => Loss: 50.07748437104243777185\n",
      "Iteration 11671 => Loss: 50.07729179442063838223\n",
      "Iteration 11672 => Loss: 50.07709921931014207530\n",
      "Iteration 11673 => Loss: 50.07690664571098437818\n",
      "Iteration 11674 => Loss: 50.07671407362311555289\n",
      "Iteration 11675 => Loss: 50.07652150304654981028\n",
      "Iteration 11676 => Loss: 50.07632893398125872864\n",
      "Iteration 11677 => Loss: 50.07613636642724941339\n",
      "Iteration 11678 => Loss: 50.07594380038450765369\n",
      "Iteration 11679 => Loss: 50.07575123585300502782\n",
      "Iteration 11680 => Loss: 50.07555867283274153579\n",
      "Iteration 11681 => Loss: 50.07536611132368875587\n",
      "Iteration 11682 => Loss: 50.07517355132587510980\n",
      "Iteration 11683 => Loss: 50.07498099283924375413\n",
      "Iteration 11684 => Loss: 50.07478843586379468888\n",
      "Iteration 11685 => Loss: 50.07459588039954212491\n",
      "Iteration 11686 => Loss: 50.07440332644645053506\n",
      "Iteration 11687 => Loss: 50.07421077400451281392\n",
      "Iteration 11688 => Loss: 50.07401822307370053977\n",
      "Iteration 11689 => Loss: 50.07382567365404213433\n",
      "Iteration 11690 => Loss: 50.07363312574548075418\n",
      "Iteration 11691 => Loss: 50.07344057934803771559\n",
      "Iteration 11692 => Loss: 50.07324803446168459686\n",
      "Iteration 11693 => Loss: 50.07305549108641429257\n",
      "Iteration 11694 => Loss: 50.07286294922221969728\n",
      "Iteration 11695 => Loss: 50.07267040886905107300\n",
      "Iteration 11696 => Loss: 50.07247787002697947401\n",
      "Iteration 11697 => Loss: 50.07228533269591252974\n",
      "Iteration 11698 => Loss: 50.07209279687587155649\n",
      "Iteration 11699 => Loss: 50.07190026256683523798\n",
      "Iteration 11700 => Loss: 50.07170772976880357419\n",
      "Iteration 11701 => Loss: 50.07151519848176945970\n",
      "Iteration 11702 => Loss: 50.07132266870570447281\n",
      "Iteration 11703 => Loss: 50.07113014044060150809\n",
      "Iteration 11704 => Loss: 50.07093761368646056553\n",
      "Iteration 11705 => Loss: 50.07074508844325322343\n",
      "Iteration 11706 => Loss: 50.07055256471096527093\n",
      "Iteration 11707 => Loss: 50.07036004248961091889\n",
      "Iteration 11708 => Loss: 50.07016752177913332389\n",
      "Iteration 11709 => Loss: 50.06997500257956801306\n",
      "Iteration 11710 => Loss: 50.06978248489090077555\n",
      "Iteration 11711 => Loss: 50.06958996871308187337\n",
      "Iteration 11712 => Loss: 50.06939745404611130652\n",
      "Iteration 11713 => Loss: 50.06920494088998907500\n",
      "Iteration 11714 => Loss: 50.06901242924472228424\n",
      "Iteration 11715 => Loss: 50.06881991911023987996\n",
      "Iteration 11716 => Loss: 50.06862741048659160015\n",
      "Iteration 11717 => Loss: 50.06843490337374902310\n",
      "Iteration 11718 => Loss: 50.06824239777166951626\n",
      "Iteration 11719 => Loss: 50.06804989368037439590\n",
      "Iteration 11720 => Loss: 50.06785739109981392403\n",
      "Iteration 11721 => Loss: 50.06766489003006626035\n",
      "Iteration 11722 => Loss: 50.06747239047099640175\n",
      "Iteration 11723 => Loss: 50.06727989242269671877\n",
      "Iteration 11724 => Loss: 50.06708739588509615714\n",
      "Iteration 11725 => Loss: 50.06689490085818050602\n",
      "Iteration 11726 => Loss: 50.06670240734197108168\n",
      "Iteration 11727 => Loss: 50.06650991533645367326\n",
      "Iteration 11728 => Loss: 50.06631742484158564821\n",
      "Iteration 11729 => Loss: 50.06612493585739542823\n",
      "Iteration 11730 => Loss: 50.06593244838379774819\n",
      "Iteration 11731 => Loss: 50.06573996242089208408\n",
      "Iteration 11732 => Loss: 50.06554747796855764363\n",
      "Iteration 11733 => Loss: 50.06535499502687969198\n",
      "Iteration 11734 => Loss: 50.06516251359575164770\n",
      "Iteration 11735 => Loss: 50.06497003367523745965\n",
      "Iteration 11736 => Loss: 50.06477755526528028440\n",
      "Iteration 11737 => Loss: 50.06458507836588722739\n",
      "Iteration 11738 => Loss: 50.06439260297703697233\n",
      "Iteration 11739 => Loss: 50.06420012909874373008\n",
      "Iteration 11740 => Loss: 50.06400765673095776265\n",
      "Iteration 11741 => Loss: 50.06381518587369328088\n",
      "Iteration 11742 => Loss: 50.06362271652692186308\n",
      "Iteration 11743 => Loss: 50.06343024869065061466\n",
      "Iteration 11744 => Loss: 50.06323778236484400850\n",
      "Iteration 11745 => Loss: 50.06304531754950915001\n",
      "Iteration 11746 => Loss: 50.06285285424462472292\n",
      "Iteration 11747 => Loss: 50.06266039245017651638\n",
      "Iteration 11748 => Loss: 50.06246793216616453037\n",
      "Iteration 11749 => Loss: 50.06227547339258165948\n",
      "Iteration 11750 => Loss: 50.06208301612940658742\n",
      "Iteration 11751 => Loss: 50.06189056037661799792\n",
      "Iteration 11752 => Loss: 50.06169810613420878553\n",
      "Iteration 11753 => Loss: 50.06150565340216473942\n",
      "Iteration 11754 => Loss: 50.06131320218051428128\n",
      "Iteration 11755 => Loss: 50.06112075246917214599\n",
      "Iteration 11756 => Loss: 50.06092830426818807155\n",
      "Iteration 11757 => Loss: 50.06073585757749100367\n",
      "Iteration 11758 => Loss: 50.06054341239715199663\n",
      "Iteration 11759 => Loss: 50.06035096872707867988\n",
      "Iteration 11760 => Loss: 50.06015852656731368597\n",
      "Iteration 11761 => Loss: 50.05996608591781438236\n",
      "Iteration 11762 => Loss: 50.05977364677857366360\n",
      "Iteration 11763 => Loss: 50.05958120914961995140\n",
      "Iteration 11764 => Loss: 50.05938877303086798065\n",
      "Iteration 11765 => Loss: 50.05919633842236038390\n",
      "Iteration 11766 => Loss: 50.05900390532404031774\n",
      "Iteration 11767 => Loss: 50.05881147373597883643\n",
      "Iteration 11768 => Loss: 50.05861904365807646400\n",
      "Iteration 11769 => Loss: 50.05842661509036162215\n",
      "Iteration 11770 => Loss: 50.05823418803283431089\n",
      "Iteration 11771 => Loss: 50.05804176248543058136\n",
      "Iteration 11772 => Loss: 50.05784933844820017157\n",
      "Iteration 11773 => Loss: 50.05765691592108623809\n",
      "Iteration 11774 => Loss: 50.05746449490407457006\n",
      "Iteration 11775 => Loss: 50.05727207539722201091\n",
      "Iteration 11776 => Loss: 50.05707965740044329550\n",
      "Iteration 11777 => Loss: 50.05688724091376684555\n",
      "Iteration 11778 => Loss: 50.05669482593712871221\n",
      "Iteration 11779 => Loss: 50.05650241247059284433\n",
      "Iteration 11780 => Loss: 50.05631000051409529306\n",
      "Iteration 11781 => Loss: 50.05611759006763605839\n",
      "Iteration 11782 => Loss: 50.05592518113117961320\n",
      "Iteration 11783 => Loss: 50.05573277370475437920\n",
      "Iteration 11784 => Loss: 50.05554036778834614552\n",
      "Iteration 11785 => Loss: 50.05534796338191227960\n",
      "Iteration 11786 => Loss: 50.05515556048546699230\n",
      "Iteration 11787 => Loss: 50.05496315909898186192\n",
      "Iteration 11788 => Loss: 50.05477075922246399386\n",
      "Iteration 11789 => Loss: 50.05457836085589917730\n",
      "Iteration 11790 => Loss: 50.05438596399923767422\n",
      "Iteration 11791 => Loss: 50.05419356865251501176\n",
      "Iteration 11792 => Loss: 50.05400117481570987366\n",
      "Iteration 11793 => Loss: 50.05380878248879383818\n",
      "Iteration 11794 => Loss: 50.05361639167174558906\n",
      "Iteration 11795 => Loss: 50.05342400236458644258\n",
      "Iteration 11796 => Loss: 50.05323161456730218788\n",
      "Iteration 11797 => Loss: 50.05303922827980755983\n",
      "Iteration 11798 => Loss: 50.05284684350222335070\n",
      "Iteration 11799 => Loss: 50.05265446023442166279\n",
      "Iteration 11800 => Loss: 50.05246207847645223410\n",
      "Iteration 11801 => Loss: 50.05226969822828664292\n",
      "Iteration 11802 => Loss: 50.05207731948991067839\n",
      "Iteration 11803 => Loss: 50.05188494226130302422\n",
      "Iteration 11804 => Loss: 50.05169256654247078586\n",
      "Iteration 11805 => Loss: 50.05150019233337133073\n",
      "Iteration 11806 => Loss: 50.05130781963404018597\n",
      "Iteration 11807 => Loss: 50.05111544844441340274\n",
      "Iteration 11808 => Loss: 50.05092307876453361359\n",
      "Iteration 11809 => Loss: 50.05073071059435818597\n",
      "Iteration 11810 => Loss: 50.05053834393387290902\n",
      "Iteration 11811 => Loss: 50.05034597878307067731\n",
      "Iteration 11812 => Loss: 50.05015361514192306913\n",
      "Iteration 11813 => Loss: 50.04996125301045850620\n",
      "Iteration 11814 => Loss: 50.04976889238863435594\n",
      "Iteration 11815 => Loss: 50.04957653327644351293\n",
      "Iteration 11816 => Loss: 50.04938417567389308260\n",
      "Iteration 11817 => Loss: 50.04919181958091911611\n",
      "Iteration 11818 => Loss: 50.04899946499756424600\n",
      "Iteration 11819 => Loss: 50.04880711192381426144\n",
      "Iteration 11820 => Loss: 50.04861476035963363529\n",
      "Iteration 11821 => Loss: 50.04842241030501526211\n",
      "Iteration 11822 => Loss: 50.04823006175994493105\n",
      "Iteration 11823 => Loss: 50.04803771472441553669\n",
      "Iteration 11824 => Loss: 50.04784536919840576275\n",
      "Iteration 11825 => Loss: 50.04765302518193692549\n",
      "Iteration 11826 => Loss: 50.04746068267495928694\n",
      "Iteration 11827 => Loss: 50.04726834167749416338\n",
      "Iteration 11828 => Loss: 50.04707600218949181681\n",
      "Iteration 11829 => Loss: 50.04688366421095935266\n",
      "Iteration 11830 => Loss: 50.04669132774188256008\n",
      "Iteration 11831 => Loss: 50.04649899278225433363\n",
      "Iteration 11832 => Loss: 50.04630665933207467333\n",
      "Iteration 11833 => Loss: 50.04611432739131515746\n",
      "Iteration 11834 => Loss: 50.04592199695994736430\n",
      "Iteration 11835 => Loss: 50.04572966803799261015\n",
      "Iteration 11836 => Loss: 50.04553734062543668415\n",
      "Iteration 11837 => Loss: 50.04534501472226537544\n",
      "Iteration 11838 => Loss: 50.04515269032842894603\n",
      "Iteration 11839 => Loss: 50.04496036744394871221\n",
      "Iteration 11840 => Loss: 50.04476804606880335768\n",
      "Iteration 11841 => Loss: 50.04457572620299998789\n",
      "Iteration 11842 => Loss: 50.04438340784650307569\n",
      "Iteration 11843 => Loss: 50.04419109099931972651\n",
      "Iteration 11844 => Loss: 50.04399877566142151863\n",
      "Iteration 11845 => Loss: 50.04380646183280845207\n",
      "Iteration 11846 => Loss: 50.04361414951347342139\n",
      "Iteration 11847 => Loss: 50.04342183870337379403\n",
      "Iteration 11848 => Loss: 50.04322952940253088627\n",
      "Iteration 11849 => Loss: 50.04303722161092338183\n",
      "Iteration 11850 => Loss: 50.04284491532851575357\n",
      "Iteration 11851 => Loss: 50.04265261055536484491\n",
      "Iteration 11852 => Loss: 50.04246030729136407444\n",
      "Iteration 11853 => Loss: 50.04226800553658449644\n",
      "Iteration 11854 => Loss: 50.04207570529096216205\n",
      "Iteration 11855 => Loss: 50.04188340655448996586\n",
      "Iteration 11856 => Loss: 50.04169110932720343499\n",
      "Iteration 11857 => Loss: 50.04149881360903151517\n",
      "Iteration 11858 => Loss: 50.04130651939998841726\n",
      "Iteration 11859 => Loss: 50.04111422670005993041\n",
      "Iteration 11860 => Loss: 50.04092193550923894918\n",
      "Iteration 11861 => Loss: 50.04072964582750415730\n",
      "Iteration 11862 => Loss: 50.04053735765484134390\n",
      "Iteration 11863 => Loss: 50.04034507099125761442\n",
      "Iteration 11864 => Loss: 50.04015278583671033630\n",
      "Iteration 11865 => Loss: 50.03996050219124214209\n",
      "Iteration 11866 => Loss: 50.03976822005477487210\n",
      "Iteration 11867 => Loss: 50.03957593942734405346\n",
      "Iteration 11868 => Loss: 50.03938366030892836989\n",
      "Iteration 11869 => Loss: 50.03919138269948518882\n",
      "Iteration 11870 => Loss: 50.03899910659903582655\n",
      "Iteration 11871 => Loss: 50.03880683200758028306\n",
      "Iteration 11872 => Loss: 50.03861455892506171494\n",
      "Iteration 11873 => Loss: 50.03842228735151564933\n",
      "Iteration 11874 => Loss: 50.03823001728688524281\n",
      "Iteration 11875 => Loss: 50.03803774873117049538\n",
      "Iteration 11876 => Loss: 50.03784548168439982874\n",
      "Iteration 11877 => Loss: 50.03765321614650218862\n",
      "Iteration 11878 => Loss: 50.03746095211749178588\n",
      "Iteration 11879 => Loss: 50.03726868959739704223\n",
      "Iteration 11880 => Loss: 50.03707642858614690340\n",
      "Iteration 11881 => Loss: 50.03688416908374136938\n",
      "Iteration 11882 => Loss: 50.03669191109020886188\n",
      "Iteration 11883 => Loss: 50.03649965460544990492\n",
      "Iteration 11884 => Loss: 50.03630739962957818534\n",
      "Iteration 11885 => Loss: 50.03611514616248001630\n",
      "Iteration 11886 => Loss: 50.03592289420417671408\n",
      "Iteration 11887 => Loss: 50.03573064375465406783\n",
      "Iteration 11888 => Loss: 50.03553839481389786670\n",
      "Iteration 11889 => Loss: 50.03534614738191521610\n",
      "Iteration 11890 => Loss: 50.03515390145867769434\n",
      "Iteration 11891 => Loss: 50.03496165704416398512\n",
      "Iteration 11892 => Loss: 50.03476941413838829931\n",
      "Iteration 11893 => Loss: 50.03457717274131510976\n",
      "Iteration 11894 => Loss: 50.03438493285297283819\n",
      "Iteration 11895 => Loss: 50.03419269447329043032\n",
      "Iteration 11896 => Loss: 50.03400045760228209701\n",
      "Iteration 11897 => Loss: 50.03380822223994783826\n",
      "Iteration 11898 => Loss: 50.03361598838626633778\n",
      "Iteration 11899 => Loss: 50.03342375604120917387\n",
      "Iteration 11900 => Loss: 50.03323152520480476824\n",
      "Iteration 11901 => Loss: 50.03303929587700338288\n",
      "Iteration 11902 => Loss: 50.03284706805782633410\n",
      "Iteration 11903 => Loss: 50.03265484174721677846\n",
      "Iteration 11904 => Loss: 50.03246261694521734853\n",
      "Iteration 11905 => Loss: 50.03227039365177120089\n",
      "Iteration 11906 => Loss: 50.03207817186688544098\n",
      "Iteration 11907 => Loss: 50.03188595159055296335\n",
      "Iteration 11908 => Loss: 50.03169373282273824088\n",
      "Iteration 11909 => Loss: 50.03150151556345548443\n",
      "Iteration 11910 => Loss: 50.03130929981269048312\n",
      "Iteration 11911 => Loss: 50.03111708557041481527\n",
      "Iteration 11912 => Loss: 50.03092487283661427000\n",
      "Iteration 11913 => Loss: 50.03073266161133147989\n",
      "Iteration 11914 => Loss: 50.03054045189447407438\n",
      "Iteration 11915 => Loss: 50.03034824368607758061\n",
      "Iteration 11916 => Loss: 50.03015603698612778771\n",
      "Iteration 11917 => Loss: 50.02996383179461048485\n",
      "Iteration 11918 => Loss: 50.02977162811150435573\n",
      "Iteration 11919 => Loss: 50.02957942593680229493\n",
      "Iteration 11920 => Loss: 50.02938722527047588073\n",
      "Iteration 11921 => Loss: 50.02919502611253932400\n",
      "Iteration 11922 => Loss: 50.02900282846297841388\n",
      "Iteration 11923 => Loss: 50.02881063232177893951\n",
      "Iteration 11924 => Loss: 50.02861843768892669004\n",
      "Iteration 11925 => Loss: 50.02842624456440034919\n",
      "Iteration 11926 => Loss: 50.02823405294819281153\n",
      "Iteration 11927 => Loss: 50.02804186284030407705\n",
      "Iteration 11928 => Loss: 50.02784967424071282949\n",
      "Iteration 11929 => Loss: 50.02765748714940485797\n",
      "Iteration 11930 => Loss: 50.02746530156635884623\n",
      "Iteration 11931 => Loss: 50.02727311749158900511\n",
      "Iteration 11932 => Loss: 50.02708093492505980748\n",
      "Iteration 11933 => Loss: 50.02688875386678546420\n",
      "Iteration 11934 => Loss: 50.02669657431671623726\n",
      "Iteration 11935 => Loss: 50.02650439627486633754\n",
      "Iteration 11936 => Loss: 50.02631221974124287044\n",
      "Iteration 11937 => Loss: 50.02612004471578899256\n",
      "Iteration 11938 => Loss: 50.02592787119851180933\n",
      "Iteration 11939 => Loss: 50.02573569918941132073\n",
      "Iteration 11940 => Loss: 50.02554352868848042135\n",
      "Iteration 11941 => Loss: 50.02535135969566937320\n",
      "Iteration 11942 => Loss: 50.02515919221099949254\n",
      "Iteration 11943 => Loss: 50.02496702623444235769\n",
      "Iteration 11944 => Loss: 50.02477486176601217949\n",
      "Iteration 11945 => Loss: 50.02458269880568053622\n",
      "Iteration 11946 => Loss: 50.02439053735341190077\n",
      "Iteration 11947 => Loss: 50.02419837740924890568\n",
      "Iteration 11948 => Loss: 50.02400621897312049668\n",
      "Iteration 11949 => Loss: 50.02381406204502667379\n",
      "Iteration 11950 => Loss: 50.02362190662499585869\n",
      "Iteration 11951 => Loss: 50.02342975271298541884\n",
      "Iteration 11952 => Loss: 50.02323760030897403794\n",
      "Iteration 11953 => Loss: 50.02304544941301855943\n",
      "Iteration 11954 => Loss: 50.02285330002498398017\n",
      "Iteration 11955 => Loss: 50.02266115214496977615\n",
      "Iteration 11956 => Loss: 50.02246900577289778766\n",
      "Iteration 11957 => Loss: 50.02227686090878222558\n",
      "Iteration 11958 => Loss: 50.02208471755262308989\n",
      "Iteration 11959 => Loss: 50.02189257570440616973\n",
      "Iteration 11960 => Loss: 50.02170043536409593798\n",
      "Iteration 11961 => Loss: 50.02150829653168528921\n",
      "Iteration 11962 => Loss: 50.02131615920716711798\n",
      "Iteration 11963 => Loss: 50.02112402339053431888\n",
      "Iteration 11964 => Loss: 50.02093188908178689189\n",
      "Iteration 11965 => Loss: 50.02073975628087509904\n",
      "Iteration 11966 => Loss: 50.02054762498784867830\n",
      "Iteration 11967 => Loss: 50.02035549520262946999\n",
      "Iteration 11968 => Loss: 50.02016336692526010665\n",
      "Iteration 11969 => Loss: 50.01997124015566953403\n",
      "Iteration 11970 => Loss: 50.01977911489390749011\n",
      "Iteration 11971 => Loss: 50.01958699113991713148\n",
      "Iteration 11972 => Loss: 50.01939486889369135270\n",
      "Iteration 11973 => Loss: 50.01920274815525857548\n",
      "Iteration 11974 => Loss: 50.01901062892459748355\n",
      "Iteration 11975 => Loss: 50.01881851120164412805\n",
      "Iteration 11976 => Loss: 50.01862639498641982527\n",
      "Iteration 11977 => Loss: 50.01843428027891036436\n",
      "Iteration 11978 => Loss: 50.01824216707913706159\n",
      "Iteration 11979 => Loss: 50.01805005538703596812\n",
      "Iteration 11980 => Loss: 50.01785794520262129481\n",
      "Iteration 11981 => Loss: 50.01766583652588593623\n",
      "Iteration 11982 => Loss: 50.01747372935679436523\n",
      "Iteration 11983 => Loss: 50.01728162369534658183\n",
      "Iteration 11984 => Loss: 50.01708951954154258601\n",
      "Iteration 11985 => Loss: 50.01689741689536816693\n",
      "Iteration 11986 => Loss: 50.01670531575679490288\n",
      "Iteration 11987 => Loss: 50.01651321612584411014\n",
      "Iteration 11988 => Loss: 50.01632111800246605071\n",
      "Iteration 11989 => Loss: 50.01612902138663940832\n",
      "Iteration 11990 => Loss: 50.01593692627842102638\n",
      "Iteration 11991 => Loss: 50.01574483267771853434\n",
      "Iteration 11992 => Loss: 50.01555274058457456476\n",
      "Iteration 11993 => Loss: 50.01536064999895359051\n",
      "Iteration 11994 => Loss: 50.01516856092084850616\n",
      "Iteration 11995 => Loss: 50.01497647335025931170\n",
      "Iteration 11996 => Loss: 50.01478438728714337458\n",
      "Iteration 11997 => Loss: 50.01459230273152911650\n",
      "Iteration 11998 => Loss: 50.01440021968337390490\n",
      "Iteration 11999 => Loss: 50.01420813814267773978\n",
      "Iteration 12000 => Loss: 50.01401605810942641028\n",
      "Iteration 12001 => Loss: 50.01382397958362702184\n",
      "Iteration 12002 => Loss: 50.01363190256521562560\n",
      "Iteration 12003 => Loss: 50.01343982705424195956\n",
      "Iteration 12004 => Loss: 50.01324775305065628572\n",
      "Iteration 12005 => Loss: 50.01305568055446570952\n",
      "Iteration 12006 => Loss: 50.01286360956564891467\n",
      "Iteration 12007 => Loss: 50.01267154008417037403\n",
      "Iteration 12008 => Loss: 50.01247947211008693102\n",
      "Iteration 12009 => Loss: 50.01228740564331332052\n",
      "Iteration 12010 => Loss: 50.01209534068384954253\n",
      "Iteration 12011 => Loss: 50.01190327723171691332\n",
      "Iteration 12012 => Loss: 50.01171121528691543290\n",
      "Iteration 12013 => Loss: 50.01151915484938825784\n",
      "Iteration 12014 => Loss: 50.01132709591913538816\n",
      "Iteration 12015 => Loss: 50.01113503849614971841\n",
      "Iteration 12016 => Loss: 50.01094298258042414318\n",
      "Iteration 12017 => Loss: 50.01075092817195155703\n",
      "Iteration 12018 => Loss: 50.01055887527068932741\n",
      "Iteration 12019 => Loss: 50.01036682387668719230\n",
      "Iteration 12020 => Loss: 50.01017477398985278114\n",
      "Iteration 12021 => Loss: 50.00998272561022872651\n",
      "Iteration 12022 => Loss: 50.00979067873781502840\n",
      "Iteration 12023 => Loss: 50.00959863337253352711\n",
      "Iteration 12024 => Loss: 50.00940658951444817149\n",
      "Iteration 12025 => Loss: 50.00921454716350211811\n",
      "Iteration 12026 => Loss: 50.00902250631968826156\n",
      "Iteration 12027 => Loss: 50.00883046698299949639\n",
      "Iteration 12028 => Loss: 50.00863842915344292805\n",
      "Iteration 12029 => Loss: 50.00844639283098302940\n",
      "Iteration 12030 => Loss: 50.00825435801560558957\n",
      "Iteration 12031 => Loss: 50.00806232470730350315\n",
      "Iteration 12032 => Loss: 50.00787029290608387555\n",
      "Iteration 12033 => Loss: 50.00767826261191828507\n",
      "Iteration 12034 => Loss: 50.00748623382477120458\n",
      "Iteration 12035 => Loss: 50.00729420654468526664\n",
      "Iteration 12036 => Loss: 50.00710218077161783867\n",
      "Iteration 12037 => Loss: 50.00691015650554049898\n",
      "Iteration 12038 => Loss: 50.00671813374646035300\n",
      "Iteration 12039 => Loss: 50.00652611249439161156\n",
      "Iteration 12040 => Loss: 50.00633409274927743127\n",
      "Iteration 12041 => Loss: 50.00614207451111781211\n",
      "Iteration 12042 => Loss: 50.00595005777992696494\n",
      "Iteration 12043 => Loss: 50.00575804255564804635\n",
      "Iteration 12044 => Loss: 50.00556602883830237261\n",
      "Iteration 12045 => Loss: 50.00537401662786862744\n",
      "Iteration 12046 => Loss: 50.00518200592435391627\n",
      "Iteration 12047 => Loss: 50.00498999672770139568\n",
      "Iteration 12048 => Loss: 50.00479798903793238196\n",
      "Iteration 12049 => Loss: 50.00460598285505398053\n",
      "Iteration 12050 => Loss: 50.00441397817901645340\n",
      "Iteration 12051 => Loss: 50.00422197500984111684\n",
      "Iteration 12052 => Loss: 50.00402997334744981117\n",
      "Iteration 12053 => Loss: 50.00383797319192780151\n",
      "Iteration 12054 => Loss: 50.00364597454316850644\n",
      "Iteration 12055 => Loss: 50.00345397740122166397\n",
      "Iteration 12056 => Loss: 50.00326198176607306323\n",
      "Iteration 12057 => Loss: 50.00306998763768717708\n",
      "Iteration 12058 => Loss: 50.00287799501605690011\n",
      "Iteration 12059 => Loss: 50.00268600390116091603\n",
      "Iteration 12060 => Loss: 50.00249401429302054112\n",
      "Iteration 12061 => Loss: 50.00230202619161445909\n",
      "Iteration 12062 => Loss: 50.00211003959692135368\n",
      "Iteration 12063 => Loss: 50.00191805450889859230\n",
      "Iteration 12064 => Loss: 50.00172607092757459668\n",
      "Iteration 12065 => Loss: 50.00153408885294936681\n",
      "Iteration 12066 => Loss: 50.00134210828496605927\n",
      "Iteration 12067 => Loss: 50.00115012922363888492\n",
      "Iteration 12068 => Loss: 50.00095815166896073833\n",
      "Iteration 12069 => Loss: 50.00076617562093161951\n",
      "Iteration 12070 => Loss: 50.00057420107948047416\n",
      "Iteration 12071 => Loss: 50.00038222804466414573\n",
      "Iteration 12072 => Loss: 50.00019025651642579078\n",
      "Iteration 12073 => Loss: 49.99999828649477251474\n",
      "Iteration 12074 => Loss: 49.99980631797969721219\n",
      "Iteration 12075 => Loss: 49.99961435097118567228\n",
      "Iteration 12076 => Loss: 49.99942238546920236786\n",
      "Iteration 12077 => Loss: 49.99923042147377572064\n",
      "Iteration 12078 => Loss: 49.99903845898485599264\n",
      "Iteration 12079 => Loss: 49.99884649800245739470\n",
      "Iteration 12080 => Loss: 49.99865453852653018885\n",
      "Iteration 12081 => Loss: 49.99846258055715253477\n",
      "Iteration 12082 => Loss: 49.99827062409420364020\n",
      "Iteration 12083 => Loss: 49.99807866913771903228\n",
      "Iteration 12084 => Loss: 49.99788671568770581644\n",
      "Iteration 12085 => Loss: 49.99769476374411425468\n",
      "Iteration 12086 => Loss: 49.99750281330695145243\n",
      "Iteration 12087 => Loss: 49.99731086437623872598\n",
      "Iteration 12088 => Loss: 49.99711891695189791562\n",
      "Iteration 12089 => Loss: 49.99692697103396454850\n",
      "Iteration 12090 => Loss: 49.99673502662241020289\n",
      "Iteration 12091 => Loss: 49.99654308371722066795\n",
      "Iteration 12092 => Loss: 49.99635114231840304910\n",
      "Iteration 12093 => Loss: 49.99615920242590760836\n",
      "Iteration 12094 => Loss: 49.99596726403975566200\n",
      "Iteration 12095 => Loss: 49.99577532715992589374\n",
      "Iteration 12096 => Loss: 49.99558339178641830358\n",
      "Iteration 12097 => Loss: 49.99539145791921157524\n",
      "Iteration 12098 => Loss: 49.99519952555827018159\n",
      "Iteration 12099 => Loss: 49.99500759470362254433\n",
      "Iteration 12100 => Loss: 49.99481566535524024175\n",
      "Iteration 12101 => Loss: 49.99462373751308774672\n",
      "Iteration 12102 => Loss: 49.99443181117720769180\n",
      "Iteration 12103 => Loss: 49.99423988634752902271\n",
      "Iteration 12104 => Loss: 49.99404796302407305575\n",
      "Iteration 12105 => Loss: 49.99385604120681847462\n",
      "Iteration 12106 => Loss: 49.99366412089575817390\n",
      "Iteration 12107 => Loss: 49.99347220209087083731\n",
      "Iteration 12108 => Loss: 49.99328028479216357027\n",
      "Iteration 12109 => Loss: 49.99308836899962926736\n",
      "Iteration 12110 => Loss: 49.99289645471320397974\n",
      "Iteration 12111 => Loss: 49.99270454193292323453\n",
      "Iteration 12112 => Loss: 49.99251263065878703173\n",
      "Iteration 12113 => Loss: 49.99232072089073142251\n",
      "Iteration 12114 => Loss: 49.99212881262879903943\n",
      "Iteration 12115 => Loss: 49.99193690587293303906\n",
      "Iteration 12116 => Loss: 49.99174500062316184312\n",
      "Iteration 12117 => Loss: 49.99155309687943571362\n",
      "Iteration 12118 => Loss: 49.99136119464175465055\n",
      "Iteration 12119 => Loss: 49.99116929391011865391\n",
      "Iteration 12120 => Loss: 49.99097739468450640743\n",
      "Iteration 12121 => Loss: 49.99078549696490370025\n",
      "Iteration 12122 => Loss: 49.99059360075133184864\n",
      "Iteration 12123 => Loss: 49.99040170604372690377\n",
      "Iteration 12124 => Loss: 49.99020981284209597106\n",
      "Iteration 12125 => Loss: 49.99001792114646747223\n",
      "Iteration 12126 => Loss: 49.98982603095675614213\n",
      "Iteration 12127 => Loss: 49.98963414227302592963\n",
      "Iteration 12128 => Loss: 49.98944225509520578044\n",
      "Iteration 12129 => Loss: 49.98925036942330279999\n",
      "Iteration 12130 => Loss: 49.98905848525730277743\n",
      "Iteration 12131 => Loss: 49.98886660259721992361\n",
      "Iteration 12132 => Loss: 49.98867472144300450054\n",
      "Iteration 12133 => Loss: 49.98848284179466361365\n",
      "Iteration 12134 => Loss: 49.98829096365220436837\n",
      "Iteration 12135 => Loss: 49.98809908701557702670\n",
      "Iteration 12136 => Loss: 49.98790721188478158865\n",
      "Iteration 12137 => Loss: 49.98771533825981805421\n",
      "Iteration 12138 => Loss: 49.98752346614069352881\n",
      "Iteration 12139 => Loss: 49.98733159552735827447\n",
      "Iteration 12140 => Loss: 49.98713972641980518574\n",
      "Iteration 12141 => Loss: 49.98694785881802005179\n",
      "Iteration 12142 => Loss: 49.98675599272200997802\n",
      "Iteration 12143 => Loss: 49.98656412813176785903\n",
      "Iteration 12144 => Loss: 49.98637226504726527310\n",
      "Iteration 12145 => Loss: 49.98618040346848090394\n",
      "Iteration 12146 => Loss: 49.98598854339542896241\n",
      "Iteration 12147 => Loss: 49.98579668482807392138\n",
      "Iteration 12148 => Loss: 49.98560482776642288627\n",
      "Iteration 12149 => Loss: 49.98541297221045454080\n",
      "Iteration 12150 => Loss: 49.98522111816016177954\n",
      "Iteration 12151 => Loss: 49.98502926561550907536\n",
      "Iteration 12152 => Loss: 49.98483741457653195539\n",
      "Iteration 12153 => Loss: 49.98464556504319489250\n",
      "Iteration 12154 => Loss: 49.98445371701546235954\n",
      "Iteration 12155 => Loss: 49.98426187049334146195\n",
      "Iteration 12156 => Loss: 49.98407002547683219973\n",
      "Iteration 12157 => Loss: 49.98387818196591325659\n",
      "Iteration 12158 => Loss: 49.98368633996057042168\n",
      "Iteration 12159 => Loss: 49.98349449946078948415\n",
      "Iteration 12160 => Loss: 49.98330266046658465484\n",
      "Iteration 12161 => Loss: 49.98311082297787777406\n",
      "Iteration 12162 => Loss: 49.98291898699473989609\n",
      "Iteration 12163 => Loss: 49.98272715251710707207\n",
      "Iteration 12164 => Loss: 49.98253531954497930201\n",
      "Iteration 12165 => Loss: 49.98234348807834948047\n",
      "Iteration 12166 => Loss: 49.98215165811721050204\n",
      "Iteration 12167 => Loss: 49.98195982966153394500\n",
      "Iteration 12168 => Loss: 49.98176800271132691478\n",
      "Iteration 12169 => Loss: 49.98157617726655388424\n",
      "Iteration 12170 => Loss: 49.98138435332720774795\n",
      "Iteration 12171 => Loss: 49.98119253089330982220\n",
      "Iteration 12172 => Loss: 49.98100070996481747443\n",
      "Iteration 12173 => Loss: 49.98080889054171649377\n",
      "Iteration 12174 => Loss: 49.98061707262402109109\n",
      "Iteration 12175 => Loss: 49.98042525621170995009\n",
      "Iteration 12176 => Loss: 49.98023344130473333280\n",
      "Iteration 12177 => Loss: 49.98004162790310545006\n",
      "Iteration 12178 => Loss: 49.97984981600684761816\n",
      "Iteration 12179 => Loss: 49.97965800561588878281\n",
      "Iteration 12180 => Loss: 49.97946619673029289288\n",
      "Iteration 12181 => Loss: 49.97927438934996757780\n",
      "Iteration 12182 => Loss: 49.97908258347495547014\n",
      "Iteration 12183 => Loss: 49.97889077910522104276\n",
      "Iteration 12184 => Loss: 49.97869897624075008480\n",
      "Iteration 12185 => Loss: 49.97850717488154259627\n",
      "Iteration 12186 => Loss: 49.97831537502757015545\n",
      "Iteration 12187 => Loss: 49.97812357667883276235\n",
      "Iteration 12188 => Loss: 49.97793177983535883868\n",
      "Iteration 12189 => Loss: 49.97773998449706311931\n",
      "Iteration 12190 => Loss: 49.97754819066396692051\n",
      "Iteration 12191 => Loss: 49.97735639833604892601\n",
      "Iteration 12192 => Loss: 49.97716460751334466295\n",
      "Iteration 12193 => Loss: 49.97697281819577597162\n",
      "Iteration 12194 => Loss: 49.97678103038335706287\n",
      "Iteration 12195 => Loss: 49.97658924407608793672\n",
      "Iteration 12196 => Loss: 49.97639745927395438230\n",
      "Iteration 12197 => Loss: 49.97620567597692087247\n",
      "Iteration 12198 => Loss: 49.97601389418498740724\n",
      "Iteration 12199 => Loss: 49.97582211389817530289\n",
      "Iteration 12200 => Loss: 49.97563033511642061058\n",
      "Iteration 12201 => Loss: 49.97543855783975885743\n",
      "Iteration 12202 => Loss: 49.97524678206813320003\n",
      "Iteration 12203 => Loss: 49.97505500780157916552\n",
      "Iteration 12204 => Loss: 49.97486323504003280505\n",
      "Iteration 12205 => Loss: 49.97467146378350832947\n",
      "Iteration 12206 => Loss: 49.97447969403201994965\n",
      "Iteration 12207 => Loss: 49.97428792578551792758\n",
      "Iteration 12208 => Loss: 49.97409615904400936870\n",
      "Iteration 12209 => Loss: 49.97390439380745874587\n",
      "Iteration 12210 => Loss: 49.97371263007588026994\n",
      "Iteration 12211 => Loss: 49.97352086784926683549\n",
      "Iteration 12212 => Loss: 49.97332910712756870453\n",
      "Iteration 12213 => Loss: 49.97313734791081429876\n",
      "Iteration 12214 => Loss: 49.97294559019896809104\n",
      "Iteration 12215 => Loss: 49.97275383399203718682\n",
      "Iteration 12216 => Loss: 49.97256207928999316437\n",
      "Iteration 12217 => Loss: 49.97237032609284312912\n",
      "Iteration 12218 => Loss: 49.97217857440054444851\n",
      "Iteration 12219 => Loss: 49.97198682421308291168\n",
      "Iteration 12220 => Loss: 49.97179507553050115121\n",
      "Iteration 12221 => Loss: 49.97160332835274232366\n",
      "Iteration 12222 => Loss: 49.97141158267980642904\n",
      "Iteration 12223 => Loss: 49.97121983851169346735\n",
      "Iteration 12224 => Loss: 49.97102809584834659518\n",
      "Iteration 12225 => Loss: 49.97083635468982265593\n",
      "Iteration 12226 => Loss: 49.97064461503605059534\n",
      "Iteration 12227 => Loss: 49.97045287688703041340\n",
      "Iteration 12228 => Loss: 49.97026114024279763726\n",
      "Iteration 12229 => Loss: 49.97006940510326700178\n",
      "Iteration 12230 => Loss: 49.96987767146848113953\n",
      "Iteration 12231 => Loss: 49.96968593933841873422\n",
      "Iteration 12232 => Loss: 49.96949420871304425873\n",
      "Iteration 12233 => Loss: 49.96930247959235771305\n",
      "Iteration 12234 => Loss: 49.96911075197636620260\n",
      "Iteration 12235 => Loss: 49.96891902586505551653\n",
      "Iteration 12236 => Loss: 49.96872730125838302229\n",
      "Iteration 12237 => Loss: 49.96853557815634871986\n",
      "Iteration 12238 => Loss: 49.96834385655895260925\n",
      "Iteration 12239 => Loss: 49.96815213646619469046\n",
      "Iteration 12240 => Loss: 49.96796041787800390921\n",
      "Iteration 12241 => Loss: 49.96776870079445131978\n",
      "Iteration 12242 => Loss: 49.96757698521547297332\n",
      "Iteration 12243 => Loss: 49.96738527114106176441\n",
      "Iteration 12244 => Loss: 49.96719355857123190390\n",
      "Iteration 12245 => Loss: 49.96700184750591233751\n",
      "Iteration 12246 => Loss: 49.96681013794516701410\n",
      "Iteration 12247 => Loss: 49.96661842988893198481\n",
      "Iteration 12248 => Loss: 49.96642672333722856592\n",
      "Iteration 12249 => Loss: 49.96623501829001412489\n",
      "Iteration 12250 => Loss: 49.96604331474728155627\n",
      "Iteration 12251 => Loss: 49.96585161270904507091\n",
      "Iteration 12252 => Loss: 49.96565991217526914170\n",
      "Iteration 12253 => Loss: 49.96546821314595376862\n",
      "Iteration 12254 => Loss: 49.96527651562107052996\n",
      "Iteration 12255 => Loss: 49.96508481960062653116\n",
      "Iteration 12256 => Loss: 49.96489312508461466678\n",
      "Iteration 12257 => Loss: 49.96470143207298519883\n",
      "Iteration 12258 => Loss: 49.96450974056577365445\n",
      "Iteration 12259 => Loss: 49.96431805056294450651\n",
      "Iteration 12260 => Loss: 49.96412636206449064957\n",
      "Iteration 12261 => Loss: 49.96393467507039787279\n",
      "Iteration 12262 => Loss: 49.96374298958065196530\n",
      "Iteration 12263 => Loss: 49.96355130559523161082\n",
      "Iteration 12264 => Loss: 49.96335962311416523107\n",
      "Iteration 12265 => Loss: 49.96316794213737466634\n",
      "Iteration 12266 => Loss: 49.96297626266492386549\n",
      "Iteration 12267 => Loss: 49.96278458469674177422\n",
      "Iteration 12268 => Loss: 49.96259290823283549798\n",
      "Iteration 12269 => Loss: 49.96240123327319793134\n",
      "Iteration 12270 => Loss: 49.96220955981783617972\n",
      "Iteration 12271 => Loss: 49.96201788786669339970\n",
      "Iteration 12272 => Loss: 49.96182621741978380214\n",
      "Iteration 12273 => Loss: 49.96163454847712870333\n",
      "Iteration 12274 => Loss: 49.96144288103862862727\n",
      "Iteration 12275 => Loss: 49.96125121510436883909\n",
      "Iteration 12276 => Loss: 49.96105955067426407368\n",
      "Iteration 12277 => Loss: 49.96086788774833564730\n",
      "Iteration 12278 => Loss: 49.96067622632656224368\n",
      "Iteration 12279 => Loss: 49.96048456640897938996\n",
      "Iteration 12280 => Loss: 49.96029290799548050472\n",
      "Iteration 12281 => Loss: 49.96010125108612243139\n",
      "Iteration 12282 => Loss: 49.95990959568087674825\n",
      "Iteration 12283 => Loss: 49.95971794177977187701\n",
      "Iteration 12284 => Loss: 49.95952628938271544712\n",
      "Iteration 12285 => Loss: 49.95933463848973588028\n",
      "Iteration 12286 => Loss: 49.95914298910084028194\n",
      "Iteration 12287 => Loss: 49.95895134121599312493\n",
      "Iteration 12288 => Loss: 49.95875969483517309300\n",
      "Iteration 12289 => Loss: 49.95856804995841571326\n",
      "Iteration 12290 => Loss: 49.95837640658564993146\n",
      "Iteration 12291 => Loss: 49.95818476471690416929\n",
      "Iteration 12292 => Loss: 49.95799312435215711048\n",
      "Iteration 12293 => Loss: 49.95780148549136612246\n",
      "Iteration 12294 => Loss: 49.95760984813458804865\n",
      "Iteration 12295 => Loss: 49.95741821228174472935\n",
      "Iteration 12296 => Loss: 49.95722657793285037542\n",
      "Iteration 12297 => Loss: 49.95703494508790498685\n",
      "Iteration 12298 => Loss: 49.95684331374687303651\n",
      "Iteration 12299 => Loss: 49.95665168390974031354\n",
      "Iteration 12300 => Loss: 49.95646005557653523965\n",
      "Iteration 12301 => Loss: 49.95626842874721518228\n",
      "Iteration 12302 => Loss: 49.95607680342176593058\n",
      "Iteration 12303 => Loss: 49.95588517960017327368\n",
      "Iteration 12304 => Loss: 49.95569355728243721160\n",
      "Iteration 12305 => Loss: 49.95550193646855774432\n",
      "Iteration 12306 => Loss: 49.95531031715849223929\n",
      "Iteration 12307 => Loss: 49.95511869935225490735\n",
      "Iteration 12308 => Loss: 49.95492708304982443224\n",
      "Iteration 12309 => Loss: 49.95473546825116528680\n",
      "Iteration 12310 => Loss: 49.95454385495632720904\n",
      "Iteration 12311 => Loss: 49.95435224316526046096\n",
      "Iteration 12312 => Loss: 49.95416063287791530456\n",
      "Iteration 12313 => Loss: 49.95396902409434858328\n",
      "Iteration 12314 => Loss: 49.95377741681448213740\n",
      "Iteration 12315 => Loss: 49.95358581103837281034\n",
      "Iteration 12316 => Loss: 49.95339420676597086413\n",
      "Iteration 12317 => Loss: 49.95320260399725498246\n",
      "Iteration 12318 => Loss: 49.95301100273223937620\n",
      "Iteration 12319 => Loss: 49.95281940297090983449\n",
      "Iteration 12320 => Loss: 49.95262780471322372478\n",
      "Iteration 12321 => Loss: 49.95243620795918104704\n",
      "Iteration 12322 => Loss: 49.95224461270881732844\n",
      "Iteration 12323 => Loss: 49.95205301896205440926\n",
      "Iteration 12324 => Loss: 49.95186142671894913292\n",
      "Iteration 12325 => Loss: 49.95166983597940912887\n",
      "Iteration 12326 => Loss: 49.95147824674346281881\n",
      "Iteration 12327 => Loss: 49.95128665901112441361\n",
      "Iteration 12328 => Loss: 49.95109507278234417527\n",
      "Iteration 12329 => Loss: 49.95090348805709368207\n",
      "Iteration 12330 => Loss: 49.95071190483542267202\n",
      "Iteration 12331 => Loss: 49.95052032311728851255\n",
      "Iteration 12332 => Loss: 49.95032874290266988737\n",
      "Iteration 12333 => Loss: 49.95013716419158100734\n",
      "Iteration 12334 => Loss: 49.94994558698395081819\n",
      "Iteration 12335 => Loss: 49.94975401127984326877\n",
      "Iteration 12336 => Loss: 49.94956243707920862107\n",
      "Iteration 12337 => Loss: 49.94937086438201845340\n",
      "Iteration 12338 => Loss: 49.94917929318829408203\n",
      "Iteration 12339 => Loss: 49.94898772349800708525\n",
      "Iteration 12340 => Loss: 49.94879615531115035765\n",
      "Iteration 12341 => Loss: 49.94860458862771679378\n",
      "Iteration 12342 => Loss: 49.94841302344767797194\n",
      "Iteration 12343 => Loss: 49.94822145977103389214\n",
      "Iteration 12344 => Loss: 49.94802989759777034351\n",
      "Iteration 12345 => Loss: 49.94783833692788022063\n",
      "Iteration 12346 => Loss: 49.94764677776134220721\n",
      "Iteration 12347 => Loss: 49.94745522009815630327\n",
      "Iteration 12348 => Loss: 49.94726366393832250878\n",
      "Iteration 12349 => Loss: 49.94707210928177687492\n",
      "Iteration 12350 => Loss: 49.94688055612854782339\n",
      "Iteration 12351 => Loss: 49.94668900447864245962\n",
      "Iteration 12352 => Loss: 49.94649745433202525646\n",
      "Iteration 12353 => Loss: 49.94630590568866068679\n",
      "Iteration 12354 => Loss: 49.94611435854857006689\n",
      "Iteration 12355 => Loss: 49.94592281291171786961\n",
      "Iteration 12356 => Loss: 49.94573126877812541125\n",
      "Iteration 12357 => Loss: 49.94553972614774295380\n",
      "Iteration 12358 => Loss: 49.94534818502059891898\n",
      "Iteration 12359 => Loss: 49.94515664539662935795\n",
      "Iteration 12360 => Loss: 49.94496510727590532497\n",
      "Iteration 12361 => Loss: 49.94477357065831313321\n",
      "Iteration 12362 => Loss: 49.94458203554390962609\n",
      "Iteration 12363 => Loss: 49.94439050193265217104\n",
      "Iteration 12364 => Loss: 49.94419896982455497891\n",
      "Iteration 12365 => Loss: 49.94400743921958962801\n",
      "Iteration 12366 => Loss: 49.94381591011774190747\n",
      "Iteration 12367 => Loss: 49.94362438251901181729\n",
      "Iteration 12368 => Loss: 49.94343285642336383034\n",
      "Iteration 12369 => Loss: 49.94324133183079794662\n",
      "Iteration 12370 => Loss: 49.94304980874132127155\n",
      "Iteration 12371 => Loss: 49.94285828715491959429\n",
      "Iteration 12372 => Loss: 49.94266676707155738768\n",
      "Iteration 12373 => Loss: 49.94247524849123465174\n",
      "Iteration 12374 => Loss: 49.94228373141390875389\n",
      "Iteration 12375 => Loss: 49.94209221583963653757\n",
      "Iteration 12376 => Loss: 49.94190070176836826477\n",
      "Iteration 12377 => Loss: 49.94170918920006840835\n",
      "Iteration 12378 => Loss: 49.94151767813477249547\n",
      "Iteration 12379 => Loss: 49.94132616857245210440\n",
      "Iteration 12380 => Loss: 49.94113466051305749716\n",
      "Iteration 12381 => Loss: 49.94094315395665972801\n",
      "Iteration 12382 => Loss: 49.94075164890316642641\n",
      "Iteration 12383 => Loss: 49.94056014535259180320\n",
      "Iteration 12384 => Loss: 49.94036864330490743669\n",
      "Iteration 12385 => Loss: 49.94017714276011332686\n",
      "Iteration 12386 => Loss: 49.93998564371825921171\n",
      "Iteration 12387 => Loss: 49.93979414617925272069\n",
      "Iteration 12388 => Loss: 49.93960265014310095921\n",
      "Iteration 12389 => Loss: 49.93941115560979682186\n",
      "Iteration 12390 => Loss: 49.93921966257936873035\n",
      "Iteration 12391 => Loss: 49.93902817105170299783\n",
      "Iteration 12392 => Loss: 49.93883668102689910029\n",
      "Iteration 12393 => Loss: 49.93864519250490729974\n",
      "Iteration 12394 => Loss: 49.93845370548567075275\n",
      "Iteration 12395 => Loss: 49.93826221996923919733\n",
      "Iteration 12396 => Loss: 49.93807073595558421175\n",
      "Iteration 12397 => Loss: 49.93787925344467026889\n",
      "Iteration 12398 => Loss: 49.93768777243651157960\n",
      "Iteration 12399 => Loss: 49.93749629293105130046\n",
      "Iteration 12400 => Loss: 49.93730481492836048574\n",
      "Iteration 12401 => Loss: 49.93711333842833255403\n",
      "Iteration 12402 => Loss: 49.93692186343103145418\n",
      "Iteration 12403 => Loss: 49.93673038993640744820\n",
      "Iteration 12404 => Loss: 49.93653891794446764152\n",
      "Iteration 12405 => Loss: 49.93634744745518361242\n",
      "Iteration 12406 => Loss: 49.93615597846854115005\n",
      "Iteration 12407 => Loss: 49.93596451098454735984\n",
      "Iteration 12408 => Loss: 49.93577304500316671465\n",
      "Iteration 12409 => Loss: 49.93558158052442763619\n",
      "Iteration 12410 => Loss: 49.93539011754826617562\n",
      "Iteration 12411 => Loss: 49.93519865607468943836\n",
      "Iteration 12412 => Loss: 49.93500719610371874069\n",
      "Iteration 12413 => Loss: 49.93481573763530434462\n",
      "Iteration 12414 => Loss: 49.93462428066945335559\n",
      "Iteration 12415 => Loss: 49.93443282520614445730\n",
      "Iteration 12416 => Loss: 49.93424137124534922805\n",
      "Iteration 12417 => Loss: 49.93404991878708187869\n",
      "Iteration 12418 => Loss: 49.93385846783135662008\n",
      "Iteration 12419 => Loss: 49.93366701837809529252\n",
      "Iteration 12420 => Loss: 49.93347557042732631771\n",
      "Iteration 12421 => Loss: 49.93328412397902837938\n",
      "Iteration 12422 => Loss: 49.93309267903321568838\n",
      "Iteration 12423 => Loss: 49.93290123558981719043\n",
      "Iteration 12424 => Loss: 49.93270979364886841267\n",
      "Iteration 12425 => Loss: 49.93251835321034803883\n",
      "Iteration 12426 => Loss: 49.93232691427423475261\n",
      "Iteration 12427 => Loss: 49.93213547684054276488\n",
      "Iteration 12428 => Loss: 49.93194404090922233763\n",
      "Iteration 12429 => Loss: 49.93175260648029478716\n",
      "Iteration 12430 => Loss: 49.93156117355373879718\n",
      "Iteration 12431 => Loss: 49.93136974212951173513\n",
      "Iteration 12432 => Loss: 49.93117831220765623357\n",
      "Iteration 12433 => Loss: 49.93098688378813676536\n",
      "Iteration 12434 => Loss: 49.93079545687091780337\n",
      "Iteration 12435 => Loss: 49.93060403145599224217\n",
      "Iteration 12436 => Loss: 49.93041260754340981975\n",
      "Iteration 12437 => Loss: 49.93022118513307816556\n",
      "Iteration 12438 => Loss: 49.93002976422502570131\n",
      "Iteration 12439 => Loss: 49.92983834481923821613\n",
      "Iteration 12440 => Loss: 49.92964692691570149918\n",
      "Iteration 12441 => Loss: 49.92945551051440133961\n",
      "Iteration 12442 => Loss: 49.92926409561532352654\n",
      "Iteration 12443 => Loss: 49.92907268221846806000\n",
      "Iteration 12444 => Loss: 49.92888127032379941284\n",
      "Iteration 12445 => Loss: 49.92868985993133179591\n",
      "Iteration 12446 => Loss: 49.92849845104103678750\n",
      "Iteration 12447 => Loss: 49.92830704365290728219\n",
      "Iteration 12448 => Loss: 49.92811563776693617456\n",
      "Iteration 12449 => Loss: 49.92792423338310925374\n",
      "Iteration 12450 => Loss: 49.92773283050141230888\n",
      "Iteration 12451 => Loss: 49.92754142912184533998\n",
      "Iteration 12452 => Loss: 49.92735002924437281990\n",
      "Iteration 12453 => Loss: 49.92715863086902317036\n",
      "Iteration 12454 => Loss: 49.92696723399574665336\n",
      "Iteration 12455 => Loss: 49.92677583862451484720\n",
      "Iteration 12456 => Loss: 49.92658444475537038443\n",
      "Iteration 12457 => Loss: 49.92639305238824931621\n",
      "Iteration 12458 => Loss: 49.92620166152318716968\n",
      "Iteration 12459 => Loss: 49.92601027216016262855\n",
      "Iteration 12460 => Loss: 49.92581888429911884941\n",
      "Iteration 12461 => Loss: 49.92562749794009846482\n",
      "Iteration 12462 => Loss: 49.92543611308308015850\n",
      "Iteration 12463 => Loss: 49.92524472972802129789\n",
      "Iteration 12464 => Loss: 49.92505334787490767212\n",
      "Iteration 12465 => Loss: 49.92486196752378901920\n",
      "Iteration 12466 => Loss: 49.92467058867459428484\n",
      "Iteration 12467 => Loss: 49.92447921132731636362\n",
      "Iteration 12468 => Loss: 49.92428783548199078268\n",
      "Iteration 12469 => Loss: 49.92409646113856069860\n",
      "Iteration 12470 => Loss: 49.92390508829699768967\n",
      "Iteration 12471 => Loss: 49.92371371695735859930\n",
      "Iteration 12472 => Loss: 49.92352234711957947866\n",
      "Iteration 12473 => Loss: 49.92333097878363901145\n",
      "Iteration 12474 => Loss: 49.92313961194956561940\n",
      "Iteration 12475 => Loss: 49.92294824661733798621\n",
      "Iteration 12476 => Loss: 49.92275688278694900646\n",
      "Iteration 12477 => Loss: 49.92256552045834183673\n",
      "Iteration 12478 => Loss: 49.92237415963153779330\n",
      "Iteration 12479 => Loss: 49.92218280030651555990\n",
      "Iteration 12480 => Loss: 49.92199144248330355822\n",
      "Iteration 12481 => Loss: 49.92180008616183783943\n",
      "Iteration 12482 => Loss: 49.92160873134213261437\n",
      "Iteration 12483 => Loss: 49.92141737802416656677\n",
      "Iteration 12484 => Loss: 49.92122602620791838035\n",
      "Iteration 12485 => Loss: 49.92103467589340937138\n",
      "Iteration 12486 => Loss: 49.92084332708059690731\n",
      "Iteration 12487 => Loss: 49.92065197976948809355\n",
      "Iteration 12488 => Loss: 49.92046063396005450841\n",
      "Iteration 12489 => Loss: 49.92026928965230325730\n",
      "Iteration 12490 => Loss: 49.92007794684619170766\n",
      "Iteration 12491 => Loss: 49.91988660554175538664\n",
      "Iteration 12492 => Loss: 49.91969526573895166166\n",
      "Iteration 12493 => Loss: 49.91950392743775211102\n",
      "Iteration 12494 => Loss: 49.91931259063817094557\n",
      "Iteration 12495 => Loss: 49.91912125534020816531\n",
      "Iteration 12496 => Loss: 49.91892992154382113767\n",
      "Iteration 12497 => Loss: 49.91873858924900986267\n",
      "Iteration 12498 => Loss: 49.91854725845576723486\n",
      "Iteration 12499 => Loss: 49.91835592916408614883\n",
      "Iteration 12500 => Loss: 49.91816460137393818286\n",
      "Iteration 12501 => Loss: 49.91797327508530912610\n",
      "Iteration 12502 => Loss: 49.91778195029822740025\n",
      "Iteration 12503 => Loss: 49.91759062701262905648\n",
      "Iteration 12504 => Loss: 49.91739930522854251649\n",
      "Iteration 12505 => Loss: 49.91720798494593935857\n",
      "Iteration 12506 => Loss: 49.91701666616479826644\n",
      "Iteration 12507 => Loss: 49.91682534888510502924\n",
      "Iteration 12508 => Loss: 49.91663403310687385783\n",
      "Iteration 12509 => Loss: 49.91644271883009054136\n",
      "Iteration 12510 => Loss: 49.91625140605471244726\n",
      "Iteration 12511 => Loss: 49.91606009478074668095\n",
      "Iteration 12512 => Loss: 49.91586878500818613702\n",
      "Iteration 12513 => Loss: 49.91567747673703792088\n",
      "Iteration 12514 => Loss: 49.91548616996722387285\n",
      "Iteration 12515 => Loss: 49.91529486469880794175\n",
      "Iteration 12516 => Loss: 49.91510356093173328418\n",
      "Iteration 12517 => Loss: 49.91491225866601411099\n",
      "Iteration 12518 => Loss: 49.91472095790160068418\n",
      "Iteration 12519 => Loss: 49.91452965863851432005\n",
      "Iteration 12520 => Loss: 49.91433836087674080773\n",
      "Iteration 12521 => Loss: 49.91414706461625883094\n",
      "Iteration 12522 => Loss: 49.91395576985706128426\n",
      "Iteration 12523 => Loss: 49.91376447659913395682\n",
      "Iteration 12524 => Loss: 49.91357318484247684864\n",
      "Iteration 12525 => Loss: 49.91338189458705443258\n",
      "Iteration 12526 => Loss: 49.91319060583287381405\n",
      "Iteration 12527 => Loss: 49.91299931857991367679\n",
      "Iteration 12528 => Loss: 49.91280803282816691535\n",
      "Iteration 12529 => Loss: 49.91261674857761931889\n",
      "Iteration 12530 => Loss: 49.91242546582825667656\n",
      "Iteration 12531 => Loss: 49.91223418458007898835\n",
      "Iteration 12532 => Loss: 49.91204290483305072712\n",
      "Iteration 12533 => Loss: 49.91185162658720031459\n",
      "Iteration 12534 => Loss: 49.91166034984247090733\n",
      "Iteration 12535 => Loss: 49.91146907459886961078\n",
      "Iteration 12536 => Loss: 49.91127780085640353036\n",
      "Iteration 12537 => Loss: 49.91108652861503003351\n",
      "Iteration 12538 => Loss: 49.91089525787477043650\n",
      "Iteration 12539 => Loss: 49.91070398863558210678\n",
      "Iteration 12540 => Loss: 49.91051272089747925520\n",
      "Iteration 12541 => Loss: 49.91032145466039082748\n",
      "Iteration 12542 => Loss: 49.91013018992438787791\n",
      "Iteration 12543 => Loss: 49.90993892668939935220\n",
      "Iteration 12544 => Loss: 49.90974766495545367206\n",
      "Iteration 12545 => Loss: 49.90955640472251531037\n",
      "Iteration 12546 => Loss: 49.90936514599057716168\n",
      "Iteration 12547 => Loss: 49.90917388875962501515\n",
      "Iteration 12548 => Loss: 49.90898263302964465993\n",
      "Iteration 12549 => Loss: 49.90879137880063609600\n",
      "Iteration 12550 => Loss: 49.90860012607258511252\n",
      "Iteration 12551 => Loss: 49.90840887484547039321\n",
      "Iteration 12552 => Loss: 49.90821762511928483264\n",
      "Iteration 12553 => Loss: 49.90802637689400711452\n",
      "Iteration 12554 => Loss: 49.90783513016964434428\n",
      "Iteration 12555 => Loss: 49.90764388494618941650\n",
      "Iteration 12556 => Loss: 49.90745264122360680403\n",
      "Iteration 12557 => Loss: 49.90726139900188940146\n",
      "Iteration 12558 => Loss: 49.90707015828103010335\n",
      "Iteration 12559 => Loss: 49.90687891906101469885\n",
      "Iteration 12560 => Loss: 49.90668768134185739882\n",
      "Iteration 12561 => Loss: 49.90649644512348004355\n",
      "Iteration 12562 => Loss: 49.90630521040596079274\n",
      "Iteration 12563 => Loss: 49.90611397718922859212\n",
      "Iteration 12564 => Loss: 49.90592274547326212542\n",
      "Iteration 12565 => Loss: 49.90573151525808981432\n",
      "Iteration 12566 => Loss: 49.90554028654369034257\n",
      "Iteration 12567 => Loss: 49.90534905933002107759\n",
      "Iteration 12568 => Loss: 49.90515783361710333565\n",
      "Iteration 12569 => Loss: 49.90496660940493711678\n",
      "Iteration 12570 => Loss: 49.90477538669345847211\n",
      "Iteration 12571 => Loss: 49.90458416548271003421\n",
      "Iteration 12572 => Loss: 49.90439294577262785424\n",
      "Iteration 12573 => Loss: 49.90420172756323324847\n",
      "Iteration 12574 => Loss: 49.90401051085451911149\n",
      "Iteration 12575 => Loss: 49.90381929564647833786\n",
      "Iteration 12576 => Loss: 49.90362808193907540044\n",
      "Iteration 12577 => Loss: 49.90343686973228187753\n",
      "Iteration 12578 => Loss: 49.90324565902611908541\n",
      "Iteration 12579 => Loss: 49.90305444982059412951\n",
      "Iteration 12580 => Loss: 49.90286324211565727182\n",
      "Iteration 12581 => Loss: 49.90267203591129430151\n",
      "Iteration 12582 => Loss: 49.90248083120751942943\n",
      "Iteration 12583 => Loss: 49.90228962800429712843\n",
      "Iteration 12584 => Loss: 49.90209842630165582023\n",
      "Iteration 12585 => Loss: 49.90190722609953866140\n",
      "Iteration 12586 => Loss: 49.90171602739794565196\n",
      "Iteration 12587 => Loss: 49.90152483019687679189\n",
      "Iteration 12588 => Loss: 49.90133363449631076492\n",
      "Iteration 12589 => Loss: 49.90114244029624046561\n",
      "Iteration 12590 => Loss: 49.90095124759664457770\n",
      "Iteration 12591 => Loss: 49.90076005639752310117\n",
      "Iteration 12592 => Loss: 49.90056886669885471974\n",
      "Iteration 12593 => Loss: 49.90037767850063943342\n",
      "Iteration 12594 => Loss: 49.90018649180287013678\n",
      "Iteration 12595 => Loss: 49.89999530660550419725\n",
      "Iteration 12596 => Loss: 49.89980412290857003654\n",
      "Iteration 12597 => Loss: 49.89961294071201791667\n",
      "Iteration 12598 => Loss: 49.89942176001586204848\n",
      "Iteration 12599 => Loss: 49.89923058082007401026\n",
      "Iteration 12600 => Loss: 49.89903940312466090745\n",
      "Iteration 12601 => Loss: 49.89884822692960142376\n",
      "Iteration 12602 => Loss: 49.89865705223486713749\n",
      "Iteration 12603 => Loss: 49.89846587904047225948\n",
      "Iteration 12604 => Loss: 49.89827470734639547345\n",
      "Iteration 12605 => Loss: 49.89808353715262256856\n",
      "Iteration 12606 => Loss: 49.89789236845913933394\n",
      "Iteration 12607 => Loss: 49.89770120126595287502\n",
      "Iteration 12608 => Loss: 49.89751003557301345381\n",
      "Iteration 12609 => Loss: 49.89731887138034949203\n",
      "Iteration 12610 => Loss: 49.89712770868793256795\n",
      "Iteration 12611 => Loss: 49.89693654749572715446\n",
      "Iteration 12612 => Loss: 49.89674538780376877867\n",
      "Iteration 12613 => Loss: 49.89655422961202901888\n",
      "Iteration 12614 => Loss: 49.89636307292047234796\n",
      "Iteration 12615 => Loss: 49.89617191772909876590\n",
      "Iteration 12616 => Loss: 49.89598076403790827271\n",
      "Iteration 12617 => Loss: 49.89578961184689376296\n",
      "Iteration 12618 => Loss: 49.89559846115601260408\n",
      "Iteration 12619 => Loss: 49.89540731196526479607\n",
      "Iteration 12620 => Loss: 49.89521616427467165522\n",
      "Iteration 12621 => Loss: 49.89502501808418344353\n",
      "Iteration 12622 => Loss: 49.89483387339379305558\n",
      "Iteration 12623 => Loss: 49.89464273020352891308\n",
      "Iteration 12624 => Loss: 49.89445158851329154004\n",
      "Iteration 12625 => Loss: 49.89426044832316620159\n",
      "Iteration 12626 => Loss: 49.89406930963308894889\n",
      "Iteration 12627 => Loss: 49.89387817244305267650\n",
      "Iteration 12628 => Loss: 49.89368703675305027900\n",
      "Iteration 12629 => Loss: 49.89349590256308175640\n",
      "Iteration 12630 => Loss: 49.89330476987311868697\n",
      "Iteration 12631 => Loss: 49.89311363868313975445\n",
      "Iteration 12632 => Loss: 49.89292250899318048596\n",
      "Iteration 12633 => Loss: 49.89273138080317693266\n",
      "Iteration 12634 => Loss: 49.89254025411314330540\n",
      "Iteration 12635 => Loss: 49.89234912892305118248\n",
      "Iteration 12636 => Loss: 49.89215800523290056390\n",
      "Iteration 12637 => Loss: 49.89196688304267723879\n",
      "Iteration 12638 => Loss: 49.89177576235238831259\n",
      "Iteration 12639 => Loss: 49.89158464316199115274\n",
      "Iteration 12640 => Loss: 49.89139352547149997008\n",
      "Iteration 12641 => Loss: 49.89120240928086502663\n",
      "Iteration 12642 => Loss: 49.89101129459013606038\n",
      "Iteration 12643 => Loss: 49.89082018139923491162\n",
      "Iteration 12644 => Loss: 49.89062906970819000207\n",
      "Iteration 12645 => Loss: 49.89043795951696580460\n",
      "Iteration 12646 => Loss: 49.89024685082559074090\n",
      "Iteration 12647 => Loss: 49.89005574363402217841\n",
      "Iteration 12648 => Loss: 49.88986463794223169543\n",
      "Iteration 12649 => Loss: 49.88967353375024771367\n",
      "Iteration 12650 => Loss: 49.88948243105804181141\n",
      "Iteration 12651 => Loss: 49.88929132986557135609\n",
      "Iteration 12652 => Loss: 49.88910023017289319114\n",
      "Iteration 12653 => Loss: 49.88890913197990784056\n",
      "Iteration 12654 => Loss: 49.88871803528669346406\n",
      "Iteration 12655 => Loss: 49.88852694009317190194\n",
      "Iteration 12656 => Loss: 49.88833584639937157590\n",
      "Iteration 12657 => Loss: 49.88814475420525695881\n",
      "Iteration 12658 => Loss: 49.88795366351082805068\n",
      "Iteration 12659 => Loss: 49.88776257431603511350\n",
      "Iteration 12660 => Loss: 49.88757148662094920155\n",
      "Iteration 12661 => Loss: 49.88738040042547794428\n",
      "Iteration 12662 => Loss: 49.88718931572967818511\n",
      "Iteration 12663 => Loss: 49.88699823253346465890\n",
      "Iteration 12664 => Loss: 49.88680715083687289280\n",
      "Iteration 12665 => Loss: 49.88661607063986735966\n",
      "Iteration 12666 => Loss: 49.88642499194246227034\n",
      "Iteration 12667 => Loss: 49.88623391474465051942\n",
      "Iteration 12668 => Loss: 49.88604283904637526348\n",
      "Iteration 12669 => Loss: 49.88585176484767202965\n",
      "Iteration 12670 => Loss: 49.88566069214847686908\n",
      "Iteration 12671 => Loss: 49.88546962094884662520\n",
      "Iteration 12672 => Loss: 49.88527855124869603287\n",
      "Iteration 12673 => Loss: 49.88508748304806772467\n",
      "Iteration 12674 => Loss: 49.88489641634696880601\n",
      "Iteration 12675 => Loss: 49.88470535114532111720\n",
      "Iteration 12676 => Loss: 49.88451428744313886909\n",
      "Iteration 12677 => Loss: 49.88432322524042206169\n",
      "Iteration 12678 => Loss: 49.88413216453713516785\n",
      "Iteration 12679 => Loss: 49.88394110533330660928\n",
      "Iteration 12680 => Loss: 49.88375004762887954257\n",
      "Iteration 12681 => Loss: 49.88355899142387528400\n",
      "Iteration 12682 => Loss: 49.88336793671825830643\n",
      "Iteration 12683 => Loss: 49.88317688351204992614\n",
      "Iteration 12684 => Loss: 49.88298583180517908886\n",
      "Iteration 12685 => Loss: 49.88279478159768842715\n",
      "Iteration 12686 => Loss: 49.88260373288957083560\n",
      "Iteration 12687 => Loss: 49.88241268568077657619\n",
      "Iteration 12688 => Loss: 49.88222163997131275437\n",
      "Iteration 12689 => Loss: 49.88203059576117226470\n",
      "Iteration 12690 => Loss: 49.88183955305034089633\n",
      "Iteration 12691 => Loss: 49.88164851183879022756\n",
      "Iteration 12692 => Loss: 49.88145747212652025837\n",
      "Iteration 12693 => Loss: 49.88126643391353809420\n",
      "Iteration 12694 => Loss: 49.88107539719980110249\n",
      "Iteration 12695 => Loss: 49.88088436198530217780\n",
      "Iteration 12696 => Loss: 49.88069332827004842557\n",
      "Iteration 12697 => Loss: 49.88050229605401852950\n",
      "Iteration 12698 => Loss: 49.88031126533717696248\n",
      "Iteration 12699 => Loss: 49.88012023611956635705\n",
      "Iteration 12700 => Loss: 49.87992920840113697523\n",
      "Iteration 12701 => Loss: 49.87973818218186039530\n",
      "Iteration 12702 => Loss: 49.87954715746176503899\n",
      "Iteration 12703 => Loss: 49.87935613424082248457\n",
      "Iteration 12704 => Loss: 49.87916511251901852120\n",
      "Iteration 12705 => Loss: 49.87897409229631762173\n",
      "Iteration 12706 => Loss: 49.87878307357276241873\n",
      "Iteration 12707 => Loss: 49.87859205634830317422\n",
      "Iteration 12708 => Loss: 49.87840104062295409904\n",
      "Iteration 12709 => Loss: 49.87821002639665124434\n",
      "Iteration 12710 => Loss: 49.87801901366945855898\n",
      "Iteration 12711 => Loss: 49.87782800244128367240\n",
      "Iteration 12712 => Loss: 49.87763699271219053344\n",
      "Iteration 12713 => Loss: 49.87744598448211519326\n",
      "Iteration 12714 => Loss: 49.87725497775105765186\n",
      "Iteration 12715 => Loss: 49.87706397251901790924\n",
      "Iteration 12716 => Loss: 49.87687296878598175454\n",
      "Iteration 12717 => Loss: 49.87668196655192787148\n",
      "Iteration 12718 => Loss: 49.87649096581684915463\n",
      "Iteration 12719 => Loss: 49.87629996658071718230\n",
      "Iteration 12720 => Loss: 49.87610896884356748160\n",
      "Iteration 12721 => Loss: 49.87591797260534320912\n",
      "Iteration 12722 => Loss: 49.87572697786604436487\n",
      "Iteration 12723 => Loss: 49.87553598462565673799\n",
      "Iteration 12724 => Loss: 49.87534499288418743390\n",
      "Iteration 12725 => Loss: 49.87515400264161513633\n",
      "Iteration 12726 => Loss: 49.87496301389792563441\n",
      "Iteration 12727 => Loss: 49.87477202665308340102\n",
      "Iteration 12728 => Loss: 49.87458104090712396328\n",
      "Iteration 12729 => Loss: 49.87439005665998337236\n",
      "Iteration 12730 => Loss: 49.87419907391171136624\n",
      "Iteration 12731 => Loss: 49.87400809266223689065\n",
      "Iteration 12732 => Loss: 49.87381711291157415644\n",
      "Iteration 12733 => Loss: 49.87362613465973026905\n",
      "Iteration 12734 => Loss: 49.87343515790666259591\n",
      "Iteration 12735 => Loss: 49.87324418265234271530\n",
      "Iteration 12736 => Loss: 49.87305320889681325980\n",
      "Iteration 12737 => Loss: 49.87286223664003870226\n",
      "Iteration 12738 => Loss: 49.87267126588199772641\n",
      "Iteration 12739 => Loss: 49.87248029662268322681\n",
      "Iteration 12740 => Loss: 49.87228932886208809805\n",
      "Iteration 12741 => Loss: 49.87209836260019102383\n",
      "Iteration 12742 => Loss: 49.87190739783700621501\n",
      "Iteration 12743 => Loss: 49.87171643457249103903\n",
      "Iteration 12744 => Loss: 49.87152547280665260132\n",
      "Iteration 12745 => Loss: 49.87133451253945537474\n",
      "Iteration 12746 => Loss: 49.87114355377090646471\n",
      "Iteration 12747 => Loss: 49.87095259650100587123\n",
      "Iteration 12748 => Loss: 49.87076164072973938346\n",
      "Iteration 12749 => Loss: 49.87057068645706436882\n",
      "Iteration 12750 => Loss: 49.87037973368297372190\n",
      "Iteration 12751 => Loss: 49.87018878240748165354\n",
      "Iteration 12752 => Loss: 49.86999783263058105831\n",
      "Iteration 12753 => Loss: 49.86980688435222219823\n",
      "Iteration 12754 => Loss: 49.86961593757241928415\n",
      "Iteration 12755 => Loss: 49.86942499229117942150\n",
      "Iteration 12756 => Loss: 49.86923404850844576686\n",
      "Iteration 12757 => Loss: 49.86904310622423253108\n",
      "Iteration 12758 => Loss: 49.86885216543852550330\n",
      "Iteration 12759 => Loss: 49.86866122615133178897\n",
      "Iteration 12760 => Loss: 49.86847028836259454465\n",
      "Iteration 12761 => Loss: 49.86827935207233508663\n",
      "Iteration 12762 => Loss: 49.86808841728052499320\n",
      "Iteration 12763 => Loss: 49.86789748398717847522\n",
      "Iteration 12764 => Loss: 49.86770655219223868926\n",
      "Iteration 12765 => Loss: 49.86751562189574826789\n",
      "Iteration 12766 => Loss: 49.86732469309765036769\n",
      "Iteration 12767 => Loss: 49.86713376579797341037\n",
      "Iteration 12768 => Loss: 49.86694283999666765794\n",
      "Iteration 12769 => Loss: 49.86675191569374732126\n",
      "Iteration 12770 => Loss: 49.86656099288917687318\n",
      "Iteration 12771 => Loss: 49.86637007158297762999\n",
      "Iteration 12772 => Loss: 49.86617915177510695912\n",
      "Iteration 12773 => Loss: 49.86598823346553643887\n",
      "Iteration 12774 => Loss: 49.86579731665431580723\n",
      "Iteration 12775 => Loss: 49.86560640134140953705\n",
      "Iteration 12776 => Loss: 49.86541548752677499579\n",
      "Iteration 12777 => Loss: 49.86522457521042639428\n",
      "Iteration 12778 => Loss: 49.86503366439236373253\n",
      "Iteration 12779 => Loss: 49.86484275507254437798\n",
      "Iteration 12780 => Loss: 49.86465184725097543605\n",
      "Iteration 12781 => Loss: 49.86446094092762848504\n",
      "Iteration 12782 => Loss: 49.86427003610251773580\n",
      "Iteration 12783 => Loss: 49.86407913277561476662\n",
      "Iteration 12784 => Loss: 49.86388823094691247206\n",
      "Iteration 12785 => Loss: 49.86369733061639664129\n",
      "Iteration 12786 => Loss: 49.86350643178407437972\n",
      "Iteration 12787 => Loss: 49.86331553444988884394\n",
      "Iteration 12788 => Loss: 49.86312463861385424480\n",
      "Iteration 12789 => Loss: 49.86293374427599189858\n",
      "Iteration 12790 => Loss: 49.86274285143623785643\n",
      "Iteration 12791 => Loss: 49.86255196009457790751\n",
      "Iteration 12792 => Loss: 49.86236107025106178980\n",
      "Iteration 12793 => Loss: 49.86217018190561134361\n",
      "Iteration 12794 => Loss: 49.86197929505824788521\n",
      "Iteration 12795 => Loss: 49.86178840970897141460\n",
      "Iteration 12796 => Loss: 49.86159752585773929923\n",
      "Iteration 12797 => Loss: 49.86140664350457996079\n",
      "Iteration 12798 => Loss: 49.86121576264941523959\n",
      "Iteration 12799 => Loss: 49.86102488329230197905\n",
      "Iteration 12800 => Loss: 49.86083400543319044118\n",
      "Iteration 12801 => Loss: 49.86064312907205220426\n",
      "Iteration 12802 => Loss: 49.86045225420894411172\n",
      "Iteration 12803 => Loss: 49.86026138084378800386\n",
      "Iteration 12804 => Loss: 49.86007050897661230238\n",
      "Iteration 12805 => Loss: 49.85987963860735305843\n",
      "Iteration 12806 => Loss: 49.85968876973606001002\n",
      "Iteration 12807 => Loss: 49.85949790236269052457\n",
      "Iteration 12808 => Loss: 49.85930703648725881294\n",
      "Iteration 12809 => Loss: 49.85911617210970803171\n",
      "Iteration 12810 => Loss: 49.85892530923004528631\n",
      "Iteration 12811 => Loss: 49.85873444784829899845\n",
      "Iteration 12812 => Loss: 49.85854358796440521928\n",
      "Iteration 12813 => Loss: 49.85835272957836394880\n",
      "Iteration 12814 => Loss: 49.85816187269016097616\n",
      "Iteration 12815 => Loss: 49.85797101729981761764\n",
      "Iteration 12816 => Loss: 49.85778016340726992439\n",
      "Iteration 12817 => Loss: 49.85758931101254631812\n",
      "Iteration 12818 => Loss: 49.85739846011563258799\n",
      "Iteration 12819 => Loss: 49.85720761071650031226\n",
      "Iteration 12820 => Loss: 49.85701676281512817468\n",
      "Iteration 12821 => Loss: 49.85682591641153749151\n",
      "Iteration 12822 => Loss: 49.85663507150569984105\n",
      "Iteration 12823 => Loss: 49.85644422809760811788\n",
      "Iteration 12824 => Loss: 49.85625338618721968942\n",
      "Iteration 12825 => Loss: 49.85606254577456297739\n",
      "Iteration 12826 => Loss: 49.85587170685962377092\n",
      "Iteration 12827 => Loss: 49.85568086944237364833\n",
      "Iteration 12828 => Loss: 49.85549003352279129331\n",
      "Iteration 12829 => Loss: 49.85529919910088381130\n",
      "Iteration 12830 => Loss: 49.85510836617665830772\n",
      "Iteration 12831 => Loss: 49.85491753475003662288\n",
      "Iteration 12832 => Loss: 49.85472670482107560019\n",
      "Iteration 12833 => Loss: 49.85453587638973260709\n",
      "Iteration 12834 => Loss: 49.85434504945601474901\n",
      "Iteration 12835 => Loss: 49.85415422401987228795\n",
      "Iteration 12836 => Loss: 49.85396340008133364563\n",
      "Iteration 12837 => Loss: 49.85377257764037750576\n",
      "Iteration 12838 => Loss: 49.85358175669696834120\n",
      "Iteration 12839 => Loss: 49.85339093725112036282\n",
      "Iteration 12840 => Loss: 49.85320011930280514889\n",
      "Iteration 12841 => Loss: 49.85300930285202269943\n",
      "Iteration 12842 => Loss: 49.85281848789876590899\n",
      "Iteration 12843 => Loss: 49.85262767444303477760\n",
      "Iteration 12844 => Loss: 49.85243686248477246181\n",
      "Iteration 12845 => Loss: 49.85224605202396475079\n",
      "Iteration 12846 => Loss: 49.85205524306067559337\n",
      "Iteration 12847 => Loss: 49.85186443559481972443\n",
      "Iteration 12848 => Loss: 49.85167362962641135482\n",
      "Iteration 12849 => Loss: 49.85148282515545758997\n",
      "Iteration 12850 => Loss: 49.85129202218189448104\n",
      "Iteration 12851 => Loss: 49.85110122070576466058\n",
      "Iteration 12852 => Loss: 49.85091042072703970689\n",
      "Iteration 12853 => Loss: 49.85071962224570540911\n",
      "Iteration 12854 => Loss: 49.85052882526172624011\n",
      "Iteration 12855 => Loss: 49.85033802977513062160\n",
      "Iteration 12856 => Loss: 49.85014723578587592101\n",
      "Iteration 12857 => Loss: 49.84995644329395503291\n",
      "Iteration 12858 => Loss: 49.84976565229938927359\n",
      "Iteration 12859 => Loss: 49.84957486280212890506\n",
      "Iteration 12860 => Loss: 49.84938407480215971646\n",
      "Iteration 12861 => Loss: 49.84919328829951723492\n",
      "Iteration 12862 => Loss: 49.84900250329413040618\n",
      "Iteration 12863 => Loss: 49.84881171978602765194\n",
      "Iteration 12864 => Loss: 49.84862093777515923421\n",
      "Iteration 12865 => Loss: 49.84843015726156778555\n",
      "Iteration 12866 => Loss: 49.84823937824520356799\n",
      "Iteration 12867 => Loss: 49.84804860072607368693\n",
      "Iteration 12868 => Loss: 49.84785782470413550982\n",
      "Iteration 12869 => Loss: 49.84766705017939614208\n",
      "Iteration 12870 => Loss: 49.84747627715186268915\n",
      "Iteration 12871 => Loss: 49.84728550562147830760\n",
      "Iteration 12872 => Loss: 49.84709473558829273543\n",
      "Iteration 12873 => Loss: 49.84690396705223491836\n",
      "Iteration 12874 => Loss: 49.84671320001333327809\n",
      "Iteration 12875 => Loss: 49.84652243447156649836\n",
      "Iteration 12876 => Loss: 49.84633167042689905202\n",
      "Iteration 12877 => Loss: 49.84614090787933804449\n",
      "Iteration 12878 => Loss: 49.84595014682887637036\n",
      "Iteration 12879 => Loss: 49.84575938727551402962\n",
      "Iteration 12880 => Loss: 49.84556862921921549514\n",
      "Iteration 12881 => Loss: 49.84537787265995234520\n",
      "Iteration 12882 => Loss: 49.84518711759777431780\n",
      "Iteration 12883 => Loss: 49.84499636403260325324\n",
      "Iteration 12884 => Loss: 49.84480561196446757322\n",
      "Iteration 12885 => Loss: 49.84461486139333175061\n",
      "Iteration 12886 => Loss: 49.84442411231922420711\n",
      "Iteration 12887 => Loss: 49.84423336474206678304\n",
      "Iteration 12888 => Loss: 49.84404261866189500552\n",
      "Iteration 12889 => Loss: 49.84385187407871597998\n",
      "Iteration 12890 => Loss: 49.84366113099247286300\n",
      "Iteration 12891 => Loss: 49.84347038940316565458\n",
      "Iteration 12892 => Loss: 49.84327964931080146016\n",
      "Iteration 12893 => Loss: 49.84308891071535896344\n",
      "Iteration 12894 => Loss: 49.84289817361680263730\n",
      "Iteration 12895 => Loss: 49.84270743801516090343\n",
      "Iteration 12896 => Loss: 49.84251670391039112928\n",
      "Iteration 12897 => Loss: 49.84232597130250042028\n",
      "Iteration 12898 => Loss: 49.84213524019146035471\n",
      "Iteration 12899 => Loss: 49.84194451057725672172\n",
      "Iteration 12900 => Loss: 49.84175378245992504844\n",
      "Iteration 12901 => Loss: 49.84156305583938717518\n",
      "Iteration 12902 => Loss: 49.84137233071567152365\n",
      "Iteration 12903 => Loss: 49.84118160708875677756\n",
      "Iteration 12904 => Loss: 49.84099088495862872605\n",
      "Iteration 12905 => Loss: 49.84080016432528026371\n",
      "Iteration 12906 => Loss: 49.84060944518869717967\n",
      "Iteration 12907 => Loss: 49.84041872754887236852\n",
      "Iteration 12908 => Loss: 49.84022801140577030310\n",
      "Iteration 12909 => Loss: 49.84003729675939808885\n",
      "Iteration 12910 => Loss: 49.83984658360977704206\n",
      "Iteration 12911 => Loss: 49.83965587195684321387\n",
      "Iteration 12912 => Loss: 49.83946516180062502599\n",
      "Iteration 12913 => Loss: 49.83927445314105142415\n",
      "Iteration 12914 => Loss: 49.83908374597816504092\n",
      "Iteration 12915 => Loss: 49.83889304031195166544\n",
      "Iteration 12916 => Loss: 49.83870233614236155972\n",
      "Iteration 12917 => Loss: 49.83851163346943025090\n",
      "Iteration 12918 => Loss: 49.83832093229312931726\n",
      "Iteration 12919 => Loss: 49.83813023261341612624\n",
      "Iteration 12920 => Loss: 49.83793953443030488870\n",
      "Iteration 12921 => Loss: 49.83774883774380271007\n",
      "Iteration 12922 => Loss: 49.83755814255387406320\n",
      "Iteration 12923 => Loss: 49.83736744886049763181\n",
      "Iteration 12924 => Loss: 49.83717675666368762677\n",
      "Iteration 12925 => Loss: 49.83698606596340852093\n",
      "Iteration 12926 => Loss: 49.83679537675966741972\n",
      "Iteration 12927 => Loss: 49.83660468905244300686\n",
      "Iteration 12928 => Loss: 49.83641400284174238777\n",
      "Iteration 12929 => Loss: 49.83622331812751582447\n",
      "Iteration 12930 => Loss: 49.83603263490979173866\n",
      "Iteration 12931 => Loss: 49.83584195318852039236\n",
      "Iteration 12932 => Loss: 49.83565127296370889098\n",
      "Iteration 12933 => Loss: 49.83546059423535723454\n",
      "Iteration 12934 => Loss: 49.83526991700342279046\n",
      "Iteration 12935 => Loss: 49.83507924126795529673\n",
      "Iteration 12936 => Loss: 49.83488856702886948824\n",
      "Iteration 12937 => Loss: 49.83469789428618668126\n",
      "Iteration 12938 => Loss: 49.83450722303989266493\n",
      "Iteration 12939 => Loss: 49.83431655328999454468\n",
      "Iteration 12940 => Loss: 49.83412588503644258253\n",
      "Iteration 12941 => Loss: 49.83393521827925098933\n",
      "Iteration 12942 => Loss: 49.83374455301839844878\n",
      "Iteration 12943 => Loss: 49.83355388925387075005\n",
      "Iteration 12944 => Loss: 49.83336322698567499856\n",
      "Iteration 12945 => Loss: 49.83317256621380408887\n",
      "Iteration 12946 => Loss: 49.83298190693819407215\n",
      "Iteration 12947 => Loss: 49.83279124915886626468\n",
      "Iteration 12948 => Loss: 49.83260059287585619359\n",
      "Iteration 12949 => Loss: 49.83240993808905727747\n",
      "Iteration 12950 => Loss: 49.83221928479854057059\n",
      "Iteration 12951 => Loss: 49.83202863300424212412\n",
      "Iteration 12952 => Loss: 49.83183798270617614889\n",
      "Iteration 12953 => Loss: 49.83164733390430711779\n",
      "Iteration 12954 => Loss: 49.83145668659865634709\n",
      "Iteration 12955 => Loss: 49.83126604078919541507\n",
      "Iteration 12956 => Loss: 49.83107539647593142718\n",
      "Iteration 12957 => Loss: 49.83088475365880753998\n",
      "Iteration 12958 => Loss: 49.83069411233783796433\n",
      "Iteration 12959 => Loss: 49.83050347251300848939\n",
      "Iteration 12960 => Loss: 49.83031283418433332599\n",
      "Iteration 12961 => Loss: 49.83012219735175563073\n",
      "Iteration 12962 => Loss: 49.82993156201529671989\n",
      "Iteration 12963 => Loss: 49.82974092817492817176\n",
      "Iteration 12964 => Loss: 49.82955029583063577547\n",
      "Iteration 12965 => Loss: 49.82935966498244084733\n",
      "Iteration 12966 => Loss: 49.82916903563029364932\n",
      "Iteration 12967 => Loss: 49.82897840777417997060\n",
      "Iteration 12968 => Loss: 49.82878778141412823288\n",
      "Iteration 12969 => Loss: 49.82859715655008159274\n",
      "Iteration 12970 => Loss: 49.82840653318208268274\n",
      "Iteration 12971 => Loss: 49.82821591131006755404\n",
      "Iteration 12972 => Loss: 49.82802529093404331206\n",
      "Iteration 12973 => Loss: 49.82783467205398153510\n",
      "Iteration 12974 => Loss: 49.82764405466991064486\n",
      "Iteration 12975 => Loss: 49.82745343878175248165\n",
      "Iteration 12976 => Loss: 49.82726282438957099430\n",
      "Iteration 12977 => Loss: 49.82707221149333065568\n",
      "Iteration 12978 => Loss: 49.82688160009298883324\n",
      "Iteration 12979 => Loss: 49.82669099018858105410\n",
      "Iteration 12980 => Loss: 49.82650038178003626399\n",
      "Iteration 12981 => Loss: 49.82630977486740420090\n",
      "Iteration 12982 => Loss: 49.82611916945061381057\n",
      "Iteration 12983 => Loss: 49.82592856552971483097\n",
      "Iteration 12984 => Loss: 49.82573796310465752413\n",
      "Iteration 12985 => Loss: 49.82554736217542767918\n",
      "Iteration 12986 => Loss: 49.82535676274203950697\n",
      "Iteration 12987 => Loss: 49.82516616480445037496\n",
      "Iteration 12988 => Loss: 49.82497556836266738856\n",
      "Iteration 12989 => Loss: 49.82478497341668344234\n",
      "Iteration 12990 => Loss: 49.82459437996648432545\n",
      "Iteration 12991 => Loss: 49.82440378801202740533\n",
      "Iteration 12992 => Loss: 49.82421319755336241997\n",
      "Iteration 12993 => Loss: 49.82402260859041831509\n",
      "Iteration 12994 => Loss: 49.82383202112322351240\n",
      "Iteration 12995 => Loss: 49.82364143515171406307\n",
      "Iteration 12996 => Loss: 49.82345085067593259964\n",
      "Iteration 12997 => Loss: 49.82326026769585780585\n",
      "Iteration 12998 => Loss: 49.82306968621143994369\n",
      "Iteration 12999 => Loss: 49.82287910622271454031\n",
      "Iteration 13000 => Loss: 49.82268852772965317399\n",
      "Iteration 13001 => Loss: 49.82249795073225584474\n",
      "Iteration 13002 => Loss: 49.82230737523046570914\n",
      "Iteration 13003 => Loss: 49.82211680122431118889\n",
      "Iteration 13004 => Loss: 49.82192622871378517857\n",
      "Iteration 13005 => Loss: 49.82173565769886636190\n",
      "Iteration 13006 => Loss: 49.82154508817951921174\n",
      "Iteration 13007 => Loss: 49.82135452015574372808\n",
      "Iteration 13008 => Loss: 49.82116395362756833265\n",
      "Iteration 13009 => Loss: 49.82097338859492197116\n",
      "Iteration 13010 => Loss: 49.82078282505782595990\n",
      "Iteration 13011 => Loss: 49.82059226301628029887\n",
      "Iteration 13012 => Loss: 49.82040170247024946093\n",
      "Iteration 13013 => Loss: 49.82021114341971212980\n",
      "Iteration 13014 => Loss: 49.82002058586466830548\n",
      "Iteration 13015 => Loss: 49.81983002980512509339\n",
      "Iteration 13016 => Loss: 49.81963947524104696640\n",
      "Iteration 13017 => Loss: 49.81944892217244813537\n",
      "Iteration 13018 => Loss: 49.81925837059928596773\n",
      "Iteration 13019 => Loss: 49.81906782052156756890\n",
      "Iteration 13020 => Loss: 49.81887727193928583347\n",
      "Iteration 13021 => Loss: 49.81868672485241233971\n",
      "Iteration 13022 => Loss: 49.81849617926092577136\n",
      "Iteration 13023 => Loss: 49.81830563516481902298\n",
      "Iteration 13024 => Loss: 49.81811509256412762170\n",
      "Iteration 13025 => Loss: 49.81792455145880182954\n",
      "Iteration 13026 => Loss: 49.81773401184882743564\n",
      "Iteration 13027 => Loss: 49.81754347373418312372\n",
      "Iteration 13028 => Loss: 49.81735293711488310464\n",
      "Iteration 13029 => Loss: 49.81716240199089895668\n",
      "Iteration 13030 => Loss: 49.81697186836223778528\n",
      "Iteration 13031 => Loss: 49.81678133622885695786\n",
      "Iteration 13032 => Loss: 49.81659080559078489614\n",
      "Iteration 13033 => Loss: 49.81640027644795765127\n",
      "Iteration 13034 => Loss: 49.81620974880041075039\n",
      "Iteration 13035 => Loss: 49.81601922264811577179\n",
      "Iteration 13036 => Loss: 49.81582869799105850461\n",
      "Iteration 13037 => Loss: 49.81563817482923894886\n",
      "Iteration 13038 => Loss: 49.81544765316261447197\n",
      "Iteration 13039 => Loss: 49.81525713299121349564\n",
      "Iteration 13040 => Loss: 49.81506661431499338732\n",
      "Iteration 13041 => Loss: 49.81487609713394704158\n",
      "Iteration 13042 => Loss: 49.81468558144808156385\n",
      "Iteration 13043 => Loss: 49.81449506725736142698\n",
      "Iteration 13044 => Loss: 49.81430455456177242013\n",
      "Iteration 13045 => Loss: 49.81411404336136428128\n",
      "Iteration 13046 => Loss: 49.81392353365605885074\n",
      "Iteration 13047 => Loss: 49.81373302544584902307\n",
      "Iteration 13048 => Loss: 49.81354251873074190371\n",
      "Iteration 13049 => Loss: 49.81335201351072328180\n",
      "Iteration 13050 => Loss: 49.81316150978577184105\n",
      "Iteration 13051 => Loss: 49.81297100755591600318\n",
      "Iteration 13052 => Loss: 49.81278050682107760849\n",
      "Iteration 13053 => Loss: 49.81259000758127797326\n",
      "Iteration 13054 => Loss: 49.81239950983654551919\n",
      "Iteration 13055 => Loss: 49.81220901358678787574\n",
      "Iteration 13056 => Loss: 49.81201851883206188631\n",
      "Iteration 13057 => Loss: 49.81182802557231070750\n",
      "Iteration 13058 => Loss: 49.81163753380754855016\n",
      "Iteration 13059 => Loss: 49.81144704353773988714\n",
      "Iteration 13060 => Loss: 49.81125655476291314017\n",
      "Iteration 13061 => Loss: 49.81106606748301857124\n",
      "Iteration 13062 => Loss: 49.81087558169806328578\n",
      "Iteration 13063 => Loss: 49.81068509740801886210\n",
      "Iteration 13064 => Loss: 49.81049461461289240560\n",
      "Iteration 13065 => Loss: 49.81030413331268391630\n",
      "Iteration 13066 => Loss: 49.81011365350733655077\n",
      "Iteration 13067 => Loss: 49.80992317519687162530\n",
      "Iteration 13068 => Loss: 49.80973269838127492903\n",
      "Iteration 13069 => Loss: 49.80954222306052514568\n",
      "Iteration 13070 => Loss: 49.80935174923462227525\n",
      "Iteration 13071 => Loss: 49.80916127690355210689\n",
      "Iteration 13072 => Loss: 49.80897080606727200802\n",
      "Iteration 13073 => Loss: 49.80878033672582461122\n",
      "Iteration 13074 => Loss: 49.80858986887915307307\n",
      "Iteration 13075 => Loss: 49.80839940252729292069\n",
      "Iteration 13076 => Loss: 49.80820893767016599440\n",
      "Iteration 13077 => Loss: 49.80801847430780782133\n",
      "Iteration 13078 => Loss: 49.80782801244021840148\n",
      "Iteration 13079 => Loss: 49.80763755206734089143\n",
      "Iteration 13080 => Loss: 49.80744709318916818575\n",
      "Iteration 13081 => Loss: 49.80725663580575002243\n",
      "Iteration 13082 => Loss: 49.80706617991700824177\n",
      "Iteration 13083 => Loss: 49.80687572552294994921\n",
      "Iteration 13084 => Loss: 49.80668527262356803931\n",
      "Iteration 13085 => Loss: 49.80649482121887672292\n",
      "Iteration 13086 => Loss: 49.80630437130881205121\n",
      "Iteration 13087 => Loss: 49.80611392289339534045\n",
      "Iteration 13088 => Loss: 49.80592347597261948522\n",
      "Iteration 13089 => Loss: 49.80573303054644185295\n",
      "Iteration 13090 => Loss: 49.80554258661488375992\n",
      "Iteration 13091 => Loss: 49.80535214417791678443\n",
      "Iteration 13092 => Loss: 49.80516170323552671562\n",
      "Iteration 13093 => Loss: 49.80497126378769934263\n",
      "Iteration 13094 => Loss: 49.80478082583443466547\n",
      "Iteration 13095 => Loss: 49.80459038937573268413\n",
      "Iteration 13096 => Loss: 49.80439995441155076605\n",
      "Iteration 13097 => Loss: 49.80420952094189601667\n",
      "Iteration 13098 => Loss: 49.80401908896675422511\n",
      "Iteration 13099 => Loss: 49.80382865848611118054\n",
      "Iteration 13100 => Loss: 49.80363822949995977751\n",
      "Iteration 13101 => Loss: 49.80344780200829291061\n",
      "Iteration 13102 => Loss: 49.80325737601108926356\n",
      "Iteration 13103 => Loss: 49.80306695150832041463\n",
      "Iteration 13104 => Loss: 49.80287652850001478555\n",
      "Iteration 13105 => Loss: 49.80268610698610842746\n",
      "Iteration 13106 => Loss: 49.80249568696663686751\n",
      "Iteration 13107 => Loss: 49.80230526844159300026\n",
      "Iteration 13108 => Loss: 49.80211485141092708773\n",
      "Iteration 13109 => Loss: 49.80192443587464623533\n",
      "Iteration 13110 => Loss: 49.80173402183270781052\n",
      "Iteration 13111 => Loss: 49.80154360928516865670\n",
      "Iteration 13112 => Loss: 49.80135319823195771960\n",
      "Iteration 13113 => Loss: 49.80116278867310342093\n",
      "Iteration 13114 => Loss: 49.80097238060854181185\n",
      "Iteration 13115 => Loss: 49.80078197403829420864\n",
      "Iteration 13116 => Loss: 49.80059156896236061129\n",
      "Iteration 13117 => Loss: 49.80040116538073391439\n",
      "Iteration 13118 => Loss: 49.80021076329336437993\n",
      "Iteration 13119 => Loss: 49.80002036270025200793\n",
      "Iteration 13120 => Loss: 49.79982996360139679837\n",
      "Iteration 13121 => Loss: 49.79963956599679875126\n",
      "Iteration 13122 => Loss: 49.79944916988641523403\n",
      "Iteration 13123 => Loss: 49.79925877527026756297\n",
      "Iteration 13124 => Loss: 49.79906838214831310552\n",
      "Iteration 13125 => Loss: 49.79887799052055896709\n",
      "Iteration 13126 => Loss: 49.79868760038698383141\n",
      "Iteration 13127 => Loss: 49.79849721174758769848\n",
      "Iteration 13128 => Loss: 49.79830682460234925202\n",
      "Iteration 13129 => Loss: 49.79811643895124007031\n",
      "Iteration 13130 => Loss: 49.79792605479430989135\n",
      "Iteration 13131 => Loss: 49.79773567213148055544\n",
      "Iteration 13132 => Loss: 49.79754529096275916800\n",
      "Iteration 13133 => Loss: 49.79735491128813151818\n",
      "Iteration 13134 => Loss: 49.79716453310763313311\n",
      "Iteration 13135 => Loss: 49.79697415642116453682\n",
      "Iteration 13136 => Loss: 49.79678378122878257273\n",
      "Iteration 13137 => Loss: 49.79659340753045881911\n",
      "Iteration 13138 => Loss: 49.79640303532618617055\n",
      "Iteration 13139 => Loss: 49.79621266461591488905\n",
      "Iteration 13140 => Loss: 49.79602229539968760719\n",
      "Iteration 13141 => Loss: 49.79583192767746879781\n",
      "Iteration 13142 => Loss: 49.79564156144924425007\n",
      "Iteration 13143 => Loss: 49.79545119671497843683\n",
      "Iteration 13144 => Loss: 49.79526083347470688523\n",
      "Iteration 13145 => Loss: 49.79507047172839406812\n",
      "Iteration 13146 => Loss: 49.79488011147603288009\n",
      "Iteration 13147 => Loss: 49.79468975271760911028\n",
      "Iteration 13148 => Loss: 49.79449939545310144240\n",
      "Iteration 13149 => Loss: 49.79430903968251698188\n",
      "Iteration 13150 => Loss: 49.79411868540583441245\n",
      "Iteration 13151 => Loss: 49.79392833262303952324\n",
      "Iteration 13152 => Loss: 49.79373798133411810340\n",
      "Iteration 13153 => Loss: 49.79354763153907725837\n",
      "Iteration 13154 => Loss: 49.79335728323786725014\n",
      "Iteration 13155 => Loss: 49.79316693643053071128\n",
      "Iteration 13156 => Loss: 49.79297659111698948209\n",
      "Iteration 13157 => Loss: 49.79278624729730751142\n",
      "Iteration 13158 => Loss: 49.79259590497140663956\n",
      "Iteration 13159 => Loss: 49.79240556413931528823\n",
      "Iteration 13160 => Loss: 49.79221522480099082486\n",
      "Iteration 13161 => Loss: 49.79202488695646877659\n",
      "Iteration 13162 => Loss: 49.79183455060568519457\n",
      "Iteration 13163 => Loss: 49.79164421574866139508\n",
      "Iteration 13164 => Loss: 49.79145388238536895642\n",
      "Iteration 13165 => Loss: 49.79126355051582919486\n",
      "Iteration 13166 => Loss: 49.79107322013995684529\n",
      "Iteration 13167 => Loss: 49.79088289125780875111\n",
      "Iteration 13168 => Loss: 49.79069256386937780690\n",
      "Iteration 13169 => Loss: 49.79050223797459295838\n",
      "Iteration 13170 => Loss: 49.79031191357348973270\n",
      "Iteration 13171 => Loss: 49.79012159066603970814\n",
      "Iteration 13172 => Loss: 49.78993126925222867385\n",
      "Iteration 13173 => Loss: 49.78974094933204952440\n",
      "Iteration 13174 => Loss: 49.78955063090550225979\n",
      "Iteration 13175 => Loss: 49.78936031397255135289\n",
      "Iteration 13176 => Loss: 49.78916999853321101455\n",
      "Iteration 13177 => Loss: 49.78897968458746703391\n",
      "Iteration 13178 => Loss: 49.78878937213524835670\n",
      "Iteration 13179 => Loss: 49.78859906117663314262\n",
      "Iteration 13180 => Loss: 49.78840875171157165369\n",
      "Iteration 13181 => Loss: 49.78821844374002125733\n",
      "Iteration 13182 => Loss: 49.78802813726201748068\n",
      "Iteration 13183 => Loss: 49.78783783227753900746\n",
      "Iteration 13184 => Loss: 49.78764752878652899426\n",
      "Iteration 13185 => Loss: 49.78745722678903007363\n",
      "Iteration 13186 => Loss: 49.78726692628501382387\n",
      "Iteration 13187 => Loss: 49.78707662727446603412\n",
      "Iteration 13188 => Loss: 49.78688632975736538810\n",
      "Iteration 13189 => Loss: 49.78669603373371899124\n",
      "Iteration 13190 => Loss: 49.78650573920350552726\n",
      "Iteration 13191 => Loss: 49.78631544616670367986\n",
      "Iteration 13192 => Loss: 49.78612515462332055449\n",
      "Iteration 13193 => Loss: 49.78593486457333483486\n",
      "Iteration 13194 => Loss: 49.78574457601672520468\n",
      "Iteration 13195 => Loss: 49.78555428895350587482\n",
      "Iteration 13196 => Loss: 49.78536400338364842355\n",
      "Iteration 13197 => Loss: 49.78517371930713153461\n",
      "Iteration 13198 => Loss: 49.78498343672395520798\n",
      "Iteration 13199 => Loss: 49.78479315563410523282\n",
      "Iteration 13200 => Loss: 49.78460287603757450370\n",
      "Iteration 13201 => Loss: 49.78441259793435591519\n",
      "Iteration 13202 => Loss: 49.78422232132442104557\n",
      "Iteration 13203 => Loss: 49.78403204620778410572\n",
      "Iteration 13204 => Loss: 49.78384177258440246305\n",
      "Iteration 13205 => Loss: 49.78365150045426190673\n",
      "Iteration 13206 => Loss: 49.78346122981737664759\n",
      "Iteration 13207 => Loss: 49.78327096067373247479\n",
      "Iteration 13208 => Loss: 49.78308069302332938832\n",
      "Iteration 13209 => Loss: 49.78289042686612475563\n",
      "Iteration 13210 => Loss: 49.78270016220208304958\n",
      "Iteration 13211 => Loss: 49.78250989903126821901\n",
      "Iteration 13212 => Loss: 49.78231963735361631507\n",
      "Iteration 13213 => Loss: 49.78212937716912733777\n",
      "Iteration 13214 => Loss: 49.78193911847780128710\n",
      "Iteration 13215 => Loss: 49.78174886127958842508\n",
      "Iteration 13216 => Loss: 49.78155860557453138426\n",
      "Iteration 13217 => Loss: 49.78136835136256621581\n",
      "Iteration 13218 => Loss: 49.78117809864373555229\n",
      "Iteration 13219 => Loss: 49.78098784741796833941\n",
      "Iteration 13220 => Loss: 49.78079759768530720976\n",
      "Iteration 13221 => Loss: 49.78060734944570953076\n",
      "Iteration 13222 => Loss: 49.78041710269916109155\n",
      "Iteration 13223 => Loss: 49.78022685744567610300\n",
      "Iteration 13224 => Loss: 49.78003661368521903796\n",
      "Iteration 13225 => Loss: 49.77984637141777568559\n",
      "Iteration 13226 => Loss: 49.77965613064333894044\n",
      "Iteration 13227 => Loss: 49.77946589136192301339\n",
      "Iteration 13228 => Loss: 49.77927565357347816644\n",
      "Iteration 13229 => Loss: 49.77908541727801150500\n",
      "Iteration 13230 => Loss: 49.77889518247551592367\n",
      "Iteration 13231 => Loss: 49.77870494916596300072\n",
      "Iteration 13232 => Loss: 49.77851471734936694702\n",
      "Iteration 13233 => Loss: 49.77832448702567802457\n",
      "Iteration 13234 => Loss: 49.77813425819493176050\n",
      "Iteration 13235 => Loss: 49.77794403085708552226\n",
      "Iteration 13236 => Loss: 49.77775380501211088813\n",
      "Iteration 13237 => Loss: 49.77756358066004338525\n",
      "Iteration 13238 => Loss: 49.77737335780084038106\n",
      "Iteration 13239 => Loss: 49.77718313643449477013\n",
      "Iteration 13240 => Loss: 49.77699291656099234160\n",
      "Iteration 13241 => Loss: 49.77680269818034020091\n",
      "Iteration 13242 => Loss: 49.77661248129248150462\n",
      "Iteration 13243 => Loss: 49.77642226589745888532\n",
      "Iteration 13244 => Loss: 49.77623205199524392128\n",
      "Iteration 13245 => Loss: 49.77604183958580108538\n",
      "Iteration 13246 => Loss: 49.77585162866913037760\n",
      "Iteration 13247 => Loss: 49.77566141924523179796\n",
      "Iteration 13248 => Loss: 49.77547121131409824102\n",
      "Iteration 13249 => Loss: 49.77528100487567996879\n",
      "Iteration 13250 => Loss: 49.77509079993001961384\n",
      "Iteration 13251 => Loss: 49.77490059647707454360\n",
      "Iteration 13252 => Loss: 49.77471039451682344179\n",
      "Iteration 13253 => Loss: 49.77452019404927341384\n",
      "Iteration 13254 => Loss: 49.77432999507441024889\n",
      "Iteration 13255 => Loss: 49.77413979759220552523\n",
      "Iteration 13256 => Loss: 49.77394960160267345373\n",
      "Iteration 13257 => Loss: 49.77375940710577850723\n",
      "Iteration 13258 => Loss: 49.77356921410153489660\n",
      "Iteration 13259 => Loss: 49.77337902258990709470\n",
      "Iteration 13260 => Loss: 49.77318883257088799610\n",
      "Iteration 13261 => Loss: 49.77299864404447760080\n",
      "Iteration 13262 => Loss: 49.77280845701064748710\n",
      "Iteration 13263 => Loss: 49.77261827146942607669\n",
      "Iteration 13264 => Loss: 49.77242808742074231532\n",
      "Iteration 13265 => Loss: 49.77223790486461041382\n",
      "Iteration 13266 => Loss: 49.77204772380102326679\n",
      "Iteration 13267 => Loss: 49.77185754422997376878\n",
      "Iteration 13268 => Loss: 49.77166736615143349809\n",
      "Iteration 13269 => Loss: 49.77147718956543087643\n",
      "Iteration 13270 => Loss: 49.77128701447188774409\n",
      "Iteration 13271 => Loss: 49.77109684087084673365\n",
      "Iteration 13272 => Loss: 49.77090666876228652882\n",
      "Iteration 13273 => Loss: 49.77071649814615739160\n",
      "Iteration 13274 => Loss: 49.77052632902248774371\n",
      "Iteration 13275 => Loss: 49.77033616139126337430\n",
      "Iteration 13276 => Loss: 49.77014599525247007250\n",
      "Iteration 13277 => Loss: 49.76995583060608652204\n",
      "Iteration 13278 => Loss: 49.76976566745210561749\n",
      "Iteration 13279 => Loss: 49.76957550579051314799\n",
      "Iteration 13280 => Loss: 49.76938534562130200811\n",
      "Iteration 13281 => Loss: 49.76919518694443667073\n",
      "Iteration 13282 => Loss: 49.76900502975993845212\n",
      "Iteration 13283 => Loss: 49.76881487406780735228\n",
      "Iteration 13284 => Loss: 49.76862471986798652779\n",
      "Iteration 13285 => Loss: 49.76843456716047597865\n",
      "Iteration 13286 => Loss: 49.76824441594530412658\n",
      "Iteration 13287 => Loss: 49.76805426622242833901\n",
      "Iteration 13288 => Loss: 49.76786411799180598337\n",
      "Iteration 13289 => Loss: 49.76767397125347969222\n",
      "Iteration 13290 => Loss: 49.76748382600739972759\n",
      "Iteration 13291 => Loss: 49.76729368225358740574\n",
      "Iteration 13292 => Loss: 49.76710353999198588326\n",
      "Iteration 13293 => Loss: 49.76691339922264489815\n",
      "Iteration 13294 => Loss: 49.76672325994548629069\n",
      "Iteration 13295 => Loss: 49.76653312216055269346\n",
      "Iteration 13296 => Loss: 49.76634298586782279017\n",
      "Iteration 13297 => Loss: 49.76615285106723263198\n",
      "Iteration 13298 => Loss: 49.76596271775883195687\n",
      "Iteration 13299 => Loss: 49.76577258594259234314\n",
      "Iteration 13300 => Loss: 49.76558245561849247451\n",
      "Iteration 13301 => Loss: 49.76539232678652524555\n",
      "Iteration 13302 => Loss: 49.76520219944668355083\n",
      "Iteration 13303 => Loss: 49.76501207359895317950\n",
      "Iteration 13304 => Loss: 49.76482194924331281527\n",
      "Iteration 13305 => Loss: 49.76463182637975535272\n",
      "Iteration 13306 => Loss: 49.76444170500827368642\n",
      "Iteration 13307 => Loss: 49.76425158512886071094\n",
      "Iteration 13308 => Loss: 49.76406146674150221543\n",
      "Iteration 13309 => Loss: 49.76387134984616977817\n",
      "Iteration 13310 => Loss: 49.76368123444285629375\n",
      "Iteration 13311 => Loss: 49.76349112053159728930\n",
      "Iteration 13312 => Loss: 49.76330100811231460511\n",
      "Iteration 13313 => Loss: 49.76311089718501534662\n",
      "Iteration 13314 => Loss: 49.76292078774970661925\n",
      "Iteration 13315 => Loss: 49.76273067980638131758\n",
      "Iteration 13316 => Loss: 49.76254057335498259818\n",
      "Iteration 13317 => Loss: 49.76235046839555309361\n",
      "Iteration 13318 => Loss: 49.76216036492806438218\n",
      "Iteration 13319 => Loss: 49.76197026295247383132\n",
      "Iteration 13320 => Loss: 49.76178016246879565188\n",
      "Iteration 13321 => Loss: 49.76159006347703694928\n",
      "Iteration 13322 => Loss: 49.76139996597715509097\n",
      "Iteration 13323 => Loss: 49.76120986996915007694\n",
      "Iteration 13324 => Loss: 49.76101977545298638006\n",
      "Iteration 13325 => Loss: 49.76082968242872084375\n",
      "Iteration 13326 => Loss: 49.76063959089626109744\n",
      "Iteration 13327 => Loss: 49.76044950085560714115\n",
      "Iteration 13328 => Loss: 49.76025941230680871286\n",
      "Iteration 13329 => Loss: 49.76006932524980896915\n",
      "Iteration 13330 => Loss: 49.75987923968460080459\n",
      "Iteration 13331 => Loss: 49.75968915561117711377\n",
      "Iteration 13332 => Loss: 49.75949907302952368582\n",
      "Iteration 13333 => Loss: 49.75930899193961209903\n",
      "Iteration 13334 => Loss: 49.75911891234144235341\n",
      "Iteration 13335 => Loss: 49.75892883423503576523\n",
      "Iteration 13336 => Loss: 49.75873875762034259651\n",
      "Iteration 13337 => Loss: 49.75854868249734863639\n",
      "Iteration 13338 => Loss: 49.75835860886608230658\n",
      "Iteration 13339 => Loss: 49.75816853672645834195\n",
      "Iteration 13340 => Loss: 49.75797846607855490220\n",
      "Iteration 13341 => Loss: 49.75778839692229382763\n",
      "Iteration 13342 => Loss: 49.75759832925766801281\n",
      "Iteration 13343 => Loss: 49.75740826308470587946\n",
      "Iteration 13344 => Loss: 49.75721819840338611129\n",
      "Iteration 13345 => Loss: 49.75702813521366607574\n",
      "Iteration 13346 => Loss: 49.75683807351556708909\n",
      "Iteration 13347 => Loss: 49.75664801330903941334\n",
      "Iteration 13348 => Loss: 49.75645795459409725936\n",
      "Iteration 13349 => Loss: 49.75626789737074062714\n",
      "Iteration 13350 => Loss: 49.75607784163892688412\n",
      "Iteration 13351 => Loss: 49.75588778739867734657\n",
      "Iteration 13352 => Loss: 49.75569773464996359280\n",
      "Iteration 13353 => Loss: 49.75550768339276430652\n",
      "Iteration 13354 => Loss: 49.75531763362705106601\n",
      "Iteration 13355 => Loss: 49.75512758535288782014\n",
      "Iteration 13356 => Loss: 49.75493753857019640918\n",
      "Iteration 13357 => Loss: 49.75474749327896972773\n",
      "Iteration 13358 => Loss: 49.75455744947922909205\n",
      "Iteration 13359 => Loss: 49.75436740717092476416\n",
      "Iteration 13360 => Loss: 49.75417736635407095491\n",
      "Iteration 13361 => Loss: 49.75398732702863924260\n",
      "Iteration 13362 => Loss: 49.75379728919462962722\n",
      "Iteration 13363 => Loss: 49.75360725285203500334\n",
      "Iteration 13364 => Loss: 49.75341721800081273841\n",
      "Iteration 13365 => Loss: 49.75322718464099125413\n",
      "Iteration 13366 => Loss: 49.75303715277255633964\n",
      "Iteration 13367 => Loss: 49.75284712239545115153\n",
      "Iteration 13368 => Loss: 49.75265709350971121694\n",
      "Iteration 13369 => Loss: 49.75246706611532232500\n",
      "Iteration 13370 => Loss: 49.75227704021222052688\n",
      "Iteration 13371 => Loss: 49.75208701580045556057\n",
      "Iteration 13372 => Loss: 49.75189699287999900434\n",
      "Iteration 13373 => Loss: 49.75170697145080822565\n",
      "Iteration 13374 => Loss: 49.75151695151291164620\n",
      "Iteration 13375 => Loss: 49.75132693306628084429\n",
      "Iteration 13376 => Loss: 49.75113691611090871447\n",
      "Iteration 13377 => Loss: 49.75094690064677394048\n",
      "Iteration 13378 => Loss: 49.75075688667386941688\n",
      "Iteration 13379 => Loss: 49.75056687419219514368\n",
      "Iteration 13380 => Loss: 49.75037686320170848830\n",
      "Iteration 13381 => Loss: 49.75018685370243076704\n",
      "Iteration 13382 => Loss: 49.74999684569435487447\n",
      "Iteration 13383 => Loss: 49.74980683917740975630\n",
      "Iteration 13384 => Loss: 49.74961683415165225597\n",
      "Iteration 13385 => Loss: 49.74942683061705395176\n",
      "Iteration 13386 => Loss: 49.74923682857357221110\n",
      "Iteration 13387 => Loss: 49.74904682802122835028\n",
      "Iteration 13388 => Loss: 49.74885682896000815845\n",
      "Iteration 13389 => Loss: 49.74866683138986900303\n",
      "Iteration 13390 => Loss: 49.74847683531081088404\n",
      "Iteration 13391 => Loss: 49.74828684072286932860\n",
      "Iteration 13392 => Loss: 49.74809684762597328245\n",
      "Iteration 13393 => Loss: 49.74790685602013695643\n",
      "Iteration 13394 => Loss: 49.74771686590533903427\n",
      "Iteration 13395 => Loss: 49.74752687728157951597\n",
      "Iteration 13396 => Loss: 49.74733689014885840152\n",
      "Iteration 13397 => Loss: 49.74714690450712595293\n",
      "Iteration 13398 => Loss: 49.74695692035638217021\n",
      "Iteration 13399 => Loss: 49.74676693769664126421\n",
      "Iteration 13400 => Loss: 49.74657695652787481322\n",
      "Iteration 13401 => Loss: 49.74638697685004018467\n",
      "Iteration 13402 => Loss: 49.74619699866318711656\n",
      "Iteration 13403 => Loss: 49.74600702196726587090\n",
      "Iteration 13404 => Loss: 49.74581704676226934225\n",
      "Iteration 13405 => Loss: 49.74562707304819753062\n",
      "Iteration 13406 => Loss: 49.74543710082502201431\n",
      "Iteration 13407 => Loss: 49.74524713009272147701\n",
      "Iteration 13408 => Loss: 49.74505716085132434046\n",
      "Iteration 13409 => Loss: 49.74486719310078797207\n",
      "Iteration 13410 => Loss: 49.74467722684111947729\n",
      "Iteration 13411 => Loss: 49.74448726207226911811\n",
      "Iteration 13412 => Loss: 49.74429729879427952710\n",
      "Iteration 13413 => Loss: 49.74410733700710096628\n",
      "Iteration 13414 => Loss: 49.74391737671073343563\n",
      "Iteration 13415 => Loss: 49.74372741790517693516\n",
      "Iteration 13416 => Loss: 49.74353746059038172689\n",
      "Iteration 13417 => Loss: 49.74334750476638333794\n",
      "Iteration 13418 => Loss: 49.74315755043313913575\n",
      "Iteration 13419 => Loss: 49.74296759759065622575\n",
      "Iteration 13420 => Loss: 49.74277764623889908080\n",
      "Iteration 13421 => Loss: 49.74258769637786059548\n",
      "Iteration 13422 => Loss: 49.74239774800756208606\n",
      "Iteration 13423 => Loss: 49.74220780112796091998\n",
      "Iteration 13424 => Loss: 49.74201785573904288640\n",
      "Iteration 13425 => Loss: 49.74182791184082219615\n",
      "Iteration 13426 => Loss: 49.74163796943327042754\n",
      "Iteration 13427 => Loss: 49.74144802851635915886\n",
      "Iteration 13428 => Loss: 49.74125808909009549552\n",
      "Iteration 13429 => Loss: 49.74106815115447943754\n",
      "Iteration 13430 => Loss: 49.74087821470948966862\n",
      "Iteration 13431 => Loss: 49.74068827975510487249\n",
      "Iteration 13432 => Loss: 49.74049834629131794372\n",
      "Iteration 13433 => Loss: 49.74030841431812177689\n",
      "Iteration 13434 => Loss: 49.74011848383550216113\n",
      "Iteration 13435 => Loss: 49.73992855484343067474\n",
      "Iteration 13436 => Loss: 49.73973862734192863400\n",
      "Iteration 13437 => Loss: 49.73954870133096761720\n",
      "Iteration 13438 => Loss: 49.73935877681052630805\n",
      "Iteration 13439 => Loss: 49.73916885378061181200\n",
      "Iteration 13440 => Loss: 49.73897893224120281275\n",
      "Iteration 13441 => Loss: 49.73878901219229931030\n",
      "Iteration 13442 => Loss: 49.73859909363385156666\n",
      "Iteration 13443 => Loss: 49.73840917656589510898\n",
      "Iteration 13444 => Loss: 49.73821926098838730468\n",
      "Iteration 13445 => Loss: 49.73802934690132815376\n",
      "Iteration 13446 => Loss: 49.73783943430471765623\n",
      "Iteration 13447 => Loss: 49.73764952319849186324\n",
      "Iteration 13448 => Loss: 49.73745961358271472363\n",
      "Iteration 13449 => Loss: 49.73726970545735071028\n",
      "Iteration 13450 => Loss: 49.73707979882233587432\n",
      "Iteration 13451 => Loss: 49.73688989367774127004\n",
      "Iteration 13452 => Loss: 49.73669999002346742145\n",
      "Iteration 13453 => Loss: 49.73651008785957827740\n",
      "Iteration 13454 => Loss: 49.73632018718600988905\n",
      "Iteration 13455 => Loss: 49.73613028800277646724\n",
      "Iteration 13456 => Loss: 49.73594039030989222283\n",
      "Iteration 13457 => Loss: 49.73575049410728610155\n",
      "Iteration 13458 => Loss: 49.73556059939497231426\n",
      "Iteration 13459 => Loss: 49.73537070617295796637\n",
      "Iteration 13460 => Loss: 49.73518081444122174162\n",
      "Iteration 13461 => Loss: 49.73499092419972100743\n",
      "Iteration 13462 => Loss: 49.73480103544846997465\n",
      "Iteration 13463 => Loss: 49.73461114818748285415\n",
      "Iteration 13464 => Loss: 49.73442126241670990794\n",
      "Iteration 13465 => Loss: 49.73423137813612981972\n",
      "Iteration 13466 => Loss: 49.73404149534577101122\n",
      "Iteration 13467 => Loss: 49.73385161404560506071\n",
      "Iteration 13468 => Loss: 49.73366173423562486278\n",
      "Iteration 13469 => Loss: 49.73347185591578067942\n",
      "Iteration 13470 => Loss: 49.73328197908610803779\n",
      "Iteration 13471 => Loss: 49.73309210374658562159\n",
      "Iteration 13472 => Loss: 49.73290222989719211455\n",
      "Iteration 13473 => Loss: 49.73271235753790620038\n",
      "Iteration 13474 => Loss: 49.73252248666873498451\n",
      "Iteration 13475 => Loss: 49.73233261728965004522\n",
      "Iteration 13476 => Loss: 49.73214274940065848796\n",
      "Iteration 13477 => Loss: 49.73195288300176031271\n",
      "Iteration 13478 => Loss: 49.73176301809291999234\n",
      "Iteration 13479 => Loss: 49.73157315467410199972\n",
      "Iteration 13480 => Loss: 49.73138329274534186197\n",
      "Iteration 13481 => Loss: 49.73119343230661115740\n",
      "Iteration 13482 => Loss: 49.73100357335787435886\n",
      "Iteration 13483 => Loss: 49.73081371589915278264\n",
      "Iteration 13484 => Loss: 49.73062385993042511245\n",
      "Iteration 13485 => Loss: 49.73043400545169845373\n",
      "Iteration 13486 => Loss: 49.73024415246290885761\n",
      "Iteration 13487 => Loss: 49.73005430096408474583\n",
      "Iteration 13488 => Loss: 49.72986445095518348580\n",
      "Iteration 13489 => Loss: 49.72967460243624060467\n",
      "Iteration 13490 => Loss: 49.72948475540722057531\n",
      "Iteration 13491 => Loss: 49.72929490986810918685\n",
      "Iteration 13492 => Loss: 49.72910506581886380673\n",
      "Iteration 13493 => Loss: 49.72891522325952706751\n",
      "Iteration 13494 => Loss: 49.72872538219008475835\n",
      "Iteration 13495 => Loss: 49.72853554261049424667\n",
      "Iteration 13496 => Loss: 49.72834570452074842706\n",
      "Iteration 13497 => Loss: 49.72815586792084729950\n",
      "Iteration 13498 => Loss: 49.72796603281075533687\n",
      "Iteration 13499 => Loss: 49.72777619919050096087\n",
      "Iteration 13500 => Loss: 49.72758636706004864436\n",
      "Iteration 13501 => Loss: 49.72739653641938417650\n",
      "Iteration 13502 => Loss: 49.72720670726850755727\n",
      "Iteration 13503 => Loss: 49.72701687960736904870\n",
      "Iteration 13504 => Loss: 49.72682705343601128334\n",
      "Iteration 13505 => Loss: 49.72663722875440583948\n",
      "Iteration 13506 => Loss: 49.72644740556253140085\n",
      "Iteration 13507 => Loss: 49.72625758386037375658\n",
      "Iteration 13508 => Loss: 49.72606776364793290668\n",
      "Iteration 13509 => Loss: 49.72587794492519464029\n",
      "Iteration 13510 => Loss: 49.72568812769211632485\n",
      "Iteration 13511 => Loss: 49.72549831194874059292\n",
      "Iteration 13512 => Loss: 49.72530849769502481195\n",
      "Iteration 13513 => Loss: 49.72511868493094766563\n",
      "Iteration 13514 => Loss: 49.72492887365652336484\n",
      "Iteration 13515 => Loss: 49.72473906387173769872\n",
      "Iteration 13516 => Loss: 49.72454925557656224555\n",
      "Iteration 13517 => Loss: 49.72435944877097568906\n",
      "Iteration 13518 => Loss: 49.72416964345499934552\n",
      "Iteration 13519 => Loss: 49.72397983962860479323\n",
      "Iteration 13520 => Loss: 49.72379003729177782134\n",
      "Iteration 13521 => Loss: 49.72360023644451132441\n",
      "Iteration 13522 => Loss: 49.72341043708679109159\n",
      "Iteration 13523 => Loss: 49.72322063921860291202\n",
      "Iteration 13524 => Loss: 49.72303084283993257486\n",
      "Iteration 13525 => Loss: 49.72284104795077297467\n",
      "Iteration 13526 => Loss: 49.72265125455111700603\n",
      "Iteration 13527 => Loss: 49.72246146264097177436\n",
      "Iteration 13528 => Loss: 49.72227167222026622539\n",
      "Iteration 13529 => Loss: 49.72208188328905009712\n",
      "Iteration 13530 => Loss: 49.72189209584728786240\n",
      "Iteration 13531 => Loss: 49.72170230989496531038\n",
      "Iteration 13532 => Loss: 49.72151252543206823020\n",
      "Iteration 13533 => Loss: 49.72132274245859662187\n",
      "Iteration 13534 => Loss: 49.72113296097453627453\n",
      "Iteration 13535 => Loss: 49.72094318097985166105\n",
      "Iteration 13536 => Loss: 49.72075340247455699227\n",
      "Iteration 13537 => Loss: 49.72056362545863095193\n",
      "Iteration 13538 => Loss: 49.72037384993206643458\n",
      "Iteration 13539 => Loss: 49.72018407589485633480\n",
      "Iteration 13540 => Loss: 49.71999430334698644174\n",
      "Iteration 13541 => Loss: 49.71980453228844964997\n",
      "Iteration 13542 => Loss: 49.71961476271920332692\n",
      "Iteration 13543 => Loss: 49.71942499463928299974\n",
      "Iteration 13544 => Loss: 49.71923522804861761415\n",
      "Iteration 13545 => Loss: 49.71904546294727822442\n",
      "Iteration 13546 => Loss: 49.71885569933516535457\n",
      "Iteration 13547 => Loss: 49.71866593721231453173\n",
      "Iteration 13548 => Loss: 49.71847617657871865049\n",
      "Iteration 13549 => Loss: 49.71828641743434928912\n",
      "Iteration 13550 => Loss: 49.71809665977919934221\n",
      "Iteration 13551 => Loss: 49.71790690361325459889\n",
      "Iteration 13552 => Loss: 49.71771714893651505918\n",
      "Iteration 13553 => Loss: 49.71752739574894519592\n",
      "Iteration 13554 => Loss: 49.71733764405056632540\n",
      "Iteration 13555 => Loss: 49.71714789384133581507\n",
      "Iteration 13556 => Loss: 49.71695814512125366491\n",
      "Iteration 13557 => Loss: 49.71676839789031987493\n",
      "Iteration 13558 => Loss: 49.71657865214849181257\n",
      "Iteration 13559 => Loss: 49.71638890789579079410\n",
      "Iteration 13560 => Loss: 49.71619916513219550325\n",
      "Iteration 13561 => Loss: 49.71600942385768462373\n",
      "Iteration 13562 => Loss: 49.71581968407227236639\n",
      "Iteration 13563 => Loss: 49.71562994577593030954\n",
      "Iteration 13564 => Loss: 49.71544020896860871517\n",
      "Iteration 13565 => Loss: 49.71525047365035021585\n",
      "Iteration 13566 => Loss: 49.71506073982113349530\n",
      "Iteration 13567 => Loss: 49.71487100748092302638\n",
      "Iteration 13568 => Loss: 49.71468127662974012537\n",
      "Iteration 13569 => Loss: 49.71449154726754926514\n",
      "Iteration 13570 => Loss: 49.71430181939432912941\n",
      "Iteration 13571 => Loss: 49.71411209301010103445\n",
      "Iteration 13572 => Loss: 49.71392236811481524228\n",
      "Iteration 13573 => Loss: 49.71373264470850728003\n",
      "Iteration 13574 => Loss: 49.71354292279112030428\n",
      "Iteration 13575 => Loss: 49.71335320236266142047\n",
      "Iteration 13576 => Loss: 49.71316348342312352315\n",
      "Iteration 13577 => Loss: 49.71297376597249240149\n",
      "Iteration 13578 => Loss: 49.71278405001075384462\n",
      "Iteration 13579 => Loss: 49.71259433553790074711\n",
      "Iteration 13580 => Loss: 49.71240462255389047641\n",
      "Iteration 13581 => Loss: 49.71221491105876566508\n",
      "Iteration 13582 => Loss: 49.71202520105247657511\n",
      "Iteration 13583 => Loss: 49.71183549253502320653\n",
      "Iteration 13584 => Loss: 49.71164578550639134846\n",
      "Iteration 13585 => Loss: 49.71145607996658100092\n",
      "Iteration 13586 => Loss: 49.71126637591554953133\n",
      "Iteration 13587 => Loss: 49.71107667335331115055\n",
      "Iteration 13588 => Loss: 49.71088697227984454230\n",
      "Iteration 13589 => Loss: 49.71069727269517102286\n",
      "Iteration 13590 => Loss: 49.71050757459919822168\n",
      "Iteration 13591 => Loss: 49.71031787799201140388\n",
      "Iteration 13592 => Loss: 49.71012818287352530433\n",
      "Iteration 13593 => Loss: 49.70993848924378255560\n",
      "Iteration 13594 => Loss: 49.70974879710274052513\n",
      "Iteration 13595 => Loss: 49.70955910645036368578\n",
      "Iteration 13596 => Loss: 49.70936941728670888097\n",
      "Iteration 13597 => Loss: 49.70917972961169795099\n",
      "Iteration 13598 => Loss: 49.70899004342534510670\n",
      "Iteration 13599 => Loss: 49.70880035872765745353\n",
      "Iteration 13600 => Loss: 49.70861067551859235891\n",
      "Iteration 13601 => Loss: 49.70842099379815692828\n",
      "Iteration 13602 => Loss: 49.70823131356633695077\n",
      "Iteration 13603 => Loss: 49.70804163482308268840\n",
      "Iteration 13604 => Loss: 49.70785195756843677373\n",
      "Iteration 13605 => Loss: 49.70766228180240631218\n",
      "Iteration 13606 => Loss: 49.70747260752493446034\n",
      "Iteration 13607 => Loss: 49.70728293473598569108\n",
      "Iteration 13608 => Loss: 49.70709326343558132066\n",
      "Iteration 13609 => Loss: 49.70690359362371424368\n",
      "Iteration 13610 => Loss: 49.70671392530034182755\n",
      "Iteration 13611 => Loss: 49.70652425846551381028\n",
      "Iteration 13612 => Loss: 49.70633459311917334844\n",
      "Iteration 13613 => Loss: 49.70614492926130623118\n",
      "Iteration 13614 => Loss: 49.70595526689191956393\n",
      "Iteration 13615 => Loss: 49.70576560601097781955\n",
      "Iteration 13616 => Loss: 49.70557594661850941975\n",
      "Iteration 13617 => Loss: 49.70538628871447173196\n",
      "Iteration 13618 => Loss: 49.70519663229882922906\n",
      "Iteration 13619 => Loss: 49.70500697737163164902\n",
      "Iteration 13620 => Loss: 49.70481732393282925386\n",
      "Iteration 13621 => Loss: 49.70462767198241493816\n",
      "Iteration 13622 => Loss: 49.70443802152038870190\n",
      "Iteration 13623 => Loss: 49.70424837254671501796\n",
      "Iteration 13624 => Loss: 49.70405872506140099176\n",
      "Iteration 13625 => Loss: 49.70386907906441109617\n",
      "Iteration 13626 => Loss: 49.70367943455578085832\n",
      "Iteration 13627 => Loss: 49.70348979153545343479\n",
      "Iteration 13628 => Loss: 49.70330015000344303644\n",
      "Iteration 13629 => Loss: 49.70311050995972124156\n",
      "Iteration 13630 => Loss: 49.70292087140431647185\n",
      "Iteration 13631 => Loss: 49.70273123433715056763\n",
      "Iteration 13632 => Loss: 49.70254159875826616144\n",
      "Iteration 13633 => Loss: 49.70235196466762772616\n",
      "Iteration 13634 => Loss: 49.70216233206522105093\n",
      "Iteration 13635 => Loss: 49.70197270095103192489\n",
      "Iteration 13636 => Loss: 49.70178307132507455890\n",
      "Iteration 13637 => Loss: 49.70159344318729921497\n",
      "Iteration 13638 => Loss: 49.70140381653775563109\n",
      "Iteration 13639 => Loss: 49.70121419137634433127\n",
      "Iteration 13640 => Loss: 49.70102456770314347523\n",
      "Iteration 13641 => Loss: 49.70083494551807490325\n",
      "Iteration 13642 => Loss: 49.70064532482115993162\n",
      "Iteration 13643 => Loss: 49.70045570561237724405\n",
      "Iteration 13644 => Loss: 49.70026608789170552427\n",
      "Iteration 13645 => Loss: 49.70007647165915898313\n",
      "Iteration 13646 => Loss: 49.69988685691470919892\n",
      "Iteration 13647 => Loss: 49.69969724365834906621\n",
      "Iteration 13648 => Loss: 49.69950763189003595244\n",
      "Iteration 13649 => Loss: 49.69931802160981249017\n",
      "Iteration 13650 => Loss: 49.69912841281762183598\n",
      "Iteration 13651 => Loss: 49.69893880551349951702\n",
      "Iteration 13652 => Loss: 49.69874919969738158443\n",
      "Iteration 13653 => Loss: 49.69855959536927514364\n",
      "Iteration 13654 => Loss: 49.69836999252917308922\n",
      "Iteration 13655 => Loss: 49.69818039117708963204\n",
      "Iteration 13656 => Loss: 49.69799079131298213952\n",
      "Iteration 13657 => Loss: 49.69780119293682218995\n",
      "Iteration 13658 => Loss: 49.69761159604864531047\n",
      "Iteration 13659 => Loss: 49.69742200064840886853\n",
      "Iteration 13660 => Loss: 49.69723240673609154783\n",
      "Iteration 13661 => Loss: 49.69704281431170045380\n",
      "Iteration 13662 => Loss: 49.69685322337524269187\n",
      "Iteration 13663 => Loss: 49.69666363392664720777\n",
      "Iteration 13664 => Loss: 49.69647404596597084492\n",
      "Iteration 13665 => Loss: 49.69628445949317807617\n",
      "Iteration 13666 => Loss: 49.69609487450821205812\n",
      "Iteration 13667 => Loss: 49.69590529101112963417\n",
      "Iteration 13668 => Loss: 49.69571570900187396091\n",
      "Iteration 13669 => Loss: 49.69552612848044503835\n",
      "Iteration 13670 => Loss: 49.69533654944686418276\n",
      "Iteration 13671 => Loss: 49.69514697190106033986\n",
      "Iteration 13672 => Loss: 49.69495739584306193137\n",
      "Iteration 13673 => Loss: 49.69476782127284764101\n",
      "Iteration 13674 => Loss: 49.69457824819039615249\n",
      "Iteration 13675 => Loss: 49.69438867659572167668\n",
      "Iteration 13676 => Loss: 49.69419910648877447557\n",
      "Iteration 13677 => Loss: 49.69400953786956165459\n",
      "Iteration 13678 => Loss: 49.69381997073810453003\n",
      "Iteration 13679 => Loss: 49.69363040509431783676\n",
      "Iteration 13680 => Loss: 49.69344084093825131276\n",
      "Iteration 13681 => Loss: 49.69325127826988364177\n",
      "Iteration 13682 => Loss: 49.69306171708918640206\n",
      "Iteration 13683 => Loss: 49.69287215739614538279\n",
      "Iteration 13684 => Loss: 49.69268259919077479481\n",
      "Iteration 13685 => Loss: 49.69249304247303911097\n",
      "Iteration 13686 => Loss: 49.69230348724293122586\n",
      "Iteration 13687 => Loss: 49.69211393350045113948\n",
      "Iteration 13688 => Loss: 49.69192438124557043011\n",
      "Iteration 13689 => Loss: 49.69173483047830330861\n",
      "Iteration 13690 => Loss: 49.69154528119861424784\n",
      "Iteration 13691 => Loss: 49.69135573340649614238\n",
      "Iteration 13692 => Loss: 49.69116618710192057051\n",
      "Iteration 13693 => Loss: 49.69097664228491595395\n",
      "Iteration 13694 => Loss: 49.69078709895544676556\n",
      "Iteration 13695 => Loss: 49.69059755711349168905\n",
      "Iteration 13696 => Loss: 49.69040801675904361900\n",
      "Iteration 13697 => Loss: 49.69021847789212387170\n",
      "Iteration 13698 => Loss: 49.69002894051267560371\n",
      "Iteration 13699 => Loss: 49.68983940462072013133\n",
      "Iteration 13700 => Loss: 49.68964987021623613828\n",
      "Iteration 13701 => Loss: 49.68946033729919520283\n",
      "Iteration 13702 => Loss: 49.68927080586958311414\n",
      "Iteration 13703 => Loss: 49.68908127592743539935\n",
      "Iteration 13704 => Loss: 49.68889174747270232047\n",
      "Iteration 13705 => Loss: 49.68870222050537677205\n",
      "Iteration 13706 => Loss: 49.68851269502543743783\n",
      "Iteration 13707 => Loss: 49.68832317103289142324\n",
      "Iteration 13708 => Loss: 49.68813364852773162283\n",
      "Iteration 13709 => Loss: 49.68794412750991540406\n",
      "Iteration 13710 => Loss: 49.68775460797945697777\n",
      "Iteration 13711 => Loss: 49.68756508993634923854\n",
      "Iteration 13712 => Loss: 49.68737557338055665923\n",
      "Iteration 13713 => Loss: 49.68718605831205792356\n",
      "Iteration 13714 => Loss: 49.68699654473090987494\n",
      "Iteration 13715 => Loss: 49.68680703263702014283\n",
      "Iteration 13716 => Loss: 49.68661752203043846521\n",
      "Iteration 13717 => Loss: 49.68642801291109378781\n",
      "Iteration 13718 => Loss: 49.68623850527902874319\n",
      "Iteration 13719 => Loss: 49.68604899913420069879\n",
      "Iteration 13720 => Loss: 49.68585949447660965461\n",
      "Iteration 13721 => Loss: 49.68566999130625561065\n",
      "Iteration 13722 => Loss: 49.68548048962309593435\n",
      "Iteration 13723 => Loss: 49.68529098942712352027\n",
      "Iteration 13724 => Loss: 49.68510149071837389556\n",
      "Iteration 13725 => Loss: 49.68491199349677600594\n",
      "Iteration 13726 => Loss: 49.68472249776232985141\n",
      "Iteration 13727 => Loss: 49.68453300351504253740\n",
      "Iteration 13728 => Loss: 49.68434351075492116934\n",
      "Iteration 13729 => Loss: 49.68415401948190179837\n",
      "Iteration 13730 => Loss: 49.68396452969601995164\n",
      "Iteration 13731 => Loss: 49.68377504139725431287\n",
      "Iteration 13732 => Loss: 49.68358555458554803863\n",
      "Iteration 13733 => Loss: 49.68339606926095086692\n",
      "Iteration 13734 => Loss: 49.68320658542341305974\n",
      "Iteration 13735 => Loss: 49.68301710307292040625\n",
      "Iteration 13736 => Loss: 49.68282762220950132814\n",
      "Iteration 13737 => Loss: 49.68263814283311319286\n",
      "Iteration 13738 => Loss: 49.68244866494374889498\n",
      "Iteration 13739 => Loss: 49.68225918854138001279\n",
      "Iteration 13740 => Loss: 49.68206971362602786257\n",
      "Iteration 13741 => Loss: 49.68188024019766402262\n",
      "Iteration 13742 => Loss: 49.68169076825628849292\n",
      "Iteration 13743 => Loss: 49.68150129780183732464\n",
      "Iteration 13744 => Loss: 49.68131182883438867748\n",
      "Iteration 13745 => Loss: 49.68112236135385728630\n",
      "Iteration 13746 => Loss: 49.68093289536023604569\n",
      "Iteration 13747 => Loss: 49.68074343085356758820\n",
      "Iteration 13748 => Loss: 49.68055396783378796499\n",
      "Iteration 13749 => Loss: 49.68036450630093270320\n",
      "Iteration 13750 => Loss: 49.68017504625493785397\n",
      "Iteration 13751 => Loss: 49.67998558769582473360\n",
      "Iteration 13752 => Loss: 49.67979613062357202580\n",
      "Iteration 13753 => Loss: 49.67960667503815130885\n",
      "Iteration 13754 => Loss: 49.67941722093957679363\n",
      "Iteration 13755 => Loss: 49.67922776832784137468\n",
      "Iteration 13756 => Loss: 49.67903831720290952489\n",
      "Iteration 13757 => Loss: 49.67884886756478124425\n",
      "Iteration 13758 => Loss: 49.67865941941344232191\n",
      "Iteration 13759 => Loss: 49.67846997274889275786\n",
      "Iteration 13760 => Loss: 49.67828052757110413040\n",
      "Iteration 13761 => Loss: 49.67809108388005512325\n",
      "Iteration 13762 => Loss: 49.67790164167576705267\n",
      "Iteration 13763 => Loss: 49.67771220095822570784\n",
      "Iteration 13764 => Loss: 49.67752276172737424531\n",
      "Iteration 13765 => Loss: 49.67733332398325529766\n",
      "Iteration 13766 => Loss: 49.67714388772583333775\n",
      "Iteration 13767 => Loss: 49.67695445295505862759\n",
      "Iteration 13768 => Loss: 49.67676501967100222146\n",
      "Iteration 13769 => Loss: 49.67657558787360017050\n",
      "Iteration 13770 => Loss: 49.67638615756283115843\n",
      "Iteration 13771 => Loss: 49.67619672873871650154\n",
      "Iteration 13772 => Loss: 49.67600730140123488354\n",
      "Iteration 13773 => Loss: 49.67581787555036498816\n",
      "Iteration 13774 => Loss: 49.67562845118609260453\n",
      "Iteration 13775 => Loss: 49.67543902830839641638\n",
      "Iteration 13776 => Loss: 49.67524960691729773998\n",
      "Iteration 13777 => Loss: 49.67506018701276104821\n",
      "Iteration 13778 => Loss: 49.67487076859480055191\n",
      "Iteration 13779 => Loss: 49.67468135166338782938\n",
      "Iteration 13780 => Loss: 49.67449193621848024804\n",
      "Iteration 13781 => Loss: 49.67430252226011333505\n",
      "Iteration 13782 => Loss: 49.67411310978825866869\n",
      "Iteration 13783 => Loss: 49.67392369880289493267\n",
      "Iteration 13784 => Loss: 49.67373428930402212700\n",
      "Iteration 13785 => Loss: 49.67354488129162604082\n",
      "Iteration 13786 => Loss: 49.67335547476568535785\n",
      "Iteration 13787 => Loss: 49.67316606972621428895\n",
      "Iteration 13788 => Loss: 49.67297666617318441240\n",
      "Iteration 13789 => Loss: 49.67278726410657441193\n",
      "Iteration 13790 => Loss: 49.67259786352638428752\n",
      "Iteration 13791 => Loss: 49.67240846443259982834\n",
      "Iteration 13792 => Loss: 49.67221906682519971810\n",
      "Iteration 13793 => Loss: 49.67202967070418395679\n",
      "Iteration 13794 => Loss: 49.67184027606954543899\n",
      "Iteration 13795 => Loss: 49.67165088292127705927\n",
      "Iteration 13796 => Loss: 49.67146149125932907964\n",
      "Iteration 13797 => Loss: 49.67127210108372992181\n",
      "Iteration 13798 => Loss: 49.67108271239446537493\n",
      "Iteration 13799 => Loss: 49.67089332519149280643\n",
      "Iteration 13800 => Loss: 49.67070393947484063801\n",
      "Iteration 13801 => Loss: 49.67051455524449465884\n",
      "Iteration 13802 => Loss: 49.67032517250037670919\n",
      "Iteration 13803 => Loss: 49.67013579124254363251\n",
      "Iteration 13804 => Loss: 49.66994641147099542877\n",
      "Iteration 13805 => Loss: 49.66975703318565393829\n",
      "Iteration 13806 => Loss: 49.66956765638654758277\n",
      "Iteration 13807 => Loss: 49.66937828107367636221\n",
      "Iteration 13808 => Loss: 49.66918890724699764405\n",
      "Iteration 13809 => Loss: 49.66899953490651142829\n",
      "Iteration 13810 => Loss: 49.66881016405223192578\n",
      "Iteration 13811 => Loss: 49.66862079468412360939\n",
      "Iteration 13812 => Loss: 49.66843142680215095197\n",
      "Iteration 13813 => Loss: 49.66824206040632816439\n",
      "Iteration 13814 => Loss: 49.66805269549666235207\n",
      "Iteration 13815 => Loss: 49.66786333207311798787\n",
      "Iteration 13816 => Loss: 49.66767397013568086095\n",
      "Iteration 13817 => Loss: 49.66748460968434386587\n",
      "Iteration 13818 => Loss: 49.66729525071911410805\n",
      "Iteration 13819 => Loss: 49.66710589323994184952\n",
      "Iteration 13820 => Loss: 49.66691653724686972282\n",
      "Iteration 13821 => Loss: 49.66672718273981956827\n",
      "Iteration 13822 => Loss: 49.66653782971884112385\n",
      "Iteration 13823 => Loss: 49.66634847818387754614\n",
      "Iteration 13824 => Loss: 49.66615912813491462430\n",
      "Iteration 13825 => Loss: 49.66596977957200209630\n",
      "Iteration 13826 => Loss: 49.66578043249506890788\n",
      "Iteration 13827 => Loss: 49.66559108690411505904\n",
      "Iteration 13828 => Loss: 49.66540174279911923350\n",
      "Iteration 13829 => Loss: 49.66521240018012406381\n",
      "Iteration 13830 => Loss: 49.66502305904706560113\n",
      "Iteration 13831 => Loss: 49.66483371939995805633\n",
      "Iteration 13832 => Loss: 49.66464438123875879683\n",
      "Iteration 13833 => Loss: 49.66445504456349624434\n",
      "Iteration 13834 => Loss: 49.66426570937410645001\n",
      "Iteration 13835 => Loss: 49.66407637567062494099\n",
      "Iteration 13836 => Loss: 49.66388704345302329557\n",
      "Iteration 13837 => Loss: 49.66369771272130861917\n",
      "Iteration 13838 => Loss: 49.66350838347542406837\n",
      "Iteration 13839 => Loss: 49.66331905571539806488\n",
      "Iteration 13840 => Loss: 49.66312972944120218699\n",
      "Iteration 13841 => Loss: 49.66294040465285064556\n",
      "Iteration 13842 => Loss: 49.66275108135027949174\n",
      "Iteration 13843 => Loss: 49.66256175953352425267\n",
      "Iteration 13844 => Loss: 49.66237243920256361207\n",
      "Iteration 13845 => Loss: 49.66218312035735493737\n",
      "Iteration 13846 => Loss: 49.66199380299794086113\n",
      "Iteration 13847 => Loss: 49.66180448712425032909\n",
      "Iteration 13848 => Loss: 49.66161517273631176295\n",
      "Iteration 13849 => Loss: 49.66142585983411805728\n",
      "Iteration 13850 => Loss: 49.66123654841761947409\n",
      "Iteration 13851 => Loss: 49.66104723848684443510\n",
      "Iteration 13852 => Loss: 49.66085793004172899145\n",
      "Iteration 13853 => Loss: 49.66066862308232288115\n",
      "Iteration 13854 => Loss: 49.66047931760859057704\n",
      "Iteration 13855 => Loss: 49.66029001362052497370\n",
      "Iteration 13856 => Loss: 49.66010071111809764943\n",
      "Iteration 13857 => Loss: 49.65991141010130860423\n",
      "Iteration 13858 => Loss: 49.65972211057013652180\n",
      "Iteration 13859 => Loss: 49.65953281252458140216\n",
      "Iteration 13860 => Loss: 49.65934351596461482359\n",
      "Iteration 13861 => Loss: 49.65915422089027941865\n",
      "Iteration 13862 => Loss: 49.65896492730147571137\n",
      "Iteration 13863 => Loss: 49.65877563519823922888\n",
      "Iteration 13864 => Loss: 49.65858634458057707661\n",
      "Iteration 13865 => Loss: 49.65839705544846083285\n",
      "Iteration 13866 => Loss: 49.65820776780186207588\n",
      "Iteration 13867 => Loss: 49.65801848164078791115\n",
      "Iteration 13868 => Loss: 49.65782919696523123321\n",
      "Iteration 13869 => Loss: 49.65763991377515651493\n",
      "Iteration 13870 => Loss: 49.65745063207057086174\n",
      "Iteration 13871 => Loss: 49.65726135185146006279\n",
      "Iteration 13872 => Loss: 49.65707207311780280179\n",
      "Iteration 13873 => Loss: 49.65688279586961328960\n",
      "Iteration 13874 => Loss: 49.65669352010684178822\n",
      "Iteration 13875 => Loss: 49.65650424582949540309\n",
      "Iteration 13876 => Loss: 49.65631497303758834505\n",
      "Iteration 13877 => Loss: 49.65612570173107087612\n",
      "Iteration 13878 => Loss: 49.65593643190994299630\n",
      "Iteration 13879 => Loss: 49.65574716357419760016\n",
      "Iteration 13880 => Loss: 49.65555789672382047684\n",
      "Iteration 13881 => Loss: 49.65536863135878320463\n",
      "Iteration 13882 => Loss: 49.65517936747910709983\n",
      "Iteration 13883 => Loss: 49.65499010508476374071\n",
      "Iteration 13884 => Loss: 49.65480084417571760014\n",
      "Iteration 13885 => Loss: 49.65461158475202552154\n",
      "Iteration 13886 => Loss: 49.65442232681359513435\n",
      "Iteration 13887 => Loss: 49.65423307036046196572\n",
      "Iteration 13888 => Loss: 49.65404381539260469935\n",
      "Iteration 13889 => Loss: 49.65385456191001622983\n",
      "Iteration 13890 => Loss: 49.65366530991266813544\n",
      "Iteration 13891 => Loss: 49.65347605940056041618\n",
      "Iteration 13892 => Loss: 49.65328681037367886120\n",
      "Iteration 13893 => Loss: 49.65309756283202347049\n",
      "Iteration 13894 => Loss: 49.65290831677557292778\n",
      "Iteration 13895 => Loss: 49.65271907220430591678\n",
      "Iteration 13896 => Loss: 49.65252982911822954293\n",
      "Iteration 13897 => Loss: 49.65234058751732959536\n",
      "Iteration 13898 => Loss: 49.65215134740157765236\n",
      "Iteration 13899 => Loss: 49.65196210877096660852\n",
      "Iteration 13900 => Loss: 49.65177287162550356925\n",
      "Iteration 13901 => Loss: 49.65158363596514590199\n",
      "Iteration 13902 => Loss: 49.65139440178991492303\n",
      "Iteration 13903 => Loss: 49.65120516909977510522\n",
      "Iteration 13904 => Loss: 49.65101593789473355400\n",
      "Iteration 13905 => Loss: 49.65082670817475474223\n",
      "Iteration 13906 => Loss: 49.65063747993985288076\n",
      "Iteration 13907 => Loss: 49.65044825318997823160\n",
      "Iteration 13908 => Loss: 49.65025902792518763817\n",
      "Iteration 13909 => Loss: 49.65006980414540294078\n",
      "Iteration 13910 => Loss: 49.64988058185063835026\n",
      "Iteration 13911 => Loss: 49.64969136104087965577\n",
      "Iteration 13912 => Loss: 49.64950214171612685732\n",
      "Iteration 13913 => Loss: 49.64931292387633732233\n",
      "Iteration 13914 => Loss: 49.64912370752153236708\n",
      "Iteration 13915 => Loss: 49.64893449265168356987\n",
      "Iteration 13916 => Loss: 49.64874527926679093071\n",
      "Iteration 13917 => Loss: 49.64855606736681892244\n",
      "Iteration 13918 => Loss: 49.64836685695179596678\n",
      "Iteration 13919 => Loss: 49.64817764802164390403\n",
      "Iteration 13920 => Loss: 49.64798844057643378846\n",
      "Iteration 13921 => Loss: 49.64779923461611588209\n",
      "Iteration 13922 => Loss: 49.64761003014066176320\n",
      "Iteration 13923 => Loss: 49.64742082715007143179\n",
      "Iteration 13924 => Loss: 49.64723162564433778243\n",
      "Iteration 13925 => Loss: 49.64704242562345370970\n",
      "Iteration 13926 => Loss: 49.64685322708740500275\n",
      "Iteration 13927 => Loss: 49.64666403003617034528\n",
      "Iteration 13928 => Loss: 49.64647483446972131560\n",
      "Iteration 13929 => Loss: 49.64628564038810054626\n",
      "Iteration 13930 => Loss: 49.64609644779125829928\n",
      "Iteration 13931 => Loss: 49.64590725667918746922\n",
      "Iteration 13932 => Loss: 49.64571806705187384523\n",
      "Iteration 13933 => Loss: 49.64552887890933163817\n",
      "Iteration 13934 => Loss: 49.64533969225148268833\n",
      "Iteration 13935 => Loss: 49.64515050707839094457\n",
      "Iteration 13936 => Loss: 49.64496132339002087974\n",
      "Iteration 13937 => Loss: 49.64477214118633696671\n",
      "Iteration 13938 => Loss: 49.64458296046736052176\n",
      "Iteration 13939 => Loss: 49.64439378123306312318\n",
      "Iteration 13940 => Loss: 49.64420460348340924384\n",
      "Iteration 13941 => Loss: 49.64401542721845572714\n",
      "Iteration 13942 => Loss: 49.64382625243811020255\n",
      "Iteration 13943 => Loss: 49.64363707914240819719\n",
      "Iteration 13944 => Loss: 49.64344790733133550020\n",
      "Iteration 13945 => Loss: 49.64325873700487790074\n",
      "Iteration 13946 => Loss: 49.64306956816300697710\n",
      "Iteration 13947 => Loss: 49.64288040080572272927\n",
      "Iteration 13948 => Loss: 49.64269123493301094641\n",
      "Iteration 13949 => Loss: 49.64250207054487873393\n",
      "Iteration 13950 => Loss: 49.64231290764129767012\n",
      "Iteration 13951 => Loss: 49.64212374622222512244\n",
      "Iteration 13952 => Loss: 49.64193458628771793428\n",
      "Iteration 13953 => Loss: 49.64174542783772636767\n",
      "Iteration 13954 => Loss: 49.64155627087222910632\n",
      "Iteration 13955 => Loss: 49.64136711539120483394\n",
      "Iteration 13956 => Loss: 49.64117796139471039396\n",
      "Iteration 13957 => Loss: 49.64098880888264631039\n",
      "Iteration 13958 => Loss: 49.64079965785505521580\n",
      "Iteration 13959 => Loss: 49.64061050831192289934\n",
      "Iteration 13960 => Loss: 49.64042136025319962300\n",
      "Iteration 13961 => Loss: 49.64023221367891380851\n",
      "Iteration 13962 => Loss: 49.64004306858904413957\n",
      "Iteration 13963 => Loss: 49.63985392498357640534\n",
      "Iteration 13964 => Loss: 49.63966478286248928953\n",
      "Iteration 13965 => Loss: 49.63947564222578989757\n",
      "Iteration 13966 => Loss: 49.63928650307344270232\n",
      "Iteration 13967 => Loss: 49.63909736540546191463\n",
      "Iteration 13968 => Loss: 49.63890822922182621824\n",
      "Iteration 13969 => Loss: 49.63871909452250008599\n",
      "Iteration 13970 => Loss: 49.63852996130752615045\n",
      "Iteration 13971 => Loss: 49.63834082957683335735\n",
      "Iteration 13972 => Loss: 49.63815169933045723383\n",
      "Iteration 13973 => Loss: 49.63796257056833383103\n",
      "Iteration 13974 => Loss: 49.63777344329051288696\n",
      "Iteration 13975 => Loss: 49.63758431749695176904\n",
      "Iteration 13976 => Loss: 49.63739519318761495015\n",
      "Iteration 13977 => Loss: 49.63720607036253085198\n",
      "Iteration 13978 => Loss: 49.63701694902167815826\n",
      "Iteration 13979 => Loss: 49.63682782916502844728\n",
      "Iteration 13980 => Loss: 49.63663871079258171903\n",
      "Iteration 13981 => Loss: 49.63644959390434507895\n",
      "Iteration 13982 => Loss: 49.63626047850026878905\n",
      "Iteration 13983 => Loss: 49.63607136458035284932\n",
      "Iteration 13984 => Loss: 49.63588225214461857604\n",
      "Iteration 13985 => Loss: 49.63569314119301623123\n",
      "Iteration 13986 => Loss: 49.63550403172554581488\n",
      "Iteration 13987 => Loss: 49.63531492374218601071\n",
      "Iteration 13988 => Loss: 49.63512581724294392416\n",
      "Iteration 13989 => Loss: 49.63493671222780534436\n",
      "Iteration 13990 => Loss: 49.63474760869676316588\n",
      "Iteration 13991 => Loss: 49.63455850664977475617\n",
      "Iteration 13992 => Loss: 49.63436940608684722065\n",
      "Iteration 13993 => Loss: 49.63418030700799477017\n",
      "Iteration 13994 => Loss: 49.63399120941316766675\n",
      "Iteration 13995 => Loss: 49.63380211330237301581\n",
      "Iteration 13996 => Loss: 49.63361301867559660650\n",
      "Iteration 13997 => Loss: 49.63342392553279580625\n",
      "Iteration 13998 => Loss: 49.63323483387402745848\n",
      "Iteration 13999 => Loss: 49.63304574369919919263\n",
      "Iteration 14000 => Loss: 49.63285665500838206299\n",
      "Iteration 14001 => Loss: 49.63266756780150501527\n",
      "Iteration 14002 => Loss: 49.63247848207858936576\n",
      "Iteration 14003 => Loss: 49.63228939783958537646\n",
      "Iteration 14004 => Loss: 49.63210031508450725823\n",
      "Iteration 14005 => Loss: 49.63191123381334080022\n",
      "Iteration 14006 => Loss: 49.63172215402609310786\n",
      "Iteration 14007 => Loss: 49.63153307572274286485\n",
      "Iteration 14008 => Loss: 49.63134399890322612237\n",
      "Iteration 14009 => Loss: 49.63115492356758551296\n",
      "Iteration 14010 => Loss: 49.63096584971580682577\n",
      "Iteration 14011 => Loss: 49.63077677734786874453\n",
      "Iteration 14012 => Loss: 49.63058770646376416380\n",
      "Iteration 14013 => Loss: 49.63039863706347887273\n",
      "Iteration 14014 => Loss: 49.63020956914700576590\n",
      "Iteration 14015 => Loss: 49.63002050271430931616\n",
      "Iteration 14016 => Loss: 49.62983143776541794523\n",
      "Iteration 14017 => Loss: 49.62964237430028902054\n",
      "Iteration 14018 => Loss: 49.62945331231891543666\n",
      "Iteration 14019 => Loss: 49.62926425182129719360\n",
      "Iteration 14020 => Loss: 49.62907519280740586964\n",
      "Iteration 14021 => Loss: 49.62888613527725567565\n",
      "Iteration 14022 => Loss: 49.62869707923080397904\n",
      "Iteration 14023 => Loss: 49.62850802466805788526\n",
      "Iteration 14024 => Loss: 49.62831897158899607803\n",
      "Iteration 14025 => Loss: 49.62812991999363276818\n",
      "Iteration 14026 => Loss: 49.62794086988193242860\n",
      "Iteration 14027 => Loss: 49.62775182125385953213\n",
      "Iteration 14028 => Loss: 49.62756277410946381679\n",
      "Iteration 14029 => Loss: 49.62737372844867422828\n",
      "Iteration 14030 => Loss: 49.62718468427151918831\n",
      "Iteration 14031 => Loss: 49.62699564157798448605\n",
      "Iteration 14032 => Loss: 49.62680660036802748891\n",
      "Iteration 14033 => Loss: 49.62661756064165530233\n",
      "Iteration 14034 => Loss: 49.62642852239886792631\n",
      "Iteration 14035 => Loss: 49.62623948563962983371\n",
      "Iteration 14036 => Loss: 49.62605045036396234082\n",
      "Iteration 14037 => Loss: 49.62586141657182281506\n",
      "Iteration 14038 => Loss: 49.62567238426318994016\n",
      "Iteration 14039 => Loss: 49.62548335343810634868\n",
      "Iteration 14040 => Loss: 49.62529432409650809177\n",
      "Iteration 14041 => Loss: 49.62510529623840938029\n",
      "Iteration 14042 => Loss: 49.62491626986377468711\n",
      "Iteration 14043 => Loss: 49.62472724497264664478\n",
      "Iteration 14044 => Loss: 49.62453822156493998818\n",
      "Iteration 14045 => Loss: 49.62434919964070445531\n",
      "Iteration 14046 => Loss: 49.62416017919989030815\n",
      "Iteration 14047 => Loss: 49.62397116024247623045\n",
      "Iteration 14048 => Loss: 49.62378214276851906561\n",
      "Iteration 14049 => Loss: 49.62359312677793354851\n",
      "Iteration 14050 => Loss: 49.62340411227072678457\n",
      "Iteration 14051 => Loss: 49.62321509924690587923\n",
      "Iteration 14052 => Loss: 49.62302608770645662162\n",
      "Iteration 14053 => Loss: 49.62283707764935059004\n",
      "Iteration 14054 => Loss: 49.62264806907558778448\n",
      "Iteration 14055 => Loss: 49.62245906198515399410\n",
      "Iteration 14056 => Loss: 49.62227005637804921889\n",
      "Iteration 14057 => Loss: 49.62208105225424503715\n",
      "Iteration 14058 => Loss: 49.62189204961372013258\n",
      "Iteration 14059 => Loss: 49.62170304845650292691\n",
      "Iteration 14060 => Loss: 49.62151404878255078756\n",
      "Iteration 14061 => Loss: 49.62132505059184239826\n",
      "Iteration 14062 => Loss: 49.62113605388439196986\n",
      "Iteration 14063 => Loss: 49.62094705866017108065\n",
      "Iteration 14064 => Loss: 49.62075806491917262520\n",
      "Iteration 14065 => Loss: 49.62056907266141081436\n",
      "Iteration 14066 => Loss: 49.62038008188682169930\n",
      "Iteration 14067 => Loss: 49.62019109259545501800\n",
      "Iteration 14068 => Loss: 49.62000210478722550533\n",
      "Iteration 14069 => Loss: 49.61981311846217579387\n",
      "Iteration 14070 => Loss: 49.61962413362030588360\n",
      "Iteration 14071 => Loss: 49.61943515026155182568\n",
      "Iteration 14072 => Loss: 49.61924616838593493640\n",
      "Iteration 14073 => Loss: 49.61905718799344100489\n",
      "Iteration 14074 => Loss: 49.61886820908404160946\n",
      "Iteration 14075 => Loss: 49.61867923165777227723\n",
      "Iteration 14076 => Loss: 49.61849025571456195394\n",
      "Iteration 14077 => Loss: 49.61830128125444616671\n",
      "Iteration 14078 => Loss: 49.61811230827736096671\n",
      "Iteration 14079 => Loss: 49.61792333678334898650\n",
      "Iteration 14080 => Loss: 49.61773436677238180437\n",
      "Iteration 14081 => Loss: 49.61754539824441678775\n",
      "Iteration 14082 => Loss: 49.61735643119946814750\n",
      "Iteration 14083 => Loss: 49.61716746563754298904\n",
      "Iteration 14084 => Loss: 49.61697850155858446897\n",
      "Iteration 14085 => Loss: 49.61678953896262100898\n",
      "Iteration 14086 => Loss: 49.61660057784961708194\n",
      "Iteration 14087 => Loss: 49.61641161821957979328\n",
      "Iteration 14088 => Loss: 49.61622266007249493214\n",
      "Iteration 14089 => Loss: 49.61603370340833407681\n",
      "Iteration 14090 => Loss: 49.61584474822709012187\n",
      "Iteration 14091 => Loss: 49.61565579452876306732\n",
      "Iteration 14092 => Loss: 49.61546684231333870230\n",
      "Iteration 14093 => Loss: 49.61527789158079571052\n",
      "Iteration 14094 => Loss: 49.61508894233111988115\n",
      "Iteration 14095 => Loss: 49.61489999456434674130\n",
      "Iteration 14096 => Loss: 49.61471104828038392043\n",
      "Iteration 14097 => Loss: 49.61452210347925984024\n",
      "Iteration 14098 => Loss: 49.61433316016098160617\n",
      "Iteration 14099 => Loss: 49.61414421832552079650\n",
      "Iteration 14100 => Loss: 49.61395527797287030580\n",
      "Iteration 14101 => Loss: 49.61376633910298750152\n",
      "Iteration 14102 => Loss: 49.61357740171591501621\n",
      "Iteration 14103 => Loss: 49.61338846581161021732\n",
      "Iteration 14104 => Loss: 49.61319953139005178855\n",
      "Iteration 14105 => Loss: 49.61301059845123972991\n",
      "Iteration 14106 => Loss: 49.61282166699518114683\n",
      "Iteration 14107 => Loss: 49.61263273702184051217\n",
      "Iteration 14108 => Loss: 49.61244380853118940422\n",
      "Iteration 14109 => Loss: 49.61225488152327756097\n",
      "Iteration 14110 => Loss: 49.61206595599804103358\n",
      "Iteration 14111 => Loss: 49.61187703195545850576\n",
      "Iteration 14112 => Loss: 49.61168810939556550466\n",
      "Iteration 14113 => Loss: 49.61149918831833360855\n",
      "Iteration 14114 => Loss: 49.61131026872372729031\n",
      "Iteration 14115 => Loss: 49.61112135061173944450\n",
      "Iteration 14116 => Loss: 49.61093243398238428199\n",
      "Iteration 14117 => Loss: 49.61074351883564759191\n",
      "Iteration 14118 => Loss: 49.61055460517149384714\n",
      "Iteration 14119 => Loss: 49.61036569298993015309\n",
      "Iteration 14120 => Loss: 49.61017678229094229891\n",
      "Iteration 14121 => Loss: 49.60998787307450896833\n",
      "Iteration 14122 => Loss: 49.60979896534065147762\n",
      "Iteration 14123 => Loss: 49.60961005908930587793\n",
      "Iteration 14124 => Loss: 49.60942115432046506385\n",
      "Iteration 14125 => Loss: 49.60923225103417166792\n",
      "Iteration 14126 => Loss: 49.60904334923038305760\n",
      "Iteration 14127 => Loss: 49.60885444890907791660\n",
      "Iteration 14128 => Loss: 49.60866555007024913948\n",
      "Iteration 14129 => Loss: 49.60847665271387540997\n",
      "Iteration 14130 => Loss: 49.60828775683998514978\n",
      "Iteration 14131 => Loss: 49.60809886244851441006\n",
      "Iteration 14132 => Loss: 49.60790996953949161252\n",
      "Iteration 14133 => Loss: 49.60772107811290254631\n",
      "Iteration 14134 => Loss: 49.60753218816868326257\n",
      "Iteration 14135 => Loss: 49.60734329970691192102\n",
      "Iteration 14136 => Loss: 49.60715441272750325652\n",
      "Iteration 14137 => Loss: 49.60696552723047858535\n",
      "Iteration 14138 => Loss: 49.60677664321581659124\n",
      "Iteration 14139 => Loss: 49.60658776068348174704\n",
      "Iteration 14140 => Loss: 49.60639887963350247446\n",
      "Iteration 14141 => Loss: 49.60621000006585035180\n",
      "Iteration 14142 => Loss: 49.60602112198052537906\n",
      "Iteration 14143 => Loss: 49.60583224537749913452\n",
      "Iteration 14144 => Loss: 49.60564337025676451276\n",
      "Iteration 14145 => Loss: 49.60545449661831440835\n",
      "Iteration 14146 => Loss: 49.60526562446214882129\n",
      "Iteration 14147 => Loss: 49.60507675378819669731\n",
      "Iteration 14148 => Loss: 49.60488788459655040697\n",
      "Iteration 14149 => Loss: 49.60469901688710336884\n",
      "Iteration 14150 => Loss: 49.60451015065990532094\n",
      "Iteration 14151 => Loss: 49.60432128591487810354\n",
      "Iteration 14152 => Loss: 49.60413242265207856008\n",
      "Iteration 14153 => Loss: 49.60394356087147116341\n",
      "Iteration 14154 => Loss: 49.60375470057302038640\n",
      "Iteration 14155 => Loss: 49.60356584175674754533\n",
      "Iteration 14156 => Loss: 49.60337698442264553478\n",
      "Iteration 14157 => Loss: 49.60318812857065751132\n",
      "Iteration 14158 => Loss: 49.60299927420081900209\n",
      "Iteration 14159 => Loss: 49.60281042131309447996\n",
      "Iteration 14160 => Loss: 49.60262156990746973406\n",
      "Iteration 14161 => Loss: 49.60243271998395186984\n",
      "Iteration 14162 => Loss: 49.60224387154252667642\n",
      "Iteration 14163 => Loss: 49.60205502458316573211\n",
      "Iteration 14164 => Loss: 49.60186617910583350977\n",
      "Iteration 14165 => Loss: 49.60167733511061527452\n",
      "Iteration 14166 => Loss: 49.60148849259739023410\n",
      "Iteration 14167 => Loss: 49.60129965156620102107\n",
      "Iteration 14168 => Loss: 49.60111081201701210830\n",
      "Iteration 14169 => Loss: 49.60092197394985902292\n",
      "Iteration 14170 => Loss: 49.60073313736466360524\n",
      "Iteration 14171 => Loss: 49.60054430226144717153\n",
      "Iteration 14172 => Loss: 49.60035546864023814351\n",
      "Iteration 14173 => Loss: 49.60016663650095836147\n",
      "Iteration 14174 => Loss: 49.59997780584362914169\n",
      "Iteration 14175 => Loss: 49.59978897666822916790\n",
      "Iteration 14176 => Loss: 49.59960014897475133466\n",
      "Iteration 14177 => Loss: 49.59941132276318853656\n",
      "Iteration 14178 => Loss: 49.59922249803349814101\n",
      "Iteration 14179 => Loss: 49.59903367478572278060\n",
      "Iteration 14180 => Loss: 49.59884485301980561189\n",
      "Iteration 14181 => Loss: 49.59865603273576084575\n",
      "Iteration 14182 => Loss: 49.59846721393357427132\n",
      "Iteration 14183 => Loss: 49.59827839661322457232\n",
      "Iteration 14184 => Loss: 49.59808958077469043246\n",
      "Iteration 14185 => Loss: 49.59790076641798606261\n",
      "Iteration 14186 => Loss: 49.59771195354307593561\n",
      "Iteration 14187 => Loss: 49.59752314214996715691\n",
      "Iteration 14188 => Loss: 49.59733433223864551564\n",
      "Iteration 14189 => Loss: 49.59714552380906127382\n",
      "Iteration 14190 => Loss: 49.59695671686127838029\n",
      "Iteration 14191 => Loss: 49.59676791139522578078\n",
      "Iteration 14192 => Loss: 49.59657910741088926443\n",
      "Iteration 14193 => Loss: 49.59639030490832567466\n",
      "Iteration 14194 => Loss: 49.59620150388744264092\n",
      "Iteration 14195 => Loss: 49.59601270434825437405\n",
      "Iteration 14196 => Loss: 49.59582390629075376864\n",
      "Iteration 14197 => Loss: 49.59563510971494793012\n",
      "Iteration 14198 => Loss: 49.59544631462078001505\n",
      "Iteration 14199 => Loss: 49.59525752100828555058\n",
      "Iteration 14200 => Loss: 49.59506872887744322043\n",
      "Iteration 14201 => Loss: 49.59487993822822460288\n",
      "Iteration 14202 => Loss: 49.59469114906061548709\n",
      "Iteration 14203 => Loss: 49.59450236137462297847\n",
      "Iteration 14204 => Loss: 49.59431357517024707704\n",
      "Iteration 14205 => Loss: 49.59412479044741672851\n",
      "Iteration 14206 => Loss: 49.59393600720617456545\n",
      "Iteration 14207 => Loss: 49.59374722544647084987\n",
      "Iteration 14208 => Loss: 49.59355844516834821434\n",
      "Iteration 14209 => Loss: 49.59336966637174981543\n",
      "Iteration 14210 => Loss: 49.59318088905667565314\n",
      "Iteration 14211 => Loss: 49.59299211322313283290\n",
      "Iteration 14212 => Loss: 49.59280333887107872215\n",
      "Iteration 14213 => Loss: 49.59261456600051332089\n",
      "Iteration 14214 => Loss: 49.59242579461142952368\n",
      "Iteration 14215 => Loss: 49.59223702470381311969\n",
      "Iteration 14216 => Loss: 49.59204825627766410889\n",
      "Iteration 14217 => Loss: 49.59185948933294696417\n",
      "Iteration 14218 => Loss: 49.59167072386966879094\n",
      "Iteration 14219 => Loss: 49.59148195988780827292\n",
      "Iteration 14220 => Loss: 49.59129319738737251555\n",
      "Iteration 14221 => Loss: 49.59110443636831178083\n",
      "Iteration 14222 => Loss: 49.59091567683065449046\n",
      "Iteration 14223 => Loss: 49.59072691877435801189\n",
      "Iteration 14224 => Loss: 49.59053816219942234511\n",
      "Iteration 14225 => Loss: 49.59034940710584749013\n",
      "Iteration 14226 => Loss: 49.59016065349361923609\n",
      "Iteration 14227 => Loss: 49.58997190136273047756\n",
      "Iteration 14228 => Loss: 49.58978315071312437112\n",
      "Iteration 14229 => Loss: 49.58959440154483644392\n",
      "Iteration 14230 => Loss: 49.58940565385785248509\n",
      "Iteration 14231 => Loss: 49.58921690765216538921\n",
      "Iteration 14232 => Loss: 49.58902816292771120743\n",
      "Iteration 14233 => Loss: 49.58883941968453257232\n",
      "Iteration 14234 => Loss: 49.58865067792260816759\n",
      "Iteration 14235 => Loss: 49.58846193764190957154\n",
      "Iteration 14236 => Loss: 49.58827319884242257331\n",
      "Iteration 14237 => Loss: 49.58808446152416138375\n",
      "Iteration 14238 => Loss: 49.58789572568709047573\n",
      "Iteration 14239 => Loss: 49.58770699133124537639\n",
      "Iteration 14240 => Loss: 49.58751825845653371516\n",
      "Iteration 14241 => Loss: 49.58732952706300523005\n",
      "Iteration 14242 => Loss: 49.58714079715063149933\n",
      "Iteration 14243 => Loss: 49.58695206871940541760\n",
      "Iteration 14244 => Loss: 49.58676334176931277398\n",
      "Iteration 14245 => Loss: 49.58657461630032514677\n",
      "Iteration 14246 => Loss: 49.58638589231244964139\n",
      "Iteration 14247 => Loss: 49.58619716980568625786\n",
      "Iteration 14248 => Loss: 49.58600844877997104732\n",
      "Iteration 14249 => Loss: 49.58581972923536795861\n",
      "Iteration 14250 => Loss: 49.58563101117179172661\n",
      "Iteration 14251 => Loss: 49.58544229458929208931\n",
      "Iteration 14252 => Loss: 49.58525357948781930872\n",
      "Iteration 14253 => Loss: 49.58506486586736627942\n",
      "Iteration 14254 => Loss: 49.58487615372793300139\n",
      "Iteration 14255 => Loss: 49.58468744306949815837\n",
      "Iteration 14256 => Loss: 49.58449873389206175034\n",
      "Iteration 14257 => Loss: 49.58431002619560246103\n",
      "Iteration 14258 => Loss: 49.58412131998011318501\n",
      "Iteration 14259 => Loss: 49.58393261524557260600\n",
      "Iteration 14260 => Loss: 49.58374391199200204028\n",
      "Iteration 14261 => Loss: 49.58355521021934464443\n",
      "Iteration 14262 => Loss: 49.58336650992760041845\n",
      "Iteration 14263 => Loss: 49.58317781111676225692\n",
      "Iteration 14264 => Loss: 49.58298911378684437068\n",
      "Iteration 14265 => Loss: 49.58280041793780412718\n",
      "Iteration 14266 => Loss: 49.58261172356964863184\n",
      "Iteration 14267 => Loss: 49.58242303068232814667\n",
      "Iteration 14268 => Loss: 49.58223433927588530423\n",
      "Iteration 14269 => Loss: 49.58204564935027747197\n",
      "Iteration 14270 => Loss: 49.58185696090551175530\n",
      "Iteration 14271 => Loss: 49.58166827394154552167\n",
      "Iteration 14272 => Loss: 49.58147958845838587649\n",
      "Iteration 14273 => Loss: 49.58129090445601860893\n",
      "Iteration 14274 => Loss: 49.58110222193442950811\n",
      "Iteration 14275 => Loss: 49.58091354089363278490\n",
      "Iteration 14276 => Loss: 49.58072486133357870131\n",
      "Iteration 14277 => Loss: 49.58053618325426015190\n",
      "Iteration 14278 => Loss: 49.58034750665569134753\n",
      "Iteration 14279 => Loss: 49.58015883153785807735\n",
      "Iteration 14280 => Loss: 49.57997015790071060337\n",
      "Iteration 14281 => Loss: 49.57978148574425603101\n",
      "Iteration 14282 => Loss: 49.57959281506853699284\n",
      "Iteration 14283 => Loss: 49.57940414587347532915\n",
      "Iteration 14284 => Loss: 49.57921547815908525081\n",
      "Iteration 14285 => Loss: 49.57902681192532412524\n",
      "Iteration 14286 => Loss: 49.57883814717221326873\n",
      "Iteration 14287 => Loss: 49.57864948389976689214\n",
      "Iteration 14288 => Loss: 49.57846082210787841404\n",
      "Iteration 14289 => Loss: 49.57827216179664731044\n",
      "Iteration 14290 => Loss: 49.57808350296600963247\n",
      "Iteration 14291 => Loss: 49.57789484561593695844\n",
      "Iteration 14292 => Loss: 49.57770618974644349919\n",
      "Iteration 14293 => Loss: 49.57751753535752214930\n",
      "Iteration 14294 => Loss: 49.57732888244912317077\n",
      "Iteration 14295 => Loss: 49.57714023102131051246\n",
      "Iteration 14296 => Loss: 49.57695158107397759295\n",
      "Iteration 14297 => Loss: 49.57676293260718125566\n",
      "Iteration 14298 => Loss: 49.57657428562088597346\n",
      "Iteration 14299 => Loss: 49.57638564011506332463\n",
      "Iteration 14300 => Loss: 49.57619699608974173088\n",
      "Iteration 14301 => Loss: 49.57600835354489277051\n",
      "Iteration 14302 => Loss: 49.57581971248048091638\n",
      "Iteration 14303 => Loss: 49.57563107289650616849\n",
      "Iteration 14304 => Loss: 49.57544243479301115940\n",
      "Iteration 14305 => Loss: 49.57525379816989641313\n",
      "Iteration 14306 => Loss: 49.57506516302721877310\n",
      "Iteration 14307 => Loss: 49.57487652936492850131\n",
      "Iteration 14308 => Loss: 49.57468789718302559777\n",
      "Iteration 14309 => Loss: 49.57449926648148164077\n",
      "Iteration 14310 => Loss: 49.57431063726032505201\n",
      "Iteration 14311 => Loss: 49.57412200951951319894\n",
      "Iteration 14312 => Loss: 49.57393338325902476527\n",
      "Iteration 14313 => Loss: 49.57374475847889527813\n",
      "Iteration 14314 => Loss: 49.57355613517907499954\n",
      "Iteration 14315 => Loss: 49.57336751335954971864\n",
      "Iteration 14316 => Loss: 49.57317889302030522458\n",
      "Iteration 14317 => Loss: 49.57299027416137704449\n",
      "Iteration 14318 => Loss: 49.57280165678270122953\n",
      "Iteration 14319 => Loss: 49.57261304088428488512\n",
      "Iteration 14320 => Loss: 49.57242442646612801127\n",
      "Iteration 14321 => Loss: 49.57223581352818086998\n",
      "Iteration 14322 => Loss: 49.57204720207047898839\n",
      "Iteration 14323 => Loss: 49.57185859209297973393\n",
      "Iteration 14324 => Loss: 49.57166998359569021204\n",
      "Iteration 14325 => Loss: 49.57148137657861042271\n",
      "Iteration 14326 => Loss: 49.57129277104167641710\n",
      "Iteration 14327 => Loss: 49.57110416698490951148\n",
      "Iteration 14328 => Loss: 49.57091556440831681130\n",
      "Iteration 14329 => Loss: 49.57072696331186278940\n",
      "Iteration 14330 => Loss: 49.57053836369552612950\n",
      "Iteration 14331 => Loss: 49.57034976555932814790\n",
      "Iteration 14332 => Loss: 49.57016116890321200117\n",
      "Iteration 14333 => Loss: 49.56997257372722032187\n",
      "Iteration 14334 => Loss: 49.56978398003128205573\n",
      "Iteration 14335 => Loss: 49.56959538781543983532\n",
      "Iteration 14336 => Loss: 49.56940679707966523893\n",
      "Iteration 14337 => Loss: 49.56921820782392273941\n",
      "Iteration 14338 => Loss: 49.56902962004824075848\n",
      "Iteration 14339 => Loss: 49.56884103375257666357\n",
      "Iteration 14340 => Loss: 49.56865244893690203298\n",
      "Iteration 14341 => Loss: 49.56846386560125949927\n",
      "Iteration 14342 => Loss: 49.56827528374560642987\n",
      "Iteration 14343 => Loss: 49.56808670336992150851\n",
      "Iteration 14344 => Loss: 49.56789812447421184061\n",
      "Iteration 14345 => Loss: 49.56770954705846321531\n",
      "Iteration 14346 => Loss: 49.56752097112266142176\n",
      "Iteration 14347 => Loss: 49.56733239666679224911\n",
      "Iteration 14348 => Loss: 49.56714382369085569735\n",
      "Iteration 14349 => Loss: 49.56695525219480202850\n",
      "Iteration 14350 => Loss: 49.56676668217865966426\n",
      "Iteration 14351 => Loss: 49.56657811364240728835\n",
      "Iteration 14352 => Loss: 49.56638954658604490078\n",
      "Iteration 14353 => Loss: 49.56620098100951565812\n",
      "Iteration 14354 => Loss: 49.56601241691287640379\n",
      "Iteration 14355 => Loss: 49.56582385429605608351\n",
      "Iteration 14356 => Loss: 49.56563529315906890815\n",
      "Iteration 14357 => Loss: 49.56544673350190066685\n",
      "Iteration 14358 => Loss: 49.56525817532454425418\n",
      "Iteration 14359 => Loss: 49.56506961862696414300\n",
      "Iteration 14360 => Loss: 49.56488106340916743875\n",
      "Iteration 14361 => Loss: 49.56469250967116835227\n",
      "Iteration 14362 => Loss: 49.56450395741291004015\n",
      "Iteration 14363 => Loss: 49.56431540663442092409\n",
      "Iteration 14364 => Loss: 49.56412685733563705526\n",
      "Iteration 14365 => Loss: 49.56393830951659396078\n",
      "Iteration 14366 => Loss: 49.56374976317726321895\n",
      "Iteration 14367 => Loss: 49.56356121831764482977\n",
      "Iteration 14368 => Loss: 49.56337267493767484439\n",
      "Iteration 14369 => Loss: 49.56318413303742431708\n",
      "Iteration 14370 => Loss: 49.56299559261682219358\n",
      "Iteration 14371 => Loss: 49.56280705367588979016\n",
      "Iteration 14372 => Loss: 49.56261851621460579054\n",
      "Iteration 14373 => Loss: 49.56242998023292756216\n",
      "Iteration 14374 => Loss: 49.56224144573089063215\n",
      "Iteration 14375 => Loss: 49.56205291270845236795\n",
      "Iteration 14376 => Loss: 49.56186438116561987499\n",
      "Iteration 14377 => Loss: 49.56167585110235762613\n",
      "Iteration 14378 => Loss: 49.56148732251869404308\n",
      "Iteration 14379 => Loss: 49.56129879541457938785\n",
      "Iteration 14380 => Loss: 49.56111026979001366044\n",
      "Iteration 14381 => Loss: 49.56092174564498975542\n",
      "Iteration 14382 => Loss: 49.56073322297949346193\n",
      "Iteration 14383 => Loss: 49.56054470179351767456\n",
      "Iteration 14384 => Loss: 49.56035618208703397158\n",
      "Iteration 14385 => Loss: 49.56016766386005656386\n",
      "Iteration 14386 => Loss: 49.55997914711254992426\n",
      "Iteration 14387 => Loss: 49.55979063184449984192\n",
      "Iteration 14388 => Loss: 49.55960211805594184398\n",
      "Iteration 14389 => Loss: 49.55941360574681198159\n",
      "Iteration 14390 => Loss: 49.55922509491713157104\n",
      "Iteration 14391 => Loss: 49.55903658556682955805\n",
      "Iteration 14392 => Loss: 49.55884807769597699689\n",
      "Iteration 14393 => Loss: 49.55865957130452414958\n",
      "Iteration 14394 => Loss: 49.55847106639244969983\n",
      "Iteration 14395 => Loss: 49.55828256295974654222\n",
      "Iteration 14396 => Loss: 49.55809406100641467674\n",
      "Iteration 14397 => Loss: 49.55790556053243278711\n",
      "Iteration 14398 => Loss: 49.55771706153780797877\n",
      "Iteration 14399 => Loss: 49.55752856402251893542\n",
      "Iteration 14400 => Loss: 49.55734006798650881365\n",
      "Iteration 14401 => Loss: 49.55715157342983445687\n",
      "Iteration 14402 => Loss: 49.55696308035243902168\n",
      "Iteration 14403 => Loss: 49.55677458875434382435\n",
      "Iteration 14404 => Loss: 49.55658609863553465402\n",
      "Iteration 14405 => Loss: 49.55639760999596887814\n",
      "Iteration 14406 => Loss: 49.55620912283564649670\n",
      "Iteration 14407 => Loss: 49.55602063715456040427\n",
      "Iteration 14408 => Loss: 49.55583215295271770628\n",
      "Iteration 14409 => Loss: 49.55564367023006155932\n",
      "Iteration 14410 => Loss: 49.55545518898662038509\n",
      "Iteration 14411 => Loss: 49.55526670922237997274\n",
      "Iteration 14412 => Loss: 49.55507823093729058428\n",
      "Iteration 14413 => Loss: 49.55488975413140195769\n",
      "Iteration 14414 => Loss: 49.55470127880465014414\n",
      "Iteration 14415 => Loss: 49.55451280495705645990\n",
      "Iteration 14416 => Loss: 49.55432433258859958869\n",
      "Iteration 14417 => Loss: 49.55413586169922979252\n",
      "Iteration 14418 => Loss: 49.55394739228898970396\n",
      "Iteration 14419 => Loss: 49.55375892435785800672\n",
      "Iteration 14420 => Loss: 49.55357045790582759537\n",
      "Iteration 14421 => Loss: 49.55338199293283452107\n",
      "Iteration 14422 => Loss: 49.55319352943892141639\n",
      "Iteration 14423 => Loss: 49.55300506742403854332\n",
      "Iteration 14424 => Loss: 49.55281660688824274530\n",
      "Iteration 14425 => Loss: 49.55262814783142033548\n",
      "Iteration 14426 => Loss: 49.55243969025364947356\n",
      "Iteration 14427 => Loss: 49.55225123415486621070\n",
      "Iteration 14428 => Loss: 49.55206277953509186318\n",
      "Iteration 14429 => Loss: 49.55187432639429090386\n",
      "Iteration 14430 => Loss: 49.55168587473247754360\n",
      "Iteration 14431 => Loss: 49.55149742454960914984\n",
      "Iteration 14432 => Loss: 49.55130897584567861713\n",
      "Iteration 14433 => Loss: 49.55112052862068594550\n",
      "Iteration 14434 => Loss: 49.55093208287464534578\n",
      "Iteration 14435 => Loss: 49.55074363860747865829\n",
      "Iteration 14436 => Loss: 49.55055519581922141015\n",
      "Iteration 14437 => Loss: 49.55036675450986649594\n",
      "Iteration 14438 => Loss: 49.55017831467937838852\n",
      "Iteration 14439 => Loss: 49.54998987632776419332\n",
      "Iteration 14440 => Loss: 49.54980143945500969949\n",
      "Iteration 14441 => Loss: 49.54961300406108648531\n",
      "Iteration 14442 => Loss: 49.54942457014600876164\n",
      "Iteration 14443 => Loss: 49.54923613770972679049\n",
      "Iteration 14444 => Loss: 49.54904770675226188814\n",
      "Iteration 14445 => Loss: 49.54885927727360694917\n",
      "Iteration 14446 => Loss: 49.54867084927373355185\n",
      "Iteration 14447 => Loss: 49.54848242275262037992\n",
      "Iteration 14448 => Loss: 49.54829399771026743338\n",
      "Iteration 14449 => Loss: 49.54810557414668181764\n",
      "Iteration 14450 => Loss: 49.54791715206180668929\n",
      "Iteration 14451 => Loss: 49.54772873145567757547\n",
      "Iteration 14452 => Loss: 49.54754031232825184361\n",
      "Iteration 14453 => Loss: 49.54735189467952949371\n",
      "Iteration 14454 => Loss: 49.54716347850953184206\n",
      "Iteration 14455 => Loss: 49.54697506381818783439\n",
      "Iteration 14456 => Loss: 49.54678665060549747068\n",
      "Iteration 14457 => Loss: 49.54659823887148917265\n",
      "Iteration 14458 => Loss: 49.54640982861612741317\n",
      "Iteration 14459 => Loss: 49.54622141983939087595\n",
      "Iteration 14460 => Loss: 49.54603301254127956099\n",
      "Iteration 14461 => Loss: 49.54584460672176504659\n",
      "Iteration 14462 => Loss: 49.54565620238085443816\n",
      "Iteration 14463 => Loss: 49.54546779951855484114\n",
      "Iteration 14464 => Loss: 49.54527939813479520126\n",
      "Iteration 14465 => Loss: 49.54509099822963236193\n",
      "Iteration 14466 => Loss: 49.54490259980299526887\n",
      "Iteration 14467 => Loss: 49.54471420285491234381\n",
      "Iteration 14468 => Loss: 49.54452580738535516502\n",
      "Iteration 14469 => Loss: 49.54433741339431662709\n",
      "Iteration 14470 => Loss: 49.54414902088180383544\n",
      "Iteration 14471 => Loss: 49.54396062984774573579\n",
      "Iteration 14472 => Loss: 49.54377224029220627699\n",
      "Iteration 14473 => Loss: 49.54358385221512151020\n",
      "Iteration 14474 => Loss: 49.54339546561649854084\n",
      "Iteration 14475 => Loss: 49.54320708049633736891\n",
      "Iteration 14476 => Loss: 49.54301869685457404557\n",
      "Iteration 14477 => Loss: 49.54283031469127251967\n",
      "Iteration 14478 => Loss: 49.54264193400638305320\n",
      "Iteration 14479 => Loss: 49.54245355479987011904\n",
      "Iteration 14480 => Loss: 49.54226517707176924432\n",
      "Iteration 14481 => Loss: 49.54207680082201648020\n",
      "Iteration 14482 => Loss: 49.54188842605066156466\n",
      "Iteration 14483 => Loss: 49.54170005275767607600\n",
      "Iteration 14484 => Loss: 49.54151168094298895994\n",
      "Iteration 14485 => Loss: 49.54132331060666416533\n",
      "Iteration 14486 => Loss: 49.54113494174864484876\n",
      "Iteration 14487 => Loss: 49.54094657436893811564\n",
      "Iteration 14488 => Loss: 49.54075820846753686055\n",
      "Iteration 14489 => Loss: 49.54056984404440555636\n",
      "Iteration 14490 => Loss: 49.54038148109957973020\n",
      "Iteration 14491 => Loss: 49.54019311963298832779\n",
      "Iteration 14492 => Loss: 49.54000475964465266543\n",
      "Iteration 14493 => Loss: 49.53981640113455853225\n",
      "Iteration 14494 => Loss: 49.53962804410269882283\n",
      "Iteration 14495 => Loss: 49.53943968854905222088\n",
      "Iteration 14496 => Loss: 49.53925133447362583183\n",
      "Iteration 14497 => Loss: 49.53906298187634860142\n",
      "Iteration 14498 => Loss: 49.53887463075727737305\n",
      "Iteration 14499 => Loss: 49.53868628111638372502\n",
      "Iteration 14500 => Loss: 49.53849793295365344648\n",
      "Iteration 14501 => Loss: 49.53830958626903679942\n",
      "Iteration 14502 => Loss: 49.53812124106257641643\n",
      "Iteration 14503 => Loss: 49.53793289733423677035\n",
      "Iteration 14504 => Loss: 49.53774455508402496662\n",
      "Iteration 14505 => Loss: 49.53755621431189126724\n",
      "Iteration 14506 => Loss: 49.53736787501786409393\n",
      "Iteration 14507 => Loss: 49.53717953720189370870\n",
      "Iteration 14508 => Loss: 49.53699120086398721696\n",
      "Iteration 14509 => Loss: 49.53680286600414461873\n",
      "Iteration 14510 => Loss: 49.53661453262235170314\n",
      "Iteration 14511 => Loss: 49.53642620071857294306\n",
      "Iteration 14512 => Loss: 49.53623787029283676020\n",
      "Iteration 14513 => Loss: 49.53604954134508631114\n",
      "Iteration 14514 => Loss: 49.53586121387535001759\n",
      "Iteration 14515 => Loss: 49.53567288788357103613\n",
      "Iteration 14516 => Loss: 49.53548456336977778847\n",
      "Iteration 14517 => Loss: 49.53529624033394895832\n",
      "Iteration 14518 => Loss: 49.53510791877607033484\n",
      "Iteration 14519 => Loss: 49.53491959869612770717\n",
      "Iteration 14520 => Loss: 49.53473128009408554817\n",
      "Iteration 14521 => Loss: 49.53454296296999359583\n",
      "Iteration 14522 => Loss: 49.53435464732380921760\n",
      "Iteration 14523 => Loss: 49.53416633315548267547\n",
      "Iteration 14524 => Loss: 49.53397802046504949658\n",
      "Iteration 14525 => Loss: 49.53378970925248125923\n",
      "Iteration 14526 => Loss: 49.53360139951779927969\n",
      "Iteration 14527 => Loss: 49.53341309126091829285\n",
      "Iteration 14528 => Loss: 49.53322478448191645839\n",
      "Iteration 14529 => Loss: 49.53303647918070140577\n",
      "Iteration 14530 => Loss: 49.53284817535730866211\n",
      "Iteration 14531 => Loss: 49.53265987301171691115\n",
      "Iteration 14532 => Loss: 49.53247157214389773117\n",
      "Iteration 14533 => Loss: 49.53228327275387243844\n",
      "Iteration 14534 => Loss: 49.53209497484160550584\n",
      "Iteration 14535 => Loss: 49.53190667840707561709\n",
      "Iteration 14536 => Loss: 49.53171838345030408846\n",
      "Iteration 14537 => Loss: 49.53153008997125539281\n",
      "Iteration 14538 => Loss: 49.53134179796991531930\n",
      "Iteration 14539 => Loss: 49.53115350744628386792\n",
      "Iteration 14540 => Loss: 49.53096521840034682782\n",
      "Iteration 14541 => Loss: 49.53077693083211840985\n",
      "Iteration 14542 => Loss: 49.53058864474152755975\n",
      "Iteration 14543 => Loss: 49.53040036012862401549\n",
      "Iteration 14544 => Loss: 49.53021207699333672281\n",
      "Iteration 14545 => Loss: 49.53002379533570831427\n",
      "Iteration 14546 => Loss: 49.52983551515569615731\n",
      "Iteration 14547 => Loss: 49.52964723645329314650\n",
      "Iteration 14548 => Loss: 49.52945895922847796555\n",
      "Iteration 14549 => Loss: 49.52927068348128614161\n",
      "Iteration 14550 => Loss: 49.52908240921166083126\n",
      "Iteration 14551 => Loss: 49.52889413641961624535\n",
      "Iteration 14552 => Loss: 49.52870586510508132960\n",
      "Iteration 14553 => Loss: 49.52851759526812003287\n",
      "Iteration 14554 => Loss: 49.52832932690868972259\n",
      "Iteration 14555 => Loss: 49.52814106002678329332\n",
      "Iteration 14556 => Loss: 49.52795279462237942880\n",
      "Iteration 14557 => Loss: 49.52776453069547812902\n",
      "Iteration 14558 => Loss: 49.52757626824605807769\n",
      "Iteration 14559 => Loss: 49.52738800727411216940\n",
      "Iteration 14560 => Loss: 49.52719974777961908785\n",
      "Iteration 14561 => Loss: 49.52701148976259304391\n",
      "Iteration 14562 => Loss: 49.52682323322299851043\n",
      "Iteration 14563 => Loss: 49.52663497816082838199\n",
      "Iteration 14564 => Loss: 49.52644672457605423688\n",
      "Iteration 14565 => Loss: 49.52625847246871870766\n",
      "Iteration 14566 => Loss: 49.52607022183876495092\n",
      "Iteration 14567 => Loss: 49.52588197268619296665\n",
      "Iteration 14568 => Loss: 49.52569372501098143857\n",
      "Iteration 14569 => Loss: 49.52550547881313747212\n",
      "Iteration 14570 => Loss: 49.52531723409263264557\n",
      "Iteration 14571 => Loss: 49.52512899084945985351\n",
      "Iteration 14572 => Loss: 49.52494074908361909593\n",
      "Iteration 14573 => Loss: 49.52475250879509616198\n",
      "Iteration 14574 => Loss: 49.52456426998386262994\n",
      "Iteration 14575 => Loss: 49.52437603264992560526\n",
      "Iteration 14576 => Loss: 49.52418779679325666621\n",
      "Iteration 14577 => Loss: 49.52399956241386291822\n",
      "Iteration 14578 => Loss: 49.52381132951171593959\n",
      "Iteration 14579 => Loss: 49.52362309808678730860\n",
      "Iteration 14580 => Loss: 49.52343486813913386868\n",
      "Iteration 14581 => Loss: 49.52324663966864903841\n",
      "Iteration 14582 => Loss: 49.52305841267539676664\n",
      "Iteration 14583 => Loss: 49.52287018715935573709\n",
      "Iteration 14584 => Loss: 49.52268196312048331720\n",
      "Iteration 14585 => Loss: 49.52249374055878661238\n",
      "Iteration 14586 => Loss: 49.52230551947425141179\n",
      "Iteration 14587 => Loss: 49.52211729986684929372\n",
      "Iteration 14588 => Loss: 49.52192908173660157445\n",
      "Iteration 14589 => Loss: 49.52174086508350114855\n",
      "Iteration 14590 => Loss: 49.52155264990747696174\n",
      "Iteration 14591 => Loss: 49.52136443620857164660\n",
      "Iteration 14592 => Loss: 49.52117622398673546513\n",
      "Iteration 14593 => Loss: 49.52098801324201104990\n",
      "Iteration 14594 => Loss: 49.52079980397434866290\n",
      "Iteration 14595 => Loss: 49.52061159618371277702\n",
      "Iteration 14596 => Loss: 49.52042338987015313023\n",
      "Iteration 14597 => Loss: 49.52023518503362708998\n",
      "Iteration 14598 => Loss: 49.52004698167410623455\n",
      "Iteration 14599 => Loss: 49.51985877979161188023\n",
      "Iteration 14600 => Loss: 49.51967057938610849988\n",
      "Iteration 14601 => Loss: 49.51948238045757477721\n",
      "Iteration 14602 => Loss: 49.51929418300603913394\n",
      "Iteration 14603 => Loss: 49.51910598703145183208\n",
      "Iteration 14604 => Loss: 49.51891779253385550419\n",
      "Iteration 14605 => Loss: 49.51872959951314356886\n",
      "Iteration 14606 => Loss: 49.51854140796939418578\n",
      "Iteration 14607 => Loss: 49.51835321790257182784\n",
      "Iteration 14608 => Loss: 49.51816502931261965159\n",
      "Iteration 14609 => Loss: 49.51797684219957318419\n",
      "Iteration 14610 => Loss: 49.51778865656341110935\n",
      "Iteration 14611 => Loss: 49.51760047240414053249\n",
      "Iteration 14612 => Loss: 49.51741228972170461020\n",
      "Iteration 14613 => Loss: 49.51722410851612465876\n",
      "Iteration 14614 => Loss: 49.51703592878737936189\n",
      "Iteration 14615 => Loss: 49.51684775053546871959\n",
      "Iteration 14616 => Loss: 49.51665957376035720472\n",
      "Iteration 14617 => Loss: 49.51647139846205192271\n",
      "Iteration 14618 => Loss: 49.51628322464053866270\n",
      "Iteration 14619 => Loss: 49.51609505229580321384\n",
      "Iteration 14620 => Loss: 49.51590688142783136527\n",
      "Iteration 14621 => Loss: 49.51571871203660890615\n",
      "Iteration 14622 => Loss: 49.51553054412214294189\n",
      "Iteration 14623 => Loss: 49.51534237768441926164\n",
      "Iteration 14624 => Loss: 49.51515421272339523284\n",
      "Iteration 14625 => Loss: 49.51496604923908506635\n",
      "Iteration 14626 => Loss: 49.51477788723146744587\n",
      "Iteration 14627 => Loss: 49.51458972670054237142\n",
      "Iteration 14628 => Loss: 49.51440156764628852670\n",
      "Iteration 14629 => Loss: 49.51421341006869880630\n",
      "Iteration 14630 => Loss: 49.51402525396775899935\n",
      "Iteration 14631 => Loss: 49.51383709934344778958\n",
      "Iteration 14632 => Loss: 49.51364894619577228241\n",
      "Iteration 14633 => Loss: 49.51346079452471826698\n",
      "Iteration 14634 => Loss: 49.51327264433025732160\n",
      "Iteration 14635 => Loss: 49.51308449561240365711\n",
      "Iteration 14636 => Loss: 49.51289634837112885180\n",
      "Iteration 14637 => Loss: 49.51270820260641869481\n",
      "Iteration 14638 => Loss: 49.51252005831826608073\n",
      "Iteration 14639 => Loss: 49.51233191550665679870\n",
      "Iteration 14640 => Loss: 49.51214377417159795414\n",
      "Iteration 14641 => Loss: 49.51195563431303980906\n",
      "Iteration 14642 => Loss: 49.51176749593101078517\n",
      "Iteration 14643 => Loss: 49.51157935902547535534\n",
      "Iteration 14644 => Loss: 49.51139122359641220328\n",
      "Iteration 14645 => Loss: 49.51120308964386396156\n",
      "Iteration 14646 => Loss: 49.51101495716773115419\n",
      "Iteration 14647 => Loss: 49.51082682616809904630\n",
      "Iteration 14648 => Loss: 49.51063869664488947819\n",
      "Iteration 14649 => Loss: 49.51045056859813087158\n",
      "Iteration 14650 => Loss: 49.51026244202774506675\n",
      "Iteration 14651 => Loss: 49.51007431693379601256\n",
      "Iteration 14652 => Loss: 49.50988619331624818187\n",
      "Iteration 14653 => Loss: 49.50969807117508025840\n",
      "Iteration 14654 => Loss: 49.50950995051027803129\n",
      "Iteration 14655 => Loss: 49.50932183132183439511\n",
      "Iteration 14656 => Loss: 49.50913371360975645530\n",
      "Iteration 14657 => Loss: 49.50894559737401579014\n",
      "Iteration 14658 => Loss: 49.50875748261458397792\n",
      "Iteration 14659 => Loss: 49.50856936933146812407\n",
      "Iteration 14660 => Loss: 49.50838125752466112317\n",
      "Iteration 14661 => Loss: 49.50819314719414876436\n",
      "Iteration 14662 => Loss: 49.50800503833990973135\n",
      "Iteration 14663 => Loss: 49.50781693096192981329\n",
      "Iteration 14664 => Loss: 49.50762882506023743190\n",
      "Iteration 14665 => Loss: 49.50744072063476863832\n",
      "Iteration 14666 => Loss: 49.50725261768553053798\n",
      "Iteration 14667 => Loss: 49.50706451621253023632\n",
      "Iteration 14668 => Loss: 49.50687641621573220618\n",
      "Iteration 14669 => Loss: 49.50668831769512223673\n",
      "Iteration 14670 => Loss: 49.50650022065074296052\n",
      "Iteration 14671 => Loss: 49.50631212508248069071\n",
      "Iteration 14672 => Loss: 49.50612403099039937615\n",
      "Iteration 14673 => Loss: 49.50593593837449191142\n",
      "Iteration 14674 => Loss: 49.50574784723470855852\n",
      "Iteration 14675 => Loss: 49.50555975757107063373\n",
      "Iteration 14676 => Loss: 49.50537166938352129364\n",
      "Iteration 14677 => Loss: 49.50518358267211027623\n",
      "Iteration 14678 => Loss: 49.50499549743676652724\n",
      "Iteration 14679 => Loss: 49.50480741367751846838\n",
      "Iteration 14680 => Loss: 49.50461933139435899420\n",
      "Iteration 14681 => Loss: 49.50443125058723126131\n",
      "Iteration 14682 => Loss: 49.50424317125617079682\n",
      "Iteration 14683 => Loss: 49.50405509340113496819\n",
      "Iteration 14684 => Loss: 49.50386701702213798626\n",
      "Iteration 14685 => Loss: 49.50367894211913721847\n",
      "Iteration 14686 => Loss: 49.50349086869215398110\n",
      "Iteration 14687 => Loss: 49.50330279674115274702\n",
      "Iteration 14688 => Loss: 49.50311472626610509451\n",
      "Iteration 14689 => Loss: 49.50292665726707497242\n",
      "Iteration 14690 => Loss: 49.50273858974397711563\n",
      "Iteration 14691 => Loss: 49.50255052369680441871\n",
      "Iteration 14692 => Loss: 49.50236245912559240878\n",
      "Iteration 14693 => Loss: 49.50217439603029134787\n",
      "Iteration 14694 => Loss: 49.50198633441087991969\n",
      "Iteration 14695 => Loss: 49.50179827426740075680\n",
      "Iteration 14696 => Loss: 49.50161021559978280493\n",
      "Iteration 14697 => Loss: 49.50142215840806159122\n",
      "Iteration 14698 => Loss: 49.50123410269218737767\n",
      "Iteration 14699 => Loss: 49.50104604845217437514\n",
      "Iteration 14700 => Loss: 49.50085799568799416193\n",
      "Iteration 14701 => Loss: 49.50066994439962542174\n",
      "Iteration 14702 => Loss: 49.50048189458710368172\n",
      "Iteration 14703 => Loss: 49.50029384625036499301\n",
      "Iteration 14704 => Loss: 49.50010579938942356648\n",
      "Iteration 14705 => Loss: 49.49991775400425808584\n",
      "Iteration 14706 => Loss: 49.49972971009487565652\n",
      "Iteration 14707 => Loss: 49.49954166766125496224\n",
      "Iteration 14708 => Loss: 49.49935362670338889757\n",
      "Iteration 14709 => Loss: 49.49916558722124193537\n",
      "Iteration 14710 => Loss: 49.49897754921481407564\n",
      "Iteration 14711 => Loss: 49.49878951268409110753\n",
      "Iteration 14712 => Loss: 49.49860147762909434732\n",
      "Iteration 14713 => Loss: 49.49841344404978826788\n",
      "Iteration 14714 => Loss: 49.49822541194615865834\n",
      "Iteration 14715 => Loss: 49.49803738131817709700\n",
      "Iteration 14716 => Loss: 49.49784935216586490014\n",
      "Iteration 14717 => Loss: 49.49766132448917232978\n",
      "Iteration 14718 => Loss: 49.49747329828813491304\n",
      "Iteration 14719 => Loss: 49.49728527356271712279\n",
      "Iteration 14720 => Loss: 49.49709725031290474817\n",
      "Iteration 14721 => Loss: 49.49690922853867647291\n",
      "Iteration 14722 => Loss: 49.49672120824002519157\n",
      "Iteration 14723 => Loss: 49.49653318941696511502\n",
      "Iteration 14724 => Loss: 49.49634517206946782153\n",
      "Iteration 14725 => Loss: 49.49615715619751199483\n",
      "Iteration 14726 => Loss: 49.49596914180111184578\n",
      "Iteration 14727 => Loss: 49.49578112888021763638\n",
      "Iteration 14728 => Loss: 49.49559311743486489377\n",
      "Iteration 14729 => Loss: 49.49540510746498256367\n",
      "Iteration 14730 => Loss: 49.49521709897060617322\n",
      "Iteration 14731 => Loss: 49.49502909195172151158\n",
      "Iteration 14732 => Loss: 49.49484108640830726245\n",
      "Iteration 14733 => Loss: 49.49465308234034210955\n",
      "Iteration 14734 => Loss: 49.49446507974781894745\n",
      "Iteration 14735 => Loss: 49.49427707863071645988\n",
      "Iteration 14736 => Loss: 49.49408907898907727940\n",
      "Iteration 14737 => Loss: 49.49390108082283035174\n",
      "Iteration 14738 => Loss: 49.49371308413198278231\n",
      "Iteration 14739 => Loss: 49.49352508891652036027\n",
      "Iteration 14740 => Loss: 49.49333709517642176934\n",
      "Iteration 14741 => Loss: 49.49314910291170122036\n",
      "Iteration 14742 => Loss: 49.49296111212234450250\n",
      "Iteration 14743 => Loss: 49.49277312280832319402\n",
      "Iteration 14744 => Loss: 49.49258513496963018952\n",
      "Iteration 14745 => Loss: 49.49239714860624417270\n",
      "Iteration 14746 => Loss: 49.49220916371816514356\n",
      "Iteration 14747 => Loss: 49.49202118030540731297\n",
      "Iteration 14748 => Loss: 49.49183319836790673207\n",
      "Iteration 14749 => Loss: 49.49164521790569892801\n",
      "Iteration 14750 => Loss: 49.49145723891873416278\n",
      "Iteration 14751 => Loss: 49.49126926140701243639\n",
      "Iteration 14752 => Loss: 49.49108128537054085427\n",
      "Iteration 14753 => Loss: 49.49089331080929099471\n",
      "Iteration 14754 => Loss: 49.49070533772327706856\n",
      "Iteration 14755 => Loss: 49.49051736611244933783\n",
      "Iteration 14756 => Loss: 49.49032939597682201338\n",
      "Iteration 14757 => Loss: 49.49014142731633114636\n",
      "Iteration 14758 => Loss: 49.48995346013104068561\n",
      "Iteration 14759 => Loss: 49.48976549442093642028\n",
      "Iteration 14760 => Loss: 49.48957753018594019068\n",
      "Iteration 14761 => Loss: 49.48938956742609462935\n",
      "Iteration 14762 => Loss: 49.48920160614135710375\n",
      "Iteration 14763 => Loss: 49.48901364633173471930\n",
      "Iteration 14764 => Loss: 49.48882568799722747599\n",
      "Iteration 14765 => Loss: 49.48863773113777853041\n",
      "Iteration 14766 => Loss: 49.48844977575341630427\n",
      "Iteration 14767 => Loss: 49.48826182184411948128\n",
      "Iteration 14768 => Loss: 49.48807386940987385060\n",
      "Iteration 14769 => Loss: 49.48788591845067941222\n",
      "Iteration 14770 => Loss: 49.48769796896649353357\n",
      "Iteration 14771 => Loss: 49.48751002095735174180\n",
      "Iteration 14772 => Loss: 49.48732207442321140434\n",
      "Iteration 14773 => Loss: 49.48713412936403699405\n",
      "Iteration 14774 => Loss: 49.48694618577986403807\n",
      "Iteration 14775 => Loss: 49.48675824367067122012\n",
      "Iteration 14776 => Loss: 49.48657030303641590763\n",
      "Iteration 14777 => Loss: 49.48638236387711941688\n",
      "Iteration 14778 => Loss: 49.48619442619277464246\n",
      "Iteration 14779 => Loss: 49.48600648998333895179\n",
      "Iteration 14780 => Loss: 49.48581855524884076658\n",
      "Iteration 14781 => Loss: 49.48563062198920192714\n",
      "Iteration 14782 => Loss: 49.48544269020448638230\n",
      "Iteration 14783 => Loss: 49.48525475989463728865\n",
      "Iteration 14784 => Loss: 49.48506683105964754077\n",
      "Iteration 14785 => Loss: 49.48487890369953134950\n",
      "Iteration 14786 => Loss: 49.48469097781427450400\n",
      "Iteration 14787 => Loss: 49.48450305340381305541\n",
      "Iteration 14788 => Loss: 49.48431513046818253088\n",
      "Iteration 14789 => Loss: 49.48412720900736161411\n",
      "Iteration 14790 => Loss: 49.48393928902135030512\n",
      "Iteration 14791 => Loss: 49.48375137051009886591\n",
      "Iteration 14792 => Loss: 49.48356345347364992904\n",
      "Iteration 14793 => Loss: 49.48337553791196086195\n",
      "Iteration 14794 => Loss: 49.48318762382501034836\n",
      "Iteration 14795 => Loss: 49.48299971121279128283\n",
      "Iteration 14796 => Loss: 49.48281180007531787624\n",
      "Iteration 14797 => Loss: 49.48262389041257591771\n",
      "Iteration 14798 => Loss: 49.48243598222449435298\n",
      "Iteration 14799 => Loss: 49.48224807551115844717\n",
      "Iteration 14800 => Loss: 49.48206017027247582973\n",
      "Iteration 14801 => Loss: 49.48187226650848202780\n",
      "Iteration 14802 => Loss: 49.48168436421911309253\n",
      "Iteration 14803 => Loss: 49.48149646340441876191\n",
      "Iteration 14804 => Loss: 49.48130856406434219252\n",
      "Iteration 14805 => Loss: 49.48112066619889048980\n",
      "Iteration 14806 => Loss: 49.48093276980807075915\n",
      "Iteration 14807 => Loss: 49.48074487489184036804\n",
      "Iteration 14808 => Loss: 49.48055698145018510559\n",
      "Iteration 14809 => Loss: 49.48036908948313339351\n",
      "Iteration 14810 => Loss: 49.48018119899063549383\n",
      "Iteration 14811 => Loss: 49.47999330997270561738\n",
      "Iteration 14812 => Loss: 49.47980542242930113161\n",
      "Iteration 14813 => Loss: 49.47961753636043624738\n",
      "Iteration 14814 => Loss: 49.47942965176608964839\n",
      "Iteration 14815 => Loss: 49.47924176864625422922\n",
      "Iteration 14816 => Loss: 49.47905388700090867360\n",
      "Iteration 14817 => Loss: 49.47886600683006719237\n",
      "Iteration 14818 => Loss: 49.47867812813368004754\n",
      "Iteration 14819 => Loss: 49.47849025091176855540\n",
      "Iteration 14820 => Loss: 49.47830237516427587252\n",
      "Iteration 14821 => Loss: 49.47811450089125173690\n",
      "Iteration 14822 => Loss: 49.47792662809266772683\n",
      "Iteration 14823 => Loss: 49.47773875676846699889\n",
      "Iteration 14824 => Loss: 49.47755088691868508022\n",
      "Iteration 14825 => Loss: 49.47736301854327933825\n",
      "Iteration 14826 => Loss: 49.47717515164229240554\n",
      "Iteration 14827 => Loss: 49.47698728621564612240\n",
      "Iteration 14828 => Loss: 49.47679942226335469968\n",
      "Iteration 14829 => Loss: 49.47661155978541813738\n",
      "Iteration 14830 => Loss: 49.47642369878181511922\n",
      "Iteration 14831 => Loss: 49.47623583925254564519\n",
      "Iteration 14832 => Loss: 49.47604798119757418817\n",
      "Iteration 14833 => Loss: 49.47586012461690074815\n",
      "Iteration 14834 => Loss: 49.47567226951053953599\n",
      "Iteration 14835 => Loss: 49.47548441587844081369\n",
      "Iteration 14836 => Loss: 49.47529656372060458125\n",
      "Iteration 14837 => Loss: 49.47510871303703083868\n",
      "Iteration 14838 => Loss: 49.47492086382769826969\n",
      "Iteration 14839 => Loss: 49.47473301609257845257\n",
      "Iteration 14840 => Loss: 49.47454516983168559818\n",
      "Iteration 14841 => Loss: 49.47435732504500549567\n",
      "Iteration 14842 => Loss: 49.47416948173250972332\n",
      "Iteration 14843 => Loss: 49.47398163989421249198\n",
      "Iteration 14844 => Loss: 49.47379379953008537996\n",
      "Iteration 14845 => Loss: 49.47360596064012128181\n",
      "Iteration 14846 => Loss: 49.47341812322429888127\n",
      "Iteration 14847 => Loss: 49.47323028728263238918\n",
      "Iteration 14848 => Loss: 49.47304245281506496212\n",
      "Iteration 14849 => Loss: 49.47285461982164633810\n",
      "Iteration 14850 => Loss: 49.47266678830229835739\n",
      "Iteration 14851 => Loss: 49.47247895825707075801\n",
      "Iteration 14852 => Loss: 49.47229112968589248567\n",
      "Iteration 14853 => Loss: 49.47210330258882038379\n",
      "Iteration 14854 => Loss: 49.47191547696577629267\n",
      "Iteration 14855 => Loss: 49.47172765281677442317\n",
      "Iteration 14856 => Loss: 49.47153983014182188072\n",
      "Iteration 14857 => Loss: 49.47135200894089024359\n",
      "Iteration 14858 => Loss: 49.47116418921395819552\n",
      "Iteration 14859 => Loss: 49.47097637096105415822\n",
      "Iteration 14860 => Loss: 49.47078855418211418282\n",
      "Iteration 14861 => Loss: 49.47060073887714537477\n",
      "Iteration 14862 => Loss: 49.47041292504616194492\n",
      "Iteration 14863 => Loss: 49.47022511268911415527\n",
      "Iteration 14864 => Loss: 49.47003730180600200583\n",
      "Iteration 14865 => Loss: 49.46984949239683260203\n",
      "Iteration 14866 => Loss: 49.46966168446158462757\n",
      "Iteration 14867 => Loss: 49.46947387800024387161\n",
      "Iteration 14868 => Loss: 49.46928607301280322872\n",
      "Iteration 14869 => Loss: 49.46909826949920585548\n",
      "Iteration 14870 => Loss: 49.46891046745952280617\n",
      "Iteration 14871 => Loss: 49.46872266689369723736\n",
      "Iteration 14872 => Loss: 49.46853486780170783277\n",
      "Iteration 14873 => Loss: 49.46834707018356880326\n",
      "Iteration 14874 => Loss: 49.46815927403924462169\n",
      "Iteration 14875 => Loss: 49.46797147936874949892\n",
      "Iteration 14876 => Loss: 49.46778368617202659152\n",
      "Iteration 14877 => Loss: 49.46759589444911853207\n",
      "Iteration 14878 => Loss: 49.46740810419998979341\n",
      "Iteration 14879 => Loss: 49.46722031542461905929\n",
      "Iteration 14880 => Loss: 49.46703252812299922425\n",
      "Iteration 14881 => Loss: 49.46684474229514449917\n",
      "Iteration 14882 => Loss: 49.46665695794102646232\n",
      "Iteration 14883 => Loss: 49.46646917506059537573\n",
      "Iteration 14884 => Loss: 49.46628139365390097737\n",
      "Iteration 14885 => Loss: 49.46609361372090063469\n",
      "Iteration 14886 => Loss: 49.46590583526159434768\n",
      "Iteration 14887 => Loss: 49.46571805827596080007\n",
      "Iteration 14888 => Loss: 49.46553028276397157015\n",
      "Iteration 14889 => Loss: 49.46534250872564086876\n",
      "Iteration 14890 => Loss: 49.46515473616095448506\n",
      "Iteration 14891 => Loss: 49.46496696506991241904\n",
      "Iteration 14892 => Loss: 49.46477919545248624900\n",
      "Iteration 14893 => Loss: 49.46459142730864044779\n",
      "Iteration 14894 => Loss: 49.46440366063842475342\n",
      "Iteration 14895 => Loss: 49.46421589544176811160\n",
      "Iteration 14896 => Loss: 49.46402813171867762776\n",
      "Iteration 14897 => Loss: 49.46384036946916040733\n",
      "Iteration 14898 => Loss: 49.46365260869318802861\n",
      "Iteration 14899 => Loss: 49.46346484939075338616\n",
      "Iteration 14900 => Loss: 49.46327709156184937456\n",
      "Iteration 14901 => Loss: 49.46308933520645467752\n",
      "Iteration 14902 => Loss: 49.46290158032455508419\n",
      "Iteration 14903 => Loss: 49.46271382691616480543\n",
      "Iteration 14904 => Loss: 49.46252607498121989238\n",
      "Iteration 14905 => Loss: 49.46233832451977008304\n",
      "Iteration 14906 => Loss: 49.46215057553177274485\n",
      "Iteration 14907 => Loss: 49.46196282801722077238\n",
      "Iteration 14908 => Loss: 49.46177508197609995477\n",
      "Iteration 14909 => Loss: 49.46158733740838187032\n",
      "Iteration 14910 => Loss: 49.46139959431408072987\n",
      "Iteration 14911 => Loss: 49.46121185269318232258\n",
      "Iteration 14912 => Loss: 49.46102411254567954302\n",
      "Iteration 14913 => Loss: 49.46083637387154396947\n",
      "Iteration 14914 => Loss: 49.46064863667077560194\n",
      "Iteration 14915 => Loss: 49.46046090094334601872\n",
      "Iteration 14916 => Loss: 49.46027316668927653609\n",
      "Iteration 14917 => Loss: 49.46008543390852452148\n",
      "Iteration 14918 => Loss: 49.45989770260107576405\n",
      "Iteration 14919 => Loss: 49.45970997276694447464\n",
      "Iteration 14920 => Loss: 49.45952224440609512612\n",
      "Iteration 14921 => Loss: 49.45933451751854192935\n",
      "Iteration 14922 => Loss: 49.45914679210427777889\n",
      "Iteration 14923 => Loss: 49.45895906816325293676\n",
      "Iteration 14924 => Loss: 49.45877134569548161380\n",
      "Iteration 14925 => Loss: 49.45858362470091407204\n",
      "Iteration 14926 => Loss: 49.45839590517961426031\n",
      "Iteration 14927 => Loss: 49.45820818713149691348\n",
      "Iteration 14928 => Loss: 49.45802047055660466413\n",
      "Iteration 14929 => Loss: 49.45783275545488777425\n",
      "Iteration 14930 => Loss: 49.45764504182635334928\n",
      "Iteration 14931 => Loss: 49.45745732967098717836\n",
      "Iteration 14932 => Loss: 49.45726961898878926149\n",
      "Iteration 14933 => Loss: 49.45708190977970986069\n",
      "Iteration 14934 => Loss: 49.45689420204377029222\n",
      "Iteration 14935 => Loss: 49.45670649578096345067\n",
      "Iteration 14936 => Loss: 49.45651879099125380890\n",
      "Iteration 14937 => Loss: 49.45633108767464136690\n",
      "Iteration 14938 => Loss: 49.45614338583113323011\n",
      "Iteration 14939 => Loss: 49.45595568546067255511\n",
      "Iteration 14940 => Loss: 49.45576798656327355275\n",
      "Iteration 14941 => Loss: 49.45558028913894332845\n",
      "Iteration 14942 => Loss: 49.45539259318763924966\n",
      "Iteration 14943 => Loss: 49.45520489870937552723\n",
      "Iteration 14944 => Loss: 49.45501720570413795031\n",
      "Iteration 14945 => Loss: 49.45482951417187678089\n",
      "Iteration 14946 => Loss: 49.45464182411262754613\n",
      "Iteration 14947 => Loss: 49.45445413552634761345\n",
      "Iteration 14948 => Loss: 49.45426644841305119371\n",
      "Iteration 14949 => Loss: 49.45407876277270986520\n",
      "Iteration 14950 => Loss: 49.45389107860530231164\n",
      "Iteration 14951 => Loss: 49.45370339591084984932\n",
      "Iteration 14952 => Loss: 49.45351571468931695108\n",
      "Iteration 14953 => Loss: 49.45332803494068940608\n",
      "Iteration 14954 => Loss: 49.45314035666495300347\n",
      "Iteration 14955 => Loss: 49.45295267986215037581\n",
      "Iteration 14956 => Loss: 49.45276500453216073083\n",
      "Iteration 14957 => Loss: 49.45257733067506933367\n",
      "Iteration 14958 => Loss: 49.45238965829083355175\n",
      "Iteration 14959 => Loss: 49.45220198737943206879\n",
      "Iteration 14960 => Loss: 49.45201431794087909566\n",
      "Iteration 14961 => Loss: 49.45182664997513910521\n",
      "Iteration 14962 => Loss: 49.45163898348220499201\n",
      "Iteration 14963 => Loss: 49.45145131846207675608\n",
      "Iteration 14964 => Loss: 49.45126365491470465940\n",
      "Iteration 14965 => Loss: 49.45107599284014554541\n",
      "Iteration 14966 => Loss: 49.45088833223831414898\n",
      "Iteration 14967 => Loss: 49.45070067310925310267\n",
      "Iteration 14968 => Loss: 49.45051301545291977391\n",
      "Iteration 14969 => Loss: 49.45032535926931416270\n",
      "Iteration 14970 => Loss: 49.45013770455844337448\n",
      "Iteration 14971 => Loss: 49.44995005132026477668\n",
      "Iteration 14972 => Loss: 49.44976239955476415844\n",
      "Iteration 14973 => Loss: 49.44957474926197704690\n",
      "Iteration 14974 => Loss: 49.44938710044183238779\n",
      "Iteration 14975 => Loss: 49.44919945309435149738\n",
      "Iteration 14976 => Loss: 49.44901180721952727026\n",
      "Iteration 14977 => Loss: 49.44882416281732417929\n",
      "Iteration 14978 => Loss: 49.44863651988775643531\n",
      "Iteration 14979 => Loss: 49.44844887843080272205\n",
      "Iteration 14980 => Loss: 49.44826123844642751237\n",
      "Iteration 14981 => Loss: 49.44807359993466633341\n",
      "Iteration 14982 => Loss: 49.44788596289546234175\n",
      "Iteration 14983 => Loss: 49.44769832732884395909\n",
      "Iteration 14984 => Loss: 49.44751069323476855288\n",
      "Iteration 14985 => Loss: 49.44732306061320059598\n",
      "Iteration 14986 => Loss: 49.44713542946423245894\n",
      "Iteration 14987 => Loss: 49.44694779978774334950\n",
      "Iteration 14988 => Loss: 49.44676017158376168936\n",
      "Iteration 14989 => Loss: 49.44657254485228747853\n",
      "Iteration 14990 => Loss: 49.44638491959329229530\n",
      "Iteration 14991 => Loss: 49.44619729580676903424\n",
      "Iteration 14992 => Loss: 49.44600967349269637907\n",
      "Iteration 14993 => Loss: 49.44582205265108854064\n",
      "Iteration 14994 => Loss: 49.44563443328191709725\n",
      "Iteration 14995 => Loss: 49.44544681538516783803\n",
      "Iteration 14996 => Loss: 49.44525919896085497385\n",
      "Iteration 14997 => Loss: 49.44507158400892166128\n",
      "Iteration 14998 => Loss: 49.44488397052941053289\n",
      "Iteration 14999 => Loss: 49.44469635852224342898\n",
      "Iteration 15000 => Loss: 49.44450874798747008754\n",
      "Iteration 15001 => Loss: 49.44432113892504077057\n",
      "Iteration 15002 => Loss: 49.44413353133495547809\n",
      "Iteration 15003 => Loss: 49.44394592521720710465\n",
      "Iteration 15004 => Loss: 49.44375832057177433398\n",
      "Iteration 15005 => Loss: 49.44357071739867848237\n",
      "Iteration 15006 => Loss: 49.44338311569787691724\n",
      "Iteration 15007 => Loss: 49.44319551546935542774\n",
      "Iteration 15008 => Loss: 49.44300791671309980302\n",
      "Iteration 15009 => Loss: 49.44282031942912425393\n",
      "Iteration 15010 => Loss: 49.44263272361740746419\n",
      "Iteration 15011 => Loss: 49.44244512927790680124\n",
      "Iteration 15012 => Loss: 49.44225753641065068678\n",
      "Iteration 15013 => Loss: 49.44206994501561780453\n",
      "Iteration 15014 => Loss: 49.44188235509279394364\n",
      "Iteration 15015 => Loss: 49.44169476664215778783\n",
      "Iteration 15016 => Loss: 49.44150717966372354795\n",
      "Iteration 15017 => Loss: 49.44131959415744859143\n",
      "Iteration 15018 => Loss: 49.44113201012331870743\n",
      "Iteration 15019 => Loss: 49.44094442756135521222\n",
      "Iteration 15020 => Loss: 49.44075684647152257867\n",
      "Iteration 15021 => Loss: 49.44056926685383501763\n",
      "Iteration 15022 => Loss: 49.44038168870825700196\n",
      "Iteration 15023 => Loss: 49.44019411203477432082\n",
      "Iteration 15024 => Loss: 49.44000653683336565791\n",
      "Iteration 15025 => Loss: 49.43981896310408075124\n",
      "Iteration 15026 => Loss: 49.43963139084684144109\n",
      "Iteration 15027 => Loss: 49.43944382006164772747\n",
      "Iteration 15028 => Loss: 49.43925625074851382124\n",
      "Iteration 15029 => Loss: 49.43906868290740419525\n",
      "Iteration 15030 => Loss: 49.43888111653831884951\n",
      "Iteration 15031 => Loss: 49.43869355164125067859\n",
      "Iteration 15032 => Loss: 49.43850598821618547163\n",
      "Iteration 15033 => Loss: 49.43831842626308770150\n",
      "Iteration 15034 => Loss: 49.43813086578200000076\n",
      "Iteration 15035 => Loss: 49.43794330677285131515\n",
      "Iteration 15036 => Loss: 49.43775574923567717178\n",
      "Iteration 15037 => Loss: 49.43756819317041362183\n",
      "Iteration 15038 => Loss: 49.43738063857708198157\n",
      "Iteration 15039 => Loss: 49.43719308545569646185\n",
      "Iteration 15040 => Loss: 49.43700553380620021926\n",
      "Iteration 15041 => Loss: 49.43681798362862878093\n",
      "Iteration 15042 => Loss: 49.43663043492290398717\n",
      "Iteration 15043 => Loss: 49.43644288768905425968\n",
      "Iteration 15044 => Loss: 49.43625534192708670389\n",
      "Iteration 15045 => Loss: 49.43606779763695158181\n",
      "Iteration 15046 => Loss: 49.43588025481865599886\n",
      "Iteration 15047 => Loss: 49.43569271347219284962\n",
      "Iteration 15048 => Loss: 49.43550517359752660695\n",
      "Iteration 15049 => Loss: 49.43531763519471411428\n",
      "Iteration 15050 => Loss: 49.43513009826364879018\n",
      "Iteration 15051 => Loss: 49.43494256280436616180\n",
      "Iteration 15052 => Loss: 49.43475502881685912371\n",
      "Iteration 15053 => Loss: 49.43456749630109925420\n",
      "Iteration 15054 => Loss: 49.43437996525710786955\n",
      "Iteration 15055 => Loss: 49.43419243568483523177\n",
      "Iteration 15056 => Loss: 49.43400490758426002458\n",
      "Iteration 15057 => Loss: 49.43381738095543909139\n",
      "Iteration 15058 => Loss: 49.43362985579829427252\n",
      "Iteration 15059 => Loss: 49.43344233211285398966\n",
      "Iteration 15060 => Loss: 49.43325480989907561025\n",
      "Iteration 15061 => Loss: 49.43306728915695913429\n",
      "Iteration 15062 => Loss: 49.43287976988649035093\n",
      "Iteration 15063 => Loss: 49.43269225208769768187\n",
      "Iteration 15064 => Loss: 49.43250473576048165114\n",
      "Iteration 15065 => Loss: 49.43231722090492041843\n",
      "Iteration 15066 => Loss: 49.43212970752095714033\n",
      "Iteration 15067 => Loss: 49.43194219560859181684\n",
      "Iteration 15068 => Loss: 49.43175468516780313166\n",
      "Iteration 15069 => Loss: 49.43156717619859108481\n",
      "Iteration 15070 => Loss: 49.43137966870094857086\n",
      "Iteration 15071 => Loss: 49.43119216267482585181\n",
      "Iteration 15072 => Loss: 49.43100465812027266566\n",
      "Iteration 15073 => Loss: 49.43081715503723216898\n",
      "Iteration 15074 => Loss: 49.43062965342571146721\n",
      "Iteration 15075 => Loss: 49.43044215328569634949\n",
      "Iteration 15076 => Loss: 49.43025465461715839410\n",
      "Iteration 15077 => Loss: 49.43006715742009049563\n",
      "Iteration 15078 => Loss: 49.42987966169451397036\n",
      "Iteration 15079 => Loss: 49.42969216744039329114\n",
      "Iteration 15080 => Loss: 49.42950467465772845799\n",
      "Iteration 15081 => Loss: 49.42931718334646973290\n",
      "Iteration 15082 => Loss: 49.42912969350663843215\n",
      "Iteration 15083 => Loss: 49.42894220513821323948\n",
      "Iteration 15084 => Loss: 49.42875471824120126030\n",
      "Iteration 15085 => Loss: 49.42856723281558117833\n",
      "Iteration 15086 => Loss: 49.42837974886132457186\n",
      "Iteration 15087 => Loss: 49.42819226637841723004\n",
      "Iteration 15088 => Loss: 49.42800478536690178544\n",
      "Iteration 15089 => Loss: 49.42781730582670718377\n",
      "Iteration 15090 => Loss: 49.42762982775781921418\n",
      "Iteration 15091 => Loss: 49.42744235116029472010\n",
      "Iteration 15092 => Loss: 49.42725487603403422554\n",
      "Iteration 15093 => Loss: 49.42706740237910167934\n",
      "Iteration 15094 => Loss: 49.42687993019541892181\n",
      "Iteration 15095 => Loss: 49.42669245948303569094\n",
      "Iteration 15096 => Loss: 49.42650499024190224873\n",
      "Iteration 15097 => Loss: 49.42631752247202570061\n",
      "Iteration 15098 => Loss: 49.42613005617338473030\n",
      "Iteration 15099 => Loss: 49.42594259134596512695\n",
      "Iteration 15100 => Loss: 49.42575512798974557427\n",
      "Iteration 15101 => Loss: 49.42556766610474738854\n",
      "Iteration 15102 => Loss: 49.42538020569092793721\n",
      "Iteration 15103 => Loss: 49.42519274674830853655\n",
      "Iteration 15104 => Loss: 49.42500528927684655400\n",
      "Iteration 15105 => Loss: 49.42481783327654198956\n",
      "Iteration 15106 => Loss: 49.42463037874737352695\n",
      "Iteration 15107 => Loss: 49.42444292568934116616\n",
      "Iteration 15108 => Loss: 49.42425547410242359092\n",
      "Iteration 15109 => Loss: 49.42406802398663501208\n",
      "Iteration 15110 => Loss: 49.42388057534192569165\n",
      "Iteration 15111 => Loss: 49.42369312816830984048\n",
      "Iteration 15112 => Loss: 49.42350568246578035314\n",
      "Iteration 15113 => Loss: 49.42331823823430170251\n",
      "Iteration 15114 => Loss: 49.42313079547389520485\n",
      "Iteration 15115 => Loss: 49.42294335418448980590\n",
      "Iteration 15116 => Loss: 49.42275591436614945451\n",
      "Iteration 15117 => Loss: 49.42256847601881730725\n",
      "Iteration 15118 => Loss: 49.42238103914247915327\n",
      "Iteration 15119 => Loss: 49.42219360373715630885\n",
      "Iteration 15120 => Loss: 49.42200616980280614143\n",
      "Iteration 15121 => Loss: 49.42181873733942865101\n",
      "Iteration 15122 => Loss: 49.42163130634700962673\n",
      "Iteration 15123 => Loss: 49.42144387682554196317\n",
      "Iteration 15124 => Loss: 49.42125644877501855490\n",
      "Iteration 15125 => Loss: 49.42106902219540387478\n",
      "Iteration 15126 => Loss: 49.42088159708671213366\n",
      "Iteration 15127 => Loss: 49.42069417344893622612\n",
      "Iteration 15128 => Loss: 49.42050675128204062503\n",
      "Iteration 15129 => Loss: 49.42031933058600401409\n",
      "Iteration 15130 => Loss: 49.42013191136086902588\n",
      "Iteration 15131 => Loss: 49.41994449360655750070\n",
      "Iteration 15132 => Loss: 49.41975707732311917653\n",
      "Iteration 15133 => Loss: 49.41956966251049010452\n",
      "Iteration 15134 => Loss: 49.41938224916868449554\n",
      "Iteration 15135 => Loss: 49.41919483729770234959\n",
      "Iteration 15136 => Loss: 49.41900742689751524495\n",
      "Iteration 15137 => Loss: 49.41882001796811607619\n",
      "Iteration 15138 => Loss: 49.41863261050949773789\n",
      "Iteration 15139 => Loss: 49.41844520452162470292\n",
      "Iteration 15140 => Loss: 49.41825780000452539298\n",
      "Iteration 15141 => Loss: 49.41807039695815717550\n",
      "Iteration 15142 => Loss: 49.41788299538251294507\n",
      "Iteration 15143 => Loss: 49.41769559527758559625\n",
      "Iteration 15144 => Loss: 49.41750819664338223447\n",
      "Iteration 15145 => Loss: 49.41732079947986022717\n",
      "Iteration 15146 => Loss: 49.41713340378702667977\n",
      "Iteration 15147 => Loss: 49.41694600956484606513\n",
      "Iteration 15148 => Loss: 49.41675861681333969955\n",
      "Iteration 15149 => Loss: 49.41657122553248626673\n",
      "Iteration 15150 => Loss: 49.41638383572226445040\n",
      "Iteration 15151 => Loss: 49.41619644738267425055\n",
      "Iteration 15152 => Loss: 49.41600906051370145633\n",
      "Iteration 15153 => Loss: 49.41582167511529632975\n",
      "Iteration 15154 => Loss: 49.41563429118750860880\n",
      "Iteration 15155 => Loss: 49.41544690873031697720\n",
      "Iteration 15156 => Loss: 49.41525952774365748610\n",
      "Iteration 15157 => Loss: 49.41507214822758697892\n",
      "Iteration 15158 => Loss: 49.41488477018203440139\n",
      "Iteration 15159 => Loss: 49.41469739360702817521\n",
      "Iteration 15160 => Loss: 49.41451001850256119496\n",
      "Iteration 15161 => Loss: 49.41432264486857661723\n",
      "Iteration 15162 => Loss: 49.41413527270509575828\n",
      "Iteration 15163 => Loss: 49.41394790201209730185\n",
      "Iteration 15164 => Loss: 49.41376053278960256421\n",
      "Iteration 15165 => Loss: 49.41357316503752628023\n",
      "Iteration 15166 => Loss: 49.41338579875593950419\n",
      "Iteration 15167 => Loss: 49.41319843394478539267\n",
      "Iteration 15168 => Loss: 49.41301107060404973481\n",
      "Iteration 15169 => Loss: 49.41282370873375384690\n",
      "Iteration 15170 => Loss: 49.41263634833382667466\n",
      "Iteration 15171 => Loss: 49.41244898940430374523\n",
      "Iteration 15172 => Loss: 49.41226163194518505861\n",
      "Iteration 15173 => Loss: 49.41207427595643508766\n",
      "Iteration 15174 => Loss: 49.41188692143801830525\n",
      "Iteration 15175 => Loss: 49.41169956838999866022\n",
      "Iteration 15176 => Loss: 49.41151221681226957116\n",
      "Iteration 15177 => Loss: 49.41132486670487367064\n",
      "Iteration 15178 => Loss: 49.41113751806781095866\n",
      "Iteration 15179 => Loss: 49.41095017090103880264\n",
      "Iteration 15180 => Loss: 49.41076282520454299174\n",
      "Iteration 15181 => Loss: 49.41057548097833063139\n",
      "Iteration 15182 => Loss: 49.41038813822240882700\n",
      "Iteration 15183 => Loss: 49.41020079693674915688\n",
      "Iteration 15184 => Loss: 49.41001345712130188303\n",
      "Iteration 15185 => Loss: 49.40982611877609542717\n",
      "Iteration 15186 => Loss: 49.40963878190112978928\n",
      "Iteration 15187 => Loss: 49.40945144649636233680\n",
      "Iteration 15188 => Loss: 49.40926411256179306974\n",
      "Iteration 15189 => Loss: 49.40907678009741488268\n",
      "Iteration 15190 => Loss: 49.40888944910321356474\n",
      "Iteration 15191 => Loss: 49.40870211957913937795\n",
      "Iteration 15192 => Loss: 49.40851479152527048200\n",
      "Iteration 15193 => Loss: 49.40832746494150740091\n",
      "Iteration 15194 => Loss: 49.40814013982788566182\n",
      "Iteration 15195 => Loss: 49.40795281618436973758\n",
      "Iteration 15196 => Loss: 49.40776549401099515535\n",
      "Iteration 15197 => Loss: 49.40757817330768375541\n",
      "Iteration 15198 => Loss: 49.40739085407447106491\n",
      "Iteration 15199 => Loss: 49.40720353631131445127\n",
      "Iteration 15200 => Loss: 49.40701622001822812535\n",
      "Iteration 15201 => Loss: 49.40682890519518366546\n",
      "Iteration 15202 => Loss: 49.40664159184216686072\n",
      "Iteration 15203 => Loss: 49.40645427995920613284\n",
      "Iteration 15204 => Loss: 49.40626696954622332214\n",
      "Iteration 15205 => Loss: 49.40607966060326816660\n",
      "Iteration 15206 => Loss: 49.40589235313031224450\n",
      "Iteration 15207 => Loss: 49.40570504712728450158\n",
      "Iteration 15208 => Loss: 49.40551774259427730840\n",
      "Iteration 15209 => Loss: 49.40533043953120539982\n",
      "Iteration 15210 => Loss: 49.40514313793808298669\n",
      "Iteration 15211 => Loss: 49.40495583781488875275\n",
      "Iteration 15212 => Loss: 49.40476853916162980340\n",
      "Iteration 15213 => Loss: 49.40458124197827061153\n",
      "Iteration 15214 => Loss: 49.40439394626480407169\n",
      "Iteration 15215 => Loss: 49.40420665202123018389\n",
      "Iteration 15216 => Loss: 49.40401935924750631557\n",
      "Iteration 15217 => Loss: 49.40383206794369641557\n",
      "Iteration 15218 => Loss: 49.40364477810970100791\n",
      "Iteration 15219 => Loss: 49.40345748974557693600\n",
      "Iteration 15220 => Loss: 49.40327020285125314558\n",
      "Iteration 15221 => Loss: 49.40308291742676516378\n",
      "Iteration 15222 => Loss: 49.40289563347205614718\n",
      "Iteration 15223 => Loss: 49.40270835098717583378\n",
      "Iteration 15224 => Loss: 49.40252106997206027472\n",
      "Iteration 15225 => Loss: 49.40233379042672368087\n",
      "Iteration 15226 => Loss: 49.40214651235115894679\n",
      "Iteration 15227 => Loss: 49.40195923574529501821\n",
      "Iteration 15228 => Loss: 49.40177196060920294940\n",
      "Iteration 15229 => Loss: 49.40158468694283300238\n",
      "Iteration 15230 => Loss: 49.40139741474619938799\n",
      "Iteration 15231 => Loss: 49.40121014401923815740\n",
      "Iteration 15232 => Loss: 49.40102287476198483773\n",
      "Iteration 15233 => Loss: 49.40083560697436837472\n",
      "Iteration 15234 => Loss: 49.40064834065648113892\n",
      "Iteration 15235 => Loss: 49.40046107580820233807\n",
      "Iteration 15236 => Loss: 49.40027381242960302643\n",
      "Iteration 15237 => Loss: 49.40008655052063346602\n",
      "Iteration 15238 => Loss: 49.39989929008125812970\n",
      "Iteration 15239 => Loss: 49.39971203111150543918\n",
      "Iteration 15240 => Loss: 49.39952477361136118361\n",
      "Iteration 15241 => Loss: 49.39933751758078983585\n",
      "Iteration 15242 => Loss: 49.39915026301979139589\n",
      "Iteration 15243 => Loss: 49.39896300992838007460\n",
      "Iteration 15244 => Loss: 49.39877575830649902855\n",
      "Iteration 15245 => Loss: 49.39858850815416246860\n",
      "Iteration 15246 => Loss: 49.39840125947136328932\n",
      "Iteration 15247 => Loss: 49.39821401225806596358\n",
      "Iteration 15248 => Loss: 49.39802676651429891308\n",
      "Iteration 15249 => Loss: 49.39783952224001950526\n",
      "Iteration 15250 => Loss: 49.39765227943522063470\n",
      "Iteration 15251 => Loss: 49.39746503809988809053\n",
      "Iteration 15252 => Loss: 49.39727779823403608361\n",
      "Iteration 15253 => Loss: 49.39709055983760777053\n",
      "Iteration 15254 => Loss: 49.39690332291063157300\n",
      "Iteration 15255 => Loss: 49.39671608745307196386\n",
      "Iteration 15256 => Loss: 49.39652885346492183771\n",
      "Iteration 15257 => Loss: 49.39634162094618119454\n",
      "Iteration 15258 => Loss: 49.39615438989684292892\n",
      "Iteration 15259 => Loss: 49.39596716031685019743\n",
      "Iteration 15260 => Loss: 49.39577993220626694892\n",
      "Iteration 15261 => Loss: 49.39559270556500791827\n",
      "Iteration 15262 => Loss: 49.39540548039311573802\n",
      "Iteration 15263 => Loss: 49.39521825669053356478\n",
      "Iteration 15264 => Loss: 49.39503103445729692567\n",
      "Iteration 15265 => Loss: 49.39484381369334897727\n",
      "Iteration 15266 => Loss: 49.39465659439871814129\n",
      "Iteration 15267 => Loss: 49.39446937657337599603\n",
      "Iteration 15268 => Loss: 49.39428216021729411978\n",
      "Iteration 15269 => Loss: 49.39409494533047961795\n",
      "Iteration 15270 => Loss: 49.39390773191293249056\n",
      "Iteration 15271 => Loss: 49.39372051996459589418\n",
      "Iteration 15272 => Loss: 49.39353330948551956681\n",
      "Iteration 15273 => Loss: 49.39334610047562534874\n",
      "Iteration 15274 => Loss: 49.39315889293497718882\n",
      "Iteration 15275 => Loss: 49.39297168686352534905\n",
      "Iteration 15276 => Loss: 49.39278448226123430231\n",
      "Iteration 15277 => Loss: 49.39259727912811825945\n",
      "Iteration 15278 => Loss: 49.39241007746417011504\n",
      "Iteration 15279 => Loss: 49.39222287726935434193\n",
      "Iteration 15280 => Loss: 49.39203567854369225643\n",
      "Iteration 15281 => Loss: 49.39184848128715543680\n",
      "Iteration 15282 => Loss: 49.39166128549972967221\n",
      "Iteration 15283 => Loss: 49.39147409118139364637\n",
      "Iteration 15284 => Loss: 49.39128689833217578098\n",
      "Iteration 15285 => Loss: 49.39109970695199791635\n",
      "Iteration 15286 => Loss: 49.39091251704093110675\n",
      "Iteration 15287 => Loss: 49.39072532859891140333\n",
      "Iteration 15288 => Loss: 49.39053814162591748982\n",
      "Iteration 15289 => Loss: 49.39035095612194226078\n",
      "Iteration 15290 => Loss: 49.39016377208704966506\n",
      "Iteration 15291 => Loss: 49.38997658952113312125\n",
      "Iteration 15292 => Loss: 49.38978940842420684021\n",
      "Iteration 15293 => Loss: 49.38960222879626371650\n",
      "Iteration 15294 => Loss: 49.38941505063731085556\n",
      "Iteration 15295 => Loss: 49.38922787394731273025\n",
      "Iteration 15296 => Loss: 49.38904069872629776228\n",
      "Iteration 15297 => Loss: 49.38885352497418779194\n",
      "Iteration 15298 => Loss: 49.38866635269101834638\n",
      "Iteration 15299 => Loss: 49.38847918187677521473\n",
      "Iteration 15300 => Loss: 49.38829201253142997530\n",
      "Iteration 15301 => Loss: 49.38810484465497552264\n",
      "Iteration 15302 => Loss: 49.38791767824742606763\n",
      "Iteration 15303 => Loss: 49.38773051330873897768\n",
      "Iteration 15304 => Loss: 49.38754334983890714739\n",
      "Iteration 15305 => Loss: 49.38735618783790926045\n",
      "Iteration 15306 => Loss: 49.38716902730576663316\n",
      "Iteration 15307 => Loss: 49.38698186824245794924\n",
      "Iteration 15308 => Loss: 49.38679471064794057611\n",
      "Iteration 15309 => Loss: 49.38660755452225004092\n",
      "Iteration 15310 => Loss: 49.38642039986532950024\n",
      "Iteration 15311 => Loss: 49.38623324667720027037\n",
      "Iteration 15312 => Loss: 49.38604609495785524587\n",
      "Iteration 15313 => Loss: 49.38585894470724468874\n",
      "Iteration 15314 => Loss: 49.38567179592538991528\n",
      "Iteration 15315 => Loss: 49.38548464861225539835\n",
      "Iteration 15316 => Loss: 49.38529750276784113794\n",
      "Iteration 15317 => Loss: 49.38511035839214713405\n",
      "Iteration 15318 => Loss: 49.38492321548517338670\n",
      "Iteration 15319 => Loss: 49.38473607404686305244\n",
      "Iteration 15320 => Loss: 49.38454893407723034215\n",
      "Iteration 15321 => Loss: 49.38436179557626104497\n",
      "Iteration 15322 => Loss: 49.38417465854396226632\n",
      "Iteration 15323 => Loss: 49.38398752298028426821\n",
      "Iteration 15324 => Loss: 49.38380038888524126151\n",
      "Iteration 15325 => Loss: 49.38361325625882614077\n",
      "Iteration 15326 => Loss: 49.38342612510101048429\n",
      "Iteration 15327 => Loss: 49.38323899541178718664\n",
      "Iteration 15328 => Loss: 49.38305186719115624783\n",
      "Iteration 15329 => Loss: 49.38286474043909635157\n",
      "Iteration 15330 => Loss: 49.38267761515557907614\n",
      "Iteration 15331 => Loss: 49.38249049134063994870\n",
      "Iteration 15332 => Loss: 49.38230336899422212582\n",
      "Iteration 15333 => Loss: 49.38211624811633271293\n",
      "Iteration 15334 => Loss: 49.38192912870696460459\n",
      "Iteration 15335 => Loss: 49.38174201076609648453\n",
      "Iteration 15336 => Loss: 49.38155489429371414190\n",
      "Iteration 15337 => Loss: 49.38136777928981757668\n",
      "Iteration 15338 => Loss: 49.38118066575438547261\n",
      "Iteration 15339 => Loss: 49.38099355368741782968\n",
      "Iteration 15340 => Loss: 49.38080644308887912075\n",
      "Iteration 15341 => Loss: 49.38061933395879066211\n",
      "Iteration 15342 => Loss: 49.38043222629712403204\n",
      "Iteration 15343 => Loss: 49.38024512010384370342\n",
      "Iteration 15344 => Loss: 49.38005801537899941422\n",
      "Iteration 15345 => Loss: 49.37987091212252011019\n",
      "Iteration 15346 => Loss: 49.37968381033442000216\n",
      "Iteration 15347 => Loss: 49.37949671001470619558\n",
      "Iteration 15348 => Loss: 49.37930961116332184702\n",
      "Iteration 15349 => Loss: 49.37912251378029537818\n",
      "Iteration 15350 => Loss: 49.37893541786559126194\n",
      "Iteration 15351 => Loss: 49.37874832341919528744\n",
      "Iteration 15352 => Loss: 49.37856123044111456011\n",
      "Iteration 15353 => Loss: 49.37837413893134197451\n",
      "Iteration 15354 => Loss: 49.37818704888984910895\n",
      "Iteration 15355 => Loss: 49.37799996031661464713\n",
      "Iteration 15356 => Loss: 49.37781287321165990534\n",
      "Iteration 15357 => Loss: 49.37762578757495646187\n",
      "Iteration 15358 => Loss: 49.37743870340647589501\n",
      "Iteration 15359 => Loss: 49.37725162070622531019\n",
      "Iteration 15360 => Loss: 49.37706453947418339112\n",
      "Iteration 15361 => Loss: 49.37687745971034303238\n",
      "Iteration 15362 => Loss: 49.37669038141471844483\n",
      "Iteration 15363 => Loss: 49.37650330458725989047\n",
      "Iteration 15364 => Loss: 49.37631622922796736930\n",
      "Iteration 15365 => Loss: 49.37612915533684088132\n",
      "Iteration 15366 => Loss: 49.37594208291387332110\n",
      "Iteration 15367 => Loss: 49.37575501195900784523\n",
      "Iteration 15368 => Loss: 49.37556794247225866457\n",
      "Iteration 15369 => Loss: 49.37538087445365420081\n",
      "Iteration 15370 => Loss: 49.37519380790312339968\n",
      "Iteration 15371 => Loss: 49.37500674282070889376\n",
      "Iteration 15372 => Loss: 49.37481967920635383962\n",
      "Iteration 15373 => Loss: 49.37463261706007955354\n",
      "Iteration 15374 => Loss: 49.37444555638185050839\n",
      "Iteration 15375 => Loss: 49.37425849717165249331\n",
      "Iteration 15376 => Loss: 49.37407143942951393001\n",
      "Iteration 15377 => Loss: 49.37388438315535665879\n",
      "Iteration 15378 => Loss: 49.37369732834923752307\n",
      "Iteration 15379 => Loss: 49.37351027501108546858\n",
      "Iteration 15380 => Loss: 49.37332322314095023330\n",
      "Iteration 15381 => Loss: 49.37313617273876786840\n",
      "Iteration 15382 => Loss: 49.37294912380455258472\n",
      "Iteration 15383 => Loss: 49.37276207633829727683\n",
      "Iteration 15384 => Loss: 49.37257503033995931219\n",
      "Iteration 15385 => Loss: 49.37238798580956711248\n",
      "Iteration 15386 => Loss: 49.37220094274707804516\n",
      "Iteration 15387 => Loss: 49.37201390115251342650\n",
      "Iteration 15388 => Loss: 49.37182686102580930765\n",
      "Iteration 15389 => Loss: 49.37163982236700121575\n",
      "Iteration 15390 => Loss: 49.37145278517607493995\n",
      "Iteration 15391 => Loss: 49.37126574945299495312\n",
      "Iteration 15392 => Loss: 49.37107871519775414981\n",
      "Iteration 15393 => Loss: 49.37089168241038095175\n",
      "Iteration 15394 => Loss: 49.37070465109079009380\n",
      "Iteration 15395 => Loss: 49.37051762123901710311\n",
      "Iteration 15396 => Loss: 49.37033059285506197966\n",
      "Iteration 15397 => Loss: 49.37014356593888209090\n",
      "Iteration 15398 => Loss: 49.36995654049049875312\n",
      "Iteration 15399 => Loss: 49.36976951650986933373\n",
      "Iteration 15400 => Loss: 49.36958249399698672732\n",
      "Iteration 15401 => Loss: 49.36939547295187225018\n",
      "Iteration 15402 => Loss: 49.36920845337446905887\n",
      "Iteration 15403 => Loss: 49.36902143526478425883\n",
      "Iteration 15404 => Loss: 49.36883441862281074464\n",
      "Iteration 15405 => Loss: 49.36864740344854141085\n",
      "Iteration 15406 => Loss: 49.36846038974194073035\n",
      "Iteration 15407 => Loss: 49.36827337750302291397\n",
      "Iteration 15408 => Loss: 49.36808636673176664544\n",
      "Iteration 15409 => Loss: 49.36789935742817192477\n",
      "Iteration 15410 => Loss: 49.36771234959221743566\n",
      "Iteration 15411 => Loss: 49.36752534322386765098\n",
      "Iteration 15412 => Loss: 49.36733833832315099244\n",
      "Iteration 15413 => Loss: 49.36715133489004614376\n",
      "Iteration 15414 => Loss: 49.36696433292450336694\n",
      "Iteration 15415 => Loss: 49.36677733242657239998\n",
      "Iteration 15416 => Loss: 49.36659033339619639946\n",
      "Iteration 15417 => Loss: 49.36640333583338247081\n",
      "Iteration 15418 => Loss: 49.36621633973810929774\n",
      "Iteration 15419 => Loss: 49.36602934511039819654\n",
      "Iteration 15420 => Loss: 49.36584235195017811293\n",
      "Iteration 15421 => Loss: 49.36565536025748457405\n",
      "Iteration 15422 => Loss: 49.36546837003229626362\n",
      "Iteration 15423 => Loss: 49.36528138127458475992\n",
      "Iteration 15424 => Loss: 49.36509439398435006296\n",
      "Iteration 15425 => Loss: 49.36490740816158506732\n",
      "Iteration 15426 => Loss: 49.36472042380630398384\n",
      "Iteration 15427 => Loss: 49.36453344091844996910\n",
      "Iteration 15428 => Loss: 49.36434645949800881226\n",
      "Iteration 15429 => Loss: 49.36415947954499472417\n",
      "Iteration 15430 => Loss: 49.36397250105940770482\n",
      "Iteration 15431 => Loss: 49.36378552404119801622\n",
      "Iteration 15432 => Loss: 49.36359854849037276381\n",
      "Iteration 15433 => Loss: 49.36341157440695326386\n",
      "Iteration 15434 => Loss: 49.36322460179086846210\n",
      "Iteration 15435 => Loss: 49.36303763064213967482\n",
      "Iteration 15436 => Loss: 49.36285066096075269115\n",
      "Iteration 15437 => Loss: 49.36266369274669330025\n",
      "Iteration 15438 => Loss: 49.36247672599993308040\n",
      "Iteration 15439 => Loss: 49.36228976072050755874\n",
      "Iteration 15440 => Loss: 49.36210279690833147015\n",
      "Iteration 15441 => Loss: 49.36191583456349007974\n",
      "Iteration 15442 => Loss: 49.36172887368589101698\n",
      "Iteration 15443 => Loss: 49.36154191427556270355\n",
      "Iteration 15444 => Loss: 49.36135495633247671776\n",
      "Iteration 15445 => Loss: 49.36116799985662595418\n",
      "Iteration 15446 => Loss: 49.36098104484799620195\n",
      "Iteration 15447 => Loss: 49.36079409130659456650\n",
      "Iteration 15448 => Loss: 49.36060713923237130984\n",
      "Iteration 15449 => Loss: 49.36042018862538327539\n",
      "Iteration 15450 => Loss: 49.36023323948552388174\n",
      "Iteration 15451 => Loss: 49.36004629181284997230\n",
      "Iteration 15452 => Loss: 49.35985934560732601994\n",
      "Iteration 15453 => Loss: 49.35967240086893781381\n",
      "Iteration 15454 => Loss: 49.35948545759769245933\n",
      "Iteration 15455 => Loss: 49.35929851579358285107\n",
      "Iteration 15456 => Loss: 49.35911157545657346191\n",
      "Iteration 15457 => Loss: 49.35892463658664297554\n",
      "Iteration 15458 => Loss: 49.35873769918382691912\n",
      "Iteration 15459 => Loss: 49.35855076324807555466\n",
      "Iteration 15460 => Loss: 49.35836382877938888214\n",
      "Iteration 15461 => Loss: 49.35817689577774558529\n",
      "Iteration 15462 => Loss: 49.35798996424314566411\n",
      "Iteration 15463 => Loss: 49.35780303417558911860\n",
      "Iteration 15464 => Loss: 49.35761610557502621077\n",
      "Iteration 15465 => Loss: 49.35742917844147825690\n",
      "Iteration 15466 => Loss: 49.35724225277491683528\n",
      "Iteration 15467 => Loss: 49.35705532857534905133\n",
      "Iteration 15468 => Loss: 49.35686840584277490507\n",
      "Iteration 15469 => Loss: 49.35668148457711623678\n",
      "Iteration 15470 => Loss: 49.35649456477843699531\n",
      "Iteration 15471 => Loss: 49.35630764644668033725\n",
      "Iteration 15472 => Loss: 49.35612072958186047344\n",
      "Iteration 15473 => Loss: 49.35593381418392766591\n",
      "Iteration 15474 => Loss: 49.35574690025291744178\n",
      "Iteration 15475 => Loss: 49.35555998778880848477\n",
      "Iteration 15476 => Loss: 49.35537307679157947859\n",
      "Iteration 15477 => Loss: 49.35518616726119489613\n",
      "Iteration 15478 => Loss: 49.35499925919769026450\n",
      "Iteration 15479 => Loss: 49.35481235260099452944\n",
      "Iteration 15480 => Loss: 49.35462544747115742894\n",
      "Iteration 15481 => Loss: 49.35443854380815054128\n",
      "Iteration 15482 => Loss: 49.35425164161191702306\n",
      "Iteration 15483 => Loss: 49.35406474088251371768\n",
      "Iteration 15484 => Loss: 49.35387784161989088716\n",
      "Iteration 15485 => Loss: 49.35369094382406274235\n",
      "Iteration 15486 => Loss: 49.35350404749495822898\n",
      "Iteration 15487 => Loss: 49.35331715263263419047\n",
      "Iteration 15488 => Loss: 49.35313025923705509967\n",
      "Iteration 15489 => Loss: 49.35294336730819253489\n",
      "Iteration 15490 => Loss: 49.35275647684605360155\n",
      "Iteration 15491 => Loss: 49.35256958785060987793\n",
      "Iteration 15492 => Loss: 49.35238270032186136405\n",
      "Iteration 15493 => Loss: 49.35219581425980805989\n",
      "Iteration 15494 => Loss: 49.35200892966443575460\n",
      "Iteration 15495 => Loss: 49.35182204653570892106\n",
      "Iteration 15496 => Loss: 49.35163516487362755925\n",
      "Iteration 15497 => Loss: 49.35144828467819166917\n",
      "Iteration 15498 => Loss: 49.35126140594937993455\n",
      "Iteration 15499 => Loss: 49.35107452868717103911\n",
      "Iteration 15500 => Loss: 49.35088765289160050997\n",
      "Iteration 15501 => Loss: 49.35070077856259018745\n",
      "Iteration 15502 => Loss: 49.35051390570016849324\n",
      "Iteration 15503 => Loss: 49.35032703430430700564\n",
      "Iteration 15504 => Loss: 49.35014016437499861922\n",
      "Iteration 15505 => Loss: 49.34995329591225754484\n",
      "Iteration 15506 => Loss: 49.34976642891602693908\n",
      "Iteration 15507 => Loss: 49.34957956338633522364\n",
      "Iteration 15508 => Loss: 49.34939269932314687139\n",
      "Iteration 15509 => Loss: 49.34920583672646898776\n",
      "Iteration 15510 => Loss: 49.34901897559625894019\n",
      "Iteration 15511 => Loss: 49.34883211593253804494\n",
      "Iteration 15512 => Loss: 49.34864525773529209118\n",
      "Iteration 15513 => Loss: 49.34845840100447134091\n",
      "Iteration 15514 => Loss: 49.34827154574010421584\n",
      "Iteration 15515 => Loss: 49.34808469194219071596\n",
      "Iteration 15516 => Loss: 49.34789783961067399787\n",
      "Iteration 15517 => Loss: 49.34771098874556116698\n",
      "Iteration 15518 => Loss: 49.34752413934685932873\n",
      "Iteration 15519 => Loss: 49.34733729141452585054\n",
      "Iteration 15520 => Loss: 49.34715044494856073243\n",
      "Iteration 15521 => Loss: 49.34696359994897818524\n",
      "Iteration 15522 => Loss: 49.34677675641574268184\n",
      "Iteration 15523 => Loss: 49.34658991434883290594\n",
      "Iteration 15524 => Loss: 49.34640307374824885756\n",
      "Iteration 15525 => Loss: 49.34621623461398343125\n",
      "Iteration 15526 => Loss: 49.34602939694602952159\n",
      "Iteration 15527 => Loss: 49.34584256074437291772\n",
      "Iteration 15528 => Loss: 49.34565572600899230338\n",
      "Iteration 15529 => Loss: 49.34546889273986636226\n",
      "Iteration 15530 => Loss: 49.34528206093700219981\n",
      "Iteration 15531 => Loss: 49.34509523060038560516\n",
      "Iteration 15532 => Loss: 49.34490840173000947289\n",
      "Iteration 15533 => Loss: 49.34472157432585248671\n",
      "Iteration 15534 => Loss: 49.34453474838789333035\n",
      "Iteration 15535 => Loss: 49.34434792391617463636\n",
      "Iteration 15536 => Loss: 49.34416110091059692877\n",
      "Iteration 15537 => Loss: 49.34397427937121705099\n",
      "Iteration 15538 => Loss: 49.34378745929800658132\n",
      "Iteration 15539 => Loss: 49.34360064069095841432\n",
      "Iteration 15540 => Loss: 49.34341382355004412830\n",
      "Iteration 15541 => Loss: 49.34322700787524951238\n",
      "Iteration 15542 => Loss: 49.34304019366658877743\n",
      "Iteration 15543 => Loss: 49.34285338092404060717\n",
      "Iteration 15544 => Loss: 49.34266656964757657988\n",
      "Iteration 15545 => Loss: 49.34247975983720380100\n",
      "Iteration 15546 => Loss: 49.34229295149290805966\n",
      "Iteration 15547 => Loss: 49.34210614461466803959\n",
      "Iteration 15548 => Loss: 49.34191933920246952994\n",
      "Iteration 15549 => Loss: 49.34173253525631253069\n",
      "Iteration 15550 => Loss: 49.34154573277621125271\n",
      "Iteration 15551 => Loss: 49.34135893176208043087\n",
      "Iteration 15552 => Loss: 49.34117213221397690859\n",
      "Iteration 15553 => Loss: 49.34098533413187226415\n",
      "Iteration 15554 => Loss: 49.34079853751574518128\n",
      "Iteration 15555 => Loss: 49.34061174236558144912\n",
      "Iteration 15556 => Loss: 49.34042494868138106767\n",
      "Iteration 15557 => Loss: 49.34023815646314403693\n",
      "Iteration 15558 => Loss: 49.34005136571080640806\n",
      "Iteration 15559 => Loss: 49.33986457642443923532\n",
      "Iteration 15560 => Loss: 49.33967778860395014817\n",
      "Iteration 15561 => Loss: 49.33949100224935335746\n",
      "Iteration 15562 => Loss: 49.33930421736068439031\n",
      "Iteration 15563 => Loss: 49.33911743393786508705\n",
      "Iteration 15564 => Loss: 49.33893065198090255308\n",
      "Iteration 15565 => Loss: 49.33874387148983942097\n",
      "Iteration 15566 => Loss: 49.33855709246459042561\n",
      "Iteration 15567 => Loss: 49.33837031490516267240\n",
      "Iteration 15568 => Loss: 49.33818353881157037222\n",
      "Iteration 15569 => Loss: 49.33799676418379220877\n",
      "Iteration 15570 => Loss: 49.33780999102179976035\n",
      "Iteration 15571 => Loss: 49.33762321932560013238\n",
      "Iteration 15572 => Loss: 49.33743644909515779773\n",
      "Iteration 15573 => Loss: 49.33724968033050117810\n",
      "Iteration 15574 => Loss: 49.33706291303159474637\n",
      "Iteration 15575 => Loss: 49.33687614719841008082\n",
      "Iteration 15576 => Loss: 49.33668938283096849773\n",
      "Iteration 15577 => Loss: 49.33650261992923446996\n",
      "Iteration 15578 => Loss: 49.33631585849321510295\n",
      "Iteration 15579 => Loss: 49.33612909852288908041\n",
      "Iteration 15580 => Loss: 49.33594234001824219149\n",
      "Iteration 15581 => Loss: 49.33575558297926022533\n",
      "Iteration 15582 => Loss: 49.33556882740593607650\n",
      "Iteration 15583 => Loss: 49.33538207329827685044\n",
      "Iteration 15584 => Loss: 49.33519532065625412542\n",
      "Iteration 15585 => Loss: 49.33500856947983947975\n",
      "Iteration 15586 => Loss: 49.33482181976905422971\n",
      "Iteration 15587 => Loss: 49.33463507152385574273\n",
      "Iteration 15588 => Loss: 49.33444832474425822966\n",
      "Iteration 15589 => Loss: 49.33426157943023326879\n",
      "Iteration 15590 => Loss: 49.33407483558176664928\n",
      "Iteration 15591 => Loss: 49.33388809319885126570\n",
      "Iteration 15592 => Loss: 49.33370135228152264517\n",
      "Iteration 15593 => Loss: 49.33351461282971683886\n",
      "Iteration 15594 => Loss: 49.33332787484341253048\n",
      "Iteration 15595 => Loss: 49.33314113832261682546\n",
      "Iteration 15596 => Loss: 49.33295440326732261838\n",
      "Iteration 15597 => Loss: 49.33276766967750148751\n",
      "Iteration 15598 => Loss: 49.33258093755317474916\n",
      "Iteration 15599 => Loss: 49.33239420689433529787\n",
      "Iteration 15600 => Loss: 49.33220747770091918483\n",
      "Iteration 15601 => Loss: 49.33202074997294062086\n",
      "Iteration 15602 => Loss: 49.33183402371038539513\n",
      "Iteration 15603 => Loss: 49.33164729891326771849\n",
      "Iteration 15604 => Loss: 49.33146057558153074751\n",
      "Iteration 15605 => Loss: 49.33127385371521000934\n",
      "Iteration 15606 => Loss: 49.33108713331427708226\n",
      "Iteration 15607 => Loss: 49.33090041437868933372\n",
      "Iteration 15608 => Loss: 49.33071369690849650169\n",
      "Iteration 15609 => Loss: 49.33052698090363463734\n",
      "Iteration 15610 => Loss: 49.33034026636411084610\n",
      "Iteration 15611 => Loss: 49.33015355328991091710\n",
      "Iteration 15612 => Loss: 49.32996684168104906121\n",
      "Iteration 15613 => Loss: 49.32978013153746843500\n",
      "Iteration 15614 => Loss: 49.32959342285916193305\n",
      "Iteration 15615 => Loss: 49.32940671564617218792\n",
      "Iteration 15616 => Loss: 49.32922000989842103991\n",
      "Iteration 15617 => Loss: 49.32903330561592980530\n",
      "Iteration 15618 => Loss: 49.32884660279869848409\n",
      "Iteration 15619 => Loss: 49.32865990144669865458\n",
      "Iteration 15620 => Loss: 49.32847320155990900048\n",
      "Iteration 15621 => Loss: 49.32828650313835083807\n",
      "Iteration 15622 => Loss: 49.32809980618198153479\n",
      "Iteration 15623 => Loss: 49.32791311069078687979\n",
      "Iteration 15624 => Loss: 49.32772641666478108391\n",
      "Iteration 15625 => Loss: 49.32753972410392151460\n",
      "Iteration 15626 => Loss: 49.32735303300823659356\n",
      "Iteration 15627 => Loss: 49.32716634337770500451\n",
      "Iteration 15628 => Loss: 49.32697965521228411490\n",
      "Iteration 15629 => Loss: 49.32679296851198103013\n",
      "Iteration 15630 => Loss: 49.32660628327678864480\n",
      "Iteration 15631 => Loss: 49.32641959950669274804\n",
      "Iteration 15632 => Loss: 49.32623291720170044528\n",
      "Iteration 15633 => Loss: 49.32604623636174778767\n",
      "Iteration 15634 => Loss: 49.32585955698689872406\n",
      "Iteration 15635 => Loss: 49.32567287907704667305\n",
      "Iteration 15636 => Loss: 49.32548620263226979432\n",
      "Iteration 15637 => Loss: 49.32529952765251124447\n",
      "Iteration 15638 => Loss: 49.32511285413775681263\n",
      "Iteration 15639 => Loss: 49.32492618208802781510\n",
      "Iteration 15640 => Loss: 49.32473951150326740844\n",
      "Iteration 15641 => Loss: 49.32455284238351822523\n",
      "Iteration 15642 => Loss: 49.32436617472871631662\n",
      "Iteration 15643 => Loss: 49.32417950853886168261\n",
      "Iteration 15644 => Loss: 49.32399284381397563948\n",
      "Iteration 15645 => Loss: 49.32380618055400134381\n",
      "Iteration 15646 => Loss: 49.32361951875897432274\n",
      "Iteration 15647 => Loss: 49.32343285842885194370\n",
      "Iteration 15648 => Loss: 49.32324619956362710127\n",
      "Iteration 15649 => Loss: 49.32305954216331400630\n",
      "Iteration 15650 => Loss: 49.32287288622784870995\n",
      "Iteration 15651 => Loss: 49.32268623175725252850\n",
      "Iteration 15652 => Loss: 49.32249957875149704023\n",
      "Iteration 15653 => Loss: 49.32231292721061066686\n",
      "Iteration 15654 => Loss: 49.32212627713454367040\n",
      "Iteration 15655 => Loss: 49.32193962852333868341\n",
      "Iteration 15656 => Loss: 49.32175298137688201905\n",
      "Iteration 15657 => Loss: 49.32156633569524473160\n",
      "Iteration 15658 => Loss: 49.32137969147838418849\n",
      "Iteration 15659 => Loss: 49.32119304872630749514\n",
      "Iteration 15660 => Loss: 49.32100640743899333529\n",
      "Iteration 15661 => Loss: 49.32081976761642749807\n",
      "Iteration 15662 => Loss: 49.32063312925860287805\n",
      "Iteration 15663 => Loss: 49.32044649236551236982\n",
      "Iteration 15664 => Loss: 49.32025985693714176250\n",
      "Iteration 15665 => Loss: 49.32007322297346263440\n",
      "Iteration 15666 => Loss: 49.31988659047448209094\n",
      "Iteration 15667 => Loss: 49.31969995944017171041\n",
      "Iteration 15668 => Loss: 49.31951332987053859824\n",
      "Iteration 15669 => Loss: 49.31932670176557564901\n",
      "Iteration 15670 => Loss: 49.31914007512524023014\n",
      "Iteration 15671 => Loss: 49.31895344994956076334\n",
      "Iteration 15672 => Loss: 49.31876682623850882692\n",
      "Iteration 15673 => Loss: 49.31858020399206310458\n",
      "Iteration 15674 => Loss: 49.31839358321020228004\n",
      "Iteration 15675 => Loss: 49.31820696389294766959\n",
      "Iteration 15676 => Loss: 49.31802034604027795694\n",
      "Iteration 15677 => Loss: 49.31783372965217182582\n",
      "Iteration 15678 => Loss: 49.31764711472860085451\n",
      "Iteration 15679 => Loss: 49.31746050126960767557\n",
      "Iteration 15680 => Loss: 49.31727388927509991845\n",
      "Iteration 15681 => Loss: 49.31708727874514863743\n",
      "Iteration 15682 => Loss: 49.31690066967971830536\n",
      "Iteration 15683 => Loss: 49.31671406207876628969\n",
      "Iteration 15684 => Loss: 49.31652745594230680126\n",
      "Iteration 15685 => Loss: 49.31634085127031141838\n",
      "Iteration 15686 => Loss: 49.31615424806280856274\n",
      "Iteration 15687 => Loss: 49.31596764631970586379\n",
      "Iteration 15688 => Loss: 49.31578104604108858666\n",
      "Iteration 15689 => Loss: 49.31559444722686436080\n",
      "Iteration 15690 => Loss: 49.31540784987709002962\n",
      "Iteration 15691 => Loss: 49.31522125399173006599\n",
      "Iteration 15692 => Loss: 49.31503465957073473191\n",
      "Iteration 15693 => Loss: 49.31484806661415376539\n",
      "Iteration 15694 => Loss: 49.31466147512190190128\n",
      "Iteration 15695 => Loss: 49.31447488509402887757\n",
      "Iteration 15696 => Loss: 49.31428829653051337800\n",
      "Iteration 15697 => Loss: 49.31410170943133408628\n",
      "Iteration 15698 => Loss: 49.31391512379647679154\n",
      "Iteration 15699 => Loss: 49.31372853962592017751\n",
      "Iteration 15700 => Loss: 49.31354195691968556048\n",
      "Iteration 15701 => Loss: 49.31335537567774451873\n",
      "Iteration 15702 => Loss: 49.31316879590006863054\n",
      "Iteration 15703 => Loss: 49.31298221758666500136\n",
      "Iteration 15704 => Loss: 49.31279564073752652575\n",
      "Iteration 15705 => Loss: 49.31260906535262478201\n",
      "Iteration 15706 => Loss: 49.31242249143193845384\n",
      "Iteration 15707 => Loss: 49.31223591897551017382\n",
      "Iteration 15708 => Loss: 49.31204934798327599310\n",
      "Iteration 15709 => Loss: 49.31186277845526433339\n",
      "Iteration 15710 => Loss: 49.31167621039139703498\n",
      "Iteration 15711 => Loss: 49.31148964379174515216\n",
      "Iteration 15712 => Loss: 49.31130307865623052521\n",
      "Iteration 15713 => Loss: 49.31111651498486736500\n",
      "Iteration 15714 => Loss: 49.31092995277767698781\n",
      "Iteration 15715 => Loss: 49.31074339203460255021\n",
      "Iteration 15716 => Loss: 49.31055683275563694679\n",
      "Iteration 15717 => Loss: 49.31037027494078017753\n",
      "Iteration 15718 => Loss: 49.31018371859001803159\n",
      "Iteration 15719 => Loss: 49.30999716370335050897\n",
      "Iteration 15720 => Loss: 49.30981061028075629338\n",
      "Iteration 15721 => Loss: 49.30962405832222117397\n",
      "Iteration 15722 => Loss: 49.30943750782772383445\n",
      "Iteration 15723 => Loss: 49.30925095879727138026\n",
      "Iteration 15724 => Loss: 49.30906441123085670597\n",
      "Iteration 15725 => Loss: 49.30887786512844428444\n",
      "Iteration 15726 => Loss: 49.30869132049003411566\n",
      "Iteration 15727 => Loss: 49.30850477731561909422\n",
      "Iteration 15728 => Loss: 49.30831823560520632554\n",
      "Iteration 15729 => Loss: 49.30813169535873896621\n",
      "Iteration 15730 => Loss: 49.30794515657623833249\n",
      "Iteration 15731 => Loss: 49.30775861925769021354\n",
      "Iteration 15732 => Loss: 49.30757208340306618766\n",
      "Iteration 15733 => Loss: 49.30738554901237336026\n",
      "Iteration 15734 => Loss: 49.30719901608561173134\n",
      "Iteration 15735 => Loss: 49.30701248462270314121\n",
      "Iteration 15736 => Loss: 49.30682595462371153872\n",
      "Iteration 15737 => Loss: 49.30663942608858718586\n",
      "Iteration 15738 => Loss: 49.30645289901733008264\n",
      "Iteration 15739 => Loss: 49.30626637340994022907\n",
      "Iteration 15740 => Loss: 49.30607984926640341428\n",
      "Iteration 15741 => Loss: 49.30589332658666279485\n",
      "Iteration 15742 => Loss: 49.30570680537076810879\n",
      "Iteration 15743 => Loss: 49.30552028561868382894\n",
      "Iteration 15744 => Loss: 49.30533376733037442818\n",
      "Iteration 15745 => Loss: 49.30514725050586832822\n",
      "Iteration 15746 => Loss: 49.30496073514513000191\n",
      "Iteration 15747 => Loss: 49.30477422124816655469\n",
      "Iteration 15748 => Loss: 49.30458770881494245941\n",
      "Iteration 15749 => Loss: 49.30440119784545771608\n",
      "Iteration 15750 => Loss: 49.30421468833969811385\n",
      "Iteration 15751 => Loss: 49.30402818029766365271\n",
      "Iteration 15752 => Loss: 49.30384167371933301638\n",
      "Iteration 15753 => Loss: 49.30365516860469199401\n",
      "Iteration 15754 => Loss: 49.30346866495374058559\n",
      "Iteration 15755 => Loss: 49.30328216276646458027\n",
      "Iteration 15756 => Loss: 49.30309566204282845092\n",
      "Iteration 15757 => Loss: 49.30290916278286772467\n",
      "Iteration 15758 => Loss: 49.30272266498650424182\n",
      "Iteration 15759 => Loss: 49.30253616865380195122\n",
      "Iteration 15760 => Loss: 49.30234967378469690402\n",
      "Iteration 15761 => Loss: 49.30216318037918910022\n",
      "Iteration 15762 => Loss: 49.30197668843728564525\n",
      "Iteration 15763 => Loss: 49.30179019795895811740\n",
      "Iteration 15764 => Loss: 49.30160370894417809495\n",
      "Iteration 15765 => Loss: 49.30141722139296689420\n",
      "Iteration 15766 => Loss: 49.30123073530531740971\n",
      "Iteration 15767 => Loss: 49.30104425068117279807\n",
      "Iteration 15768 => Loss: 49.30085776752056858641\n",
      "Iteration 15769 => Loss: 49.30067128582346924759\n",
      "Iteration 15770 => Loss: 49.30048480558986767619\n",
      "Iteration 15771 => Loss: 49.30029832681975676678\n",
      "Iteration 15772 => Loss: 49.30011184951311520308\n",
      "Iteration 15773 => Loss: 49.29992537366995009052\n",
      "Iteration 15774 => Loss: 49.29973889929021879652\n",
      "Iteration 15775 => Loss: 49.29955242637393553196\n",
      "Iteration 15776 => Loss: 49.29936595492108608596\n",
      "Iteration 15777 => Loss: 49.29917948493166335311\n",
      "Iteration 15778 => Loss: 49.29899301640561759541\n",
      "Iteration 15779 => Loss: 49.29880654934299855086\n",
      "Iteration 15780 => Loss: 49.29862008374374227060\n",
      "Iteration 15781 => Loss: 49.29843361960787717635\n",
      "Iteration 15782 => Loss: 49.29824715693536774097\n",
      "Iteration 15783 => Loss: 49.29806069572619975361\n",
      "Iteration 15784 => Loss: 49.29787423598038031969\n",
      "Iteration 15785 => Loss: 49.29768777769788101750\n",
      "Iteration 15786 => Loss: 49.29750132087866631991\n",
      "Iteration 15787 => Loss: 49.29731486552279307034\n",
      "Iteration 15788 => Loss: 49.29712841163021863622\n",
      "Iteration 15789 => Loss: 49.29694195920087906870\n",
      "Iteration 15790 => Loss: 49.29675550823485963292\n",
      "Iteration 15791 => Loss: 49.29656905873207506374\n",
      "Iteration 15792 => Loss: 49.29638261069254667746\n",
      "Iteration 15793 => Loss: 49.29619616411623894692\n",
      "Iteration 15794 => Loss: 49.29600971900315897756\n",
      "Iteration 15795 => Loss: 49.29582327535329255852\n",
      "Iteration 15796 => Loss: 49.29563683316661837353\n",
      "Iteration 15797 => Loss: 49.29545039244312931714\n",
      "Iteration 15798 => Loss: 49.29526395318282538938\n",
      "Iteration 15799 => Loss: 49.29507751538569237937\n",
      "Iteration 15800 => Loss: 49.29489107905168765456\n",
      "Iteration 15801 => Loss: 49.29470464418086095293\n",
      "Iteration 15802 => Loss: 49.29451821077314832564\n",
      "Iteration 15803 => Loss: 49.29433177882854977270\n",
      "Iteration 15804 => Loss: 49.29414534834705108324\n",
      "Iteration 15805 => Loss: 49.29395891932867357355\n",
      "Iteration 15806 => Loss: 49.29377249177338882191\n",
      "Iteration 15807 => Loss: 49.29358606568115419577\n",
      "Iteration 15808 => Loss: 49.29339964105198390598\n",
      "Iteration 15809 => Loss: 49.29321321788587795254\n",
      "Iteration 15810 => Loss: 49.29302679618280080831\n",
      "Iteration 15811 => Loss: 49.29284037594275247329\n",
      "Iteration 15812 => Loss: 49.29265395716571163121\n",
      "Iteration 15813 => Loss: 49.29246753985167828205\n",
      "Iteration 15814 => Loss: 49.29228112400063821497\n",
      "Iteration 15815 => Loss: 49.29209470961259142996\n",
      "Iteration 15816 => Loss: 49.29190829668752371617\n",
      "Iteration 15817 => Loss: 49.29172188522537823019\n",
      "Iteration 15818 => Loss: 49.29153547522621892085\n",
      "Iteration 15819 => Loss: 49.29134906668996762846\n",
      "Iteration 15820 => Loss: 49.29116265961665988016\n",
      "Iteration 15821 => Loss: 49.29097625400625304337\n",
      "Iteration 15822 => Loss: 49.29078984985876132896\n",
      "Iteration 15823 => Loss: 49.29060344717414210436\n",
      "Iteration 15824 => Loss: 49.29041704595240958042\n",
      "Iteration 15825 => Loss: 49.29023064619353533544\n",
      "Iteration 15826 => Loss: 49.29004424789751226399\n",
      "Iteration 15827 => Loss: 49.28985785106435457692\n",
      "Iteration 15828 => Loss: 49.28967145569402674710\n",
      "Iteration 15829 => Loss: 49.28948506178651456366\n",
      "Iteration 15830 => Loss: 49.28929866934180381577\n",
      "Iteration 15831 => Loss: 49.28911227835990871426\n",
      "Iteration 15832 => Loss: 49.28892588884078662659\n",
      "Iteration 15833 => Loss: 49.28873950078444465817\n",
      "Iteration 15834 => Loss: 49.28855311419086859814\n",
      "Iteration 15835 => Loss: 49.28836672906001581396\n",
      "Iteration 15836 => Loss: 49.28818034539194314902\n",
      "Iteration 15837 => Loss: 49.28799396318657954907\n",
      "Iteration 15838 => Loss: 49.28780758244394633039\n",
      "Iteration 15839 => Loss: 49.28762120316399375497\n",
      "Iteration 15840 => Loss: 49.28743482534675734996\n",
      "Iteration 15841 => Loss: 49.28724844899222290451\n",
      "Iteration 15842 => Loss: 49.28706207410031225891\n",
      "Iteration 15843 => Loss: 49.28687570067108936200\n",
      "Iteration 15844 => Loss: 49.28668932870453289752\n",
      "Iteration 15845 => Loss: 49.28650295820059312746\n",
      "Iteration 15846 => Loss: 49.28631658915928426268\n",
      "Iteration 15847 => Loss: 49.28613022158057077604\n",
      "Iteration 15848 => Loss: 49.28594385546448108926\n",
      "Iteration 15849 => Loss: 49.28575749081099388604\n",
      "Iteration 15850 => Loss: 49.28557112762006653384\n",
      "Iteration 15851 => Loss: 49.28538476589169192721\n",
      "Iteration 15852 => Loss: 49.28519840562590559330\n",
      "Iteration 15853 => Loss: 49.28501204682264358325\n",
      "Iteration 15854 => Loss: 49.28482568948193431879\n",
      "Iteration 15855 => Loss: 49.28463933360374937820\n",
      "Iteration 15856 => Loss: 49.28445297918805323434\n",
      "Iteration 15857 => Loss: 49.28426662623488141435\n",
      "Iteration 15858 => Loss: 49.28408027474418418024\n",
      "Iteration 15859 => Loss: 49.28389392471594021572\n",
      "Iteration 15860 => Loss: 49.28370757615020636422\n",
      "Iteration 15861 => Loss: 49.28352122904689025518\n",
      "Iteration 15862 => Loss: 49.28333488340602741573\n",
      "Iteration 15863 => Loss: 49.28314853922761784588\n",
      "Iteration 15864 => Loss: 49.28296219651161180764\n",
      "Iteration 15865 => Loss: 49.28277585525799509014\n",
      "Iteration 15866 => Loss: 49.28258951546679611511\n",
      "Iteration 15867 => Loss: 49.28240317713797935539\n",
      "Iteration 15868 => Loss: 49.28221684027154481100\n",
      "Iteration 15869 => Loss: 49.28203050486744984937\n",
      "Iteration 15870 => Loss: 49.28184417092571578678\n",
      "Iteration 15871 => Loss: 49.28165783844629999066\n",
      "Iteration 15872 => Loss: 49.28147150742924509359\n",
      "Iteration 15873 => Loss: 49.28128517787449425214\n",
      "Iteration 15874 => Loss: 49.28109884978204746631\n",
      "Iteration 15875 => Loss: 49.28091252315189052524\n",
      "Iteration 15876 => Loss: 49.28072619798402342894\n",
      "Iteration 15877 => Loss: 49.28053987427841065028\n",
      "Iteration 15878 => Loss: 49.28035355203508061095\n",
      "Iteration 15879 => Loss: 49.28016723125399067840\n",
      "Iteration 15880 => Loss: 49.27998091193510532548\n",
      "Iteration 15881 => Loss: 49.27979459407848139563\n",
      "Iteration 15882 => Loss: 49.27960827768406204541\n",
      "Iteration 15883 => Loss: 49.27942196275184016940\n",
      "Iteration 15884 => Loss: 49.27923564928180155675\n",
      "Iteration 15885 => Loss: 49.27904933727396041832\n",
      "Iteration 15886 => Loss: 49.27886302672825280524\n",
      "Iteration 15887 => Loss: 49.27867671764473556095\n",
      "Iteration 15888 => Loss: 49.27849041002333763117\n",
      "Iteration 15889 => Loss: 49.27830410386408033219\n",
      "Iteration 15890 => Loss: 49.27811779916694234771\n",
      "Iteration 15891 => Loss: 49.27793149593190946689\n",
      "Iteration 15892 => Loss: 49.27774519415899590058\n",
      "Iteration 15893 => Loss: 49.27755889384814480536\n",
      "Iteration 15894 => Loss: 49.27737259499938460294\n",
      "Iteration 15895 => Loss: 49.27718629761268687162\n",
      "Iteration 15896 => Loss: 49.27700000168803029510\n",
      "Iteration 15897 => Loss: 49.27681370722542908425\n",
      "Iteration 15898 => Loss: 49.27662741422486192278\n",
      "Iteration 15899 => Loss: 49.27644112268627196727\n",
      "Iteration 15900 => Loss: 49.27625483260972316657\n",
      "Iteration 15901 => Loss: 49.27606854399515867726\n",
      "Iteration 15902 => Loss: 49.27588225684257849935\n",
      "Iteration 15903 => Loss: 49.27569597115198263282\n",
      "Iteration 15904 => Loss: 49.27550968692332133969\n",
      "Iteration 15905 => Loss: 49.27532340415663014710\n",
      "Iteration 15906 => Loss: 49.27513712285187352791\n",
      "Iteration 15907 => Loss: 49.27495084300903016583\n",
      "Iteration 15908 => Loss: 49.27476456462811427173\n",
      "Iteration 15909 => Loss: 49.27457828770909031846\n",
      "Iteration 15910 => Loss: 49.27439201225197962231\n",
      "Iteration 15911 => Loss: 49.27420573825671112900\n",
      "Iteration 15912 => Loss: 49.27401946572334168195\n",
      "Iteration 15913 => Loss: 49.27383319465183575403\n",
      "Iteration 15914 => Loss: 49.27364692504214360724\n",
      "Iteration 15915 => Loss: 49.27346065689429366330\n",
      "Iteration 15916 => Loss: 49.27327439020830013305\n",
      "Iteration 15917 => Loss: 49.27308812498409196223\n",
      "Iteration 15918 => Loss: 49.27290186122169046712\n",
      "Iteration 15919 => Loss: 49.27271559892105301515\n",
      "Iteration 15920 => Loss: 49.27252933808220092260\n",
      "Iteration 15921 => Loss: 49.27234307870512708405\n",
      "Iteration 15922 => Loss: 49.27215682078980307779\n",
      "Iteration 15923 => Loss: 49.27197056433623600924\n",
      "Iteration 15924 => Loss: 49.27178430934437614042\n",
      "Iteration 15925 => Loss: 49.27159805581425189303\n",
      "Iteration 15926 => Loss: 49.27141180374583484536\n",
      "Iteration 15927 => Loss: 49.27122555313910368113\n",
      "Iteration 15928 => Loss: 49.27103930399405129492\n",
      "Iteration 15929 => Loss: 49.27085305631068479215\n",
      "Iteration 15930 => Loss: 49.27066681008897575111\n",
      "Iteration 15931 => Loss: 49.27048056532890996095\n",
      "Iteration 15932 => Loss: 49.27029432203051584338\n",
      "Iteration 15933 => Loss: 49.27010808019370813327\n",
      "Iteration 15934 => Loss: 49.26992183981853656860\n",
      "Iteration 15935 => Loss: 49.26973560090496562225\n",
      "Iteration 15936 => Loss: 49.26954936345300239964\n",
      "Iteration 15937 => Loss: 49.26936312746259716278\n",
      "Iteration 15938 => Loss: 49.26917689293377833337\n",
      "Iteration 15939 => Loss: 49.26899065986651748972\n",
      "Iteration 15940 => Loss: 49.26880442826079331553\n",
      "Iteration 15941 => Loss: 49.26861819811660581081\n",
      "Iteration 15942 => Loss: 49.26843196943395497556\n",
      "Iteration 15943 => Loss: 49.26824574221282659892\n",
      "Iteration 15944 => Loss: 49.26805951645316383747\n",
      "Iteration 15945 => Loss: 49.26787329215502353463\n",
      "Iteration 15946 => Loss: 49.26768706931833463614\n",
      "Iteration 15947 => Loss: 49.26750084794313266912\n",
      "Iteration 15948 => Loss: 49.26731462802938210643\n",
      "Iteration 15949 => Loss: 49.26712840957706873724\n",
      "Iteration 15950 => Loss: 49.26694219258620677238\n",
      "Iteration 15951 => Loss: 49.26675597705675357929\n",
      "Iteration 15952 => Loss: 49.26656976298870205255\n",
      "Iteration 15953 => Loss: 49.26638355038205219216\n",
      "Iteration 15954 => Loss: 49.26619733923681110355\n",
      "Iteration 15955 => Loss: 49.26601112955291483786\n",
      "Iteration 15956 => Loss: 49.26582492133038471138\n",
      "Iteration 15957 => Loss: 49.26563871456922782954\n",
      "Iteration 15958 => Loss: 49.26545250926939445435\n",
      "Iteration 15959 => Loss: 49.26526630543091300751\n",
      "Iteration 15960 => Loss: 49.26508010305371954018\n",
      "Iteration 15961 => Loss: 49.26489390213783536865\n",
      "Iteration 15962 => Loss: 49.26470770268327470376\n",
      "Iteration 15963 => Loss: 49.26452150468996649124\n",
      "Iteration 15964 => Loss: 49.26433530815794625823\n",
      "Iteration 15965 => Loss: 49.26414911308719268845\n",
      "Iteration 15966 => Loss: 49.26396291947767025476\n",
      "Iteration 15967 => Loss: 49.26377672732939316802\n",
      "Iteration 15968 => Loss: 49.26359053664233300651\n",
      "Iteration 15969 => Loss: 49.26340434741649687567\n",
      "Iteration 15970 => Loss: 49.26321815965187056463\n",
      "Iteration 15971 => Loss: 49.26303197334844696798\n",
      "Iteration 15972 => Loss: 49.26284578850616213685\n",
      "Iteration 15973 => Loss: 49.26265960512508712554\n",
      "Iteration 15974 => Loss: 49.26247342320514377434\n",
      "Iteration 15975 => Loss: 49.26228724274636761038\n",
      "Iteration 15976 => Loss: 49.26210106374870889567\n",
      "Iteration 15977 => Loss: 49.26191488621218894650\n",
      "Iteration 15978 => Loss: 49.26172871013675802487\n",
      "Iteration 15979 => Loss: 49.26154253552244455250\n",
      "Iteration 15980 => Loss: 49.26135636236922010767\n",
      "Iteration 15981 => Loss: 49.26117019067706337410\n",
      "Iteration 15982 => Loss: 49.26098402044598145721\n",
      "Iteration 15983 => Loss: 49.26079785167593882989\n",
      "Iteration 15984 => Loss: 49.26061168436693549211\n",
      "Iteration 15985 => Loss: 49.26042551851897854931\n",
      "Iteration 15986 => Loss: 49.26023935413206089606\n",
      "Iteration 15987 => Loss: 49.26005319120612568895\n",
      "Iteration 15988 => Loss: 49.25986702974118003340\n",
      "Iteration 15989 => Loss: 49.25968086973722392941\n",
      "Iteration 15990 => Loss: 49.25949471119426448240\n",
      "Iteration 15991 => Loss: 49.25930855411225195439\n",
      "Iteration 15992 => Loss: 49.25912239849118634538\n",
      "Iteration 15993 => Loss: 49.25893624433106054994\n",
      "Iteration 15994 => Loss: 49.25875009163187456807\n",
      "Iteration 15995 => Loss: 49.25856394039359287262\n",
      "Iteration 15996 => Loss: 49.25837779061622967447\n",
      "Iteration 15997 => Loss: 49.25819164229973523561\n",
      "Iteration 15998 => Loss: 49.25800549544415929404\n",
      "Iteration 15999 => Loss: 49.25781935004941658462\n",
      "Iteration 16000 => Loss: 49.25763320611555684536\n",
      "Iteration 16001 => Loss: 49.25744706364255165454\n",
      "Iteration 16002 => Loss: 49.25726092263035127417\n",
      "Iteration 16003 => Loss: 49.25707478307897702052\n",
      "Iteration 16004 => Loss: 49.25688864498845731532\n",
      "Iteration 16005 => Loss: 49.25670250835872110429\n",
      "Iteration 16006 => Loss: 49.25651637318975417656\n",
      "Iteration 16007 => Loss: 49.25633023948157784844\n",
      "Iteration 16008 => Loss: 49.25614410723417080362\n",
      "Iteration 16009 => Loss: 49.25595797644752593669\n",
      "Iteration 16010 => Loss: 49.25577184712161482594\n",
      "Iteration 16011 => Loss: 49.25558571925645168221\n",
      "Iteration 16012 => Loss: 49.25539959285200808381\n",
      "Iteration 16013 => Loss: 49.25521346790824850359\n",
      "Iteration 16014 => Loss: 49.25502734442522978497\n",
      "Iteration 16015 => Loss: 49.25484122240286666283\n",
      "Iteration 16016 => Loss: 49.25465510184119466430\n",
      "Iteration 16017 => Loss: 49.25446898274018536767\n",
      "Iteration 16018 => Loss: 49.25428286509981745667\n",
      "Iteration 16019 => Loss: 49.25409674892008382585\n",
      "Iteration 16020 => Loss: 49.25391063420098447523\n",
      "Iteration 16021 => Loss: 49.25372452094254072108\n",
      "Iteration 16022 => Loss: 49.25353840914467440371\n",
      "Iteration 16023 => Loss: 49.25335229880739973396\n",
      "Iteration 16024 => Loss: 49.25316618993070960641\n",
      "Iteration 16025 => Loss: 49.25298008251460402107\n",
      "Iteration 16026 => Loss: 49.25279397655906166165\n",
      "Iteration 16027 => Loss: 49.25260787206405410643\n",
      "Iteration 16028 => Loss: 49.25242176902960267171\n",
      "Iteration 16029 => Loss: 49.25223566745565051406\n",
      "Iteration 16030 => Loss: 49.25204956734224026604\n",
      "Iteration 16031 => Loss: 49.25186346868932218968\n",
      "Iteration 16032 => Loss: 49.25167737149689628495\n",
      "Iteration 16033 => Loss: 49.25149127576496965730\n",
      "Iteration 16034 => Loss: 49.25130518149348546331\n",
      "Iteration 16035 => Loss: 49.25111908868246501925\n",
      "Iteration 16036 => Loss: 49.25093299733189411427\n",
      "Iteration 16037 => Loss: 49.25074690744175143209\n",
      "Iteration 16038 => Loss: 49.25056081901205828899\n",
      "Iteration 16039 => Loss: 49.25037473204276494698\n",
      "Iteration 16040 => Loss: 49.25018864653385008978\n",
      "Iteration 16041 => Loss: 49.25000256248535634995\n",
      "Iteration 16042 => Loss: 49.24981647989721267322\n",
      "Iteration 16043 => Loss: 49.24963039876945458673\n",
      "Iteration 16044 => Loss: 49.24944431910205366876\n",
      "Iteration 16045 => Loss: 49.24925824089499570846\n",
      "Iteration 16046 => Loss: 49.24907216414825938955\n",
      "Iteration 16047 => Loss: 49.24888608886183760660\n",
      "Iteration 16048 => Loss: 49.24870001503573746504\n",
      "Iteration 16049 => Loss: 49.24851394266993054316\n",
      "Iteration 16050 => Loss: 49.24832787176441684096\n",
      "Iteration 16051 => Loss: 49.24814180231916793673\n",
      "Iteration 16052 => Loss: 49.24795573433417672504\n",
      "Iteration 16053 => Loss: 49.24776966780944320590\n",
      "Iteration 16054 => Loss: 49.24758360274496737929\n",
      "Iteration 16055 => Loss: 49.24739753914069240182\n",
      "Iteration 16056 => Loss: 49.24721147699666090602\n",
      "Iteration 16057 => Loss: 49.24702541631280894308\n",
      "Iteration 16058 => Loss: 49.24683935708917204011\n",
      "Iteration 16059 => Loss: 49.24665329932571466998\n",
      "Iteration 16060 => Loss: 49.24646724302241551641\n",
      "Iteration 16061 => Loss: 49.24628118817928879025\n",
      "Iteration 16062 => Loss: 49.24609513479632738608\n",
      "Iteration 16063 => Loss: 49.24590908287347446048\n",
      "Iteration 16064 => Loss: 49.24572303241075132973\n",
      "Iteration 16065 => Loss: 49.24553698340814378298\n",
      "Iteration 16066 => Loss: 49.24535093586565892565\n",
      "Iteration 16067 => Loss: 49.24516488978324701975\n",
      "Iteration 16068 => Loss: 49.24497884516090806528\n",
      "Iteration 16069 => Loss: 49.24479280199866337853\n",
      "Iteration 16070 => Loss: 49.24460676029644901064\n",
      "Iteration 16071 => Loss: 49.24442072005429338333\n",
      "Iteration 16072 => Loss: 49.24423468127215386403\n",
      "Iteration 16073 => Loss: 49.24404864395008729616\n",
      "Iteration 16074 => Loss: 49.24386260808797999289\n",
      "Iteration 16075 => Loss: 49.24367657368590300848\n",
      "Iteration 16076 => Loss: 49.24349054074378528867\n",
      "Iteration 16077 => Loss: 49.24330450926166236059\n",
      "Iteration 16078 => Loss: 49.24311847923950580252\n",
      "Iteration 16079 => Loss: 49.24293245067729429820\n",
      "Iteration 16080 => Loss: 49.24274642357502074219\n",
      "Iteration 16081 => Loss: 49.24256039793270645077\n",
      "Iteration 16082 => Loss: 49.24237437375028747510\n",
      "Iteration 16083 => Loss: 49.24218835102777802604\n",
      "Iteration 16084 => Loss: 49.24200232976514968186\n",
      "Iteration 16085 => Loss: 49.24181630996244507514\n",
      "Iteration 16086 => Loss: 49.24163029161957894075\n",
      "Iteration 16087 => Loss: 49.24144427473660101668\n",
      "Iteration 16088 => Loss: 49.24125825931345445952\n",
      "Iteration 16089 => Loss: 49.24107224535016769096\n",
      "Iteration 16090 => Loss: 49.24088623284668386759\n",
      "Iteration 16091 => Loss: 49.24070022180303141113\n",
      "Iteration 16092 => Loss: 49.24051421221918900528\n",
      "Iteration 16093 => Loss: 49.24032820409512822835\n",
      "Iteration 16094 => Loss: 49.24014219743084908032\n",
      "Iteration 16095 => Loss: 49.23995619222635156120\n",
      "Iteration 16096 => Loss: 49.23977018848161435471\n",
      "Iteration 16097 => Loss: 49.23958418619661614457\n",
      "Iteration 16098 => Loss: 49.23939818537134271992\n",
      "Iteration 16099 => Loss: 49.23921218600580829161\n",
      "Iteration 16100 => Loss: 49.23902618809997733251\n",
      "Iteration 16101 => Loss: 49.23884019165385694805\n",
      "Iteration 16102 => Loss: 49.23865419666742582194\n",
      "Iteration 16103 => Loss: 49.23846820314067684876\n",
      "Iteration 16104 => Loss: 49.23828221107358160680\n",
      "Iteration 16105 => Loss: 49.23809622046616141233\n",
      "Iteration 16106 => Loss: 49.23791023131835942195\n",
      "Iteration 16107 => Loss: 49.23772424363021826821\n",
      "Iteration 16108 => Loss: 49.23753825740168821312\n",
      "Iteration 16109 => Loss: 49.23735227263276215126\n",
      "Iteration 16110 => Loss: 49.23716628932344718805\n",
      "Iteration 16111 => Loss: 49.23698030747371490179\n",
      "Iteration 16112 => Loss: 49.23679432708355108161\n",
      "Iteration 16113 => Loss: 49.23660834815294862210\n",
      "Iteration 16114 => Loss: 49.23642237068192173410\n",
      "Iteration 16115 => Loss: 49.23623639467043489049\n",
      "Iteration 16116 => Loss: 49.23605042011845966954\n",
      "Iteration 16117 => Loss: 49.23586444702599607126\n",
      "Iteration 16118 => Loss: 49.23567847539305830651\n",
      "Iteration 16119 => Loss: 49.23549250521958953186\n",
      "Iteration 16120 => Loss: 49.23530653650564659074\n",
      "Iteration 16121 => Loss: 49.23512056925115842887\n",
      "Iteration 16122 => Loss: 49.23493460345613215168\n",
      "Iteration 16123 => Loss: 49.23474863912053933745\n",
      "Iteration 16124 => Loss: 49.23456267624440840791\n",
      "Iteration 16125 => Loss: 49.23437671482768962505\n",
      "Iteration 16126 => Loss: 49.23419075487036167260\n",
      "Iteration 16127 => Loss: 49.23400479637248139397\n",
      "Iteration 16128 => Loss: 49.23381883933397062947\n",
      "Iteration 16129 => Loss: 49.23363288375485780080\n",
      "Iteration 16130 => Loss: 49.23344692963507895911\n",
      "Iteration 16131 => Loss: 49.23326097697471226411\n",
      "Iteration 16132 => Loss: 49.23307502577365113439\n",
      "Iteration 16133 => Loss: 49.23288907603195241336\n",
      "Iteration 16134 => Loss: 49.23270312774954504675\n",
      "Iteration 16135 => Loss: 49.23251718092646456171\n",
      "Iteration 16136 => Loss: 49.23233123556270385279\n",
      "Iteration 16137 => Loss: 49.23214529165821318202\n",
      "Iteration 16138 => Loss: 49.23195934921301386566\n",
      "Iteration 16139 => Loss: 49.23177340822705616574\n",
      "Iteration 16140 => Loss: 49.23158746870036850396\n",
      "Iteration 16141 => Loss: 49.23140153063290824775\n",
      "Iteration 16142 => Loss: 49.23121559402471092426\n",
      "Iteration 16143 => Loss: 49.23102965887572679549\n",
      "Iteration 16144 => Loss: 49.23084372518593454515\n",
      "Iteration 16145 => Loss: 49.23065779295536259497\n",
      "Iteration 16146 => Loss: 49.23047186218395410151\n",
      "Iteration 16147 => Loss: 49.23028593287174459192\n",
      "Iteration 16148 => Loss: 49.23010000501869143363\n",
      "Iteration 16149 => Loss: 49.22991407862475909951\n",
      "Iteration 16150 => Loss: 49.22972815369001153840\n",
      "Iteration 16151 => Loss: 49.22954223021435637975\n",
      "Iteration 16152 => Loss: 49.22935630819784336154\n",
      "Iteration 16153 => Loss: 49.22917038764044406207\n",
      "Iteration 16154 => Loss: 49.22898446854210874335\n",
      "Iteration 16155 => Loss: 49.22879855090286582708\n",
      "Iteration 16156 => Loss: 49.22861263472271531327\n",
      "Iteration 16157 => Loss: 49.22842672000160746393\n",
      "Iteration 16158 => Loss: 49.22824080673955648990\n",
      "Iteration 16159 => Loss: 49.22805489493653396949\n",
      "Iteration 16160 => Loss: 49.22786898459252569182\n",
      "Iteration 16161 => Loss: 49.22768307570758139491\n",
      "Iteration 16162 => Loss: 49.22749716828160160276\n",
      "Iteration 16163 => Loss: 49.22731126231462184251\n",
      "Iteration 16164 => Loss: 49.22712535780662079787\n",
      "Iteration 16165 => Loss: 49.22693945475759136343\n",
      "Iteration 16166 => Loss: 49.22675355316749801204\n",
      "Iteration 16167 => Loss: 49.22656765303638337627\n",
      "Iteration 16168 => Loss: 49.22638175436418350728\n",
      "Iteration 16169 => Loss: 49.22619585715090551048\n",
      "Iteration 16170 => Loss: 49.22600996139655649131\n",
      "Iteration 16171 => Loss: 49.22582406710109381720\n",
      "Iteration 16172 => Loss: 49.22563817426451748815\n",
      "Iteration 16173 => Loss: 49.22545228288681329332\n",
      "Iteration 16174 => Loss: 49.22526639296800254897\n",
      "Iteration 16175 => Loss: 49.22508050450800709541\n",
      "Iteration 16176 => Loss: 49.22489461750688377606\n",
      "Iteration 16177 => Loss: 49.22470873196456864207\n",
      "Iteration 16178 => Loss: 49.22452284788110432601\n",
      "Iteration 16179 => Loss: 49.22433696525642687902\n",
      "Iteration 16180 => Loss: 49.22415108409055761740\n",
      "Iteration 16181 => Loss: 49.22396520438346811943\n",
      "Iteration 16182 => Loss: 49.22377932613515838511\n",
      "Iteration 16183 => Loss: 49.22359344934560709817\n",
      "Iteration 16184 => Loss: 49.22340757401479294231\n",
      "Iteration 16185 => Loss: 49.22322170014274433925\n",
      "Iteration 16186 => Loss: 49.22303582772941865642\n",
      "Iteration 16187 => Loss: 49.22284995677478747211\n",
      "Iteration 16188 => Loss: 49.22266408727887920804\n",
      "Iteration 16189 => Loss: 49.22247821924165833707\n",
      "Iteration 16190 => Loss: 49.22229235266311775376\n",
      "Iteration 16191 => Loss: 49.22210648754325745813\n",
      "Iteration 16192 => Loss: 49.22192062388204902845\n",
      "Iteration 16193 => Loss: 49.22173476167951378102\n",
      "Iteration 16194 => Loss: 49.22154890093557355613\n",
      "Iteration 16195 => Loss: 49.22136304165029230262\n",
      "Iteration 16196 => Loss: 49.22117718382361317708\n",
      "Iteration 16197 => Loss: 49.22099132745553617951\n",
      "Iteration 16198 => Loss: 49.22080547254605420449\n",
      "Iteration 16199 => Loss: 49.22061961909514593572\n",
      "Iteration 16200 => Loss: 49.22043376710280426778\n",
      "Iteration 16201 => Loss: 49.22024791656900788439\n",
      "Iteration 16202 => Loss: 49.22006206749378520726\n",
      "Iteration 16203 => Loss: 49.21987621987707228755\n",
      "Iteration 16204 => Loss: 49.21969037371889754695\n",
      "Iteration 16205 => Loss: 49.21950452901923256377\n",
      "Iteration 16206 => Loss: 49.21931868577806312715\n",
      "Iteration 16207 => Loss: 49.21913284399538923708\n",
      "Iteration 16208 => Loss: 49.21894700367117536643\n",
      "Iteration 16209 => Loss: 49.21876116480542862064\n",
      "Iteration 16210 => Loss: 49.21857532739814899969\n",
      "Iteration 16211 => Loss: 49.21838949144931518731\n",
      "Iteration 16212 => Loss: 49.21820365695889165636\n",
      "Iteration 16213 => Loss: 49.21801782392691393397\n",
      "Iteration 16214 => Loss: 49.21783199235331807131\n",
      "Iteration 16215 => Loss: 49.21764616223811117379\n",
      "Iteration 16216 => Loss: 49.21746033358131455770\n",
      "Iteration 16217 => Loss: 49.21727450638289269591\n",
      "Iteration 16218 => Loss: 49.21708868064281006127\n",
      "Iteration 16219 => Loss: 49.21690285636109507550\n",
      "Iteration 16220 => Loss: 49.21671703353771221146\n",
      "Iteration 16221 => Loss: 49.21653121217266146914\n",
      "Iteration 16222 => Loss: 49.21634539226592153227\n",
      "Iteration 16223 => Loss: 49.21615957381749950628\n",
      "Iteration 16224 => Loss: 49.21597375682736696945\n",
      "Iteration 16225 => Loss: 49.21578794129549550007\n",
      "Iteration 16226 => Loss: 49.21560212722190641443\n",
      "Iteration 16227 => Loss: 49.21541631460657839625\n",
      "Iteration 16228 => Loss: 49.21523050344951855095\n",
      "Iteration 16229 => Loss: 49.21504469375067714054\n",
      "Iteration 16230 => Loss: 49.21485888551003995417\n",
      "Iteration 16231 => Loss: 49.21467307872763541354\n",
      "Iteration 16232 => Loss: 49.21448727340344220238\n",
      "Iteration 16233 => Loss: 49.21430146953742479354\n",
      "Iteration 16234 => Loss: 49.21411566712960450332\n",
      "Iteration 16235 => Loss: 49.21392986617992448828\n",
      "Iteration 16236 => Loss: 49.21374406668842027557\n",
      "Iteration 16237 => Loss: 49.21355826865504923262\n",
      "Iteration 16238 => Loss: 49.21337247207983267572\n",
      "Iteration 16239 => Loss: 49.21318667696270665601\n",
      "Iteration 16240 => Loss: 49.21300088330371380607\n",
      "Iteration 16241 => Loss: 49.21281509110281149333\n",
      "Iteration 16242 => Loss: 49.21262930035999261236\n",
      "Iteration 16243 => Loss: 49.21244351107525716316\n",
      "Iteration 16244 => Loss: 49.21225772324858382945\n",
      "Iteration 16245 => Loss: 49.21207193687997971665\n",
      "Iteration 16246 => Loss: 49.21188615196937377050\n",
      "Iteration 16247 => Loss: 49.21170036851684415069\n",
      "Iteration 16248 => Loss: 49.21151458652231980295\n",
      "Iteration 16249 => Loss: 49.21132880598580783271\n",
      "Iteration 16250 => Loss: 49.21114302690726560741\n",
      "Iteration 16251 => Loss: 49.21095724928671444331\n",
      "Iteration 16252 => Loss: 49.21077147312414723501\n",
      "Iteration 16253 => Loss: 49.21058569841952845536\n",
      "Iteration 16254 => Loss: 49.21039992517287942064\n",
      "Iteration 16255 => Loss: 49.21021415338415039287\n",
      "Iteration 16256 => Loss: 49.21002838305337689917\n",
      "Iteration 16257 => Loss: 49.20984261418050209613\n",
      "Iteration 16258 => Loss: 49.20965684676553308918\n",
      "Iteration 16259 => Loss: 49.20947108080845566747\n",
      "Iteration 16260 => Loss: 49.20928531630925562013\n",
      "Iteration 16261 => Loss: 49.20909955326793294716\n",
      "Iteration 16262 => Loss: 49.20891379168445922687\n",
      "Iteration 16263 => Loss: 49.20872803155882735382\n",
      "Iteration 16264 => Loss: 49.20854227289105864429\n",
      "Iteration 16265 => Loss: 49.20835651568108204401\n",
      "Iteration 16266 => Loss: 49.20817075992894018555\n",
      "Iteration 16267 => Loss: 49.20798500563459754176\n",
      "Iteration 16268 => Loss: 49.20779925279803279636\n",
      "Iteration 16269 => Loss: 49.20761350141924594936\n",
      "Iteration 16270 => Loss: 49.20742775149825121161\n",
      "Iteration 16271 => Loss: 49.20724200303498463427\n",
      "Iteration 16272 => Loss: 49.20705625602949595532\n",
      "Iteration 16273 => Loss: 49.20687051048169990963\n",
      "Iteration 16274 => Loss: 49.20668476639162491892\n",
      "Iteration 16275 => Loss: 49.20649902375929229947\n",
      "Iteration 16276 => Loss: 49.20631328258463810243\n",
      "Iteration 16277 => Loss: 49.20612754286767653866\n",
      "Iteration 16278 => Loss: 49.20594180460838629187\n",
      "Iteration 16279 => Loss: 49.20575606780676736207\n",
      "Iteration 16280 => Loss: 49.20557033246279843297\n",
      "Iteration 16281 => Loss: 49.20538459857647239915\n",
      "Iteration 16282 => Loss: 49.20519886614776083889\n",
      "Iteration 16283 => Loss: 49.20501313517668506847\n",
      "Iteration 16284 => Loss: 49.20482740566322377163\n",
      "Iteration 16285 => Loss: 49.20464167760732010493\n",
      "Iteration 16286 => Loss: 49.20445595100903091179\n",
      "Iteration 16287 => Loss: 49.20427022586832066509\n",
      "Iteration 16288 => Loss: 49.20408450218516094310\n",
      "Iteration 16289 => Loss: 49.20389877995952332412\n",
      "Iteration 16290 => Loss: 49.20371305919145754615\n",
      "Iteration 16291 => Loss: 49.20352733988092097661\n",
      "Iteration 16292 => Loss: 49.20334162202788519380\n",
      "Iteration 16293 => Loss: 49.20315590563235019772\n",
      "Iteration 16294 => Loss: 49.20297019069431598837\n",
      "Iteration 16295 => Loss: 49.20278447721376124946\n",
      "Iteration 16296 => Loss: 49.20259876519068598100\n",
      "Iteration 16297 => Loss: 49.20241305462506176127\n",
      "Iteration 16298 => Loss: 49.20222734551686727400\n",
      "Iteration 16299 => Loss: 49.20204163786613094089\n",
      "Iteration 16300 => Loss: 49.20185593167281723481\n",
      "Iteration 16301 => Loss: 49.20167022693690483948\n",
      "Iteration 16302 => Loss: 49.20148452365838664946\n",
      "Iteration 16303 => Loss: 49.20129882183728398104\n",
      "Iteration 16304 => Loss: 49.20111312147354709623\n",
      "Iteration 16305 => Loss: 49.20092742256716888960\n",
      "Iteration 16306 => Loss: 49.20074172511814936115\n",
      "Iteration 16307 => Loss: 49.20055602912647430003\n",
      "Iteration 16308 => Loss: 49.20037033459212949538\n",
      "Iteration 16309 => Loss: 49.20018464151511494720\n",
      "Iteration 16310 => Loss: 49.19999894989540223378\n",
      "Iteration 16311 => Loss: 49.19981325973299135512\n",
      "Iteration 16312 => Loss: 49.19962757102786810037\n",
      "Iteration 16313 => Loss: 49.19944188378001825868\n",
      "Iteration 16314 => Loss: 49.19925619798943472460\n",
      "Iteration 16315 => Loss: 49.19907051365611749816\n",
      "Iteration 16316 => Loss: 49.19888483078000973592\n",
      "Iteration 16317 => Loss: 49.19869914936113985959\n",
      "Iteration 16318 => Loss: 49.19851346939947944747\n",
      "Iteration 16319 => Loss: 49.19832779089505692127\n",
      "Iteration 16320 => Loss: 49.19814211384780833214\n",
      "Iteration 16321 => Loss: 49.19795643825774078550\n",
      "Iteration 16322 => Loss: 49.19777076412484717594\n",
      "Iteration 16323 => Loss: 49.19758509144912750344\n",
      "Iteration 16324 => Loss: 49.19739942023054624087\n",
      "Iteration 16325 => Loss: 49.19721375046910338824\n",
      "Iteration 16326 => Loss: 49.19702808216478473469\n",
      "Iteration 16327 => Loss: 49.19684241531758317478\n",
      "Iteration 16328 => Loss: 49.19665674992749160310\n",
      "Iteration 16329 => Loss: 49.19647108599450291422\n",
      "Iteration 16330 => Loss: 49.19628542351856737014\n",
      "Iteration 16331 => Loss: 49.19609976249974181428\n",
      "Iteration 16332 => Loss: 49.19591410293791966524\n",
      "Iteration 16333 => Loss: 49.19572844483316487185\n",
      "Iteration 16334 => Loss: 49.19554278818546322327\n",
      "Iteration 16335 => Loss: 49.19535713299477919236\n",
      "Iteration 16336 => Loss: 49.19517147926107725198\n",
      "Iteration 16337 => Loss: 49.19498582698441424554\n",
      "Iteration 16338 => Loss: 49.19480017616472622421\n",
      "Iteration 16339 => Loss: 49.19461452680201318799\n",
      "Iteration 16340 => Loss: 49.19442887889628224229\n",
      "Iteration 16341 => Loss: 49.19424323244749075457\n",
      "Iteration 16342 => Loss: 49.19405758745563161938\n",
      "Iteration 16343 => Loss: 49.19387194392073325844\n",
      "Iteration 16344 => Loss: 49.19368630184273172290\n",
      "Iteration 16345 => Loss: 49.19350066122164832905\n",
      "Iteration 16346 => Loss: 49.19331502205746886602\n",
      "Iteration 16347 => Loss: 49.19312938435014359584\n",
      "Iteration 16348 => Loss: 49.19294374809975067819\n",
      "Iteration 16349 => Loss: 49.19275811330618353168\n",
      "Iteration 16350 => Loss: 49.19257247996947057800\n",
      "Iteration 16351 => Loss: 49.19238684808959760630\n",
      "Iteration 16352 => Loss: 49.19220121766655040574\n",
      "Iteration 16353 => Loss: 49.19201558870033608173\n",
      "Iteration 16354 => Loss: 49.19182996119090489628\n",
      "Iteration 16355 => Loss: 49.19164433513829948197\n",
      "Iteration 16356 => Loss: 49.19145871054247010079\n",
      "Iteration 16357 => Loss: 49.19127308740341675275\n",
      "Iteration 16358 => Loss: 49.19108746572110391071\n",
      "Iteration 16359 => Loss: 49.19090184549555999638\n",
      "Iteration 16360 => Loss: 49.19071622672672106091\n",
      "Iteration 16361 => Loss: 49.19053060941464394773\n",
      "Iteration 16362 => Loss: 49.19034499355927891884\n",
      "Iteration 16363 => Loss: 49.19015937916056913082\n",
      "Iteration 16364 => Loss: 49.18997376621859984880\n",
      "Iteration 16365 => Loss: 49.18978815473330712393\n",
      "Iteration 16366 => Loss: 49.18960254470468385080\n",
      "Iteration 16367 => Loss: 49.18941693613269450225\n",
      "Iteration 16368 => Loss: 49.18923132901738171086\n",
      "Iteration 16369 => Loss: 49.18904572335868863320\n",
      "Iteration 16370 => Loss: 49.18886011915662237470\n",
      "Iteration 16371 => Loss: 49.18867451641116161909\n",
      "Iteration 16372 => Loss: 49.18848891512230636636\n",
      "Iteration 16373 => Loss: 49.18830331529004951108\n",
      "Iteration 16374 => Loss: 49.18811771691436263154\n",
      "Iteration 16375 => Loss: 49.18793211999523151690\n",
      "Iteration 16376 => Loss: 49.18774652453266327257\n",
      "Iteration 16377 => Loss: 49.18756093052662947684\n",
      "Iteration 16378 => Loss: 49.18737533797715144601\n",
      "Iteration 16379 => Loss: 49.18718974688417944208\n",
      "Iteration 16380 => Loss: 49.18700415724771346504\n",
      "Iteration 16381 => Loss: 49.18681856906775351490\n",
      "Iteration 16382 => Loss: 49.18663298234427116995\n",
      "Iteration 16383 => Loss: 49.18644739707728064104\n",
      "Iteration 16384 => Loss: 49.18626181326673219019\n",
      "Iteration 16385 => Loss: 49.18607623091264713366\n",
      "Iteration 16386 => Loss: 49.18589065001498994434\n",
      "Iteration 16387 => Loss: 49.18570507057377483306\n",
      "Iteration 16388 => Loss: 49.18551949258896627271\n",
      "Iteration 16389 => Loss: 49.18533391606057847412\n",
      "Iteration 16390 => Loss: 49.18514834098856169931\n",
      "Iteration 16391 => Loss: 49.18496276737297989712\n",
      "Iteration 16392 => Loss: 49.18477719521371938072\n",
      "Iteration 16393 => Loss: 49.18459162451083699352\n",
      "Iteration 16394 => Loss: 49.18440605526429720840\n",
      "Iteration 16395 => Loss: 49.18422048747410713077\n",
      "Iteration 16396 => Loss: 49.18403492114023123349\n",
      "Iteration 16397 => Loss: 49.18384935626266951658\n",
      "Iteration 16398 => Loss: 49.18366379284143619088\n",
      "Iteration 16399 => Loss: 49.18347823087646730755\n",
      "Iteration 16400 => Loss: 49.18329267036779839373\n",
      "Iteration 16401 => Loss: 49.18310711131535839513\n",
      "Iteration 16402 => Loss: 49.18292155371921126061\n",
      "Iteration 16403 => Loss: 49.18273599757930014675\n",
      "Iteration 16404 => Loss: 49.18255044289560373727\n",
      "Iteration 16405 => Loss: 49.18236488966819308644\n",
      "Iteration 16406 => Loss: 49.18217933789694029656\n",
      "Iteration 16407 => Loss: 49.18199378758190931649\n",
      "Iteration 16408 => Loss: 49.18180823872304330280\n",
      "Iteration 16409 => Loss: 49.18162269132040620434\n",
      "Iteration 16410 => Loss: 49.18143714537389143970\n",
      "Iteration 16411 => Loss: 49.18125160088352743060\n",
      "Iteration 16412 => Loss: 49.18106605784934259873\n",
      "Iteration 16413 => Loss: 49.18088051627125878440\n",
      "Iteration 16414 => Loss: 49.18069497614931151475\n",
      "Iteration 16415 => Loss: 49.18050943748346526263\n",
      "Iteration 16416 => Loss: 49.18032390027372002805\n",
      "Iteration 16417 => Loss: 49.18013836452006160016\n",
      "Iteration 16418 => Loss: 49.17995283022245445181\n",
      "Iteration 16419 => Loss: 49.17976729738095542643\n",
      "Iteration 16420 => Loss: 49.17958176599547925889\n",
      "Iteration 16421 => Loss: 49.17939623606604726547\n",
      "Iteration 16422 => Loss: 49.17921070759263812988\n",
      "Iteration 16423 => Loss: 49.17902518057525895756\n",
      "Iteration 16424 => Loss: 49.17883965501390264308\n",
      "Iteration 16425 => Loss: 49.17865413090850523758\n",
      "Iteration 16426 => Loss: 49.17846860825910937365\n",
      "Iteration 16427 => Loss: 49.17828308706570084041\n",
      "Iteration 16428 => Loss: 49.17809756732820858360\n",
      "Iteration 16429 => Loss: 49.17791204904671076292\n",
      "Iteration 16430 => Loss: 49.17772653222111500781\n",
      "Iteration 16431 => Loss: 49.17754101685147816170\n",
      "Iteration 16432 => Loss: 49.17735550293772917030\n",
      "Iteration 16433 => Loss: 49.17716999047991066618\n",
      "Iteration 16434 => Loss: 49.17698447947795159507\n",
      "Iteration 16435 => Loss: 49.17679896993189458954\n",
      "Iteration 16436 => Loss: 49.17661346184169701701\n",
      "Iteration 16437 => Loss: 49.17642795520735887749\n",
      "Iteration 16438 => Loss: 49.17624245002886596012\n",
      "Iteration 16439 => Loss: 49.17605694630623958119\n",
      "Iteration 16440 => Loss: 49.17587144403940158099\n",
      "Iteration 16441 => Loss: 49.17568594322838038124\n",
      "Iteration 16442 => Loss: 49.17550044387316887651\n",
      "Iteration 16443 => Loss: 49.17531494597371022337\n",
      "Iteration 16444 => Loss: 49.17512944953008258153\n",
      "Iteration 16445 => Loss: 49.17494395454220068586\n",
      "Iteration 16446 => Loss: 49.17475846101007164179\n",
      "Iteration 16447 => Loss: 49.17457296893365992219\n",
      "Iteration 16448 => Loss: 49.17438747831302237046\n",
      "Iteration 16449 => Loss: 49.17420198914810214319\n",
      "Iteration 16450 => Loss: 49.17401650143887081867\n",
      "Iteration 16451 => Loss: 49.17383101518533550234\n",
      "Iteration 16452 => Loss: 49.17364553038749619418\n",
      "Iteration 16453 => Loss: 49.17346004704535289420\n",
      "Iteration 16454 => Loss: 49.17327456515884875898\n",
      "Iteration 16455 => Loss: 49.17308908472798378853\n",
      "Iteration 16456 => Loss: 49.17290360575277219368\n",
      "Iteration 16457 => Loss: 49.17271812823319976360\n",
      "Iteration 16458 => Loss: 49.17253265216924518199\n",
      "Iteration 16459 => Loss: 49.17234717756089423801\n",
      "Iteration 16460 => Loss: 49.17216170440812561537\n",
      "Iteration 16461 => Loss: 49.17197623271093931407\n",
      "Iteration 16462 => Loss: 49.17179076246934243954\n",
      "Iteration 16463 => Loss: 49.17160529368331367550\n",
      "Iteration 16464 => Loss: 49.17141982635280328395\n",
      "Iteration 16465 => Loss: 49.17123436047786100289\n",
      "Iteration 16466 => Loss: 49.17104889605841577804\n",
      "Iteration 16467 => Loss: 49.17086343309449603112\n",
      "Iteration 16468 => Loss: 49.17067797158608044583\n",
      "Iteration 16469 => Loss: 49.17049251153317612761\n",
      "Iteration 16470 => Loss: 49.17030705293571912762\n",
      "Iteration 16471 => Loss: 49.17012159579376628926\n",
      "Iteration 16472 => Loss: 49.16993614010726076913\n",
      "Iteration 16473 => Loss: 49.16975068587617414551\n",
      "Iteration 16474 => Loss: 49.16956523310057036724\n",
      "Iteration 16475 => Loss: 49.16937978178034995835\n",
      "Iteration 16476 => Loss: 49.16919433191554844598\n",
      "Iteration 16477 => Loss: 49.16900888350615161926\n",
      "Iteration 16478 => Loss: 49.16882343655215237277\n",
      "Iteration 16479 => Loss: 49.16863799105352939023\n",
      "Iteration 16480 => Loss: 49.16845254701026135535\n",
      "Iteration 16481 => Loss: 49.16826710442234116272\n",
      "Iteration 16482 => Loss: 49.16808166328977591775\n",
      "Iteration 16483 => Loss: 49.16789622361255140959\n",
      "Iteration 16484 => Loss: 49.16771078539066053281\n",
      "Iteration 16485 => Loss: 49.16752534862406776028\n",
      "Iteration 16486 => Loss: 49.16733991331277309200\n",
      "Iteration 16487 => Loss: 49.16715447945674100083\n",
      "Iteration 16488 => Loss: 49.16696904705599280305\n",
      "Iteration 16489 => Loss: 49.16678361611054270952\n",
      "Iteration 16490 => Loss: 49.16659818662030545511\n",
      "Iteration 16491 => Loss: 49.16641275858533077781\n",
      "Iteration 16492 => Loss: 49.16622733200557604505\n",
      "Iteration 16493 => Loss: 49.16604190688104125684\n",
      "Iteration 16494 => Loss: 49.16585648321171930775\n",
      "Iteration 16495 => Loss: 49.16567106099758177606\n",
      "Iteration 16496 => Loss: 49.16548564023862155636\n",
      "Iteration 16497 => Loss: 49.16530022093484575407\n",
      "Iteration 16498 => Loss: 49.16511480308624015834\n",
      "Iteration 16499 => Loss: 49.16492938669276213659\n",
      "Iteration 16500 => Loss: 49.16474397175444721597\n",
      "Iteration 16501 => Loss: 49.16455855827123855306\n",
      "Iteration 16502 => Loss: 49.16437314624313614786\n",
      "Iteration 16503 => Loss: 49.16418773567016131665\n",
      "Iteration 16504 => Loss: 49.16400232655228563772\n",
      "Iteration 16505 => Loss: 49.16381691888947358393\n",
      "Iteration 16506 => Loss: 49.16363151268173226072\n",
      "Iteration 16507 => Loss: 49.16344610792906166807\n",
      "Iteration 16508 => Loss: 49.16326070463141917344\n",
      "Iteration 16509 => Loss: 49.16307530278881188224\n",
      "Iteration 16510 => Loss: 49.16288990240122558362\n",
      "Iteration 16511 => Loss: 49.16270450346866738300\n",
      "Iteration 16512 => Loss: 49.16251910599110885869\n",
      "Iteration 16513 => Loss: 49.16233370996854290524\n",
      "Iteration 16514 => Loss: 49.16214831540095531182\n",
      "Iteration 16515 => Loss: 49.16196292228831765669\n",
      "Iteration 16516 => Loss: 49.16177753063062993988\n",
      "Iteration 16517 => Loss: 49.16159214042791347765\n",
      "Iteration 16518 => Loss: 49.16140675168011853202\n",
      "Iteration 16519 => Loss: 49.16122136438724510299\n",
      "Iteration 16520 => Loss: 49.16103597854927897970\n",
      "Iteration 16521 => Loss: 49.16085059416621305672\n",
      "Iteration 16522 => Loss: 49.16066521123803312321\n",
      "Iteration 16523 => Loss: 49.16047982976473207373\n",
      "Iteration 16524 => Loss: 49.16029444974630990828\n",
      "Iteration 16525 => Loss: 49.16010907118268846716\n",
      "Iteration 16526 => Loss: 49.15992369407394591008\n",
      "Iteration 16527 => Loss: 49.15973831842003960446\n",
      "Iteration 16528 => Loss: 49.15955294422094823403\n",
      "Iteration 16529 => Loss: 49.15936757147664337708\n",
      "Iteration 16530 => Loss: 49.15918220018715345532\n",
      "Iteration 16531 => Loss: 49.15899683035245004703\n",
      "Iteration 16532 => Loss: 49.15881146197250473051\n",
      "Iteration 16533 => Loss: 49.15862609504733171661\n",
      "Iteration 16534 => Loss: 49.15844072957690258363\n",
      "Iteration 16535 => Loss: 49.15825536556121022613\n",
      "Iteration 16536 => Loss: 49.15807000300024043327\n",
      "Iteration 16537 => Loss: 49.15788464189400031046\n",
      "Iteration 16538 => Loss: 49.15769928224245433057\n",
      "Iteration 16539 => Loss: 49.15751392404561670446\n",
      "Iteration 16540 => Loss: 49.15732856730343058871\n",
      "Iteration 16541 => Loss: 49.15714321201594572130\n",
      "Iteration 16542 => Loss: 49.15695785818311236426\n",
      "Iteration 16543 => Loss: 49.15677250580490209586\n",
      "Iteration 16544 => Loss: 49.15658715488135044325\n",
      "Iteration 16545 => Loss: 49.15640180541240056300\n",
      "Iteration 16546 => Loss: 49.15621645739808798226\n",
      "Iteration 16547 => Loss: 49.15603111083837006845\n",
      "Iteration 16548 => Loss: 49.15584576573325392701\n",
      "Iteration 16549 => Loss: 49.15566042208270403080\n",
      "Iteration 16550 => Loss: 49.15547507988672748525\n",
      "Iteration 16551 => Loss: 49.15528973914528165778\n",
      "Iteration 16552 => Loss: 49.15510439985841628641\n",
      "Iteration 16553 => Loss: 49.15491906202605321141\n",
      "Iteration 16554 => Loss: 49.15473372564822795994\n",
      "Iteration 16555 => Loss: 49.15454839072491921570\n",
      "Iteration 16556 => Loss: 49.15436305725608434614\n",
      "Iteration 16557 => Loss: 49.15417772524176598381\n",
      "Iteration 16558 => Loss: 49.15399239468191439073\n",
      "Iteration 16559 => Loss: 49.15380706557652956690\n",
      "Iteration 16560 => Loss: 49.15362173792558309060\n",
      "Iteration 16561 => Loss: 49.15343641172906785641\n",
      "Iteration 16562 => Loss: 49.15325108698701228604\n",
      "Iteration 16563 => Loss: 49.15306576369936664150\n",
      "Iteration 16564 => Loss: 49.15288044186611671194\n",
      "Iteration 16565 => Loss: 49.15269512148727670819\n",
      "Iteration 16566 => Loss: 49.15250980256283241943\n",
      "Iteration 16567 => Loss: 49.15232448509274831849\n",
      "Iteration 16568 => Loss: 49.15213916907703151082\n",
      "Iteration 16569 => Loss: 49.15195385451563936385\n",
      "Iteration 16570 => Loss: 49.15176854140860740472\n",
      "Iteration 16571 => Loss: 49.15158322975587879000\n",
      "Iteration 16572 => Loss: 49.15139791955749615227\n",
      "Iteration 16573 => Loss: 49.15121261081340975352\n",
      "Iteration 16574 => Loss: 49.15102730352361248833\n",
      "Iteration 16575 => Loss: 49.15084199768811146214\n",
      "Iteration 16576 => Loss: 49.15065669330685693694\n",
      "Iteration 16577 => Loss: 49.15047139037987733445\n",
      "Iteration 16578 => Loss: 49.15028608890715844382\n",
      "Iteration 16579 => Loss: 49.15010078888865052704\n",
      "Iteration 16580 => Loss: 49.14991549032437490041\n",
      "Iteration 16581 => Loss: 49.14973019321430314221\n",
      "Iteration 16582 => Loss: 49.14954489755844946330\n",
      "Iteration 16583 => Loss: 49.14935960335679254740\n",
      "Iteration 16584 => Loss: 49.14917431060928976194\n",
      "Iteration 16585 => Loss: 49.14898901931597663406\n",
      "Iteration 16586 => Loss: 49.14880372947678921491\n",
      "Iteration 16587 => Loss: 49.14861844109179855877\n",
      "Iteration 16588 => Loss: 49.14843315416089808423\n",
      "Iteration 16589 => Loss: 49.14824786868415174013\n",
      "Iteration 16590 => Loss: 49.14806258466147426134\n",
      "Iteration 16591 => Loss: 49.14787730209293670214\n",
      "Iteration 16592 => Loss: 49.14769202097845379740\n",
      "Iteration 16593 => Loss: 49.14750674131806817968\n",
      "Iteration 16594 => Loss: 49.14732146311175142728\n",
      "Iteration 16595 => Loss: 49.14713618635946801305\n",
      "Iteration 16596 => Loss: 49.14695091106124635871\n",
      "Iteration 16597 => Loss: 49.14676563721703672627\n",
      "Iteration 16598 => Loss: 49.14658036482686043200\n",
      "Iteration 16599 => Loss: 49.14639509389069615963\n",
      "Iteration 16600 => Loss: 49.14620982440851548745\n",
      "Iteration 16601 => Loss: 49.14602455638033262630\n",
      "Iteration 16602 => Loss: 49.14583928980609783821\n",
      "Iteration 16603 => Loss: 49.14565402468585375573\n",
      "Iteration 16604 => Loss: 49.14546876101955064087\n",
      "Iteration 16605 => Loss: 49.14528349880717428277\n",
      "Iteration 16606 => Loss: 49.14509823804874599773\n",
      "Iteration 16607 => Loss: 49.14491297874423025860\n",
      "Iteration 16608 => Loss: 49.14472772089360574910\n",
      "Iteration 16609 => Loss: 49.14454246449691510179\n",
      "Iteration 16610 => Loss: 49.14435720955405884069\n",
      "Iteration 16611 => Loss: 49.14417195606509380923\n",
      "Iteration 16612 => Loss: 49.14398670402998448026\n",
      "Iteration 16613 => Loss: 49.14380145344872374835\n",
      "Iteration 16614 => Loss: 49.14361620432129740266\n",
      "Iteration 16615 => Loss: 49.14343095664771254860\n",
      "Iteration 16616 => Loss: 49.14324571042794076448\n",
      "Iteration 16617 => Loss: 49.14306046566196073400\n",
      "Iteration 16618 => Loss: 49.14287522234977245716\n",
      "Iteration 16619 => Loss: 49.14268998049134751227\n",
      "Iteration 16620 => Loss: 49.14250474008671432102\n",
      "Iteration 16621 => Loss: 49.14231950113582314543\n",
      "Iteration 16622 => Loss: 49.14213426363868819635\n",
      "Iteration 16623 => Loss: 49.14194902759527394664\n",
      "Iteration 16624 => Loss: 49.14176379300563013430\n",
      "Iteration 16625 => Loss: 49.14157855986963596706\n",
      "Iteration 16626 => Loss: 49.14139332818738381548\n",
      "Iteration 16627 => Loss: 49.14120809795878841442\n",
      "Iteration 16628 => Loss: 49.14102286918388529102\n",
      "Iteration 16629 => Loss: 49.14083764186263181273\n",
      "Iteration 16630 => Loss: 49.14065241599503508496\n",
      "Iteration 16631 => Loss: 49.14046719158110931858\n",
      "Iteration 16632 => Loss: 49.14028196862080477558\n",
      "Iteration 16633 => Loss: 49.14009674711410724512\n",
      "Iteration 16634 => Loss: 49.13991152706103804348\n",
      "Iteration 16635 => Loss: 49.13972630846154743267\n",
      "Iteration 16636 => Loss: 49.13954109131565672897\n",
      "Iteration 16637 => Loss: 49.13935587562333040523\n",
      "Iteration 16638 => Loss: 49.13917066138456135604\n",
      "Iteration 16639 => Loss: 49.13898544859935668683\n",
      "Iteration 16640 => Loss: 49.13880023726768797587\n",
      "Iteration 16641 => Loss: 49.13861502738954811775\n",
      "Iteration 16642 => Loss: 49.13842981896492290161\n",
      "Iteration 16643 => Loss: 49.13824461199379101117\n",
      "Iteration 16644 => Loss: 49.13805940647617376271\n",
      "Iteration 16645 => Loss: 49.13787420241204273452\n",
      "Iteration 16646 => Loss: 49.13768899980136950489\n",
      "Iteration 16647 => Loss: 49.13750379864416828468\n",
      "Iteration 16648 => Loss: 49.13731859894039644132\n",
      "Iteration 16649 => Loss: 49.13713340069010371280\n",
      "Iteration 16650 => Loss: 49.13694820389319062315\n",
      "Iteration 16651 => Loss: 49.13676300854972112120\n",
      "Iteration 16652 => Loss: 49.13657781465963125811\n",
      "Iteration 16653 => Loss: 49.13639262222294945559\n",
      "Iteration 16654 => Loss: 49.13620743123965439736\n",
      "Iteration 16655 => Loss: 49.13602224170971055628\n",
      "Iteration 16656 => Loss: 49.13583705363312503778\n",
      "Iteration 16657 => Loss: 49.13565186700989073643\n",
      "Iteration 16658 => Loss: 49.13546668184001475765\n",
      "Iteration 16659 => Loss: 49.13528149812344025804\n",
      "Iteration 16660 => Loss: 49.13509631586017434302\n",
      "Iteration 16661 => Loss: 49.13491113505020990715\n",
      "Iteration 16662 => Loss: 49.13472595569354695044\n",
      "Iteration 16663 => Loss: 49.13454077779012862948\n",
      "Iteration 16664 => Loss: 49.13435560134002599852\n",
      "Iteration 16665 => Loss: 49.13417042634314668703\n",
      "Iteration 16666 => Loss: 49.13398525279951911671\n",
      "Iteration 16667 => Loss: 49.13380008070911486584\n",
      "Iteration 16668 => Loss: 49.13361491007193393443\n",
      "Iteration 16669 => Loss: 49.13342974088798342791\n",
      "Iteration 16670 => Loss: 49.13324457315721360828\n",
      "Iteration 16671 => Loss: 49.13305940687963868641\n",
      "Iteration 16672 => Loss: 49.13287424205523734599\n",
      "Iteration 16673 => Loss: 49.13268907868398827077\n",
      "Iteration 16674 => Loss: 49.13250391676589146073\n",
      "Iteration 16675 => Loss: 49.13231875630094691587\n",
      "Iteration 16676 => Loss: 49.13213359728911910906\n",
      "Iteration 16677 => Loss: 49.13194843973041514573\n",
      "Iteration 16678 => Loss: 49.13176328362484213130\n",
      "Iteration 16679 => Loss: 49.13157812897232901150\n",
      "Iteration 16680 => Loss: 49.13139297577291131347\n",
      "Iteration 16681 => Loss: 49.13120782402657482635\n",
      "Iteration 16682 => Loss: 49.13102267373330533928\n",
      "Iteration 16683 => Loss: 49.13083752489305311428\n",
      "Iteration 16684 => Loss: 49.13065237750587499477\n",
      "Iteration 16685 => Loss: 49.13046723157169992646\n",
      "Iteration 16686 => Loss: 49.13028208709053501480\n",
      "Iteration 16687 => Loss: 49.13009694406240157605\n",
      "Iteration 16688 => Loss: 49.12991180248724987223\n",
      "Iteration 16689 => Loss: 49.12972666236507279791\n",
      "Iteration 16690 => Loss: 49.12954152369586324767\n",
      "Iteration 16691 => Loss: 49.12935638647960701064\n",
      "Iteration 16692 => Loss: 49.12917125071632540312\n",
      "Iteration 16693 => Loss: 49.12898611640596158168\n",
      "Iteration 16694 => Loss: 49.12880098354852265174\n",
      "Iteration 16695 => Loss: 49.12861585214400861332\n",
      "Iteration 16696 => Loss: 49.12843072219240525556\n",
      "Iteration 16697 => Loss: 49.12824559369365573502\n",
      "Iteration 16698 => Loss: 49.12806046664780268429\n",
      "Iteration 16699 => Loss: 49.12787534105481768165\n",
      "Iteration 16700 => Loss: 49.12769021691468651625\n",
      "Iteration 16701 => Loss: 49.12750509422738787180\n",
      "Iteration 16702 => Loss: 49.12731997299294306458\n",
      "Iteration 16703 => Loss: 49.12713485321131656747\n",
      "Iteration 16704 => Loss: 49.12694973488250838045\n",
      "Iteration 16705 => Loss: 49.12676461800646876554\n",
      "Iteration 16706 => Loss: 49.12657950258324035531\n",
      "Iteration 16707 => Loss: 49.12639438861276630632\n",
      "Iteration 16708 => Loss: 49.12620927609508214573\n",
      "Iteration 16709 => Loss: 49.12602416503011681925\n",
      "Iteration 16710 => Loss: 49.12583905541794138117\n",
      "Iteration 16711 => Loss: 49.12565394725846346091\n",
      "Iteration 16712 => Loss: 49.12546884055173279648\n",
      "Iteration 16713 => Loss: 49.12528373529768543904\n",
      "Iteration 16714 => Loss: 49.12509863149633559942\n",
      "Iteration 16715 => Loss: 49.12491352914767617222\n",
      "Iteration 16716 => Loss: 49.12472842825170005199\n",
      "Iteration 16717 => Loss: 49.12454332880837171160\n",
      "Iteration 16718 => Loss: 49.12435823081769825649\n",
      "Iteration 16719 => Loss: 49.12417313427965126493\n",
      "Iteration 16720 => Loss: 49.12398803919425915865\n",
      "Iteration 16721 => Loss: 49.12380294556144377793\n",
      "Iteration 16722 => Loss: 49.12361785338126907163\n",
      "Iteration 16723 => Loss: 49.12343276265369240718\n",
      "Iteration 16724 => Loss: 49.12324767337867825745\n",
      "Iteration 16725 => Loss: 49.12306258555623372786\n",
      "Iteration 16726 => Loss: 49.12287749918635881841\n",
      "Iteration 16727 => Loss: 49.12269241426901800196\n",
      "Iteration 16728 => Loss: 49.12250733080421838395\n",
      "Iteration 16729 => Loss: 49.12232224879195996436\n",
      "Iteration 16730 => Loss: 49.12213716823220721608\n",
      "Iteration 16731 => Loss: 49.12195208912494592823\n",
      "Iteration 16732 => Loss: 49.12176701147019031168\n",
      "Iteration 16733 => Loss: 49.12158193526791905015\n",
      "Iteration 16734 => Loss: 49.12139686051808951106\n",
      "Iteration 16735 => Loss: 49.12121178722074432699\n",
      "Iteration 16736 => Loss: 49.12102671537582665451\n",
      "Iteration 16737 => Loss: 49.12084164498336491533\n",
      "Iteration 16738 => Loss: 49.12065657604328805519\n",
      "Iteration 16739 => Loss: 49.12047150855564581207\n",
      "Iteration 16740 => Loss: 49.12028644252040265883\n",
      "Iteration 16741 => Loss: 49.12010137793754438462\n",
      "Iteration 16742 => Loss: 49.11991631480707809487\n",
      "Iteration 16743 => Loss: 49.11973125312896115702\n",
      "Iteration 16744 => Loss: 49.11954619290321488734\n",
      "Iteration 16745 => Loss: 49.11936113412977533699\n",
      "Iteration 16746 => Loss: 49.11917607680871356024\n",
      "Iteration 16747 => Loss: 49.11899102093995850282\n",
      "Iteration 16748 => Loss: 49.11880596652349595388\n",
      "Iteration 16749 => Loss: 49.11862091355932591341\n",
      "Iteration 16750 => Loss: 49.11843586204747680313\n",
      "Iteration 16751 => Loss: 49.11825081198786335790\n",
      "Iteration 16752 => Loss: 49.11806576338052821029\n",
      "Iteration 16753 => Loss: 49.11788071622545004402\n",
      "Iteration 16754 => Loss: 49.11769567052260754281\n",
      "Iteration 16755 => Loss: 49.11751062627200070665\n",
      "Iteration 16756 => Loss: 49.11732558347358690298\n",
      "Iteration 16757 => Loss: 49.11714054212741586980\n",
      "Iteration 16758 => Loss: 49.11695550223341655283\n",
      "Iteration 16759 => Loss: 49.11677046379160316292\n",
      "Iteration 16760 => Loss: 49.11658542680195438379\n",
      "Iteration 16761 => Loss: 49.11640039126449153173\n",
      "Iteration 16762 => Loss: 49.11621535717914355246\n",
      "Iteration 16763 => Loss: 49.11603032454596728940\n",
      "Iteration 16764 => Loss: 49.11584529336489168827\n",
      "Iteration 16765 => Loss: 49.11566026363593806536\n",
      "Iteration 16766 => Loss: 49.11547523535909931525\n",
      "Iteration 16767 => Loss: 49.11529020853435412164\n",
      "Iteration 16768 => Loss: 49.11510518316167406283\n",
      "Iteration 16769 => Loss: 49.11492015924106624425\n",
      "Iteration 16770 => Loss: 49.11473513677252356047\n",
      "Iteration 16771 => Loss: 49.11455011575602469520\n",
      "Iteration 16772 => Loss: 49.11436509619155543760\n",
      "Iteration 16773 => Loss: 49.11418007807911578766\n",
      "Iteration 16774 => Loss: 49.11399506141869863995\n",
      "Iteration 16775 => Loss: 49.11381004621024715107\n",
      "Iteration 16776 => Loss: 49.11362503245381105899\n",
      "Iteration 16777 => Loss: 49.11344002014936194200\n",
      "Iteration 16778 => Loss: 49.11325500929686427298\n",
      "Iteration 16779 => Loss: 49.11306999989633936821\n",
      "Iteration 16780 => Loss: 49.11288499194773748968\n",
      "Iteration 16781 => Loss: 49.11269998545107284826\n",
      "Iteration 16782 => Loss: 49.11251498040633833853\n",
      "Iteration 16783 => Loss: 49.11232997681349843333\n",
      "Iteration 16784 => Loss: 49.11214497467258155439\n",
      "Iteration 16785 => Loss: 49.11195997398352375285\n",
      "Iteration 16786 => Loss: 49.11177497474636766128\n",
      "Iteration 16787 => Loss: 49.11158997696105643627\n",
      "Iteration 16788 => Loss: 49.11140498062761139408\n",
      "Iteration 16789 => Loss: 49.11121998574599700760\n",
      "Iteration 16790 => Loss: 49.11103499231622748766\n",
      "Iteration 16791 => Loss: 49.11085000033825309629\n",
      "Iteration 16792 => Loss: 49.11066500981210936061\n",
      "Iteration 16793 => Loss: 49.11048002073774654264\n",
      "Iteration 16794 => Loss: 49.11029503311516464237\n",
      "Iteration 16795 => Loss: 49.11011004694437076523\n",
      "Iteration 16796 => Loss: 49.10992506222534359495\n",
      "Iteration 16797 => Loss: 49.10974007895805470980\n",
      "Iteration 16798 => Loss: 49.10955509714250410980\n",
      "Iteration 16799 => Loss: 49.10937011677867758408\n",
      "Iteration 16800 => Loss: 49.10918513786657513265\n",
      "Iteration 16801 => Loss: 49.10900016040616122837\n",
      "Iteration 16802 => Loss: 49.10881518439746429294\n",
      "Iteration 16803 => Loss: 49.10863020984043458839\n",
      "Iteration 16804 => Loss: 49.10844523673507922013\n",
      "Iteration 16805 => Loss: 49.10826026508137687188\n",
      "Iteration 16806 => Loss: 49.10807529487934885992\n",
      "Iteration 16807 => Loss: 49.10789032612893123542\n",
      "Iteration 16808 => Loss: 49.10770535883013820921\n",
      "Iteration 16809 => Loss: 49.10752039298296978131\n",
      "Iteration 16810 => Loss: 49.10733542858737621373\n",
      "Iteration 16811 => Loss: 49.10715046564342145530\n",
      "Iteration 16812 => Loss: 49.10696550415101313547\n",
      "Iteration 16813 => Loss: 49.10678054411017967595\n",
      "Iteration 16814 => Loss: 49.10659558552091397132\n",
      "Iteration 16815 => Loss: 49.10641062838317338901\n",
      "Iteration 16816 => Loss: 49.10622567269697213987\n",
      "Iteration 16817 => Loss: 49.10604071846229601306\n",
      "Iteration 16818 => Loss: 49.10585576567914500856\n",
      "Iteration 16819 => Loss: 49.10567081434748359925\n",
      "Iteration 16820 => Loss: 49.10548586446729757427\n",
      "Iteration 16821 => Loss: 49.10530091603862246075\n",
      "Iteration 16822 => Loss: 49.10511596906138009899\n",
      "Iteration 16823 => Loss: 49.10493102353560601614\n",
      "Iteration 16824 => Loss: 49.10474607946125757962\n",
      "Iteration 16825 => Loss: 49.10456113683834900030\n",
      "Iteration 16826 => Loss: 49.10437619566688027817\n",
      "Iteration 16827 => Loss: 49.10419125594679456981\n",
      "Iteration 16828 => Loss: 49.10400631767809898065\n",
      "Iteration 16829 => Loss: 49.10382138086083614326\n",
      "Iteration 16830 => Loss: 49.10363644549489947622\n",
      "Iteration 16831 => Loss: 49.10345151158034582295\n",
      "Iteration 16832 => Loss: 49.10326657911714676175\n",
      "Iteration 16833 => Loss: 49.10308164810529518718\n",
      "Iteration 16834 => Loss: 49.10289671854474136126\n",
      "Iteration 16835 => Loss: 49.10271179043552791654\n",
      "Iteration 16836 => Loss: 49.10252686377761932590\n",
      "Iteration 16837 => Loss: 49.10234193857100848390\n",
      "Iteration 16838 => Loss: 49.10215701481567407427\n",
      "Iteration 16839 => Loss: 49.10197209251161609700\n",
      "Iteration 16840 => Loss: 49.10178717165881323581\n",
      "Iteration 16841 => Loss: 49.10160225225725838527\n",
      "Iteration 16842 => Loss: 49.10141733430693733453\n",
      "Iteration 16843 => Loss: 49.10123241780785718902\n",
      "Iteration 16844 => Loss: 49.10104750275997531617\n",
      "Iteration 16845 => Loss: 49.10086258916330592683\n",
      "Iteration 16846 => Loss: 49.10067767701783481016\n",
      "Iteration 16847 => Loss: 49.10049276632352643901\n",
      "Iteration 16848 => Loss: 49.10030785708040212967\n",
      "Iteration 16849 => Loss: 49.10012294928845477671\n",
      "Iteration 16850 => Loss: 49.09993804294760622042\n",
      "Iteration 16851 => Loss: 49.09975313805793462052\n",
      "Iteration 16852 => Loss: 49.09956823461936181729\n",
      "Iteration 16853 => Loss: 49.09938333263192333789\n",
      "Iteration 16854 => Loss: 49.09919843209554812802\n",
      "Iteration 16855 => Loss: 49.09901353301029303111\n",
      "Iteration 16856 => Loss: 49.09882863537610830917\n",
      "Iteration 16857 => Loss: 49.09864373919300817306\n",
      "Iteration 16858 => Loss: 49.09845884446094999021\n",
      "Iteration 16859 => Loss: 49.09827395117992665519\n",
      "Iteration 16860 => Loss: 49.09808905934995237885\n",
      "Iteration 16861 => Loss: 49.09790416897098452864\n",
      "Iteration 16862 => Loss: 49.09771928004305152626\n",
      "Iteration 16863 => Loss: 49.09753439256609652830\n",
      "Iteration 16864 => Loss: 49.09734950654011953475\n",
      "Iteration 16865 => Loss: 49.09716462196513475646\n",
      "Iteration 16866 => Loss: 49.09697973884109956089\n",
      "Iteration 16867 => Loss: 49.09679485716804947515\n",
      "Iteration 16868 => Loss: 49.09660997694589923412\n",
      "Iteration 16869 => Loss: 49.09642509817469857580\n",
      "Iteration 16870 => Loss: 49.09624022085440486762\n",
      "Iteration 16871 => Loss: 49.09605534498503942586\n",
      "Iteration 16872 => Loss: 49.09587047056658093425\n",
      "Iteration 16873 => Loss: 49.09568559759898676020\n",
      "Iteration 16874 => Loss: 49.09550072608225690374\n",
      "Iteration 16875 => Loss: 49.09531585601640557570\n",
      "Iteration 16876 => Loss: 49.09513098740139014353\n",
      "Iteration 16877 => Loss: 49.09494612023721060723\n",
      "Iteration 16878 => Loss: 49.09476125452387407222\n",
      "Iteration 16879 => Loss: 49.09457639026135211680\n",
      "Iteration 16880 => Loss: 49.09439152744962342467\n",
      "Iteration 16881 => Loss: 49.09420666608871641756\n",
      "Iteration 16882 => Loss: 49.09402180617855293576\n",
      "Iteration 16883 => Loss: 49.09383694771919692812\n",
      "Iteration 16884 => Loss: 49.09365209071058444579\n",
      "Iteration 16885 => Loss: 49.09346723515270127791\n",
      "Iteration 16886 => Loss: 49.09328238104558295163\n",
      "Iteration 16887 => Loss: 49.09309752838917262352\n",
      "Iteration 16888 => Loss: 49.09291267718347739901\n",
      "Iteration 16889 => Loss: 49.09272782742850438353\n",
      "Iteration 16890 => Loss: 49.09254297912420383909\n",
      "Iteration 16891 => Loss: 49.09235813227058997654\n",
      "Iteration 16892 => Loss: 49.09217328686763437418\n",
      "Iteration 16893 => Loss: 49.09198844291536545370\n",
      "Iteration 16894 => Loss: 49.09180360041371216084\n",
      "Iteration 16895 => Loss: 49.09161875936270291731\n",
      "Iteration 16896 => Loss: 49.09143391976229509055\n",
      "Iteration 16897 => Loss: 49.09124908161253131311\n",
      "Iteration 16898 => Loss: 49.09106424491336184701\n",
      "Iteration 16899 => Loss: 49.09087940966477248139\n",
      "Iteration 16900 => Loss: 49.09069457586675611083\n",
      "Iteration 16901 => Loss: 49.09050974351931984074\n",
      "Iteration 16902 => Loss: 49.09032491262244235486\n",
      "Iteration 16903 => Loss: 49.09014008317608812604\n",
      "Iteration 16904 => Loss: 49.08995525518025715428\n",
      "Iteration 16905 => Loss: 49.08977042863496365044\n",
      "Iteration 16906 => Loss: 49.08958560354019340366\n",
      "Iteration 16907 => Loss: 49.08940077989589667595\n",
      "Iteration 16908 => Loss: 49.08921595770209478360\n",
      "Iteration 16909 => Loss: 49.08903113695877351574\n",
      "Iteration 16910 => Loss: 49.08884631766589734525\n",
      "Iteration 16911 => Loss: 49.08866149982350179926\n",
      "Iteration 16912 => Loss: 49.08847668343152292891\n",
      "Iteration 16913 => Loss: 49.08829186848998205051\n",
      "Iteration 16914 => Loss: 49.08810705499885784775\n",
      "Iteration 16915 => Loss: 49.08792224295814321522\n",
      "Iteration 16916 => Loss: 49.08773743236780973120\n",
      "Iteration 16917 => Loss: 49.08755262322787871199\n",
      "Iteration 16918 => Loss: 49.08736781553832173586\n",
      "Iteration 16919 => Loss: 49.08718300929909617025\n",
      "Iteration 16920 => Loss: 49.08699820451025175316\n",
      "Iteration 16921 => Loss: 49.08681340117173164117\n",
      "Iteration 16922 => Loss: 49.08662859928355715056\n",
      "Iteration 16923 => Loss: 49.08644379884567854333\n",
      "Iteration 16924 => Loss: 49.08625899985810292492\n",
      "Iteration 16925 => Loss: 49.08607420232081608447\n",
      "Iteration 16926 => Loss: 49.08588940623383933826\n",
      "Iteration 16927 => Loss: 49.08570461159709452659\n",
      "Iteration 16928 => Loss: 49.08551981841063138745\n",
      "Iteration 16929 => Loss: 49.08533502667442149914\n",
      "Iteration 16930 => Loss: 49.08515023638842222908\n",
      "Iteration 16931 => Loss: 49.08496544755266199900\n",
      "Iteration 16932 => Loss: 49.08478066016711238717\n",
      "Iteration 16933 => Loss: 49.08459587423176628818\n",
      "Iteration 16934 => Loss: 49.08441108974662370201\n",
      "Iteration 16935 => Loss: 49.08422630671163489069\n",
      "Iteration 16936 => Loss: 49.08404152512683538134\n",
      "Iteration 16937 => Loss: 49.08385674499217543598\n",
      "Iteration 16938 => Loss: 49.08367196630766216003\n",
      "Iteration 16939 => Loss: 49.08348718907328134264\n",
      "Iteration 16940 => Loss: 49.08330241328905430009\n",
      "Iteration 16941 => Loss: 49.08311763895489576726\n",
      "Iteration 16942 => Loss: 49.08293286607086258755\n",
      "Iteration 16943 => Loss: 49.08274809463689791755\n",
      "Iteration 16944 => Loss: 49.08256332465303728441\n",
      "Iteration 16945 => Loss: 49.08237855611919542298\n",
      "Iteration 16946 => Loss: 49.08219378903546470383\n",
      "Iteration 16947 => Loss: 49.08200902340173854554\n",
      "Iteration 16948 => Loss: 49.08182425921803115898\n",
      "Iteration 16949 => Loss: 49.08163949648437096585\n",
      "Iteration 16950 => Loss: 49.08145473520072243900\n",
      "Iteration 16951 => Loss: 49.08126997536707847303\n",
      "Iteration 16952 => Loss: 49.08108521698338932993\n",
      "Iteration 16953 => Loss: 49.08090046004968343141\n",
      "Iteration 16954 => Loss: 49.08071570456593235576\n",
      "Iteration 16955 => Loss: 49.08053095053215031385\n",
      "Iteration 16956 => Loss: 49.08034619794830177852\n",
      "Iteration 16957 => Loss: 49.08016144681439385522\n",
      "Iteration 16958 => Loss: 49.07997669713038391137\n",
      "Iteration 16959 => Loss: 49.07979194889629326326\n",
      "Iteration 16960 => Loss: 49.07960720211210059460\n",
      "Iteration 16961 => Loss: 49.07942245677775616741\n",
      "Iteration 16962 => Loss: 49.07923771289330261425\n",
      "Iteration 16963 => Loss: 49.07905297045871861883\n",
      "Iteration 16964 => Loss: 49.07886822947401128658\n",
      "Iteration 16965 => Loss: 49.07868348993908824696\n",
      "Iteration 16966 => Loss: 49.07849875185401344879\n",
      "Iteration 16967 => Loss: 49.07831401521874425953\n",
      "Iteration 16968 => Loss: 49.07812928003328067916\n",
      "Iteration 16969 => Loss: 49.07794454629763691855\n",
      "Iteration 16970 => Loss: 49.07775981401175613428\n",
      "Iteration 16971 => Loss: 49.07757508317563122091\n",
      "Iteration 16972 => Loss: 49.07739035378927638931\n",
      "Iteration 16973 => Loss: 49.07720562585267032318\n",
      "Iteration 16974 => Loss: 49.07702089936578460083\n",
      "Iteration 16975 => Loss: 49.07683617432864053853\n",
      "Iteration 16976 => Loss: 49.07665145074119550372\n",
      "Iteration 16977 => Loss: 49.07646672860344239098\n",
      "Iteration 16978 => Loss: 49.07628200791540251657\n",
      "Iteration 16979 => Loss: 49.07609728867703324795\n",
      "Iteration 16980 => Loss: 49.07591257088832747968\n",
      "Iteration 16981 => Loss: 49.07572785454929231719\n",
      "Iteration 16982 => Loss: 49.07554313965989223334\n",
      "Iteration 16983 => Loss: 49.07535842622010591185\n",
      "Iteration 16984 => Loss: 49.07517371422994756358\n",
      "Iteration 16985 => Loss: 49.07498900368942429395\n",
      "Iteration 16986 => Loss: 49.07480429459847925955\n",
      "Iteration 16987 => Loss: 49.07461958695711956580\n",
      "Iteration 16988 => Loss: 49.07443488076533100184\n",
      "Iteration 16989 => Loss: 49.07425017602312777854\n",
      "Iteration 16990 => Loss: 49.07406547273047436875\n",
      "Iteration 16991 => Loss: 49.07388077088734235076\n",
      "Iteration 16992 => Loss: 49.07369607049376725172\n",
      "Iteration 16993 => Loss: 49.07351137154967091192\n",
      "Iteration 16994 => Loss: 49.07332667405512438563\n",
      "Iteration 16995 => Loss: 49.07314197801004951316\n",
      "Iteration 16996 => Loss: 49.07295728341447471621\n",
      "Iteration 16997 => Loss: 49.07277259026836446765\n",
      "Iteration 16998 => Loss: 49.07258789857173297833\n",
      "Iteration 16999 => Loss: 49.07240320832452340483\n",
      "Iteration 17000 => Loss: 49.07221851952677127429\n",
      "Iteration 17001 => Loss: 49.07203383217844105957\n",
      "Iteration 17002 => Loss: 49.07184914627952565525\n",
      "Iteration 17003 => Loss: 49.07166446183001085046\n",
      "Iteration 17004 => Loss: 49.07147977882991085608\n",
      "Iteration 17005 => Loss: 49.07129509727919014495\n",
      "Iteration 17006 => Loss: 49.07111041717784161165\n",
      "Iteration 17007 => Loss: 49.07092573852582972904\n",
      "Iteration 17008 => Loss: 49.07074106132317581341\n",
      "Iteration 17009 => Loss: 49.07055638556986565391\n",
      "Iteration 17010 => Loss: 49.07037171126587793424\n",
      "Iteration 17011 => Loss: 49.07018703841121265441\n",
      "Iteration 17012 => Loss: 49.07000236700583428728\n",
      "Iteration 17013 => Loss: 49.06981769704976414914\n",
      "Iteration 17014 => Loss: 49.06963302854295960742\n",
      "Iteration 17015 => Loss: 49.06944836148542066212\n",
      "Iteration 17016 => Loss: 49.06926369587714020781\n",
      "Iteration 17017 => Loss: 49.06907903171811824450\n",
      "Iteration 17018 => Loss: 49.06889436900831924504\n",
      "Iteration 17019 => Loss: 49.06870970774775742029\n",
      "Iteration 17020 => Loss: 49.06852504793640434855\n",
      "Iteration 17021 => Loss: 49.06834038957424581895\n",
      "Iteration 17022 => Loss: 49.06815573266126762064\n",
      "Iteration 17023 => Loss: 49.06797107719747685906\n",
      "Iteration 17024 => Loss: 49.06778642318287353419\n",
      "Iteration 17025 => Loss: 49.06760177061739369719\n",
      "Iteration 17026 => Loss: 49.06741711950106576978\n",
      "Iteration 17027 => Loss: 49.06723246983388264653\n",
      "Iteration 17028 => Loss: 49.06704782161581590572\n",
      "Iteration 17029 => Loss: 49.06686317484683002021\n",
      "Iteration 17030 => Loss: 49.06667852952697472801\n",
      "Iteration 17031 => Loss: 49.06649388565619318570\n",
      "Iteration 17032 => Loss: 49.06630924323448539326\n",
      "Iteration 17033 => Loss: 49.06612460226185135070\n",
      "Iteration 17034 => Loss: 49.06593996273826974175\n",
      "Iteration 17035 => Loss: 49.06575532466371214468\n",
      "Iteration 17036 => Loss: 49.06557068803820698122\n",
      "Iteration 17037 => Loss: 49.06538605286171872422\n",
      "Iteration 17038 => Loss: 49.06520141913421895197\n",
      "Iteration 17039 => Loss: 49.06501678685571476990\n",
      "Iteration 17040 => Loss: 49.06483215602621328344\n",
      "Iteration 17041 => Loss: 49.06464752664568607088\n",
      "Iteration 17042 => Loss: 49.06446289871411181593\n",
      "Iteration 17043 => Loss: 49.06427827223147630775\n",
      "Iteration 17044 => Loss: 49.06409364719780086261\n",
      "Iteration 17045 => Loss: 49.06390902361303574253\n",
      "Iteration 17046 => Loss: 49.06372440147719515835\n",
      "Iteration 17047 => Loss: 49.06353978079026489922\n",
      "Iteration 17048 => Loss: 49.06335516155220233259\n",
      "Iteration 17049 => Loss: 49.06317054376305009100\n",
      "Iteration 17050 => Loss: 49.06298592742277264733\n",
      "Iteration 17051 => Loss: 49.06280131253133447444\n",
      "Iteration 17052 => Loss: 49.06261669908874978319\n",
      "Iteration 17053 => Loss: 49.06243208709499015185\n",
      "Iteration 17054 => Loss: 49.06224747655007689673\n",
      "Iteration 17055 => Loss: 49.06206286745396738525\n",
      "Iteration 17056 => Loss: 49.06187825980665451198\n",
      "Iteration 17057 => Loss: 49.06169365360815959320\n",
      "Iteration 17058 => Loss: 49.06150904885841157466\n",
      "Iteration 17059 => Loss: 49.06132444555744598347\n",
      "Iteration 17060 => Loss: 49.06113984370524150336\n",
      "Iteration 17061 => Loss: 49.06095524330176260719\n",
      "Iteration 17062 => Loss: 49.06077064434704482210\n",
      "Iteration 17063 => Loss: 49.06058604684103841009\n",
      "Iteration 17064 => Loss: 49.06040145078374337118\n",
      "Iteration 17065 => Loss: 49.06021685617515259992\n",
      "Iteration 17066 => Loss: 49.06003226301524478004\n",
      "Iteration 17067 => Loss: 49.05984767130401991153\n",
      "Iteration 17068 => Loss: 49.05966308104145667812\n",
      "Iteration 17069 => Loss: 49.05947849222754086895\n",
      "Iteration 17070 => Loss: 49.05929390486227958945\n",
      "Iteration 17071 => Loss: 49.05910931894564441791\n",
      "Iteration 17072 => Loss: 49.05892473447763535432\n",
      "Iteration 17073 => Loss: 49.05874015145823818784\n",
      "Iteration 17074 => Loss: 49.05855556988741739133\n",
      "Iteration 17075 => Loss: 49.05837098976520849192\n",
      "Iteration 17076 => Loss: 49.05818641109156175162\n",
      "Iteration 17077 => Loss: 49.05800183386645585415\n",
      "Iteration 17078 => Loss: 49.05781725808994764293\n",
      "Iteration 17079 => Loss: 49.05763268376197316911\n",
      "Iteration 17080 => Loss: 49.05744811088251111642\n",
      "Iteration 17081 => Loss: 49.05726353945158280112\n",
      "Iteration 17082 => Loss: 49.05707896946913848524\n",
      "Iteration 17083 => Loss: 49.05689440093519948505\n",
      "Iteration 17084 => Loss: 49.05670983384974448427\n",
      "Iteration 17085 => Loss: 49.05652526821275927205\n",
      "Iteration 17086 => Loss: 49.05634070402425805923\n",
      "Iteration 17087 => Loss: 49.05615614128419821327\n",
      "Iteration 17088 => Loss: 49.05597157999255131244\n",
      "Iteration 17089 => Loss: 49.05578702014937420017\n",
      "Iteration 17090 => Loss: 49.05560246175454608419\n",
      "Iteration 17091 => Loss: 49.05541790480819486220\n",
      "Iteration 17092 => Loss: 49.05523334931017842564\n",
      "Iteration 17093 => Loss: 49.05504879526059625050\n",
      "Iteration 17094 => Loss: 49.05486424265934886080\n",
      "Iteration 17095 => Loss: 49.05467969150646467824\n",
      "Iteration 17096 => Loss: 49.05449514180195791369\n",
      "Iteration 17097 => Loss: 49.05431059354575040743\n",
      "Iteration 17098 => Loss: 49.05412604673787768661\n",
      "Iteration 17099 => Loss: 49.05394150137830422409\n",
      "Iteration 17100 => Loss: 49.05375695746706554701\n",
      "Iteration 17101 => Loss: 49.05357241500410481194\n",
      "Iteration 17102 => Loss: 49.05338787398943622975\n",
      "Iteration 17103 => Loss: 49.05320333442301006244\n",
      "Iteration 17104 => Loss: 49.05301879630486183714\n",
      "Iteration 17105 => Loss: 49.05283425963495602673\n",
      "Iteration 17106 => Loss: 49.05264972441326420949\n",
      "Iteration 17107 => Loss: 49.05246519063980059627\n",
      "Iteration 17108 => Loss: 49.05228065831458650337\n",
      "Iteration 17109 => Loss: 49.05209612743752956021\n",
      "Iteration 17110 => Loss: 49.05191159800867239937\n",
      "Iteration 17111 => Loss: 49.05172707002799370457\n",
      "Iteration 17112 => Loss: 49.05154254349547926495\n",
      "Iteration 17113 => Loss: 49.05135801841112197508\n",
      "Iteration 17114 => Loss: 49.05117349477492183496\n",
      "Iteration 17115 => Loss: 49.05098897258684331746\n",
      "Iteration 17116 => Loss: 49.05080445184687221172\n",
      "Iteration 17117 => Loss: 49.05061993255501562317\n",
      "Iteration 17118 => Loss: 49.05043541471124513009\n",
      "Iteration 17119 => Loss: 49.05025089831556783793\n",
      "Iteration 17120 => Loss: 49.05006638336799085209\n",
      "Iteration 17121 => Loss: 49.04988186986845732918\n",
      "Iteration 17122 => Loss: 49.04969735781698858545\n",
      "Iteration 17123 => Loss: 49.04951284721354909379\n",
      "Iteration 17124 => Loss: 49.04932833805814595962\n",
      "Iteration 17125 => Loss: 49.04914383035075076123\n",
      "Iteration 17126 => Loss: 49.04895932409135639318\n",
      "Iteration 17127 => Loss: 49.04877481927997706634\n",
      "Iteration 17128 => Loss: 49.04859031591657014815\n",
      "Iteration 17129 => Loss: 49.04840581400114274402\n",
      "Iteration 17130 => Loss: 49.04822131353366643225\n",
      "Iteration 17131 => Loss: 49.04803681451414831827\n",
      "Iteration 17132 => Loss: 49.04785231694256708579\n",
      "Iteration 17133 => Loss: 49.04766782081892273482\n",
      "Iteration 17134 => Loss: 49.04748332614318684364\n",
      "Iteration 17135 => Loss: 49.04729883291533809597\n",
      "Iteration 17136 => Loss: 49.04711434113541201896\n",
      "Iteration 17137 => Loss: 49.04692985080334466375\n",
      "Iteration 17138 => Loss: 49.04674536191915024119\n",
      "Iteration 17139 => Loss: 49.04656087448283585672\n",
      "Iteration 17140 => Loss: 49.04637638849435887778\n",
      "Iteration 17141 => Loss: 49.04619190395371219893\n",
      "Iteration 17142 => Loss: 49.04600742086088160931\n",
      "Iteration 17143 => Loss: 49.04582293921587421437\n",
      "Iteration 17144 => Loss: 49.04563845901869001409\n",
      "Iteration 17145 => Loss: 49.04545398026927216506\n",
      "Iteration 17146 => Loss: 49.04526950296761356185\n",
      "Iteration 17147 => Loss: 49.04508502711375683702\n",
      "Iteration 17148 => Loss: 49.04490055270764514717\n",
      "Iteration 17149 => Loss: 49.04471607974928559770\n",
      "Iteration 17150 => Loss: 49.04453160823864976692\n",
      "Iteration 17151 => Loss: 49.04434713817575897110\n",
      "Iteration 17152 => Loss: 49.04416266956055636683\n",
      "Iteration 17153 => Loss: 49.04397820239307037582\n",
      "Iteration 17154 => Loss: 49.04379373667326547093\n",
      "Iteration 17155 => Loss: 49.04360927240112033587\n",
      "Iteration 17156 => Loss: 49.04342480957666339236\n",
      "Iteration 17157 => Loss: 49.04324034819984490241\n",
      "Iteration 17158 => Loss: 49.04305588827067907687\n",
      "Iteration 17159 => Loss: 49.04287142978915170488\n",
      "Iteration 17160 => Loss: 49.04268697275524147017\n",
      "Iteration 17161 => Loss: 49.04250251716892705645\n",
      "Iteration 17162 => Loss: 49.04231806303022267457\n",
      "Iteration 17163 => Loss: 49.04213361033910700826\n",
      "Iteration 17164 => Loss: 49.04194915909555163580\n",
      "Iteration 17165 => Loss: 49.04176470929958497891\n",
      "Iteration 17166 => Loss: 49.04158026095113598330\n",
      "Iteration 17167 => Loss: 49.04139581405026149241\n",
      "Iteration 17168 => Loss: 49.04121136859690466281\n",
      "Iteration 17169 => Loss: 49.04102692459105838907\n",
      "Iteration 17170 => Loss: 49.04084248203272977662\n",
      "Iteration 17171 => Loss: 49.04065804092188329832\n",
      "Iteration 17172 => Loss: 49.04047360125852605961\n",
      "Iteration 17173 => Loss: 49.04028916304265095505\n",
      "Iteration 17174 => Loss: 49.04010472627422956293\n",
      "Iteration 17175 => Loss: 49.03992029095324767241\n",
      "Iteration 17176 => Loss: 49.03973585707972659975\n",
      "Iteration 17177 => Loss: 49.03955142465362371240\n",
      "Iteration 17178 => Loss: 49.03936699367493190493\n",
      "Iteration 17179 => Loss: 49.03918256414364407192\n",
      "Iteration 17180 => Loss: 49.03899813605976021336\n",
      "Iteration 17181 => Loss: 49.03881370942325190754\n",
      "Iteration 17182 => Loss: 49.03862928423410494361\n",
      "Iteration 17183 => Loss: 49.03844486049234063785\n",
      "Iteration 17184 => Loss: 49.03826043819790214684\n",
      "Iteration 17185 => Loss: 49.03807601735079657601\n",
      "Iteration 17186 => Loss: 49.03789159795103813622\n",
      "Iteration 17187 => Loss: 49.03770717999856287861\n",
      "Iteration 17188 => Loss: 49.03752276349342054118\n",
      "Iteration 17189 => Loss: 49.03733834843556849137\n",
      "Iteration 17190 => Loss: 49.03715393482497120203\n",
      "Iteration 17191 => Loss: 49.03696952266167130574\n",
      "Iteration 17192 => Loss: 49.03678511194560485364\n",
      "Iteration 17193 => Loss: 49.03660070267678605660\n",
      "Iteration 17194 => Loss: 49.03641629485522912546\n",
      "Iteration 17195 => Loss: 49.03623188848085590053\n",
      "Iteration 17196 => Loss: 49.03604748355371611979\n",
      "Iteration 17197 => Loss: 49.03586308007376715068\n",
      "Iteration 17198 => Loss: 49.03567867804102320406\n",
      "Iteration 17199 => Loss: 49.03549427745543454193\n",
      "Iteration 17200 => Loss: 49.03530987831703669144\n",
      "Iteration 17201 => Loss: 49.03512548062577991459\n",
      "Iteration 17202 => Loss: 49.03494108438167131681\n",
      "Iteration 17203 => Loss: 49.03475668958467537095\n",
      "Iteration 17204 => Loss: 49.03457229623483470959\n",
      "Iteration 17205 => Loss: 49.03438790433207117303\n",
      "Iteration 17206 => Loss: 49.03420351387642028840\n",
      "Iteration 17207 => Loss: 49.03401912486784652856\n",
      "Iteration 17208 => Loss: 49.03383473730634989352\n",
      "Iteration 17209 => Loss: 49.03365035119192327784\n",
      "Iteration 17210 => Loss: 49.03346596652455957610\n",
      "Iteration 17211 => Loss: 49.03328158330421615574\n",
      "Iteration 17212 => Loss: 49.03309720153092143846\n",
      "Iteration 17213 => Loss: 49.03291282120463279171\n",
      "Iteration 17214 => Loss: 49.03272844232534311004\n",
      "Iteration 17215 => Loss: 49.03254406489307370975\n",
      "Iteration 17216 => Loss: 49.03235968890776774742\n",
      "Iteration 17217 => Loss: 49.03217531436943943390\n",
      "Iteration 17218 => Loss: 49.03199094127809587462\n",
      "Iteration 17219 => Loss: 49.03180656963366601531\n",
      "Iteration 17220 => Loss: 49.03162219943620669937\n",
      "Iteration 17221 => Loss: 49.03143783068563266170\n",
      "Iteration 17222 => Loss: 49.03125346338202206198\n",
      "Iteration 17223 => Loss: 49.03106909752530384594\n",
      "Iteration 17224 => Loss: 49.03088473311546380273\n",
      "Iteration 17225 => Loss: 49.03070037015251614321\n",
      "Iteration 17226 => Loss: 49.03051600863642534023\n",
      "Iteration 17227 => Loss: 49.03033164856722692093\n",
      "Iteration 17228 => Loss: 49.03014728994484272562\n",
      "Iteration 17229 => Loss: 49.02996293276930117599\n",
      "Iteration 17230 => Loss: 49.02977857704060227206\n",
      "Iteration 17231 => Loss: 49.02959422275871048669\n",
      "Iteration 17232 => Loss: 49.02940986992360450358\n",
      "Iteration 17233 => Loss: 49.02922551853531274446\n",
      "Iteration 17234 => Loss: 49.02904116859379257676\n",
      "Iteration 17235 => Loss: 49.02885682009901557876\n",
      "Iteration 17236 => Loss: 49.02867247305105280475\n",
      "Iteration 17237 => Loss: 49.02848812744978346245\n",
      "Iteration 17238 => Loss: 49.02830378329527860615\n",
      "Iteration 17239 => Loss: 49.02811944058747428699\n",
      "Iteration 17240 => Loss: 49.02793509932640603211\n",
      "Iteration 17241 => Loss: 49.02775075951202410351\n",
      "Iteration 17242 => Loss: 49.02756642114432850121\n",
      "Iteration 17243 => Loss: 49.02738208422332633063\n",
      "Iteration 17244 => Loss: 49.02719774874896785377\n",
      "Iteration 17245 => Loss: 49.02701341472128859778\n",
      "Iteration 17246 => Loss: 49.02682908214023882465\n",
      "Iteration 17247 => Loss: 49.02664475100583274525\n",
      "Iteration 17248 => Loss: 49.02646042131803483244\n",
      "Iteration 17249 => Loss: 49.02627609307683798079\n",
      "Iteration 17250 => Loss: 49.02609176628224929573\n",
      "Iteration 17251 => Loss: 49.02590744093424746097\n",
      "Iteration 17252 => Loss: 49.02572311703283247653\n",
      "Iteration 17253 => Loss: 49.02553879457797592067\n",
      "Iteration 17254 => Loss: 49.02535447356966358257\n",
      "Iteration 17255 => Loss: 49.02517015400790256763\n",
      "Iteration 17256 => Loss: 49.02498583589265734872\n",
      "Iteration 17257 => Loss: 49.02480151922394924213\n",
      "Iteration 17258 => Loss: 49.02461720400175693158\n",
      "Iteration 17259 => Loss: 49.02443289022603778449\n",
      "Iteration 17260 => Loss: 49.02424857789681311715\n",
      "Iteration 17261 => Loss: 49.02406426701405450785\n",
      "Iteration 17262 => Loss: 49.02387995757776906203\n",
      "Iteration 17263 => Loss: 49.02369564958793546339\n",
      "Iteration 17264 => Loss: 49.02351134304453239565\n",
      "Iteration 17265 => Loss: 49.02332703794755985882\n",
      "Iteration 17266 => Loss: 49.02314273429698232576\n",
      "Iteration 17267 => Loss: 49.02295843209284953446\n",
      "Iteration 17268 => Loss: 49.02277413133508332521\n",
      "Iteration 17269 => Loss: 49.02258983202371211974\n",
      "Iteration 17270 => Loss: 49.02240553415871460174\n",
      "Iteration 17271 => Loss: 49.02222123774006945496\n",
      "Iteration 17272 => Loss: 49.02203694276776957395\n",
      "Iteration 17273 => Loss: 49.02185264924180074786\n",
      "Iteration 17274 => Loss: 49.02166835716218429297\n",
      "Iteration 17275 => Loss: 49.02148406652886336587\n",
      "Iteration 17276 => Loss: 49.02129977734185217741\n",
      "Iteration 17277 => Loss: 49.02111548960111520046\n",
      "Iteration 17278 => Loss: 49.02093120330667375129\n",
      "Iteration 17279 => Loss: 49.02074691845852072447\n",
      "Iteration 17280 => Loss: 49.02056263505659927660\n",
      "Iteration 17281 => Loss: 49.02037835310092361851\n",
      "Iteration 17282 => Loss: 49.02019407259149375022\n",
      "Iteration 17283 => Loss: 49.02000979352827414459\n",
      "Iteration 17284 => Loss: 49.01982551591128611790\n",
      "Iteration 17285 => Loss: 49.01964123974048703758\n",
      "Iteration 17286 => Loss: 49.01945696501587690364\n",
      "Iteration 17287 => Loss: 49.01927269173744861064\n",
      "Iteration 17288 => Loss: 49.01908841990518084231\n",
      "Iteration 17289 => Loss: 49.01890414951908070407\n",
      "Iteration 17290 => Loss: 49.01871988057912687964\n",
      "Iteration 17291 => Loss: 49.01853561308531226359\n",
      "Iteration 17292 => Loss: 49.01835134703760132879\n",
      "Iteration 17293 => Loss: 49.01816708243599407524\n",
      "Iteration 17294 => Loss: 49.01798281928050471379\n",
      "Iteration 17295 => Loss: 49.01779855757109771730\n",
      "Iteration 17296 => Loss: 49.01761429730776598035\n",
      "Iteration 17297 => Loss: 49.01743003849049529208\n",
      "Iteration 17298 => Loss: 49.01724578111925723078\n",
      "Iteration 17299 => Loss: 49.01706152519409442903\n",
      "Iteration 17300 => Loss: 49.01687727071495714881\n",
      "Iteration 17301 => Loss: 49.01669301768183117929\n",
      "Iteration 17302 => Loss: 49.01650876609471652046\n",
      "Iteration 17303 => Loss: 49.01632451595359896146\n",
      "Iteration 17304 => Loss: 49.01614026725845718602\n",
      "Iteration 17305 => Loss: 49.01595602000931251041\n",
      "Iteration 17306 => Loss: 49.01577177420612230208\n",
      "Iteration 17307 => Loss: 49.01558752984887235016\n",
      "Iteration 17308 => Loss: 49.01540328693756265466\n",
      "Iteration 17309 => Loss: 49.01521904547218611015\n",
      "Iteration 17310 => Loss: 49.01503480545271429492\n",
      "Iteration 17311 => Loss: 49.01485056687918273610\n",
      "Iteration 17312 => Loss: 49.01466632975152037943\n",
      "Iteration 17313 => Loss: 49.01448209406973433033\n",
      "Iteration 17314 => Loss: 49.01429785983383879966\n",
      "Iteration 17315 => Loss: 49.01411362704380536570\n",
      "Iteration 17316 => Loss: 49.01392939569959850132\n",
      "Iteration 17317 => Loss: 49.01374516580124662823\n",
      "Iteration 17318 => Loss: 49.01356093734871421930\n",
      "Iteration 17319 => Loss: 49.01337671034200127451\n",
      "Iteration 17320 => Loss: 49.01319248478109358302\n",
      "Iteration 17321 => Loss: 49.01300826066599114483\n",
      "Iteration 17322 => Loss: 49.01282403799665843280\n",
      "Iteration 17323 => Loss: 49.01263981677308123608\n",
      "Iteration 17324 => Loss: 49.01245559699528087094\n",
      "Iteration 17325 => Loss: 49.01227137866320759940\n",
      "Iteration 17326 => Loss: 49.01208716177688273774\n",
      "Iteration 17327 => Loss: 49.01190294633627786425\n",
      "Iteration 17328 => Loss: 49.01171873234140008435\n",
      "Iteration 17329 => Loss: 49.01153451979220676549\n",
      "Iteration 17330 => Loss: 49.01135030868871211851\n",
      "Iteration 17331 => Loss: 49.01116609903089482714\n",
      "Iteration 17332 => Loss: 49.01098189081874778594\n",
      "Iteration 17333 => Loss: 49.01079768405226388950\n",
      "Iteration 17334 => Loss: 49.01061347873139339981\n",
      "Iteration 17335 => Loss: 49.01042927485619316030\n",
      "Iteration 17336 => Loss: 49.01024507242659211670\n",
      "Iteration 17337 => Loss: 49.01006087144261869071\n",
      "Iteration 17338 => Loss: 49.00987667190424446062\n",
      "Iteration 17339 => Loss: 49.00969247381145521558\n",
      "Iteration 17340 => Loss: 49.00950827716424385017\n",
      "Iteration 17341 => Loss: 49.00932408196258904809\n",
      "Iteration 17342 => Loss: 49.00913988820647659850\n",
      "Iteration 17343 => Loss: 49.00895569589592781767\n",
      "Iteration 17344 => Loss: 49.00877150503090717848\n",
      "Iteration 17345 => Loss: 49.00858731561141468092\n",
      "Iteration 17346 => Loss: 49.00840312763742190327\n",
      "Iteration 17347 => Loss: 49.00821894110894305641\n",
      "Iteration 17348 => Loss: 49.00803475602591419147\n",
      "Iteration 17349 => Loss: 49.00785057238838504645\n",
      "Iteration 17350 => Loss: 49.00766639019632719965\n",
      "Iteration 17351 => Loss: 49.00748220944969801849\n",
      "Iteration 17352 => Loss: 49.00729803014852592469\n",
      "Iteration 17353 => Loss: 49.00711385229276828568\n",
      "Iteration 17354 => Loss: 49.00692967588243931232\n",
      "Iteration 17355 => Loss: 49.00674550091753900460\n",
      "Iteration 17356 => Loss: 49.00656132739798209741\n",
      "Iteration 17357 => Loss: 49.00637715532383964501\n",
      "Iteration 17358 => Loss: 49.00619298469506190941\n",
      "Iteration 17359 => Loss: 49.00600881551166310146\n",
      "Iteration 17360 => Loss: 49.00582464777360769403\n",
      "Iteration 17361 => Loss: 49.00564048148088858170\n",
      "Iteration 17362 => Loss: 49.00545631663348444818\n",
      "Iteration 17363 => Loss: 49.00527215323141660974\n",
      "Iteration 17364 => Loss: 49.00508799127464953926\n",
      "Iteration 17365 => Loss: 49.00490383076316192046\n",
      "Iteration 17366 => Loss: 49.00471967169695375333\n",
      "Iteration 17367 => Loss: 49.00453551407604635415\n",
      "Iteration 17368 => Loss: 49.00435135790036866865\n",
      "Iteration 17369 => Loss: 49.00416720316995622397\n",
      "Iteration 17370 => Loss: 49.00398304988477349298\n",
      "Iteration 17371 => Loss: 49.00379889804482758109\n",
      "Iteration 17372 => Loss: 49.00361474765007585574\n",
      "Iteration 17373 => Loss: 49.00343059870053252780\n",
      "Iteration 17374 => Loss: 49.00324645119618338640\n",
      "Iteration 17375 => Loss: 49.00306230513701422069\n",
      "Iteration 17376 => Loss: 49.00287816052301081982\n",
      "Iteration 17377 => Loss: 49.00269401735415897292\n",
      "Iteration 17378 => Loss: 49.00250987563047999629\n",
      "Iteration 17379 => Loss: 49.00232573535190994107\n",
      "Iteration 17380 => Loss: 49.00214159651846301813\n",
      "Iteration 17381 => Loss: 49.00195745913011080575\n",
      "Iteration 17382 => Loss: 49.00177332318691014734\n",
      "Iteration 17383 => Loss: 49.00158918868876867236\n",
      "Iteration 17384 => Loss: 49.00140505563570059167\n",
      "Iteration 17385 => Loss: 49.00122092402771301067\n",
      "Iteration 17386 => Loss: 49.00103679386477750768\n",
      "Iteration 17387 => Loss: 49.00085266514686566097\n",
      "Iteration 17388 => Loss: 49.00066853787402010312\n",
      "Iteration 17389 => Loss: 49.00048441204616977984\n",
      "Iteration 17390 => Loss: 49.00030028766335732371\n",
      "Iteration 17391 => Loss: 49.00011616472550457502\n",
      "Iteration 17392 => Loss: 48.99993204323268258804\n",
      "Iteration 17393 => Loss: 48.99974792318478478137\n",
      "Iteration 17394 => Loss: 48.99956380458188220928\n",
      "Iteration 17395 => Loss: 48.99937968742395355548\n",
      "Iteration 17396 => Loss: 48.99919557171092776571\n",
      "Iteration 17397 => Loss: 48.99901145744284747252\n",
      "Iteration 17398 => Loss: 48.99882734461965583250\n",
      "Iteration 17399 => Loss: 48.99864323324141679450\n",
      "Iteration 17400 => Loss: 48.99845912330805930424\n",
      "Iteration 17401 => Loss: 48.99827501481959046714\n",
      "Iteration 17402 => Loss: 48.99809090777599607236\n",
      "Iteration 17403 => Loss: 48.99790680217725480361\n",
      "Iteration 17404 => Loss: 48.99772269802337376632\n",
      "Iteration 17405 => Loss: 48.99753859531433164420\n",
      "Iteration 17406 => Loss: 48.99735449405010712098\n",
      "Iteration 17407 => Loss: 48.99717039423070019666\n",
      "Iteration 17408 => Loss: 48.99698629585611797665\n",
      "Iteration 17409 => Loss: 48.99680219892631782841\n",
      "Iteration 17410 => Loss: 48.99661810344129264649\n",
      "Iteration 17411 => Loss: 48.99643400940106374719\n",
      "Iteration 17412 => Loss: 48.99624991680556007623\n",
      "Iteration 17413 => Loss: 48.99606582565482426617\n",
      "Iteration 17414 => Loss: 48.99588173594882789530\n",
      "Iteration 17415 => Loss: 48.99569764768756385820\n",
      "Iteration 17416 => Loss: 48.99551356087100373315\n",
      "Iteration 17417 => Loss: 48.99532947549914041474\n",
      "Iteration 17418 => Loss: 48.99514539157200232466\n",
      "Iteration 17419 => Loss: 48.99496130908948998695\n",
      "Iteration 17420 => Loss: 48.99477722805170287756\n",
      "Iteration 17421 => Loss: 48.99459314845853441511\n",
      "Iteration 17422 => Loss: 48.99440907031004854844\n",
      "Iteration 17423 => Loss: 48.99422499360616001240\n",
      "Iteration 17424 => Loss: 48.99404091834691143958\n",
      "Iteration 17425 => Loss: 48.99385684453229572455\n",
      "Iteration 17426 => Loss: 48.99367277216224891845\n",
      "Iteration 17427 => Loss: 48.99348870123680654842\n",
      "Iteration 17428 => Loss: 48.99330463175594729819\n",
      "Iteration 17429 => Loss: 48.99312056371965695689\n",
      "Iteration 17430 => Loss: 48.99293649712790710282\n",
      "Iteration 17431 => Loss: 48.99275243198074036854\n",
      "Iteration 17432 => Loss: 48.99256836827805727808\n",
      "Iteration 17433 => Loss: 48.99238430601992888569\n",
      "Iteration 17434 => Loss: 48.99220024520628413711\n",
      "Iteration 17435 => Loss: 48.99201618583717277033\n",
      "Iteration 17436 => Loss: 48.99183212791253083651\n",
      "Iteration 17437 => Loss: 48.99164807143236544107\n",
      "Iteration 17438 => Loss: 48.99146401639667658401\n",
      "Iteration 17439 => Loss: 48.99127996280543584362\n",
      "Iteration 17440 => Loss: 48.99109591065864321990\n",
      "Iteration 17441 => Loss: 48.99091185995626318572\n",
      "Iteration 17442 => Loss: 48.99072781069831705736\n",
      "Iteration 17443 => Loss: 48.99054376288477641310\n",
      "Iteration 17444 => Loss: 48.99035971651563414753\n",
      "Iteration 17445 => Loss: 48.99017567159089736606\n",
      "Iteration 17446 => Loss: 48.98999162811049501443\n",
      "Iteration 17447 => Loss: 48.98980758607448393604\n",
      "Iteration 17448 => Loss: 48.98962354548282860378\n",
      "Iteration 17449 => Loss: 48.98943950633550770135\n",
      "Iteration 17450 => Loss: 48.98925546863251412333\n",
      "Iteration 17451 => Loss: 48.98907143237382655343\n",
      "Iteration 17452 => Loss: 48.98888739755946630794\n",
      "Iteration 17453 => Loss: 48.98870336418939075429\n",
      "Iteration 17454 => Loss: 48.98851933226359989249\n",
      "Iteration 17455 => Loss: 48.98833530178209372252\n",
      "Iteration 17456 => Loss: 48.98815127274482250641\n",
      "Iteration 17457 => Loss: 48.98796724515182177129\n",
      "Iteration 17458 => Loss: 48.98778321900305599002\n",
      "Iteration 17459 => Loss: 48.98759919429851095174\n",
      "Iteration 17460 => Loss: 48.98741517103819376189\n",
      "Iteration 17461 => Loss: 48.98723114922208310418\n",
      "Iteration 17462 => Loss: 48.98704712885015766233\n",
      "Iteration 17463 => Loss: 48.98686310992242454176\n",
      "Iteration 17464 => Loss: 48.98667909243884821535\n",
      "Iteration 17465 => Loss: 48.98649507639944289394\n",
      "Iteration 17466 => Loss: 48.98631106180417305040\n",
      "Iteration 17467 => Loss: 48.98612704865303157931\n",
      "Iteration 17468 => Loss: 48.98594303694606111321\n",
      "Iteration 17469 => Loss: 48.98575902668316928157\n",
      "Iteration 17470 => Loss: 48.98557501786437740066\n",
      "Iteration 17471 => Loss: 48.98539101048969968133\n",
      "Iteration 17472 => Loss: 48.98520700455908638560\n",
      "Iteration 17473 => Loss: 48.98502300007253751346\n",
      "Iteration 17474 => Loss: 48.98483899703003885406\n",
      "Iteration 17475 => Loss: 48.98465499543159751283\n",
      "Iteration 17476 => Loss: 48.98447099527718506806\n",
      "Iteration 17477 => Loss: 48.98428699656681573060\n",
      "Iteration 17478 => Loss: 48.98410299930045397332\n",
      "Iteration 17479 => Loss: 48.98391900347808558536\n",
      "Iteration 17480 => Loss: 48.98373500909971056672\n",
      "Iteration 17481 => Loss: 48.98355101616529339026\n",
      "Iteration 17482 => Loss: 48.98336702467486958312\n",
      "Iteration 17483 => Loss: 48.98318303462838230189\n",
      "Iteration 17484 => Loss: 48.98299904602585286284\n",
      "Iteration 17485 => Loss: 48.98281505886725994969\n",
      "Iteration 17486 => Loss: 48.98263107315257514074\n",
      "Iteration 17487 => Loss: 48.98244708888180554140\n",
      "Iteration 17488 => Loss: 48.98226310605494404626\n",
      "Iteration 17489 => Loss: 48.98207912467196223361\n",
      "Iteration 17490 => Loss: 48.98189514473283878715\n",
      "Iteration 17491 => Loss: 48.98171116623760212860\n",
      "Iteration 17492 => Loss: 48.98152718918622383626\n",
      "Iteration 17493 => Loss: 48.98134321357868259383\n",
      "Iteration 17494 => Loss: 48.98115923941495708505\n",
      "Iteration 17495 => Loss: 48.98097526669506862618\n",
      "Iteration 17496 => Loss: 48.98079129541898169009\n",
      "Iteration 17497 => Loss: 48.98060732558671048764\n",
      "Iteration 17498 => Loss: 48.98042335719818396456\n",
      "Iteration 17499 => Loss: 48.98023939025345896425\n",
      "Iteration 17500 => Loss: 48.98005542475247864331\n",
      "Iteration 17501 => Loss: 48.97987146069527852887\n",
      "Iteration 17502 => Loss: 48.97968749808178756666\n",
      "Iteration 17503 => Loss: 48.97950353691204838924\n",
      "Iteration 17504 => Loss: 48.97931957718602546947\n",
      "Iteration 17505 => Loss: 48.97913561890369749108\n",
      "Iteration 17506 => Loss: 48.97895166206505024320\n",
      "Iteration 17507 => Loss: 48.97876770667013346383\n",
      "Iteration 17508 => Loss: 48.97858375271885478242\n",
      "Iteration 17509 => Loss: 48.97839980021124262066\n",
      "Iteration 17510 => Loss: 48.97821584914726855686\n",
      "Iteration 17511 => Loss: 48.97803189952695390730\n",
      "Iteration 17512 => Loss: 48.97784795135026314483\n",
      "Iteration 17513 => Loss: 48.97766400461717495318\n",
      "Iteration 17514 => Loss: 48.97748005932769643778\n",
      "Iteration 17515 => Loss: 48.97729611548181338776\n",
      "Iteration 17516 => Loss: 48.97711217307951159228\n",
      "Iteration 17517 => Loss: 48.97692823212078394590\n",
      "Iteration 17518 => Loss: 48.97674429260561623778\n",
      "Iteration 17519 => Loss: 48.97656035453398004620\n",
      "Iteration 17520 => Loss: 48.97637641790588958202\n",
      "Iteration 17521 => Loss: 48.97619248272131642352\n",
      "Iteration 17522 => Loss: 48.97600854898027478157\n",
      "Iteration 17523 => Loss: 48.97582461668272912902\n",
      "Iteration 17524 => Loss: 48.97564068582867236046\n",
      "Iteration 17525 => Loss: 48.97545675641809026502\n",
      "Iteration 17526 => Loss: 48.97527282845098284270\n",
      "Iteration 17527 => Loss: 48.97508890192732167179\n",
      "Iteration 17528 => Loss: 48.97490497684710675230\n",
      "Iteration 17529 => Loss: 48.97472105321035229508\n",
      "Iteration 17530 => Loss: 48.97453713101700145671\n",
      "Iteration 17531 => Loss: 48.97435321026707555347\n",
      "Iteration 17532 => Loss: 48.97416929096054616366\n",
      "Iteration 17533 => Loss: 48.97398537309736354928\n",
      "Iteration 17534 => Loss: 48.97380145667759876460\n",
      "Iteration 17535 => Loss: 48.97361754170120917706\n",
      "Iteration 17536 => Loss: 48.97343362816815215410\n",
      "Iteration 17537 => Loss: 48.97324971607844190657\n",
      "Iteration 17538 => Loss: 48.97306580543206422362\n",
      "Iteration 17539 => Loss: 48.97288189622903331610\n",
      "Iteration 17540 => Loss: 48.97269798846927812974\n",
      "Iteration 17541 => Loss: 48.97251408215284129710\n",
      "Iteration 17542 => Loss: 48.97233017727968729105\n",
      "Iteration 17543 => Loss: 48.97214627384980190072\n",
      "Iteration 17544 => Loss: 48.97196237186318512613\n",
      "Iteration 17545 => Loss: 48.97177847131981565099\n",
      "Iteration 17546 => Loss: 48.97159457221968636986\n",
      "Iteration 17547 => Loss: 48.97141067456281149362\n",
      "Iteration 17548 => Loss: 48.97122677834914128425\n",
      "Iteration 17549 => Loss: 48.97104288357866863635\n",
      "Iteration 17550 => Loss: 48.97085899025141486618\n",
      "Iteration 17551 => Loss: 48.97067509836731602491\n",
      "Iteration 17552 => Loss: 48.97049120792642185052\n",
      "Iteration 17553 => Loss: 48.97030731892866128874\n",
      "Iteration 17554 => Loss: 48.97012343137406276128\n",
      "Iteration 17555 => Loss: 48.96993954526262626814\n",
      "Iteration 17556 => Loss: 48.96975566059428786048\n",
      "Iteration 17557 => Loss: 48.96957177736909017085\n",
      "Iteration 17558 => Loss: 48.96938789558697635584\n",
      "Iteration 17559 => Loss: 48.96920401524795352088\n",
      "Iteration 17560 => Loss: 48.96902013635204298225\n",
      "Iteration 17561 => Loss: 48.96883625889918789653\n",
      "Iteration 17562 => Loss: 48.96865238288939536915\n",
      "Iteration 17563 => Loss: 48.96846850832264408382\n",
      "Iteration 17564 => Loss: 48.96828463519894825140\n",
      "Iteration 17565 => Loss: 48.96810076351825813390\n",
      "Iteration 17566 => Loss: 48.96791689328058794217\n",
      "Iteration 17567 => Loss: 48.96773302448593767622\n",
      "Iteration 17568 => Loss: 48.96754915713427180890\n",
      "Iteration 17569 => Loss: 48.96736529122557612936\n",
      "Iteration 17570 => Loss: 48.96718142675985774304\n",
      "Iteration 17571 => Loss: 48.96699756373710954449\n",
      "Iteration 17572 => Loss: 48.96681370215728890116\n",
      "Iteration 17573 => Loss: 48.96662984202041712933\n",
      "Iteration 17574 => Loss: 48.96644598332646580729\n",
      "Iteration 17575 => Loss: 48.96626212607543493505\n",
      "Iteration 17576 => Loss: 48.96607827026729609088\n",
      "Iteration 17577 => Loss: 48.96589441590206348565\n",
      "Iteration 17578 => Loss: 48.96571056297968027593\n",
      "Iteration 17579 => Loss: 48.96552671150018909429\n",
      "Iteration 17580 => Loss: 48.96534286146355441360\n",
      "Iteration 17581 => Loss: 48.96515901286975491757\n",
      "Iteration 17582 => Loss: 48.96497516571881902792\n",
      "Iteration 17583 => Loss: 48.96479132001064726865\n",
      "Iteration 17584 => Loss: 48.96460747574533911575\n",
      "Iteration 17585 => Loss: 48.96442363292281640952\n",
      "Iteration 17586 => Loss: 48.96423979154307204453\n",
      "Iteration 17587 => Loss: 48.96405595160612023165\n",
      "Iteration 17588 => Loss: 48.96387211311191123286\n",
      "Iteration 17589 => Loss: 48.96368827606048057532\n",
      "Iteration 17590 => Loss: 48.96350444045178562646\n",
      "Iteration 17591 => Loss: 48.96332060628581217543\n",
      "Iteration 17592 => Loss: 48.96313677356256732764\n",
      "Iteration 17593 => Loss: 48.96295294228204397768\n",
      "Iteration 17594 => Loss: 48.96276911244419949298\n",
      "Iteration 17595 => Loss: 48.96258528404907650611\n",
      "Iteration 17596 => Loss: 48.96240145709661106821\n",
      "Iteration 17597 => Loss: 48.96221763158676765215\n",
      "Iteration 17598 => Loss: 48.96203380751962441764\n",
      "Iteration 17599 => Loss: 48.96184998489511031039\n",
      "Iteration 17600 => Loss: 48.96166616371323243584\n",
      "Iteration 17601 => Loss: 48.96148234397396947770\n",
      "Iteration 17602 => Loss: 48.96129852567731433055\n",
      "Iteration 17603 => Loss: 48.96111470882323857268\n",
      "Iteration 17604 => Loss: 48.96093089341179194207\n",
      "Iteration 17605 => Loss: 48.96074707944286785732\n",
      "Iteration 17606 => Loss: 48.96056326691654447814\n",
      "Iteration 17607 => Loss: 48.96037945583275075023\n",
      "Iteration 17608 => Loss: 48.96019564619149377904\n",
      "Iteration 17609 => Loss: 48.96001183799276645914\n",
      "Iteration 17610 => Loss: 48.95982803123656168509\n",
      "Iteration 17611 => Loss: 48.95964422592287235148\n",
      "Iteration 17612 => Loss: 48.95946042205165582573\n",
      "Iteration 17613 => Loss: 48.95927661962294052955\n",
      "Iteration 17614 => Loss: 48.95909281863671225210\n",
      "Iteration 17615 => Loss: 48.95890901909291414995\n",
      "Iteration 17616 => Loss: 48.95872522099156753939\n",
      "Iteration 17617 => Loss: 48.95854142433266531498\n",
      "Iteration 17618 => Loss: 48.95835762911620037130\n",
      "Iteration 17619 => Loss: 48.95817383534213718121\n",
      "Iteration 17620 => Loss: 48.95799004301048285015\n",
      "Iteration 17621 => Loss: 48.95780625212122316725\n",
      "Iteration 17622 => Loss: 48.95762246267435102709\n",
      "Iteration 17623 => Loss: 48.95743867466984511339\n",
      "Iteration 17624 => Loss: 48.95725488810767700443\n",
      "Iteration 17625 => Loss: 48.95707110298785380564\n",
      "Iteration 17626 => Loss: 48.95688731931040393874\n",
      "Iteration 17627 => Loss: 48.95670353707524924403\n",
      "Iteration 17628 => Loss: 48.95651975628243235406\n",
      "Iteration 17629 => Loss: 48.95633597693187510913\n",
      "Iteration 17630 => Loss: 48.95615219902364856353\n",
      "Iteration 17631 => Loss: 48.95596842255768876839\n",
      "Iteration 17632 => Loss: 48.95578464753400993459\n",
      "Iteration 17633 => Loss: 48.95560087395256942955\n",
      "Iteration 17634 => Loss: 48.95541710181338146413\n",
      "Iteration 17635 => Loss: 48.95523333111642472204\n",
      "Iteration 17636 => Loss: 48.95504956186169209786\n",
      "Iteration 17637 => Loss: 48.95486579404916938074\n",
      "Iteration 17638 => Loss: 48.95468202767884235982\n",
      "Iteration 17639 => Loss: 48.95449826275071103510\n",
      "Iteration 17640 => Loss: 48.95431449926476119572\n",
      "Iteration 17641 => Loss: 48.95413073722095020912\n",
      "Iteration 17642 => Loss: 48.95394697661933491872\n",
      "Iteration 17643 => Loss: 48.95376321745983716482\n",
      "Iteration 17644 => Loss: 48.95357945974248536913\n",
      "Iteration 17645 => Loss: 48.95339570346724400451\n",
      "Iteration 17646 => Loss: 48.95321194863410596554\n",
      "Iteration 17647 => Loss: 48.95302819524309256849\n",
      "Iteration 17648 => Loss: 48.95284444329413986452\n",
      "Iteration 17649 => Loss: 48.95266069278726916991\n",
      "Iteration 17650 => Loss: 48.95247694372246627381\n",
      "Iteration 17651 => Loss: 48.95229319609972407079\n",
      "Iteration 17652 => Loss: 48.95210944991902124457\n",
      "Iteration 17653 => Loss: 48.95192570518033647886\n",
      "Iteration 17654 => Loss: 48.95174196188367687910\n",
      "Iteration 17655 => Loss: 48.95155822002902823442\n",
      "Iteration 17656 => Loss: 48.95137447961636922855\n",
      "Iteration 17657 => Loss: 48.95119074064569275606\n",
      "Iteration 17658 => Loss: 48.95100700311699881695\n",
      "Iteration 17659 => Loss: 48.95082326703028030579\n",
      "Iteration 17660 => Loss: 48.95063953238549459002\n",
      "Iteration 17661 => Loss: 48.95045579918264166963\n",
      "Iteration 17662 => Loss: 48.95027206742172865006\n",
      "Iteration 17663 => Loss: 48.95008833710272710960\n",
      "Iteration 17664 => Loss: 48.94990460822564415366\n",
      "Iteration 17665 => Loss: 48.94972088079045136055\n",
      "Iteration 17666 => Loss: 48.94953715479714162484\n",
      "Iteration 17667 => Loss: 48.94935343024569363024\n",
      "Iteration 17668 => Loss: 48.94916970713609316590\n",
      "Iteration 17669 => Loss: 48.94898598546838286438\n",
      "Iteration 17670 => Loss: 48.94880226524248456599\n",
      "Iteration 17671 => Loss: 48.94861854645841958700\n",
      "Iteration 17672 => Loss: 48.94843482911615950570\n",
      "Iteration 17673 => Loss: 48.94825111321571853296\n",
      "Iteration 17674 => Loss: 48.94806739875706824705\n",
      "Iteration 17675 => Loss: 48.94788368574019443713\n",
      "Iteration 17676 => Loss: 48.94769997416507578691\n",
      "Iteration 17677 => Loss: 48.94751626403175492896\n",
      "Iteration 17678 => Loss: 48.94733255534014659816\n",
      "Iteration 17679 => Loss: 48.94714884809028632162\n",
      "Iteration 17680 => Loss: 48.94696514228214567765\n",
      "Iteration 17681 => Loss: 48.94678143791573177168\n",
      "Iteration 17682 => Loss: 48.94659773499100907657\n",
      "Iteration 17683 => Loss: 48.94641403350797048688\n",
      "Iteration 17684 => Loss: 48.94623033346663021348\n",
      "Iteration 17685 => Loss: 48.94604663486693851837\n",
      "Iteration 17686 => Loss: 48.94586293770893092869\n",
      "Iteration 17687 => Loss: 48.94567924199252928474\n",
      "Iteration 17688 => Loss: 48.94549554771779753537\n",
      "Iteration 17689 => Loss: 48.94531185488467173172\n",
      "Iteration 17690 => Loss: 48.94512816349317319009\n",
      "Iteration 17691 => Loss: 48.94494447354325217248\n",
      "Iteration 17692 => Loss: 48.94476078503492288974\n",
      "Iteration 17693 => Loss: 48.94457709796819244730\n",
      "Iteration 17694 => Loss: 48.94439341234301110717\n",
      "Iteration 17695 => Loss: 48.94420972815939308020\n",
      "Iteration 17696 => Loss: 48.94402604541730283927\n",
      "Iteration 17697 => Loss: 48.94384236411676880607\n",
      "Iteration 17698 => Loss: 48.94365868425774124262\n",
      "Iteration 17699 => Loss: 48.94347500584022014891\n",
      "Iteration 17700 => Loss: 48.94329132886421263038\n",
      "Iteration 17701 => Loss: 48.94310765332966184360\n",
      "Iteration 17702 => Loss: 48.94292397923663884285\n",
      "Iteration 17703 => Loss: 48.94274030658504415214\n",
      "Iteration 17704 => Loss: 48.94255663537491329862\n",
      "Iteration 17705 => Loss: 48.94237296560621075514\n",
      "Iteration 17706 => Loss: 48.94218929727895783799\n",
      "Iteration 17707 => Loss: 48.94200563039311191460\n",
      "Iteration 17708 => Loss: 48.94182196494868009040\n",
      "Iteration 17709 => Loss: 48.94163830094564104911\n",
      "Iteration 17710 => Loss: 48.94145463838398057987\n",
      "Iteration 17711 => Loss: 48.94127097726370578812\n",
      "Iteration 17712 => Loss: 48.94108731758478114671\n",
      "Iteration 17713 => Loss: 48.94090365934722797192\n",
      "Iteration 17714 => Loss: 48.94072000255099652577\n",
      "Iteration 17715 => Loss: 48.94053634719610101911\n",
      "Iteration 17716 => Loss: 48.94035269328253434651\n",
      "Iteration 17717 => Loss: 48.94016904081024676998\n",
      "Iteration 17718 => Loss: 48.93998538977926671123\n",
      "Iteration 17719 => Loss: 48.93980174018959417026\n",
      "Iteration 17720 => Loss: 48.93961809204115809280\n",
      "Iteration 17721 => Loss: 48.93943444533400821683\n",
      "Iteration 17722 => Loss: 48.93925080006809480437\n",
      "Iteration 17723 => Loss: 48.93906715624343206628\n",
      "Iteration 17724 => Loss: 48.93888351385998447540\n",
      "Iteration 17725 => Loss: 48.93869987291775203175\n",
      "Iteration 17726 => Loss: 48.93851623341672052447\n",
      "Iteration 17727 => Loss: 48.93833259535690416442\n",
      "Iteration 17728 => Loss: 48.93814895873824610817\n",
      "Iteration 17729 => Loss: 48.93796532356078188286\n",
      "Iteration 17730 => Loss: 48.93778168982445464508\n",
      "Iteration 17731 => Loss: 48.93759805752926439482\n",
      "Iteration 17732 => Loss: 48.93741442667523955379\n",
      "Iteration 17733 => Loss: 48.93723079726233038400\n",
      "Iteration 17734 => Loss: 48.93704716929052978003\n",
      "Iteration 17735 => Loss: 48.93686354275983063644\n",
      "Iteration 17736 => Loss: 48.93667991767022584781\n",
      "Iteration 17737 => Loss: 48.93649629402172962500\n",
      "Iteration 17738 => Loss: 48.93631267181427091373\n",
      "Iteration 17739 => Loss: 48.93612905104787103028\n",
      "Iteration 17740 => Loss: 48.93594543172251576379\n",
      "Iteration 17741 => Loss: 48.93576181383819800885\n",
      "Iteration 17742 => Loss: 48.93557819739491066002\n",
      "Iteration 17743 => Loss: 48.93539458239263950645\n",
      "Iteration 17744 => Loss: 48.93521096883137033728\n",
      "Iteration 17745 => Loss: 48.93502735671106762538\n",
      "Iteration 17746 => Loss: 48.93484374603175979246\n",
      "Iteration 17747 => Loss: 48.93466013679341131137\n",
      "Iteration 17748 => Loss: 48.93447652899602218213\n",
      "Iteration 17749 => Loss: 48.93429292263959240472\n",
      "Iteration 17750 => Loss: 48.93410931772406513574\n",
      "Iteration 17751 => Loss: 48.93392571424946879688\n",
      "Iteration 17752 => Loss: 48.93374211221580338815\n",
      "Iteration 17753 => Loss: 48.93355851162303338242\n",
      "Iteration 17754 => Loss: 48.93337491247112325254\n",
      "Iteration 17755 => Loss: 48.93319131476011563109\n",
      "Iteration 17756 => Loss: 48.93300771848996788549\n",
      "Iteration 17757 => Loss: 48.93282412366065869946\n",
      "Iteration 17758 => Loss: 48.93264053027223781100\n",
      "Iteration 17759 => Loss: 48.93245693832457732242\n",
      "Iteration 17760 => Loss: 48.93227334781779092054\n",
      "Iteration 17761 => Loss: 48.93208975875180755111\n",
      "Iteration 17762 => Loss: 48.93190617112660589783\n",
      "Iteration 17763 => Loss: 48.93172258494220017155\n",
      "Iteration 17764 => Loss: 48.93153900019855484516\n",
      "Iteration 17765 => Loss: 48.93135541689568412949\n",
      "Iteration 17766 => Loss: 48.93117183503355960283\n",
      "Iteration 17767 => Loss: 48.93098825461217415977\n",
      "Iteration 17768 => Loss: 48.93080467563152069488\n",
      "Iteration 17769 => Loss: 48.93062109809159210272\n",
      "Iteration 17770 => Loss: 48.93043752199238127787\n",
      "Iteration 17771 => Loss: 48.93025394733384558776\n",
      "Iteration 17772 => Loss: 48.93007037411600634869\n",
      "Iteration 17773 => Loss: 48.92988680233882092807\n",
      "Iteration 17774 => Loss: 48.92970323200231774763\n",
      "Iteration 17775 => Loss: 48.92951966310645417479\n",
      "Iteration 17776 => Loss: 48.92933609565122310414\n",
      "Iteration 17777 => Loss: 48.92915252963663874652\n",
      "Iteration 17778 => Loss: 48.92896896506265136395\n",
      "Iteration 17779 => Loss: 48.92878540192928937813\n",
      "Iteration 17780 => Loss: 48.92860184023651726193\n",
      "Iteration 17781 => Loss: 48.92841827998434212077\n",
      "Iteration 17782 => Loss: 48.92823472117267868953\n",
      "Iteration 17783 => Loss: 48.92805116380162644418\n",
      "Iteration 17784 => Loss: 48.92786760787109301418\n",
      "Iteration 17785 => Loss: 48.92768405338113524294\n",
      "Iteration 17786 => Loss: 48.92750050033167497077\n",
      "Iteration 17787 => Loss: 48.92731694872273351393\n",
      "Iteration 17788 => Loss: 48.92713339855430376701\n",
      "Iteration 17789 => Loss: 48.92694984982635730830\n",
      "Iteration 17790 => Loss: 48.92676630253890124322\n",
      "Iteration 17791 => Loss: 48.92658275669191425550\n",
      "Iteration 17792 => Loss: 48.92639921228537502884\n",
      "Iteration 17793 => Loss: 48.92621566931929777411\n",
      "Iteration 17794 => Loss: 48.92603212779363985874\n",
      "Iteration 17795 => Loss: 48.92584858770840838815\n",
      "Iteration 17796 => Loss: 48.92566504906359625693\n",
      "Iteration 17797 => Loss: 48.92548151185916083250\n",
      "Iteration 17798 => Loss: 48.92529797609515185286\n",
      "Iteration 17799 => Loss: 48.92511444177151958002\n",
      "Iteration 17800 => Loss: 48.92493090888823559226\n",
      "Iteration 17801 => Loss: 48.92474737744531410044\n",
      "Iteration 17802 => Loss: 48.92456384744271957743\n",
      "Iteration 17803 => Loss: 48.92438031888050176121\n",
      "Iteration 17804 => Loss: 48.92419679175856828124\n",
      "Iteration 17805 => Loss: 48.92401326607696887550\n",
      "Iteration 17806 => Loss: 48.92382974183566091142\n",
      "Iteration 17807 => Loss: 48.92364621903465149444\n",
      "Iteration 17808 => Loss: 48.92346269767389799199\n",
      "Iteration 17809 => Loss: 48.92327917775343593121\n",
      "Iteration 17810 => Loss: 48.92309565927320846868\n",
      "Iteration 17811 => Loss: 48.92291214223322270982\n",
      "Iteration 17812 => Loss: 48.92272862663348576007\n",
      "Iteration 17813 => Loss: 48.92254511247395498685\n",
      "Iteration 17814 => Loss: 48.92236159975463749561\n",
      "Iteration 17815 => Loss: 48.92217808847551907547\n",
      "Iteration 17816 => Loss: 48.92199457863659262102\n",
      "Iteration 17817 => Loss: 48.92181107023783681598\n",
      "Iteration 17818 => Loss: 48.92162756327925876576\n",
      "Iteration 17819 => Loss: 48.92144405776081583781\n",
      "Iteration 17820 => Loss: 48.92126055368252224298\n",
      "Iteration 17821 => Loss: 48.92107705104434955956\n",
      "Iteration 17822 => Loss: 48.92089354984629778755\n",
      "Iteration 17823 => Loss: 48.92071005008836692696\n",
      "Iteration 17824 => Loss: 48.92052655177050723978\n",
      "Iteration 17825 => Loss: 48.92034305489276135859\n",
      "Iteration 17826 => Loss: 48.92015955945507243996\n",
      "Iteration 17827 => Loss: 48.91997606545744048390\n",
      "Iteration 17828 => Loss: 48.91979257289987970125\n",
      "Iteration 17829 => Loss: 48.91960908178236167032\n",
      "Iteration 17830 => Loss: 48.91942559210485086396\n",
      "Iteration 17831 => Loss: 48.91924210386736859846\n",
      "Iteration 17832 => Loss: 48.91905861706990066295\n",
      "Iteration 17833 => Loss: 48.91887513171241153032\n",
      "Iteration 17834 => Loss: 48.91869164779490830597\n",
      "Iteration 17835 => Loss: 48.91850816531737677906\n",
      "Iteration 17836 => Loss: 48.91832468427980984416\n",
      "Iteration 17837 => Loss: 48.91814120468221460669\n",
      "Iteration 17838 => Loss: 48.91795772652451290696\n",
      "Iteration 17839 => Loss: 48.91777424980676869382\n",
      "Iteration 17840 => Loss: 48.91759077452893222926\n",
      "Iteration 17841 => Loss: 48.91740730069100351329\n",
      "Iteration 17842 => Loss: 48.91722382829295412421\n",
      "Iteration 17843 => Loss: 48.91704035733480537829\n",
      "Iteration 17844 => Loss: 48.91685688781652174839\n",
      "Iteration 17845 => Loss: 48.91667341973808902367\n",
      "Iteration 17846 => Loss: 48.91648995309950720412\n",
      "Iteration 17847 => Loss: 48.91630648790076207888\n",
      "Iteration 17848 => Loss: 48.91612302414184654253\n",
      "Iteration 17849 => Loss: 48.91593956182273217337\n",
      "Iteration 17850 => Loss: 48.91575610094344028766\n",
      "Iteration 17851 => Loss: 48.91557264150392114743\n",
      "Iteration 17852 => Loss: 48.91538918350419606895\n",
      "Iteration 17853 => Loss: 48.91520572694423663052\n",
      "Iteration 17854 => Loss: 48.91502227182402151584\n",
      "Iteration 17855 => Loss: 48.91483881814357204121\n",
      "Iteration 17856 => Loss: 48.91465536590283846863\n",
      "Iteration 17857 => Loss: 48.91447191510184921981\n",
      "Iteration 17858 => Loss: 48.91428846574056166219\n",
      "Iteration 17859 => Loss: 48.91410501781896869034\n",
      "Iteration 17860 => Loss: 48.91392157133707030425\n",
      "Iteration 17861 => Loss: 48.91373812629485229309\n",
      "Iteration 17862 => Loss: 48.91355468269228623512\n",
      "Iteration 17863 => Loss: 48.91337124052940055208\n",
      "Iteration 17864 => Loss: 48.91318779980615261138\n",
      "Iteration 17865 => Loss: 48.91300436052254951846\n",
      "Iteration 17866 => Loss: 48.91282092267853442991\n",
      "Iteration 17867 => Loss: 48.91263748627414287284\n",
      "Iteration 17868 => Loss: 48.91245405130936063642\n",
      "Iteration 17869 => Loss: 48.91227061778416640436\n",
      "Iteration 17870 => Loss: 48.91208718569854596581\n",
      "Iteration 17871 => Loss: 48.91190375505248510990\n",
      "Iteration 17872 => Loss: 48.91172032584597673122\n",
      "Iteration 17873 => Loss: 48.91153689807902793518\n",
      "Iteration 17874 => Loss: 48.91135347175158898381\n",
      "Iteration 17875 => Loss: 48.91117004686369540423\n",
      "Iteration 17876 => Loss: 48.91098662341529745845\n",
      "Iteration 17877 => Loss: 48.91080320140637383020\n",
      "Iteration 17878 => Loss: 48.91061978083697425745\n",
      "Iteration 17879 => Loss: 48.91043636170703479138\n",
      "Iteration 17880 => Loss: 48.91025294401654122112\n",
      "Iteration 17881 => Loss: 48.91006952776550775752\n",
      "Iteration 17882 => Loss: 48.90988611295396282230\n",
      "Iteration 17883 => Loss: 48.90970269958179272862\n",
      "Iteration 17884 => Loss: 48.90951928764905431990\n",
      "Iteration 17885 => Loss: 48.90933587715571917443\n",
      "Iteration 17886 => Loss: 48.90915246810178018677\n",
      "Iteration 17887 => Loss: 48.90896906048723735694\n",
      "Iteration 17888 => Loss: 48.90878565431204805236\n",
      "Iteration 17889 => Loss: 48.90860224957624780018\n",
      "Iteration 17890 => Loss: 48.90841884627978686240\n",
      "Iteration 17891 => Loss: 48.90823544442265813359\n",
      "Iteration 17892 => Loss: 48.90805204400488293004\n",
      "Iteration 17893 => Loss: 48.90786864502639730290\n",
      "Iteration 17894 => Loss: 48.90768524748722256845\n",
      "Iteration 17895 => Loss: 48.90750185138734451584\n",
      "Iteration 17896 => Loss: 48.90731845672675603964\n",
      "Iteration 17897 => Loss: 48.90713506350542871814\n",
      "Iteration 17898 => Loss: 48.90695167172333412964\n",
      "Iteration 17899 => Loss: 48.90676828138054332840\n",
      "Iteration 17900 => Loss: 48.90658489247697104929\n",
      "Iteration 17901 => Loss: 48.90640150501262439775\n",
      "Iteration 17902 => Loss: 48.90621811898748916292\n",
      "Iteration 17903 => Loss: 48.90603473440155113394\n",
      "Iteration 17904 => Loss: 48.90585135125481031082\n",
      "Iteration 17905 => Loss: 48.90566796954726669355\n",
      "Iteration 17906 => Loss: 48.90548458927887764958\n",
      "Iteration 17907 => Loss: 48.90530121044963607346\n",
      "Iteration 17908 => Loss: 48.90511783305956328149\n",
      "Iteration 17909 => Loss: 48.90493445710862374654\n",
      "Iteration 17910 => Loss: 48.90475108259678904687\n",
      "Iteration 17911 => Loss: 48.90456770952408049880\n",
      "Iteration 17912 => Loss: 48.90438433789047678601\n",
      "Iteration 17913 => Loss: 48.90420096769598501396\n",
      "Iteration 17914 => Loss: 48.90401759894053412836\n",
      "Iteration 17915 => Loss: 48.90383423162416676178\n",
      "Iteration 17916 => Loss: 48.90365086574685449250\n",
      "Iteration 17917 => Loss: 48.90346750130859021510\n",
      "Iteration 17918 => Loss: 48.90328413830937392959\n",
      "Iteration 17919 => Loss: 48.90310077674916300339\n",
      "Iteration 17920 => Loss: 48.90291741662797875279\n",
      "Iteration 17921 => Loss: 48.90273405794577143979\n",
      "Iteration 17922 => Loss: 48.90255070070256948611\n",
      "Iteration 17923 => Loss: 48.90236734489834447004\n",
      "Iteration 17924 => Loss: 48.90218399053308928615\n",
      "Iteration 17925 => Loss: 48.90200063760678972358\n",
      "Iteration 17926 => Loss: 48.90181728611942446605\n",
      "Iteration 17927 => Loss: 48.90163393607100061899\n",
      "Iteration 17928 => Loss: 48.90145058746149686613\n",
      "Iteration 17929 => Loss: 48.90126724029090610202\n",
      "Iteration 17930 => Loss: 48.90108389455919990496\n",
      "Iteration 17931 => Loss: 48.90090055026639959124\n",
      "Iteration 17932 => Loss: 48.90071720741246963371\n",
      "Iteration 17933 => Loss: 48.90053386599741003238\n",
      "Iteration 17934 => Loss: 48.90035052602119236553\n",
      "Iteration 17935 => Loss: 48.90016718748381663318\n",
      "Iteration 17936 => Loss: 48.89998385038526862445\n",
      "Iteration 17937 => Loss: 48.89980051472556255021\n",
      "Iteration 17938 => Loss: 48.89961718050466288332\n",
      "Iteration 17939 => Loss: 48.89943384772254120207\n",
      "Iteration 17940 => Loss: 48.89925051637921171732\n",
      "Iteration 17941 => Loss: 48.89906718647466732364\n",
      "Iteration 17942 => Loss: 48.89888385800886538846\n",
      "Iteration 17943 => Loss: 48.89870053098183433349\n",
      "Iteration 17944 => Loss: 48.89851720539352442074\n",
      "Iteration 17945 => Loss: 48.89833388124397828278\n",
      "Iteration 17946 => Loss: 48.89815055853312486533\n",
      "Iteration 17947 => Loss: 48.89796723726097127383\n",
      "Iteration 17948 => Loss: 48.89778391742752461369\n",
      "Iteration 17949 => Loss: 48.89760059903277067406\n",
      "Iteration 17950 => Loss: 48.89741728207668103323\n",
      "Iteration 17951 => Loss: 48.89723396655923437493\n",
      "Iteration 17952 => Loss: 48.89705065248048043713\n",
      "Iteration 17953 => Loss: 48.89686733984034106015\n",
      "Iteration 17954 => Loss: 48.89668402863883756027\n",
      "Iteration 17955 => Loss: 48.89650071887595572662\n",
      "Iteration 17956 => Loss: 48.89631741055164582122\n",
      "Iteration 17957 => Loss: 48.89613410366595758205\n",
      "Iteration 17958 => Loss: 48.89595079821884837656\n",
      "Iteration 17959 => Loss: 48.89576749421031820475\n",
      "Iteration 17960 => Loss: 48.89558419164033153947\n",
      "Iteration 17961 => Loss: 48.89540089050890969702\n",
      "Iteration 17962 => Loss: 48.89521759081601715025\n",
      "Iteration 17963 => Loss: 48.89503429256166100458\n",
      "Iteration 17964 => Loss: 48.89485099574579862747\n",
      "Iteration 17965 => Loss: 48.89466770036845133518\n",
      "Iteration 17966 => Loss: 48.89448440642959781144\n",
      "Iteration 17967 => Loss: 48.89430111392923805624\n",
      "Iteration 17968 => Loss: 48.89411782286731522618\n",
      "Iteration 17969 => Loss: 48.89393453324386484837\n",
      "Iteration 17970 => Loss: 48.89375124505886560655\n",
      "Iteration 17971 => Loss: 48.89356795831232460614\n",
      "Iteration 17972 => Loss: 48.89338467300418500372\n",
      "Iteration 17973 => Loss: 48.89320138913446101014\n",
      "Iteration 17974 => Loss: 48.89301810670314551999\n",
      "Iteration 17975 => Loss: 48.89283482571023142782\n",
      "Iteration 17976 => Loss: 48.89265154615566189023\n",
      "Iteration 17977 => Loss: 48.89246826803947243434\n",
      "Iteration 17978 => Loss: 48.89228499136164884931\n",
      "Iteration 17979 => Loss: 48.89210171612216271342\n",
      "Iteration 17980 => Loss: 48.89191844232102113210\n",
      "Iteration 17981 => Loss: 48.89173516995818857822\n",
      "Iteration 17982 => Loss: 48.89155189903369347348\n",
      "Iteration 17983 => Loss: 48.89136862954748607990\n",
      "Iteration 17984 => Loss: 48.89118536149957350290\n",
      "Iteration 17985 => Loss: 48.89100209488992732076\n",
      "Iteration 17986 => Loss: 48.89081882971856174436\n",
      "Iteration 17987 => Loss: 48.89063556598544835197\n",
      "Iteration 17988 => Loss: 48.89045230369054451103\n",
      "Iteration 17989 => Loss: 48.89026904283389995953\n",
      "Iteration 17990 => Loss: 48.89008578341549338120\n",
      "Iteration 17991 => Loss: 48.88990252543528214346\n",
      "Iteration 17992 => Loss: 48.88971926889326624632\n",
      "Iteration 17993 => Loss: 48.88953601378944568978\n",
      "Iteration 17994 => Loss: 48.88935276012379915755\n",
      "Iteration 17995 => Loss: 48.88916950789631243879\n",
      "Iteration 17996 => Loss: 48.88898625710697842806\n",
      "Iteration 17997 => Loss: 48.88880300775579001993\n",
      "Iteration 17998 => Loss: 48.88861975984273300355\n",
      "Iteration 17999 => Loss: 48.88843651336780737893\n",
      "Iteration 18000 => Loss: 48.88825326833097051349\n",
      "Iteration 18001 => Loss: 48.88807002473224372352\n",
      "Iteration 18002 => Loss: 48.88788678257158437646\n",
      "Iteration 18003 => Loss: 48.88770354184903510486\n",
      "Iteration 18004 => Loss: 48.88752030256452485446\n",
      "Iteration 18005 => Loss: 48.88733706471806783611\n",
      "Iteration 18006 => Loss: 48.88715382830966404981\n",
      "Iteration 18007 => Loss: 48.88697059333927796843\n",
      "Iteration 18008 => Loss: 48.88678735980691669738\n",
      "Iteration 18009 => Loss: 48.88660412771255892039\n",
      "Iteration 18010 => Loss: 48.88642089705621174289\n",
      "Iteration 18011 => Loss: 48.88623766783781832146\n",
      "Iteration 18012 => Loss: 48.88605444005741418323\n",
      "Iteration 18013 => Loss: 48.88587121371498511735\n",
      "Iteration 18014 => Loss: 48.88568798881048849125\n",
      "Iteration 18015 => Loss: 48.88550476534395272665\n",
      "Iteration 18016 => Loss: 48.88532154331532808555\n",
      "Iteration 18017 => Loss: 48.88513832272460035711\n",
      "Iteration 18018 => Loss: 48.88495510357181217387\n",
      "Iteration 18019 => Loss: 48.88477188585689958700\n",
      "Iteration 18020 => Loss: 48.88458866957987680735\n",
      "Iteration 18021 => Loss: 48.88440545474071541321\n",
      "Iteration 18022 => Loss: 48.88422224133942961544\n",
      "Iteration 18023 => Loss: 48.88403902937599809775\n",
      "Iteration 18024 => Loss: 48.88385581885038533301\n",
      "Iteration 18025 => Loss: 48.88367260976260553207\n",
      "Iteration 18026 => Loss: 48.88348940211265158950\n",
      "Iteration 18027 => Loss: 48.88330619590048797818\n",
      "Iteration 18028 => Loss: 48.88312299112611469809\n",
      "Iteration 18029 => Loss: 48.88293978778956017095\n",
      "Iteration 18030 => Loss: 48.88275658589071070992\n",
      "Iteration 18031 => Loss: 48.88257338542966579098\n",
      "Iteration 18032 => Loss: 48.88239018640636146529\n",
      "Iteration 18033 => Loss: 48.88220698882078352199\n",
      "Iteration 18034 => Loss: 48.88202379267294617193\n",
      "Iteration 18035 => Loss: 48.88184059796279967713\n",
      "Iteration 18036 => Loss: 48.88165740469038667015\n",
      "Iteration 18037 => Loss: 48.88147421285564320215\n",
      "Iteration 18038 => Loss: 48.88129102245858348397\n",
      "Iteration 18039 => Loss: 48.88110783349919330476\n",
      "Iteration 18040 => Loss: 48.88092464597745845367\n",
      "Iteration 18041 => Loss: 48.88074145989336471985\n",
      "Iteration 18042 => Loss: 48.88055827524692631414\n",
      "Iteration 18043 => Loss: 48.88037509203808639313\n",
      "Iteration 18044 => Loss: 48.88019191026688048396\n",
      "Iteration 18045 => Loss: 48.88000872993326595406\n",
      "Iteration 18046 => Loss: 48.87982555103722859258\n",
      "Iteration 18047 => Loss: 48.87964237357878261037\n",
      "Iteration 18048 => Loss: 48.87945919755789958572\n",
      "Iteration 18049 => Loss: 48.87927602297456530778\n",
      "Iteration 18050 => Loss: 48.87909284982880109283\n",
      "Iteration 18051 => Loss: 48.87890967812054299202\n",
      "Iteration 18052 => Loss: 48.87872650784981942707\n",
      "Iteration 18053 => Loss: 48.87854333901660197625\n",
      "Iteration 18054 => Loss: 48.87836017162089774502\n",
      "Iteration 18055 => Loss: 48.87817700566265699536\n",
      "Iteration 18056 => Loss: 48.87799384114190814898\n",
      "Iteration 18057 => Loss: 48.87781067805862278419\n",
      "Iteration 18058 => Loss: 48.87762751641279379555\n",
      "Iteration 18059 => Loss: 48.87744435620440697221\n",
      "Iteration 18060 => Loss: 48.87726119743344810331\n",
      "Iteration 18061 => Loss: 48.87707804009992429428\n",
      "Iteration 18062 => Loss: 48.87689488420377870170\n",
      "Iteration 18063 => Loss: 48.87671172974505395814\n",
      "Iteration 18064 => Loss: 48.87652857672370743103\n",
      "Iteration 18065 => Loss: 48.87634542513973912037\n",
      "Iteration 18066 => Loss: 48.87616227499314192073\n",
      "Iteration 18067 => Loss: 48.87597912628388741041\n",
      "Iteration 18068 => Loss: 48.87579597901198980026\n",
      "Iteration 18069 => Loss: 48.87561283317738514143\n",
      "Iteration 18070 => Loss: 48.87542968878014448819\n",
      "Iteration 18071 => Loss: 48.87524654582018257543\n",
      "Iteration 18072 => Loss: 48.87506340429754203569\n",
      "Iteration 18073 => Loss: 48.87488026421216602557\n",
      "Iteration 18074 => Loss: 48.87469712556406165049\n",
      "Iteration 18075 => Loss: 48.87451398835322891046\n",
      "Iteration 18076 => Loss: 48.87433085257966780546\n",
      "Iteration 18077 => Loss: 48.87414771824330017580\n",
      "Iteration 18078 => Loss: 48.87396458534419707576\n",
      "Iteration 18079 => Loss: 48.87378145388230166191\n",
      "Iteration 18080 => Loss: 48.87359832385758551254\n",
      "Iteration 18081 => Loss: 48.87341519527009126023\n",
      "Iteration 18082 => Loss: 48.87323206811978337782\n",
      "Iteration 18083 => Loss: 48.87304894240664765448\n",
      "Iteration 18084 => Loss: 48.87286581813066987934\n",
      "Iteration 18085 => Loss: 48.87268269529182873612\n",
      "Iteration 18086 => Loss: 48.87249957389013133024\n",
      "Iteration 18087 => Loss: 48.87231645392557766172\n",
      "Iteration 18088 => Loss: 48.87213333539811799255\n",
      "Iteration 18089 => Loss: 48.87195021830778074445\n",
      "Iteration 18090 => Loss: 48.87176710265451617943\n",
      "Iteration 18091 => Loss: 48.87158398843836693004\n",
      "Iteration 18092 => Loss: 48.87140087565926194202\n",
      "Iteration 18093 => Loss: 48.87121776431721542622\n",
      "Iteration 18094 => Loss: 48.87103465441222027721\n",
      "Iteration 18095 => Loss: 48.87085154594427649499\n",
      "Iteration 18096 => Loss: 48.87066843891334144701\n",
      "Iteration 18097 => Loss: 48.87048533331943644953\n",
      "Iteration 18098 => Loss: 48.87030222916251176457\n",
      "Iteration 18099 => Loss: 48.87011912644260291927\n",
      "Iteration 18100 => Loss: 48.86993602515964596478\n",
      "Iteration 18101 => Loss: 48.86975292531367642823\n",
      "Iteration 18102 => Loss: 48.86956982690467299335\n",
      "Iteration 18103 => Loss: 48.86938672993260723842\n",
      "Iteration 18104 => Loss: 48.86920363439749337431\n",
      "Iteration 18105 => Loss: 48.86902054029927455758\n",
      "Iteration 18106 => Loss: 48.86883744763798631539\n",
      "Iteration 18107 => Loss: 48.86865435641357890972\n",
      "Iteration 18108 => Loss: 48.86847126662608786773\n",
      "Iteration 18109 => Loss: 48.86828817827545634600\n",
      "Iteration 18110 => Loss: 48.86810509136172697708\n",
      "Iteration 18111 => Loss: 48.86792200588480028500\n",
      "Iteration 18112 => Loss: 48.86773892184474732403\n",
      "Iteration 18113 => Loss: 48.86755583924153967246\n",
      "Iteration 18114 => Loss: 48.86737275807514180315\n",
      "Iteration 18115 => Loss: 48.86718967834555371610\n",
      "Iteration 18116 => Loss: 48.86700660005276830589\n",
      "Iteration 18117 => Loss: 48.86682352319676425623\n",
      "Iteration 18118 => Loss: 48.86664044777756288340\n",
      "Iteration 18119 => Loss: 48.86645737379510023857\n",
      "Iteration 18120 => Loss: 48.86627430124939763800\n",
      "Iteration 18121 => Loss: 48.86609123014044797628\n",
      "Iteration 18122 => Loss: 48.86590816046823704255\n",
      "Iteration 18123 => Loss: 48.86572509223273641510\n",
      "Iteration 18124 => Loss: 48.86554202543393188307\n",
      "Iteration 18125 => Loss: 48.86535896007185186818\n",
      "Iteration 18126 => Loss: 48.86517589614643952700\n",
      "Iteration 18127 => Loss: 48.86499283365772328125\n",
      "Iteration 18128 => Loss: 48.86480977260563918207\n",
      "Iteration 18129 => Loss: 48.86462671299023696747\n",
      "Iteration 18130 => Loss: 48.86444365481147400487\n",
      "Iteration 18131 => Loss: 48.86426059806933608343\n",
      "Iteration 18132 => Loss: 48.86407754276381609770\n",
      "Iteration 18133 => Loss: 48.86389448889490694228\n",
      "Iteration 18134 => Loss: 48.86371143646259440629\n",
      "Iteration 18135 => Loss: 48.86352838546688559518\n",
      "Iteration 18136 => Loss: 48.86334533590772366551\n",
      "Iteration 18137 => Loss: 48.86316228778512993358\n",
      "Iteration 18138 => Loss: 48.86297924109910439938\n",
      "Iteration 18139 => Loss: 48.86279619584959732492\n",
      "Iteration 18140 => Loss: 48.86261315203661581563\n",
      "Iteration 18141 => Loss: 48.86243010966018829322\n",
      "Iteration 18142 => Loss: 48.86224706872024370341\n",
      "Iteration 18143 => Loss: 48.86206402921679625706\n",
      "Iteration 18144 => Loss: 48.86188099114982463789\n",
      "Iteration 18145 => Loss: 48.86169795451935726760\n",
      "Iteration 18146 => Loss: 48.86151491932532309193\n",
      "Iteration 18147 => Loss: 48.86133188556775053257\n",
      "Iteration 18148 => Loss: 48.86114885324659695698\n",
      "Iteration 18149 => Loss: 48.86096582236191210313\n",
      "Iteration 18150 => Loss: 48.86078279291362491676\n",
      "Iteration 18151 => Loss: 48.86059976490173539787\n",
      "Iteration 18152 => Loss: 48.86041673832624354645\n",
      "Iteration 18153 => Loss: 48.86023371318714225708\n",
      "Iteration 18154 => Loss: 48.86005068948439600263\n",
      "Iteration 18155 => Loss: 48.85986766721801899394\n",
      "Iteration 18156 => Loss: 48.85968464638798991473\n",
      "Iteration 18157 => Loss: 48.85950162699428034330\n",
      "Iteration 18158 => Loss: 48.85931860903694001763\n",
      "Iteration 18159 => Loss: 48.85913559251589788346\n",
      "Iteration 18160 => Loss: 48.85895257743113972992\n",
      "Iteration 18161 => Loss: 48.85876956378269397874\n",
      "Iteration 18162 => Loss: 48.85858655157051089191\n",
      "Iteration 18163 => Loss: 48.85840354079460468029\n",
      "Iteration 18164 => Loss: 48.85822053145498244930\n",
      "Iteration 18165 => Loss: 48.85803752355158025011\n",
      "Iteration 18166 => Loss: 48.85785451708441939900\n",
      "Iteration 18167 => Loss: 48.85767151205349989596\n",
      "Iteration 18168 => Loss: 48.85748850845878621385\n",
      "Iteration 18169 => Loss: 48.85730550630025703640\n",
      "Iteration 18170 => Loss: 48.85712250557794078532\n",
      "Iteration 18171 => Loss: 48.85693950629179482803\n",
      "Iteration 18172 => Loss: 48.85675650844182626997\n",
      "Iteration 18173 => Loss: 48.85657351202799958401\n",
      "Iteration 18174 => Loss: 48.85639051705035029727\n",
      "Iteration 18175 => Loss: 48.85620752350880025006\n",
      "Iteration 18176 => Loss: 48.85602453140339207494\n",
      "Iteration 18177 => Loss: 48.85584154073409024477\n",
      "Iteration 18178 => Loss: 48.85565855150088765413\n",
      "Iteration 18179 => Loss: 48.85547556370379140844\n",
      "Iteration 18180 => Loss: 48.85529257734275176972\n",
      "Iteration 18181 => Loss: 48.85510959241777584339\n",
      "Iteration 18182 => Loss: 48.85492660892887073487\n",
      "Iteration 18183 => Loss: 48.85474362687601512789\n",
      "Iteration 18184 => Loss: 48.85456064625918770616\n",
      "Iteration 18185 => Loss: 48.85437766707838846969\n",
      "Iteration 18186 => Loss: 48.85419468933358189133\n",
      "Iteration 18187 => Loss: 48.85401171302479639280\n",
      "Iteration 18188 => Loss: 48.85382873815197513068\n",
      "Iteration 18189 => Loss: 48.85364576471513942124\n",
      "Iteration 18190 => Loss: 48.85346279271429636992\n",
      "Iteration 18191 => Loss: 48.85327982214936781702\n",
      "Iteration 18192 => Loss: 48.85309685302041771138\n",
      "Iteration 18193 => Loss: 48.85291388532738210415\n",
      "Iteration 18194 => Loss: 48.85273091907026099534\n",
      "Iteration 18195 => Loss: 48.85254795424906859580\n",
      "Iteration 18196 => Loss: 48.85236499086374806211\n",
      "Iteration 18197 => Loss: 48.85218202891432071056\n",
      "Iteration 18198 => Loss: 48.85199906840079364656\n",
      "Iteration 18199 => Loss: 48.85181610932311002671\n",
      "Iteration 18200 => Loss: 48.85163315168127695642\n",
      "Iteration 18201 => Loss: 48.85145019547532285742\n",
      "Iteration 18202 => Loss: 48.85126724070514114828\n",
      "Iteration 18203 => Loss: 48.85108428737081709414\n",
      "Iteration 18204 => Loss: 48.85090133547228674615\n",
      "Iteration 18205 => Loss: 48.85071838500955720974\n",
      "Iteration 18206 => Loss: 48.85053543598262137948\n",
      "Iteration 18207 => Loss: 48.85035248839144372823\n",
      "Iteration 18208 => Loss: 48.85016954223603846685\n",
      "Iteration 18209 => Loss: 48.84998659751639848992\n",
      "Iteration 18210 => Loss: 48.84980365423247405943\n",
      "Iteration 18211 => Loss: 48.84962071238429359710\n",
      "Iteration 18212 => Loss: 48.84943777197182868122\n",
      "Iteration 18213 => Loss: 48.84925483299506510093\n",
      "Iteration 18214 => Loss: 48.84907189545399575081\n",
      "Iteration 18215 => Loss: 48.84888895934862063086\n",
      "Iteration 18216 => Loss: 48.84870602467891842480\n",
      "Iteration 18217 => Loss: 48.84852309144488202719\n",
      "Iteration 18218 => Loss: 48.84834015964648301633\n",
      "Iteration 18219 => Loss: 48.84815722928372139222\n",
      "Iteration 18220 => Loss: 48.84797430035660426029\n",
      "Iteration 18221 => Loss: 48.84779137286508898796\n",
      "Iteration 18222 => Loss: 48.84760844680917557525\n",
      "Iteration 18223 => Loss: 48.84742552218886402216\n",
      "Iteration 18224 => Loss: 48.84724259900413301239\n",
      "Iteration 18225 => Loss: 48.84705967725498254595\n",
      "Iteration 18226 => Loss: 48.84687675694139841198\n",
      "Iteration 18227 => Loss: 48.84669383806334508336\n",
      "Iteration 18228 => Loss: 48.84651092062082256007\n",
      "Iteration 18229 => Loss: 48.84632800461383794755\n",
      "Iteration 18230 => Loss: 48.84614509004237703493\n",
      "Iteration 18231 => Loss: 48.84596217690641140052\n",
      "Iteration 18232 => Loss: 48.84577926520594104431\n",
      "Iteration 18233 => Loss: 48.84559635494095175545\n",
      "Iteration 18234 => Loss: 48.84541344611143642851\n",
      "Iteration 18235 => Loss: 48.84523053871735243092\n",
      "Iteration 18236 => Loss: 48.84504763275874239525\n",
      "Iteration 18237 => Loss: 48.84486472823558500522\n",
      "Iteration 18238 => Loss: 48.84468182514781631198\n",
      "Iteration 18239 => Loss: 48.84449892349547184267\n",
      "Iteration 18240 => Loss: 48.84431602327853738643\n",
      "Iteration 18241 => Loss: 48.84413312449700583784\n",
      "Iteration 18242 => Loss: 48.84395022715082745890\n",
      "Iteration 18243 => Loss: 48.84376733124003777675\n",
      "Iteration 18244 => Loss: 48.84358443676460126426\n",
      "Iteration 18245 => Loss: 48.84340154372451081599\n",
      "Iteration 18246 => Loss: 48.84321865211974511567\n",
      "Iteration 18247 => Loss: 48.84303576195031126872\n",
      "Iteration 18248 => Loss: 48.84285287321619506429\n",
      "Iteration 18249 => Loss: 48.84266998591736808066\n",
      "Iteration 18250 => Loss: 48.84248710005383742327\n",
      "Iteration 18251 => Loss: 48.84230421562559598669\n",
      "Iteration 18252 => Loss: 48.84212133263260824378\n",
      "Iteration 18253 => Loss: 48.84193845107485998369\n",
      "Iteration 18254 => Loss: 48.84175557095239383898\n",
      "Iteration 18255 => Loss: 48.84157269226513875537\n",
      "Iteration 18256 => Loss: 48.84138981501311604916\n",
      "Iteration 18257 => Loss: 48.84120693919629019319\n",
      "Iteration 18258 => Loss: 48.84102406481467539834\n",
      "Iteration 18259 => Loss: 48.84084119186825034831\n",
      "Iteration 18260 => Loss: 48.84065832035699372682\n",
      "Iteration 18261 => Loss: 48.84047545028091263930\n",
      "Iteration 18262 => Loss: 48.84029258163997155862\n",
      "Iteration 18263 => Loss: 48.84010971443418469562\n",
      "Iteration 18264 => Loss: 48.83992684866353073403\n",
      "Iteration 18265 => Loss: 48.83974398432800967385\n",
      "Iteration 18266 => Loss: 48.83956112142759309336\n",
      "Iteration 18267 => Loss: 48.83937825996225257086\n",
      "Iteration 18268 => Loss: 48.83919539993200942263\n",
      "Iteration 18269 => Loss: 48.83901254133684943781\n",
      "Iteration 18270 => Loss: 48.83882968417674419470\n",
      "Iteration 18271 => Loss: 48.83864682845170790415\n",
      "Iteration 18272 => Loss: 48.83846397416170503902\n",
      "Iteration 18273 => Loss: 48.83828112130672138846\n",
      "Iteration 18274 => Loss: 48.83809826988676405790\n",
      "Iteration 18275 => Loss: 48.83791541990183304733\n",
      "Iteration 18276 => Loss: 48.83773257135188572420\n",
      "Iteration 18277 => Loss: 48.83754972423692919392\n",
      "Iteration 18278 => Loss: 48.83736687855693503479\n",
      "Iteration 18279 => Loss: 48.83718403431191745767\n",
      "Iteration 18280 => Loss: 48.83700119150184093542\n",
      "Iteration 18281 => Loss: 48.83681835012671257346\n",
      "Iteration 18282 => Loss: 48.83663551018650395008\n",
      "Iteration 18283 => Loss: 48.83645267168122217072\n",
      "Iteration 18284 => Loss: 48.83626983461084591909\n",
      "Iteration 18285 => Loss: 48.83608699897536808976\n",
      "Iteration 18286 => Loss: 48.83590416477476736645\n",
      "Iteration 18287 => Loss: 48.83572133200903664374\n",
      "Iteration 18288 => Loss: 48.83553850067817592162\n",
      "Iteration 18289 => Loss: 48.83535567078217809467\n",
      "Iteration 18290 => Loss: 48.83517284232100763575\n",
      "Iteration 18291 => Loss: 48.83499001529466454485\n",
      "Iteration 18292 => Loss: 48.83480718970313461114\n",
      "Iteration 18293 => Loss: 48.83462436554642494002\n",
      "Iteration 18294 => Loss: 48.83444154282450000437\n",
      "Iteration 18295 => Loss: 48.83425872153733848791\n",
      "Iteration 18296 => Loss: 48.83407590168497591776\n",
      "Iteration 18297 => Loss: 48.83389308326736255594\n",
      "Iteration 18298 => Loss: 48.83371026628450550788\n",
      "Iteration 18299 => Loss: 48.83352745073638345730\n",
      "Iteration 18300 => Loss: 48.83334463662299640418\n",
      "Iteration 18301 => Loss: 48.83316182394430882141\n",
      "Iteration 18302 => Loss: 48.83297901270032070897\n",
      "Iteration 18303 => Loss: 48.83279620289103917230\n",
      "Iteration 18304 => Loss: 48.83261339451644289511\n",
      "Iteration 18305 => Loss: 48.83243058757651766655\n",
      "Iteration 18306 => Loss: 48.83224778207124217033\n",
      "Iteration 18307 => Loss: 48.83206497800059509018\n",
      "Iteration 18308 => Loss: 48.83188217536464037494\n",
      "Iteration 18309 => Loss: 48.83169937416325723234\n",
      "Iteration 18310 => Loss: 48.83151657439652382209\n",
      "Iteration 18311 => Loss: 48.83133377606436908991\n",
      "Iteration 18312 => Loss: 48.83115097916682145751\n",
      "Iteration 18313 => Loss: 48.83096818370383829233\n",
      "Iteration 18314 => Loss: 48.83078538967543380522\n",
      "Iteration 18315 => Loss: 48.83060259708159378533\n",
      "Iteration 18316 => Loss: 48.83041980592229691638\n",
      "Iteration 18317 => Loss: 48.83023701619752188208\n",
      "Iteration 18318 => Loss: 48.83005422790728999871\n",
      "Iteration 18319 => Loss: 48.82987144105155863372\n",
      "Iteration 18320 => Loss: 48.82968865563034910338\n",
      "Iteration 18321 => Loss: 48.82950587164361877512\n",
      "Iteration 18322 => Loss: 48.82932308909136054353\n",
      "Iteration 18323 => Loss: 48.82914030797356019775\n",
      "Iteration 18324 => Loss: 48.82895752829023905406\n",
      "Iteration 18325 => Loss: 48.82877475004134026904\n",
      "Iteration 18326 => Loss: 48.82859197322689936982\n",
      "Iteration 18327 => Loss: 48.82840919784688082927\n",
      "Iteration 18328 => Loss: 48.82822642390123490941\n",
      "Iteration 18329 => Loss: 48.82804365139001845364\n",
      "Iteration 18330 => Loss: 48.82786088031320304026\n",
      "Iteration 18331 => Loss: 48.82767811067075314213\n",
      "Iteration 18332 => Loss: 48.82749534246266165383\n",
      "Iteration 18333 => Loss: 48.82731257568893568077\n",
      "Iteration 18334 => Loss: 48.82712981034956101212\n",
      "Iteration 18335 => Loss: 48.82694704644450212072\n",
      "Iteration 18336 => Loss: 48.82676428397375900659\n",
      "Iteration 18337 => Loss: 48.82658152293734588056\n",
      "Iteration 18338 => Loss: 48.82639876333523432095\n",
      "Iteration 18339 => Loss: 48.82621600516740301146\n",
      "Iteration 18340 => Loss: 48.82603324843385195209\n",
      "Iteration 18341 => Loss: 48.82585049313455982656\n",
      "Iteration 18342 => Loss: 48.82566773926950531859\n",
      "Iteration 18343 => Loss: 48.82548498683870974446\n",
      "Iteration 18344 => Loss: 48.82530223584216599875\n",
      "Iteration 18345 => Loss: 48.82511948627981723803\n",
      "Iteration 18346 => Loss: 48.82493673815167056773\n",
      "Iteration 18347 => Loss: 48.82475399145773309328\n",
      "Iteration 18348 => Loss: 48.82457124619797639298\n",
      "Iteration 18349 => Loss: 48.82438850237240757224\n",
      "Iteration 18350 => Loss: 48.82420575998101242021\n",
      "Iteration 18351 => Loss: 48.82402301902374119891\n",
      "Iteration 18352 => Loss: 48.82384027950062233003\n",
      "Iteration 18353 => Loss: 48.82365754141163449731\n",
      "Iteration 18354 => Loss: 48.82347480475677770073\n",
      "Iteration 18355 => Loss: 48.82329206953601641317\n",
      "Iteration 18356 => Loss: 48.82310933574935063461\n",
      "Iteration 18357 => Loss: 48.82292660339677325965\n",
      "Iteration 18358 => Loss: 48.82274387247826297198\n",
      "Iteration 18359 => Loss: 48.82256114299383398247\n",
      "Iteration 18360 => Loss: 48.82237841494344365856\n",
      "Iteration 18361 => Loss: 48.82219568832707778938\n",
      "Iteration 18362 => Loss: 48.82201296314475058580\n",
      "Iteration 18363 => Loss: 48.82183023939645494238\n",
      "Iteration 18364 => Loss: 48.82164751708214822656\n",
      "Iteration 18365 => Loss: 48.82146479620185175463\n",
      "Iteration 18366 => Loss: 48.82128207675553710487\n",
      "Iteration 18367 => Loss: 48.82109935874318296101\n",
      "Iteration 18368 => Loss: 48.82091664216480353389\n",
      "Iteration 18369 => Loss: 48.82073392702036329638\n",
      "Iteration 18370 => Loss: 48.82055121330985514305\n",
      "Iteration 18371 => Loss: 48.82036850103330039019\n",
      "Iteration 18372 => Loss: 48.82018579019064929980\n",
      "Iteration 18373 => Loss: 48.82000308078190897731\n",
      "Iteration 18374 => Loss: 48.81982037280703679016\n",
      "Iteration 18375 => Loss: 48.81963766626608247634\n",
      "Iteration 18376 => Loss: 48.81945496115896787614\n",
      "Iteration 18377 => Loss: 48.81927225748573562214\n",
      "Iteration 18378 => Loss: 48.81908955524633597634\n",
      "Iteration 18379 => Loss: 48.81890685444079025501\n",
      "Iteration 18380 => Loss: 48.81872415506905582561\n",
      "Iteration 18381 => Loss: 48.81854145713114689897\n",
      "Iteration 18382 => Loss: 48.81835876062704926426\n",
      "Iteration 18383 => Loss: 48.81817606555672739432\n",
      "Iteration 18384 => Loss: 48.81799337192019550002\n",
      "Iteration 18385 => Loss: 48.81781067971743937051\n",
      "Iteration 18386 => Loss: 48.81762798894842347863\n",
      "Iteration 18387 => Loss: 48.81744529961316203526\n",
      "Iteration 18388 => Loss: 48.81726261171163372410\n",
      "Iteration 18389 => Loss: 48.81707992524386696687\n",
      "Iteration 18390 => Loss: 48.81689724020976228758\n",
      "Iteration 18391 => Loss: 48.81671455660938363508\n",
      "Iteration 18392 => Loss: 48.81653187444269548223\n",
      "Iteration 18393 => Loss: 48.81634919370967651275\n",
      "Iteration 18394 => Loss: 48.81616651441034093750\n",
      "Iteration 18395 => Loss: 48.81598383654465322934\n",
      "Iteration 18396 => Loss: 48.81580116011263470455\n",
      "Iteration 18397 => Loss: 48.81561848511423562513\n",
      "Iteration 18398 => Loss: 48.81543581154944888567\n",
      "Iteration 18399 => Loss: 48.81525313941827448616\n",
      "Iteration 18400 => Loss: 48.81507046872071953203\n",
      "Iteration 18401 => Loss: 48.81488779945674849614\n",
      "Iteration 18402 => Loss: 48.81470513162634006221\n",
      "Iteration 18403 => Loss: 48.81452246522952265195\n",
      "Iteration 18404 => Loss: 48.81433980026625363280\n",
      "Iteration 18405 => Loss: 48.81415713673651168847\n",
      "Iteration 18406 => Loss: 48.81397447464031813524\n",
      "Iteration 18407 => Loss: 48.81379181397766586770\n",
      "Iteration 18408 => Loss: 48.81360915474849093698\n",
      "Iteration 18409 => Loss: 48.81342649695283597566\n",
      "Iteration 18410 => Loss: 48.81324384059065124575\n",
      "Iteration 18411 => Loss: 48.81306118566198648523\n",
      "Iteration 18412 => Loss: 48.81287853216674221812\n",
      "Iteration 18413 => Loss: 48.81269588010498949870\n",
      "Iteration 18414 => Loss: 48.81251322947664306184\n",
      "Iteration 18415 => Loss: 48.81233058028174554011\n",
      "Iteration 18416 => Loss: 48.81214793252028982806\n",
      "Iteration 18417 => Loss: 48.81196528619221197687\n",
      "Iteration 18418 => Loss: 48.81178264129755461909\n",
      "Iteration 18419 => Loss: 48.81159999783627512215\n",
      "Iteration 18420 => Loss: 48.81141735580838769692\n",
      "Iteration 18421 => Loss: 48.81123471521382128913\n",
      "Iteration 18422 => Loss: 48.81105207605264695303\n",
      "Iteration 18423 => Loss: 48.81086943832480784522\n",
      "Iteration 18424 => Loss: 48.81068680203030396569\n",
      "Iteration 18425 => Loss: 48.81050416716911399817\n",
      "Iteration 18426 => Loss: 48.81032153374123794265\n",
      "Iteration 18427 => Loss: 48.81013890174665448285\n",
      "Iteration 18428 => Loss: 48.80995627118534230249\n",
      "Iteration 18429 => Loss: 48.80977364205732982327\n",
      "Iteration 18430 => Loss: 48.80959101436258151807\n",
      "Iteration 18431 => Loss: 48.80940838810106896517\n",
      "Iteration 18432 => Loss: 48.80922576327280637543\n",
      "Iteration 18433 => Loss: 48.80904313987777243256\n",
      "Iteration 18434 => Loss: 48.80886051791595292570\n",
      "Iteration 18435 => Loss: 48.80867789738734785487\n",
      "Iteration 18436 => Loss: 48.80849527829194300921\n",
      "Iteration 18437 => Loss: 48.80831266062972417785\n",
      "Iteration 18438 => Loss: 48.80813004440067004452\n",
      "Iteration 18439 => Loss: 48.80794742960477350380\n",
      "Iteration 18440 => Loss: 48.80776481624202745024\n",
      "Iteration 18441 => Loss: 48.80758220431243898929\n",
      "Iteration 18442 => Loss: 48.80739959381597969923\n",
      "Iteration 18443 => Loss: 48.80721698475261405292\n",
      "Iteration 18444 => Loss: 48.80703437712236336665\n",
      "Iteration 18445 => Loss: 48.80685177092520632414\n",
      "Iteration 18446 => Loss: 48.80666916616115003080\n",
      "Iteration 18447 => Loss: 48.80648656283013764323\n",
      "Iteration 18448 => Loss: 48.80630396093222600484\n",
      "Iteration 18449 => Loss: 48.80612136046734406136\n",
      "Iteration 18450 => Loss: 48.80593876143551312907\n",
      "Iteration 18451 => Loss: 48.80575616383667636455\n",
      "Iteration 18452 => Loss: 48.80557356767089061123\n",
      "Iteration 18453 => Loss: 48.80539097293807770939\n",
      "Iteration 18454 => Loss: 48.80520837963828029160\n",
      "Iteration 18455 => Loss: 48.80502578777145572531\n",
      "Iteration 18456 => Loss: 48.80484319733763243221\n",
      "Iteration 18457 => Loss: 48.80466060833673225261\n",
      "Iteration 18458 => Loss: 48.80447802076879781907\n",
      "Iteration 18459 => Loss: 48.80429543463379360446\n",
      "Iteration 18460 => Loss: 48.80411284993171250335\n",
      "Iteration 18461 => Loss: 48.80393026666256162116\n",
      "Iteration 18462 => Loss: 48.80374768482629832533\n",
      "Iteration 18463 => Loss: 48.80356510442295103758\n",
      "Iteration 18464 => Loss: 48.80338252545245580905\n",
      "Iteration 18465 => Loss: 48.80319994791484106145\n",
      "Iteration 18466 => Loss: 48.80301737181009258393\n",
      "Iteration 18467 => Loss: 48.80283479713821037649\n",
      "Iteration 18468 => Loss: 48.80265222389911627943\n",
      "Iteration 18469 => Loss: 48.80246965209288845244\n",
      "Iteration 18470 => Loss: 48.80228708171945584127\n",
      "Iteration 18471 => Loss: 48.80210451277883976218\n",
      "Iteration 18472 => Loss: 48.80192194527099758261\n",
      "Iteration 18473 => Loss: 48.80173937919594351342\n",
      "Iteration 18474 => Loss: 48.80155681455364913290\n",
      "Iteration 18475 => Loss: 48.80137425134412154648\n",
      "Iteration 18476 => Loss: 48.80119168956733233244\n",
      "Iteration 18477 => Loss: 48.80100912922330280708\n",
      "Iteration 18478 => Loss: 48.80082657031198323239\n",
      "Iteration 18479 => Loss: 48.80064401283335229209\n",
      "Iteration 18480 => Loss: 48.80046145678745972418\n",
      "Iteration 18481 => Loss: 48.80027890217422736896\n",
      "Iteration 18482 => Loss: 48.80009634899370496441\n",
      "Iteration 18483 => Loss: 48.79991379724582856170\n",
      "Iteration 18484 => Loss: 48.79973124693060526624\n",
      "Iteration 18485 => Loss: 48.79954869804804218347\n",
      "Iteration 18486 => Loss: 48.79936615059810378625\n",
      "Iteration 18487 => Loss: 48.79918360458079007458\n",
      "Iteration 18488 => Loss: 48.79900105999608683760\n",
      "Iteration 18489 => Loss: 48.79881851684398696989\n",
      "Iteration 18490 => Loss: 48.79863597512448336602\n",
      "Iteration 18491 => Loss: 48.79845343483754760427\n",
      "Iteration 18492 => Loss: 48.79827089598320100094\n",
      "Iteration 18493 => Loss: 48.79808835856136539633\n",
      "Iteration 18494 => Loss: 48.79790582257209763384\n",
      "Iteration 18495 => Loss: 48.79772328801535508092\n",
      "Iteration 18496 => Loss: 48.79754075489114484299\n",
      "Iteration 18497 => Loss: 48.79735822319943849834\n",
      "Iteration 18498 => Loss: 48.79717569294025025783\n",
      "Iteration 18499 => Loss: 48.79699316411350906719\n",
      "Iteration 18500 => Loss: 48.79681063671928598069\n",
      "Iteration 18501 => Loss: 48.79662811075750283862\n",
      "Iteration 18502 => Loss: 48.79644558622818095728\n",
      "Iteration 18503 => Loss: 48.79626306313129902037\n",
      "Iteration 18504 => Loss: 48.79608054146685702790\n",
      "Iteration 18505 => Loss: 48.79589802123484076901\n",
      "Iteration 18506 => Loss: 48.79571550243521471657\n",
      "Iteration 18507 => Loss: 48.79553298506800018686\n",
      "Iteration 18508 => Loss: 48.79535046913316165273\n",
      "Iteration 18509 => Loss: 48.79516795463070621963\n",
      "Iteration 18510 => Loss: 48.79498544156062678212\n",
      "Iteration 18511 => Loss: 48.79480292992289491849\n",
      "Iteration 18512 => Loss: 48.79462041971748220703\n",
      "Iteration 18513 => Loss: 48.79443791094440996403\n",
      "Iteration 18514 => Loss: 48.79425540360367818948\n",
      "Iteration 18515 => Loss: 48.79407289769523003997\n",
      "Iteration 18516 => Loss: 48.79389039321908683178\n",
      "Iteration 18517 => Loss: 48.79370789017523435405\n",
      "Iteration 18518 => Loss: 48.79352538856364418507\n",
      "Iteration 18519 => Loss: 48.79334288838432343027\n",
      "Iteration 18520 => Loss: 48.79316038963725077338\n",
      "Iteration 18521 => Loss: 48.79297789232241910895\n",
      "Iteration 18522 => Loss: 48.79279539643982843700\n",
      "Iteration 18523 => Loss: 48.79261290198945033580\n",
      "Iteration 18524 => Loss: 48.79243040897128480538\n",
      "Iteration 18525 => Loss: 48.79224791738529631857\n",
      "Iteration 18526 => Loss: 48.79206542723149908625\n",
      "Iteration 18527 => Loss: 48.79188293850987889755\n",
      "Iteration 18528 => Loss: 48.79170045122040733077\n",
      "Iteration 18529 => Loss: 48.79151796536311280761\n",
      "Iteration 18530 => Loss: 48.79133548093795269551\n",
      "Iteration 18531 => Loss: 48.79115299794489857277\n",
      "Iteration 18532 => Loss: 48.79097051638398596651\n",
      "Iteration 18533 => Loss: 48.79078803625515803333\n",
      "Iteration 18534 => Loss: 48.79060555755844319492\n",
      "Iteration 18535 => Loss: 48.79042308029379881873\n",
      "Iteration 18536 => Loss: 48.79024060446123911561\n",
      "Iteration 18537 => Loss: 48.79005813006072855842\n",
      "Iteration 18538 => Loss: 48.78987565709225293631\n",
      "Iteration 18539 => Loss: 48.78969318555585488184\n",
      "Iteration 18540 => Loss: 48.78951071545146334074\n",
      "Iteration 18541 => Loss: 48.78932824677908541844\n",
      "Iteration 18542 => Loss: 48.78914577953870690408\n",
      "Iteration 18543 => Loss: 48.78896331373031358680\n",
      "Iteration 18544 => Loss: 48.78878084935393388832\n",
      "Iteration 18545 => Loss: 48.78859838640951096522\n",
      "Iteration 18546 => Loss: 48.78841592489702350122\n",
      "Iteration 18547 => Loss: 48.78823346481653544515\n",
      "Iteration 18548 => Loss: 48.78805100616793311019\n",
      "Iteration 18549 => Loss: 48.78786854895128044518\n",
      "Iteration 18550 => Loss: 48.78768609316654192298\n",
      "Iteration 18551 => Loss: 48.78750363881370333274\n",
      "Iteration 18552 => Loss: 48.78732118589275046361\n",
      "Iteration 18553 => Loss: 48.78713873440368331558\n",
      "Iteration 18554 => Loss: 48.78695628434648767779\n",
      "Iteration 18555 => Loss: 48.78677383572115644483\n",
      "Iteration 18556 => Loss: 48.78659138852768251127\n",
      "Iteration 18557 => Loss: 48.78640894276603034996\n",
      "Iteration 18558 => Loss: 48.78622649843619285548\n",
      "Iteration 18559 => Loss: 48.78604405553817713326\n",
      "Iteration 18560 => Loss: 48.78586161407195476158\n",
      "Iteration 18561 => Loss: 48.78567917403754705674\n",
      "Iteration 18562 => Loss: 48.78549673543489717531\n",
      "Iteration 18563 => Loss: 48.78531429826402643357\n",
      "Iteration 18564 => Loss: 48.78513186252491351524\n",
      "Iteration 18565 => Loss: 48.78494942821754420947\n",
      "Iteration 18566 => Loss: 48.78476699534189719998\n",
      "Iteration 18567 => Loss: 48.78458456389799380304\n",
      "Iteration 18568 => Loss: 48.78440213388578428066\n",
      "Iteration 18569 => Loss: 48.78421970530529705457\n",
      "Iteration 18570 => Loss: 48.78403727815648949218\n",
      "Iteration 18571 => Loss: 48.78385485243935448807\n",
      "Iteration 18572 => Loss: 48.78367242815390625310\n",
      "Iteration 18573 => Loss: 48.78349000530007373300\n",
      "Iteration 18574 => Loss: 48.78330758387792087660\n",
      "Iteration 18575 => Loss: 48.78312516388739794593\n",
      "Iteration 18576 => Loss: 48.78294274532849783554\n",
      "Iteration 18577 => Loss: 48.78276032820119922917\n",
      "Iteration 18578 => Loss: 48.78257791250548791595\n",
      "Iteration 18579 => Loss: 48.78239549824139942302\n",
      "Iteration 18580 => Loss: 48.78221308540889111782\n",
      "Iteration 18581 => Loss: 48.78203067400792036779\n",
      "Iteration 18582 => Loss: 48.78184826403850848919\n",
      "Iteration 18583 => Loss: 48.78166585550064837662\n",
      "Iteration 18584 => Loss: 48.78148344839431871378\n",
      "Iteration 18585 => Loss: 48.78130104271951239525\n",
      "Iteration 18586 => Loss: 48.78111863847620099932\n",
      "Iteration 18587 => Loss: 48.78093623566440584227\n",
      "Iteration 18588 => Loss: 48.78075383428410560782\n",
      "Iteration 18589 => Loss: 48.78057143433527187426\n",
      "Iteration 18590 => Loss: 48.78038903581787621988\n",
      "Iteration 18591 => Loss: 48.78020663873198259353\n",
      "Iteration 18592 => Loss: 48.78002424307749862464\n",
      "Iteration 18593 => Loss: 48.77984184885446694580\n",
      "Iteration 18594 => Loss: 48.77965945606283781899\n",
      "Iteration 18595 => Loss: 48.77947706470261834966\n",
      "Iteration 18596 => Loss: 48.77929467477380143237\n",
      "Iteration 18597 => Loss: 48.77911228627639417255\n",
      "Iteration 18598 => Loss: 48.77892989921033972678\n",
      "Iteration 18599 => Loss: 48.77874751357565230592\n",
      "Iteration 18600 => Loss: 48.77856512937232480454\n",
      "Iteration 18601 => Loss: 48.77838274660030748464\n",
      "Iteration 18602 => Loss: 48.77820036525965718965\n",
      "Iteration 18603 => Loss: 48.77801798535030997073\n",
      "Iteration 18604 => Loss: 48.77783560687227293329\n",
      "Iteration 18605 => Loss: 48.77765322982553897191\n",
      "Iteration 18606 => Loss: 48.77747085421006545403\n",
      "Iteration 18607 => Loss: 48.77728848002589501220\n",
      "Iteration 18608 => Loss: 48.77710610727297080302\n",
      "Iteration 18609 => Loss: 48.77692373595131414277\n",
      "Iteration 18610 => Loss: 48.77674136606088950430\n",
      "Iteration 18611 => Loss: 48.77655899760168267676\n",
      "Iteration 18612 => Loss: 48.77637663057371497644\n",
      "Iteration 18613 => Loss: 48.77619426497694377076\n",
      "Iteration 18614 => Loss: 48.77601190081134774346\n",
      "Iteration 18615 => Loss: 48.77582953807696242166\n",
      "Iteration 18616 => Loss: 48.77564717677375938365\n",
      "Iteration 18617 => Loss: 48.77546481690169599688\n",
      "Iteration 18618 => Loss: 48.77528245846078647219\n",
      "Iteration 18619 => Loss: 48.77510010145102370416\n",
      "Iteration 18620 => Loss: 48.77491774587240058736\n",
      "Iteration 18621 => Loss: 48.77473539172486738380\n",
      "Iteration 18622 => Loss: 48.77455303900845251519\n",
      "Iteration 18623 => Loss: 48.77437068772312755982\n",
      "Iteration 18624 => Loss: 48.77418833786889251769\n",
      "Iteration 18625 => Loss: 48.77400598944574028337\n",
      "Iteration 18626 => Loss: 48.77382364245362111888\n",
      "Iteration 18627 => Loss: 48.77364129689256344591\n",
      "Iteration 18628 => Loss: 48.77345895276256015904\n",
      "Iteration 18629 => Loss: 48.77327661006358283657\n",
      "Iteration 18630 => Loss: 48.77309426879559595136\n",
      "Iteration 18631 => Loss: 48.77291192895862792511\n",
      "Iteration 18632 => Loss: 48.77272959055265744155\n",
      "Iteration 18633 => Loss: 48.77254725357767028981\n",
      "Iteration 18634 => Loss: 48.77236491803363804820\n",
      "Iteration 18635 => Loss: 48.77218258392056782213\n",
      "Iteration 18636 => Loss: 48.77200025123843829533\n",
      "Iteration 18637 => Loss: 48.77181791998727788950\n",
      "Iteration 18638 => Loss: 48.77163559016703686666\n",
      "Iteration 18639 => Loss: 48.77145326177769391052\n",
      "Iteration 18640 => Loss: 48.77127093481926323193\n",
      "Iteration 18641 => Loss: 48.77108860929171640919\n",
      "Iteration 18642 => Loss: 48.77090628519506765315\n",
      "Iteration 18643 => Loss: 48.77072396252928854210\n",
      "Iteration 18644 => Loss: 48.77054164129434354891\n",
      "Iteration 18645 => Loss: 48.77035932149026820071\n",
      "Iteration 18646 => Loss: 48.77017700311701275950\n",
      "Iteration 18647 => Loss: 48.76999468617459854158\n",
      "Iteration 18648 => Loss: 48.76981237066298291438\n",
      "Iteration 18649 => Loss: 48.76963005658218719418\n",
      "Iteration 18650 => Loss: 48.76944774393216164299\n",
      "Iteration 18651 => Loss: 48.76926543271294178794\n",
      "Iteration 18652 => Loss: 48.76908312292447078562\n",
      "Iteration 18653 => Loss: 48.76890081456675574145\n",
      "Iteration 18654 => Loss: 48.76871850763980376087\n",
      "Iteration 18655 => Loss: 48.76853620214357931673\n",
      "Iteration 18656 => Loss: 48.76835389807807530360\n",
      "Iteration 18657 => Loss: 48.76817159544328461607\n",
      "Iteration 18658 => Loss: 48.76798929423921435955\n",
      "Iteration 18659 => Loss: 48.76780699446579347978\n",
      "Iteration 18660 => Loss: 48.76762469612307882016\n",
      "Iteration 18661 => Loss: 48.76744239921102774815\n",
      "Iteration 18662 => Loss: 48.76726010372964026374\n",
      "Iteration 18663 => Loss: 48.76707780967888794521\n",
      "Iteration 18664 => Loss: 48.76689551705877789800\n",
      "Iteration 18665 => Loss: 48.76671322586929591125\n",
      "Iteration 18666 => Loss: 48.76653093611039224697\n",
      "Iteration 18667 => Loss: 48.76634864778212374858\n",
      "Iteration 18668 => Loss: 48.76616636088441936181\n",
      "Iteration 18669 => Loss: 48.76598407541731461379\n",
      "Iteration 18670 => Loss: 48.76580179138075976653\n",
      "Iteration 18671 => Loss: 48.76561950877477613631\n",
      "Iteration 18672 => Loss: 48.76543722759932819599\n",
      "Iteration 18673 => Loss: 48.76525494785442305101\n",
      "Iteration 18674 => Loss: 48.76507266954005359594\n",
      "Iteration 18675 => Loss: 48.76489039265615588192\n",
      "Iteration 18676 => Loss: 48.76470811720277254153\n",
      "Iteration 18677 => Loss: 48.76452584317987515306\n",
      "Iteration 18678 => Loss: 48.76434357058745661107\n",
      "Iteration 18679 => Loss: 48.76416129942551691556\n",
      "Iteration 18680 => Loss: 48.76397902969402764484\n",
      "Iteration 18681 => Loss: 48.76379676139296748261\n",
      "Iteration 18682 => Loss: 48.76361449452233642887\n",
      "Iteration 18683 => Loss: 48.76343222908213448363\n",
      "Iteration 18684 => Loss: 48.76324996507236875232\n",
      "Iteration 18685 => Loss: 48.76306770249295396980\n",
      "Iteration 18686 => Loss: 48.76288544134396829577\n",
      "Iteration 18687 => Loss: 48.76270318162531225425\n",
      "Iteration 18688 => Loss: 48.76252092333706400495\n",
      "Iteration 18689 => Loss: 48.76233866647913828274\n",
      "Iteration 18690 => Loss: 48.76215641105157772017\n",
      "Iteration 18691 => Loss: 48.76197415705434679012\n",
      "Iteration 18692 => Loss: 48.76179190448743128172\n",
      "Iteration 18693 => Loss: 48.76160965335082408956\n",
      "Iteration 18694 => Loss: 48.76142740364450389734\n",
      "Iteration 18695 => Loss: 48.76124515536849202135\n",
      "Iteration 18696 => Loss: 48.76106290852273872360\n",
      "Iteration 18697 => Loss: 48.76088066310722979324\n",
      "Iteration 18698 => Loss: 48.76069841912200075740\n",
      "Iteration 18699 => Loss: 48.76051617656700898351\n",
      "Iteration 18700 => Loss: 48.76033393544223315530\n",
      "Iteration 18701 => Loss: 48.76015169574770879990\n",
      "Iteration 18702 => Loss: 48.75996945748336486304\n",
      "Iteration 18703 => Loss: 48.75978722064921555557\n",
      "Iteration 18704 => Loss: 48.75960498524526087749\n",
      "Iteration 18705 => Loss: 48.75942275127150082881\n",
      "Iteration 18706 => Loss: 48.75924051872787856610\n",
      "Iteration 18707 => Loss: 48.75905828761440830021\n",
      "Iteration 18708 => Loss: 48.75887605793106871488\n",
      "Iteration 18709 => Loss: 48.75869382967787402094\n",
      "Iteration 18710 => Loss: 48.75851160285479579670\n",
      "Iteration 18711 => Loss: 48.75832937746180562044\n",
      "Iteration 18712 => Loss: 48.75814715349895323016\n",
      "Iteration 18713 => Loss: 48.75796493096615336071\n",
      "Iteration 18714 => Loss: 48.75778270986341311755\n",
      "Iteration 18715 => Loss: 48.75760049019075381693\n",
      "Iteration 18716 => Loss: 48.75741827194814703716\n",
      "Iteration 18717 => Loss: 48.75723605513558567282\n",
      "Iteration 18718 => Loss: 48.75705383975304130217\n",
      "Iteration 18719 => Loss: 48.75687162580049971439\n",
      "Iteration 18720 => Loss: 48.75668941327798222574\n",
      "Iteration 18721 => Loss: 48.75650720218546751994\n",
      "Iteration 18722 => Loss: 48.75632499252293428071\n",
      "Iteration 18723 => Loss: 48.75614278429033277007\n",
      "Iteration 18724 => Loss: 48.75596057748773404228\n",
      "Iteration 18725 => Loss: 48.75577837211507414850\n",
      "Iteration 18726 => Loss: 48.75559616817235308872\n",
      "Iteration 18727 => Loss: 48.75541396565954954667\n",
      "Iteration 18728 => Loss: 48.75523176457667062778\n",
      "Iteration 18729 => Loss: 48.75504956492369501575\n",
      "Iteration 18730 => Loss: 48.75486736670061560517\n",
      "Iteration 18731 => Loss: 48.75468516990740397432\n",
      "Iteration 18732 => Loss: 48.75450297454408854492\n",
      "Iteration 18733 => Loss: 48.75432078061060536811\n",
      "Iteration 18734 => Loss: 48.75413858810698286561\n",
      "Iteration 18735 => Loss: 48.75395639703318551028\n",
      "Iteration 18736 => Loss: 48.75377420738924882926\n",
      "Iteration 18737 => Loss: 48.75359201917509466284\n",
      "Iteration 18738 => Loss: 48.75340983239076564359\n",
      "Iteration 18739 => Loss: 48.75322764703620492810\n",
      "Iteration 18740 => Loss: 48.75304546311143383264\n",
      "Iteration 18741 => Loss: 48.75286328061642393550\n",
      "Iteration 18742 => Loss: 48.75268109955118944754\n",
      "Iteration 18743 => Loss: 48.75249891991570194705\n",
      "Iteration 18744 => Loss: 48.75231674170995432860\n",
      "Iteration 18745 => Loss: 48.75213456493391106505\n",
      "Iteration 18746 => Loss: 48.75195238958760768355\n",
      "Iteration 18747 => Loss: 48.75177021567098023525\n",
      "Iteration 18748 => Loss: 48.75158804318405714184\n",
      "Iteration 18749 => Loss: 48.75140587212681708706\n",
      "Iteration 18750 => Loss: 48.75122370249925296548\n",
      "Iteration 18751 => Loss: 48.75104153430132924996\n",
      "Iteration 18752 => Loss: 48.75085936753304594049\n",
      "Iteration 18753 => Loss: 48.75067720219441724794\n",
      "Iteration 18754 => Loss: 48.75049503828540053973\n",
      "Iteration 18755 => Loss: 48.75031287580600292131\n",
      "Iteration 18756 => Loss: 48.75013071475621018180\n",
      "Iteration 18757 => Loss: 48.74994855513601521579\n",
      "Iteration 18758 => Loss: 48.74976639694538249614\n",
      "Iteration 18759 => Loss: 48.74958424018431912828\n",
      "Iteration 18760 => Loss: 48.74940208485282511219\n",
      "Iteration 18761 => Loss: 48.74921993095086492076\n",
      "Iteration 18762 => Loss: 48.74903777847844565940\n",
      "Iteration 18763 => Loss: 48.74885562743553180098\n",
      "Iteration 18764 => Loss: 48.74867347782213755636\n",
      "Iteration 18765 => Loss: 48.74849132963827003096\n",
      "Iteration 18766 => Loss: 48.74830918288386527593\n",
      "Iteration 18767 => Loss: 48.74812703755895171298\n",
      "Iteration 18768 => Loss: 48.74794489366347960413\n",
      "Iteration 18769 => Loss: 48.74776275119747737108\n",
      "Iteration 18770 => Loss: 48.74758061016091659212\n",
      "Iteration 18771 => Loss: 48.74739847055380437268\n",
      "Iteration 18772 => Loss: 48.74721633237611939649\n",
      "Iteration 18773 => Loss: 48.74703419562782613639\n",
      "Iteration 18774 => Loss: 48.74685206030893880325\n",
      "Iteration 18775 => Loss: 48.74666992641945029163\n",
      "Iteration 18776 => Loss: 48.74648779395931796898\n",
      "Iteration 18777 => Loss: 48.74630566292857736244\n",
      "Iteration 18778 => Loss: 48.74612353332715741772\n",
      "Iteration 18779 => Loss: 48.74594140515510076739\n",
      "Iteration 18780 => Loss: 48.74575927841238609517\n",
      "Iteration 18781 => Loss: 48.74557715309897076850\n",
      "Iteration 18782 => Loss: 48.74539502921488320908\n",
      "Iteration 18783 => Loss: 48.74521290676008078435\n",
      "Iteration 18784 => Loss: 48.74503078573458481060\n",
      "Iteration 18785 => Loss: 48.74484866613834554983\n",
      "Iteration 18786 => Loss: 48.74466654797137010746\n",
      "Iteration 18787 => Loss: 48.74448443123367269436\n",
      "Iteration 18788 => Loss: 48.74430231592518225625\n",
      "Iteration 18789 => Loss: 48.74412020204595563655\n",
      "Iteration 18790 => Loss: 48.74393808959593599184\n",
      "Iteration 18791 => Loss: 48.74375597857512332212\n",
      "Iteration 18792 => Loss: 48.74357386898351052196\n",
      "Iteration 18793 => Loss: 48.74339176082110469679\n",
      "Iteration 18794 => Loss: 48.74320965408784189776\n",
      "Iteration 18795 => Loss: 48.74302754878374344116\n",
      "Iteration 18796 => Loss: 48.74284544490881643242\n",
      "Iteration 18797 => Loss: 48.74266334246301823896\n",
      "Iteration 18798 => Loss: 48.74248124144634886079\n",
      "Iteration 18799 => Loss: 48.74229914185881540334\n",
      "Iteration 18800 => Loss: 48.74211704370038233947\n",
      "Iteration 18801 => Loss: 48.74193494697104256375\n",
      "Iteration 18802 => Loss: 48.74175285167080318161\n",
      "Iteration 18803 => Loss: 48.74157075779961445505\n",
      "Iteration 18804 => Loss: 48.74138866535749059494\n",
      "Iteration 18805 => Loss: 48.74120657434443160128\n",
      "Iteration 18806 => Loss: 48.74102448476040194691\n",
      "Iteration 18807 => Loss: 48.74084239660540163186\n",
      "Iteration 18808 => Loss: 48.74066030987944486697\n",
      "Iteration 18809 => Loss: 48.74047822458246770339\n",
      "Iteration 18810 => Loss: 48.74029614071449856283\n",
      "Iteration 18811 => Loss: 48.74011405827550191816\n",
      "Iteration 18812 => Loss: 48.73993197726549908566\n",
      "Iteration 18813 => Loss: 48.73974989768444743277\n",
      "Iteration 18814 => Loss: 48.73956781953233274862\n",
      "Iteration 18815 => Loss: 48.73938574280918345494\n",
      "Iteration 18816 => Loss: 48.73920366751493560287\n",
      "Iteration 18817 => Loss: 48.73902159364961761412\n",
      "Iteration 18818 => Loss: 48.73883952121321527784\n",
      "Iteration 18819 => Loss: 48.73865745020570017232\n",
      "Iteration 18820 => Loss: 48.73847538062707940298\n",
      "Iteration 18821 => Loss: 48.73829331247731744270\n",
      "Iteration 18822 => Loss: 48.73811124575643560775\n",
      "Iteration 18823 => Loss: 48.73792918046437705470\n",
      "Iteration 18824 => Loss: 48.73774711660117731071\n",
      "Iteration 18825 => Loss: 48.73756505416679374321\n",
      "Iteration 18826 => Loss: 48.73738299316121924676\n",
      "Iteration 18827 => Loss: 48.73720093358446803222\n",
      "Iteration 18828 => Loss: 48.73701887543649746704\n",
      "Iteration 18829 => Loss: 48.73683681871730044577\n",
      "Iteration 18830 => Loss: 48.73665476342690539013\n",
      "Iteration 18831 => Loss: 48.73647270956525545671\n",
      "Iteration 18832 => Loss: 48.73629065713234354007\n",
      "Iteration 18833 => Loss: 48.73610860612819806192\n",
      "Iteration 18834 => Loss: 48.73592655655276217885\n",
      "Iteration 18835 => Loss: 48.73574450840604299628\n",
      "Iteration 18836 => Loss: 48.73556246168803340879\n",
      "Iteration 18837 => Loss: 48.73538041639869078381\n",
      "Iteration 18838 => Loss: 48.73519837253804354305\n",
      "Iteration 18839 => Loss: 48.73501633010607747565\n",
      "Iteration 18840 => Loss: 48.73483428910277126533\n",
      "Iteration 18841 => Loss: 48.73465224952811070125\n",
      "Iteration 18842 => Loss: 48.73447021138207446711\n",
      "Iteration 18843 => Loss: 48.73428817466466966835\n",
      "Iteration 18844 => Loss: 48.73410613937589630495\n",
      "Iteration 18845 => Loss: 48.73392410551569753352\n",
      "Iteration 18846 => Loss: 48.73374207308411598660\n",
      "Iteration 18847 => Loss: 48.73356004208110192621\n",
      "Iteration 18848 => Loss: 48.73337801250666956321\n",
      "Iteration 18849 => Loss: 48.73319598436077626502\n",
      "Iteration 18850 => Loss: 48.73301395764343624251\n",
      "Iteration 18851 => Loss: 48.73283193235464239024\n",
      "Iteration 18852 => Loss: 48.73264990849437339193\n",
      "Iteration 18853 => Loss: 48.73246788606260082588\n",
      "Iteration 18854 => Loss: 48.73228586505933179751\n",
      "Iteration 18855 => Loss: 48.73210384548459472853\n",
      "Iteration 18856 => Loss: 48.73192182733829724839\n",
      "Iteration 18857 => Loss: 48.73173981062047488422\n",
      "Iteration 18858 => Loss: 48.73155779533112053059\n",
      "Iteration 18859 => Loss: 48.73137578147021997665\n",
      "Iteration 18860 => Loss: 48.73119376903773058984\n",
      "Iteration 18861 => Loss: 48.73101175803366658101\n",
      "Iteration 18862 => Loss: 48.73082974845802084474\n",
      "Iteration 18863 => Loss: 48.73064774031077917016\n",
      "Iteration 18864 => Loss: 48.73046573359194155728\n",
      "Iteration 18865 => Loss: 48.73028372830147958439\n",
      "Iteration 18866 => Loss: 48.73010172443937193520\n",
      "Iteration 18867 => Loss: 48.72991972200563282058\n",
      "Iteration 18868 => Loss: 48.72973772100021250253\n",
      "Iteration 18869 => Loss: 48.72955572142315361361\n",
      "Iteration 18870 => Loss: 48.72937372327441352127\n",
      "Iteration 18871 => Loss: 48.72919172655398512006\n",
      "Iteration 18872 => Loss: 48.72900973126184709372\n",
      "Iteration 18873 => Loss: 48.72882773739801365309\n",
      "Iteration 18874 => Loss: 48.72864574496245637647\n",
      "Iteration 18875 => Loss: 48.72846375395516105300\n",
      "Iteration 18876 => Loss: 48.72828176437611347183\n",
      "Iteration 18877 => Loss: 48.72809977622531363295\n",
      "Iteration 18878 => Loss: 48.72791778950274732551\n",
      "Iteration 18879 => Loss: 48.72773580420840744409\n",
      "Iteration 18880 => Loss: 48.72755382034228688326\n",
      "Iteration 18881 => Loss: 48.72737183790437853759\n",
      "Iteration 18882 => Loss: 48.72718985689461845823\n",
      "Iteration 18883 => Loss: 48.72700787731305638317\n",
      "Iteration 18884 => Loss: 48.72682589915965678529\n",
      "Iteration 18885 => Loss: 48.72664392243443387542\n",
      "Iteration 18886 => Loss: 48.72646194713731659931\n",
      "Iteration 18887 => Loss: 48.72627997326835469494\n",
      "Iteration 18888 => Loss: 48.72609800082751263517\n",
      "Iteration 18889 => Loss: 48.72591602981479042001\n",
      "Iteration 18890 => Loss: 48.72573406023013831145\n",
      "Iteration 18891 => Loss: 48.72555209207361315293\n",
      "Iteration 18892 => Loss: 48.72537012534511546846\n",
      "Iteration 18893 => Loss: 48.72518816004472341774\n",
      "Iteration 18894 => Loss: 48.72500619617236594650\n",
      "Iteration 18895 => Loss: 48.72482423372805726558\n",
      "Iteration 18896 => Loss: 48.72464227271178316414\n",
      "Iteration 18897 => Loss: 48.72446031312352232590\n",
      "Iteration 18898 => Loss: 48.72427835496328185627\n",
      "Iteration 18899 => Loss: 48.72409639823102622813\n",
      "Iteration 18900 => Loss: 48.72391444292678386319\n",
      "Iteration 18901 => Loss: 48.72373248905049791802\n",
      "Iteration 18902 => Loss: 48.72355053660216128719\n",
      "Iteration 18903 => Loss: 48.72336858558178818157\n",
      "Iteration 18904 => Loss: 48.72318663598937149573\n",
      "Iteration 18905 => Loss: 48.72300468782486859709\n",
      "Iteration 18906 => Loss: 48.72282274108828659109\n",
      "Iteration 18907 => Loss: 48.72264079577962547773\n",
      "Iteration 18908 => Loss: 48.72245885189884262445\n",
      "Iteration 18909 => Loss: 48.72227690944597355838\n",
      "Iteration 18910 => Loss: 48.72209496842096143610\n",
      "Iteration 18911 => Loss: 48.72191302882379204675\n",
      "Iteration 18912 => Loss: 48.72173109065451512834\n",
      "Iteration 18913 => Loss: 48.72154915391305962657\n",
      "Iteration 18914 => Loss: 48.72136721859943975232\n",
      "Iteration 18915 => Loss: 48.72118528471362708387\n",
      "Iteration 18916 => Loss: 48.72100335225562872665\n",
      "Iteration 18917 => Loss: 48.72082142122544468066\n",
      "Iteration 18918 => Loss: 48.72063949162303231333\n",
      "Iteration 18919 => Loss: 48.72045756344837030838\n",
      "Iteration 18920 => Loss: 48.72027563670150840380\n",
      "Iteration 18921 => Loss: 48.72009371138236843990\n",
      "Iteration 18922 => Loss: 48.71991178749098594380\n",
      "Iteration 18923 => Loss: 48.71972986502731828296\n",
      "Iteration 18924 => Loss: 48.71954794399139387906\n",
      "Iteration 18925 => Loss: 48.71936602438315588870\n",
      "Iteration 18926 => Loss: 48.71918410620261852273\n",
      "Iteration 18927 => Loss: 48.71900218944976757030\n",
      "Iteration 18928 => Loss: 48.71882027412458882054\n",
      "Iteration 18929 => Loss: 48.71863836022708227347\n",
      "Iteration 18930 => Loss: 48.71845644775719819108\n",
      "Iteration 18931 => Loss: 48.71827453671496499510\n",
      "Iteration 18932 => Loss: 48.71809262710036847466\n",
      "Iteration 18933 => Loss: 48.71791071891338731348\n",
      "Iteration 18934 => Loss: 48.71772881215401440613\n",
      "Iteration 18935 => Loss: 48.71754690682222843634\n",
      "Iteration 18936 => Loss: 48.71736500291803650953\n",
      "Iteration 18937 => Loss: 48.71718310044139599313\n",
      "Iteration 18938 => Loss: 48.71700119939233530886\n",
      "Iteration 18939 => Loss: 48.71681929977084024586\n",
      "Iteration 18940 => Loss: 48.71663740157685396071\n",
      "Iteration 18941 => Loss: 48.71645550481040487512\n",
      "Iteration 18942 => Loss: 48.71627360947147167280\n",
      "Iteration 18943 => Loss: 48.71609171556005435377\n",
      "Iteration 18944 => Loss: 48.71590982307611028546\n",
      "Iteration 18945 => Loss: 48.71572793201965367871\n",
      "Iteration 18946 => Loss: 48.71554604239068453353\n",
      "Iteration 18947 => Loss: 48.71536415418916021736\n",
      "Iteration 18948 => Loss: 48.71518226741508783562\n",
      "Iteration 18949 => Loss: 48.71500038206844607203\n",
      "Iteration 18950 => Loss: 48.71481849814924203201\n",
      "Iteration 18951 => Loss: 48.71463661565745439930\n",
      "Iteration 18952 => Loss: 48.71445473459306896302\n",
      "Iteration 18953 => Loss: 48.71427285495607861776\n",
      "Iteration 18954 => Loss: 48.71409097674644783638\n",
      "Iteration 18955 => Loss: 48.71390909996423346229\n",
      "Iteration 18956 => Loss: 48.71372722460932180866\n",
      "Iteration 18957 => Loss: 48.71354535068179814061\n",
      "Iteration 18958 => Loss: 48.71336347818159850931\n",
      "Iteration 18959 => Loss: 48.71318160710874423103\n",
      "Iteration 18960 => Loss: 48.71299973746315714607\n",
      "Iteration 18961 => Loss: 48.71281786924490830870\n",
      "Iteration 18962 => Loss: 48.71263600245394087551\n",
      "Iteration 18963 => Loss: 48.71245413709027616278\n",
      "Iteration 18964 => Loss: 48.71227227315387153794\n",
      "Iteration 18965 => Loss: 48.71209041064471989557\n",
      "Iteration 18966 => Loss: 48.71190854956279991939\n",
      "Iteration 18967 => Loss: 48.71172668990814003109\n",
      "Iteration 18968 => Loss: 48.71154483168069759813\n",
      "Iteration 18969 => Loss: 48.71136297488046551507\n",
      "Iteration 18970 => Loss: 48.71118111950744378191\n",
      "Iteration 18971 => Loss: 48.71099926556161818780\n",
      "Iteration 18972 => Loss: 48.71081741304296741646\n",
      "Iteration 18973 => Loss: 48.71063556195147015160\n",
      "Iteration 18974 => Loss: 48.71045371228714060408\n",
      "Iteration 18975 => Loss: 48.71027186404996456304\n",
      "Iteration 18976 => Loss: 48.71009001723992071220\n",
      "Iteration 18977 => Loss: 48.70990817185696641900\n",
      "Iteration 18978 => Loss: 48.70972632790117984314\n",
      "Iteration 18979 => Loss: 48.70954448537247571949\n",
      "Iteration 18980 => Loss: 48.70936264427086115347\n",
      "Iteration 18981 => Loss: 48.70918080459634325052\n",
      "Iteration 18982 => Loss: 48.70899896634885806179\n",
      "Iteration 18983 => Loss: 48.70881712952843400899\n",
      "Iteration 18984 => Loss: 48.70863529413505688126\n",
      "Iteration 18985 => Loss: 48.70845346016874088946\n",
      "Iteration 18986 => Loss: 48.70827162762942208474\n",
      "Iteration 18987 => Loss: 48.70808979651713599424\n",
      "Iteration 18988 => Loss: 48.70790796683184709082\n",
      "Iteration 18989 => Loss: 48.70772613857354116362\n",
      "Iteration 18990 => Loss: 48.70754431174221110723\n",
      "Iteration 18991 => Loss: 48.70736248633785692164\n",
      "Iteration 18992 => Loss: 48.70718066236044307971\n",
      "Iteration 18993 => Loss: 48.70699883980996247601\n",
      "Iteration 18994 => Loss: 48.70681701868646484854\n",
      "Iteration 18995 => Loss: 48.70663519898986493217\n",
      "Iteration 18996 => Loss: 48.70645338072017693776\n",
      "Iteration 18997 => Loss: 48.70627156387737954901\n",
      "Iteration 18998 => Loss: 48.70608974846147987137\n",
      "Iteration 18999 => Loss: 48.70590793447244948311\n",
      "Iteration 19000 => Loss: 48.70572612191030259510\n",
      "Iteration 19001 => Loss: 48.70554431077500368019\n",
      "Iteration 19002 => Loss: 48.70536250106653852754\n",
      "Iteration 19003 => Loss: 48.70518069278491424257\n",
      "Iteration 19004 => Loss: 48.70499888593012371985\n",
      "Iteration 19005 => Loss: 48.70481708050212432681\n",
      "Iteration 19006 => Loss: 48.70463527650093027432\n",
      "Iteration 19007 => Loss: 48.70445347392651314067\n",
      "Iteration 19008 => Loss: 48.70427167277890134756\n",
      "Iteration 19009 => Loss: 48.70408987305803094614\n",
      "Iteration 19010 => Loss: 48.70390807476391614728\n",
      "Iteration 19011 => Loss: 48.70372627789657116182\n",
      "Iteration 19012 => Loss: 48.70354448245592493549\n",
      "Iteration 19013 => Loss: 48.70336268844202720629\n",
      "Iteration 19014 => Loss: 48.70318089585482823622\n",
      "Iteration 19015 => Loss: 48.70299910469432091986\n",
      "Iteration 19016 => Loss: 48.70281731496049815178\n",
      "Iteration 19017 => Loss: 48.70263552665338124825\n",
      "Iteration 19018 => Loss: 48.70245373977289915501\n",
      "Iteration 19019 => Loss: 48.70227195431908029377\n",
      "Iteration 19020 => Loss: 48.70209017029189624282\n",
      "Iteration 19021 => Loss: 48.70190838769136121300\n",
      "Iteration 19022 => Loss: 48.70172660651744678262\n",
      "Iteration 19023 => Loss: 48.70154482677011742453\n",
      "Iteration 19024 => Loss: 48.70136304844940156045\n",
      "Iteration 19025 => Loss: 48.70118127155525655780\n",
      "Iteration 19026 => Loss: 48.70099949608771083831\n",
      "Iteration 19027 => Loss: 48.70081772204672176940\n",
      "Iteration 19028 => Loss: 48.70063594943228224565\n",
      "Iteration 19029 => Loss: 48.70045417824438516163\n",
      "Iteration 19030 => Loss: 48.70027240848303051735\n",
      "Iteration 19031 => Loss: 48.70009064014817568022\n",
      "Iteration 19032 => Loss: 48.69990887323983486112\n",
      "Iteration 19033 => Loss: 48.69972710775799384919\n",
      "Iteration 19034 => Loss: 48.69954534370264553900\n",
      "Iteration 19035 => Loss: 48.69936358107375440341\n",
      "Iteration 19036 => Loss: 48.69918181987134175870\n",
      "Iteration 19037 => Loss: 48.69900006009539339402\n",
      "Iteration 19038 => Loss: 48.69881830174587378224\n",
      "Iteration 19039 => Loss: 48.69863654482276871249\n",
      "Iteration 19040 => Loss: 48.69845478932608529021\n",
      "Iteration 19041 => Loss: 48.69827303525582351540\n",
      "Iteration 19042 => Loss: 48.69809128261197628262\n",
      "Iteration 19043 => Loss: 48.69790953139448674847\n",
      "Iteration 19044 => Loss: 48.69772778160334780750\n",
      "Iteration 19045 => Loss: 48.69754603323859498687\n",
      "Iteration 19046 => Loss: 48.69736428630020697028\n",
      "Iteration 19047 => Loss: 48.69718254078815533603\n",
      "Iteration 19048 => Loss: 48.69700079670243297869\n",
      "Iteration 19049 => Loss: 48.69681905404301858198\n",
      "Iteration 19050 => Loss: 48.69663731280991214589\n",
      "Iteration 19051 => Loss: 48.69645557300310656501\n",
      "Iteration 19052 => Loss: 48.69627383462260183933\n",
      "Iteration 19053 => Loss: 48.69609209766834112543\n",
      "Iteration 19054 => Loss: 48.69591036214036705587\n",
      "Iteration 19055 => Loss: 48.69572862803860857639\n",
      "Iteration 19056 => Loss: 48.69554689536312963583\n",
      "Iteration 19057 => Loss: 48.69536516411385917991\n",
      "Iteration 19058 => Loss: 48.69518343429079720863\n",
      "Iteration 19059 => Loss: 48.69500170589395793286\n",
      "Iteration 19060 => Loss: 48.69481997892330582545\n",
      "Iteration 19061 => Loss: 48.69463825337884799183\n",
      "Iteration 19062 => Loss: 48.69445652926054890486\n",
      "Iteration 19063 => Loss: 48.69427480656842277540\n",
      "Iteration 19064 => Loss: 48.69409308530242697088\n",
      "Iteration 19065 => Loss: 48.69391136546258991302\n",
      "Iteration 19066 => Loss: 48.69372964704886896925\n",
      "Iteration 19067 => Loss: 48.69354793006126413957\n",
      "Iteration 19068 => Loss: 48.69336621449978963483\n",
      "Iteration 19069 => Loss: 48.69318450036439571704\n",
      "Iteration 19070 => Loss: 48.69300278765506817535\n",
      "Iteration 19071 => Loss: 48.69282107637182122062\n",
      "Iteration 19072 => Loss: 48.69263936651463353655\n",
      "Iteration 19073 => Loss: 48.69245765808350512316\n",
      "Iteration 19074 => Loss: 48.69227595107840045330\n",
      "Iteration 19075 => Loss: 48.69209424549935505411\n",
      "Iteration 19076 => Loss: 48.69191254134627655503\n",
      "Iteration 19077 => Loss: 48.69173083861922179949\n",
      "Iteration 19078 => Loss: 48.69154913731818368205\n",
      "Iteration 19079 => Loss: 48.69136743744310535931\n",
      "Iteration 19080 => Loss: 48.69118573899400104210\n",
      "Iteration 19081 => Loss: 48.69100404197085651958\n",
      "Iteration 19082 => Loss: 48.69082234637367889718\n",
      "Iteration 19083 => Loss: 48.69064065220242554233\n",
      "Iteration 19084 => Loss: 48.69045895945706803332\n",
      "Iteration 19085 => Loss: 48.69027726813765610814\n",
      "Iteration 19086 => Loss: 48.69009557824415423966\n",
      "Iteration 19087 => Loss: 48.68991388977654111159\n",
      "Iteration 19088 => Loss: 48.68973220273480961851\n",
      "Iteration 19089 => Loss: 48.68955051711893844413\n",
      "Iteration 19090 => Loss: 48.68936883292892048303\n",
      "Iteration 19091 => Loss: 48.68918715016477705149\n",
      "Iteration 19092 => Loss: 48.68900546882644420066\n",
      "Iteration 19093 => Loss: 48.68882378891394324683\n",
      "Iteration 19094 => Loss: 48.68864211042725997913\n",
      "Iteration 19095 => Loss: 48.68846043336638018673\n",
      "Iteration 19096 => Loss: 48.68827875773129676418\n",
      "Iteration 19097 => Loss: 48.68809708352199550063\n",
      "Iteration 19098 => Loss: 48.68791541073845507981\n",
      "Iteration 19099 => Loss: 48.68773373938067550171\n",
      "Iteration 19100 => Loss: 48.68755206944863545004\n",
      "Iteration 19101 => Loss: 48.68737040094234913568\n",
      "Iteration 19102 => Loss: 48.68718873386177392604\n",
      "Iteration 19103 => Loss: 48.68700706820691692656\n",
      "Iteration 19104 => Loss: 48.68682540397777813723\n",
      "Iteration 19105 => Loss: 48.68664374117430071465\n",
      "Iteration 19106 => Loss: 48.68646207979651308051\n",
      "Iteration 19107 => Loss: 48.68628041984442234025\n",
      "Iteration 19108 => Loss: 48.68609876131795743959\n",
      "Iteration 19109 => Loss: 48.68591710421712548396\n",
      "Iteration 19110 => Loss: 48.68573544854196910592\n",
      "Iteration 19111 => Loss: 48.68555379429241014577\n",
      "Iteration 19112 => Loss: 48.68537214146846991980\n",
      "Iteration 19113 => Loss: 48.68519049007014132258\n",
      "Iteration 19114 => Loss: 48.68500884009738882696\n",
      "Iteration 19115 => Loss: 48.68482719155023374924\n",
      "Iteration 19116 => Loss: 48.68464554442861924599\n",
      "Iteration 19117 => Loss: 48.68446389873260926606\n",
      "Iteration 19118 => Loss: 48.68428225446210433347\n",
      "Iteration 19119 => Loss: 48.68410061161712576450\n",
      "Iteration 19120 => Loss: 48.68391897019770198085\n",
      "Iteration 19121 => Loss: 48.68373733020377613911\n",
      "Iteration 19122 => Loss: 48.68355569163536955557\n",
      "Iteration 19123 => Loss: 48.68337405449241117594\n",
      "Iteration 19124 => Loss: 48.68319241877495073823\n",
      "Iteration 19125 => Loss: 48.68301078448297403156\n",
      "Iteration 19126 => Loss: 48.68282915161643842339\n",
      "Iteration 19127 => Loss: 48.68264752017536522999\n",
      "Iteration 19128 => Loss: 48.68246589015971181880\n",
      "Iteration 19129 => Loss: 48.68228426156949240067\n",
      "Iteration 19130 => Loss: 48.68210263440467144846\n",
      "Iteration 19131 => Loss: 48.68192100866524896219\n",
      "Iteration 19132 => Loss: 48.68173938435123915269\n",
      "Iteration 19133 => Loss: 48.68155776146257807113\n",
      "Iteration 19134 => Loss: 48.68137613999930835007\n",
      "Iteration 19135 => Loss: 48.68119451996135893523\n",
      "Iteration 19136 => Loss: 48.68101290134877956461\n",
      "Iteration 19137 => Loss: 48.68083128416152760565\n",
      "Iteration 19138 => Loss: 48.68064966839961726919\n",
      "Iteration 19139 => Loss: 48.68046805406299881724\n",
      "Iteration 19140 => Loss: 48.68028644115168646067\n",
      "Iteration 19141 => Loss: 48.68010482966565177776\n",
      "Iteration 19142 => Loss: 48.67992321960490897936\n",
      "Iteration 19143 => Loss: 48.67974161096941543292\n",
      "Iteration 19144 => Loss: 48.67956000375920666556\n",
      "Iteration 19145 => Loss: 48.67937839797421162302\n",
      "Iteration 19146 => Loss: 48.67919679361444451615\n",
      "Iteration 19147 => Loss: 48.67901519067991955581\n",
      "Iteration 19148 => Loss: 48.67883358917059410942\n",
      "Iteration 19149 => Loss: 48.67865198908647528242\n",
      "Iteration 19150 => Loss: 48.67847039042754175853\n",
      "Iteration 19151 => Loss: 48.67828879319377932688\n",
      "Iteration 19152 => Loss: 48.67810719738520219835\n",
      "Iteration 19153 => Loss: 48.67792560300174642407\n",
      "Iteration 19154 => Loss: 48.67774401004346174204\n",
      "Iteration 19155 => Loss: 48.67756241851030551970\n",
      "Iteration 19156 => Loss: 48.67738082840226354620\n",
      "Iteration 19157 => Loss: 48.67719923971932161066\n",
      "Iteration 19158 => Loss: 48.67701765246150813482\n",
      "Iteration 19159 => Loss: 48.67683606662875206439\n",
      "Iteration 19160 => Loss: 48.67665448222106761023\n",
      "Iteration 19161 => Loss: 48.67647289923847608861\n",
      "Iteration 19162 => Loss: 48.67629131768093486698\n",
      "Iteration 19163 => Loss: 48.67610973754841552363\n",
      "Iteration 19164 => Loss: 48.67592815884094648027\n",
      "Iteration 19165 => Loss: 48.67574658155847799890\n",
      "Iteration 19166 => Loss: 48.67556500570103850123\n",
      "Iteration 19167 => Loss: 48.67538343126857824927\n",
      "Iteration 19168 => Loss: 48.67520185826111855931\n",
      "Iteration 19169 => Loss: 48.67502028667863100964\n",
      "Iteration 19170 => Loss: 48.67483871652110138939\n",
      "Iteration 19171 => Loss: 48.67465714778853680400\n",
      "Iteration 19172 => Loss: 48.67447558048091593719\n",
      "Iteration 19173 => Loss: 48.67429401459821036724\n",
      "Iteration 19174 => Loss: 48.67411245014042719959\n",
      "Iteration 19175 => Loss: 48.67393088710753801251\n",
      "Iteration 19176 => Loss: 48.67374932549958543859\n",
      "Iteration 19177 => Loss: 48.67356776531649842354\n",
      "Iteration 19178 => Loss: 48.67338620655828407280\n",
      "Iteration 19179 => Loss: 48.67320464922494238635\n",
      "Iteration 19180 => Loss: 48.67302309331643783707\n",
      "Iteration 19181 => Loss: 48.67284153883279174124\n",
      "Iteration 19182 => Loss: 48.67265998577395436087\n",
      "Iteration 19183 => Loss: 48.67247843413993990680\n",
      "Iteration 19184 => Loss: 48.67229688393074127362\n",
      "Iteration 19185 => Loss: 48.67211533514633003961\n",
      "Iteration 19186 => Loss: 48.67193378778672041562\n",
      "Iteration 19187 => Loss: 48.67175224185187687453\n",
      "Iteration 19188 => Loss: 48.67157069734179941634\n",
      "Iteration 19189 => Loss: 48.67138915425645251389\n",
      "Iteration 19190 => Loss: 48.67120761259587879977\n",
      "Iteration 19191 => Loss: 48.67102607236002143054\n",
      "Iteration 19192 => Loss: 48.67084453354886619536\n",
      "Iteration 19193 => Loss: 48.67066299616243441051\n",
      "Iteration 19194 => Loss: 48.67048146020069765427\n",
      "Iteration 19195 => Loss: 48.67029992566364882123\n",
      "Iteration 19196 => Loss: 48.67011839255127370052\n",
      "Iteration 19197 => Loss: 48.66993686086355097586\n",
      "Iteration 19198 => Loss: 48.66975533060048775269\n",
      "Iteration 19199 => Loss: 48.66957380176204850386\n",
      "Iteration 19200 => Loss: 48.66939227434825454566\n",
      "Iteration 19201 => Loss: 48.66921074835907745637\n",
      "Iteration 19202 => Loss: 48.66902922379451013057\n",
      "Iteration 19203 => Loss: 48.66884770065453125198\n",
      "Iteration 19204 => Loss: 48.66866617893914082060\n",
      "Iteration 19205 => Loss: 48.66848465864832462557\n",
      "Iteration 19206 => Loss: 48.66830313978205424519\n",
      "Iteration 19207 => Loss: 48.66812162234032967945\n",
      "Iteration 19208 => Loss: 48.66794010632315803377\n",
      "Iteration 19209 => Loss: 48.66775859173052509732\n",
      "Iteration 19210 => Loss: 48.66757707856240244837\n",
      "Iteration 19211 => Loss: 48.66739556681877587607\n",
      "Iteration 19212 => Loss: 48.66721405649967380214\n",
      "Iteration 19213 => Loss: 48.66703254760501806686\n",
      "Iteration 19214 => Loss: 48.66685104013485840824\n",
      "Iteration 19215 => Loss: 48.66666953408913798285\n",
      "Iteration 19216 => Loss: 48.66648802946787810697\n",
      "Iteration 19217 => Loss: 48.66630652627105746433\n",
      "Iteration 19218 => Loss: 48.66612502449866894949\n",
      "Iteration 19219 => Loss: 48.66594352415069835160\n",
      "Iteration 19220 => Loss: 48.66576202522711724896\n",
      "Iteration 19221 => Loss: 48.66558052772795406327\n",
      "Iteration 19222 => Loss: 48.66539903165315195110\n",
      "Iteration 19223 => Loss: 48.66521753700272512333\n",
      "Iteration 19224 => Loss: 48.66503604377666647451\n",
      "Iteration 19225 => Loss: 48.66485455197496179380\n",
      "Iteration 19226 => Loss: 48.66467306159759687034\n",
      "Iteration 19227 => Loss: 48.66449157264455038785\n",
      "Iteration 19228 => Loss: 48.66431008511581524090\n",
      "Iteration 19229 => Loss: 48.66412859901137721863\n",
      "Iteration 19230 => Loss: 48.66394711433124342648\n",
      "Iteration 19231 => Loss: 48.66376563107539254815\n",
      "Iteration 19232 => Loss: 48.66358414924381037281\n",
      "Iteration 19233 => Loss: 48.66340266883648979501\n",
      "Iteration 19234 => Loss: 48.66322118985341660391\n",
      "Iteration 19235 => Loss: 48.66303971229458369407\n",
      "Iteration 19236 => Loss: 48.66285823615997685465\n",
      "Iteration 19237 => Loss: 48.66267676144960319107\n",
      "Iteration 19238 => Loss: 48.66249528816337743820\n",
      "Iteration 19239 => Loss: 48.66231381630139907202\n",
      "Iteration 19240 => Loss: 48.66213234586359703826\n",
      "Iteration 19241 => Loss: 48.66195087684995002064\n",
      "Iteration 19242 => Loss: 48.66176940926045091373\n",
      "Iteration 19243 => Loss: 48.66158794309512813925\n",
      "Iteration 19244 => Loss: 48.66140647835391064291\n",
      "Iteration 19245 => Loss: 48.66122501503684816271\n",
      "Iteration 19246 => Loss: 48.66104355314388385523\n",
      "Iteration 19247 => Loss: 48.66086209267501772047\n",
      "Iteration 19248 => Loss: 48.66068063363025686385\n",
      "Iteration 19249 => Loss: 48.66049917600959417996\n",
      "Iteration 19250 => Loss: 48.66031771981296571994\n",
      "Iteration 19251 => Loss: 48.66013626504041411636\n",
      "Iteration 19252 => Loss: 48.65995481169191094750\n",
      "Iteration 19253 => Loss: 48.65977335976742779167\n",
      "Iteration 19254 => Loss: 48.65959190926698596513\n",
      "Iteration 19255 => Loss: 48.65941046019056415162\n",
      "Iteration 19256 => Loss: 48.65922901253812682398\n",
      "Iteration 19257 => Loss: 48.65904756630969529851\n",
      "Iteration 19258 => Loss: 48.65886612150523404807\n",
      "Iteration 19259 => Loss: 48.65868467812474307266\n",
      "Iteration 19260 => Loss: 48.65850323616821526684\n",
      "Iteration 19261 => Loss: 48.65832179563562220892\n",
      "Iteration 19262 => Loss: 48.65814035652700653145\n",
      "Iteration 19263 => Loss: 48.65795891884228296931\n",
      "Iteration 19264 => Loss: 48.65777748258146573335\n",
      "Iteration 19265 => Loss: 48.65759604774455482357\n",
      "Iteration 19266 => Loss: 48.65741461433153602911\n",
      "Iteration 19267 => Loss: 48.65723318234239513913\n",
      "Iteration 19268 => Loss: 48.65705175177713215362\n",
      "Iteration 19269 => Loss: 48.65687032263573286173\n",
      "Iteration 19270 => Loss: 48.65668889491817594717\n",
      "Iteration 19271 => Loss: 48.65650746862444009366\n",
      "Iteration 19272 => Loss: 48.65632604375453240664\n",
      "Iteration 19273 => Loss: 48.65614462030844578067\n",
      "Iteration 19274 => Loss: 48.65596319828616600489\n",
      "Iteration 19275 => Loss: 48.65578177768764334132\n",
      "Iteration 19276 => Loss: 48.65560035851293463338\n",
      "Iteration 19277 => Loss: 48.65541894076197593222\n",
      "Iteration 19278 => Loss: 48.65523752443479565954\n",
      "Iteration 19279 => Loss: 48.65505610953132276109\n",
      "Iteration 19280 => Loss: 48.65487469605162118569\n",
      "Iteration 19281 => Loss: 48.65469328399564119536\n",
      "Iteration 19282 => Loss: 48.65451187336334726297\n",
      "Iteration 19283 => Loss: 48.65433046415478202107\n",
      "Iteration 19284 => Loss: 48.65414905636989573168\n",
      "Iteration 19285 => Loss: 48.65396765000869550022\n",
      "Iteration 19286 => Loss: 48.65378624507114579956\n",
      "Iteration 19287 => Loss: 48.65360484155725373512\n",
      "Iteration 19288 => Loss: 48.65342343946702641233\n",
      "Iteration 19289 => Loss: 48.65324203880040698778\n",
      "Iteration 19290 => Loss: 48.65306063955741677773\n",
      "Iteration 19291 => Loss: 48.65287924173804867678\n",
      "Iteration 19292 => Loss: 48.65269784534229557948\n",
      "Iteration 19293 => Loss: 48.65251645037009353700\n",
      "Iteration 19294 => Loss: 48.65233505682150649818\n",
      "Iteration 19295 => Loss: 48.65215366469646340875\n",
      "Iteration 19296 => Loss: 48.65197227399499979583\n",
      "Iteration 19297 => Loss: 48.65179088471705171060\n",
      "Iteration 19298 => Loss: 48.65160949686265468017\n",
      "Iteration 19299 => Loss: 48.65142811043175896657\n",
      "Iteration 19300 => Loss: 48.65124672542441430778\n",
      "Iteration 19301 => Loss: 48.65106534184053543868\n",
      "Iteration 19302 => Loss: 48.65088395968015788640\n",
      "Iteration 19303 => Loss: 48.65070257894325322923\n",
      "Iteration 19304 => Loss: 48.65052119962982146717\n",
      "Iteration 19305 => Loss: 48.65033982173984128394\n",
      "Iteration 19306 => Loss: 48.65015844527329846869\n",
      "Iteration 19307 => Loss: 48.64997707023020012684\n",
      "Iteration 19308 => Loss: 48.64979569661053204754\n",
      "Iteration 19309 => Loss: 48.64961432441425159823\n",
      "Iteration 19310 => Loss: 48.64943295364137298975\n",
      "Iteration 19311 => Loss: 48.64925158429188201126\n",
      "Iteration 19312 => Loss: 48.64907021636576445189\n",
      "Iteration 19313 => Loss: 48.64888884986304162794\n",
      "Iteration 19314 => Loss: 48.64870748478364959055\n",
      "Iteration 19315 => Loss: 48.64852612112760255059\n",
      "Iteration 19316 => Loss: 48.64834475889489340261\n",
      "Iteration 19317 => Loss: 48.64816339808552214663\n",
      "Iteration 19318 => Loss: 48.64798203869945325550\n",
      "Iteration 19319 => Loss: 48.64780068073666541295\n",
      "Iteration 19320 => Loss: 48.64761932419716572440\n",
      "Iteration 19321 => Loss: 48.64743796908094708442\n",
      "Iteration 19322 => Loss: 48.64725661538801659844\n",
      "Iteration 19323 => Loss: 48.64707526311831031762\n",
      "Iteration 19324 => Loss: 48.64689391227185666366\n",
      "Iteration 19325 => Loss: 48.64671256284864142572\n",
      "Iteration 19326 => Loss: 48.64653121484865749835\n",
      "Iteration 19327 => Loss: 48.64634986827186224900\n",
      "Iteration 19328 => Loss: 48.64616852311826278310\n",
      "Iteration 19329 => Loss: 48.64598717938785199522\n",
      "Iteration 19330 => Loss: 48.64580583708062277992\n",
      "Iteration 19331 => Loss: 48.64562449619655382094\n",
      "Iteration 19332 => Loss: 48.64544315673565932912\n",
      "Iteration 19333 => Loss: 48.64526181869788246104\n",
      "Iteration 19334 => Loss: 48.64508048208325163841\n",
      "Iteration 19335 => Loss: 48.64489914689174554496\n",
      "Iteration 19336 => Loss: 48.64471781312331444269\n",
      "Iteration 19337 => Loss: 48.64453648077801517502\n",
      "Iteration 19338 => Loss: 48.64435514985579800395\n",
      "Iteration 19339 => Loss: 48.64417382035664161322\n",
      "Iteration 19340 => Loss: 48.64399249228057442451\n",
      "Iteration 19341 => Loss: 48.64381116562753959442\n",
      "Iteration 19342 => Loss: 48.64362984039755133381\n",
      "Iteration 19343 => Loss: 48.64344851659058832638\n",
      "Iteration 19344 => Loss: 48.64326719420665057214\n",
      "Iteration 19345 => Loss: 48.64308587324572386024\n",
      "Iteration 19346 => Loss: 48.64290455370779397981\n",
      "Iteration 19347 => Loss: 48.64272323559286093086\n",
      "Iteration 19348 => Loss: 48.64254191890087497541\n",
      "Iteration 19349 => Loss: 48.64236060363187164057\n",
      "Iteration 19350 => Loss: 48.64217928978582961008\n",
      "Iteration 19351 => Loss: 48.64199797736272046222\n",
      "Iteration 19352 => Loss: 48.64181666636255840785\n",
      "Iteration 19353 => Loss: 48.64163535678526528727\n",
      "Iteration 19354 => Loss: 48.64145404863093347103\n",
      "Iteration 19355 => Loss: 48.64127274189947058858\n",
      "Iteration 19356 => Loss: 48.64109143659089795619\n",
      "Iteration 19357 => Loss: 48.64091013270519425760\n",
      "Iteration 19358 => Loss: 48.64072883024235949279\n",
      "Iteration 19359 => Loss: 48.64054752920238655634\n",
      "Iteration 19360 => Loss: 48.64036622958523281568\n",
      "Iteration 19361 => Loss: 48.64018493139094090338\n",
      "Iteration 19362 => Loss: 48.64000363461943976517\n",
      "Iteration 19363 => Loss: 48.63982233927075782276\n",
      "Iteration 19364 => Loss: 48.63964104534486665443\n",
      "Iteration 19365 => Loss: 48.63945975284176626019\n",
      "Iteration 19366 => Loss: 48.63927846176143532375\n",
      "Iteration 19367 => Loss: 48.63909717210385963426\n",
      "Iteration 19368 => Loss: 48.63891588386906050800\n",
      "Iteration 19369 => Loss: 48.63873459705697399613\n",
      "Iteration 19370 => Loss: 48.63855331166763562578\n",
      "Iteration 19371 => Loss: 48.63837202770100276439\n",
      "Iteration 19372 => Loss: 48.63819074515710383366\n",
      "Iteration 19373 => Loss: 48.63800946403586777933\n",
      "Iteration 19374 => Loss: 48.63782818433733012853\n",
      "Iteration 19375 => Loss: 48.63764690606145535412\n",
      "Iteration 19376 => Loss: 48.63746562920825766696\n",
      "Iteration 19377 => Loss: 48.63728435377770153991\n",
      "Iteration 19378 => Loss: 48.63710307976978697297\n",
      "Iteration 19379 => Loss: 48.63692180718451396615\n",
      "Iteration 19380 => Loss: 48.63674053602186120315\n",
      "Iteration 19381 => Loss: 48.63655926628179315685\n",
      "Iteration 19382 => Loss: 48.63637799796433114352\n",
      "Iteration 19383 => Loss: 48.63619673106945384689\n",
      "Iteration 19384 => Loss: 48.63601546559715416151\n",
      "Iteration 19385 => Loss: 48.63583420154739656027\n",
      "Iteration 19386 => Loss: 48.63565293892022367572\n",
      "Iteration 19387 => Loss: 48.63547167771556445359\n",
      "Iteration 19388 => Loss: 48.63529041793344021016\n",
      "Iteration 19389 => Loss: 48.63510915957382962915\n",
      "Iteration 19390 => Loss: 48.63492790263671849971\n",
      "Iteration 19391 => Loss: 48.63474664712212103268\n",
      "Iteration 19392 => Loss: 48.63456539302998749008\n",
      "Iteration 19393 => Loss: 48.63438414036033918819\n",
      "Iteration 19394 => Loss: 48.63420288911314770530\n",
      "Iteration 19395 => Loss: 48.63402163928841304141\n",
      "Iteration 19396 => Loss: 48.63384039088612098567\n",
      "Iteration 19397 => Loss: 48.63365914390624311636\n",
      "Iteration 19398 => Loss: 48.63347789834877232806\n",
      "Iteration 19399 => Loss: 48.63329665421373704248\n",
      "Iteration 19400 => Loss: 48.63311541150108041620\n",
      "Iteration 19401 => Loss: 48.63293417021080244922\n",
      "Iteration 19402 => Loss: 48.63275293034291024696\n",
      "Iteration 19403 => Loss: 48.63257169189735407144\n",
      "Iteration 19404 => Loss: 48.63239045487416944979\n",
      "Iteration 19405 => Loss: 48.63220921927333506574\n",
      "Iteration 19406 => Loss: 48.63202798509480828670\n",
      "Iteration 19407 => Loss: 48.63184675233859621812\n",
      "Iteration 19408 => Loss: 48.63166552100469175457\n",
      "Iteration 19409 => Loss: 48.63148429109308779061\n",
      "Iteration 19410 => Loss: 48.63130306260374879912\n",
      "Iteration 19411 => Loss: 48.63112183553670320180\n",
      "Iteration 19412 => Loss: 48.63094060989192257694\n",
      "Iteration 19413 => Loss: 48.63075938566935718654\n",
      "Iteration 19414 => Loss: 48.63057816286907097947\n",
      "Iteration 19415 => Loss: 48.63039694149099290144\n",
      "Iteration 19416 => Loss: 48.63021572153513005787\n",
      "Iteration 19417 => Loss: 48.63003450300147534335\n",
      "Iteration 19418 => Loss: 48.62985328589000744159\n",
      "Iteration 19419 => Loss: 48.62967207020071924717\n",
      "Iteration 19420 => Loss: 48.62949085593361786550\n",
      "Iteration 19421 => Loss: 48.62930964308865355861\n",
      "Iteration 19422 => Loss: 48.62912843166584764276\n",
      "Iteration 19423 => Loss: 48.62894722166520011797\n",
      "Iteration 19424 => Loss: 48.62876601308666124623\n",
      "Iteration 19425 => Loss: 48.62858480593022392213\n",
      "Iteration 19426 => Loss: 48.62840360019591656737\n",
      "Iteration 19427 => Loss: 48.62822239588368944396\n",
      "Iteration 19428 => Loss: 48.62804119299353544648\n",
      "Iteration 19429 => Loss: 48.62785999152546878577\n",
      "Iteration 19430 => Loss: 48.62767879147945393470\n",
      "Iteration 19431 => Loss: 48.62749759285550510413\n",
      "Iteration 19432 => Loss: 48.62731639565356545063\n",
      "Iteration 19433 => Loss: 48.62713519987366339592\n",
      "Iteration 19434 => Loss: 48.62695400551578472914\n",
      "Iteration 19435 => Loss: 48.62677281257987971230\n",
      "Iteration 19436 => Loss: 48.62659162106601229425\n",
      "Iteration 19437 => Loss: 48.62641043097409720986\n",
      "Iteration 19438 => Loss: 48.62622924230416288083\n",
      "Iteration 19439 => Loss: 48.62604805505618088546\n",
      "Iteration 19440 => Loss: 48.62586686923015122375\n",
      "Iteration 19441 => Loss: 48.62568568482605968484\n",
      "Iteration 19442 => Loss: 48.62550450184388495245\n",
      "Iteration 19443 => Loss: 48.62532332028363413201\n",
      "Iteration 19444 => Loss: 48.62514214014527880181\n",
      "Iteration 19445 => Loss: 48.62496096142882606728\n",
      "Iteration 19446 => Loss: 48.62477978413423329584\n",
      "Iteration 19447 => Loss: 48.62459860826152180380\n",
      "Iteration 19448 => Loss: 48.62441743381068448571\n",
      "Iteration 19449 => Loss: 48.62423626078169291986\n",
      "Iteration 19450 => Loss: 48.62405508917454000084\n",
      "Iteration 19451 => Loss: 48.62387391898918309607\n",
      "Iteration 19452 => Loss: 48.62369275022565773270\n",
      "Iteration 19453 => Loss: 48.62351158288393548901\n",
      "Iteration 19454 => Loss: 48.62333041696400925957\n",
      "Iteration 19455 => Loss: 48.62314925246585062268\n",
      "Iteration 19456 => Loss: 48.62296808938946668377\n",
      "Iteration 19457 => Loss: 48.62278692773486454826\n",
      "Iteration 19458 => Loss: 48.62260576750195895102\n",
      "Iteration 19459 => Loss: 48.62242460869083515718\n",
      "Iteration 19460 => Loss: 48.62224345130141500704\n",
      "Iteration 19461 => Loss: 48.62206229533371981688\n",
      "Iteration 19462 => Loss: 48.62188114078773537585\n",
      "Iteration 19463 => Loss: 48.62169998766341194596\n",
      "Iteration 19464 => Loss: 48.62151883596079926519\n",
      "Iteration 19465 => Loss: 48.62133768567981917386\n",
      "Iteration 19466 => Loss: 48.62115653682052140994\n",
      "Iteration 19467 => Loss: 48.62097538938287044630\n",
      "Iteration 19468 => Loss: 48.62079424336684496666\n",
      "Iteration 19469 => Loss: 48.62061309877245918187\n",
      "Iteration 19470 => Loss: 48.62043195559968467023\n",
      "Iteration 19471 => Loss: 48.62025081384850722088\n",
      "Iteration 19472 => Loss: 48.62006967351891262297\n",
      "Iteration 19473 => Loss: 48.61988853461090087649\n",
      "Iteration 19474 => Loss: 48.61970739712446487601\n",
      "Iteration 19475 => Loss: 48.61952626105958330527\n",
      "Iteration 19476 => Loss: 48.61934512641624905882\n",
      "Iteration 19477 => Loss: 48.61916399319445503124\n",
      "Iteration 19478 => Loss: 48.61898286139417990626\n",
      "Iteration 19479 => Loss: 48.61880173101541657843\n",
      "Iteration 19480 => Loss: 48.61862060205815083691\n",
      "Iteration 19481 => Loss: 48.61843947452236847084\n",
      "Iteration 19482 => Loss: 48.61825834840809790194\n",
      "Iteration 19483 => Loss: 48.61807722371526807592\n",
      "Iteration 19484 => Loss: 48.61789610044390741450\n",
      "Iteration 19485 => Loss: 48.61771497859397328511\n",
      "Iteration 19486 => Loss: 48.61753385816549410947\n",
      "Iteration 19487 => Loss: 48.61735273915841304415\n",
      "Iteration 19488 => Loss: 48.61717162157277982715\n",
      "Iteration 19489 => Loss: 48.61699050540851629876\n",
      "Iteration 19490 => Loss: 48.61680939066567930240\n",
      "Iteration 19491 => Loss: 48.61662827734418357295\n",
      "Iteration 19492 => Loss: 48.61644716544406463754\n",
      "Iteration 19493 => Loss: 48.61626605496532249617\n",
      "Iteration 19494 => Loss: 48.61608494590790741086\n",
      "Iteration 19495 => Loss: 48.61590383827183359244\n",
      "Iteration 19496 => Loss: 48.61572273205709393551\n",
      "Iteration 19497 => Loss: 48.61554162726363159663\n",
      "Iteration 19498 => Loss: 48.61536052389150341924\n",
      "Iteration 19499 => Loss: 48.61517942194065255990\n",
      "Iteration 19500 => Loss: 48.61499832141107191319\n",
      "Iteration 19501 => Loss: 48.61481722230278279540\n",
      "Iteration 19502 => Loss: 48.61463612461573546852\n",
      "Iteration 19503 => Loss: 48.61445502834992993257\n",
      "Iteration 19504 => Loss: 48.61427393350535197669\n",
      "Iteration 19505 => Loss: 48.61409284008201581173\n",
      "Iteration 19506 => Loss: 48.61391174807989301598\n",
      "Iteration 19507 => Loss: 48.61373065749894806231\n",
      "Iteration 19508 => Loss: 48.61354956833921647785\n",
      "Iteration 19509 => Loss: 48.61336848060064141919\n",
      "Iteration 19510 => Loss: 48.61318739428322999174\n",
      "Iteration 19511 => Loss: 48.61300630938699640637\n",
      "Iteration 19512 => Loss: 48.61282522591189092509\n",
      "Iteration 19513 => Loss: 48.61264414385793486417\n",
      "Iteration 19514 => Loss: 48.61246306322507848563\n",
      "Iteration 19515 => Loss: 48.61228198401335731660\n",
      "Iteration 19516 => Loss: 48.61210090622272161909\n",
      "Iteration 19517 => Loss: 48.61191982985319270938\n",
      "Iteration 19518 => Loss: 48.61173875490471374405\n",
      "Iteration 19519 => Loss: 48.61155768137732735568\n",
      "Iteration 19520 => Loss: 48.61137660927098380625\n",
      "Iteration 19521 => Loss: 48.61119553858568309579\n",
      "Iteration 19522 => Loss: 48.61101446932143232971\n",
      "Iteration 19523 => Loss: 48.61083340147816755916\n",
      "Iteration 19524 => Loss: 48.61065233505593852215\n",
      "Iteration 19525 => Loss: 48.61047127005470258609\n",
      "Iteration 19526 => Loss: 48.61029020647446685643\n",
      "Iteration 19527 => Loss: 48.61010914431521001688\n",
      "Iteration 19528 => Loss: 48.60992808357690364574\n",
      "Iteration 19529 => Loss: 48.60974702425956905927\n",
      "Iteration 19530 => Loss: 48.60956596636317783577\n",
      "Iteration 19531 => Loss: 48.60938490988770155354\n",
      "Iteration 19532 => Loss: 48.60920385483315442343\n",
      "Iteration 19533 => Loss: 48.60902280119951512916\n",
      "Iteration 19534 => Loss: 48.60884174898677656529\n",
      "Iteration 19535 => Loss: 48.60866069819491741555\n",
      "Iteration 19536 => Loss: 48.60847964882397320707\n",
      "Iteration 19537 => Loss: 48.60829860087383735845\n",
      "Iteration 19538 => Loss: 48.60811755434460934566\n",
      "Iteration 19539 => Loss: 48.60793650923620390358\n",
      "Iteration 19540 => Loss: 48.60775546554863524307\n",
      "Iteration 19541 => Loss: 48.60757442328186783698\n",
      "Iteration 19542 => Loss: 48.60739338243590879074\n",
      "Iteration 19543 => Loss: 48.60721234301079363149\n",
      "Iteration 19544 => Loss: 48.60703130500644419953\n",
      "Iteration 19545 => Loss: 48.60685026842286760029\n",
      "Iteration 19546 => Loss: 48.60666923326004962291\n",
      "Iteration 19547 => Loss: 48.60648819951797605654\n",
      "Iteration 19548 => Loss: 48.60630716719666111203\n",
      "Iteration 19549 => Loss: 48.60612613629608347310\n",
      "Iteration 19550 => Loss: 48.60594510681621471804\n",
      "Iteration 19551 => Loss: 48.60576407875706905770\n",
      "Iteration 19552 => Loss: 48.60558305211861096495\n",
      "Iteration 19553 => Loss: 48.60540202690084754522\n",
      "Iteration 19554 => Loss: 48.60522100310377169308\n",
      "Iteration 19555 => Loss: 48.60503998072732656510\n",
      "Iteration 19556 => Loss: 48.60485895977156900472\n",
      "Iteration 19557 => Loss: 48.60467794023643506307\n",
      "Iteration 19558 => Loss: 48.60449692212192474017\n",
      "Iteration 19559 => Loss: 48.60431590542806645772\n",
      "Iteration 19560 => Loss: 48.60413489015479626687\n",
      "Iteration 19561 => Loss: 48.60395387630212837848\n",
      "Iteration 19562 => Loss: 48.60377286387006279256\n",
      "Iteration 19563 => Loss: 48.60359185285854977110\n",
      "Iteration 19564 => Loss: 48.60341084326760352496\n",
      "Iteration 19565 => Loss: 48.60322983509721694872\n",
      "Iteration 19566 => Loss: 48.60304882834737583153\n",
      "Iteration 19567 => Loss: 48.60286782301805885709\n",
      "Iteration 19568 => Loss: 48.60268681910927313083\n",
      "Iteration 19569 => Loss: 48.60250581662101154734\n",
      "Iteration 19570 => Loss: 48.60232481555320305233\n",
      "Iteration 19571 => Loss: 48.60214381590590448923\n",
      "Iteration 19572 => Loss: 48.60196281767908743632\n",
      "Iteration 19573 => Loss: 48.60178182087273057732\n",
      "Iteration 19574 => Loss: 48.60160082548684101766\n",
      "Iteration 19575 => Loss: 48.60141983152135480850\n",
      "Iteration 19576 => Loss: 48.60123883897634300411\n",
      "Iteration 19577 => Loss: 48.60105784785172744478\n",
      "Iteration 19578 => Loss: 48.60087685814752234137\n",
      "Iteration 19579 => Loss: 48.60069586986372058846\n",
      "Iteration 19580 => Loss: 48.60051488300030086975\n",
      "Iteration 19581 => Loss: 48.60033389755726318526\n",
      "Iteration 19582 => Loss: 48.60015291353457911327\n",
      "Iteration 19583 => Loss: 48.59997193093226286464\n",
      "Iteration 19584 => Loss: 48.59979094975027891223\n",
      "Iteration 19585 => Loss: 48.59960996998862725604\n",
      "Iteration 19586 => Loss: 48.59942899164729368522\n",
      "Iteration 19587 => Loss: 48.59924801472626398890\n",
      "Iteration 19588 => Loss: 48.59906703922553106167\n",
      "Iteration 19589 => Loss: 48.59888606514510911438\n",
      "Iteration 19590 => Loss: 48.59870509248492709276\n",
      "Iteration 19591 => Loss: 48.59852412124502762936\n",
      "Iteration 19592 => Loss: 48.59834315142538940790\n",
      "Iteration 19593 => Loss: 48.59816218302597690126\n",
      "Iteration 19594 => Loss: 48.59798121604679721486\n",
      "Iteration 19595 => Loss: 48.59780025048784324326\n",
      "Iteration 19596 => Loss: 48.59761928634908656477\n",
      "Iteration 19597 => Loss: 48.59743832363052717938\n",
      "Iteration 19598 => Loss: 48.59725736233216508708\n",
      "Iteration 19599 => Loss: 48.59707640245397897161\n",
      "Iteration 19600 => Loss: 48.59689544399594041124\n",
      "Iteration 19601 => Loss: 48.59671448695808493312\n",
      "Iteration 19602 => Loss: 48.59653353134034858840\n",
      "Iteration 19603 => Loss: 48.59635257714274558793\n",
      "Iteration 19604 => Loss: 48.59617162436525461544\n",
      "Iteration 19605 => Loss: 48.59599067300788277635\n",
      "Iteration 19606 => Loss: 48.59580972307059454351\n",
      "Iteration 19607 => Loss: 48.59562877455341123323\n",
      "Iteration 19608 => Loss: 48.59544782745628310749\n",
      "Iteration 19609 => Loss: 48.59526688177921727174\n",
      "Iteration 19610 => Loss: 48.59508593752222083140\n",
      "Iteration 19611 => Loss: 48.59490499468526536475\n",
      "Iteration 19612 => Loss: 48.59472405326833666095\n",
      "Iteration 19613 => Loss: 48.59454311327139919285\n",
      "Iteration 19614 => Loss: 48.59436217469449559303\n",
      "Iteration 19615 => Loss: 48.59418123753759033434\n",
      "Iteration 19616 => Loss: 48.59400030180066210050\n",
      "Iteration 19617 => Loss: 48.59381936748370378609\n",
      "Iteration 19618 => Loss: 48.59363843458671539111\n",
      "Iteration 19619 => Loss: 48.59345750310968981012\n",
      "Iteration 19620 => Loss: 48.59327657305258441056\n",
      "Iteration 19621 => Loss: 48.59309564441542761415\n",
      "Iteration 19622 => Loss: 48.59291471719817678832\n",
      "Iteration 19623 => Loss: 48.59273379140082482763\n",
      "Iteration 19624 => Loss: 48.59255286702338594296\n",
      "Iteration 19625 => Loss: 48.59237194406581039630\n",
      "Iteration 19626 => Loss: 48.59219102252813371479\n",
      "Iteration 19627 => Loss: 48.59201010241032747672\n",
      "Iteration 19628 => Loss: 48.59182918371235615496\n",
      "Iteration 19629 => Loss: 48.59164826643421264407\n",
      "Iteration 19630 => Loss: 48.59146735057591826035\n",
      "Iteration 19631 => Loss: 48.59128643613742326579\n",
      "Iteration 19632 => Loss: 48.59110552311875608211\n",
      "Iteration 19633 => Loss: 48.59092461151985986589\n",
      "Iteration 19634 => Loss: 48.59074370134074882799\n",
      "Iteration 19635 => Loss: 48.59056279258145139011\n",
      "Iteration 19636 => Loss: 48.59038188524188939255\n",
      "Iteration 19637 => Loss: 48.59020097932206994074\n",
      "Iteration 19638 => Loss: 48.59002007482201435096\n",
      "Iteration 19639 => Loss: 48.58983917174166577979\n",
      "Iteration 19640 => Loss: 48.58965827008103843809\n",
      "Iteration 19641 => Loss: 48.58947736984011811501\n",
      "Iteration 19642 => Loss: 48.58929647101892612682\n",
      "Iteration 19643 => Loss: 48.58911557361737010297\n",
      "Iteration 19644 => Loss: 48.58893467763550688687\n",
      "Iteration 19645 => Loss: 48.58875378307329384597\n",
      "Iteration 19646 => Loss: 48.58857288993074519112\n",
      "Iteration 19647 => Loss: 48.58839199820784671147\n",
      "Iteration 19648 => Loss: 48.58821110790456998529\n",
      "Iteration 19649 => Loss: 48.58803021902089369632\n",
      "Iteration 19650 => Loss: 48.58784933155683205541\n",
      "Iteration 19651 => Loss: 48.58766844551239216798\n",
      "Iteration 19652 => Loss: 48.58748756088750297977\n",
      "Iteration 19653 => Loss: 48.58730667768219291247\n",
      "Iteration 19654 => Loss: 48.58712579589646196609\n",
      "Iteration 19655 => Loss: 48.58694491553024619179\n",
      "Iteration 19656 => Loss: 48.58676403658361664384\n",
      "Iteration 19657 => Loss: 48.58658315905649516253\n",
      "Iteration 19658 => Loss: 48.58640228294889595873\n",
      "Iteration 19659 => Loss: 48.58622140826076929443\n",
      "Iteration 19660 => Loss: 48.58604053499219332934\n",
      "Iteration 19661 => Loss: 48.58585966314306148206\n",
      "Iteration 19662 => Loss: 48.58567879271340927971\n",
      "Iteration 19663 => Loss: 48.58549792370322251145\n",
      "Iteration 19664 => Loss: 48.58531705611249407184\n",
      "Iteration 19665 => Loss: 48.58513618994118843375\n",
      "Iteration 19666 => Loss: 48.58495532518931270261\n",
      "Iteration 19667 => Loss: 48.58477446185687398383\n",
      "Iteration 19668 => Loss: 48.58459359994382253944\n",
      "Iteration 19669 => Loss: 48.58441273945017258029\n",
      "Iteration 19670 => Loss: 48.58423188037589568467\n",
      "Iteration 19671 => Loss: 48.58405102272101316885\n",
      "Iteration 19672 => Loss: 48.58387016648547529485\n",
      "Iteration 19673 => Loss: 48.58368931166928916809\n",
      "Iteration 19674 => Loss: 48.58350845827244768316\n",
      "Iteration 19675 => Loss: 48.58332760629492952376\n",
      "Iteration 19676 => Loss: 48.58314675573672758446\n",
      "Iteration 19677 => Loss: 48.58296590659782765442\n",
      "Iteration 19678 => Loss: 48.58278505887823683906\n",
      "Iteration 19679 => Loss: 48.58260421257789829497\n",
      "Iteration 19680 => Loss: 48.58242336769686176012\n",
      "Iteration 19681 => Loss: 48.58224252423507749654\n",
      "Iteration 19682 => Loss: 48.58206168219256682050\n",
      "Iteration 19683 => Loss: 48.58188084156927288859\n",
      "Iteration 19684 => Loss: 48.58170000236519570080\n",
      "Iteration 19685 => Loss: 48.58151916458034236257\n",
      "Iteration 19686 => Loss: 48.58133832821469866303\n",
      "Iteration 19687 => Loss: 48.58115749326823618048\n",
      "Iteration 19688 => Loss: 48.58097665974097623121\n",
      "Iteration 19689 => Loss: 48.58079582763288328806\n",
      "Iteration 19690 => Loss: 48.58061499694395024562\n",
      "Iteration 19691 => Loss: 48.58043416767416289304\n",
      "Iteration 19692 => Loss: 48.58025333982350701945\n",
      "Iteration 19693 => Loss: 48.58007251339200394114\n",
      "Iteration 19694 => Loss: 48.57989168837958970926\n",
      "Iteration 19695 => Loss: 48.57971086478629985095\n",
      "Iteration 19696 => Loss: 48.57953004261208462822\n",
      "Iteration 19697 => Loss: 48.57934922185697246277\n",
      "Iteration 19698 => Loss: 48.57916840252092782748\n",
      "Iteration 19699 => Loss: 48.57898758460392940606\n",
      "Iteration 19700 => Loss: 48.57880676810599140936\n",
      "Iteration 19701 => Loss: 48.57862595302709962652\n",
      "Iteration 19702 => Loss: 48.57844513936721142500\n",
      "Iteration 19703 => Loss: 48.57826432712636943734\n",
      "Iteration 19704 => Loss: 48.57808351630450971470\n",
      "Iteration 19705 => Loss: 48.57790270690165357337\n",
      "Iteration 19706 => Loss: 48.57772189891779390791\n",
      "Iteration 19707 => Loss: 48.57754109235287387492\n",
      "Iteration 19708 => Loss: 48.57736028720695031780\n",
      "Iteration 19709 => Loss: 48.57717948347993797142\n",
      "Iteration 19710 => Loss: 48.57699868117189367922\n",
      "Iteration 19711 => Loss: 48.57681788028276059777\n",
      "Iteration 19712 => Loss: 48.57663708081253872706\n",
      "Iteration 19713 => Loss: 48.57645628276124938338\n",
      "Iteration 19714 => Loss: 48.57627548612882151247\n",
      "Iteration 19715 => Loss: 48.57609469091528353601\n",
      "Iteration 19716 => Loss: 48.57591389712063545403\n",
      "Iteration 19717 => Loss: 48.57573310474483463395\n",
      "Iteration 19718 => Loss: 48.57555231378786686491\n",
      "Iteration 19719 => Loss: 48.57537152424976056864\n",
      "Iteration 19720 => Loss: 48.57519073613047311255\n",
      "Iteration 19721 => Loss: 48.57500994942999739123\n",
      "Iteration 19722 => Loss: 48.57482916414834051011\n",
      "Iteration 19723 => Loss: 48.57464838028545273119\n",
      "Iteration 19724 => Loss: 48.57446759784137668703\n",
      "Iteration 19725 => Loss: 48.57428681681604132336\n",
      "Iteration 19726 => Loss: 48.57410603720948927275\n",
      "Iteration 19727 => Loss: 48.57392525902167079721\n",
      "Iteration 19728 => Loss: 48.57374448225258589673\n",
      "Iteration 19729 => Loss: 48.57356370690224167674\n",
      "Iteration 19730 => Loss: 48.57338293297061682097\n",
      "Iteration 19731 => Loss: 48.57320216045769001312\n",
      "Iteration 19732 => Loss: 48.57302138936345414777\n",
      "Iteration 19733 => Loss: 48.57284061968790922492\n",
      "Iteration 19734 => Loss: 48.57265985143101971744\n",
      "Iteration 19735 => Loss: 48.57247908459279983617\n",
      "Iteration 19736 => Loss: 48.57229831917322115942\n",
      "Iteration 19737 => Loss: 48.57211755517231210888\n",
      "Iteration 19738 => Loss: 48.57193679258998031401\n",
      "Iteration 19739 => Loss: 48.57175603142628972364\n",
      "Iteration 19740 => Loss: 48.57157527168119770522\n",
      "Iteration 19741 => Loss: 48.57139451335471136417\n",
      "Iteration 19742 => Loss: 48.57121375644679517336\n",
      "Iteration 19743 => Loss: 48.57103300095743492193\n",
      "Iteration 19744 => Loss: 48.57085224688665903159\n",
      "Iteration 19745 => Loss: 48.57067149423443197520\n",
      "Iteration 19746 => Loss: 48.57049074300071112020\n",
      "Iteration 19747 => Loss: 48.57030999318553199373\n",
      "Iteration 19748 => Loss: 48.57012924478889459579\n",
      "Iteration 19749 => Loss: 48.56994849781072076667\n",
      "Iteration 19750 => Loss: 48.56976775225108156064\n",
      "Iteration 19751 => Loss: 48.56958700810988460717\n",
      "Iteration 19752 => Loss: 48.56940626538717253879\n",
      "Iteration 19753 => Loss: 48.56922552408292403925\n",
      "Iteration 19754 => Loss: 48.56904478419713200310\n",
      "Iteration 19755 => Loss: 48.56886404572976800864\n",
      "Iteration 19756 => Loss: 48.56868330868081784502\n",
      "Iteration 19757 => Loss: 48.56850257305029572308\n",
      "Iteration 19758 => Loss: 48.56832183883818743197\n",
      "Iteration 19759 => Loss: 48.56814110604445744457\n",
      "Iteration 19760 => Loss: 48.56796037466910576086\n",
      "Iteration 19761 => Loss: 48.56777964471212527542\n",
      "Iteration 19762 => Loss: 48.56759891617350177739\n",
      "Iteration 19763 => Loss: 48.56741818905325658307\n",
      "Iteration 19764 => Loss: 48.56723746335131863816\n",
      "Iteration 19765 => Loss: 48.56705673906770215353\n",
      "Iteration 19766 => Loss: 48.56687601620240712919\n",
      "Iteration 19767 => Loss: 48.56669529475543356511\n",
      "Iteration 19768 => Loss: 48.56651457472672461790\n",
      "Iteration 19769 => Loss: 48.56633385611630870926\n",
      "Iteration 19770 => Loss: 48.56615313892417873376\n",
      "Iteration 19771 => Loss: 48.56597242315029916426\n",
      "Iteration 19772 => Loss: 48.56579170879464868449\n",
      "Iteration 19773 => Loss: 48.56561099585726282157\n",
      "Iteration 19774 => Loss: 48.56543028433806341582\n",
      "Iteration 19775 => Loss: 48.56524957423713573235\n",
      "Iteration 19776 => Loss: 48.56506886555436608433\n",
      "Iteration 19777 => Loss: 48.56488815828979710432\n",
      "Iteration 19778 => Loss: 48.56470745244341458147\n",
      "Iteration 19779 => Loss: 48.56452674801518298864\n",
      "Iteration 19780 => Loss: 48.56434604500515206382\n",
      "Iteration 19781 => Loss: 48.56416534341324364732\n",
      "Iteration 19782 => Loss: 48.56398464323945773913\n",
      "Iteration 19783 => Loss: 48.56380394448382276096\n",
      "Iteration 19784 => Loss: 48.56362324714629608025\n",
      "Iteration 19785 => Loss: 48.56344255122684216985\n",
      "Iteration 19786 => Loss: 48.56326185672551787320\n",
      "Iteration 19787 => Loss: 48.56308116364226634687\n",
      "Iteration 19788 => Loss: 48.56290047197707338000\n",
      "Iteration 19789 => Loss: 48.56271978172996028889\n",
      "Iteration 19790 => Loss: 48.56253909290087733552\n",
      "Iteration 19791 => Loss: 48.56235840548983873077\n",
      "Iteration 19792 => Loss: 48.56217771949682315835\n",
      "Iteration 19793 => Loss: 48.56199703492183061826\n",
      "Iteration 19794 => Loss: 48.56181635176481847793\n",
      "Iteration 19795 => Loss: 48.56163567002580805365\n",
      "Iteration 19796 => Loss: 48.56145498970477092371\n",
      "Iteration 19797 => Loss: 48.56127431080172840439\n",
      "Iteration 19798 => Loss: 48.56109363331662365226\n",
      "Iteration 19799 => Loss: 48.56091295724947087820\n",
      "Iteration 19800 => Loss: 48.56073228260027008218\n",
      "Iteration 19801 => Loss: 48.56055160936895731538\n",
      "Iteration 19802 => Loss: 48.56037093755558942121\n",
      "Iteration 19803 => Loss: 48.56019026716012376710\n",
      "Iteration 19804 => Loss: 48.56000959818253193134\n",
      "Iteration 19805 => Loss: 48.55982893062282101937\n",
      "Iteration 19806 => Loss: 48.55964826448100524203\n",
      "Iteration 19807 => Loss: 48.55946759975703486134\n",
      "Iteration 19808 => Loss: 48.55928693645090987729\n",
      "Iteration 19809 => Loss: 48.55910627456261607904\n",
      "Iteration 19810 => Loss: 48.55892561409215346657\n",
      "Iteration 19811 => Loss: 48.55874495503950782904\n",
      "Iteration 19812 => Loss: 48.55856429740464363931\n",
      "Iteration 19813 => Loss: 48.55838364118760352994\n",
      "Iteration 19814 => Loss: 48.55820298638831644666\n",
      "Iteration 19815 => Loss: 48.55802233300679660033\n",
      "Iteration 19816 => Loss: 48.55784168104307241265\n",
      "Iteration 19817 => Loss: 48.55766103049705861849\n",
      "Iteration 19818 => Loss: 48.55748038136879785043\n",
      "Iteration 19819 => Loss: 48.55729973365825458131\n",
      "Iteration 19820 => Loss: 48.55711908736542881115\n",
      "Iteration 19821 => Loss: 48.55693844249028501281\n",
      "Iteration 19822 => Loss: 48.55675779903288002970\n",
      "Iteration 19823 => Loss: 48.55657715699312149127\n",
      "Iteration 19824 => Loss: 48.55639651637104492465\n",
      "Iteration 19825 => Loss: 48.55621587716661480272\n",
      "Iteration 19826 => Loss: 48.55603523937983823089\n",
      "Iteration 19827 => Loss: 48.55585460301069389288\n",
      "Iteration 19828 => Loss: 48.55567396805916757785\n",
      "Iteration 19829 => Loss: 48.55549333452527349664\n",
      "Iteration 19830 => Loss: 48.55531270240897612211\n",
      "Iteration 19831 => Loss: 48.55513207171023992714\n",
      "Iteration 19832 => Loss: 48.55495144242912886057\n",
      "Iteration 19833 => Loss: 48.55477081456556476269\n",
      "Iteration 19834 => Loss: 48.55459018811955473893\n",
      "Iteration 19835 => Loss: 48.55440956309110589473\n",
      "Iteration 19836 => Loss: 48.55422893948018270294\n",
      "Iteration 19837 => Loss: 48.55404831728679937441\n",
      "Iteration 19838 => Loss: 48.55386769651089906574\n",
      "Iteration 19839 => Loss: 48.55368707715253862034\n",
      "Iteration 19840 => Loss: 48.55350645921163987850\n",
      "Iteration 19841 => Loss: 48.55332584268823836737\n",
      "Iteration 19842 => Loss: 48.55314522758228434895\n",
      "Iteration 19843 => Loss: 48.55296461389380624496\n",
      "Iteration 19844 => Loss: 48.55278400162276142282\n",
      "Iteration 19845 => Loss: 48.55260339076916409340\n",
      "Iteration 19846 => Loss: 48.55242278133299294041\n",
      "Iteration 19847 => Loss: 48.55224217331421243671\n",
      "Iteration 19848 => Loss: 48.55206156671285100401\n",
      "Iteration 19849 => Loss: 48.55188096152889443147\n",
      "Iteration 19850 => Loss: 48.55170035776232140279\n",
      "Iteration 19851 => Loss: 48.55151975541310349627\n",
      "Iteration 19852 => Loss: 48.55133915448122650105\n",
      "Iteration 19853 => Loss: 48.55115855496671173341\n",
      "Iteration 19854 => Loss: 48.55097795686953077166\n",
      "Iteration 19855 => Loss: 48.55079736018968361577\n",
      "Iteration 19856 => Loss: 48.55061676492712763320\n",
      "Iteration 19857 => Loss: 48.55043617108189124565\n",
      "Iteration 19858 => Loss: 48.55025557865394603141\n",
      "Iteration 19859 => Loss: 48.55007498764327777963\n",
      "Iteration 19860 => Loss: 48.54989439804988649030\n",
      "Iteration 19861 => Loss: 48.54971380987372953086\n",
      "Iteration 19862 => Loss: 48.54953322311483532303\n",
      "Iteration 19863 => Loss: 48.54935263777316123424\n",
      "Iteration 19864 => Loss: 48.54917205384873568619\n",
      "Iteration 19865 => Loss: 48.54899147134151604632\n",
      "Iteration 19866 => Loss: 48.54881089025149520921\n",
      "Iteration 19867 => Loss: 48.54863031057864475315\n",
      "Iteration 19868 => Loss: 48.54844973232300731070\n",
      "Iteration 19869 => Loss: 48.54826915548452603844\n",
      "Iteration 19870 => Loss: 48.54808858006319383094\n",
      "Iteration 19871 => Loss: 48.54790800605901068820\n",
      "Iteration 19872 => Loss: 48.54772743347196239938\n",
      "Iteration 19873 => Loss: 48.54754686230205606989\n",
      "Iteration 19874 => Loss: 48.54736629254925617261\n",
      "Iteration 19875 => Loss: 48.54718572421355560209\n",
      "Iteration 19876 => Loss: 48.54700515729492593664\n",
      "Iteration 19877 => Loss: 48.54682459179340270339\n",
      "Iteration 19878 => Loss: 48.54664402770893616434\n",
      "Iteration 19879 => Loss: 48.54646346504151921408\n",
      "Iteration 19880 => Loss: 48.54628290379116606346\n",
      "Iteration 19881 => Loss: 48.54610234395784118533\n",
      "Iteration 19882 => Loss: 48.54592178554152326342\n",
      "Iteration 19883 => Loss: 48.54574122854224071943\n",
      "Iteration 19884 => Loss: 48.54556067295994381539\n",
      "Iteration 19885 => Loss: 48.54538011879465386755\n",
      "Iteration 19886 => Loss: 48.54519956604634955966\n",
      "Iteration 19887 => Loss: 48.54501901471500246998\n",
      "Iteration 19888 => Loss: 48.54483846480059838768\n",
      "Iteration 19889 => Loss: 48.54465791630315152361\n",
      "Iteration 19890 => Loss: 48.54447736922263345605\n",
      "Iteration 19891 => Loss: 48.54429682355905839586\n",
      "Iteration 19892 => Loss: 48.54411627931237660505\n",
      "Iteration 19893 => Loss: 48.54393573648260229447\n",
      "Iteration 19894 => Loss: 48.54375519506972835870\n",
      "Iteration 19895 => Loss: 48.54357465507371927060\n",
      "Iteration 19896 => Loss: 48.54339411649460345188\n",
      "Iteration 19897 => Loss: 48.54321357933233116455\n",
      "Iteration 19898 => Loss: 48.54303304358688819775\n",
      "Iteration 19899 => Loss: 48.54285250925828165691\n",
      "Iteration 19900 => Loss: 48.54267197634651154203\n",
      "Iteration 19901 => Loss: 48.54249144485156364226\n",
      "Iteration 19902 => Loss: 48.54231091477340243046\n",
      "Iteration 19903 => Loss: 48.54213038611203501205\n",
      "Iteration 19904 => Loss: 48.54194985886746849246\n",
      "Iteration 19905 => Loss: 48.54176933303963181743\n",
      "Iteration 19906 => Loss: 48.54158880862857472493\n",
      "Iteration 19907 => Loss: 48.54140828563426168785\n",
      "Iteration 19908 => Loss: 48.54122776405667849531\n",
      "Iteration 19909 => Loss: 48.54104724389582514732\n",
      "Iteration 19910 => Loss: 48.54086672515167322217\n",
      "Iteration 19911 => Loss: 48.54068620782423693072\n",
      "Iteration 19912 => Loss: 48.54050569191348785125\n",
      "Iteration 19913 => Loss: 48.54032517741941177292\n",
      "Iteration 19914 => Loss: 48.54014466434200159028\n",
      "Iteration 19915 => Loss: 48.53996415268126440878\n",
      "Iteration 19916 => Loss: 48.53978364243715759585\n",
      "Iteration 19917 => Loss: 48.53960313360970246777\n",
      "Iteration 19918 => Loss: 48.53942262619884218111\n",
      "Iteration 19919 => Loss: 48.53924212020463357931\n",
      "Iteration 19920 => Loss: 48.53906161562699139722\n",
      "Iteration 19921 => Loss: 48.53888111246594405657\n",
      "Iteration 19922 => Loss: 48.53870061072149866277\n",
      "Iteration 19923 => Loss: 48.53852011039361258327\n",
      "Iteration 19924 => Loss: 48.53833961148226450177\n",
      "Iteration 19925 => Loss: 48.53815911398749705086\n",
      "Iteration 19926 => Loss: 48.53797861790923207082\n",
      "Iteration 19927 => Loss: 48.53779812324749798336\n",
      "Iteration 19928 => Loss: 48.53761763000229478848\n",
      "Iteration 19929 => Loss: 48.53743713817357274820\n",
      "Iteration 19930 => Loss: 48.53725664776134607337\n",
      "Iteration 19931 => Loss: 48.53707615876560055312\n",
      "Iteration 19932 => Loss: 48.53689567118632908205\n",
      "Iteration 19933 => Loss: 48.53671518502351744928\n",
      "Iteration 19934 => Loss: 48.53653470027713723312\n",
      "Iteration 19935 => Loss: 48.53635421694720264441\n",
      "Iteration 19936 => Loss: 48.53617373503368526144\n",
      "Iteration 19937 => Loss: 48.53599325453658508422\n",
      "Iteration 19938 => Loss: 48.53581277545588079647\n",
      "Iteration 19939 => Loss: 48.53563229779156529275\n",
      "Iteration 19940 => Loss: 48.53545182154363146765\n",
      "Iteration 19941 => Loss: 48.53527134671206511030\n",
      "Iteration 19942 => Loss: 48.53509087329688043155\n",
      "Iteration 19943 => Loss: 48.53491040129799927172\n",
      "Iteration 19944 => Loss: 48.53472993071547847421\n",
      "Iteration 19945 => Loss: 48.53454946154928251190\n",
      "Iteration 19946 => Loss: 48.53436899379936875221\n",
      "Iteration 19947 => Loss: 48.53418852746578693313\n",
      "Iteration 19948 => Loss: 48.53400806254850863297\n",
      "Iteration 19949 => Loss: 48.53382759904746990287\n",
      "Iteration 19950 => Loss: 48.53364713696272758625\n",
      "Iteration 19951 => Loss: 48.53346667629422483969\n",
      "Iteration 19952 => Loss: 48.53328621704199008491\n",
      "Iteration 19953 => Loss: 48.53310575920595937305\n",
      "Iteration 19954 => Loss: 48.53292530278618954753\n",
      "Iteration 19955 => Loss: 48.53274484778259534323\n",
      "Iteration 19956 => Loss: 48.53256439419522649814\n",
      "Iteration 19957 => Loss: 48.53238394202404037969\n",
      "Iteration 19958 => Loss: 48.53220349126902988246\n",
      "Iteration 19959 => Loss: 48.53202304193019500644\n",
      "Iteration 19960 => Loss: 48.53184259400751443536\n",
      "Iteration 19961 => Loss: 48.53166214750095974750\n",
      "Iteration 19962 => Loss: 48.53148170241056647001\n",
      "Iteration 19963 => Loss: 48.53130125873629907574\n",
      "Iteration 19964 => Loss: 48.53112081647812203755\n",
      "Iteration 19965 => Loss: 48.53094037563607088259\n",
      "Iteration 19966 => Loss: 48.53075993621007455658\n",
      "Iteration 19967 => Loss: 48.53057949820020411380\n",
      "Iteration 19968 => Loss: 48.53039906160637428911\n",
      "Iteration 19969 => Loss: 48.53021862642859218795\n",
      "Iteration 19970 => Loss: 48.53003819266687202116\n",
      "Iteration 19971 => Loss: 48.52985776032118536705\n",
      "Iteration 19972 => Loss: 48.52967732939152512017\n",
      "Iteration 19973 => Loss: 48.52949689987786996426\n",
      "Iteration 19974 => Loss: 48.52931647178020568845\n",
      "Iteration 19975 => Loss: 48.52913604509854650360\n",
      "Iteration 19976 => Loss: 48.52895561983287109342\n",
      "Iteration 19977 => Loss: 48.52877519598315814164\n",
      "Iteration 19978 => Loss: 48.52859477354940054283\n",
      "Iteration 19979 => Loss: 48.52841435253159119156\n",
      "Iteration 19980 => Loss: 48.52823393292970166613\n",
      "Iteration 19981 => Loss: 48.52805351474376038823\n",
      "Iteration 19982 => Loss: 48.52787309797369630360\n",
      "Iteration 19983 => Loss: 48.52769268261955915023\n",
      "Iteration 19984 => Loss: 48.52751226868131340098\n",
      "Iteration 19985 => Loss: 48.52733185615894484499\n",
      "Iteration 19986 => Loss: 48.52715144505243216599\n",
      "Iteration 19987 => Loss: 48.52697103536179668026\n",
      "Iteration 19988 => Loss: 48.52679062708698864981\n",
      "Iteration 19989 => Loss: 48.52661022022802939091\n",
      "Iteration 19990 => Loss: 48.52642981478487627101\n",
      "Iteration 19991 => Loss: 48.52624941075755060638\n",
      "Iteration 19992 => Loss: 48.52606900814602397531\n",
      "Iteration 19993 => Loss: 48.52588860695028216696\n",
      "Iteration 19994 => Loss: 48.52570820717031807590\n",
      "Iteration 19995 => Loss: 48.52552780880613170211\n",
      "Iteration 19996 => Loss: 48.52534741185768751848\n",
      "Iteration 19997 => Loss: 48.52516701632501394670\n",
      "Iteration 19998 => Loss: 48.52498662220805414336\n",
      "Iteration 19999 => Loss: 48.52480622950681521388\n",
      "Iteration 20000 => Loss: 48.52462583822129715827\n",
      "Iteration 20001 => Loss: 48.52444544835149287110\n",
      "Iteration 20002 => Loss: 48.52426505989735971980\n",
      "Iteration 20003 => Loss: 48.52408467285891191523\n",
      "Iteration 20004 => Loss: 48.52390428723612814110\n",
      "Iteration 20005 => Loss: 48.52372390302901550285\n",
      "Iteration 20006 => Loss: 48.52354352023753136791\n",
      "Iteration 20007 => Loss: 48.52336313886168994713\n",
      "Iteration 20008 => Loss: 48.52318275890146281881\n",
      "Iteration 20009 => Loss: 48.52300238035687840465\n",
      "Iteration 20010 => Loss: 48.52282200322785143953\n",
      "Iteration 20011 => Loss: 48.52264162751444587229\n",
      "Iteration 20012 => Loss: 48.52246125321661196494\n",
      "Iteration 20013 => Loss: 48.52228088033433550663\n",
      "Iteration 20014 => Loss: 48.52210050886763070821\n",
      "Iteration 20015 => Loss: 48.52192013881646204254\n",
      "Iteration 20016 => Loss: 48.52173977018083661505\n",
      "Iteration 20017 => Loss: 48.52155940296071889861\n",
      "Iteration 20018 => Loss: 48.52137903715614442035\n",
      "Iteration 20019 => Loss: 48.52119867276703502057\n",
      "Iteration 20020 => Loss: 48.52101830979344043726\n",
      "Iteration 20021 => Loss: 48.52083794823531093243\n",
      "Iteration 20022 => Loss: 48.52065758809266071694\n",
      "Iteration 20023 => Loss: 48.52047722936545426364\n",
      "Iteration 20024 => Loss: 48.52029687205369867797\n",
      "Iteration 20025 => Loss: 48.52011651615737264365\n",
      "Iteration 20026 => Loss: 48.51993616167649037152\n",
      "Iteration 20027 => Loss: 48.51975580861100212360\n",
      "Iteration 20028 => Loss: 48.51957545696092921617\n",
      "Iteration 20029 => Loss: 48.51939510672622191123\n",
      "Iteration 20030 => Loss: 48.51921475790690863050\n",
      "Iteration 20031 => Loss: 48.51903441050298226855\n",
      "Iteration 20032 => Loss: 48.51885406451438598197\n",
      "Iteration 20033 => Loss: 48.51867371994116240330\n",
      "Iteration 20034 => Loss: 48.51849337678324047829\n",
      "Iteration 20035 => Loss: 48.51831303504066994492\n",
      "Iteration 20036 => Loss: 48.51813269471339395977\n",
      "Iteration 20037 => Loss: 48.51795235580140541742\n",
      "Iteration 20038 => Loss: 48.51777201830473273958\n",
      "Iteration 20039 => Loss: 48.51759168222334039910\n",
      "Iteration 20040 => Loss: 48.51741134755720707972\n",
      "Iteration 20041 => Loss: 48.51723101430634699227\n",
      "Iteration 20042 => Loss: 48.51705068247071039877\n",
      "Iteration 20043 => Loss: 48.51687035205031151008\n",
      "Iteration 20044 => Loss: 48.51669002304515743162\n",
      "Iteration 20045 => Loss: 48.51650969545517710912\n",
      "Iteration 20046 => Loss: 48.51632936928042028057\n",
      "Iteration 20047 => Loss: 48.51614904452086562969\n",
      "Iteration 20048 => Loss: 48.51596872117647052391\n",
      "Iteration 20049 => Loss: 48.51578839924724917410\n",
      "Iteration 20050 => Loss: 48.51560807873319447481\n",
      "Iteration 20051 => Loss: 48.51542775963427800434\n",
      "Iteration 20052 => Loss: 48.51524744195049265727\n",
      "Iteration 20053 => Loss: 48.51506712568184553902\n",
      "Iteration 20054 => Loss: 48.51488681082827980617\n",
      "Iteration 20055 => Loss: 48.51470649738983809129\n",
      "Iteration 20056 => Loss: 48.51452618536649197267\n",
      "Iteration 20057 => Loss: 48.51434587475821302860\n",
      "Iteration 20058 => Loss: 48.51416556556501546993\n",
      "Iteration 20059 => Loss: 48.51398525778687087495\n",
      "Iteration 20060 => Loss: 48.51380495142377213824\n",
      "Iteration 20061 => Loss: 48.51362464647570504894\n",
      "Iteration 20062 => Loss: 48.51344434294265539620\n",
      "Iteration 20063 => Loss: 48.51326404082462318001\n",
      "Iteration 20064 => Loss: 48.51308374012159418953\n",
      "Iteration 20065 => Loss: 48.51290344083356842475\n",
      "Iteration 20066 => Loss: 48.51272314296049614768\n",
      "Iteration 20067 => Loss: 48.51254284650241999088\n",
      "Iteration 20068 => Loss: 48.51236255145925468923\n",
      "Iteration 20069 => Loss: 48.51218225783109261329\n",
      "Iteration 20070 => Loss: 48.51200196561782007620\n",
      "Iteration 20071 => Loss: 48.51182167481949392140\n",
      "Iteration 20072 => Loss: 48.51164138543608572718\n",
      "Iteration 20073 => Loss: 48.51146109746756707182\n",
      "Iteration 20074 => Loss: 48.51128081091394506075\n",
      "Iteration 20075 => Loss: 48.51110052577518416683\n",
      "Iteration 20076 => Loss: 48.51092024205131991721\n",
      "Iteration 20077 => Loss: 48.51073995974229546846\n",
      "Iteration 20078 => Loss: 48.51055967884811792601\n",
      "Iteration 20079 => Loss: 48.51037939936876597358\n",
      "Iteration 20080 => Loss: 48.51019912130426092745\n",
      "Iteration 20081 => Loss: 48.51001884465454594419\n",
      "Iteration 20082 => Loss: 48.50983856941966365639\n",
      "Iteration 20083 => Loss: 48.50965829559955011518\n",
      "Iteration 20084 => Loss: 48.50947802319419821515\n",
      "Iteration 20085 => Loss: 48.50929775220365058885\n",
      "Iteration 20086 => Loss: 48.50911748262785749830\n",
      "Iteration 20087 => Loss: 48.50893721446676920550\n",
      "Iteration 20088 => Loss: 48.50875694772045676473\n",
      "Iteration 20089 => Loss: 48.50857668238886333256\n",
      "Iteration 20090 => Loss: 48.50839641847196759272\n",
      "Iteration 20091 => Loss: 48.50821615596977665064\n",
      "Iteration 20092 => Loss: 48.50803589488229050630\n",
      "Iteration 20093 => Loss: 48.50785563520946652716\n",
      "Iteration 20094 => Loss: 48.50767537695132602948\n",
      "Iteration 20095 => Loss: 48.50749512010783348614\n",
      "Iteration 20096 => Loss: 48.50731486467898889714\n",
      "Iteration 20097 => Loss: 48.50713461066477805161\n",
      "Iteration 20098 => Loss: 48.50695435806520094957\n",
      "Iteration 20099 => Loss: 48.50677410688022206386\n",
      "Iteration 20100 => Loss: 48.50659385710984849993\n",
      "Iteration 20101 => Loss: 48.50641360875408025777\n",
      "Iteration 20102 => Loss: 48.50623336181288181024\n",
      "Iteration 20103 => Loss: 48.50605311628625315734\n",
      "Iteration 20104 => Loss: 48.50587287217416587737\n",
      "Iteration 20105 => Loss: 48.50569262947664128660\n",
      "Iteration 20106 => Loss: 48.50551238819365806876\n",
      "Iteration 20107 => Loss: 48.50533214832518780213\n",
      "Iteration 20108 => Loss: 48.50515190987122338129\n",
      "Iteration 20109 => Loss: 48.50497167283177191166\n",
      "Iteration 20110 => Loss: 48.50479143720679786611\n",
      "Iteration 20111 => Loss: 48.50461120299632966635\n",
      "Iteration 20112 => Loss: 48.50443097020031046895\n",
      "Iteration 20113 => Loss: 48.50425073881875448478\n",
      "Iteration 20114 => Loss: 48.50407050885164039755\n",
      "Iteration 20115 => Loss: 48.50389028029896820726\n",
      "Iteration 20116 => Loss: 48.50371005316073080849\n",
      "Iteration 20117 => Loss: 48.50352982743687846323\n",
      "Iteration 20118 => Loss: 48.50334960312744669864\n",
      "Iteration 20119 => Loss: 48.50316938023239998756\n",
      "Iteration 20120 => Loss: 48.50298915875172411916\n",
      "Iteration 20121 => Loss: 48.50280893868544751513\n",
      "Iteration 20122 => Loss: 48.50262872003350622663\n",
      "Iteration 20123 => Loss: 48.50244850279589314823\n",
      "Iteration 20124 => Loss: 48.50226828697265091250\n",
      "Iteration 20125 => Loss: 48.50208807256371557060\n",
      "Iteration 20126 => Loss: 48.50190785956909422794\n",
      "Iteration 20127 => Loss: 48.50172764798875846282\n",
      "Iteration 20128 => Loss: 48.50154743782275090780\n",
      "Iteration 20129 => Loss: 48.50136722907100050861\n",
      "Iteration 20130 => Loss: 48.50118702173352858154\n",
      "Iteration 20131 => Loss: 48.50100681581031381029\n",
      "Iteration 20132 => Loss: 48.50082661130132777316\n",
      "Iteration 20133 => Loss: 48.50064640820658468101\n",
      "Iteration 20134 => Loss: 48.50046620652608453383\n",
      "Iteration 20135 => Loss: 48.50028600625977759364\n",
      "Iteration 20136 => Loss: 48.50010580740769228214\n",
      "Iteration 20137 => Loss: 48.49992560996977175591\n",
      "Iteration 20138 => Loss: 48.49974541394603733124\n",
      "Iteration 20139 => Loss: 48.49956521933649611356\n",
      "Iteration 20140 => Loss: 48.49938502614109125943\n",
      "Iteration 20141 => Loss: 48.49920483435982987430\n",
      "Iteration 20142 => Loss: 48.49902464399273327444\n",
      "Iteration 20143 => Loss: 48.49884445503972330016\n",
      "Iteration 20144 => Loss: 48.49866426750084258401\n",
      "Iteration 20145 => Loss: 48.49848408137606980972\n",
      "Iteration 20146 => Loss: 48.49830389666538366100\n",
      "Iteration 20147 => Loss: 48.49812371336875571615\n",
      "Iteration 20148 => Loss: 48.49794353148623571315\n",
      "Iteration 20149 => Loss: 48.49776335101775259773\n",
      "Iteration 20150 => Loss: 48.49758317196333479160\n",
      "Iteration 20151 => Loss: 48.49740299432292545134\n",
      "Iteration 20152 => Loss: 48.49722281809655299867\n",
      "Iteration 20153 => Loss: 48.49704264328418190644\n",
      "Iteration 20154 => Loss: 48.49686246988584059636\n",
      "Iteration 20155 => Loss: 48.49668229790146511959\n",
      "Iteration 20156 => Loss: 48.49650212733108389784\n",
      "Iteration 20157 => Loss: 48.49632195817466850940\n",
      "Iteration 20158 => Loss: 48.49614179043221184884\n",
      "Iteration 20159 => Loss: 48.49596162410369970530\n",
      "Iteration 20160 => Loss: 48.49578145918912497336\n",
      "Iteration 20161 => Loss: 48.49560129568847344217\n",
      "Iteration 20162 => Loss: 48.49542113360174511172\n",
      "Iteration 20163 => Loss: 48.49524097292889024402\n",
      "Iteration 20164 => Loss: 48.49506081366997989335\n",
      "Iteration 20165 => Loss: 48.49488065582490747829\n",
      "Iteration 20166 => Loss: 48.49470049939370852599\n",
      "Iteration 20167 => Loss: 48.49452034437636172015\n",
      "Iteration 20168 => Loss: 48.49434019077287416621\n",
      "Iteration 20169 => Loss: 48.49416003858323165332\n",
      "Iteration 20170 => Loss: 48.49397988780741286519\n",
      "Iteration 20171 => Loss: 48.49379973844537516925\n",
      "Iteration 20172 => Loss: 48.49361959049718251435\n",
      "Iteration 20173 => Loss: 48.49343944396275674080\n",
      "Iteration 20174 => Loss: 48.49325929884212627030\n",
      "Iteration 20175 => Loss: 48.49307915513526268114\n",
      "Iteration 20176 => Loss: 48.49289901284214465704\n",
      "Iteration 20177 => Loss: 48.49271887196277930343\n",
      "Iteration 20178 => Loss: 48.49253873249715240945\n",
      "Iteration 20179 => Loss: 48.49235859444524265882\n",
      "Iteration 20180 => Loss: 48.49217845780705715697\n",
      "Iteration 20181 => Loss: 48.49199832258258169304\n",
      "Iteration 20182 => Loss: 48.49181818877178784533\n",
      "Iteration 20183 => Loss: 48.49163805637467561382\n",
      "Iteration 20184 => Loss: 48.49145792539122368225\n",
      "Iteration 20185 => Loss: 48.49127779582145336690\n",
      "Iteration 20186 => Loss: 48.49109766766530071891\n",
      "Iteration 20187 => Loss: 48.49091754092281547628\n",
      "Iteration 20188 => Loss: 48.49073741559393369016\n",
      "Iteration 20189 => Loss: 48.49055729167868378227\n",
      "Iteration 20190 => Loss: 48.49037716917700180375\n",
      "Iteration 20191 => Loss: 48.49019704808892328174\n",
      "Iteration 20192 => Loss: 48.49001692841446242710\n",
      "Iteration 20193 => Loss: 48.48983681015353397470\n",
      "Iteration 20194 => Loss: 48.48965669330618766253\n",
      "Iteration 20195 => Loss: 48.48947657787236664717\n",
      "Iteration 20196 => Loss: 48.48929646385209224491\n",
      "Iteration 20197 => Loss: 48.48911635124533603403\n",
      "Iteration 20198 => Loss: 48.48893624005211222538\n",
      "Iteration 20199 => Loss: 48.48875613027239239727\n",
      "Iteration 20200 => Loss: 48.48857602190613391713\n",
      "Iteration 20201 => Loss: 48.48839591495339362837\n",
      "Iteration 20202 => Loss: 48.48821580941408626586\n",
      "Iteration 20203 => Loss: 48.48803570528825446218\n",
      "Iteration 20204 => Loss: 48.48785560257588400646\n",
      "Iteration 20205 => Loss: 48.48767550127693226614\n",
      "Iteration 20206 => Loss: 48.48749540139141345207\n",
      "Iteration 20207 => Loss: 48.48731530291931335341\n",
      "Iteration 20208 => Loss: 48.48713520586061065387\n",
      "Iteration 20209 => Loss: 48.48695511021530535345\n",
      "Iteration 20210 => Loss: 48.48677501598336903044\n",
      "Iteration 20211 => Loss: 48.48659492316481589569\n",
      "Iteration 20212 => Loss: 48.48641483175961042207\n",
      "Iteration 20213 => Loss: 48.48623474176776682043\n",
      "Iteration 20214 => Loss: 48.48605465318925666907\n",
      "Iteration 20215 => Loss: 48.48587456602405865169\n",
      "Iteration 20216 => Loss: 48.48569448027218697916\n",
      "Iteration 20217 => Loss: 48.48551439593362033520\n",
      "Iteration 20218 => Loss: 48.48533431300833740352\n",
      "Iteration 20219 => Loss: 48.48515423149634528954\n",
      "Iteration 20220 => Loss: 48.48497415139759425529\n",
      "Iteration 20221 => Loss: 48.48479407271214824959\n",
      "Iteration 20222 => Loss: 48.48461399543992911276\n",
      "Iteration 20223 => Loss: 48.48443391958093684480\n",
      "Iteration 20224 => Loss: 48.48425384513517855112\n",
      "Iteration 20225 => Loss: 48.48407377210264002088\n",
      "Iteration 20226 => Loss: 48.48389370048329283236\n",
      "Iteration 20227 => Loss: 48.48371363027715830185\n",
      "Iteration 20228 => Loss: 48.48353356148417958593\n",
      "Iteration 20229 => Loss: 48.48335349410439931717\n",
      "Iteration 20230 => Loss: 48.48317342813776065213\n",
      "Iteration 20231 => Loss: 48.48299336358427780169\n",
      "Iteration 20232 => Loss: 48.48281330044390813327\n",
      "Iteration 20233 => Loss: 48.48263323871670138487\n",
      "Iteration 20234 => Loss: 48.48245317840257229136\n",
      "Iteration 20235 => Loss: 48.48227311950158480158\n",
      "Iteration 20236 => Loss: 48.48209306201366075584\n",
      "Iteration 20237 => Loss: 48.48191300593882857584\n",
      "Iteration 20238 => Loss: 48.48173295127708826158\n",
      "Iteration 20239 => Loss: 48.48155289802836165336\n",
      "Iteration 20240 => Loss: 48.48137284619271980546\n",
      "Iteration 20241 => Loss: 48.48119279577010587445\n",
      "Iteration 20242 => Loss: 48.48101274676051275492\n",
      "Iteration 20243 => Loss: 48.48083269916394755228\n",
      "Iteration 20244 => Loss: 48.48065265298038184483\n",
      "Iteration 20245 => Loss: 48.48047260820981563256\n",
      "Iteration 20246 => Loss: 48.48029256485221338835\n",
      "Iteration 20247 => Loss: 48.48011252290760353389\n",
      "Iteration 20248 => Loss: 48.47993248237590790950\n",
      "Iteration 20249 => Loss: 48.47975244325721178029\n",
      "Iteration 20250 => Loss: 48.47957240555142988114\n",
      "Iteration 20251 => Loss: 48.47939236925858352834\n",
      "Iteration 20252 => Loss: 48.47921233437864430016\n",
      "Iteration 20253 => Loss: 48.47903230091161219661\n",
      "Iteration 20254 => Loss: 48.47885226885747300685\n",
      "Iteration 20255 => Loss: 48.47867223821621252000\n",
      "Iteration 20256 => Loss: 48.47849220898783073608\n",
      "Iteration 20257 => Loss: 48.47831218117229923337\n",
      "Iteration 20258 => Loss: 48.47813215476962511730\n",
      "Iteration 20259 => Loss: 48.47795212977979417701\n",
      "Iteration 20260 => Loss: 48.47777210620277799080\n",
      "Iteration 20261 => Loss: 48.47759208403858366410\n",
      "Iteration 20262 => Loss: 48.47741206328718277518\n",
      "Iteration 20263 => Loss: 48.47723204394858953492\n",
      "Iteration 20264 => Loss: 48.47705202602275420531\n",
      "Iteration 20265 => Loss: 48.47687200950970520807\n",
      "Iteration 20266 => Loss: 48.47669199440944254320\n",
      "Iteration 20267 => Loss: 48.47651198072189515642\n",
      "Iteration 20268 => Loss: 48.47633196844709146944\n",
      "Iteration 20269 => Loss: 48.47615195758503858769\n",
      "Iteration 20270 => Loss: 48.47597194813567966776\n",
      "Iteration 20271 => Loss: 48.47579194009902892049\n",
      "Iteration 20272 => Loss: 48.47561193347507924045\n",
      "Iteration 20273 => Loss: 48.47543192826380220595\n",
      "Iteration 20274 => Loss: 48.47525192446519071154\n",
      "Iteration 20275 => Loss: 48.47507192207923765181\n",
      "Iteration 20276 => Loss: 48.47489192110593592133\n",
      "Iteration 20277 => Loss: 48.47471192154529262552\n",
      "Iteration 20278 => Loss: 48.47453192339725802640\n",
      "Iteration 20279 => Loss: 48.47435192666185344024\n",
      "Iteration 20280 => Loss: 48.47417193133902912905\n",
      "Iteration 20281 => Loss: 48.47399193742881351454\n",
      "Iteration 20282 => Loss: 48.47381194493119238587\n",
      "Iteration 20283 => Loss: 48.47363195384613732131\n",
      "Iteration 20284 => Loss: 48.47345196417363411001\n",
      "Iteration 20285 => Loss: 48.47327197591367564655\n",
      "Iteration 20286 => Loss: 48.47309198906627614178\n",
      "Iteration 20287 => Loss: 48.47291200363138585772\n",
      "Iteration 20288 => Loss: 48.47273201960903321606\n",
      "Iteration 20289 => Loss: 48.47255203699915426796\n",
      "Iteration 20290 => Loss: 48.47237205580179164599\n",
      "Iteration 20291 => Loss: 48.47219207601691692844\n",
      "Iteration 20292 => Loss: 48.47201209764447327188\n",
      "Iteration 20293 => Loss: 48.47183212068453173060\n",
      "Iteration 20294 => Loss: 48.47165214513702835575\n",
      "Iteration 20295 => Loss: 48.47147217100197025275\n",
      "Iteration 20296 => Loss: 48.47129219827932899989\n",
      "Iteration 20297 => Loss: 48.47111222696909749175\n",
      "Iteration 20298 => Loss: 48.47093225707128993918\n",
      "Iteration 20299 => Loss: 48.47075228858586370961\n",
      "Iteration 20300 => Loss: 48.47057232151284011934\n",
      "Iteration 20301 => Loss: 48.47039235585214811408\n",
      "Iteration 20302 => Loss: 48.47021239160385164269\n",
      "Iteration 20303 => Loss: 48.47003242876789386173\n",
      "Iteration 20304 => Loss: 48.46985246734427477122\n",
      "Iteration 20305 => Loss: 48.46967250733301568744\n",
      "Iteration 20306 => Loss: 48.46949254873403134525\n",
      "Iteration 20307 => Loss: 48.46931259154736437722\n",
      "Iteration 20308 => Loss: 48.46913263577297215079\n",
      "Iteration 20309 => Loss: 48.46895268141090440395\n",
      "Iteration 20310 => Loss: 48.46877272846108297699\n",
      "Iteration 20311 => Loss: 48.46859277692352918621\n",
      "Iteration 20312 => Loss: 48.46841282679822171531\n",
      "Iteration 20313 => Loss: 48.46823287808516766972\n",
      "Iteration 20314 => Loss: 48.46805293078431020604\n",
      "Iteration 20315 => Loss: 48.46787298489569195681\n",
      "Iteration 20316 => Loss: 48.46769304041928450033\n",
      "Iteration 20317 => Loss: 48.46751309735506652032\n",
      "Iteration 20318 => Loss: 48.46733315570303801678\n",
      "Iteration 20319 => Loss: 48.46715321546316346257\n",
      "Iteration 20320 => Loss: 48.46697327663546417398\n",
      "Iteration 20321 => Loss: 48.46679333921991172929\n",
      "Iteration 20322 => Loss: 48.46661340321650612850\n",
      "Iteration 20323 => Loss: 48.46643346862520473906\n",
      "Iteration 20324 => Loss: 48.46625353544605019351\n",
      "Iteration 20325 => Loss: 48.46607360367897854303\n",
      "Iteration 20326 => Loss: 48.46589367332402531474\n",
      "Iteration 20327 => Loss: 48.46571374438116208694\n",
      "Iteration 20328 => Loss: 48.46553381685033201620\n",
      "Iteration 20329 => Loss: 48.46535389073158484052\n",
      "Iteration 20330 => Loss: 48.46517396602488503277\n",
      "Iteration 20331 => Loss: 48.46499404273021838208\n",
      "Iteration 20332 => Loss: 48.46481412084760620473\n",
      "Iteration 20333 => Loss: 48.46463420037699876275\n",
      "Iteration 20334 => Loss: 48.46445428131838895069\n",
      "Iteration 20335 => Loss: 48.46427436367176966314\n",
      "Iteration 20336 => Loss: 48.46409444743716221637\n",
      "Iteration 20337 => Loss: 48.46391453261450266154\n",
      "Iteration 20338 => Loss: 48.46373461920381231494\n",
      "Iteration 20339 => Loss: 48.46355470720506986027\n",
      "Iteration 20340 => Loss: 48.46337479661827529753\n",
      "Iteration 20341 => Loss: 48.46319488744341441588\n",
      "Iteration 20342 => Loss: 48.46301497968043747733\n",
      "Iteration 20343 => Loss: 48.46283507332939421985\n",
      "Iteration 20344 => Loss: 48.46265516839026332718\n",
      "Iteration 20345 => Loss: 48.46247526486300216675\n",
      "Iteration 20346 => Loss: 48.46229536274760363312\n",
      "Iteration 20347 => Loss: 48.46211546204407483174\n",
      "Iteration 20348 => Loss: 48.46193556275239444631\n",
      "Iteration 20349 => Loss: 48.46175566487255537140\n",
      "Iteration 20350 => Loss: 48.46157576840455050160\n",
      "Iteration 20351 => Loss: 48.46139587334833720433\n",
      "Iteration 20352 => Loss: 48.46121597970395811217\n",
      "Iteration 20353 => Loss: 48.46103608747138480339\n",
      "Iteration 20354 => Loss: 48.46085619665057464545\n",
      "Iteration 20355 => Loss: 48.46067630724154895461\n",
      "Iteration 20356 => Loss: 48.46049641924427930917\n",
      "Iteration 20357 => Loss: 48.46031653265875860370\n",
      "Iteration 20358 => Loss: 48.46013664748498683821\n",
      "Iteration 20359 => Loss: 48.45995676372292848555\n",
      "Iteration 20360 => Loss: 48.45977688137261907286\n",
      "Iteration 20361 => Loss: 48.45959700043398044045\n",
      "Iteration 20362 => Loss: 48.45941712090707653715\n",
      "Iteration 20363 => Loss: 48.45923724279183630870\n",
      "Iteration 20364 => Loss: 48.45905736608827396594\n",
      "Iteration 20365 => Loss: 48.45887749079636819260\n",
      "Iteration 20366 => Loss: 48.45869761691611188326\n",
      "Iteration 20367 => Loss: 48.45851774444749082704\n",
      "Iteration 20368 => Loss: 48.45833787339051212939\n",
      "Iteration 20369 => Loss: 48.45815800374516157945\n",
      "Iteration 20370 => Loss: 48.45797813551140365007\n",
      "Iteration 20371 => Loss: 48.45779826868924544669\n",
      "Iteration 20372 => Loss: 48.45761840327867986389\n",
      "Iteration 20373 => Loss: 48.45743853927967847994\n",
      "Iteration 20374 => Loss: 48.45725867669224129486\n",
      "Iteration 20375 => Loss: 48.45707881551636120321\n",
      "Iteration 20376 => Loss: 48.45689895575201688871\n",
      "Iteration 20377 => Loss: 48.45671909739921545679\n",
      "Iteration 20378 => Loss: 48.45653924045791427488\n",
      "Iteration 20379 => Loss: 48.45635938492812755385\n",
      "Iteration 20380 => Loss: 48.45617953080985529368\n",
      "Iteration 20381 => Loss: 48.45599967810303354554\n",
      "Iteration 20382 => Loss: 48.45581982680770494198\n",
      "Iteration 20383 => Loss: 48.45563997692383395588\n",
      "Iteration 20384 => Loss: 48.45546012845143479808\n",
      "Iteration 20385 => Loss: 48.45528028139045773059\n",
      "Iteration 20386 => Loss: 48.45510043574091696428\n",
      "Iteration 20387 => Loss: 48.45492059150279828827\n",
      "Iteration 20388 => Loss: 48.45474074867608038630\n",
      "Iteration 20389 => Loss: 48.45456090726076325836\n",
      "Iteration 20390 => Loss: 48.45438106725683979903\n",
      "Iteration 20391 => Loss: 48.45420122866427448116\n",
      "Iteration 20392 => Loss: 48.45402139148309572647\n",
      "Iteration 20393 => Loss: 48.45384155571323958611\n",
      "Iteration 20394 => Loss: 48.45366172135474158722\n",
      "Iteration 20395 => Loss: 48.45348188840758041351\n",
      "Iteration 20396 => Loss: 48.45330205687172764328\n",
      "Iteration 20397 => Loss: 48.45312222674717617110\n",
      "Iteration 20398 => Loss: 48.45294239803394731325\n",
      "Iteration 20399 => Loss: 48.45276257073199133174\n",
      "Iteration 20400 => Loss: 48.45258274484130822657\n",
      "Iteration 20401 => Loss: 48.45240292036190510316\n",
      "Iteration 20402 => Loss: 48.45222309729373932896\n",
      "Iteration 20403 => Loss: 48.45204327563681800939\n",
      "Iteration 20404 => Loss: 48.45186345539111982816\n",
      "Iteration 20405 => Loss: 48.45168363655664478529\n",
      "Iteration 20406 => Loss: 48.45150381913339288076\n",
      "Iteration 20407 => Loss: 48.45132400312132858744\n",
      "Iteration 20408 => Loss: 48.45114418852044479991\n",
      "Iteration 20409 => Loss: 48.45096437533074151816\n",
      "Iteration 20410 => Loss: 48.45078456355220453133\n",
      "Iteration 20411 => Loss: 48.45060475318481252316\n",
      "Iteration 20412 => Loss: 48.45042494422857970449\n",
      "Iteration 20413 => Loss: 48.45024513668347054818\n",
      "Iteration 20414 => Loss: 48.45006533054949215966\n",
      "Iteration 20415 => Loss: 48.44988552582658769552\n",
      "Iteration 20416 => Loss: 48.44970572251482110460\n",
      "Iteration 20417 => Loss: 48.44952592061412843805\n",
      "Iteration 20418 => Loss: 48.44934612012449548502\n",
      "Iteration 20419 => Loss: 48.44916632104595066721\n",
      "Iteration 20420 => Loss: 48.44898652337844424665\n",
      "Iteration 20421 => Loss: 48.44880672712197622332\n",
      "Iteration 20422 => Loss: 48.44862693227654659722\n",
      "Iteration 20423 => Loss: 48.44844713884212694666\n",
      "Iteration 20424 => Loss: 48.44826734681874569333\n",
      "Iteration 20425 => Loss: 48.44808755620633888839\n",
      "Iteration 20426 => Loss: 48.44790776700491363727\n",
      "Iteration 20427 => Loss: 48.44772797921449836167\n",
      "Iteration 20428 => Loss: 48.44754819283502200733\n",
      "Iteration 20429 => Loss: 48.44736840786650589052\n",
      "Iteration 20430 => Loss: 48.44718862430893580040\n",
      "Iteration 20431 => Loss: 48.44700884216229752610\n",
      "Iteration 20432 => Loss: 48.44682906142657685677\n",
      "Iteration 20433 => Loss: 48.44664928210175958156\n",
      "Iteration 20434 => Loss: 48.44646950418785280590\n",
      "Iteration 20435 => Loss: 48.44628972768482100264\n",
      "Iteration 20436 => Loss: 48.44610995259267127722\n",
      "Iteration 20437 => Loss: 48.44593017891138941877\n",
      "Iteration 20438 => Loss: 48.44575040664096121645\n",
      "Iteration 20439 => Loss: 48.44557063578137245941\n",
      "Iteration 20440 => Loss: 48.44539086633263025305\n",
      "Iteration 20441 => Loss: 48.44521109829469196484\n",
      "Iteration 20442 => Loss: 48.44503133166755759476\n",
      "Iteration 20443 => Loss: 48.44485156645123424823\n",
      "Iteration 20444 => Loss: 48.44467180264570060899\n",
      "Iteration 20445 => Loss: 48.44449204025094957160\n",
      "Iteration 20446 => Loss: 48.44431227926694560892\n",
      "Iteration 20447 => Loss: 48.44413251969371714267\n",
      "Iteration 20448 => Loss: 48.44395276153120732943\n",
      "Iteration 20449 => Loss: 48.44377300477945880175\n",
      "Iteration 20450 => Loss: 48.44359324943841471622\n",
      "Iteration 20451 => Loss: 48.44341349550808217828\n",
      "Iteration 20452 => Loss: 48.44323374298844697705\n",
      "Iteration 20453 => Loss: 48.44305399187950200712\n",
      "Iteration 20454 => Loss: 48.44287424218125437392\n",
      "Iteration 20455 => Loss: 48.44269449389364012859\n",
      "Iteration 20456 => Loss: 48.44251474701671611456\n",
      "Iteration 20457 => Loss: 48.44233500155038996127\n",
      "Iteration 20458 => Loss: 48.44215525749473982842\n",
      "Iteration 20459 => Loss: 48.44197551484969466173\n",
      "Iteration 20460 => Loss: 48.44179577361525446122\n",
      "Iteration 20461 => Loss: 48.44161603379142633230\n",
      "Iteration 20462 => Loss: 48.44143629537818185327\n",
      "Iteration 20463 => Loss: 48.44125655837550681326\n",
      "Iteration 20464 => Loss: 48.44107682278340121229\n",
      "Iteration 20465 => Loss: 48.44089708860185083950\n",
      "Iteration 20466 => Loss: 48.44071735583084148402\n",
      "Iteration 20467 => Loss: 48.44053762447039446215\n",
      "Iteration 20468 => Loss: 48.44035789452045293046\n",
      "Iteration 20469 => Loss: 48.44017816598101688896\n",
      "Iteration 20470 => Loss: 48.43999843885209344307\n",
      "Iteration 20471 => Loss: 48.43981871313362574938\n",
      "Iteration 20472 => Loss: 48.43963898882565644044\n",
      "Iteration 20473 => Loss: 48.43945926592817130540\n",
      "Iteration 20474 => Loss: 48.43927954444111350085\n",
      "Iteration 20475 => Loss: 48.43909982436452565935\n",
      "Iteration 20476 => Loss: 48.43892010569835804290\n",
      "Iteration 20477 => Loss: 48.43874038844259644065\n",
      "Iteration 20478 => Loss: 48.43856067259726927432\n",
      "Iteration 20479 => Loss: 48.43838095816234812219\n",
      "Iteration 20480 => Loss: 48.43820124513779035169\n",
      "Iteration 20481 => Loss: 48.43802153352364570082\n",
      "Iteration 20482 => Loss: 48.43784182331983600989\n",
      "Iteration 20483 => Loss: 48.43766211452639680601\n",
      "Iteration 20484 => Loss: 48.43748240714330677292\n",
      "Iteration 20485 => Loss: 48.43730270117055169976\n",
      "Iteration 20486 => Loss: 48.43712299660810316482\n",
      "Iteration 20487 => Loss: 48.43694329345597537895\n",
      "Iteration 20488 => Loss: 48.43676359171416123672\n",
      "Iteration 20489 => Loss: 48.43658389138261810558\n",
      "Iteration 20490 => Loss: 48.43640419246133888009\n",
      "Iteration 20491 => Loss: 48.43622449495036619282\n",
      "Iteration 20492 => Loss: 48.43604479884961477865\n",
      "Iteration 20493 => Loss: 48.43586510415915569183\n",
      "Iteration 20494 => Loss: 48.43568541087888945640\n",
      "Iteration 20495 => Loss: 48.43550571900885159948\n",
      "Iteration 20496 => Loss: 48.43532602854904212109\n",
      "Iteration 20497 => Loss: 48.43514633949942549407\n",
      "Iteration 20498 => Loss: 48.43496665186000882386\n",
      "Iteration 20499 => Loss: 48.43478696563075658332\n",
      "Iteration 20500 => Loss: 48.43460728081166877246\n",
      "Iteration 20501 => Loss: 48.43442759740275960212\n",
      "Iteration 20502 => Loss: 48.43424791540399354517\n",
      "Iteration 20503 => Loss: 48.43406823481533507447\n",
      "Iteration 20504 => Loss: 48.43388855563681971717\n",
      "Iteration 20505 => Loss: 48.43370887786841194611\n",
      "Iteration 20506 => Loss: 48.43352920151011176131\n",
      "Iteration 20507 => Loss: 48.43334952656189784648\n",
      "Iteration 20508 => Loss: 48.43316985302376309619\n",
      "Iteration 20509 => Loss: 48.43299018089570040502\n",
      "Iteration 20510 => Loss: 48.43281051017768135125\n",
      "Iteration 20511 => Loss: 48.43263084086974856746\n",
      "Iteration 20512 => Loss: 48.43245117297180257765\n",
      "Iteration 20513 => Loss: 48.43227150648392154153\n",
      "Iteration 20514 => Loss: 48.43209184140602729940\n",
      "Iteration 20515 => Loss: 48.43191217773814827297\n",
      "Iteration 20516 => Loss: 48.43173251548023472424\n",
      "Iteration 20517 => Loss: 48.43155285463232928578\n",
      "Iteration 20518 => Loss: 48.43137319519438221960\n",
      "Iteration 20519 => Loss: 48.43119353716637931484\n",
      "Iteration 20520 => Loss: 48.43101388054834899322\n",
      "Iteration 20521 => Loss: 48.43083422534024862216\n",
      "Iteration 20522 => Loss: 48.43065457154206399082\n",
      "Iteration 20523 => Loss: 48.43047491915380931005\n",
      "Iteration 20524 => Loss: 48.43029526817543484185\n",
      "Iteration 20525 => Loss: 48.43011561860696900794\n",
      "Iteration 20526 => Loss: 48.42993597044836207033\n",
      "Iteration 20527 => Loss: 48.42975632369964245072\n",
      "Iteration 20528 => Loss: 48.42957667836078172741\n",
      "Iteration 20529 => Loss: 48.42939703443173726782\n",
      "Iteration 20530 => Loss: 48.42921739191257302082\n",
      "Iteration 20531 => Loss: 48.42903775080321793212\n",
      "Iteration 20532 => Loss: 48.42885811110368621257\n",
      "Iteration 20533 => Loss: 48.42867847281393522962\n",
      "Iteration 20534 => Loss: 48.42849883593398629955\n",
      "Iteration 20535 => Loss: 48.42831920046381100065\n",
      "Iteration 20536 => Loss: 48.42813956640340933291\n",
      "Iteration 20537 => Loss: 48.42795993375277419091\n",
      "Iteration 20538 => Loss: 48.42778030251189846922\n",
      "Iteration 20539 => Loss: 48.42760067268072532443\n",
      "Iteration 20540 => Loss: 48.42742104425929738909\n",
      "Iteration 20541 => Loss: 48.42724141724758624150\n",
      "Iteration 20542 => Loss: 48.42706179164557767081\n",
      "Iteration 20543 => Loss: 48.42688216745325036072\n",
      "Iteration 20544 => Loss: 48.42670254467061852210\n",
      "Iteration 20545 => Loss: 48.42652292329763241696\n",
      "Iteration 20546 => Loss: 48.42634330333432757243\n",
      "Iteration 20547 => Loss: 48.42616368478066846137\n",
      "Iteration 20548 => Loss: 48.42598406763664797836\n",
      "Iteration 20549 => Loss: 48.42580445190224480712\n",
      "Iteration 20550 => Loss: 48.42562483757747315849\n",
      "Iteration 20551 => Loss: 48.42544522466228329449\n",
      "Iteration 20552 => Loss: 48.42526561315669653141\n",
      "Iteration 20553 => Loss: 48.42508600306069865837\n",
      "Iteration 20554 => Loss: 48.42490639437425414826\n",
      "Iteration 20555 => Loss: 48.42472678709737010649\n",
      "Iteration 20556 => Loss: 48.42454718123003232222\n",
      "Iteration 20557 => Loss: 48.42436757677225500629\n",
      "Iteration 20558 => Loss: 48.42418797372398842072\n",
      "Iteration 20559 => Loss: 48.42400837208524677635\n",
      "Iteration 20560 => Loss: 48.42382877185600165149\n",
      "Iteration 20561 => Loss: 48.42364917303624594069\n",
      "Iteration 20562 => Loss: 48.42346957562597964397\n",
      "Iteration 20563 => Loss: 48.42328997962516723419\n",
      "Iteration 20564 => Loss: 48.42311038503385134391\n",
      "Iteration 20565 => Loss: 48.42293079185196091885\n",
      "Iteration 20566 => Loss: 48.42275120007949595902\n",
      "Iteration 20567 => Loss: 48.42257160971645646441\n",
      "Iteration 20568 => Loss: 48.42239202076287085674\n",
      "Iteration 20569 => Loss: 48.42221243321865387088\n",
      "Iteration 20570 => Loss: 48.42203284708384103396\n",
      "Iteration 20571 => Loss: 48.42185326235842524056\n",
      "Iteration 20572 => Loss: 48.42167367904235675269\n",
      "Iteration 20573 => Loss: 48.42149409713567109748\n",
      "Iteration 20574 => Loss: 48.42131451663833274779\n",
      "Iteration 20575 => Loss: 48.42113493755032749277\n",
      "Iteration 20576 => Loss: 48.42095535987164112157\n",
      "Iteration 20577 => Loss: 48.42077578360229495047\n",
      "Iteration 20578 => Loss: 48.42059620874220371434\n",
      "Iteration 20579 => Loss: 48.42041663529143846745\n",
      "Iteration 20580 => Loss: 48.42023706324994947181\n",
      "Iteration 20581 => Loss: 48.42005749261774383285\n",
      "Iteration 20582 => Loss: 48.41987792339480023429\n",
      "Iteration 20583 => Loss: 48.41969835558109025442\n",
      "Iteration 20584 => Loss: 48.41951878917664942037\n",
      "Iteration 20585 => Loss: 48.41933922418139957244\n",
      "Iteration 20586 => Loss: 48.41915966059539044863\n",
      "Iteration 20587 => Loss: 48.41898009841857231095\n",
      "Iteration 20588 => Loss: 48.41880053765095937024\n",
      "Iteration 20589 => Loss: 48.41862097829252320480\n",
      "Iteration 20590 => Loss: 48.41844142034325670920\n",
      "Iteration 20591 => Loss: 48.41826186380315988345\n",
      "Iteration 20592 => Loss: 48.41808230867221851668\n",
      "Iteration 20593 => Loss: 48.41790275495038997633\n",
      "Iteration 20594 => Loss: 48.41772320263771689497\n",
      "Iteration 20595 => Loss: 48.41754365173414953460\n",
      "Iteration 20596 => Loss: 48.41736410223968789523\n",
      "Iteration 20597 => Loss: 48.41718455415433197686\n",
      "Iteration 20598 => Loss: 48.41700500747805335777\n",
      "Iteration 20599 => Loss: 48.41682546221085203797\n",
      "Iteration 20600 => Loss: 48.41664591835269249032\n",
      "Iteration 20601 => Loss: 48.41646637590361734738\n",
      "Iteration 20602 => Loss: 48.41628683486354844945\n",
      "Iteration 20603 => Loss: 48.41610729523252132367\n",
      "Iteration 20604 => Loss: 48.41592775701051465376\n",
      "Iteration 20605 => Loss: 48.41574822019751422886\n",
      "Iteration 20606 => Loss: 48.41556868479349162726\n",
      "Iteration 20607 => Loss: 48.41538915079846816525\n",
      "Iteration 20608 => Loss: 48.41520961821242252654\n",
      "Iteration 20609 => Loss: 48.41503008703534050028\n",
      "Iteration 20610 => Loss: 48.41485055726718655933\n",
      "Iteration 20611 => Loss: 48.41467102890798201997\n",
      "Iteration 20612 => Loss: 48.41449150195772688221\n",
      "Iteration 20613 => Loss: 48.41431197641639272433\n",
      "Iteration 20614 => Loss: 48.41413245228393691377\n",
      "Iteration 20615 => Loss: 48.41395292956038076682\n",
      "Iteration 20616 => Loss: 48.41377340824573849432\n",
      "Iteration 20617 => Loss: 48.41359388833993904200\n",
      "Iteration 20618 => Loss: 48.41341436984302504243\n",
      "Iteration 20619 => Loss: 48.41323485275495386304\n",
      "Iteration 20620 => Loss: 48.41305533707571129298\n",
      "Iteration 20621 => Loss: 48.41287582280531154311\n",
      "Iteration 20622 => Loss: 48.41269630994370487542\n",
      "Iteration 20623 => Loss: 48.41251679849095523878\n",
      "Iteration 20624 => Loss: 48.41233728844697736804\n",
      "Iteration 20625 => Loss: 48.41215777981176415778\n",
      "Iteration 20626 => Loss: 48.41197827258536534600\n",
      "Iteration 20627 => Loss: 48.41179876676770277300\n",
      "Iteration 20628 => Loss: 48.41161926235877643876\n",
      "Iteration 20629 => Loss: 48.41143975935862897586\n",
      "Iteration 20630 => Loss: 48.41126025776718933002\n",
      "Iteration 20631 => Loss: 48.41108075758449302839\n",
      "Iteration 20632 => Loss: 48.41090125881046191125\n",
      "Iteration 20633 => Loss: 48.41072176144516703289\n",
      "Iteration 20634 => Loss: 48.41054226548853023360\n",
      "Iteration 20635 => Loss: 48.41036277094058704051\n",
      "Iteration 20636 => Loss: 48.41018327780129482107\n",
      "Iteration 20637 => Loss: 48.41000378607066778613\n",
      "Iteration 20638 => Loss: 48.40982429574867751398\n",
      "Iteration 20639 => Loss: 48.40964480683533111005\n",
      "Iteration 20640 => Loss: 48.40946531933057883634\n",
      "Iteration 20641 => Loss: 48.40928583323444911457\n",
      "Iteration 20642 => Loss: 48.40910634854689931217\n",
      "Iteration 20643 => Loss: 48.40892686526795785085\n",
      "Iteration 20644 => Loss: 48.40874738339758209804\n",
      "Iteration 20645 => Loss: 48.40856790293577915918\n",
      "Iteration 20646 => Loss: 48.40838842388252771798\n",
      "Iteration 20647 => Loss: 48.40820894623781356358\n",
      "Iteration 20648 => Loss: 48.40802947000162959057\n",
      "Iteration 20649 => Loss: 48.40784999517396158808\n",
      "Iteration 20650 => Loss: 48.40767052175480955611\n",
      "Iteration 20651 => Loss: 48.40749104974415217839\n",
      "Iteration 20652 => Loss: 48.40731157914197524406\n",
      "Iteration 20653 => Loss: 48.40713210994828585854\n",
      "Iteration 20654 => Loss: 48.40695264216305560012\n",
      "Iteration 20655 => Loss: 48.40677317578629867967\n",
      "Iteration 20656 => Loss: 48.40659371081793693747\n",
      "Iteration 20657 => Loss: 48.40641424725805563867\n",
      "Iteration 20658 => Loss: 48.40623478510656951812\n",
      "Iteration 20659 => Loss: 48.40605532436349989212\n",
      "Iteration 20660 => Loss: 48.40587586502882544437\n",
      "Iteration 20661 => Loss: 48.40569640710254617488\n",
      "Iteration 20662 => Loss: 48.40551695058464787280\n",
      "Iteration 20663 => Loss: 48.40533749547509501099\n",
      "Iteration 20664 => Loss: 48.40515804177389469487\n",
      "Iteration 20665 => Loss: 48.40497858948105402987\n",
      "Iteration 20666 => Loss: 48.40479913859655169972\n",
      "Iteration 20667 => Loss: 48.40461968912035928270\n",
      "Iteration 20668 => Loss: 48.40444024105247677880\n",
      "Iteration 20669 => Loss: 48.40426079439290418804\n",
      "Iteration 20670 => Loss: 48.40408134914159887785\n",
      "Iteration 20671 => Loss: 48.40390190529857505908\n",
      "Iteration 20672 => Loss: 48.40372246286382562630\n",
      "Iteration 20673 => Loss: 48.40354302183733636866\n",
      "Iteration 20674 => Loss: 48.40336358221907886445\n",
      "Iteration 20675 => Loss: 48.40318414400904600825\n",
      "Iteration 20676 => Loss: 48.40300470720725201090\n",
      "Iteration 20677 => Loss: 48.40282527181367555613\n",
      "Iteration 20678 => Loss: 48.40264583782828111680\n",
      "Iteration 20679 => Loss: 48.40246640525107579833\n",
      "Iteration 20680 => Loss: 48.40228697408204538988\n",
      "Iteration 20681 => Loss: 48.40210754432119699686\n",
      "Iteration 20682 => Loss: 48.40192811596848798672\n",
      "Iteration 20683 => Loss: 48.40174868902391835945\n",
      "Iteration 20684 => Loss: 48.40156926348750943134\n",
      "Iteration 20685 => Loss: 48.40138983935919725354\n",
      "Iteration 20686 => Loss: 48.40121041663901024776\n",
      "Iteration 20687 => Loss: 48.40103099532693420315\n",
      "Iteration 20688 => Loss: 48.40085157542294069799\n",
      "Iteration 20689 => Loss: 48.40067215692699420515\n",
      "Iteration 20690 => Loss: 48.40049273983913025177\n",
      "Iteration 20691 => Loss: 48.40031332415934173241\n",
      "Iteration 20692 => Loss: 48.40013390988757890909\n",
      "Iteration 20693 => Loss: 48.39995449702386309809\n",
      "Iteration 20694 => Loss: 48.39977508556815166685\n",
      "Iteration 20695 => Loss: 48.39959567552047303707\n",
      "Iteration 20696 => Loss: 48.39941626688079168161\n",
      "Iteration 20697 => Loss: 48.39923685964908628421\n",
      "Iteration 20698 => Loss: 48.39905745382536395027\n",
      "Iteration 20699 => Loss: 48.39887804940960336353\n",
      "Iteration 20700 => Loss: 48.39869864640181162940\n",
      "Iteration 20701 => Loss: 48.39851924480196032619\n",
      "Iteration 20702 => Loss: 48.39833984461004945388\n",
      "Iteration 20703 => Loss: 48.39816044582605769619\n",
      "Iteration 20704 => Loss: 48.39798104844996373686\n",
      "Iteration 20705 => Loss: 48.39780165248178178672\n",
      "Iteration 20706 => Loss: 48.39762225792150474035\n",
      "Iteration 20707 => Loss: 48.39744286476911128148\n",
      "Iteration 20708 => Loss: 48.39726347302454456667\n",
      "Iteration 20709 => Loss: 48.39708408268785433393\n",
      "Iteration 20710 => Loss: 48.39690469375902637239\n",
      "Iteration 20711 => Loss: 48.39672530623803936578\n",
      "Iteration 20712 => Loss: 48.39654592012484357610\n",
      "Iteration 20713 => Loss: 48.39636653541946031964\n",
      "Iteration 20714 => Loss: 48.39618715212188959640\n",
      "Iteration 20715 => Loss: 48.39600777023213851180\n",
      "Iteration 20716 => Loss: 48.39582838975014311700\n",
      "Iteration 20717 => Loss: 48.39564901067590341199\n",
      "Iteration 20718 => Loss: 48.39546963300943360764\n",
      "Iteration 20719 => Loss: 48.39529025675070528223\n",
      "Iteration 20720 => Loss: 48.39511088189972554119\n",
      "Iteration 20721 => Loss: 48.39493150845644464653\n",
      "Iteration 20722 => Loss: 48.39475213642091233623\n",
      "Iteration 20723 => Loss: 48.39457276579305045061\n",
      "Iteration 20724 => Loss: 48.39439339657288741137\n",
      "Iteration 20725 => Loss: 48.39421402876042321850\n",
      "Iteration 20726 => Loss: 48.39403466235560813402\n",
      "Iteration 20727 => Loss: 48.39385529735847057964\n",
      "Iteration 20728 => Loss: 48.39367593376896792279\n",
      "Iteration 20729 => Loss: 48.39349657158709305804\n",
      "Iteration 20730 => Loss: 48.39331721081286019626\n",
      "Iteration 20731 => Loss: 48.39313785144623381029\n",
      "Iteration 20732 => Loss: 48.39295849348719968930\n",
      "Iteration 20733 => Loss: 48.39277913693575072784\n",
      "Iteration 20734 => Loss: 48.39259978179190824221\n",
      "Iteration 20735 => Loss: 48.39242042805563670527\n",
      "Iteration 20736 => Loss: 48.39224107572690769530\n",
      "Iteration 20737 => Loss: 48.39206172480574252859\n",
      "Iteration 20738 => Loss: 48.39188237529208436172\n",
      "Iteration 20739 => Loss: 48.39170302718597582725\n",
      "Iteration 20740 => Loss: 48.39152368048737429262\n",
      "Iteration 20741 => Loss: 48.39134433519627975784\n",
      "Iteration 20742 => Loss: 48.39116499131266380118\n",
      "Iteration 20743 => Loss: 48.39098564883654773894\n",
      "Iteration 20744 => Loss: 48.39080630776790314940\n",
      "Iteration 20745 => Loss: 48.39062696810671582170\n",
      "Iteration 20746 => Loss: 48.39044762985296443958\n",
      "Iteration 20747 => Loss: 48.39026829300666321387\n",
      "Iteration 20748 => Loss: 48.39008895756777661745\n",
      "Iteration 20749 => Loss: 48.38990962353630465032\n",
      "Iteration 20750 => Loss: 48.38973029091225441789\n",
      "Iteration 20751 => Loss: 48.38955095969557618218\n",
      "Iteration 20752 => Loss: 48.38937162988628415405\n",
      "Iteration 20753 => Loss: 48.38919230148437833350\n",
      "Iteration 20754 => Loss: 48.38901297448980898253\n",
      "Iteration 20755 => Loss: 48.38883364890260452285\n",
      "Iteration 20756 => Loss: 48.38865432472273653275\n",
      "Iteration 20757 => Loss: 48.38847500195019790681\n",
      "Iteration 20758 => Loss: 48.38829568058494601246\n",
      "Iteration 20759 => Loss: 48.38811636062705190398\n",
      "Iteration 20760 => Loss: 48.38793704207640899995\n",
      "Iteration 20761 => Loss: 48.38775772493305993294\n",
      "Iteration 20762 => Loss: 48.38757840919699759752\n",
      "Iteration 20763 => Loss: 48.38739909486817936113\n",
      "Iteration 20764 => Loss: 48.38721978194661943462\n",
      "Iteration 20765 => Loss: 48.38704047043229650171\n",
      "Iteration 20766 => Loss: 48.38686116032518214070\n",
      "Iteration 20767 => Loss: 48.38668185162528345700\n",
      "Iteration 20768 => Loss: 48.38650254433262887233\n",
      "Iteration 20769 => Loss: 48.38632323844714022698\n",
      "Iteration 20770 => Loss: 48.38614393396883883725\n",
      "Iteration 20771 => Loss: 48.38596463089768917598\n",
      "Iteration 20772 => Loss: 48.38578532923373387575\n",
      "Iteration 20773 => Loss: 48.38560602897691609314\n",
      "Iteration 20774 => Loss: 48.38542673012724293358\n",
      "Iteration 20775 => Loss: 48.38524743268468597535\n",
      "Iteration 20776 => Loss: 48.38506813664924521845\n",
      "Iteration 20777 => Loss: 48.38488884202092066289\n",
      "Iteration 20778 => Loss: 48.38470954879968388695\n",
      "Iteration 20779 => Loss: 48.38453025698554199607\n",
      "Iteration 20780 => Loss: 48.38435096657846656854\n",
      "Iteration 20781 => Loss: 48.38417167757843628806\n",
      "Iteration 20782 => Loss: 48.38399238998550089264\n",
      "Iteration 20783 => Loss: 48.38381310379956090628\n",
      "Iteration 20784 => Loss: 48.38363381902065185614\n",
      "Iteration 20785 => Loss: 48.38345453564877374220\n",
      "Iteration 20786 => Loss: 48.38327525368391235361\n",
      "Iteration 20787 => Loss: 48.38309597312603926866\n",
      "Iteration 20788 => Loss: 48.38291669397514738193\n",
      "Iteration 20789 => Loss: 48.38273741623122248257\n",
      "Iteration 20790 => Loss: 48.38255813989425035970\n",
      "Iteration 20791 => Loss: 48.38237886496425232963\n",
      "Iteration 20792 => Loss: 48.38219959144119286520\n",
      "Iteration 20793 => Loss: 48.38202031932504354472\n",
      "Iteration 20794 => Loss: 48.38184104861581147361\n",
      "Iteration 20795 => Loss: 48.38166177931352507358\n",
      "Iteration 20796 => Loss: 48.38148251141810618492\n",
      "Iteration 20797 => Loss: 48.38130324492957612392\n",
      "Iteration 20798 => Loss: 48.38112397984792067973\n",
      "Iteration 20799 => Loss: 48.38094471617311143063\n",
      "Iteration 20800 => Loss: 48.38076545390517679834\n",
      "Iteration 20801 => Loss: 48.38058619304408125572\n",
      "Iteration 20802 => Loss: 48.38040693358981769734\n",
      "Iteration 20803 => Loss: 48.38022767554235059606\n",
      "Iteration 20804 => Loss: 48.38004841890171547902\n",
      "Iteration 20805 => Loss: 48.37986916366784839738\n",
      "Iteration 20806 => Loss: 48.37968990984080619455\n",
      "Iteration 20807 => Loss: 48.37951065742053202712\n",
      "Iteration 20808 => Loss: 48.37933140640699036794\n",
      "Iteration 20809 => Loss: 48.37915215680023095501\n",
      "Iteration 20810 => Loss: 48.37897290860020405034\n",
      "Iteration 20811 => Loss: 48.37879366180688833765\n",
      "Iteration 20812 => Loss: 48.37861441642030513322\n",
      "Iteration 20813 => Loss: 48.37843517244044733161\n",
      "Iteration 20814 => Loss: 48.37825592986725098399\n",
      "Iteration 20815 => Loss: 48.37807668870077293377\n",
      "Iteration 20816 => Loss: 48.37789744894096344296\n",
      "Iteration 20817 => Loss: 48.37771821058780119529\n",
      "Iteration 20818 => Loss: 48.37753897364132882331\n",
      "Iteration 20819 => Loss: 48.37735973810146106189\n",
      "Iteration 20820 => Loss: 48.37718050396824054360\n",
      "Iteration 20821 => Loss: 48.37700127124163884673\n",
      "Iteration 20822 => Loss: 48.37682203992164176043\n",
      "Iteration 20823 => Loss: 48.37664281000824928469\n",
      "Iteration 20824 => Loss: 48.37646358150144720867\n",
      "Iteration 20825 => Loss: 48.37628435440119289979\n",
      "Iteration 20826 => Loss: 48.37610512870753609604\n",
      "Iteration 20827 => Loss: 48.37592590442042705945\n",
      "Iteration 20828 => Loss: 48.37574668153984447372\n",
      "Iteration 20829 => Loss: 48.37556746006580254971\n",
      "Iteration 20830 => Loss: 48.37538823999827997113\n",
      "Iteration 20831 => Loss: 48.37520902133728384342\n",
      "Iteration 20832 => Loss: 48.37502980408277863944\n",
      "Iteration 20833 => Loss: 48.37485058823475014833\n",
      "Iteration 20834 => Loss: 48.37467137379321258095\n",
      "Iteration 20835 => Loss: 48.37449216075810909388\n",
      "Iteration 20836 => Loss: 48.37431294912948231968\n",
      "Iteration 20837 => Loss: 48.37413373890731094207\n",
      "Iteration 20838 => Loss: 48.37395453009155232849\n",
      "Iteration 20839 => Loss: 48.37377532268222068979\n",
      "Iteration 20840 => Loss: 48.37359611667928760426\n",
      "Iteration 20841 => Loss: 48.37341691208279570446\n",
      "Iteration 20842 => Loss: 48.37323770889266683071\n",
      "Iteration 20843 => Loss: 48.37305850710889387756\n",
      "Iteration 20844 => Loss: 48.37287930673152658301\n",
      "Iteration 20845 => Loss: 48.37270010776048678736\n",
      "Iteration 20846 => Loss: 48.37252091019578159603\n",
      "Iteration 20847 => Loss: 48.37234171403743232531\n",
      "Iteration 20848 => Loss: 48.37216251928538213178\n",
      "Iteration 20849 => Loss: 48.37198332593967364801\n",
      "Iteration 20850 => Loss: 48.37180413400024292514\n",
      "Iteration 20851 => Loss: 48.37162494346712549032\n",
      "Iteration 20852 => Loss: 48.37144575434026450012\n",
      "Iteration 20853 => Loss: 48.37126656661967416539\n",
      "Iteration 20854 => Loss: 48.37108738030533316987\n",
      "Iteration 20855 => Loss: 48.37090819539724861897\n",
      "Iteration 20856 => Loss: 48.37072901189539209099\n",
      "Iteration 20857 => Loss: 48.37054982979973516422\n",
      "Iteration 20858 => Loss: 48.37037064911033468206\n",
      "Iteration 20859 => Loss: 48.37019146982711248484\n",
      "Iteration 20860 => Loss: 48.37001229195008988881\n",
      "Iteration 20861 => Loss: 48.36983311547923847229\n",
      "Iteration 20862 => Loss: 48.36965394041455823526\n",
      "Iteration 20863 => Loss: 48.36947476675601365059\n",
      "Iteration 20864 => Loss: 48.36929559450365445628\n",
      "Iteration 20865 => Loss: 48.36911642365738117633\n",
      "Iteration 20866 => Loss: 48.36893725421725775959\n",
      "Iteration 20867 => Loss: 48.36875808618324867894\n",
      "Iteration 20868 => Loss: 48.36857891955533972350\n",
      "Iteration 20869 => Loss: 48.36839975433351668244\n",
      "Iteration 20870 => Loss: 48.36822059051777245031\n",
      "Iteration 20871 => Loss: 48.36804142810809992170\n",
      "Iteration 20872 => Loss: 48.36786226710447778032\n",
      "Iteration 20873 => Loss: 48.36768310750691313160\n",
      "Iteration 20874 => Loss: 48.36750394931536334298\n",
      "Iteration 20875 => Loss: 48.36732479252987815244\n",
      "Iteration 20876 => Loss: 48.36714563715037229485\n",
      "Iteration 20877 => Loss: 48.36696648317686708651\n",
      "Iteration 20878 => Loss: 48.36678733060936252741\n",
      "Iteration 20879 => Loss: 48.36660817944783730127\n",
      "Iteration 20880 => Loss: 48.36642902969228430266\n",
      "Iteration 20881 => Loss: 48.36624988134268221529\n",
      "Iteration 20882 => Loss: 48.36607073439903814460\n",
      "Iteration 20883 => Loss: 48.36589158886130235260\n",
      "Iteration 20884 => Loss: 48.36571244472952457727\n",
      "Iteration 20885 => Loss: 48.36553330200362665892\n",
      "Iteration 20886 => Loss: 48.36535416068367254638\n",
      "Iteration 20887 => Loss: 48.36517502076956986912\n",
      "Iteration 20888 => Loss: 48.36499588226138257596\n",
      "Iteration 20889 => Loss: 48.36481674515903961264\n",
      "Iteration 20890 => Loss: 48.36463760946255519002\n",
      "Iteration 20891 => Loss: 48.36445847517195062437\n",
      "Iteration 20892 => Loss: 48.36427934228714775600\n",
      "Iteration 20893 => Loss: 48.36410021080818921746\n",
      "Iteration 20894 => Loss: 48.36392108073503948162\n",
      "Iteration 20895 => Loss: 48.36374195206768433764\n",
      "Iteration 20896 => Loss: 48.36356282480614510177\n",
      "Iteration 20897 => Loss: 48.36338369895036493062\n",
      "Iteration 20898 => Loss: 48.36320457450035803504\n",
      "Iteration 20899 => Loss: 48.36302545145611020416\n",
      "Iteration 20900 => Loss: 48.36284632981761433257\n",
      "Iteration 20901 => Loss: 48.36266720958485620940\n",
      "Iteration 20902 => Loss: 48.36248809075783583467\n",
      "Iteration 20903 => Loss: 48.36230897333649636494\n",
      "Iteration 20904 => Loss: 48.36212985732088753821\n",
      "Iteration 20905 => Loss: 48.36195074271096672192\n",
      "Iteration 20906 => Loss: 48.36177162950672681063\n",
      "Iteration 20907 => Loss: 48.36159251770817490979\n",
      "Iteration 20908 => Loss: 48.36141340731525417596\n",
      "Iteration 20909 => Loss: 48.36123429832800013628\n",
      "Iteration 20910 => Loss: 48.36105519074637726362\n",
      "Iteration 20911 => Loss: 48.36087608457038555798\n",
      "Iteration 20912 => Loss: 48.36069697980001791393\n",
      "Iteration 20913 => Loss: 48.36051787643522459348\n",
      "Iteration 20914 => Loss: 48.36033877447604112376\n",
      "Iteration 20915 => Loss: 48.36015967392246039935\n",
      "Iteration 20916 => Loss: 48.35998057477441847141\n",
      "Iteration 20917 => Loss: 48.35980147703195797249\n",
      "Iteration 20918 => Loss: 48.35962238069505758631\n",
      "Iteration 20919 => Loss: 48.35944328576368178574\n",
      "Iteration 20920 => Loss: 48.35926419223782346535\n",
      "Iteration 20921 => Loss: 48.35908510011748262514\n",
      "Iteration 20922 => Loss: 48.35890600940267347596\n",
      "Iteration 20923 => Loss: 48.35872692009332496355\n",
      "Iteration 20924 => Loss: 48.35854783218948682588\n",
      "Iteration 20925 => Loss: 48.35836874569110932498\n",
      "Iteration 20926 => Loss: 48.35818966059817824998\n",
      "Iteration 20927 => Loss: 48.35801057691072202260\n",
      "Iteration 20928 => Loss: 48.35783149462869801027\n",
      "Iteration 20929 => Loss: 48.35765241375209200214\n",
      "Iteration 20930 => Loss: 48.35747333428093241992\n",
      "Iteration 20931 => Loss: 48.35729425621515531475\n",
      "Iteration 20932 => Loss: 48.35711517955476779207\n",
      "Iteration 20933 => Loss: 48.35693610429977695730\n",
      "Iteration 20934 => Loss: 48.35675703045016149417\n",
      "Iteration 20935 => Loss: 48.35657795800590719182\n",
      "Iteration 20936 => Loss: 48.35639888696698562853\n",
      "Iteration 20937 => Loss: 48.35621981733342522602\n",
      "Iteration 20938 => Loss: 48.35604074910518335173\n",
      "Iteration 20939 => Loss: 48.35586168228226711108\n",
      "Iteration 20940 => Loss: 48.35568261686464097693\n",
      "Iteration 20941 => Loss: 48.35550355285232626557\n",
      "Iteration 20942 => Loss: 48.35532449024530876613\n",
      "Iteration 20943 => Loss: 48.35514542904355295150\n",
      "Iteration 20944 => Loss: 48.35496636924705171623\n",
      "Iteration 20945 => Loss: 48.35478731085581216576\n",
      "Iteration 20946 => Loss: 48.35460825386980587837\n",
      "Iteration 20947 => Loss: 48.35442919828903285406\n",
      "Iteration 20948 => Loss: 48.35425014411346467114\n",
      "Iteration 20949 => Loss: 48.35407109134312975129\n",
      "Iteration 20950 => Loss: 48.35389203997797125112\n",
      "Iteration 20951 => Loss: 48.35371299001801759232\n",
      "Iteration 20952 => Loss: 48.35353394146322614233\n",
      "Iteration 20953 => Loss: 48.35335489431360400658\n",
      "Iteration 20954 => Loss: 48.35317584856912986879\n",
      "Iteration 20955 => Loss: 48.35299680422978241268\n",
      "Iteration 20956 => Loss: 48.35281776129558295452\n",
      "Iteration 20957 => Loss: 48.35263871976651017803\n",
      "Iteration 20958 => Loss: 48.35245967964251434523\n",
      "Iteration 20959 => Loss: 48.35228064092365229953\n",
      "Iteration 20960 => Loss: 48.35210160360984588124\n",
      "Iteration 20961 => Loss: 48.35192256770115193376\n",
      "Iteration 20962 => Loss: 48.35174353319751361369\n",
      "Iteration 20963 => Loss: 48.35156450009891671016\n",
      "Iteration 20964 => Loss: 48.35138546840534701232\n",
      "Iteration 20965 => Loss: 48.35120643811681873103\n",
      "Iteration 20966 => Loss: 48.35102740923333186629\n",
      "Iteration 20967 => Loss: 48.35084838175484378553\n",
      "Iteration 20968 => Loss: 48.35066935568133317247\n",
      "Iteration 20969 => Loss: 48.35049033101282844882\n",
      "Iteration 20970 => Loss: 48.35031130774928698202\n",
      "Iteration 20971 => Loss: 48.35013228589073719377\n",
      "Iteration 20972 => Loss: 48.34995326543712224066\n",
      "Iteration 20973 => Loss: 48.34977424638844922811\n",
      "Iteration 20974 => Loss: 48.34959522874472526155\n",
      "Iteration 20975 => Loss: 48.34941621250590060299\n",
      "Iteration 20976 => Loss: 48.34923719767198235786\n",
      "Iteration 20977 => Loss: 48.34905818424299184244\n",
      "Iteration 20978 => Loss: 48.34887917221886510788\n",
      "Iteration 20979 => Loss: 48.34870016159963057589\n",
      "Iteration 20980 => Loss: 48.34852115238523850849\n",
      "Iteration 20981 => Loss: 48.34834214457571022194\n",
      "Iteration 20982 => Loss: 48.34816313817103861084\n",
      "Iteration 20983 => Loss: 48.34798413317120946431\n",
      "Iteration 20984 => Loss: 48.34780512957618014980\n",
      "Iteration 20985 => Loss: 48.34762612738597908901\n",
      "Iteration 20986 => Loss: 48.34744712660056364939\n",
      "Iteration 20987 => Loss: 48.34726812721992672550\n",
      "Iteration 20988 => Loss: 48.34708912924408252820\n",
      "Iteration 20989 => Loss: 48.34691013267300263578\n",
      "Iteration 20990 => Loss: 48.34673113750669415367\n",
      "Iteration 20991 => Loss: 48.34655214374508602759\n",
      "Iteration 20992 => Loss: 48.34637315138824220639\n",
      "Iteration 20993 => Loss: 48.34619416043614137379\n",
      "Iteration 20994 => Loss: 48.34601517088871958094\n",
      "Iteration 20995 => Loss: 48.34583618274600524956\n",
      "Iteration 20996 => Loss: 48.34565719600797706335\n",
      "Iteration 20997 => Loss: 48.34547821067464923317\n",
      "Iteration 20998 => Loss: 48.34529922674597202104\n",
      "Iteration 20999 => Loss: 48.34512024422193832152\n",
      "Iteration 21000 => Loss: 48.34494126310256945089\n",
      "Iteration 21001 => Loss: 48.34476228338781567118\n",
      "Iteration 21002 => Loss: 48.34458330507773382578\n",
      "Iteration 21003 => Loss: 48.34440432817221022788\n",
      "Iteration 21004 => Loss: 48.34422535267131593173\n",
      "Iteration 21005 => Loss: 48.34404637857500119935\n",
      "Iteration 21006 => Loss: 48.34386740588328734702\n",
      "Iteration 21007 => Loss: 48.34368843459611042590\n",
      "Iteration 21008 => Loss: 48.34350946471349885769\n",
      "Iteration 21009 => Loss: 48.34333049623543843154\n",
      "Iteration 21010 => Loss: 48.34315152916191493659\n",
      "Iteration 21011 => Loss: 48.34297256349291416200\n",
      "Iteration 21012 => Loss: 48.34279359922842189690\n",
      "Iteration 21013 => Loss: 48.34261463636844524672\n",
      "Iteration 21014 => Loss: 48.34243567491292736804\n",
      "Iteration 21015 => Loss: 48.34225671486192510429\n",
      "Iteration 21016 => Loss: 48.34207775621537450661\n",
      "Iteration 21017 => Loss: 48.34189879897328978586\n",
      "Iteration 21018 => Loss: 48.34171984313564962576\n",
      "Iteration 21019 => Loss: 48.34154088870245402632\n",
      "Iteration 21020 => Loss: 48.34136193567367456581\n",
      "Iteration 21021 => Loss: 48.34118298404932545509\n",
      "Iteration 21022 => Loss: 48.34100403382933563989\n",
      "Iteration 21023 => Loss: 48.34082508501376906906\n",
      "Iteration 21024 => Loss: 48.34064613760259021547\n",
      "Iteration 21025 => Loss: 48.34046719159574223568\n",
      "Iteration 21026 => Loss: 48.34028824699328907855\n",
      "Iteration 21027 => Loss: 48.34010930379518100608\n",
      "Iteration 21028 => Loss: 48.33993036200140380743\n",
      "Iteration 21029 => Loss: 48.33975142161195037716\n",
      "Iteration 21030 => Loss: 48.33957248262680650441\n",
      "Iteration 21031 => Loss: 48.33939354504597929463\n",
      "Iteration 21032 => Loss: 48.33921460886944032609\n",
      "Iteration 21033 => Loss: 48.33903567409718959880\n",
      "Iteration 21034 => Loss: 48.33885674072919158561\n",
      "Iteration 21035 => Loss: 48.33867780876547470825\n",
      "Iteration 21036 => Loss: 48.33849887820599633415\n",
      "Iteration 21037 => Loss: 48.33831994905074935787\n",
      "Iteration 21038 => Loss: 48.33814102129972667399\n",
      "Iteration 21039 => Loss: 48.33796209495292117708\n",
      "Iteration 21040 => Loss: 48.33778317001035418343\n",
      "Iteration 21041 => Loss: 48.33760424647193332248\n",
      "Iteration 21042 => Loss: 48.33742532433771543765\n",
      "Iteration 21043 => Loss: 48.33724640360765079095\n",
      "Iteration 21044 => Loss: 48.33706748428177490950\n",
      "Iteration 21045 => Loss: 48.33688856636005937162\n",
      "Iteration 21046 => Loss: 48.33670964984244733387\n",
      "Iteration 21047 => Loss: 48.33653073472896721796\n",
      "Iteration 21048 => Loss: 48.33635182101961191847\n",
      "Iteration 21049 => Loss: 48.33617290871436722455\n",
      "Iteration 21050 => Loss: 48.33599399781321181990\n",
      "Iteration 21051 => Loss: 48.33581508831613859911\n",
      "Iteration 21052 => Loss: 48.33563618022314045675\n",
      "Iteration 21053 => Loss: 48.33545727353419607653\n",
      "Iteration 21054 => Loss: 48.33527836824931256388\n",
      "Iteration 21055 => Loss: 48.33509946436845439166\n",
      "Iteration 21056 => Loss: 48.33492056189164287616\n",
      "Iteration 21057 => Loss: 48.33474166081883538482\n",
      "Iteration 21058 => Loss: 48.33456276115004612848\n",
      "Iteration 21059 => Loss: 48.33438386288523247458\n",
      "Iteration 21060 => Loss: 48.33420496602440863398\n",
      "Iteration 21061 => Loss: 48.33402607056757460668\n",
      "Iteration 21062 => Loss: 48.33384717651468776012\n",
      "Iteration 21063 => Loss: 48.33366828386576941057\n",
      "Iteration 21064 => Loss: 48.33348939262076982004\n",
      "Iteration 21065 => Loss: 48.33331050277971030482\n",
      "Iteration 21066 => Loss: 48.33313161434256244320\n",
      "Iteration 21067 => Loss: 48.33295272730933334060\n",
      "Iteration 21068 => Loss: 48.33277384167997325903\n",
      "Iteration 21069 => Loss: 48.33259495745452483106\n",
      "Iteration 21070 => Loss: 48.33241607463294542413\n",
      "Iteration 21071 => Loss: 48.33223719321521372194\n",
      "Iteration 21072 => Loss: 48.33205831320135814622\n",
      "Iteration 21073 => Loss: 48.33187943459131474810\n",
      "Iteration 21074 => Loss: 48.33170055738511905474\n",
      "Iteration 21075 => Loss: 48.33152168158274974985\n",
      "Iteration 21076 => Loss: 48.33134280718417841172\n",
      "Iteration 21077 => Loss: 48.33116393418940504034\n",
      "Iteration 21078 => Loss: 48.33098506259841542487\n",
      "Iteration 21079 => Loss: 48.33080619241120245988\n",
      "Iteration 21080 => Loss: 48.33062732362775193451\n",
      "Iteration 21081 => Loss: 48.33044845624806384876\n",
      "Iteration 21082 => Loss: 48.33026959027211688635\n",
      "Iteration 21083 => Loss: 48.33009072569988973100\n",
      "Iteration 21084 => Loss: 48.32991186253138238271\n",
      "Iteration 21085 => Loss: 48.32973300076656641977\n",
      "Iteration 21086 => Loss: 48.32955414040549868560\n",
      "Iteration 21087 => Loss: 48.32937528144807970421\n",
      "Iteration 21088 => Loss: 48.32919642389433789731\n",
      "Iteration 21089 => Loss: 48.32901756774426615948\n",
      "Iteration 21090 => Loss: 48.32883871299785738529\n",
      "Iteration 21091 => Loss: 48.32865985965507604760\n",
      "Iteration 21092 => Loss: 48.32848100771593635727\n",
      "Iteration 21093 => Loss: 48.32830215718042410344\n",
      "Iteration 21094 => Loss: 48.32812330804849665356\n",
      "Iteration 21095 => Loss: 48.32794446032019664017\n",
      "Iteration 21096 => Loss: 48.32776561399547432529\n",
      "Iteration 21097 => Loss: 48.32758676907431549807\n",
      "Iteration 21098 => Loss: 48.32740792555672726394\n",
      "Iteration 21099 => Loss: 48.32722908344269541203\n",
      "Iteration 21100 => Loss: 48.32705024273221994235\n",
      "Iteration 21101 => Loss: 48.32687140342525822234\n",
      "Iteration 21102 => Loss: 48.32669256552182446285\n",
      "Iteration 21103 => Loss: 48.32651372902189024217\n",
      "Iteration 21104 => Loss: 48.32633489392546977115\n",
      "Iteration 21105 => Loss: 48.32615606023254883894\n",
      "Iteration 21106 => Loss: 48.32597722794307770755\n",
      "Iteration 21107 => Loss: 48.32579839705709900954\n",
      "Iteration 21108 => Loss: 48.32561956757456300693\n",
      "Iteration 21109 => Loss: 48.32544073949547680513\n",
      "Iteration 21110 => Loss: 48.32526191281980487702\n",
      "Iteration 21111 => Loss: 48.32508308754758274972\n",
      "Iteration 21112 => Loss: 48.32490426367876068525\n",
      "Iteration 21113 => Loss: 48.32472544121333868361\n",
      "Iteration 21114 => Loss: 48.32454662015130253394\n",
      "Iteration 21115 => Loss: 48.32436780049265223624\n",
      "Iteration 21116 => Loss: 48.32418898223734515796\n",
      "Iteration 21117 => Loss: 48.32401016538540972078\n",
      "Iteration 21118 => Loss: 48.32383134993682460845\n",
      "Iteration 21119 => Loss: 48.32365253589157561009\n",
      "Iteration 21120 => Loss: 48.32347372324964140944\n",
      "Iteration 21121 => Loss: 48.32329491201103621734\n",
      "Iteration 21122 => Loss: 48.32311610217573871751\n",
      "Iteration 21123 => Loss: 48.32293729374369206653\n",
      "Iteration 21124 => Loss: 48.32275848671494600239\n",
      "Iteration 21125 => Loss: 48.32257968108946499797\n",
      "Iteration 21126 => Loss: 48.32240087686723484239\n",
      "Iteration 21127 => Loss: 48.32222207404826264110\n",
      "Iteration 21128 => Loss: 48.32204327263252707780\n",
      "Iteration 21129 => Loss: 48.32186447262000683622\n",
      "Iteration 21130 => Loss: 48.32168567401070191636\n",
      "Iteration 21131 => Loss: 48.32150687680461942364\n",
      "Iteration 21132 => Loss: 48.32132808100170251464\n",
      "Iteration 21133 => Loss: 48.32114928660197250565\n",
      "Iteration 21134 => Loss: 48.32097049360539386953\n",
      "Iteration 21135 => Loss: 48.32079170201200923884\n",
      "Iteration 21136 => Loss: 48.32061291182174045389\n",
      "Iteration 21137 => Loss: 48.32043412303463014723\n",
      "Iteration 21138 => Loss: 48.32025533565062147545\n",
      "Iteration 21139 => Loss: 48.32007654966974996569\n",
      "Iteration 21140 => Loss: 48.31989776509197298537\n",
      "Iteration 21141 => Loss: 48.31971898191728342908\n",
      "Iteration 21142 => Loss: 48.31954020014568129682\n",
      "Iteration 21143 => Loss: 48.31936141977714527229\n",
      "Iteration 21144 => Loss: 48.31918264081168246094\n",
      "Iteration 21145 => Loss: 48.31900386324924312476\n",
      "Iteration 21146 => Loss: 48.31882508708984858004\n",
      "Iteration 21147 => Loss: 48.31864631233349882677\n",
      "Iteration 21148 => Loss: 48.31846753898012991613\n",
      "Iteration 21149 => Loss: 48.31828876702978448066\n",
      "Iteration 21150 => Loss: 48.31810999648241278237\n",
      "Iteration 21151 => Loss: 48.31793122733807166469\n",
      "Iteration 21152 => Loss: 48.31775245959664744078\n",
      "Iteration 21153 => Loss: 48.31757369325821827033\n",
      "Iteration 21154 => Loss: 48.31739492832272730993\n",
      "Iteration 21155 => Loss: 48.31721616479016745416\n",
      "Iteration 21156 => Loss: 48.31703740266055291386\n",
      "Iteration 21157 => Loss: 48.31685864193382684562\n",
      "Iteration 21158 => Loss: 48.31667988261003188200\n",
      "Iteration 21159 => Loss: 48.31650112468909696872\n",
      "Iteration 21160 => Loss: 48.31632236817107184379\n",
      "Iteration 21161 => Loss: 48.31614361305592808549\n",
      "Iteration 21162 => Loss: 48.31596485934361595582\n",
      "Iteration 21163 => Loss: 48.31578610703417098193\n",
      "Iteration 21164 => Loss: 48.31560735612755763668\n",
      "Iteration 21165 => Loss: 48.31542860662376881464\n",
      "Iteration 21166 => Loss: 48.31524985852280451581\n",
      "Iteration 21167 => Loss: 48.31507111182463631849\n",
      "Iteration 21168 => Loss: 48.31489236652928553895\n",
      "Iteration 21169 => Loss: 48.31471362263669533377\n",
      "Iteration 21170 => Loss: 48.31453488014688701924\n",
      "Iteration 21171 => Loss: 48.31435613905983927907\n",
      "Iteration 21172 => Loss: 48.31417739937555211327\n",
      "Iteration 21173 => Loss: 48.31399866109398999470\n",
      "Iteration 21174 => Loss: 48.31381992421516002878\n",
      "Iteration 21175 => Loss: 48.31364118873904089924\n",
      "Iteration 21176 => Loss: 48.31346245466564681692\n",
      "Iteration 21177 => Loss: 48.31328372199494936012\n",
      "Iteration 21178 => Loss: 48.31310499072689879085\n",
      "Iteration 21179 => Loss: 48.31292626086155195253\n",
      "Iteration 21180 => Loss: 48.31274753239886621259\n",
      "Iteration 21181 => Loss: 48.31256880533882736017\n",
      "Iteration 21182 => Loss: 48.31239007968144250071\n",
      "Iteration 21183 => Loss: 48.31221135542665479079\n",
      "Iteration 21184 => Loss: 48.31203263257452107382\n",
      "Iteration 21185 => Loss: 48.31185391112497029553\n",
      "Iteration 21186 => Loss: 48.31167519107803087763\n",
      "Iteration 21187 => Loss: 48.31149647243368150384\n",
      "Iteration 21188 => Loss: 48.31131775519188664703\n",
      "Iteration 21189 => Loss: 48.31113903935265341261\n",
      "Iteration 21190 => Loss: 48.31096032491599601144\n",
      "Iteration 21191 => Loss: 48.31078161188187181097\n",
      "Iteration 21192 => Loss: 48.31060290025027370575\n",
      "Iteration 21193 => Loss: 48.31042419002120880123\n",
      "Iteration 21194 => Loss: 48.31024548119462735940\n",
      "Iteration 21195 => Loss: 48.31006677377055780198\n",
      "Iteration 21196 => Loss: 48.30988806774897170726\n",
      "Iteration 21197 => Loss: 48.30970936312987618066\n",
      "Iteration 21198 => Loss: 48.30953065991321437878\n",
      "Iteration 21199 => Loss: 48.30935195809904314501\n",
      "Iteration 21200 => Loss: 48.30917325768727010882\n",
      "Iteration 21201 => Loss: 48.30899455867798053532\n",
      "Iteration 21202 => Loss: 48.30881586107107494854\n",
      "Iteration 21203 => Loss: 48.30863716486660308647\n",
      "Iteration 21204 => Loss: 48.30845847006449389482\n",
      "Iteration 21205 => Loss: 48.30827977666480421703\n",
      "Iteration 21206 => Loss: 48.30810108466748431510\n",
      "Iteration 21207 => Loss: 48.30792239407251997818\n",
      "Iteration 21208 => Loss: 48.30774370487989699541\n",
      "Iteration 21209 => Loss: 48.30756501708964378849\n",
      "Iteration 21210 => Loss: 48.30738633070171772488\n",
      "Iteration 21211 => Loss: 48.30720764571611169913\n",
      "Iteration 21212 => Loss: 48.30702896213281150040\n",
      "Iteration 21213 => Loss: 48.30685027995181712868\n",
      "Iteration 21214 => Loss: 48.30667159917310016226\n",
      "Iteration 21215 => Loss: 48.30649291979667481201\n",
      "Iteration 21216 => Loss: 48.30631424182249844534\n",
      "Iteration 21217 => Loss: 48.30613556525059237856\n",
      "Iteration 21218 => Loss: 48.30595689008090687366\n",
      "Iteration 21219 => Loss: 48.30577821631347745779\n",
      "Iteration 21220 => Loss: 48.30559954394826860380\n",
      "Iteration 21221 => Loss: 48.30542087298527320627\n",
      "Iteration 21222 => Loss: 48.30524220342446994891\n",
      "Iteration 21223 => Loss: 48.30506353526585883174\n",
      "Iteration 21224 => Loss: 48.30488486850943985473\n",
      "Iteration 21225 => Loss: 48.30470620315516327992\n",
      "Iteration 21226 => Loss: 48.30452753920305752899\n",
      "Iteration 21227 => Loss: 48.30434887665310839111\n",
      "Iteration 21228 => Loss: 48.30417021550525902285\n",
      "Iteration 21229 => Loss: 48.30399155575957337305\n",
      "Iteration 21230 => Loss: 48.30381289741595907117\n",
      "Iteration 21231 => Loss: 48.30363424047448006604\n",
      "Iteration 21232 => Loss: 48.30345558493506530340\n",
      "Iteration 21233 => Loss: 48.30327693079773609952\n",
      "Iteration 21234 => Loss: 48.30309827806249245441\n",
      "Iteration 21235 => Loss: 48.30291962672931305178\n",
      "Iteration 21236 => Loss: 48.30274097679814815365\n",
      "Iteration 21237 => Loss: 48.30256232826901907629\n",
      "Iteration 21238 => Loss: 48.30238368114193292513\n",
      "Iteration 21239 => Loss: 48.30220503541686127846\n",
      "Iteration 21240 => Loss: 48.30202639109378282001\n",
      "Iteration 21241 => Loss: 48.30184774817268333891\n",
      "Iteration 21242 => Loss: 48.30166910665359836230\n",
      "Iteration 21243 => Loss: 48.30149046653646394134\n",
      "Iteration 21244 => Loss: 48.30131182782128718145\n",
      "Iteration 21245 => Loss: 48.30113319050804676635\n",
      "Iteration 21246 => Loss: 48.30095455459674980148\n",
      "Iteration 21247 => Loss: 48.30077592008739628682\n",
      "Iteration 21248 => Loss: 48.30059728697993648439\n",
      "Iteration 21249 => Loss: 48.30041865527438460504\n",
      "Iteration 21250 => Loss: 48.30024002497072643791\n",
      "Iteration 21251 => Loss: 48.30006139606894066674\n",
      "Iteration 21252 => Loss: 48.29988276856904860779\n",
      "Iteration 21253 => Loss: 48.29970414247098631222\n",
      "Iteration 21254 => Loss: 48.29952551777478930717\n",
      "Iteration 21255 => Loss: 48.29934689448044338178\n",
      "Iteration 21256 => Loss: 48.29916827258789169264\n",
      "Iteration 21257 => Loss: 48.29898965209717687230\n",
      "Iteration 21258 => Loss: 48.29881103300823497193\n",
      "Iteration 21259 => Loss: 48.29863241532112283494\n",
      "Iteration 21260 => Loss: 48.29845379903578361791\n",
      "Iteration 21261 => Loss: 48.29827518415222442627\n",
      "Iteration 21262 => Loss: 48.29809657067040973288\n",
      "Iteration 21263 => Loss: 48.29791795859034664318\n",
      "Iteration 21264 => Loss: 48.29773934791202094630\n",
      "Iteration 21265 => Loss: 48.29756073863543264224\n",
      "Iteration 21266 => Loss: 48.29738213076055330930\n",
      "Iteration 21267 => Loss: 48.29720352428737584205\n",
      "Iteration 21268 => Loss: 48.29702491921589313506\n",
      "Iteration 21269 => Loss: 48.29684631554609097748\n",
      "Iteration 21270 => Loss: 48.29666771327796936930\n",
      "Iteration 21271 => Loss: 48.29648911241151409968\n",
      "Iteration 21272 => Loss: 48.29631051294669674689\n",
      "Iteration 21273 => Loss: 48.29613191488352441638\n",
      "Iteration 21274 => Loss: 48.29595331822197579186\n",
      "Iteration 21275 => Loss: 48.29577472296203666247\n",
      "Iteration 21276 => Loss: 48.29559612910372123906\n",
      "Iteration 21277 => Loss: 48.29541753664699399451\n",
      "Iteration 21278 => Loss: 48.29523894559186203423\n",
      "Iteration 21279 => Loss: 48.29506035593827562025\n",
      "Iteration 21280 => Loss: 48.29488176768627738511\n",
      "Iteration 21281 => Loss: 48.29470318083582469626\n",
      "Iteration 21282 => Loss: 48.29452459538691044827\n",
      "Iteration 21283 => Loss: 48.29434601133951332486\n",
      "Iteration 21284 => Loss: 48.29416742869364043145\n",
      "Iteration 21285 => Loss: 48.29398884744928466262\n",
      "Iteration 21286 => Loss: 48.29381026760642470208\n",
      "Iteration 21287 => Loss: 48.29363168916504633899\n",
      "Iteration 21288 => Loss: 48.29345311212514246790\n",
      "Iteration 21289 => Loss: 48.29327453648669177255\n",
      "Iteration 21290 => Loss: 48.29309596224970135836\n",
      "Iteration 21291 => Loss: 48.29291738941414280362\n",
      "Iteration 21292 => Loss: 48.29273881798001610832\n",
      "Iteration 21293 => Loss: 48.29256024794732837790\n",
      "Iteration 21294 => Loss: 48.29238167931603697980\n",
      "Iteration 21295 => Loss: 48.29220311208613480858\n",
      "Iteration 21296 => Loss: 48.29202454625765028595\n",
      "Iteration 21297 => Loss: 48.29184598183050525222\n",
      "Iteration 21298 => Loss: 48.29166741880474233994\n",
      "Iteration 21299 => Loss: 48.29148885718031891656\n",
      "Iteration 21300 => Loss: 48.29131029695722787665\n",
      "Iteration 21301 => Loss: 48.29113173813550474733\n",
      "Iteration 21302 => Loss: 48.29095318071508557978\n",
      "Iteration 21303 => Loss: 48.29077462469596326855\n",
      "Iteration 21304 => Loss: 48.29059607007815202451\n",
      "Iteration 21305 => Loss: 48.29041751686162342594\n",
      "Iteration 21306 => Loss: 48.29023896504636326199\n",
      "Iteration 21307 => Loss: 48.29006041463239284894\n",
      "Iteration 21308 => Loss: 48.28988186561964113253\n",
      "Iteration 21309 => Loss: 48.28970331800816495615\n",
      "Iteration 21310 => Loss: 48.28952477179788616013\n",
      "Iteration 21311 => Loss: 48.28934622698886869330\n",
      "Iteration 21312 => Loss: 48.28916768358105571224\n",
      "Iteration 21313 => Loss: 48.28898914157442590067\n",
      "Iteration 21314 => Loss: 48.28881060096898636402\n",
      "Iteration 21315 => Loss: 48.28863206176471578601\n",
      "Iteration 21316 => Loss: 48.28845352396162127206\n",
      "Iteration 21317 => Loss: 48.28827498755968861133\n",
      "Iteration 21318 => Loss: 48.28809645255889648752\n",
      "Iteration 21319 => Loss: 48.28791791895923068978\n",
      "Iteration 21320 => Loss: 48.28773938676069832354\n",
      "Iteration 21321 => Loss: 48.28756085596327096710\n",
      "Iteration 21322 => Loss: 48.28738232656693440958\n",
      "Iteration 21323 => Loss: 48.28720379857171707272\n",
      "Iteration 21324 => Loss: 48.28702527197752658594\n",
      "Iteration 21325 => Loss: 48.28684674678444821438\n",
      "Iteration 21326 => Loss: 48.28666822299241090377\n",
      "Iteration 21327 => Loss: 48.28648970060141465410\n",
      "Iteration 21328 => Loss: 48.28631117961147367623\n",
      "Iteration 21329 => Loss: 48.28613266002254533760\n",
      "Iteration 21330 => Loss: 48.28595414183460832191\n",
      "Iteration 21331 => Loss: 48.28577562504767684004\n",
      "Iteration 21332 => Loss: 48.28559710966177220826\n",
      "Iteration 21333 => Loss: 48.28541859567681626686\n",
      "Iteration 21334 => Loss: 48.28524008309283743756\n",
      "Iteration 21335 => Loss: 48.28506157190980729865\n",
      "Iteration 21336 => Loss: 48.28488306212772585013\n",
      "Iteration 21337 => Loss: 48.28470455374659309200\n",
      "Iteration 21338 => Loss: 48.28452604676637349712\n",
      "Iteration 21339 => Loss: 48.28434754118706706549\n",
      "Iteration 21340 => Loss: 48.28416903700868090255\n",
      "Iteration 21341 => Loss: 48.28399053423115816486\n",
      "Iteration 21342 => Loss: 48.28381203285452727414\n",
      "Iteration 21343 => Loss: 48.28363353287875270325\n",
      "Iteration 21344 => Loss: 48.28345503430387708477\n",
      "Iteration 21345 => Loss: 48.28327653712980804812\n",
      "Iteration 21346 => Loss: 48.28309804135657401503\n",
      "Iteration 21347 => Loss: 48.28291954698420340719\n",
      "Iteration 21348 => Loss: 48.28274105401261095949\n",
      "Iteration 21349 => Loss: 48.28256256244183930448\n",
      "Iteration 21350 => Loss: 48.28238407227186002046\n",
      "Iteration 21351 => Loss: 48.28220558350265179115\n",
      "Iteration 21352 => Loss: 48.28202709613422172197\n",
      "Iteration 21353 => Loss: 48.28184861016655560206\n",
      "Iteration 21354 => Loss: 48.28167012559962500973\n",
      "Iteration 21355 => Loss: 48.28149164243343705039\n",
      "Iteration 21356 => Loss: 48.28131316066799172404\n",
      "Iteration 21357 => Loss: 48.28113468030323929270\n",
      "Iteration 21358 => Loss: 48.28095620133921528350\n",
      "Iteration 21359 => Loss: 48.28077772377586285302\n",
      "Iteration 21360 => Loss: 48.28059924761319621211\n",
      "Iteration 21361 => Loss: 48.28042077285121536079\n",
      "Iteration 21362 => Loss: 48.28024229948986345562\n",
      "Iteration 21363 => Loss: 48.28006382752917602375\n",
      "Iteration 21364 => Loss: 48.27988535696913174888\n",
      "Iteration 21365 => Loss: 48.27970688780974484189\n",
      "Iteration 21366 => Loss: 48.27952842005093714306\n",
      "Iteration 21367 => Loss: 48.27934995369273707411\n",
      "Iteration 21368 => Loss: 48.27917148873513752960\n",
      "Iteration 21369 => Loss: 48.27899302517811719326\n",
      "Iteration 21370 => Loss: 48.27881456302168317052\n",
      "Iteration 21371 => Loss: 48.27863610226580703966\n",
      "Iteration 21372 => Loss: 48.27845764291047458983\n",
      "Iteration 21373 => Loss: 48.27827918495567161017\n",
      "Iteration 21374 => Loss: 48.27810072840142652240\n",
      "Iteration 21375 => Loss: 48.27792227324766116681\n",
      "Iteration 21376 => Loss: 48.27774381949443949225\n",
      "Iteration 21377 => Loss: 48.27756536714169754987\n",
      "Iteration 21378 => Loss: 48.27738691618942112882\n",
      "Iteration 21379 => Loss: 48.27720846663765286166\n",
      "Iteration 21380 => Loss: 48.27703001848632879955\n",
      "Iteration 21381 => Loss: 48.27685157173545604792\n",
      "Iteration 21382 => Loss: 48.27667312638502750133\n",
      "Iteration 21383 => Loss: 48.27649468243503605436\n",
      "Iteration 21384 => Loss: 48.27631623988545328530\n",
      "Iteration 21385 => Loss: 48.27613779873626498329\n",
      "Iteration 21386 => Loss: 48.27595935898750667548\n",
      "Iteration 21387 => Loss: 48.27578092063911441301\n",
      "Iteration 21388 => Loss: 48.27560248369108109046\n",
      "Iteration 21389 => Loss: 48.27542404814344223496\n",
      "Iteration 21390 => Loss: 48.27524561399614100310\n",
      "Iteration 21391 => Loss: 48.27506718124919871116\n",
      "Iteration 21392 => Loss: 48.27488874990256562114\n",
      "Iteration 21393 => Loss: 48.27471031995627015476\n",
      "Iteration 21394 => Loss: 48.27453189141026257403\n",
      "Iteration 21395 => Loss: 48.27435346426454998436\n",
      "Iteration 21396 => Loss: 48.27417503851916791291\n",
      "Iteration 21397 => Loss: 48.27399661417400977825\n",
      "Iteration 21398 => Loss: 48.27381819122913242381\n",
      "Iteration 21399 => Loss: 48.27363976968452163874\n",
      "Iteration 21400 => Loss: 48.27346134954014189589\n",
      "Iteration 21401 => Loss: 48.27328293079600740612\n",
      "Iteration 21402 => Loss: 48.27310451345208974772\n",
      "Iteration 21403 => Loss: 48.27292609750836049898\n",
      "Iteration 21404 => Loss: 48.27274768296484097618\n",
      "Iteration 21405 => Loss: 48.27256926982153117933\n",
      "Iteration 21406 => Loss: 48.27239085807837426501\n",
      "Iteration 21407 => Loss: 48.27221244773539154949\n",
      "Iteration 21408 => Loss: 48.27203403879256882192\n",
      "Iteration 21409 => Loss: 48.27185563124986344974\n",
      "Iteration 21410 => Loss: 48.27167722510732517094\n",
      "Iteration 21411 => Loss: 48.27149882036490424753\n",
      "Iteration 21412 => Loss: 48.27132041702257225779\n",
      "Iteration 21413 => Loss: 48.27114201508037183430\n",
      "Iteration 21414 => Loss: 48.27096361453824613363\n",
      "Iteration 21415 => Loss: 48.27078521539617383951\n",
      "Iteration 21416 => Loss: 48.27060681765419758449\n",
      "Iteration 21417 => Loss: 48.27042842131227473601\n",
      "Iteration 21418 => Loss: 48.27025002637039108322\n",
      "Iteration 21419 => Loss: 48.27007163282852530983\n",
      "Iteration 21420 => Loss: 48.26989324068672004842\n",
      "Iteration 21421 => Loss: 48.26971484994491135012\n",
      "Iteration 21422 => Loss: 48.26953646060308500410\n",
      "Iteration 21423 => Loss: 48.26935807266126943205\n",
      "Iteration 21424 => Loss: 48.26917968611942200141\n",
      "Iteration 21425 => Loss: 48.26900130097754981762\n",
      "Iteration 21426 => Loss: 48.26882291723562445895\n",
      "Iteration 21427 => Loss: 48.26864453489364592542\n",
      "Iteration 21428 => Loss: 48.26846615395162842788\n",
      "Iteration 21429 => Loss: 48.26828777440952933375\n",
      "Iteration 21430 => Loss: 48.26810939626731311591\n",
      "Iteration 21431 => Loss: 48.26793101952501530150\n",
      "Iteration 21432 => Loss: 48.26775264418261457422\n",
      "Iteration 21433 => Loss: 48.26757427024006830152\n",
      "Iteration 21434 => Loss: 48.26739589769744043224\n",
      "Iteration 21435 => Loss: 48.26721752655464570125\n",
      "Iteration 21436 => Loss: 48.26703915681169121399\n",
      "Iteration 21437 => Loss: 48.26686078846857697044\n",
      "Iteration 21438 => Loss: 48.26668242152527454891\n",
      "Iteration 21439 => Loss: 48.26650405598179105482\n",
      "Iteration 21440 => Loss: 48.26632569183814069902\n",
      "Iteration 21441 => Loss: 48.26614732909426663809\n",
      "Iteration 21442 => Loss: 48.26596896775015466119\n",
      "Iteration 21443 => Loss: 48.26579060780583319001\n",
      "Iteration 21444 => Loss: 48.26561224926127380286\n",
      "Iteration 21445 => Loss: 48.26543389211646228887\n",
      "Iteration 21446 => Loss: 48.26525553637137733176\n",
      "Iteration 21447 => Loss: 48.26507718202600472068\n",
      "Iteration 21448 => Loss: 48.26489882908037287734\n",
      "Iteration 21449 => Loss: 48.26472047753443206375\n",
      "Iteration 21450 => Loss: 48.26454212738821070161\n",
      "Iteration 21451 => Loss: 48.26436377864165194751\n",
      "Iteration 21452 => Loss: 48.26418543129477001230\n",
      "Iteration 21453 => Loss: 48.26400708534752226342\n",
      "Iteration 21454 => Loss: 48.26382874079996554428\n",
      "Iteration 21455 => Loss: 48.26365039765201458977\n",
      "Iteration 21456 => Loss: 48.26347205590371913786\n",
      "Iteration 21457 => Loss: 48.26329371555500102886\n",
      "Iteration 21458 => Loss: 48.26311537660593131704\n",
      "Iteration 21459 => Loss: 48.26293703905643894814\n",
      "Iteration 21460 => Loss: 48.26275870290652392214\n",
      "Iteration 21461 => Loss: 48.26258036815617913362\n",
      "Iteration 21462 => Loss: 48.26240203480541879344\n",
      "Iteration 21463 => Loss: 48.26222370285418605818\n",
      "Iteration 21464 => Loss: 48.26204537230249513868\n",
      "Iteration 21465 => Loss: 48.26186704315034603496\n",
      "Iteration 21466 => Loss: 48.26168871539771032531\n",
      "Iteration 21467 => Loss: 48.26151038904457379886\n",
      "Iteration 21468 => Loss: 48.26133206409095066647\n",
      "Iteration 21469 => Loss: 48.26115374053679829558\n",
      "Iteration 21470 => Loss: 48.26097541838210958076\n",
      "Iteration 21471 => Loss: 48.26079709762690583830\n",
      "Iteration 21472 => Loss: 48.26061877827113733019\n",
      "Iteration 21473 => Loss: 48.26044046031482537273\n",
      "Iteration 21474 => Loss: 48.26026214375793443878\n",
      "Iteration 21475 => Loss: 48.26008382860045742291\n",
      "Iteration 21476 => Loss: 48.25990551484239432511\n",
      "Iteration 21477 => Loss: 48.25972720248371672369\n",
      "Iteration 21478 => Loss: 48.25954889152444593492\n",
      "Iteration 21479 => Loss: 48.25937058196453932624\n",
      "Iteration 21480 => Loss: 48.25919227380399689764\n",
      "Iteration 21481 => Loss: 48.25901396704281154371\n",
      "Iteration 21482 => Loss: 48.25883566168095484272\n",
      "Iteration 21483 => Loss: 48.25865735771843390012\n",
      "Iteration 21484 => Loss: 48.25847905515525582132\n",
      "Iteration 21485 => Loss: 48.25830075399137086833\n",
      "Iteration 21486 => Loss: 48.25812245422677193574\n",
      "Iteration 21487 => Loss: 48.25794415586148033981\n",
      "Iteration 21488 => Loss: 48.25776585889544634256\n",
      "Iteration 21489 => Loss: 48.25758756332869126027\n",
      "Iteration 21490 => Loss: 48.25740926916117956580\n",
      "Iteration 21491 => Loss: 48.25723097639291836458\n",
      "Iteration 21492 => Loss: 48.25705268502389344576\n",
      "Iteration 21493 => Loss: 48.25687439505407638762\n",
      "Iteration 21494 => Loss: 48.25669610648347429560\n",
      "Iteration 21495 => Loss: 48.25651781931208716969\n",
      "Iteration 21496 => Loss: 48.25633953353987237733\n",
      "Iteration 21497 => Loss: 48.25616124916683702395\n",
      "Iteration 21498 => Loss: 48.25598296619296689869\n",
      "Iteration 21499 => Loss: 48.25580468461824068527\n",
      "Iteration 21500 => Loss: 48.25562640444270101625\n",
      "Iteration 21501 => Loss: 48.25544812566624841565\n",
      "Iteration 21502 => Loss: 48.25526984828893262147\n",
      "Iteration 21503 => Loss: 48.25509157231075363370\n",
      "Iteration 21504 => Loss: 48.25491329773163329264\n",
      "Iteration 21505 => Loss: 48.25473502455162133629\n",
      "Iteration 21506 => Loss: 48.25455675277070355378\n",
      "Iteration 21507 => Loss: 48.25437848238885152341\n",
      "Iteration 21508 => Loss: 48.25420021340602971804\n",
      "Iteration 21509 => Loss: 48.25402194582225945396\n",
      "Iteration 21510 => Loss: 48.25384367963754073116\n",
      "Iteration 21511 => Loss: 48.25366541485183802251\n",
      "Iteration 21512 => Loss: 48.25348715146511580087\n",
      "Iteration 21513 => Loss: 48.25330888947744512052\n",
      "Iteration 21514 => Loss: 48.25313062888875492717\n",
      "Iteration 21515 => Loss: 48.25295236969904522084\n",
      "Iteration 21516 => Loss: 48.25277411190828757981\n",
      "Iteration 21517 => Loss: 48.25259585551650332036\n",
      "Iteration 21518 => Loss: 48.25241760052364270450\n",
      "Iteration 21519 => Loss: 48.25223934692972704852\n",
      "Iteration 21520 => Loss: 48.25206109473475635241\n",
      "Iteration 21521 => Loss: 48.25188284393867377275\n",
      "Iteration 21522 => Loss: 48.25170459454149352041\n",
      "Iteration 21523 => Loss: 48.25152634654323691166\n",
      "Iteration 21524 => Loss: 48.25134809994383999765\n",
      "Iteration 21525 => Loss: 48.25116985474330277839\n",
      "Iteration 21526 => Loss: 48.25099161094165367558\n",
      "Iteration 21527 => Loss: 48.25081336853883584581\n",
      "Iteration 21528 => Loss: 48.25063512753484218365\n",
      "Iteration 21529 => Loss: 48.25045688792968689995\n",
      "Iteration 21530 => Loss: 48.25027864972333446758\n",
      "Iteration 21531 => Loss: 48.25010041291579909739\n",
      "Iteration 21532 => Loss: 48.24992217750705947310\n",
      "Iteration 21533 => Loss: 48.24974394349710848928\n",
      "Iteration 21534 => Loss: 48.24956571088591061880\n",
      "Iteration 21535 => Loss: 48.24938747967348717793\n",
      "Iteration 21536 => Loss: 48.24920924985979553412\n",
      "Iteration 21537 => Loss: 48.24903102144485700364\n",
      "Iteration 21538 => Loss: 48.24885279442863605937\n",
      "Iteration 21539 => Loss: 48.24867456881114691214\n",
      "Iteration 21540 => Loss: 48.24849634459234692940\n",
      "Iteration 21541 => Loss: 48.24831812177223611116\n",
      "Iteration 21542 => Loss: 48.24813990035082866825\n",
      "Iteration 21543 => Loss: 48.24796168032807486270\n",
      "Iteration 21544 => Loss: 48.24778346170400311621\n",
      "Iteration 21545 => Loss: 48.24760524447857079622\n",
      "Iteration 21546 => Loss: 48.24742702865176369187\n",
      "Iteration 21547 => Loss: 48.24724881422360311944\n",
      "Iteration 21548 => Loss: 48.24707060119406776266\n",
      "Iteration 21549 => Loss: 48.24689238956312209439\n",
      "Iteration 21550 => Loss: 48.24671417933077322004\n",
      "Iteration 21551 => Loss: 48.24653597049702113964\n",
      "Iteration 21552 => Loss: 48.24635776306183032602\n",
      "Iteration 21553 => Loss: 48.24617955702520077921\n",
      "Iteration 21554 => Loss: 48.24600135238712539376\n",
      "Iteration 21555 => Loss: 48.24582314914759706426\n",
      "Iteration 21556 => Loss: 48.24564494730660868527\n",
      "Iteration 21557 => Loss: 48.24546674686410341337\n",
      "Iteration 21558 => Loss: 48.24528854782014519742\n",
      "Iteration 21559 => Loss: 48.24511035017465587771\n",
      "Iteration 21560 => Loss: 48.24493215392766387595\n",
      "Iteration 21561 => Loss: 48.24475395907914787585\n",
      "Iteration 21562 => Loss: 48.24457576562908656115\n",
      "Iteration 21563 => Loss: 48.24439757357747993183\n",
      "Iteration 21564 => Loss: 48.24421938292431377704\n",
      "Iteration 21565 => Loss: 48.24404119366958809678\n",
      "Iteration 21566 => Loss: 48.24386300581326736392\n",
      "Iteration 21567 => Loss: 48.24368481935537289473\n",
      "Iteration 21568 => Loss: 48.24350663429586205666\n",
      "Iteration 21569 => Loss: 48.24332845063476327141\n",
      "Iteration 21570 => Loss: 48.24315026837199837928\n",
      "Iteration 21571 => Loss: 48.24297208750763843454\n",
      "Iteration 21572 => Loss: 48.24279390804161948836\n",
      "Iteration 21573 => Loss: 48.24261572997393443529\n",
      "Iteration 21574 => Loss: 48.24243755330459748620\n",
      "Iteration 21575 => Loss: 48.24225937803356600853\n",
      "Iteration 21576 => Loss: 48.24208120416085421311\n",
      "Iteration 21577 => Loss: 48.24190303168643367826\n",
      "Iteration 21578 => Loss: 48.24172486061030440396\n",
      "Iteration 21579 => Loss: 48.24154669093245928480\n",
      "Iteration 21580 => Loss: 48.24136852265286989905\n",
      "Iteration 21581 => Loss: 48.24119035577156466843\n",
      "Iteration 21582 => Loss: 48.24101219028847253867\n",
      "Iteration 21583 => Loss: 48.24083402620360061519\n",
      "Iteration 21584 => Loss: 48.24065586351698442513\n",
      "Iteration 21585 => Loss: 48.24047770222855291422\n",
      "Iteration 21586 => Loss: 48.24029954233834160959\n",
      "Iteration 21587 => Loss: 48.24012138384630077326\n",
      "Iteration 21588 => Loss: 48.23994322675245882692\n",
      "Iteration 21589 => Loss: 48.23976507105677313803\n",
      "Iteration 21590 => Loss: 48.23958691675925791742\n",
      "Iteration 21591 => Loss: 48.23940876385987763797\n",
      "Iteration 21592 => Loss: 48.23923061235862519425\n",
      "Iteration 21593 => Loss: 48.23905246225550058625\n",
      "Iteration 21594 => Loss: 48.23887431355050381399\n",
      "Iteration 21595 => Loss: 48.23869616624358513945\n",
      "Iteration 21596 => Loss: 48.23851802033475877352\n",
      "Iteration 21597 => Loss: 48.23833987582403892702\n",
      "Iteration 21598 => Loss: 48.23816173271136165113\n",
      "Iteration 21599 => Loss: 48.23798359099675536754\n",
      "Iteration 21600 => Loss: 48.23780545068020586541\n",
      "Iteration 21601 => Loss: 48.23762731176167761760\n",
      "Iteration 21602 => Loss: 48.23744917424115641325\n",
      "Iteration 21603 => Loss: 48.23727103811867067407\n",
      "Iteration 21604 => Loss: 48.23709290339419197835\n",
      "Iteration 21605 => Loss: 48.23691477006770611524\n",
      "Iteration 21606 => Loss: 48.23673663813918466303\n",
      "Iteration 21607 => Loss: 48.23655850760863472715\n",
      "Iteration 21608 => Loss: 48.23638037847605630759\n",
      "Iteration 21609 => Loss: 48.23620225074140677179\n",
      "Iteration 21610 => Loss: 48.23602412440470743604\n",
      "Iteration 21611 => Loss: 48.23584599946592987862\n",
      "Iteration 21612 => Loss: 48.23566787592508120497\n",
      "Iteration 21613 => Loss: 48.23548975378212588794\n",
      "Iteration 21614 => Loss: 48.23531163303707103296\n",
      "Iteration 21615 => Loss: 48.23513351368988111290\n",
      "Iteration 21616 => Loss: 48.23495539574057744403\n",
      "Iteration 21617 => Loss: 48.23477727918913871008\n",
      "Iteration 21618 => Loss: 48.23459916403553648934\n",
      "Iteration 21619 => Loss: 48.23442105027977078180\n",
      "Iteration 21620 => Loss: 48.23424293792185579832\n",
      "Iteration 21621 => Loss: 48.23406482696172759006\n",
      "Iteration 21622 => Loss: 48.23388671739940747329\n",
      "Iteration 21623 => Loss: 48.23370860923489544803\n",
      "Iteration 21624 => Loss: 48.23353050246816309254\n",
      "Iteration 21625 => Loss: 48.23335239709921040685\n",
      "Iteration 21626 => Loss: 48.23317429312801607466\n",
      "Iteration 21627 => Loss: 48.23299619055457299055\n",
      "Iteration 21628 => Loss: 48.23281808937885983823\n",
      "Iteration 21629 => Loss: 48.23263998960088372314\n",
      "Iteration 21630 => Loss: 48.23246189122060911814\n",
      "Iteration 21631 => Loss: 48.23228379423806444493\n",
      "Iteration 21632 => Loss: 48.23210569865319996552\n",
      "Iteration 21633 => Loss: 48.23192760446604410163\n",
      "Iteration 21634 => Loss: 48.23174951167653290440\n",
      "Iteration 21635 => Loss: 48.23157142028468769013\n",
      "Iteration 21636 => Loss: 48.23139333029050135337\n",
      "Iteration 21637 => Loss: 48.23121524169394547243\n",
      "Iteration 21638 => Loss: 48.23103715449504136359\n",
      "Iteration 21639 => Loss: 48.23085906869375349970\n",
      "Iteration 21640 => Loss: 48.23068098429006056449\n",
      "Iteration 21641 => Loss: 48.23050290128396255795\n",
      "Iteration 21642 => Loss: 48.23032481967545948010\n",
      "Iteration 21643 => Loss: 48.23014673946453001463\n",
      "Iteration 21644 => Loss: 48.22996866065115995070\n",
      "Iteration 21645 => Loss: 48.22979058323534928832\n",
      "Iteration 21646 => Loss: 48.22961250721708381661\n",
      "Iteration 21647 => Loss: 48.22943443259633511389\n",
      "Iteration 21648 => Loss: 48.22925635937311739099\n",
      "Iteration 21649 => Loss: 48.22907828754741643706\n",
      "Iteration 21650 => Loss: 48.22890021711920383041\n",
      "Iteration 21651 => Loss: 48.22872214808847957102\n",
      "Iteration 21652 => Loss: 48.22854408045522234261\n",
      "Iteration 21653 => Loss: 48.22836601421943214518\n",
      "Iteration 21654 => Loss: 48.22818794938111608417\n",
      "Iteration 21655 => Loss: 48.22800988594021021072\n",
      "Iteration 21656 => Loss: 48.22783182389677847368\n",
      "Iteration 21657 => Loss: 48.22765376325075692421\n",
      "Iteration 21658 => Loss: 48.22747570400211714059\n",
      "Iteration 21659 => Loss: 48.22729764615090886082\n",
      "Iteration 21660 => Loss: 48.22711958969706813605\n",
      "Iteration 21661 => Loss: 48.22694153464060917713\n",
      "Iteration 21662 => Loss: 48.22676348098151777322\n",
      "Iteration 21663 => Loss: 48.22658542871980813516\n",
      "Iteration 21664 => Loss: 48.22640737785541631411\n",
      "Iteration 21665 => Loss: 48.22622932838836362635\n",
      "Iteration 21666 => Loss: 48.22605128031862875559\n",
      "Iteration 21667 => Loss: 48.22587323364622591271\n",
      "Iteration 21668 => Loss: 48.22569518837108404341\n",
      "Iteration 21669 => Loss: 48.22551714449328130740\n",
      "Iteration 21670 => Loss: 48.22533910201273243956\n",
      "Iteration 21671 => Loss: 48.22516106092945165074\n",
      "Iteration 21672 => Loss: 48.22498302124341762465\n",
      "Iteration 21673 => Loss: 48.22480498295463746672\n",
      "Iteration 21674 => Loss: 48.22462694606309696610\n",
      "Iteration 21675 => Loss: 48.22444891056878901736\n",
      "Iteration 21676 => Loss: 48.22427087647168519879\n",
      "Iteration 21677 => Loss: 48.22409284377179261583\n",
      "Iteration 21678 => Loss: 48.22391481246906153046\n",
      "Iteration 21679 => Loss: 48.22373678256354168070\n",
      "Iteration 21680 => Loss: 48.22355875405518332855\n",
      "Iteration 21681 => Loss: 48.22338072694397226314\n",
      "Iteration 21682 => Loss: 48.22320270122991558992\n",
      "Iteration 21683 => Loss: 48.22302467691298488717\n",
      "Iteration 21684 => Loss: 48.22284665399320147117\n",
      "Iteration 21685 => Loss: 48.22266863247052270935\n",
      "Iteration 21686 => Loss: 48.22249061234493439088\n",
      "Iteration 21687 => Loss: 48.22231259361646493744\n",
      "Iteration 21688 => Loss: 48.22213457628505750563\n",
      "Iteration 21689 => Loss: 48.22195656035071920087\n",
      "Iteration 21690 => Loss: 48.22177854581345002316\n",
      "Iteration 21691 => Loss: 48.22160053267322865622\n",
      "Iteration 21692 => Loss: 48.22142252093003378377\n",
      "Iteration 21693 => Loss: 48.22124451058387961666\n",
      "Iteration 21694 => Loss: 48.22106650163475194404\n",
      "Iteration 21695 => Loss: 48.22088849408260813334\n",
      "Iteration 21696 => Loss: 48.22071048792744818456\n",
      "Iteration 21697 => Loss: 48.22053248316930051942\n",
      "Iteration 21698 => Loss: 48.22035447980811539992\n",
      "Iteration 21699 => Loss: 48.22017647784387861520\n",
      "Iteration 21700 => Loss: 48.21999847727659016527\n",
      "Iteration 21701 => Loss: 48.21982047810626426099\n",
      "Iteration 21702 => Loss: 48.21964248033285116435\n",
      "Iteration 21703 => Loss: 48.21946448395635087536\n",
      "Iteration 21704 => Loss: 48.21928648897677049945\n",
      "Iteration 21705 => Loss: 48.21910849539408161490\n",
      "Iteration 21706 => Loss: 48.21893050320827711630\n",
      "Iteration 21707 => Loss: 48.21875251241933568735\n",
      "Iteration 21708 => Loss: 48.21857452302725732807\n",
      "Iteration 21709 => Loss: 48.21839653503204914387\n",
      "Iteration 21710 => Loss: 48.21821854843364718590\n",
      "Iteration 21711 => Loss: 48.21804056323210119217\n",
      "Iteration 21712 => Loss: 48.21786257942736853011\n",
      "Iteration 21713 => Loss: 48.21768459701945630513\n",
      "Iteration 21714 => Loss: 48.21750661600832188469\n",
      "Iteration 21715 => Loss: 48.21732863639397947964\n",
      "Iteration 21716 => Loss: 48.21715065817640777368\n",
      "Iteration 21717 => Loss: 48.21697268135559966140\n",
      "Iteration 21718 => Loss: 48.21679470593154803737\n",
      "Iteration 21719 => Loss: 48.21661673190422447988\n",
      "Iteration 21720 => Loss: 48.21643875927366451606\n",
      "Iteration 21721 => Loss: 48.21626078803981130250\n",
      "Iteration 21722 => Loss: 48.21608281820265062834\n",
      "Iteration 21723 => Loss: 48.21590484976218959901\n",
      "Iteration 21724 => Loss: 48.21572688271842821450\n",
      "Iteration 21725 => Loss: 48.21554891707132384226\n",
      "Iteration 21726 => Loss: 48.21537095282091911486\n",
      "Iteration 21727 => Loss: 48.21519298996714297800\n",
      "Iteration 21728 => Loss: 48.21501502851001674799\n",
      "Iteration 21729 => Loss: 48.21483706844951910853\n",
      "Iteration 21730 => Loss: 48.21465910978565716505\n",
      "Iteration 21731 => Loss: 48.21448115251838117956\n",
      "Iteration 21732 => Loss: 48.21430319664771957378\n",
      "Iteration 21733 => Loss: 48.21412524217365103141\n",
      "Iteration 21734 => Loss: 48.21394728909614713075\n",
      "Iteration 21735 => Loss: 48.21376933741520076637\n",
      "Iteration 21736 => Loss: 48.21359138713082614913\n",
      "Iteration 21737 => Loss: 48.21341343824300196275\n",
      "Iteration 21738 => Loss: 48.21323549075169978551\n",
      "Iteration 21739 => Loss: 48.21305754465693382826\n",
      "Iteration 21740 => Loss: 48.21287959995865435303\n",
      "Iteration 21741 => Loss: 48.21270165665689688694\n",
      "Iteration 21742 => Loss: 48.21252371475159748115\n",
      "Iteration 21743 => Loss: 48.21234577424282718994\n",
      "Iteration 21744 => Loss: 48.21216783513049364274\n",
      "Iteration 21745 => Loss: 48.21198989741461815584\n",
      "Iteration 21746 => Loss: 48.21181196109518651838\n",
      "Iteration 21747 => Loss: 48.21163402617219162494\n",
      "Iteration 21748 => Loss: 48.21145609264564058094\n",
      "Iteration 21749 => Loss: 48.21127816051546943754\n",
      "Iteration 21750 => Loss: 48.21110022978172793273\n",
      "Iteration 21751 => Loss: 48.21092230044435922309\n",
      "Iteration 21752 => Loss: 48.21074437250337751948\n",
      "Iteration 21753 => Loss: 48.21056644595877571646\n",
      "Iteration 21754 => Loss: 48.21038852081051828691\n",
      "Iteration 21755 => Loss: 48.21021059705861233624\n",
      "Iteration 21756 => Loss: 48.21003267470304365361\n",
      "Iteration 21757 => Loss: 48.20985475374377671187\n",
      "Iteration 21758 => Loss: 48.20967683418086835445\n",
      "Iteration 21759 => Loss: 48.20949891601423331622\n",
      "Iteration 21760 => Loss: 48.20932099924389291346\n",
      "Iteration 21761 => Loss: 48.20914308386984004073\n",
      "Iteration 21762 => Loss: 48.20896516989205338177\n",
      "Iteration 21763 => Loss: 48.20878725731054004200\n",
      "Iteration 21764 => Loss: 48.20860934612526449428\n",
      "Iteration 21765 => Loss: 48.20843143633622673860\n",
      "Iteration 21766 => Loss: 48.20825352794340545870\n",
      "Iteration 21767 => Loss: 48.20807562094679354914\n",
      "Iteration 21768 => Loss: 48.20789771534641943163\n",
      "Iteration 21769 => Loss: 48.20771981114223336817\n",
      "Iteration 21770 => Loss: 48.20754190833421404250\n",
      "Iteration 21771 => Loss: 48.20736400692238987631\n",
      "Iteration 21772 => Loss: 48.20718610690669692076\n",
      "Iteration 21773 => Loss: 48.20700820828715649213\n",
      "Iteration 21774 => Loss: 48.20683031106376859043\n",
      "Iteration 21775 => Loss: 48.20665241523649768851\n",
      "Iteration 21776 => Loss: 48.20647452080535799723\n",
      "Iteration 21777 => Loss: 48.20629662777032109489\n",
      "Iteration 21778 => Loss: 48.20611873613137277061\n",
      "Iteration 21779 => Loss: 48.20594084588849881357\n",
      "Iteration 21780 => Loss: 48.20576295704171343459\n",
      "Iteration 21781 => Loss: 48.20558506959098110656\n",
      "Iteration 21782 => Loss: 48.20540718353633025117\n",
      "Iteration 21783 => Loss: 48.20522929887767560331\n",
      "Iteration 21784 => Loss: 48.20505141561506690095\n",
      "Iteration 21785 => Loss: 48.20487353374848282783\n",
      "Iteration 21786 => Loss: 48.20469565327790206766\n",
      "Iteration 21787 => Loss: 48.20451777420332462043\n",
      "Iteration 21788 => Loss: 48.20433989652472916987\n",
      "Iteration 21789 => Loss: 48.20416202024209439969\n",
      "Iteration 21790 => Loss: 48.20398414535543452075\n",
      "Iteration 21791 => Loss: 48.20380627186474242762\n",
      "Iteration 21792 => Loss: 48.20362839976996838232\n",
      "Iteration 21793 => Loss: 48.20345052907114080654\n",
      "Iteration 21794 => Loss: 48.20327265976821706772\n",
      "Iteration 21795 => Loss: 48.20309479186122558758\n",
      "Iteration 21796 => Loss: 48.20291692535012373355\n",
      "Iteration 21797 => Loss: 48.20273906023489018935\n",
      "Iteration 21798 => Loss: 48.20256119651556758754\n",
      "Iteration 21799 => Loss: 48.20238333419209908470\n",
      "Iteration 21800 => Loss: 48.20220547326444204828\n",
      "Iteration 21801 => Loss: 48.20202761373266042710\n",
      "Iteration 21802 => Loss: 48.20184975559674001033\n",
      "Iteration 21803 => Loss: 48.20167189885658842741\n",
      "Iteration 21804 => Loss: 48.20149404351227673260\n",
      "Iteration 21805 => Loss: 48.20131618956376229335\n",
      "Iteration 21806 => Loss: 48.20113833701103800422\n",
      "Iteration 21807 => Loss: 48.20096048585408254894\n",
      "Iteration 21808 => Loss: 48.20078263609289592750\n",
      "Iteration 21809 => Loss: 48.20060478772745682363\n",
      "Iteration 21810 => Loss: 48.20042694075778655360\n",
      "Iteration 21811 => Loss: 48.20024909518383537943\n",
      "Iteration 21812 => Loss: 48.20007125100559619568\n",
      "Iteration 21813 => Loss: 48.19989340822308321322\n",
      "Iteration 21814 => Loss: 48.19971556683627511575\n",
      "Iteration 21815 => Loss: 48.19953772684513637614\n",
      "Iteration 21816 => Loss: 48.19935988824968120525\n",
      "Iteration 21817 => Loss: 48.19918205104992381393\n",
      "Iteration 21818 => Loss: 48.19900421524577893706\n",
      "Iteration 21819 => Loss: 48.19882638083731052348\n",
      "Iteration 21820 => Loss: 48.19864854782445462433\n",
      "Iteration 21821 => Loss: 48.19847071620724676677\n",
      "Iteration 21822 => Loss: 48.19829288598564431823\n",
      "Iteration 21823 => Loss: 48.19811505715964727870\n",
      "Iteration 21824 => Loss: 48.19793722972923433190\n",
      "Iteration 21825 => Loss: 48.19775940369440547784\n",
      "Iteration 21826 => Loss: 48.19758157905514650565\n",
      "Iteration 21827 => Loss: 48.19740375581142899364\n",
      "Iteration 21828 => Loss: 48.19722593396327425808\n",
      "Iteration 21829 => Loss: 48.19704811351064677183\n",
      "Iteration 21830 => Loss: 48.19687029445357495661\n",
      "Iteration 21831 => Loss: 48.19669247679198775813\n",
      "Iteration 21832 => Loss: 48.19651466052592070355\n",
      "Iteration 21833 => Loss: 48.19633684565533826571\n",
      "Iteration 21834 => Loss: 48.19615903218022623378\n",
      "Iteration 21835 => Loss: 48.19598122010059881859\n",
      "Iteration 21836 => Loss: 48.19580340941643470387\n",
      "Iteration 21837 => Loss: 48.19562560012771257334\n",
      "Iteration 21838 => Loss: 48.19544779223441111071\n",
      "Iteration 21839 => Loss: 48.19526998573657294855\n",
      "Iteration 21840 => Loss: 48.19509218063414124344\n",
      "Iteration 21841 => Loss: 48.19491437692710178453\n",
      "Iteration 21842 => Loss: 48.19473657461545457181\n",
      "Iteration 21843 => Loss: 48.19455877369918539443\n",
      "Iteration 21844 => Loss: 48.19438097417830846325\n",
      "Iteration 21845 => Loss: 48.19420317605279535655\n",
      "Iteration 21846 => Loss: 48.19402537932260344178\n",
      "Iteration 21847 => Loss: 48.19384758398776824606\n",
      "Iteration 21848 => Loss: 48.19366979004828976940\n",
      "Iteration 21849 => Loss: 48.19349199750408985210\n",
      "Iteration 21850 => Loss: 48.19331420635521823215\n",
      "Iteration 21851 => Loss: 48.19313641660160385527\n",
      "Iteration 21852 => Loss: 48.19295862824330356489\n",
      "Iteration 21853 => Loss: 48.19278084128028893929\n",
      "Iteration 21854 => Loss: 48.19260305571250313506\n",
      "Iteration 21855 => Loss: 48.19242527154001720646\n",
      "Iteration 21856 => Loss: 48.19224748876272457210\n",
      "Iteration 21857 => Loss: 48.19206970738068918081\n",
      "Iteration 21858 => Loss: 48.19189192739386840003\n",
      "Iteration 21859 => Loss: 48.19171414880224091348\n",
      "Iteration 21860 => Loss: 48.19153637160582093202\n",
      "Iteration 21861 => Loss: 48.19135859580459424478\n",
      "Iteration 21862 => Loss: 48.19118082139852532464\n",
      "Iteration 21863 => Loss: 48.19100304838763548787\n",
      "Iteration 21864 => Loss: 48.19082527677191052362\n",
      "Iteration 21865 => Loss: 48.19064750655130779933\n",
      "Iteration 21866 => Loss: 48.19046973772584152584\n",
      "Iteration 21867 => Loss: 48.19029197029550459774\n",
      "Iteration 21868 => Loss: 48.19011420426024727703\n",
      "Iteration 21869 => Loss: 48.18993643962010509085\n",
      "Iteration 21870 => Loss: 48.18975867637505672292\n",
      "Iteration 21871 => Loss: 48.18958091452508085695\n",
      "Iteration 21872 => Loss: 48.18940315407016328209\n",
      "Iteration 21873 => Loss: 48.18922539501031110376\n",
      "Iteration 21874 => Loss: 48.18904763734550300569\n",
      "Iteration 21875 => Loss: 48.18886988107573898787\n",
      "Iteration 21876 => Loss: 48.18869212620096220689\n",
      "Iteration 21877 => Loss: 48.18851437272122950617\n",
      "Iteration 21878 => Loss: 48.18833662063647693685\n",
      "Iteration 21879 => Loss: 48.18815886994672581523\n",
      "Iteration 21880 => Loss: 48.18798112065194061415\n",
      "Iteration 21881 => Loss: 48.18780337275214264992\n",
      "Iteration 21882 => Loss: 48.18762562624728928995\n",
      "Iteration 21883 => Loss: 48.18744788113736632340\n",
      "Iteration 21884 => Loss: 48.18727013742240217198\n",
      "Iteration 21885 => Loss: 48.18709239510234709769\n",
      "Iteration 21886 => Loss: 48.18691465417719399511\n",
      "Iteration 21887 => Loss: 48.18673691464695707509\n",
      "Iteration 21888 => Loss: 48.18655917651161502135\n",
      "Iteration 21889 => Loss: 48.18638143977113941219\n",
      "Iteration 21890 => Loss: 48.18620370442555156387\n",
      "Iteration 21891 => Loss: 48.18602597047481594927\n",
      "Iteration 21892 => Loss: 48.18584823791891125211\n",
      "Iteration 21893 => Loss: 48.18567050675785168323\n",
      "Iteration 21894 => Loss: 48.18549277699160171551\n",
      "Iteration 21895 => Loss: 48.18531504862018977065\n",
      "Iteration 21896 => Loss: 48.18513732164356611065\n",
      "Iteration 21897 => Loss: 48.18495959606173784096\n",
      "Iteration 21898 => Loss: 48.18478187187469785613\n",
      "Iteration 21899 => Loss: 48.18460414908243194532\n",
      "Iteration 21900 => Loss: 48.18442642768491879224\n",
      "Iteration 21901 => Loss: 48.18424870768214418604\n",
      "Iteration 21902 => Loss: 48.18407098907411523214\n",
      "Iteration 21903 => Loss: 48.18389327186081771970\n",
      "Iteration 21904 => Loss: 48.18371555604222322700\n",
      "Iteration 21905 => Loss: 48.18353784161833885946\n",
      "Iteration 21906 => Loss: 48.18336012858912908996\n",
      "Iteration 21907 => Loss: 48.18318241695463655105\n",
      "Iteration 21908 => Loss: 48.18300470671479729390\n",
      "Iteration 21909 => Loss: 48.18282699786962552935\n",
      "Iteration 21910 => Loss: 48.18264929041909283569\n",
      "Iteration 21911 => Loss: 48.18247158436319210750\n",
      "Iteration 21912 => Loss: 48.18229387970193755564\n",
      "Iteration 21913 => Loss: 48.18211617643530786381\n",
      "Iteration 21914 => Loss: 48.18193847456325329404\n",
      "Iteration 21915 => Loss: 48.18176077408580937345\n",
      "Iteration 21916 => Loss: 48.18158307500294768033\n",
      "Iteration 21917 => Loss: 48.18140537731467532012\n",
      "Iteration 21918 => Loss: 48.18122768102093544940\n",
      "Iteration 21919 => Loss: 48.18104998612177070072\n",
      "Iteration 21920 => Loss: 48.18087229261714554696\n",
      "Iteration 21921 => Loss: 48.18069460050704577725\n",
      "Iteration 21922 => Loss: 48.18051690979145007532\n",
      "Iteration 21923 => Loss: 48.18033922047037265202\n",
      "Iteration 21924 => Loss: 48.18016153254379219106\n",
      "Iteration 21925 => Loss: 48.17998384601169448160\n",
      "Iteration 21926 => Loss: 48.17980616087407241821\n",
      "Iteration 21927 => Loss: 48.17962847713091889545\n",
      "Iteration 21928 => Loss: 48.17945079478220549163\n",
      "Iteration 21929 => Loss: 48.17927311382795352301\n",
      "Iteration 21930 => Loss: 48.17909543426812035705\n",
      "Iteration 21931 => Loss: 48.17891775610271309915\n",
      "Iteration 21932 => Loss: 48.17874007933169622220\n",
      "Iteration 21933 => Loss: 48.17856240395509814789\n",
      "Iteration 21934 => Loss: 48.17838472997286913824\n",
      "Iteration 21935 => Loss: 48.17820705738504472038\n",
      "Iteration 21936 => Loss: 48.17802938619155384004\n",
      "Iteration 21937 => Loss: 48.17785171639243202435\n",
      "Iteration 21938 => Loss: 48.17767404798764374618\n",
      "Iteration 21939 => Loss: 48.17749638097720321639\n",
      "Iteration 21940 => Loss: 48.17731871536108911869\n",
      "Iteration 21941 => Loss: 48.17714105113925882051\n",
      "Iteration 21942 => Loss: 48.17696338831174074357\n",
      "Iteration 21943 => Loss: 48.17678572687851357159\n",
      "Iteration 21944 => Loss: 48.17660806683957019914\n",
      "Iteration 21945 => Loss: 48.17643040819487509907\n",
      "Iteration 21946 => Loss: 48.17625275094444958768\n",
      "Iteration 21947 => Loss: 48.17607509508826524325\n",
      "Iteration 21948 => Loss: 48.17589744062632206578\n",
      "Iteration 21949 => Loss: 48.17571978755859163357\n",
      "Iteration 21950 => Loss: 48.17554213588508815747\n",
      "Iteration 21951 => Loss: 48.17536448560574768862\n",
      "Iteration 21952 => Loss: 48.17518683672064128132\n",
      "Iteration 21953 => Loss: 48.17500918922967656499\n",
      "Iteration 21954 => Loss: 48.17483154313291038306\n",
      "Iteration 21955 => Loss: 48.17465389843029299755\n",
      "Iteration 21956 => Loss: 48.17447625512181730301\n",
      "Iteration 21957 => Loss: 48.17429861320748329945\n",
      "Iteration 21958 => Loss: 48.17412097268726967059\n",
      "Iteration 21959 => Loss: 48.17394333356114799471\n",
      "Iteration 21960 => Loss: 48.17376569582916090440\n",
      "Iteration 21961 => Loss: 48.17358805949127287249\n",
      "Iteration 21962 => Loss: 48.17341042454743416101\n",
      "Iteration 21963 => Loss: 48.17323279099767319167\n",
      "Iteration 21964 => Loss: 48.17305515884198996446\n",
      "Iteration 21965 => Loss: 48.17287752808034895224\n",
      "Iteration 21966 => Loss: 48.17269989871272883875\n",
      "Iteration 21967 => Loss: 48.17252227073913672939\n",
      "Iteration 21968 => Loss: 48.17234464415956551875\n",
      "Iteration 21969 => Loss: 48.17216701897400810140\n",
      "Iteration 21970 => Loss: 48.17198939518242895019\n",
      "Iteration 21971 => Loss: 48.17181177278483517057\n",
      "Iteration 21972 => Loss: 48.17163415178120544624\n",
      "Iteration 21973 => Loss: 48.17145653217156109349\n",
      "Iteration 21974 => Loss: 48.17127891395582395262\n",
      "Iteration 21975 => Loss: 48.17110129713407928875\n",
      "Iteration 21976 => Loss: 48.17092368170622052048\n",
      "Iteration 21977 => Loss: 48.17074606767228317494\n",
      "Iteration 21978 => Loss: 48.17056845503227435756\n",
      "Iteration 21979 => Loss: 48.17039084378613722492\n",
      "Iteration 21980 => Loss: 48.17021323393390019874\n",
      "Iteration 21981 => Loss: 48.17003562547552064643\n",
      "Iteration 21982 => Loss: 48.16985801841102698972\n",
      "Iteration 21983 => Loss: 48.16968041274035527977\n",
      "Iteration 21984 => Loss: 48.16950280846353393827\n",
      "Iteration 21985 => Loss: 48.16932520558054164894\n",
      "Iteration 21986 => Loss: 48.16914760409137841179\n",
      "Iteration 21987 => Loss: 48.16897000399600159426\n",
      "Iteration 21988 => Loss: 48.16879240529443251262\n",
      "Iteration 21989 => Loss: 48.16861480798664985059\n",
      "Iteration 21990 => Loss: 48.16843721207263939732\n",
      "Iteration 21991 => Loss: 48.16825961755237983652\n",
      "Iteration 21992 => Loss: 48.16808202442589248449\n",
      "Iteration 21993 => Loss: 48.16790443269314181407\n",
      "Iteration 21994 => Loss: 48.16772684235411361442\n",
      "Iteration 21995 => Loss: 48.16754925340881499096\n",
      "Iteration 21996 => Loss: 48.16737166585722462742\n",
      "Iteration 21997 => Loss: 48.16719407969934252378\n",
      "Iteration 21998 => Loss: 48.16701649493511183664\n",
      "Iteration 21999 => Loss: 48.16683891156459651484\n",
      "Iteration 22000 => Loss: 48.16666132958772550410\n",
      "Iteration 22001 => Loss: 48.16648374900452012071\n",
      "Iteration 22002 => Loss: 48.16630616981493773210\n",
      "Iteration 22003 => Loss: 48.16612859201899254913\n",
      "Iteration 22004 => Loss: 48.16595101561668457180\n",
      "Iteration 22005 => Loss: 48.16577344060795695668\n",
      "Iteration 22006 => Loss: 48.16559586699286654721\n",
      "Iteration 22007 => Loss: 48.16541829477134939452\n",
      "Iteration 22008 => Loss: 48.16524072394339128778\n",
      "Iteration 22009 => Loss: 48.16506315450904196496\n",
      "Iteration 22010 => Loss: 48.16488558646820195008\n",
      "Iteration 22011 => Loss: 48.16470801982092098115\n",
      "Iteration 22012 => Loss: 48.16453045456717774186\n",
      "Iteration 22013 => Loss: 48.16435289070697933766\n",
      "Iteration 22014 => Loss: 48.16417532824025471427\n",
      "Iteration 22015 => Loss: 48.16399776716704650426\n",
      "Iteration 22016 => Loss: 48.16382020748734049675\n",
      "Iteration 22017 => Loss: 48.16364264920110116464\n",
      "Iteration 22018 => Loss: 48.16346509230832140247\n",
      "Iteration 22019 => Loss: 48.16328753680900831569\n",
      "Iteration 22020 => Loss: 48.16310998270314769343\n",
      "Iteration 22021 => Loss: 48.16293242999071111399\n",
      "Iteration 22022 => Loss: 48.16275487867169857736\n",
      "Iteration 22023 => Loss: 48.16257732874612429441\n",
      "Iteration 22024 => Loss: 48.16239978021392431629\n",
      "Iteration 22025 => Loss: 48.16222223307513417012\n",
      "Iteration 22026 => Loss: 48.16204468732971122336\n",
      "Iteration 22027 => Loss: 48.16186714297764837056\n",
      "Iteration 22028 => Loss: 48.16168960001897403345\n",
      "Iteration 22029 => Loss: 48.16151205845361715774\n",
      "Iteration 22030 => Loss: 48.16133451828162748143\n",
      "Iteration 22031 => Loss: 48.16115697950295526653\n",
      "Iteration 22032 => Loss: 48.16097944211757209132\n",
      "Iteration 22033 => Loss: 48.16080190612552058838\n",
      "Iteration 22034 => Loss: 48.16062437152674391427\n",
      "Iteration 22035 => Loss: 48.16044683832126338530\n",
      "Iteration 22036 => Loss: 48.16026930650904347431\n",
      "Iteration 22037 => Loss: 48.16009177609009839216\n",
      "Iteration 22038 => Loss: 48.15991424706438550629\n",
      "Iteration 22039 => Loss: 48.15973671943191902756\n",
      "Iteration 22040 => Loss: 48.15955919319268474510\n",
      "Iteration 22041 => Loss: 48.15938166834666134264\n",
      "Iteration 22042 => Loss: 48.15920414489384171475\n",
      "Iteration 22043 => Loss: 48.15902662283423296685\n",
      "Iteration 22044 => Loss: 48.15884910216778536096\n",
      "Iteration 22045 => Loss: 48.15867158289452731879\n",
      "Iteration 22046 => Loss: 48.15849406501443041861\n",
      "Iteration 22047 => Loss: 48.15831654852745913331\n",
      "Iteration 22048 => Loss: 48.15813903343364899001\n",
      "Iteration 22049 => Loss: 48.15796151973296446158\n",
      "Iteration 22050 => Loss: 48.15778400742539844259\n",
      "Iteration 22051 => Loss: 48.15760649651095803847\n",
      "Iteration 22052 => Loss: 48.15742898698957930037\n",
      "Iteration 22053 => Loss: 48.15725147886131196628\n",
      "Iteration 22054 => Loss: 48.15707397212611340365\n",
      "Iteration 22055 => Loss: 48.15689646678396229618\n",
      "Iteration 22056 => Loss: 48.15671896283487285473\n",
      "Iteration 22057 => Loss: 48.15654146027883797387\n",
      "Iteration 22058 => Loss: 48.15636395911582212648\n",
      "Iteration 22059 => Loss: 48.15618645934583952339\n",
      "Iteration 22060 => Loss: 48.15600896096885463749\n",
      "Iteration 22061 => Loss: 48.15583146398485325790\n",
      "Iteration 22062 => Loss: 48.15565396839385670091\n",
      "Iteration 22063 => Loss: 48.15547647419583654482\n",
      "Iteration 22064 => Loss: 48.15529898139077857877\n",
      "Iteration 22065 => Loss: 48.15512148997868990818\n",
      "Iteration 22066 => Loss: 48.15494399995950658422\n",
      "Iteration 22067 => Loss: 48.15476651133329255572\n",
      "Iteration 22068 => Loss: 48.15458902409998387384\n",
      "Iteration 22069 => Loss: 48.15441153825958053858\n",
      "Iteration 22070 => Loss: 48.15423405381206833908\n",
      "Iteration 22071 => Loss: 48.15405657075747569706\n",
      "Iteration 22072 => Loss: 48.15387908909575287453\n",
      "Iteration 22073 => Loss: 48.15370160882687855519\n",
      "Iteration 22074 => Loss: 48.15352412995087405534\n",
      "Iteration 22075 => Loss: 48.15334665246770384783\n",
      "Iteration 22076 => Loss: 48.15316917637737503810\n",
      "Iteration 22077 => Loss: 48.15299170167986630986\n",
      "Iteration 22078 => Loss: 48.15281422837517766311\n",
      "Iteration 22079 => Loss: 48.15263675646328067614\n",
      "Iteration 22080 => Loss: 48.15245928594416824353\n",
      "Iteration 22081 => Loss: 48.15228181681785457613\n",
      "Iteration 22082 => Loss: 48.15210434908428993594\n",
      "Iteration 22083 => Loss: 48.15192688274349563926\n",
      "Iteration 22084 => Loss: 48.15174941779544326437\n",
      "Iteration 22085 => Loss: 48.15157195424013991669\n",
      "Iteration 22086 => Loss: 48.15139449207754296367\n",
      "Iteration 22087 => Loss: 48.15121703130767372159\n",
      "Iteration 22088 => Loss: 48.15103957193047534702\n",
      "Iteration 22089 => Loss: 48.15086211394601889424\n",
      "Iteration 22090 => Loss: 48.15068465735418357099\n",
      "Iteration 22091 => Loss: 48.15050720215506174782\n",
      "Iteration 22092 => Loss: 48.15032974834859658131\n",
      "Iteration 22093 => Loss: 48.15015229593475964975\n",
      "Iteration 22094 => Loss: 48.14997484491359358572\n",
      "Iteration 22095 => Loss: 48.14979739528502022949\n",
      "Iteration 22096 => Loss: 48.14961994704906800280\n",
      "Iteration 22097 => Loss: 48.14944250020572980020\n",
      "Iteration 22098 => Loss: 48.14926505475497719999\n",
      "Iteration 22099 => Loss: 48.14908761069681730760\n",
      "Iteration 22100 => Loss: 48.14891016803122170131\n",
      "Iteration 22101 => Loss: 48.14873272675820459199\n",
      "Iteration 22102 => Loss: 48.14855528687769492535\n",
      "Iteration 22103 => Loss: 48.14837784838974954482\n",
      "Iteration 22104 => Loss: 48.14820041129434713412\n",
      "Iteration 22105 => Loss: 48.14802297559145216610\n",
      "Iteration 22106 => Loss: 48.14784554128106464077\n",
      "Iteration 22107 => Loss: 48.14766810836314903099\n",
      "Iteration 22108 => Loss: 48.14749067683771954762\n",
      "Iteration 22109 => Loss: 48.14731324670478329608\n",
      "Iteration 22110 => Loss: 48.14713581796432606552\n",
      "Iteration 22111 => Loss: 48.14695839061629101252\n",
      "Iteration 22112 => Loss: 48.14678096466069234793\n",
      "Iteration 22113 => Loss: 48.14660354009755138804\n",
      "Iteration 22114 => Loss: 48.14642611692679707858\n",
      "Iteration 22115 => Loss: 48.14624869514847205210\n",
      "Iteration 22116 => Loss: 48.14607127476254078147\n",
      "Iteration 22117 => Loss: 48.14589385576897484498\n",
      "Iteration 22118 => Loss: 48.14571643816781687519\n",
      "Iteration 22119 => Loss: 48.14553902195899581784\n",
      "Iteration 22120 => Loss: 48.14536160714253298920\n",
      "Iteration 22121 => Loss: 48.14518419371843549470\n",
      "Iteration 22122 => Loss: 48.14500678168665359635\n",
      "Iteration 22123 => Loss: 48.14482937104720150501\n",
      "Iteration 22124 => Loss: 48.14465196180003658810\n",
      "Iteration 22125 => Loss: 48.14447455394516595106\n",
      "Iteration 22126 => Loss: 48.14429714748258959389\n",
      "Iteration 22127 => Loss: 48.14411974241232172744\n",
      "Iteration 22128 => Loss: 48.14394233873429840287\n",
      "Iteration 22129 => Loss: 48.14376493644851251474\n",
      "Iteration 22130 => Loss: 48.14358753555499248478\n",
      "Iteration 22131 => Loss: 48.14341013605369568040\n",
      "Iteration 22132 => Loss: 48.14323273794461499620\n",
      "Iteration 22133 => Loss: 48.14305534122776464301\n",
      "Iteration 22134 => Loss: 48.14287794590308777742\n",
      "Iteration 22135 => Loss: 48.14270055197061992658\n",
      "Iteration 22136 => Loss: 48.14252315943033977419\n",
      "Iteration 22137 => Loss: 48.14234576828220468769\n",
      "Iteration 22138 => Loss: 48.14216837852623598337\n",
      "Iteration 22139 => Loss: 48.14199099016240523952\n",
      "Iteration 22140 => Loss: 48.14181360319071956155\n",
      "Iteration 22141 => Loss: 48.14163621761115763320\n",
      "Iteration 22142 => Loss: 48.14145883342369813818\n",
      "Iteration 22143 => Loss: 48.14128145062834107648\n",
      "Iteration 22144 => Loss: 48.14110406922508644811\n",
      "Iteration 22145 => Loss: 48.14092668921389872594\n",
      "Iteration 22146 => Loss: 48.14074931059480633166\n",
      "Iteration 22147 => Loss: 48.14057193336774531645\n",
      "Iteration 22148 => Loss: 48.14039455753272278571\n",
      "Iteration 22149 => Loss: 48.14021718308976716116\n",
      "Iteration 22150 => Loss: 48.14003981003880738854\n",
      "Iteration 22151 => Loss: 48.13986243837988610039\n",
      "Iteration 22152 => Loss: 48.13968506811296066417\n",
      "Iteration 22153 => Loss: 48.13950769923801686900\n",
      "Iteration 22154 => Loss: 48.13933033175506892576\n",
      "Iteration 22155 => Loss: 48.13915296566409551815\n",
      "Iteration 22156 => Loss: 48.13897560096506111904\n",
      "Iteration 22157 => Loss: 48.13879823765797283386\n",
      "Iteration 22158 => Loss: 48.13862087574285197888\n",
      "Iteration 22159 => Loss: 48.13844351521963460527\n",
      "Iteration 22160 => Loss: 48.13826615608833492388\n",
      "Iteration 22161 => Loss: 48.13808879834896004013\n",
      "Iteration 22162 => Loss: 48.13791144200146021603\n",
      "Iteration 22163 => Loss: 48.13773408704584255702\n",
      "Iteration 22164 => Loss: 48.13755673348209995766\n",
      "Iteration 22165 => Loss: 48.13737938131023241795\n",
      "Iteration 22166 => Loss: 48.13720203053020441075\n",
      "Iteration 22167 => Loss: 48.13702468114200883065\n",
      "Iteration 22168 => Loss: 48.13684733314565988849\n",
      "Iteration 22169 => Loss: 48.13666998654112205713\n",
      "Iteration 22170 => Loss: 48.13649264132837402030\n",
      "Iteration 22171 => Loss: 48.13631529750744419971\n",
      "Iteration 22172 => Loss: 48.13613795507830417364\n",
      "Iteration 22173 => Loss: 48.13596061404090420410\n",
      "Iteration 22174 => Loss: 48.13578327439529402909\n",
      "Iteration 22175 => Loss: 48.13560593614143101604\n",
      "Iteration 22176 => Loss: 48.13542859927930805952\n",
      "Iteration 22177 => Loss: 48.13525126380891094868\n",
      "Iteration 22178 => Loss: 48.13507392973023968352\n",
      "Iteration 22179 => Loss: 48.13489659704328005319\n",
      "Iteration 22180 => Loss: 48.13471926574800363596\n",
      "Iteration 22181 => Loss: 48.13454193584443174814\n",
      "Iteration 22182 => Loss: 48.13436460733253596800\n",
      "Iteration 22183 => Loss: 48.13418728021228076841\n",
      "Iteration 22184 => Loss: 48.13400995448372299279\n",
      "Iteration 22185 => Loss: 48.13383263014674895430\n",
      "Iteration 22186 => Loss: 48.13365530720145102350\n",
      "Iteration 22187 => Loss: 48.13347798564775104069\n",
      "Iteration 22188 => Loss: 48.13330066548567742757\n",
      "Iteration 22189 => Loss: 48.13312334671520176244\n",
      "Iteration 22190 => Loss: 48.13294602933630272901\n",
      "Iteration 22191 => Loss: 48.13276871334900164356\n",
      "Iteration 22192 => Loss: 48.13259139875324166269\n",
      "Iteration 22193 => Loss: 48.13241408554905120809\n",
      "Iteration 22194 => Loss: 48.13223677373640185806\n",
      "Iteration 22195 => Loss: 48.13205946331527940174\n",
      "Iteration 22196 => Loss: 48.13188215428568383913\n",
      "Iteration 22197 => Loss: 48.13170484664761517024\n",
      "Iteration 22198 => Loss: 48.13152754040104497335\n",
      "Iteration 22199 => Loss: 48.13135023554594482675\n",
      "Iteration 22200 => Loss: 48.13117293208234315216\n",
      "Iteration 22201 => Loss: 48.13099563001020442243\n",
      "Iteration 22202 => Loss: 48.13081832932952153215\n",
      "Iteration 22203 => Loss: 48.13064103004029448130\n",
      "Iteration 22204 => Loss: 48.13046373214249484818\n",
      "Iteration 22205 => Loss: 48.13028643563609421108\n",
      "Iteration 22206 => Loss: 48.13010914052114230799\n",
      "Iteration 22207 => Loss: 48.12993184679757519007\n",
      "Iteration 22208 => Loss: 48.12975455446539996274\n",
      "Iteration 22209 => Loss: 48.12957726352462373143\n",
      "Iteration 22210 => Loss: 48.12939997397521096900\n",
      "Iteration 22211 => Loss: 48.12922268581714746460\n",
      "Iteration 22212 => Loss: 48.12904539905044742909\n",
      "Iteration 22213 => Loss: 48.12886811367506822990\n",
      "Iteration 22214 => Loss: 48.12869082969101697245\n",
      "Iteration 22215 => Loss: 48.12851354709828655132\n",
      "Iteration 22216 => Loss: 48.12833626589685565023\n",
      "Iteration 22217 => Loss: 48.12815898608671005832\n",
      "Iteration 22218 => Loss: 48.12798170766786398644\n",
      "Iteration 22219 => Loss: 48.12780443064029611833\n",
      "Iteration 22220 => Loss: 48.12762715500396382140\n",
      "Iteration 22221 => Loss: 48.12744988075890262280\n",
      "Iteration 22222 => Loss: 48.12727260790507699539\n",
      "Iteration 22223 => Loss: 48.12709533644247272832\n",
      "Iteration 22224 => Loss: 48.12691806637108982159\n",
      "Iteration 22225 => Loss: 48.12674079769092116976\n",
      "Iteration 22226 => Loss: 48.12656353040192414028\n",
      "Iteration 22227 => Loss: 48.12638626450412715485\n",
      "Iteration 22228 => Loss: 48.12620899999750179177\n",
      "Iteration 22229 => Loss: 48.12603173688202673475\n",
      "Iteration 22230 => Loss: 48.12585447515772330007\n",
      "Iteration 22231 => Loss: 48.12567721482454885518\n",
      "Iteration 22232 => Loss: 48.12549995588251761092\n",
      "Iteration 22233 => Loss: 48.12532269833160114558\n",
      "Iteration 22234 => Loss: 48.12514544217177103747\n",
      "Iteration 22235 => Loss: 48.12496818740306281370\n",
      "Iteration 22236 => Loss: 48.12479093402542673630\n",
      "Iteration 22237 => Loss: 48.12461368203887701611\n",
      "Iteration 22238 => Loss: 48.12443643144337102058\n",
      "Iteration 22239 => Loss: 48.12425918223894427683\n",
      "Iteration 22240 => Loss: 48.12408193442555415231\n",
      "Iteration 22241 => Loss: 48.12390468800317933074\n",
      "Iteration 22242 => Loss: 48.12372744297184823381\n",
      "Iteration 22243 => Loss: 48.12355019933151112355\n",
      "Iteration 22244 => Loss: 48.12337295708216089452\n",
      "Iteration 22245 => Loss: 48.12319571622381175757\n",
      "Iteration 22246 => Loss: 48.12301847675643529101\n",
      "Iteration 22247 => Loss: 48.12284123868004570568\n",
      "Iteration 22248 => Loss: 48.12266400199460036902\n",
      "Iteration 22249 => Loss: 48.12248676670009217560\n",
      "Iteration 22250 => Loss: 48.12230953279652112542\n",
      "Iteration 22251 => Loss: 48.12213230028386590220\n",
      "Iteration 22252 => Loss: 48.12195506916213361137\n",
      "Iteration 22253 => Loss: 48.12177783943128872579\n",
      "Iteration 22254 => Loss: 48.12160061109134545632\n",
      "Iteration 22255 => Loss: 48.12142338414227538124\n",
      "Iteration 22256 => Loss: 48.12124615858407850055\n",
      "Iteration 22257 => Loss: 48.12106893441674060341\n",
      "Iteration 22258 => Loss: 48.12089171164021905724\n",
      "Iteration 22259 => Loss: 48.12071449025456360005\n",
      "Iteration 22260 => Loss: 48.12053727025971738840\n",
      "Iteration 22261 => Loss: 48.12036005165568042230\n",
      "Iteration 22262 => Loss: 48.12018283444245270175\n",
      "Iteration 22263 => Loss: 48.12000561862003422675\n",
      "Iteration 22264 => Loss: 48.11982840418837525931\n",
      "Iteration 22265 => Loss: 48.11965119114748290485\n",
      "Iteration 22266 => Loss: 48.11947397949737847966\n",
      "Iteration 22267 => Loss: 48.11929676923800514032\n",
      "Iteration 22268 => Loss: 48.11911956036936288683\n",
      "Iteration 22269 => Loss: 48.11894235289143750833\n",
      "Iteration 22270 => Loss: 48.11876514680423611026\n",
      "Iteration 22271 => Loss: 48.11858794210775869260\n",
      "Iteration 22272 => Loss: 48.11841073880194841195\n",
      "Iteration 22273 => Loss: 48.11823353688683369001\n",
      "Iteration 22274 => Loss: 48.11805633636237899964\n",
      "Iteration 22275 => Loss: 48.11787913722859144627\n",
      "Iteration 22276 => Loss: 48.11770193948545681906\n",
      "Iteration 22277 => Loss: 48.11752474313294669628\n",
      "Iteration 22278 => Loss: 48.11734754817108239422\n",
      "Iteration 22279 => Loss: 48.11717035459982128032\n",
      "Iteration 22280 => Loss: 48.11699316241917046000\n",
      "Iteration 22281 => Loss: 48.11681597162911572241\n",
      "Iteration 22282 => Loss: 48.11663878222964996212\n",
      "Iteration 22283 => Loss: 48.11646159422075896828\n",
      "Iteration 22284 => Loss: 48.11628440760240010832\n",
      "Iteration 22285 => Loss: 48.11610722237461601480\n",
      "Iteration 22286 => Loss: 48.11593003853737826603\n",
      "Iteration 22287 => Loss: 48.11575285609065133485\n",
      "Iteration 22288 => Loss: 48.11557567503445653756\n",
      "Iteration 22289 => Loss: 48.11539849536878676872\n",
      "Iteration 22290 => Loss: 48.11522131709358518492\n",
      "Iteration 22291 => Loss: 48.11504414020887310244\n",
      "Iteration 22292 => Loss: 48.11486696471464341585\n",
      "Iteration 22293 => Loss: 48.11468979061087480886\n",
      "Iteration 22294 => Loss: 48.11451261789756728149\n",
      "Iteration 22295 => Loss: 48.11433544657469241201\n",
      "Iteration 22296 => Loss: 48.11415827664225730587\n",
      "Iteration 22297 => Loss: 48.11398110810024064676\n",
      "Iteration 22298 => Loss: 48.11380394094862111842\n",
      "Iteration 22299 => Loss: 48.11362677518739872085\n",
      "Iteration 22300 => Loss: 48.11344961081657345403\n",
      "Iteration 22301 => Loss: 48.11327244783613110712\n",
      "Iteration 22302 => Loss: 48.11309528624605746927\n",
      "Iteration 22303 => Loss: 48.11291812604632411876\n",
      "Iteration 22304 => Loss: 48.11274096723693816102\n",
      "Iteration 22305 => Loss: 48.11256380981787827977\n",
      "Iteration 22306 => Loss: 48.11238665378915868587\n",
      "Iteration 22307 => Loss: 48.11220949915072964131\n",
      "Iteration 22308 => Loss: 48.11203234590261246240\n",
      "Iteration 22309 => Loss: 48.11185519404479293826\n",
      "Iteration 22310 => Loss: 48.11167804357723554176\n",
      "Iteration 22311 => Loss: 48.11150089449994737834\n",
      "Iteration 22312 => Loss: 48.11132374681294265883\n",
      "Iteration 22313 => Loss: 48.11114660051616453984\n",
      "Iteration 22314 => Loss: 48.11096945560959170507\n",
      "Iteration 22315 => Loss: 48.11079231209327389251\n",
      "Iteration 22316 => Loss: 48.11061516996717557504\n",
      "Iteration 22317 => Loss: 48.11043802923127543636\n",
      "Iteration 22318 => Loss: 48.11026088988554505477\n",
      "Iteration 22319 => Loss: 48.11008375193001995740\n",
      "Iteration 22320 => Loss: 48.10990661536465040626\n",
      "Iteration 22321 => Loss: 48.10972948018944350679\n",
      "Iteration 22322 => Loss: 48.10955234640437794269\n",
      "Iteration 22323 => Loss: 48.10937521400945371397\n",
      "Iteration 22324 => Loss: 48.10919808300464239892\n",
      "Iteration 22325 => Loss: 48.10902095338997952467\n",
      "Iteration 22326 => Loss: 48.10884382516540114239\n",
      "Iteration 22327 => Loss: 48.10866669833091435748\n",
      "Iteration 22328 => Loss: 48.10848957288650495911\n",
      "Iteration 22329 => Loss: 48.10831244883217294728\n",
      "Iteration 22330 => Loss: 48.10813532616790411112\n",
      "Iteration 22331 => Loss: 48.10795820489367002892\n",
      "Iteration 22332 => Loss: 48.10778108500948491155\n",
      "Iteration 22333 => Loss: 48.10760396651534875900\n",
      "Iteration 22334 => Loss: 48.10742684941120472786\n",
      "Iteration 22335 => Loss: 48.10724973369705992354\n",
      "Iteration 22336 => Loss: 48.10707261937292145149\n",
      "Iteration 22337 => Loss: 48.10689550643876088998\n",
      "Iteration 22338 => Loss: 48.10671839489457113359\n",
      "Iteration 22339 => Loss: 48.10654128474036639318\n",
      "Iteration 22340 => Loss: 48.10636417597608982533\n",
      "Iteration 22341 => Loss: 48.10618706860176274631\n",
      "Iteration 22342 => Loss: 48.10600996261734252357\n",
      "Iteration 22343 => Loss: 48.10583285802288600053\n",
      "Iteration 22344 => Loss: 48.10565575481831501747\n",
      "Iteration 22345 => Loss: 48.10547865300363667984\n",
      "Iteration 22346 => Loss: 48.10530155257883677677\n",
      "Iteration 22347 => Loss: 48.10512445354392241370\n",
      "Iteration 22348 => Loss: 48.10494735589885806348\n",
      "Iteration 22349 => Loss: 48.10477025964366504240\n",
      "Iteration 22350 => Loss: 48.10459316477830782333\n",
      "Iteration 22351 => Loss: 48.10441607130277930082\n",
      "Iteration 22352 => Loss: 48.10423897921705815861\n",
      "Iteration 22353 => Loss: 48.10406188852116571297\n",
      "Iteration 22354 => Loss: 48.10388479921508064763\n",
      "Iteration 22355 => Loss: 48.10370771129876743544\n",
      "Iteration 22356 => Loss: 48.10353062477222607640\n",
      "Iteration 22357 => Loss: 48.10335353963545657052\n",
      "Iteration 22358 => Loss: 48.10317645588844470694\n",
      "Iteration 22359 => Loss: 48.10299937353116916938\n",
      "Iteration 22360 => Loss: 48.10282229256364416869\n",
      "Iteration 22361 => Loss: 48.10264521298581286146\n",
      "Iteration 22362 => Loss: 48.10246813479773209110\n",
      "Iteration 22363 => Loss: 48.10229105799930238163\n",
      "Iteration 22364 => Loss: 48.10211398259060189275\n",
      "Iteration 22365 => Loss: 48.10193690857155246476\n",
      "Iteration 22366 => Loss: 48.10175983594218962480\n",
      "Iteration 22367 => Loss: 48.10158276470247784573\n",
      "Iteration 22368 => Loss: 48.10140569485241712755\n",
      "Iteration 22369 => Loss: 48.10122862639197904855\n",
      "Iteration 22370 => Loss: 48.10105155932117781958\n",
      "Iteration 22371 => Loss: 48.10087449363997080809\n",
      "Iteration 22372 => Loss: 48.10069742934839354120\n",
      "Iteration 22373 => Loss: 48.10052036644638917551\n",
      "Iteration 22374 => Loss: 48.10034330493398613271\n",
      "Iteration 22375 => Loss: 48.10016624481111335854\n",
      "Iteration 22376 => Loss: 48.09998918607782059098\n",
      "Iteration 22377 => Loss: 48.09981212873407940833\n",
      "Iteration 22378 => Loss: 48.09963507277986849431\n",
      "Iteration 22379 => Loss: 48.09945801821519495434\n",
      "Iteration 22380 => Loss: 48.09928096504000194500\n",
      "Iteration 22381 => Loss: 48.09910391325436052057\n",
      "Iteration 22382 => Loss: 48.09892686285818541592\n",
      "Iteration 22383 => Loss: 48.09874981385149084190\n",
      "Iteration 22384 => Loss: 48.09857276623426969309\n",
      "Iteration 22385 => Loss: 48.09839572000652196948\n",
      "Iteration 22386 => Loss: 48.09821867516822635480\n",
      "Iteration 22387 => Loss: 48.09804163171934732190\n",
      "Iteration 22388 => Loss: 48.09786458965989908165\n",
      "Iteration 22389 => Loss: 48.09768754898988873947\n",
      "Iteration 22390 => Loss: 48.09751050970925234651\n",
      "Iteration 22391 => Loss: 48.09733347181804674619\n",
      "Iteration 22392 => Loss: 48.09715643531619377882\n",
      "Iteration 22393 => Loss: 48.09697940020375028780\n",
      "Iteration 22394 => Loss: 48.09680236648063100802\n",
      "Iteration 22395 => Loss: 48.09662533414688567746\n",
      "Iteration 22396 => Loss: 48.09644830320246455813\n",
      "Iteration 22397 => Loss: 48.09627127364737475546\n",
      "Iteration 22398 => Loss: 48.09609424548163048030\n",
      "Iteration 22399 => Loss: 48.09591721870515357296\n",
      "Iteration 22400 => Loss: 48.09574019331801508770\n",
      "Iteration 22401 => Loss: 48.09556316932012265397\n",
      "Iteration 22402 => Loss: 48.09538614671152600977\n",
      "Iteration 22403 => Loss: 48.09520912549220383880\n",
      "Iteration 22404 => Loss: 48.09503210566210640309\n",
      "Iteration 22405 => Loss: 48.09485508722128344061\n",
      "Iteration 22406 => Loss: 48.09467807016968521339\n",
      "Iteration 22407 => Loss: 48.09450105450729040513\n",
      "Iteration 22408 => Loss: 48.09432404023410612126\n",
      "Iteration 22409 => Loss: 48.09414702735011104551\n",
      "Iteration 22410 => Loss: 48.09397001585532649415\n",
      "Iteration 22411 => Loss: 48.09379300574972404547\n",
      "Iteration 22412 => Loss: 48.09361599703326817234\n",
      "Iteration 22413 => Loss: 48.09343898970598729647\n",
      "Iteration 22414 => Loss: 48.09326198376784589072\n",
      "Iteration 22415 => Loss: 48.09308497921882263881\n",
      "Iteration 22416 => Loss: 48.09290797605891754074\n",
      "Iteration 22417 => Loss: 48.09273097428813770193\n",
      "Iteration 22418 => Loss: 48.09255397390646180611\n",
      "Iteration 22419 => Loss: 48.09237697491387564241\n",
      "Iteration 22420 => Loss: 48.09219997731033657828\n",
      "Iteration 22421 => Loss: 48.09202298109591566799\n",
      "Iteration 22422 => Loss: 48.09184598627051343556\n",
      "Iteration 22423 => Loss: 48.09166899283417251354\n",
      "Iteration 22424 => Loss: 48.09149200078686448023\n",
      "Iteration 22425 => Loss: 48.09131501012858933564\n",
      "Iteration 22426 => Loss: 48.09113802085932576347\n",
      "Iteration 22427 => Loss: 48.09096103297905955287\n",
      "Iteration 22428 => Loss: 48.09078404648778359842\n",
      "Iteration 22429 => Loss: 48.09060706138549079469\n",
      "Iteration 22430 => Loss: 48.09043007767217403625\n",
      "Iteration 22431 => Loss: 48.09025309534780490139\n",
      "Iteration 22432 => Loss: 48.09007611441238339012\n",
      "Iteration 22433 => Loss: 48.08989913486589529157\n",
      "Iteration 22434 => Loss: 48.08972215670834060575\n",
      "Iteration 22435 => Loss: 48.08954517993969091094\n",
      "Iteration 22436 => Loss: 48.08936820455997462886\n",
      "Iteration 22437 => Loss: 48.08919123056911359981\n",
      "Iteration 22438 => Loss: 48.08901425796717177263\n",
      "Iteration 22439 => Loss: 48.08883728675408519848\n",
      "Iteration 22440 => Loss: 48.08866031692985387735\n",
      "Iteration 22441 => Loss: 48.08848334849447780925\n",
      "Iteration 22442 => Loss: 48.08830638144794278332\n",
      "Iteration 22443 => Loss: 48.08812941579023458871\n",
      "Iteration 22444 => Loss: 48.08795245152133901456\n",
      "Iteration 22445 => Loss: 48.08777548864124185002\n",
      "Iteration 22446 => Loss: 48.08759852714995020051\n",
      "Iteration 22447 => Loss: 48.08742156704744274975\n",
      "Iteration 22448 => Loss: 48.08724460833371239232\n",
      "Iteration 22449 => Loss: 48.08706765100875202279\n",
      "Iteration 22450 => Loss: 48.08689069507252611402\n",
      "Iteration 22451 => Loss: 48.08671374052504887686\n",
      "Iteration 22452 => Loss: 48.08653678736629899504\n",
      "Iteration 22453 => Loss: 48.08635983559627646855\n",
      "Iteration 22454 => Loss: 48.08618288521495287569\n",
      "Iteration 22455 => Loss: 48.08600593622232821645\n",
      "Iteration 22456 => Loss: 48.08582898861839538540\n",
      "Iteration 22457 => Loss: 48.08565204240312596085\n",
      "Iteration 22458 => Loss: 48.08547509757652704820\n",
      "Iteration 22459 => Loss: 48.08529815413859154205\n",
      "Iteration 22460 => Loss: 48.08512121208927680982\n",
      "Iteration 22461 => Loss: 48.08494427142862548408\n",
      "Iteration 22462 => Loss: 48.08476733215657361598\n",
      "Iteration 22463 => Loss: 48.08459039427313541637\n",
      "Iteration 22464 => Loss: 48.08441345777829667441\n",
      "Iteration 22465 => Loss: 48.08423652267205028465\n",
      "Iteration 22466 => Loss: 48.08405958895438203626\n",
      "Iteration 22467 => Loss: 48.08388265662527061295\n",
      "Iteration 22468 => Loss: 48.08370572568471601471\n",
      "Iteration 22469 => Loss: 48.08352879613271824155\n",
      "Iteration 22470 => Loss: 48.08335186796924176633\n",
      "Iteration 22471 => Loss: 48.08317494119430079991\n",
      "Iteration 22472 => Loss: 48.08299801580786692057\n",
      "Iteration 22473 => Loss: 48.08282109180992591746\n",
      "Iteration 22474 => Loss: 48.08264416920047068515\n",
      "Iteration 22475 => Loss: 48.08246724797951543451\n",
      "Iteration 22476 => Loss: 48.08229032814701042753\n",
      "Iteration 22477 => Loss: 48.08211340970295566422\n",
      "Iteration 22478 => Loss: 48.08193649264737246085\n",
      "Iteration 22479 => Loss: 48.08175957698022529030\n",
      "Iteration 22480 => Loss: 48.08158266270147151999\n",
      "Iteration 22481 => Loss: 48.08140574981116799336\n",
      "Iteration 22482 => Loss: 48.08122883830925076154\n",
      "Iteration 22483 => Loss: 48.08105192819571982454\n",
      "Iteration 22484 => Loss: 48.08087501947058228779\n",
      "Iteration 22485 => Loss: 48.08069811213381683501\n",
      "Iteration 22486 => Loss: 48.08052120618539504449\n",
      "Iteration 22487 => Loss: 48.08034430162533823250\n",
      "Iteration 22488 => Loss: 48.08016739845361087191\n",
      "Iteration 22489 => Loss: 48.07999049667021296273\n",
      "Iteration 22490 => Loss: 48.07981359627512318866\n",
      "Iteration 22491 => Loss: 48.07963669726834865514\n",
      "Iteration 22492 => Loss: 48.07945979964984672961\n",
      "Iteration 22493 => Loss: 48.07928290341965293919\n",
      "Iteration 22494 => Loss: 48.07910600857773175676\n",
      "Iteration 22495 => Loss: 48.07892911512404765517\n",
      "Iteration 22496 => Loss: 48.07875222305863616157\n",
      "Iteration 22497 => Loss: 48.07857533238145464338\n",
      "Iteration 22498 => Loss: 48.07839844309250310062\n",
      "Iteration 22499 => Loss: 48.07822155519178863869\n",
      "Iteration 22500 => Loss: 48.07804466867924730877\n",
      "Iteration 22501 => Loss: 48.07786778355493595427\n",
      "Iteration 22502 => Loss: 48.07769089981877641549\n",
      "Iteration 22503 => Loss: 48.07751401747081132498\n",
      "Iteration 22504 => Loss: 48.07733713651101936648\n",
      "Iteration 22505 => Loss: 48.07716025693935080199\n",
      "Iteration 22506 => Loss: 48.07698337875584115864\n",
      "Iteration 22507 => Loss: 48.07680650196046201472\n",
      "Iteration 22508 => Loss: 48.07662962655321337024\n",
      "Iteration 22509 => Loss: 48.07645275253403838178\n",
      "Iteration 22510 => Loss: 48.07627587990298678733\n",
      "Iteration 22511 => Loss: 48.07609900866001595432\n",
      "Iteration 22512 => Loss: 48.07592213880513298818\n",
      "Iteration 22513 => Loss: 48.07574527033831657263\n",
      "Iteration 22514 => Loss: 48.07556840325953118054\n",
      "Iteration 22515 => Loss: 48.07539153756882654989\n",
      "Iteration 22516 => Loss: 48.07521467326611741555\n",
      "Iteration 22517 => Loss: 48.07503781035143930467\n",
      "Iteration 22518 => Loss: 48.07486094882477090096\n",
      "Iteration 22519 => Loss: 48.07468408868611930984\n",
      "Iteration 22520 => Loss: 48.07450722993545610962\n",
      "Iteration 22521 => Loss: 48.07433037257274577314\n",
      "Iteration 22522 => Loss: 48.07415351659802382756\n",
      "Iteration 22523 => Loss: 48.07397666201124764029\n",
      "Iteration 22524 => Loss: 48.07379980881241010593\n",
      "Iteration 22525 => Loss: 48.07362295700151832989\n",
      "Iteration 22526 => Loss: 48.07344610657855810132\n",
      "Iteration 22527 => Loss: 48.07326925754350099851\n",
      "Iteration 22528 => Loss: 48.07309240989633991603\n",
      "Iteration 22529 => Loss: 48.07291556363708195931\n",
      "Iteration 22530 => Loss: 48.07273871876570581207\n",
      "Iteration 22531 => Loss: 48.07256187528216884175\n",
      "Iteration 22532 => Loss: 48.07238503318652789176\n",
      "Iteration 22533 => Loss: 48.07220819247872611868\n",
      "Iteration 22534 => Loss: 48.07203135315874220623\n",
      "Iteration 22535 => Loss: 48.07185451522660457613\n",
      "Iteration 22536 => Loss: 48.07167767868226349037\n",
      "Iteration 22537 => Loss: 48.07150084352575447610\n",
      "Iteration 22538 => Loss: 48.07132400975700647905\n",
      "Iteration 22539 => Loss: 48.07114717737606923720\n",
      "Iteration 22540 => Loss: 48.07097034638289301256\n",
      "Iteration 22541 => Loss: 48.07079351677746359428\n",
      "Iteration 22542 => Loss: 48.07061668855981650950\n",
      "Iteration 22543 => Loss: 48.07043986172986649308\n",
      "Iteration 22544 => Loss: 48.07026303628764907216\n",
      "Iteration 22545 => Loss: 48.07008621223318556304\n",
      "Iteration 22546 => Loss: 48.06990938956638359514\n",
      "Iteration 22547 => Loss: 48.06973256828730711732\n",
      "Iteration 22548 => Loss: 48.06955574839590639158\n",
      "Iteration 22549 => Loss: 48.06937892989216010164\n",
      "Iteration 22550 => Loss: 48.06920211277609666922\n",
      "Iteration 22551 => Loss: 48.06902529704767346175\n",
      "Iteration 22552 => Loss: 48.06884848270691890093\n",
      "Iteration 22553 => Loss: 48.06867166975374772164\n",
      "Iteration 22554 => Loss: 48.06849485818825939987\n",
      "Iteration 22555 => Loss: 48.06831804801032603791\n",
      "Iteration 22556 => Loss: 48.06814123922000447919\n",
      "Iteration 22557 => Loss: 48.06796443181726630201\n",
      "Iteration 22558 => Loss: 48.06778762580211861177\n",
      "Iteration 22559 => Loss: 48.06761082117451167051\n",
      "Iteration 22560 => Loss: 48.06743401793446679449\n",
      "Iteration 22561 => Loss: 48.06725721608196266743\n",
      "Iteration 22562 => Loss: 48.06708041561699928934\n",
      "Iteration 22563 => Loss: 48.06690361653954823851\n",
      "Iteration 22564 => Loss: 48.06672681884958819865\n",
      "Iteration 22565 => Loss: 48.06655002254716180232\n",
      "Iteration 22566 => Loss: 48.06637322763220510069\n",
      "Iteration 22567 => Loss: 48.06619643410474651546\n",
      "Iteration 22568 => Loss: 48.06601964196473630864\n",
      "Iteration 22569 => Loss: 48.06584285121218158565\n",
      "Iteration 22570 => Loss: 48.06566606184706813565\n",
      "Iteration 22571 => Loss: 48.06548927386940306405\n",
      "Iteration 22572 => Loss: 48.06531248727914373831\n",
      "Iteration 22573 => Loss: 48.06513570207630436926\n",
      "Iteration 22574 => Loss: 48.06495891826087074605\n",
      "Iteration 22575 => Loss: 48.06478213583282155241\n",
      "Iteration 22576 => Loss: 48.06460535479216389376\n",
      "Iteration 22577 => Loss: 48.06442857513886224297\n",
      "Iteration 22578 => Loss: 48.06425179687290949460\n",
      "Iteration 22579 => Loss: 48.06407501999431275408\n",
      "Iteration 22580 => Loss: 48.06389824450305070513\n",
      "Iteration 22581 => Loss: 48.06372147039909492605\n",
      "Iteration 22582 => Loss: 48.06354469768247383854\n",
      "Iteration 22583 => Loss: 48.06336792635315902089\n",
      "Iteration 22584 => Loss: 48.06319115641112915682\n",
      "Iteration 22585 => Loss: 48.06301438785640556262\n",
      "Iteration 22586 => Loss: 48.06283762068891718400\n",
      "Iteration 22587 => Loss: 48.06266085490869954810\n",
      "Iteration 22588 => Loss: 48.06248409051572423323\n",
      "Iteration 22589 => Loss: 48.06230732750999123937\n",
      "Iteration 22590 => Loss: 48.06213056589147925024\n",
      "Iteration 22591 => Loss: 48.06195380566020247670\n",
      "Iteration 22592 => Loss: 48.06177704681611118076\n",
      "Iteration 22593 => Loss: 48.06160028935922667870\n",
      "Iteration 22594 => Loss: 48.06142353328952054881\n",
      "Iteration 22595 => Loss: 48.06124677860697858023\n",
      "Iteration 22596 => Loss: 48.06107002531162919468\n",
      "Iteration 22597 => Loss: 48.06089327340338712702\n",
      "Iteration 22598 => Loss: 48.06071652288230211525\n",
      "Iteration 22599 => Loss: 48.06053977374836705394\n",
      "Iteration 22600 => Loss: 48.06036302600152509967\n",
      "Iteration 22601 => Loss: 48.06018627964179756873\n",
      "Iteration 22602 => Loss: 48.06000953466915603940\n",
      "Iteration 22603 => Loss: 48.05983279108360761711\n",
      "Iteration 22604 => Loss: 48.05965604888515230186\n",
      "Iteration 22605 => Loss: 48.05947930807373325024\n",
      "Iteration 22606 => Loss: 48.05930256864938598937\n",
      "Iteration 22607 => Loss: 48.05912583061206788670\n",
      "Iteration 22608 => Loss: 48.05894909396176473138\n",
      "Iteration 22609 => Loss: 48.05877235869851915595\n",
      "Iteration 22610 => Loss: 48.05859562482226721158\n",
      "Iteration 22611 => Loss: 48.05841889233299468742\n",
      "Iteration 22612 => Loss: 48.05824216123072289975\n",
      "Iteration 22613 => Loss: 48.05806543151544474313\n",
      "Iteration 22614 => Loss: 48.05788870318709626872\n",
      "Iteration 22615 => Loss: 48.05771197624572010909\n",
      "Iteration 22616 => Loss: 48.05753525069130915881\n",
      "Iteration 22617 => Loss: 48.05735852652381367989\n",
      "Iteration 22618 => Loss: 48.05718180374322656689\n",
      "Iteration 22619 => Loss: 48.05700508234956203069\n",
      "Iteration 22620 => Loss: 48.05682836234279164955\n",
      "Iteration 22621 => Loss: 48.05665164372292963435\n",
      "Iteration 22622 => Loss: 48.05647492648991914166\n",
      "Iteration 22623 => Loss: 48.05629821064381701490\n",
      "Iteration 22624 => Loss: 48.05612149618452377808\n",
      "Iteration 22625 => Loss: 48.05594478311210338006\n",
      "Iteration 22626 => Loss: 48.05576807142652739913\n",
      "Iteration 22627 => Loss: 48.05559136112774609728\n",
      "Iteration 22628 => Loss: 48.05541465221578789624\n",
      "Iteration 22629 => Loss: 48.05523794469063858514\n",
      "Iteration 22630 => Loss: 48.05506123855228395314\n",
      "Iteration 22631 => Loss: 48.05488453380070978938\n",
      "Iteration 22632 => Loss: 48.05470783043588767214\n",
      "Iteration 22633 => Loss: 48.05453112845783891771\n",
      "Iteration 22634 => Loss: 48.05435442786654220981\n",
      "Iteration 22635 => Loss: 48.05417772866196202131\n",
      "Iteration 22636 => Loss: 48.05400103084413387933\n",
      "Iteration 22637 => Loss: 48.05382433441300094046\n",
      "Iteration 22638 => Loss: 48.05364763936857031013\n",
      "Iteration 22639 => Loss: 48.05347094571084198833\n",
      "Iteration 22640 => Loss: 48.05329425343981597507\n",
      "Iteration 22641 => Loss: 48.05311756255542832150\n",
      "Iteration 22642 => Loss: 48.05294087305772166019\n",
      "Iteration 22643 => Loss: 48.05276418494665335857\n",
      "Iteration 22644 => Loss: 48.05258749822223052206\n",
      "Iteration 22645 => Loss: 48.05241081288444604525\n",
      "Iteration 22646 => Loss: 48.05223412893326440098\n",
      "Iteration 22647 => Loss: 48.05205744636867848385\n",
      "Iteration 22648 => Loss: 48.05188076519070961012\n",
      "Iteration 22649 => Loss: 48.05170408539930804181\n",
      "Iteration 22650 => Loss: 48.05152740699450220063\n",
      "Iteration 22651 => Loss: 48.05135072997624234858\n",
      "Iteration 22652 => Loss: 48.05117405434452848567\n",
      "Iteration 22653 => Loss: 48.05099738009937482275\n",
      "Iteration 22654 => Loss: 48.05082070724072451640\n",
      "Iteration 22655 => Loss: 48.05064403576862730461\n",
      "Iteration 22656 => Loss: 48.05046736568301923853\n",
      "Iteration 22657 => Loss: 48.05029069698392163446\n",
      "Iteration 22658 => Loss: 48.05011402967129185981\n",
      "Iteration 22659 => Loss: 48.04993736374515833631\n",
      "Iteration 22660 => Loss: 48.04976069920546422054\n",
      "Iteration 22661 => Loss: 48.04958403605223793420\n",
      "Iteration 22662 => Loss: 48.04940737428545816101\n",
      "Iteration 22663 => Loss: 48.04923071390511069012\n",
      "Iteration 22664 => Loss: 48.04905405491117420524\n",
      "Iteration 22665 => Loss: 48.04887739730365581181\n",
      "Iteration 22666 => Loss: 48.04870074108255550982\n",
      "Iteration 22667 => Loss: 48.04852408624780935043\n",
      "Iteration 22668 => Loss: 48.04834743279944575534\n",
      "Iteration 22669 => Loss: 48.04817078073747893541\n",
      "Iteration 22670 => Loss: 48.04799413006183073094\n",
      "Iteration 22671 => Loss: 48.04781748077255087992\n",
      "Iteration 22672 => Loss: 48.04764083286959674979\n",
      "Iteration 22673 => Loss: 48.04746418635296834054\n",
      "Iteration 22674 => Loss: 48.04728754122266565219\n",
      "Iteration 22675 => Loss: 48.04711089747863184130\n",
      "Iteration 22676 => Loss: 48.04693425512093085672\n",
      "Iteration 22677 => Loss: 48.04675761414949164418\n",
      "Iteration 22678 => Loss: 48.04658097456430709826\n",
      "Iteration 22679 => Loss: 48.04640433636539853524\n",
      "Iteration 22680 => Loss: 48.04622769955273042797\n",
      "Iteration 22681 => Loss: 48.04605106412630277646\n",
      "Iteration 22682 => Loss: 48.04587443008608005357\n",
      "Iteration 22683 => Loss: 48.04569779743211910272\n",
      "Iteration 22684 => Loss: 48.04552116616431334251\n",
      "Iteration 22685 => Loss: 48.04534453628271961634\n",
      "Iteration 22686 => Loss: 48.04516790778730950251\n",
      "Iteration 22687 => Loss: 48.04499128067805457931\n",
      "Iteration 22688 => Loss: 48.04481465495499037388\n",
      "Iteration 22689 => Loss: 48.04463803061803162109\n",
      "Iteration 22690 => Loss: 48.04446140766725648064\n",
      "Iteration 22691 => Loss: 48.04428478610259389825\n",
      "Iteration 22692 => Loss: 48.04410816592403676850\n",
      "Iteration 22693 => Loss: 48.04393154713159219682\n",
      "Iteration 22694 => Loss: 48.04375492972523886692\n",
      "Iteration 22695 => Loss: 48.04357831370498388424\n",
      "Iteration 22696 => Loss: 48.04340169907077751077\n",
      "Iteration 22697 => Loss: 48.04322508582266948451\n",
      "Iteration 22698 => Loss: 48.04304847396061006748\n",
      "Iteration 22699 => Loss: 48.04287186348454952167\n",
      "Iteration 22700 => Loss: 48.04269525439454469051\n",
      "Iteration 22701 => Loss: 48.04251864669056715229\n",
      "Iteration 22702 => Loss: 48.04234204037258848530\n",
      "Iteration 22703 => Loss: 48.04216543544058737325\n",
      "Iteration 22704 => Loss: 48.04198883189458513243\n",
      "Iteration 22705 => Loss: 48.04181222973458886827\n",
      "Iteration 22706 => Loss: 48.04163562896050621021\n",
      "Iteration 22707 => Loss: 48.04145902957242242337\n",
      "Iteration 22708 => Loss: 48.04128243157025224264\n",
      "Iteration 22709 => Loss: 48.04110583495402408971\n",
      "Iteration 22710 => Loss: 48.04092923972372375374\n",
      "Iteration 22711 => Loss: 48.04075264587930860216\n",
      "Iteration 22712 => Loss: 48.04057605342082837296\n",
      "Iteration 22713 => Loss: 48.04039946234822622273\n",
      "Iteration 22714 => Loss: 48.04022287266146662432\n",
      "Iteration 22715 => Loss: 48.04004628436060642116\n",
      "Iteration 22716 => Loss: 48.03986969744560298068\n",
      "Iteration 22717 => Loss: 48.03969311191643498660\n",
      "Iteration 22718 => Loss: 48.03951652777308822806\n",
      "Iteration 22719 => Loss: 48.03933994501559112678\n",
      "Iteration 22720 => Loss: 48.03916336364389394475\n",
      "Iteration 22721 => Loss: 48.03898678365799668200\n",
      "Iteration 22722 => Loss: 48.03881020505789223307\n",
      "Iteration 22723 => Loss: 48.03863362784357349256\n",
      "Iteration 22724 => Loss: 48.03845705201501914416\n",
      "Iteration 22725 => Loss: 48.03828047757221497704\n",
      "Iteration 22726 => Loss: 48.03810390451514678034\n",
      "Iteration 22727 => Loss: 48.03792733284385008119\n",
      "Iteration 22728 => Loss: 48.03775076255826093075\n",
      "Iteration 22729 => Loss: 48.03757419365837222358\n",
      "Iteration 22730 => Loss: 48.03739762614421238140\n",
      "Iteration 22731 => Loss: 48.03722106001571745537\n",
      "Iteration 22732 => Loss: 48.03704449527293718347\n",
      "Iteration 22733 => Loss: 48.03686793191580051143\n",
      "Iteration 22734 => Loss: 48.03669136994434296639\n",
      "Iteration 22735 => Loss: 48.03651480935851481036\n",
      "Iteration 22736 => Loss: 48.03633825015833735961\n",
      "Iteration 22737 => Loss: 48.03616169234379640329\n",
      "Iteration 22738 => Loss: 48.03598513591484220342\n",
      "Iteration 22739 => Loss: 48.03580858087151739255\n",
      "Iteration 22740 => Loss: 48.03563202721376512727\n",
      "Iteration 22741 => Loss: 48.03545547494162093471\n",
      "Iteration 22742 => Loss: 48.03527892405503507689\n",
      "Iteration 22743 => Loss: 48.03510237455402176465\n",
      "Iteration 22744 => Loss: 48.03492582643853836544\n",
      "Iteration 22745 => Loss: 48.03474927970862751181\n",
      "Iteration 22746 => Loss: 48.03457273436422525492\n",
      "Iteration 22747 => Loss: 48.03439619040533870020\n",
      "Iteration 22748 => Loss: 48.03421964783199626936\n",
      "Iteration 22749 => Loss: 48.03404310664410559184\n",
      "Iteration 22750 => Loss: 48.03386656684171640563\n",
      "Iteration 22751 => Loss: 48.03369002842479318360\n",
      "Iteration 22752 => Loss: 48.03351349139335724203\n",
      "Iteration 22753 => Loss: 48.03333695574736594835\n",
      "Iteration 22754 => Loss: 48.03316042148679798629\n",
      "Iteration 22755 => Loss: 48.03298388861168888297\n",
      "Iteration 22756 => Loss: 48.03280735712198179499\n",
      "Iteration 22757 => Loss: 48.03263082701769093319\n",
      "Iteration 22758 => Loss: 48.03245429829880919215\n",
      "Iteration 22759 => Loss: 48.03227777096530104473\n",
      "Iteration 22760 => Loss: 48.03210124501715228007\n",
      "Iteration 22761 => Loss: 48.03192472045441974160\n",
      "Iteration 22762 => Loss: 48.03174819727701816419\n",
      "Iteration 22763 => Loss: 48.03157167548493333697\n",
      "Iteration 22764 => Loss: 48.03139515507821499796\n",
      "Iteration 22765 => Loss: 48.03121863605681340914\n",
      "Iteration 22766 => Loss: 48.03104211842072146510\n",
      "Iteration 22767 => Loss: 48.03086560216993916583\n",
      "Iteration 22768 => Loss: 48.03068908730443098420\n",
      "Iteration 22769 => Loss: 48.03051257382421113107\n",
      "Iteration 22770 => Loss: 48.03033606172925118472\n",
      "Iteration 22771 => Loss: 48.03015955101956535600\n",
      "Iteration 22772 => Loss: 48.02998304169512522321\n",
      "Iteration 22773 => Loss: 48.02980653375590947007\n",
      "Iteration 22774 => Loss: 48.02963002720190388573\n",
      "Iteration 22775 => Loss: 48.02945352203314399731\n",
      "Iteration 22776 => Loss: 48.02927701824957296139\n",
      "Iteration 22777 => Loss: 48.02910051585118367257\n",
      "Iteration 22778 => Loss: 48.02892401483799744710\n",
      "Iteration 22779 => Loss: 48.02874751520997875787\n",
      "Iteration 22780 => Loss: 48.02857101696708497229\n",
      "Iteration 22781 => Loss: 48.02839452010938714466\n",
      "Iteration 22782 => Loss: 48.02821802463680711526\n",
      "Iteration 22783 => Loss: 48.02804153054936620038\n",
      "Iteration 22784 => Loss: 48.02786503784701466202\n",
      "Iteration 22785 => Loss: 48.02768854652980223818\n",
      "Iteration 22786 => Loss: 48.02751205659766498002\n",
      "Iteration 22787 => Loss: 48.02733556805060999295\n",
      "Iteration 22788 => Loss: 48.02715908088863727698\n",
      "Iteration 22789 => Loss: 48.02698259511170419955\n",
      "Iteration 22790 => Loss: 48.02680611071984628779\n",
      "Iteration 22791 => Loss: 48.02662962771301380371\n",
      "Iteration 22792 => Loss: 48.02645314609122806360\n",
      "Iteration 22793 => Loss: 48.02627666585444643488\n",
      "Iteration 22794 => Loss: 48.02610018700269023384\n",
      "Iteration 22795 => Loss: 48.02592370953589551164\n",
      "Iteration 22796 => Loss: 48.02574723345411911168\n",
      "Iteration 22797 => Loss: 48.02557075875730419057\n",
      "Iteration 22798 => Loss: 48.02539428544545074828\n",
      "Iteration 22799 => Loss: 48.02521781351855167941\n",
      "Iteration 22800 => Loss: 48.02504134297660698394\n",
      "Iteration 22801 => Loss: 48.02486487381957402931\n",
      "Iteration 22802 => Loss: 48.02468840604748123724\n",
      "Iteration 22803 => Loss: 48.02451193966029308058\n",
      "Iteration 22804 => Loss: 48.02433547465800245391\n",
      "Iteration 22805 => Loss: 48.02415901104059514637\n",
      "Iteration 22806 => Loss: 48.02398254880807115796\n",
      "Iteration 22807 => Loss: 48.02380608796040206698\n",
      "Iteration 22808 => Loss: 48.02362962849760918971\n",
      "Iteration 22809 => Loss: 48.02345317041965699900\n",
      "Iteration 22810 => Loss: 48.02327671372653128401\n",
      "Iteration 22811 => Loss: 48.02310025841820362302\n",
      "Iteration 22812 => Loss: 48.02292380449471664861\n",
      "Iteration 22813 => Loss: 48.02274735195602062277\n",
      "Iteration 22814 => Loss: 48.02257090080212975636\n",
      "Iteration 22815 => Loss: 48.02239445103302273310\n",
      "Iteration 22816 => Loss: 48.02221800264866402586\n",
      "Iteration 22817 => Loss: 48.02204155564904652920\n",
      "Iteration 22818 => Loss: 48.02186511003422708654\n",
      "Iteration 22819 => Loss: 48.02168866580410622191\n",
      "Iteration 22820 => Loss: 48.02151222295871946244\n",
      "Iteration 22821 => Loss: 48.02133578149803838642\n",
      "Iteration 22822 => Loss: 48.02115934142207720470\n",
      "Iteration 22823 => Loss: 48.02098290273080749557\n",
      "Iteration 22824 => Loss: 48.02080646542420083733\n",
      "Iteration 22825 => Loss: 48.02063002950226433541\n",
      "Iteration 22826 => Loss: 48.02045359496501220065\n",
      "Iteration 22827 => Loss: 48.02027716181238758963\n",
      "Iteration 22828 => Loss: 48.02010073004441892408\n",
      "Iteration 22829 => Loss: 48.01992429966105646599\n",
      "Iteration 22830 => Loss: 48.01974787066232153165\n",
      "Iteration 22831 => Loss: 48.01957144304818569935\n",
      "Iteration 22832 => Loss: 48.01939501681866317995\n",
      "Iteration 22833 => Loss: 48.01921859197371844630\n",
      "Iteration 22834 => Loss: 48.01904216851333728755\n",
      "Iteration 22835 => Loss: 48.01886574643752680913\n",
      "Iteration 22836 => Loss: 48.01868932574626569476\n",
      "Iteration 22837 => Loss: 48.01851290643951841730\n",
      "Iteration 22838 => Loss: 48.01833648851732050389\n",
      "Iteration 22839 => Loss: 48.01816007197965774367\n",
      "Iteration 22840 => Loss: 48.01798365682648750408\n",
      "Iteration 22841 => Loss: 48.01780724305780978511\n",
      "Iteration 22842 => Loss: 48.01763083067363879763\n",
      "Iteration 22843 => Loss: 48.01745441967391059279\n",
      "Iteration 22844 => Loss: 48.01727801005866780315\n",
      "Iteration 22845 => Loss: 48.01710160182787490157\n",
      "Iteration 22846 => Loss: 48.01692519498152478263\n",
      "Iteration 22847 => Loss: 48.01674878951960323548\n",
      "Iteration 22848 => Loss: 48.01657238544209604925\n",
      "Iteration 22849 => Loss: 48.01639598274903164565\n",
      "Iteration 22850 => Loss: 48.01621958144033186500\n",
      "Iteration 22851 => Loss: 48.01604318151602512899\n",
      "Iteration 22852 => Loss: 48.01586678297610433219\n",
      "Iteration 22853 => Loss: 48.01569038582055526376\n",
      "Iteration 22854 => Loss: 48.01551399004933529113\n",
      "Iteration 22855 => Loss: 48.01533759566247994144\n",
      "Iteration 22856 => Loss: 48.01516120265996079297\n",
      "Iteration 22857 => Loss: 48.01498481104175652945\n",
      "Iteration 22858 => Loss: 48.01480842080786004544\n",
      "Iteration 22859 => Loss: 48.01463203195827844638\n",
      "Iteration 22860 => Loss: 48.01445564449300462684\n",
      "Iteration 22861 => Loss: 48.01427925841196753254\n",
      "Iteration 22862 => Loss: 48.01410287371523821776\n",
      "Iteration 22863 => Loss: 48.01392649040272431193\n",
      "Iteration 22864 => Loss: 48.01375010847448976392\n",
      "Iteration 22865 => Loss: 48.01357372793047773030\n",
      "Iteration 22866 => Loss: 48.01339734877070242192\n",
      "Iteration 22867 => Loss: 48.01322097099513541707\n",
      "Iteration 22868 => Loss: 48.01304459460377671576\n",
      "Iteration 22869 => Loss: 48.01286821959657657999\n",
      "Iteration 22870 => Loss: 48.01269184597359895861\n",
      "Iteration 22871 => Loss: 48.01251547373477990277\n",
      "Iteration 22872 => Loss: 48.01233910288012651790\n",
      "Iteration 22873 => Loss: 48.01216273340962459315\n",
      "Iteration 22874 => Loss: 48.01198636532324570680\n",
      "Iteration 22875 => Loss: 48.01180999862099696429\n",
      "Iteration 22876 => Loss: 48.01163363330288547104\n",
      "Iteration 22877 => Loss: 48.01145726936885438363\n",
      "Iteration 22878 => Loss: 48.01128090681890370206\n",
      "Iteration 22879 => Loss: 48.01110454565306895347\n",
      "Iteration 22880 => Loss: 48.01092818587130750529\n",
      "Iteration 22881 => Loss: 48.01075182747361225211\n",
      "Iteration 22882 => Loss: 48.01057547045994766677\n",
      "Iteration 22883 => Loss: 48.01039911483032085471\n",
      "Iteration 22884 => Loss: 48.01022276058472471050\n",
      "Iteration 22885 => Loss: 48.01004640772317344499\n",
      "Iteration 22886 => Loss: 48.00987005624561021477\n",
      "Iteration 22887 => Loss: 48.00969370615204923070\n",
      "Iteration 22888 => Loss: 48.00951735744247628190\n",
      "Iteration 22889 => Loss: 48.00934101011687005212\n",
      "Iteration 22890 => Loss: 48.00916466417524475219\n",
      "Iteration 22891 => Loss: 48.00898831961754353870\n",
      "Iteration 22892 => Loss: 48.00881197644382325507\n",
      "Iteration 22893 => Loss: 48.00863563465400574160\n",
      "Iteration 22894 => Loss: 48.00845929424813363084\n",
      "Iteration 22895 => Loss: 48.00828295522615007940\n",
      "Iteration 22896 => Loss: 48.00810661758806929811\n",
      "Iteration 22897 => Loss: 48.00793028133387707612\n",
      "Iteration 22898 => Loss: 48.00775394646355920258\n",
      "Iteration 22899 => Loss: 48.00757761297711567750\n",
      "Iteration 22900 => Loss: 48.00740128087453939543\n",
      "Iteration 22901 => Loss: 48.00722495015579482924\n",
      "Iteration 22902 => Loss: 48.00704862082088197894\n",
      "Iteration 22903 => Loss: 48.00687229286979373910\n",
      "Iteration 22904 => Loss: 48.00669596630251589886\n",
      "Iteration 22905 => Loss: 48.00651964111904845822\n",
      "Iteration 22906 => Loss: 48.00634331731937720633\n",
      "Iteration 22907 => Loss: 48.00616699490345951062\n",
      "Iteration 22908 => Loss: 48.00599067387133800366\n",
      "Iteration 22909 => Loss: 48.00581435422297005289\n",
      "Iteration 22910 => Loss: 48.00563803595834144744\n",
      "Iteration 22911 => Loss: 48.00546171907745929275\n",
      "Iteration 22912 => Loss: 48.00528540358027385082\n",
      "Iteration 22913 => Loss: 48.00510908946684196508\n",
      "Iteration 22914 => Loss: 48.00493277673707837039\n",
      "Iteration 22915 => Loss: 48.00475646539103991017\n",
      "Iteration 22916 => Loss: 48.00458015542866263559\n",
      "Iteration 22917 => Loss: 48.00440384684995365205\n",
      "Iteration 22918 => Loss: 48.00422753965492006500\n",
      "Iteration 22919 => Loss: 48.00405123384351213645\n",
      "Iteration 22920 => Loss: 48.00387492941579381522\n",
      "Iteration 22921 => Loss: 48.00369862637166562536\n",
      "Iteration 22922 => Loss: 48.00352232471115598855\n",
      "Iteration 22923 => Loss: 48.00334602443425069396\n",
      "Iteration 22924 => Loss: 48.00316972554095684700\n",
      "Iteration 22925 => Loss: 48.00299342803121760426\n",
      "Iteration 22926 => Loss: 48.00281713190508980915\n",
      "Iteration 22927 => Loss: 48.00264083716248819655\n",
      "Iteration 22928 => Loss: 48.00246454380346960988\n",
      "Iteration 22929 => Loss: 48.00228825182797720572\n",
      "Iteration 22930 => Loss: 48.00211196123602519492\n",
      "Iteration 22931 => Loss: 48.00193567202757805035\n",
      "Iteration 22932 => Loss: 48.00175938420264287743\n",
      "Iteration 22933 => Loss: 48.00158309776119835988\n",
      "Iteration 22934 => Loss: 48.00140681270325160312\n",
      "Iteration 22935 => Loss: 48.00123052902876708004\n",
      "Iteration 22936 => Loss: 48.00105424673778031774\n",
      "Iteration 22937 => Loss: 48.00087796583022026198\n",
      "Iteration 22938 => Loss: 48.00070168630610822902\n",
      "Iteration 22939 => Loss: 48.00052540816543711344\n",
      "Iteration 22940 => Loss: 48.00034913140817138810\n",
      "Iteration 22941 => Loss: 48.00017285603433947472\n",
      "Iteration 22942 => Loss: 47.99999658204387742444\n",
      "Iteration 22943 => Loss: 47.99982030943682076440\n",
      "Iteration 22944 => Loss: 47.99964403821315528376\n",
      "Iteration 22945 => Loss: 47.99946776837283834993\n",
      "Iteration 22946 => Loss: 47.99929149991587706836\n",
      "Iteration 22947 => Loss: 47.99911523284227143904\n",
      "Iteration 22948 => Loss: 47.99893896715202146197\n",
      "Iteration 22949 => Loss: 47.99876270284504897745\n",
      "Iteration 22950 => Loss: 47.99858643992141793433\n",
      "Iteration 22951 => Loss: 47.99841017838107148918\n",
      "Iteration 22952 => Loss: 47.99823391822401674744\n",
      "Iteration 22953 => Loss: 47.99805765945026791996\n",
      "Iteration 22954 => Loss: 47.99788140205976816333\n",
      "Iteration 22955 => Loss: 47.99770514605253879381\n",
      "Iteration 22956 => Loss: 47.99752889142855849514\n",
      "Iteration 22957 => Loss: 47.99735263818779884559\n",
      "Iteration 22958 => Loss: 47.99717638633025984518\n",
      "Iteration 22959 => Loss: 47.99700013585595570476\n",
      "Iteration 22960 => Loss: 47.99682388676486510803\n",
      "Iteration 22961 => Loss: 47.99664763905693831703\n",
      "Iteration 22962 => Loss: 47.99647139273221796429\n",
      "Iteration 22963 => Loss: 47.99629514779066141728\n",
      "Iteration 22964 => Loss: 47.99611890423226867597\n",
      "Iteration 22965 => Loss: 47.99594266205701131867\n",
      "Iteration 22966 => Loss: 47.99576642126491066165\n",
      "Iteration 22967 => Loss: 47.99559018185593828321\n",
      "Iteration 22968 => Loss: 47.99541394383006576163\n",
      "Iteration 22969 => Loss: 47.99523770718732151863\n",
      "Iteration 22970 => Loss: 47.99506147192765581622\n",
      "Iteration 22971 => Loss: 47.99488523805108286524\n",
      "Iteration 22972 => Loss: 47.99470900555758134942\n",
      "Iteration 22973 => Loss: 47.99453277444714416333\n",
      "Iteration 22974 => Loss: 47.99435654471974999069\n",
      "Iteration 22975 => Loss: 47.99418031637542725321\n",
      "Iteration 22976 => Loss: 47.99400408941410489660\n",
      "Iteration 22977 => Loss: 47.99382786383581844802\n",
      "Iteration 22978 => Loss: 47.99365163964053948575\n",
      "Iteration 22979 => Loss: 47.99347541682825379894\n",
      "Iteration 22980 => Loss: 47.99329919539896849301\n",
      "Iteration 22981 => Loss: 47.99312297535264093540\n",
      "Iteration 22982 => Loss: 47.99294675668929244239\n",
      "Iteration 22983 => Loss: 47.99277053940889459227\n",
      "Iteration 22984 => Loss: 47.99259432351144027962\n",
      "Iteration 22985 => Loss: 47.99241810899691529357\n",
      "Iteration 22986 => Loss: 47.99224189586531963414\n",
      "Iteration 22987 => Loss: 47.99206568411662487961\n",
      "Iteration 22988 => Loss: 47.99188947375083813540\n",
      "Iteration 22989 => Loss: 47.99171326476793808524\n",
      "Iteration 22990 => Loss: 47.99153705716791762370\n",
      "Iteration 22991 => Loss: 47.99136085095077675078\n",
      "Iteration 22992 => Loss: 47.99118464611647993934\n",
      "Iteration 22993 => Loss: 47.99100844266502008395\n",
      "Iteration 22994 => Loss: 47.99083224059641139547\n",
      "Iteration 22995 => Loss: 47.99065603991062545219\n",
      "Iteration 22996 => Loss: 47.99047984060764804326\n",
      "Iteration 22997 => Loss: 47.99030364268747206324\n",
      "Iteration 22998 => Loss: 47.99012744615009040672\n",
      "Iteration 22999 => Loss: 47.98995125099549596825\n",
      "Iteration 23000 => Loss: 47.98977505722366032614\n",
      "Iteration 23001 => Loss: 47.98959886483460479667\n",
      "Iteration 23002 => Loss: 47.98942267382826543098\n",
      "Iteration 23003 => Loss: 47.98924648420470617793\n",
      "Iteration 23004 => Loss: 47.98907029596384177239\n",
      "Iteration 23005 => Loss: 47.98889410910570774149\n",
      "Iteration 23006 => Loss: 47.98871792363026145267\n",
      "Iteration 23007 => Loss: 47.98854173953752422221\n",
      "Iteration 23008 => Loss: 47.98836555682746762841\n",
      "Iteration 23009 => Loss: 47.98818937550007746040\n",
      "Iteration 23010 => Loss: 47.98801319555538213990\n",
      "Iteration 23011 => Loss: 47.98783701699328219092\n",
      "Iteration 23012 => Loss: 47.98766083981386998403\n",
      "Iteration 23013 => Loss: 47.98748466401706735951\n",
      "Iteration 23014 => Loss: 47.98730848960288852822\n",
      "Iteration 23015 => Loss: 47.98713231657129796304\n",
      "Iteration 23016 => Loss: 47.98695614492233119108\n",
      "Iteration 23017 => Loss: 47.98677997465593136894\n",
      "Iteration 23018 => Loss: 47.98660380577211981290\n",
      "Iteration 23019 => Loss: 47.98642763827086099582\n",
      "Iteration 23020 => Loss: 47.98625147215216202312\n",
      "Iteration 23021 => Loss: 47.98607530741599447310\n",
      "Iteration 23022 => Loss: 47.98589914406237255662\n",
      "Iteration 23023 => Loss: 47.98572298209127495738\n",
      "Iteration 23024 => Loss: 47.98554682150267325369\n",
      "Iteration 23025 => Loss: 47.98537066229656744554\n",
      "Iteration 23026 => Loss: 47.98519450447297884921\n",
      "Iteration 23027 => Loss: 47.98501834803182930500\n",
      "Iteration 23028 => Loss: 47.98484219297317565633\n",
      "Iteration 23029 => Loss: 47.98466603929693974351\n",
      "Iteration 23030 => Loss: 47.98448988700318551537\n",
      "Iteration 23031 => Loss: 47.98431373609186323392\n",
      "Iteration 23032 => Loss: 47.98413758656295158289\n",
      "Iteration 23033 => Loss: 47.98396143841643635142\n",
      "Iteration 23034 => Loss: 47.98378529165236727749\n",
      "Iteration 23035 => Loss: 47.98360914627065199056\n",
      "Iteration 23036 => Loss: 47.98343300227132601776\n",
      "Iteration 23037 => Loss: 47.98325685965438225367\n",
      "Iteration 23038 => Loss: 47.98308071841978517114\n",
      "Iteration 23039 => Loss: 47.98290457856752055932\n",
      "Iteration 23040 => Loss: 47.98272844009759552364\n",
      "Iteration 23041 => Loss: 47.98255230301001716953\n",
      "Iteration 23042 => Loss: 47.98237616730475707527\n",
      "Iteration 23043 => Loss: 47.98220003298176550288\n",
      "Iteration 23044 => Loss: 47.98202390004110640120\n",
      "Iteration 23045 => Loss: 47.98184776848268739968\n",
      "Iteration 23046 => Loss: 47.98167163830657244716\n",
      "Iteration 23047 => Loss: 47.98149550951271180566\n",
      "Iteration 23048 => Loss: 47.98131938210110547516\n",
      "Iteration 23049 => Loss: 47.98114325607171792853\n",
      "Iteration 23050 => Loss: 47.98096713142458469292\n",
      "Iteration 23051 => Loss: 47.98079100815963471405\n",
      "Iteration 23052 => Loss: 47.98061488627693194076\n",
      "Iteration 23053 => Loss: 47.98043876577639821335\n",
      "Iteration 23054 => Loss: 47.98026264665805484810\n",
      "Iteration 23055 => Loss: 47.98008652892186631789\n",
      "Iteration 23056 => Loss: 47.97991041256786104441\n",
      "Iteration 23057 => Loss: 47.97973429759602481681\n",
      "Iteration 23058 => Loss: 47.97955818400627947540\n",
      "Iteration 23059 => Loss: 47.97938207179869607444\n",
      "Iteration 23060 => Loss: 47.97920596097324619222\n",
      "Iteration 23061 => Loss: 47.97902985152988719619\n",
      "Iteration 23062 => Loss: 47.97885374346861908634\n",
      "Iteration 23063 => Loss: 47.97867763678943475725\n",
      "Iteration 23064 => Loss: 47.97850153149234131433\n",
      "Iteration 23065 => Loss: 47.97832542757731744132\n",
      "Iteration 23066 => Loss: 47.97814932504433471649\n",
      "Iteration 23067 => Loss: 47.97797322389340735072\n",
      "Iteration 23068 => Loss: 47.97779712412449271142\n",
      "Iteration 23069 => Loss: 47.97762102573761211488\n",
      "Iteration 23070 => Loss: 47.97744492873275135025\n",
      "Iteration 23071 => Loss: 47.97726883310987489040\n",
      "Iteration 23072 => Loss: 47.97709273886899694617\n",
      "Iteration 23073 => Loss: 47.97691664601010330671\n",
      "Iteration 23074 => Loss: 47.97674055453317265574\n",
      "Iteration 23075 => Loss: 47.97656446443818367698\n",
      "Iteration 23076 => Loss: 47.97638837572514347585\n",
      "Iteration 23077 => Loss: 47.97621228839405915778\n",
      "Iteration 23078 => Loss: 47.97603620244487387936\n",
      "Iteration 23079 => Loss: 47.97586011787760895686\n",
      "Iteration 23080 => Loss: 47.97568403469224307401\n",
      "Iteration 23081 => Loss: 47.97550795288877623079\n",
      "Iteration 23082 => Loss: 47.97533187246719421637\n",
      "Iteration 23083 => Loss: 47.97515579342748281988\n",
      "Iteration 23084 => Loss: 47.97497971576963493590\n",
      "Iteration 23085 => Loss: 47.97480363949362924814\n",
      "Iteration 23086 => Loss: 47.97462756459945154575\n",
      "Iteration 23087 => Loss: 47.97445149108710893415\n",
      "Iteration 23088 => Loss: 47.97427541895658009707\n",
      "Iteration 23089 => Loss: 47.97409934820787213994\n",
      "Iteration 23090 => Loss: 47.97392327884092111390\n",
      "Iteration 23091 => Loss: 47.97374721085579096780\n",
      "Iteration 23092 => Loss: 47.97357114425238933109\n",
      "Iteration 23093 => Loss: 47.97339507903080146889\n",
      "Iteration 23094 => Loss: 47.97321901519094211608\n",
      "Iteration 23095 => Loss: 47.97304295273281127265\n",
      "Iteration 23096 => Loss: 47.97286689165640183319\n",
      "Iteration 23097 => Loss: 47.97269083196173511396\n",
      "Iteration 23098 => Loss: 47.97251477364876848242\n",
      "Iteration 23099 => Loss: 47.97233871671749483312\n",
      "Iteration 23100 => Loss: 47.97216266116789995522\n",
      "Iteration 23101 => Loss: 47.97198660699999095414\n",
      "Iteration 23102 => Loss: 47.97181055421375361902\n",
      "Iteration 23103 => Loss: 47.97163450280914531731\n",
      "Iteration 23104 => Loss: 47.97145845278618736529\n",
      "Iteration 23105 => Loss: 47.97128240414487976295\n",
      "Iteration 23106 => Loss: 47.97110635688516566688\n",
      "Iteration 23107 => Loss: 47.97093031100707349879\n",
      "Iteration 23108 => Loss: 47.97075426651060325867\n",
      "Iteration 23109 => Loss: 47.97057822339566968139\n",
      "Iteration 23110 => Loss: 47.97040218166234382124\n",
      "Iteration 23111 => Loss: 47.97022614131059015108\n",
      "Iteration 23112 => Loss: 47.97005010234038024919\n",
      "Iteration 23113 => Loss: 47.96987406475171411557\n",
      "Iteration 23114 => Loss: 47.96969802854457753938\n",
      "Iteration 23115 => Loss: 47.96952199371899183689\n",
      "Iteration 23116 => Loss: 47.96934596027489305925\n",
      "Iteration 23117 => Loss: 47.96916992821230962818\n",
      "Iteration 23118 => Loss: 47.96899389753119891111\n",
      "Iteration 23119 => Loss: 47.96881786823157511890\n",
      "Iteration 23120 => Loss: 47.96864184031340982983\n",
      "Iteration 23121 => Loss: 47.96846581377672436020\n",
      "Iteration 23122 => Loss: 47.96828978862147607742\n",
      "Iteration 23123 => Loss: 47.96811376484767208694\n",
      "Iteration 23124 => Loss: 47.96793774245528396705\n",
      "Iteration 23125 => Loss: 47.96776172144429750688\n",
      "Iteration 23126 => Loss: 47.96758570181472691729\n",
      "Iteration 23127 => Loss: 47.96740968356652956572\n",
      "Iteration 23128 => Loss: 47.96723366669975519017\n",
      "Iteration 23129 => Loss: 47.96705765121433273634\n",
      "Iteration 23130 => Loss: 47.96688163711026930969\n",
      "Iteration 23131 => Loss: 47.96670562438755780477\n",
      "Iteration 23132 => Loss: 47.96652961304619111615\n",
      "Iteration 23133 => Loss: 47.96635360308614792757\n",
      "Iteration 23134 => Loss: 47.96617759450741402816\n",
      "Iteration 23135 => Loss: 47.96600158730996810164\n",
      "Iteration 23136 => Loss: 47.96582558149385988600\n",
      "Iteration 23137 => Loss: 47.96564957705900411611\n",
      "Iteration 23138 => Loss: 47.96547357400542921368\n",
      "Iteration 23139 => Loss: 47.96529757233312096787\n",
      "Iteration 23140 => Loss: 47.96512157204207227323\n",
      "Iteration 23141 => Loss: 47.96494557313224760264\n",
      "Iteration 23142 => Loss: 47.96476957560366116695\n",
      "Iteration 23143 => Loss: 47.96459357945629164988\n",
      "Iteration 23144 => Loss: 47.96441758469015326227\n",
      "Iteration 23145 => Loss: 47.96424159130518205529\n",
      "Iteration 23146 => Loss: 47.96406559930139934522\n",
      "Iteration 23147 => Loss: 47.96388960867881223749\n",
      "Iteration 23148 => Loss: 47.96371361943738520495\n",
      "Iteration 23149 => Loss: 47.96353763157711114218\n",
      "Iteration 23150 => Loss: 47.96336164509796162747\n",
      "Iteration 23151 => Loss: 47.96318565999996508253\n",
      "Iteration 23152 => Loss: 47.96300967628309308566\n",
      "Iteration 23153 => Loss: 47.96283369394732432056\n",
      "Iteration 23154 => Loss: 47.96265771299265168182\n",
      "Iteration 23155 => Loss: 47.96248173341906095857\n",
      "Iteration 23156 => Loss: 47.96230575522654504539\n",
      "Iteration 23157 => Loss: 47.96212977841512525856\n",
      "Iteration 23158 => Loss: 47.96195380298475186009\n",
      "Iteration 23159 => Loss: 47.96177782893542484999\n",
      "Iteration 23160 => Loss: 47.96160185626712291196\n",
      "Iteration 23161 => Loss: 47.96142588497984604601\n",
      "Iteration 23162 => Loss: 47.96124991507359425214\n",
      "Iteration 23163 => Loss: 47.96107394654834621406\n",
      "Iteration 23164 => Loss: 47.96089797940407351007\n",
      "Iteration 23165 => Loss: 47.96072201364077614016\n",
      "Iteration 23166 => Loss: 47.96054604925846831520\n",
      "Iteration 23167 => Loss: 47.96037008625712871890\n",
      "Iteration 23168 => Loss: 47.96019412463671471869\n",
      "Iteration 23169 => Loss: 47.96001816439724052543\n",
      "Iteration 23170 => Loss: 47.95984220553869903370\n",
      "Iteration 23171 => Loss: 47.95966624806106182177\n",
      "Iteration 23172 => Loss: 47.95949029196435020594\n",
      "Iteration 23173 => Loss: 47.95931433724853576450\n",
      "Iteration 23174 => Loss: 47.95913838391358297031\n",
      "Iteration 23175 => Loss: 47.95896243195952024507\n",
      "Iteration 23176 => Loss: 47.95878648138629785080\n",
      "Iteration 23177 => Loss: 47.95861053219394420921\n",
      "Iteration 23178 => Loss: 47.95843458438241668773\n",
      "Iteration 23179 => Loss: 47.95825863795173660264\n",
      "Iteration 23180 => Loss: 47.95808269290187553224\n",
      "Iteration 23181 => Loss: 47.95790674923280505482\n",
      "Iteration 23182 => Loss: 47.95773080694454648665\n",
      "Iteration 23183 => Loss: 47.95755486603705719517\n",
      "Iteration 23184 => Loss: 47.95737892651035139124\n",
      "Iteration 23185 => Loss: 47.95720298836440775858\n",
      "Iteration 23186 => Loss: 47.95702705159921919176\n",
      "Iteration 23187 => Loss: 47.95685111621476437449\n",
      "Iteration 23188 => Loss: 47.95667518221105041221\n",
      "Iteration 23189 => Loss: 47.95649924958807019948\n",
      "Iteration 23190 => Loss: 47.95632331834576689289\n",
      "Iteration 23191 => Loss: 47.95614738848420444128\n",
      "Iteration 23192 => Loss: 47.95597146000331179039\n",
      "Iteration 23193 => Loss: 47.95579553290308183477\n",
      "Iteration 23194 => Loss: 47.95561960718355010158\n",
      "Iteration 23195 => Loss: 47.95544368284462422025\n",
      "Iteration 23196 => Loss: 47.95526775988637524506\n",
      "Iteration 23197 => Loss: 47.95509183830876764887\n",
      "Iteration 23198 => Loss: 47.95491591811177300997\n",
      "Iteration 23199 => Loss: 47.95473999929538422293\n",
      "Iteration 23200 => Loss: 47.95456408185960128776\n",
      "Iteration 23201 => Loss: 47.95438816580440999360\n",
      "Iteration 23202 => Loss: 47.95421225112981744587\n",
      "Iteration 23203 => Loss: 47.95403633783576680116\n",
      "Iteration 23204 => Loss: 47.95386042592230069204\n",
      "Iteration 23205 => Loss: 47.95368451538934806422\n",
      "Iteration 23206 => Loss: 47.95350860623695155027\n",
      "Iteration 23207 => Loss: 47.95333269846508983392\n",
      "Iteration 23208 => Loss: 47.95315679207371317716\n",
      "Iteration 23209 => Loss: 47.95298088706287842342\n",
      "Iteration 23210 => Loss: 47.95280498343250741300\n",
      "Iteration 23211 => Loss: 47.95262908118264277846\n",
      "Iteration 23212 => Loss: 47.95245318031324188723\n",
      "Iteration 23213 => Loss: 47.95227728082428342304\n",
      "Iteration 23214 => Loss: 47.95210138271578870217\n",
      "Iteration 23215 => Loss: 47.95192548598773640833\n",
      "Iteration 23216 => Loss: 47.95174959064010522525\n",
      "Iteration 23217 => Loss: 47.95157369667289515291\n",
      "Iteration 23218 => Loss: 47.95139780408609198048\n",
      "Iteration 23219 => Loss: 47.95122191287968149709\n",
      "Iteration 23220 => Loss: 47.95104602305364238646\n",
      "Iteration 23221 => Loss: 47.95087013460799596487\n",
      "Iteration 23222 => Loss: 47.95069424754272802147\n",
      "Iteration 23223 => Loss: 47.95051836185777460742\n",
      "Iteration 23224 => Loss: 47.95034247755319967155\n",
      "Iteration 23225 => Loss: 47.95016659462892505417\n",
      "Iteration 23226 => Loss: 47.94999071308499338784\n",
      "Iteration 23227 => Loss: 47.94981483292136914542\n",
      "Iteration 23228 => Loss: 47.94963895413802390522\n",
      "Iteration 23229 => Loss: 47.94946307673498608892\n",
      "Iteration 23230 => Loss: 47.94928720071222727483\n",
      "Iteration 23231 => Loss: 47.94911132606969061953\n",
      "Iteration 23232 => Loss: 47.94893545280746138815\n",
      "Iteration 23233 => Loss: 47.94875958092544721012\n",
      "Iteration 23234 => Loss: 47.94858371042369782344\n",
      "Iteration 23235 => Loss: 47.94840784130212796299\n",
      "Iteration 23236 => Loss: 47.94823197356079447218\n",
      "Iteration 23237 => Loss: 47.94805610719964761302\n",
      "Iteration 23238 => Loss: 47.94788024221870870178\n",
      "Iteration 23239 => Loss: 47.94770437861794221135\n",
      "Iteration 23240 => Loss: 47.94752851639734814171\n",
      "Iteration 23241 => Loss: 47.94735265555689807115\n",
      "Iteration 23242 => Loss: 47.94717679609660621054\n",
      "Iteration 23243 => Loss: 47.94700093801645124358\n",
      "Iteration 23244 => Loss: 47.94682508131641185400\n",
      "Iteration 23245 => Loss: 47.94664922599649514723\n",
      "Iteration 23246 => Loss: 47.94647337205667270155\n",
      "Iteration 23247 => Loss: 47.94629751949693741153\n",
      "Iteration 23248 => Loss: 47.94612166831728927718\n",
      "Iteration 23249 => Loss: 47.94594581851772829850\n",
      "Iteration 23250 => Loss: 47.94576997009821894835\n",
      "Iteration 23251 => Loss: 47.94559412305876122673\n",
      "Iteration 23252 => Loss: 47.94541827739933381736\n",
      "Iteration 23253 => Loss: 47.94524243311992250938\n",
      "Iteration 23254 => Loss: 47.94506659022053440822\n",
      "Iteration 23255 => Loss: 47.94489074870117661931\n",
      "Iteration 23256 => Loss: 47.94471490856177808837\n",
      "Iteration 23257 => Loss: 47.94453906980240986968\n",
      "Iteration 23258 => Loss: 47.94436323242297959268\n",
      "Iteration 23259 => Loss: 47.94418739642350857366\n",
      "Iteration 23260 => Loss: 47.94401156180401102347\n",
      "Iteration 23261 => Loss: 47.94383572856443720411\n",
      "Iteration 23262 => Loss: 47.94365989670479422102\n",
      "Iteration 23263 => Loss: 47.94348406622508207420\n",
      "Iteration 23264 => Loss: 47.94330823712527234193\n",
      "Iteration 23265 => Loss: 47.94313240940534370793\n",
      "Iteration 23266 => Loss: 47.94295658306531748849\n",
      "Iteration 23267 => Loss: 47.94278075810517236732\n",
      "Iteration 23268 => Loss: 47.94260493452490123900\n",
      "Iteration 23269 => Loss: 47.94242911232446147096\n",
      "Iteration 23270 => Loss: 47.94225329150388859034\n",
      "Iteration 23271 => Loss: 47.94207747206311864829\n",
      "Iteration 23272 => Loss: 47.94190165400218717195\n",
      "Iteration 23273 => Loss: 47.94172583732104442333\n",
      "Iteration 23274 => Loss: 47.94155002201973303499\n",
      "Iteration 23275 => Loss: 47.94137420809820326895\n",
      "Iteration 23276 => Loss: 47.94119839555644091433\n",
      "Iteration 23277 => Loss: 47.94102258439445307658\n",
      "Iteration 23278 => Loss: 47.94084677461223975570\n",
      "Iteration 23279 => Loss: 47.94067096620975121368\n",
      "Iteration 23280 => Loss: 47.94049515918700876682\n",
      "Iteration 23281 => Loss: 47.94031935354396267712\n",
      "Iteration 23282 => Loss: 47.94014354928065557715\n",
      "Iteration 23283 => Loss: 47.93996774639705193977\n",
      "Iteration 23284 => Loss: 47.93979194489313755412\n",
      "Iteration 23285 => Loss: 47.93961614476891242020\n",
      "Iteration 23286 => Loss: 47.93944034602432680003\n",
      "Iteration 23287 => Loss: 47.93926454865941622074\n",
      "Iteration 23288 => Loss: 47.93908875267415936605\n",
      "Iteration 23289 => Loss: 47.93891295806855623596\n",
      "Iteration 23290 => Loss: 47.93873716484254998704\n",
      "Iteration 23291 => Loss: 47.93856137299617614644\n",
      "Iteration 23292 => Loss: 47.93838558252939918702\n",
      "Iteration 23293 => Loss: 47.93820979344221910878\n",
      "Iteration 23294 => Loss: 47.93803400573462880629\n",
      "Iteration 23295 => Loss: 47.93785821940659275242\n",
      "Iteration 23296 => Loss: 47.93768243445812515802\n",
      "Iteration 23297 => Loss: 47.93750665088922602308\n",
      "Iteration 23298 => Loss: 47.93733086869985982048\n",
      "Iteration 23299 => Loss: 47.93715508789001233936\n",
      "Iteration 23300 => Loss: 47.93697930845969068514\n",
      "Iteration 23301 => Loss: 47.93680353040888775240\n",
      "Iteration 23302 => Loss: 47.93662775373756090858\n",
      "Iteration 23303 => Loss: 47.93645197844573146995\n",
      "Iteration 23304 => Loss: 47.93627620453337812023\n",
      "Iteration 23305 => Loss: 47.93610043200048664858\n",
      "Iteration 23306 => Loss: 47.93592466084704284413\n",
      "Iteration 23307 => Loss: 47.93574889107305381231\n",
      "Iteration 23308 => Loss: 47.93557312267846981513\n",
      "Iteration 23309 => Loss: 47.93539735566334059058\n",
      "Iteration 23310 => Loss: 47.93522159002760929525\n",
      "Iteration 23311 => Loss: 47.93504582577128303456\n",
      "Iteration 23312 => Loss: 47.93487006289432628137\n",
      "Iteration 23313 => Loss: 47.93469430139678166825\n",
      "Iteration 23314 => Loss: 47.93451854127856393006\n",
      "Iteration 23315 => Loss: 47.93434278253972280481\n",
      "Iteration 23316 => Loss: 47.93416702518021565993\n",
      "Iteration 23317 => Loss: 47.93399126920006381170\n",
      "Iteration 23318 => Loss: 47.93381551459922462755\n",
      "Iteration 23319 => Loss: 47.93363976137769810748\n",
      "Iteration 23320 => Loss: 47.93346400953548425150\n",
      "Iteration 23321 => Loss: 47.93328825907254753247\n",
      "Iteration 23322 => Loss: 47.93311250998888084496\n",
      "Iteration 23323 => Loss: 47.93293676228449839982\n",
      "Iteration 23324 => Loss: 47.93276101595937888078\n",
      "Iteration 23325 => Loss: 47.93258527101350097155\n",
      "Iteration 23326 => Loss: 47.93240952744685756670\n",
      "Iteration 23327 => Loss: 47.93223378525944866624\n",
      "Iteration 23328 => Loss: 47.93205804445124584845\n",
      "Iteration 23329 => Loss: 47.93188230502224911334\n",
      "Iteration 23330 => Loss: 47.93170656697247267175\n",
      "Iteration 23331 => Loss: 47.93153083030183125857\n",
      "Iteration 23332 => Loss: 47.93135509501039592806\n",
      "Iteration 23333 => Loss: 47.93117936109811694223\n",
      "Iteration 23334 => Loss: 47.93100362856497298480\n",
      "Iteration 23335 => Loss: 47.93082789741097826663\n",
      "Iteration 23336 => Loss: 47.93065216763612568229\n",
      "Iteration 23337 => Loss: 47.93047643924037970464\n",
      "Iteration 23338 => Loss: 47.93030071222374743911\n",
      "Iteration 23339 => Loss: 47.93012498658620046399\n",
      "Iteration 23340 => Loss: 47.92994926232773167385\n",
      "Iteration 23341 => Loss: 47.92977353944835527955\n",
      "Iteration 23342 => Loss: 47.92959781794801443766\n",
      "Iteration 23343 => Loss: 47.92942209782678020247\n",
      "Iteration 23344 => Loss: 47.92924637908456020341\n",
      "Iteration 23345 => Loss: 47.92907066172135444049\n",
      "Iteration 23346 => Loss: 47.92889494573718422998\n",
      "Iteration 23347 => Loss: 47.92871923113201404476\n",
      "Iteration 23348 => Loss: 47.92854351790585809567\n",
      "Iteration 23349 => Loss: 47.92836780605868796101\n",
      "Iteration 23350 => Loss: 47.92819209559047521907\n",
      "Iteration 23351 => Loss: 47.92801638650126250241\n",
      "Iteration 23352 => Loss: 47.92784067879097875675\n",
      "Iteration 23353 => Loss: 47.92766497245963819296\n",
      "Iteration 23354 => Loss: 47.92748926750724791646\n",
      "Iteration 23355 => Loss: 47.92731356393378661096\n",
      "Iteration 23356 => Loss: 47.92713786173922585476\n",
      "Iteration 23357 => Loss: 47.92696216092355854244\n",
      "Iteration 23358 => Loss: 47.92678646148679888483\n",
      "Iteration 23359 => Loss: 47.92661076342889714397\n",
      "Iteration 23360 => Loss: 47.92643506674988884697\n",
      "Iteration 23361 => Loss: 47.92625937144972425585\n",
      "Iteration 23362 => Loss: 47.92608367752841047604\n",
      "Iteration 23363 => Loss: 47.92590798498594040211\n",
      "Iteration 23364 => Loss: 47.92573229382229271778\n",
      "Iteration 23365 => Loss: 47.92555660403744610676\n",
      "Iteration 23366 => Loss: 47.92538091563141477991\n",
      "Iteration 23367 => Loss: 47.92520522860417742095\n",
      "Iteration 23368 => Loss: 47.92502954295572692445\n",
      "Iteration 23369 => Loss: 47.92485385868604197412\n",
      "Iteration 23370 => Loss: 47.92467817579511546455\n",
      "Iteration 23371 => Loss: 47.92450249428293318488\n",
      "Iteration 23372 => Loss: 47.92432681414951645138\n",
      "Iteration 23373 => Loss: 47.92415113539480131521\n",
      "Iteration 23374 => Loss: 47.92397545801881619809\n",
      "Iteration 23375 => Loss: 47.92379978202152557287\n",
      "Iteration 23376 => Loss: 47.92362410740293654499\n",
      "Iteration 23377 => Loss: 47.92344843416305621986\n",
      "Iteration 23378 => Loss: 47.92327276230182064864\n",
      "Iteration 23379 => Loss: 47.92309709181925825305\n",
      "Iteration 23380 => Loss: 47.92292142271535482223\n",
      "Iteration 23381 => Loss: 47.92274575499008193447\n",
      "Iteration 23382 => Loss: 47.92257008864346090604\n",
      "Iteration 23383 => Loss: 47.92239442367543489354\n",
      "Iteration 23384 => Loss: 47.92221876008602521324\n",
      "Iteration 23385 => Loss: 47.92204309787521765429\n",
      "Iteration 23386 => Loss: 47.92186743704299800584\n",
      "Iteration 23387 => Loss: 47.92169177758935205702\n",
      "Iteration 23388 => Loss: 47.92151611951427270242\n",
      "Iteration 23389 => Loss: 47.92134046281775994203\n",
      "Iteration 23390 => Loss: 47.92116480749978535414\n",
      "Iteration 23391 => Loss: 47.92098915356033472790\n",
      "Iteration 23392 => Loss: 47.92081350099940806331\n",
      "Iteration 23393 => Loss: 47.92063784981700536036\n",
      "Iteration 23394 => Loss: 47.92046220001311240821\n",
      "Iteration 23395 => Loss: 47.92028655158767236344\n",
      "Iteration 23396 => Loss: 47.92011090454073496403\n",
      "Iteration 23397 => Loss: 47.91993525887227178828\n",
      "Iteration 23398 => Loss: 47.91975961458225441447\n",
      "Iteration 23399 => Loss: 47.91958397167069705347\n",
      "Iteration 23400 => Loss: 47.91940833013755707270\n",
      "Iteration 23401 => Loss: 47.91923268998285578846\n",
      "Iteration 23402 => Loss: 47.91905705120658609530\n",
      "Iteration 23403 => Loss: 47.91888141380869114982\n",
      "Iteration 23404 => Loss: 47.91870577778919226830\n",
      "Iteration 23405 => Loss: 47.91853014314809655616\n",
      "Iteration 23406 => Loss: 47.91835450988536138084\n",
      "Iteration 23407 => Loss: 47.91817887800097963691\n",
      "Iteration 23408 => Loss: 47.91800324749494421894\n",
      "Iteration 23409 => Loss: 47.91782761836726223237\n",
      "Iteration 23410 => Loss: 47.91765199061790525548\n",
      "Iteration 23411 => Loss: 47.91747636424686618284\n",
      "Iteration 23412 => Loss: 47.91730073925410948732\n",
      "Iteration 23413 => Loss: 47.91712511563968490691\n",
      "Iteration 23414 => Loss: 47.91694949340352849276\n",
      "Iteration 23415 => Loss: 47.91677387254564024488\n",
      "Iteration 23416 => Loss: 47.91659825306603437411\n",
      "Iteration 23417 => Loss: 47.91642263496466824790\n",
      "Iteration 23418 => Loss: 47.91624701824154897167\n",
      "Iteration 23419 => Loss: 47.91607140289665522914\n",
      "Iteration 23420 => Loss: 47.91589578892998702031\n",
      "Iteration 23421 => Loss: 47.91572017634150171261\n",
      "Iteration 23422 => Loss: 47.91554456513125614947\n",
      "Iteration 23423 => Loss: 47.91536895529917217118\n",
      "Iteration 23424 => Loss: 47.91519334684526398860\n",
      "Iteration 23425 => Loss: 47.91501773976953160172\n",
      "Iteration 23426 => Loss: 47.91484213407195369427\n",
      "Iteration 23427 => Loss: 47.91466652975252316082\n",
      "Iteration 23428 => Loss: 47.91449092681123289594\n",
      "Iteration 23429 => Loss: 47.91431532524803316164\n",
      "Iteration 23430 => Loss: 47.91413972506297369591\n",
      "Iteration 23431 => Loss: 47.91396412625601897162\n",
      "Iteration 23432 => Loss: 47.91378852882711925076\n",
      "Iteration 23433 => Loss: 47.91361293277631716592\n",
      "Iteration 23434 => Loss: 47.91343733810360561165\n",
      "Iteration 23435 => Loss: 47.91326174480893484997\n",
      "Iteration 23436 => Loss: 47.91308615289229777545\n",
      "Iteration 23437 => Loss: 47.91291056235370149352\n",
      "Iteration 23438 => Loss: 47.91273497319314600418\n",
      "Iteration 23439 => Loss: 47.91255938541058867486\n",
      "Iteration 23440 => Loss: 47.91238379900607213813\n",
      "Iteration 23441 => Loss: 47.91220821397950402343\n",
      "Iteration 23442 => Loss: 47.91203263033091985790\n",
      "Iteration 23443 => Loss: 47.91185704806034095782\n",
      "Iteration 23444 => Loss: 47.91168146716768916349\n",
      "Iteration 23445 => Loss: 47.91150588765300000205\n",
      "Iteration 23446 => Loss: 47.91133030951625215721\n",
      "Iteration 23447 => Loss: 47.91115473275743852355\n",
      "Iteration 23448 => Loss: 47.91097915737653778478\n",
      "Iteration 23449 => Loss: 47.91080358337352862463\n",
      "Iteration 23450 => Loss: 47.91062801074843946481\n",
      "Iteration 23451 => Loss: 47.91045243950120635645\n",
      "Iteration 23452 => Loss: 47.91027686963187193214\n",
      "Iteration 23453 => Loss: 47.91010130114039355931\n",
      "Iteration 23454 => Loss: 47.90992573402676413252\n",
      "Iteration 23455 => Loss: 47.90975016829096233550\n",
      "Iteration 23456 => Loss: 47.90957460393300948454\n",
      "Iteration 23457 => Loss: 47.90939904095288426333\n",
      "Iteration 23458 => Loss: 47.90922347935056535562\n",
      "Iteration 23459 => Loss: 47.90904791912603144510\n",
      "Iteration 23460 => Loss: 47.90887236027925411008\n",
      "Iteration 23461 => Loss: 47.90869680281031151026\n",
      "Iteration 23462 => Loss: 47.90852124671909706422\n",
      "Iteration 23463 => Loss: 47.90834569200566761538\n",
      "Iteration 23464 => Loss: 47.90817013866997342575\n",
      "Iteration 23465 => Loss: 47.90799458671200028448\n",
      "Iteration 23466 => Loss: 47.90781903613175529699\n",
      "Iteration 23467 => Loss: 47.90764348692921004158\n",
      "Iteration 23468 => Loss: 47.90746793910437162367\n",
      "Iteration 23469 => Loss: 47.90729239265724004326\n",
      "Iteration 23470 => Loss: 47.90711684758777266779\n",
      "Iteration 23471 => Loss: 47.90694130389599081354\n",
      "Iteration 23472 => Loss: 47.90676576158183763710\n",
      "Iteration 23473 => Loss: 47.90659022064535577101\n",
      "Iteration 23474 => Loss: 47.90641468108650258273\n",
      "Iteration 23475 => Loss: 47.90623914290527807225\n",
      "Iteration 23476 => Loss: 47.90606360610166802871\n",
      "Iteration 23477 => Loss: 47.90588807067564403042\n",
      "Iteration 23478 => Loss: 47.90571253662723449906\n",
      "Iteration 23479 => Loss: 47.90553700395639680210\n",
      "Iteration 23480 => Loss: 47.90536147266312383408\n",
      "Iteration 23481 => Loss: 47.90518594274742980588\n",
      "Iteration 23482 => Loss: 47.90501041420926497949\n",
      "Iteration 23483 => Loss: 47.90483488704865067120\n",
      "Iteration 23484 => Loss: 47.90465936126555845931\n",
      "Iteration 23485 => Loss: 47.90448383685998834380\n",
      "Iteration 23486 => Loss: 47.90430831383191190298\n",
      "Iteration 23487 => Loss: 47.90413279218135755855\n",
      "Iteration 23488 => Loss: 47.90395727190827557251\n",
      "Iteration 23489 => Loss: 47.90378175301265883945\n",
      "Iteration 23490 => Loss: 47.90360623549451446479\n",
      "Iteration 23491 => Loss: 47.90343071935382823767\n",
      "Iteration 23492 => Loss: 47.90325520459055752553\n",
      "Iteration 23493 => Loss: 47.90307969120473785551\n",
      "Iteration 23494 => Loss: 47.90290417919634791133\n",
      "Iteration 23495 => Loss: 47.90272866856534506041\n",
      "Iteration 23496 => Loss: 47.90255315931174351363\n",
      "Iteration 23497 => Loss: 47.90237765143553616554\n",
      "Iteration 23498 => Loss: 47.90220214493669459443\n",
      "Iteration 23499 => Loss: 47.90202663981522590575\n",
      "Iteration 23500 => Loss: 47.90185113607109457234\n",
      "Iteration 23501 => Loss: 47.90167563370434322678\n",
      "Iteration 23502 => Loss: 47.90150013271492213107\n",
      "Iteration 23503 => Loss: 47.90132463310280996893\n",
      "Iteration 23504 => Loss: 47.90114913486799252951\n",
      "Iteration 23505 => Loss: 47.90097363801049112908\n",
      "Iteration 23506 => Loss: 47.90079814253029866222\n",
      "Iteration 23507 => Loss: 47.90062264842735828552\n",
      "Iteration 23508 => Loss: 47.90044715570169131524\n",
      "Iteration 23509 => Loss: 47.90027166435329775140\n",
      "Iteration 23510 => Loss: 47.90009617438212785601\n",
      "Iteration 23511 => Loss: 47.89992068578822426161\n",
      "Iteration 23512 => Loss: 47.89974519857152301938\n",
      "Iteration 23513 => Loss: 47.89956971273203123474\n",
      "Iteration 23514 => Loss: 47.89939422826975601311\n",
      "Iteration 23515 => Loss: 47.89921874518466893278\n",
      "Iteration 23516 => Loss: 47.89904326347677709919\n",
      "Iteration 23517 => Loss: 47.89886778314603787976\n",
      "Iteration 23518 => Loss: 47.89869230419246548536\n",
      "Iteration 23519 => Loss: 47.89851682661605281055\n",
      "Iteration 23520 => Loss: 47.89834135041677143363\n",
      "Iteration 23521 => Loss: 47.89816587559460003831\n",
      "Iteration 23522 => Loss: 47.89799040214957415174\n",
      "Iteration 23523 => Loss: 47.89781493008163693048\n",
      "Iteration 23524 => Loss: 47.89763945939080969083\n",
      "Iteration 23525 => Loss: 47.89746399007705690565\n",
      "Iteration 23526 => Loss: 47.89728852214035725865\n",
      "Iteration 23527 => Loss: 47.89711305558076048783\n",
      "Iteration 23528 => Loss: 47.89693759039819553891\n",
      "Iteration 23529 => Loss: 47.89676212659267662275\n",
      "Iteration 23530 => Loss: 47.89658666416418242306\n",
      "Iteration 23531 => Loss: 47.89641120311269872900\n",
      "Iteration 23532 => Loss: 47.89623574343823975141\n",
      "Iteration 23533 => Loss: 47.89606028514077706859\n",
      "Iteration 23534 => Loss: 47.89588482822031068054\n",
      "Iteration 23535 => Loss: 47.89570937267682637639\n",
      "Iteration 23536 => Loss: 47.89553391851028862902\n",
      "Iteration 23537 => Loss: 47.89535846572071875471\n",
      "Iteration 23538 => Loss: 47.89518301430807412089\n",
      "Iteration 23539 => Loss: 47.89500756427236893842\n",
      "Iteration 23540 => Loss: 47.89483211561357478558\n",
      "Iteration 23541 => Loss: 47.89465666833172718952\n",
      "Iteration 23542 => Loss: 47.89448122242676930682\n",
      "Iteration 23543 => Loss: 47.89430577789867982119\n",
      "Iteration 23544 => Loss: 47.89413033474750136520\n",
      "Iteration 23545 => Loss: 47.89395489297316999000\n",
      "Iteration 23546 => Loss: 47.89377945257570701187\n",
      "Iteration 23547 => Loss: 47.89360401355508400911\n",
      "Iteration 23548 => Loss: 47.89342857591130808714\n",
      "Iteration 23549 => Loss: 47.89325313964432950797\n",
      "Iteration 23550 => Loss: 47.89307770475419800960\n",
      "Iteration 23551 => Loss: 47.89290227124084964316\n",
      "Iteration 23552 => Loss: 47.89272683910431283039\n",
      "Iteration 23553 => Loss: 47.89255140834453072785\n",
      "Iteration 23554 => Loss: 47.89237597896153886268\n",
      "Iteration 23555 => Loss: 47.89220055095530170775\n",
      "Iteration 23556 => Loss: 47.89202512432581215762\n",
      "Iteration 23557 => Loss: 47.89184969907307731773\n",
      "Iteration 23558 => Loss: 47.89167427519706166095\n",
      "Iteration 23559 => Loss: 47.89149885269775097640\n",
      "Iteration 23560 => Loss: 47.89132343157515947496\n",
      "Iteration 23561 => Loss: 47.89114801182926584033\n",
      "Iteration 23562 => Loss: 47.89097259346004875624\n",
      "Iteration 23563 => Loss: 47.89079717646751532811\n",
      "Iteration 23564 => Loss: 47.89062176085163713424\n",
      "Iteration 23565 => Loss: 47.89044634661240706919\n",
      "Iteration 23566 => Loss: 47.89027093374983223839\n",
      "Iteration 23567 => Loss: 47.89009552226387711471\n",
      "Iteration 23568 => Loss: 47.88992011215454880357\n",
      "Iteration 23569 => Loss: 47.88974470342182598870\n",
      "Iteration 23570 => Loss: 47.88956929606570867008\n",
      "Iteration 23571 => Loss: 47.88939389008617553145\n",
      "Iteration 23572 => Loss: 47.88921848548321236194\n",
      "Iteration 23573 => Loss: 47.88904308225682626698\n",
      "Iteration 23574 => Loss: 47.88886768040698171944\n",
      "Iteration 23575 => Loss: 47.88869227993367871932\n",
      "Iteration 23576 => Loss: 47.88851688083692437203\n",
      "Iteration 23577 => Loss: 47.88834148311669736131\n",
      "Iteration 23578 => Loss: 47.88816608677297637087\n",
      "Iteration 23579 => Loss: 47.88799069180574718985\n",
      "Iteration 23580 => Loss: 47.88781529821502402910\n",
      "Iteration 23581 => Loss: 47.88763990600077136151\n",
      "Iteration 23582 => Loss: 47.88746451516298918705\n",
      "Iteration 23583 => Loss: 47.88728912570164908402\n",
      "Iteration 23584 => Loss: 47.88711373761678657957\n",
      "Iteration 23585 => Loss: 47.88693835090833772483\n",
      "Iteration 23586 => Loss: 47.88676296557632383610\n",
      "Iteration 23587 => Loss: 47.88658758162071649167\n",
      "Iteration 23588 => Loss: 47.88641219904152279696\n",
      "Iteration 23589 => Loss: 47.88623681783872143569\n",
      "Iteration 23590 => Loss: 47.88606143801230530244\n",
      "Iteration 23591 => Loss: 47.88588605956224597548\n",
      "Iteration 23592 => Loss: 47.88571068248855056027\n",
      "Iteration 23593 => Loss: 47.88553530679122616220\n",
      "Iteration 23594 => Loss: 47.88535993247022304331\n",
      "Iteration 23595 => Loss: 47.88518455952554830901\n",
      "Iteration 23596 => Loss: 47.88500918795720195931\n",
      "Iteration 23597 => Loss: 47.88483381776513425621\n",
      "Iteration 23598 => Loss: 47.88465844894939493770\n",
      "Iteration 23599 => Loss: 47.88448308150994847665\n",
      "Iteration 23600 => Loss: 47.88430771544675224050\n",
      "Iteration 23601 => Loss: 47.88413235075981333466\n",
      "Iteration 23602 => Loss: 47.88395698744914597000\n",
      "Iteration 23603 => Loss: 47.88378162551470751396\n",
      "Iteration 23604 => Loss: 47.88360626495650507195\n",
      "Iteration 23605 => Loss: 47.88343090577452443313\n",
      "Iteration 23606 => Loss: 47.88325554796874428121\n",
      "Iteration 23607 => Loss: 47.88308019153917882704\n",
      "Iteration 23608 => Loss: 47.88290483648579964893\n",
      "Iteration 23609 => Loss: 47.88272948280859253600\n",
      "Iteration 23610 => Loss: 47.88255413050755038284\n",
      "Iteration 23611 => Loss: 47.88237877958264476774\n",
      "Iteration 23612 => Loss: 47.88220343003391832326\n",
      "Iteration 23613 => Loss: 47.88202808186132131141\n",
      "Iteration 23614 => Loss: 47.88185273506482531047\n",
      "Iteration 23615 => Loss: 47.88167738964445163674\n",
      "Iteration 23616 => Loss: 47.88150204560020029021\n",
      "Iteration 23617 => Loss: 47.88132670293202153289\n",
      "Iteration 23618 => Loss: 47.88115136163990825935\n",
      "Iteration 23619 => Loss: 47.88097602172388889130\n",
      "Iteration 23620 => Loss: 47.88080068318391369075\n",
      "Iteration 23621 => Loss: 47.88062534601998976314\n",
      "Iteration 23622 => Loss: 47.88045001023211000302\n",
      "Iteration 23623 => Loss: 47.88027467582025309412\n",
      "Iteration 23624 => Loss: 47.88009934278439772015\n",
      "Iteration 23625 => Loss: 47.87992401112456519741\n",
      "Iteration 23626 => Loss: 47.87974868084071289331\n",
      "Iteration 23627 => Loss: 47.87957335193285501873\n",
      "Iteration 23628 => Loss: 47.87939802440097025737\n",
      "Iteration 23629 => Loss: 47.87922269824502308211\n",
      "Iteration 23630 => Loss: 47.87904737346505612550\n",
      "Iteration 23631 => Loss: 47.87887205006100543869\n",
      "Iteration 23632 => Loss: 47.87869672803289233798\n",
      "Iteration 23633 => Loss: 47.87852140738069550707\n",
      "Iteration 23634 => Loss: 47.87834608810442205140\n",
      "Iteration 23635 => Loss: 47.87817077020400802212\n",
      "Iteration 23636 => Loss: 47.87799545367951736807\n",
      "Iteration 23637 => Loss: 47.87782013853088614042\n",
      "Iteration 23638 => Loss: 47.87764482475812144457\n",
      "Iteration 23639 => Loss: 47.87746951236120906970\n",
      "Iteration 23640 => Loss: 47.87729420134013480492\n",
      "Iteration 23641 => Loss: 47.87711889169491286111\n",
      "Iteration 23642 => Loss: 47.87694358342547928942\n",
      "Iteration 23643 => Loss: 47.87676827653186961697\n",
      "Iteration 23644 => Loss: 47.87659297101406252750\n",
      "Iteration 23645 => Loss: 47.87641766687205802100\n",
      "Iteration 23646 => Loss: 47.87624236410579214862\n",
      "Iteration 23647 => Loss: 47.87606706271532175379\n",
      "Iteration 23648 => Loss: 47.87589176270061130936\n",
      "Iteration 23649 => Loss: 47.87571646406161818277\n",
      "Iteration 23650 => Loss: 47.87554116679840632287\n",
      "Iteration 23651 => Loss: 47.87536587091089046453\n",
      "Iteration 23652 => Loss: 47.87519057639907771318\n",
      "Iteration 23653 => Loss: 47.87501528326298938509\n",
      "Iteration 23654 => Loss: 47.87483999150257574229\n",
      "Iteration 23655 => Loss: 47.87466470111785099562\n",
      "Iteration 23656 => Loss: 47.87448941210877961794\n",
      "Iteration 23657 => Loss: 47.87431412447538292554\n",
      "Iteration 23658 => Loss: 47.87413883821763249671\n",
      "Iteration 23659 => Loss: 47.87396355333551412059\n",
      "Iteration 23660 => Loss: 47.87378826982902069176\n",
      "Iteration 23661 => Loss: 47.87361298769814510479\n",
      "Iteration 23662 => Loss: 47.87343770694290157053\n",
      "Iteration 23663 => Loss: 47.87326242756321903471\n",
      "Iteration 23664 => Loss: 47.87308714955912591904\n",
      "Iteration 23665 => Loss: 47.87291187293060801267\n",
      "Iteration 23666 => Loss: 47.87273659767765821016\n",
      "Iteration 23667 => Loss: 47.87256132380023387896\n",
      "Iteration 23668 => Loss: 47.87238605129838475705\n",
      "Iteration 23669 => Loss: 47.87221078017205400101\n",
      "Iteration 23670 => Loss: 47.87203551042123450543\n",
      "Iteration 23671 => Loss: 47.87186024204591205944\n",
      "Iteration 23672 => Loss: 47.87168497504610797932\n",
      "Iteration 23673 => Loss: 47.87150970942177963252\n",
      "Iteration 23674 => Loss: 47.87133444517291991360\n",
      "Iteration 23675 => Loss: 47.87115918229955013885\n",
      "Iteration 23676 => Loss: 47.87098392080162057027\n",
      "Iteration 23677 => Loss: 47.87080866067913120787\n",
      "Iteration 23678 => Loss: 47.87063340193206073536\n",
      "Iteration 23679 => Loss: 47.87045814456041625817\n",
      "Iteration 23680 => Loss: 47.87028288856420488173\n",
      "Iteration 23681 => Loss: 47.87010763394338397347\n",
      "Iteration 23682 => Loss: 47.86993238069794642797\n",
      "Iteration 23683 => Loss: 47.86975712882788513980\n",
      "Iteration 23684 => Loss: 47.86958187833318589810\n",
      "Iteration 23685 => Loss: 47.86940662921384870288\n",
      "Iteration 23686 => Loss: 47.86923138146986644870\n",
      "Iteration 23687 => Loss: 47.86905613510121781928\n",
      "Iteration 23688 => Loss: 47.86888089010788149835\n",
      "Iteration 23689 => Loss: 47.86870564648986459133\n",
      "Iteration 23690 => Loss: 47.86853040424715999279\n",
      "Iteration 23691 => Loss: 47.86835516337975349188\n",
      "Iteration 23692 => Loss: 47.86817992388759535061\n",
      "Iteration 23693 => Loss: 47.86800468577073530696\n",
      "Iteration 23694 => Loss: 47.86782944902913072838\n",
      "Iteration 23695 => Loss: 47.86765421366275319315\n",
      "Iteration 23696 => Loss: 47.86747897967164533384\n",
      "Iteration 23697 => Loss: 47.86730374705575741245\n",
      "Iteration 23698 => Loss: 47.86712851581506811272\n",
      "Iteration 23699 => Loss: 47.86695328594958454005\n",
      "Iteration 23700 => Loss: 47.86677805745930669445\n",
      "Iteration 23701 => Loss: 47.86660283034421325965\n",
      "Iteration 23702 => Loss: 47.86642760460429002478\n",
      "Iteration 23703 => Loss: 47.86625238023953698985\n",
      "Iteration 23704 => Loss: 47.86607715724991862771\n",
      "Iteration 23705 => Loss: 47.86590193563546336009\n",
      "Iteration 23706 => Loss: 47.86572671539612855440\n",
      "Iteration 23707 => Loss: 47.86555149653191421066\n",
      "Iteration 23708 => Loss: 47.86537627904279190716\n",
      "Iteration 23709 => Loss: 47.86520106292879006560\n",
      "Iteration 23710 => Loss: 47.86502584818985894799\n",
      "Iteration 23711 => Loss: 47.86485063482601276519\n",
      "Iteration 23712 => Loss: 47.86467542283722309548\n",
      "Iteration 23713 => Loss: 47.86450021222348283345\n",
      "Iteration 23714 => Loss: 47.86432500298480618994\n",
      "Iteration 23715 => Loss: 47.86414979512115053240\n",
      "Iteration 23716 => Loss: 47.86397458863252296624\n",
      "Iteration 23717 => Loss: 47.86379938351890928061\n",
      "Iteration 23718 => Loss: 47.86362417978028815924\n",
      "Iteration 23719 => Loss: 47.86344897741665960211\n",
      "Iteration 23720 => Loss: 47.86327377642799518753\n",
      "Iteration 23721 => Loss: 47.86309857681432333720\n",
      "Iteration 23722 => Loss: 47.86292337857560141856\n",
      "Iteration 23723 => Loss: 47.86274818171182943161\n",
      "Iteration 23724 => Loss: 47.86257298622297184920\n",
      "Iteration 23725 => Loss: 47.86239779210907130391\n",
      "Iteration 23726 => Loss: 47.86222259937004963604\n",
      "Iteration 23727 => Loss: 47.86204740800594947814\n",
      "Iteration 23728 => Loss: 47.86187221801675661936\n",
      "Iteration 23729 => Loss: 47.86169702940243553257\n",
      "Iteration 23730 => Loss: 47.86152184216297200692\n",
      "Iteration 23731 => Loss: 47.86134665629837314782\n",
      "Iteration 23732 => Loss: 47.86117147180863184985\n",
      "Iteration 23733 => Loss: 47.86099628869373390216\n",
      "Iteration 23734 => Loss: 47.86082110695364377762\n",
      "Iteration 23735 => Loss: 47.86064592658836858163\n",
      "Iteration 23736 => Loss: 47.86047074759792963050\n",
      "Iteration 23737 => Loss: 47.86029556998226297537\n",
      "Iteration 23738 => Loss: 47.86012039374139703796\n",
      "Iteration 23739 => Loss: 47.85994521887528918569\n",
      "Iteration 23740 => Loss: 47.85977004538396073485\n",
      "Iteration 23741 => Loss: 47.85959487326737615831\n",
      "Iteration 23742 => Loss: 47.85941970252550703435\n",
      "Iteration 23743 => Loss: 47.85924453315840310097\n",
      "Iteration 23744 => Loss: 47.85906936516601462017\n",
      "Iteration 23745 => Loss: 47.85889419854832027568\n",
      "Iteration 23746 => Loss: 47.85871903330533427834\n",
      "Iteration 23747 => Loss: 47.85854386943703531188\n",
      "Iteration 23748 => Loss: 47.85836870694343758714\n",
      "Iteration 23749 => Loss: 47.85819354582447004987\n",
      "Iteration 23750 => Loss: 47.85801838608016822718\n",
      "Iteration 23751 => Loss: 47.85784322771051080281\n",
      "Iteration 23752 => Loss: 47.85766807071548356589\n",
      "Iteration 23753 => Loss: 47.85749291509510072729\n",
      "Iteration 23754 => Loss: 47.85731776084931254900\n",
      "Iteration 23755 => Loss: 47.85714260797811192560\n",
      "Iteration 23756 => Loss: 47.85696745648152727881\n",
      "Iteration 23757 => Loss: 47.85679230635951597606\n",
      "Iteration 23758 => Loss: 47.85661715761207091191\n",
      "Iteration 23759 => Loss: 47.85644201023917077009\n",
      "Iteration 23760 => Loss: 47.85626686424082976146\n",
      "Iteration 23761 => Loss: 47.85609171961701946429\n",
      "Iteration 23762 => Loss: 47.85591657636776119489\n",
      "Iteration 23763 => Loss: 47.85574143449297679354\n",
      "Iteration 23764 => Loss: 47.85556629399272310366\n",
      "Iteration 23765 => Loss: 47.85539115486697170354\n",
      "Iteration 23766 => Loss: 47.85521601711567996063\n",
      "Iteration 23767 => Loss: 47.85504088073885498034\n",
      "Iteration 23768 => Loss: 47.85486574573651807896\n",
      "Iteration 23769 => Loss: 47.85469061210861241307\n",
      "Iteration 23770 => Loss: 47.85451547985514508810\n",
      "Iteration 23771 => Loss: 47.85434034897612320947\n",
      "Iteration 23772 => Loss: 47.85416521947150414462\n",
      "Iteration 23773 => Loss: 47.85399009134128789356\n",
      "Iteration 23774 => Loss: 47.85381496458548156170\n",
      "Iteration 23775 => Loss: 47.85363983920404962191\n",
      "Iteration 23776 => Loss: 47.85346471519702049591\n",
      "Iteration 23777 => Loss: 47.85328959256431602398\n",
      "Iteration 23778 => Loss: 47.85311447130599304955\n",
      "Iteration 23779 => Loss: 47.85293935142198762378\n",
      "Iteration 23780 => Loss: 47.85276423291234237922\n",
      "Iteration 23781 => Loss: 47.85258911577700047246\n",
      "Iteration 23782 => Loss: 47.85241400001597611435\n",
      "Iteration 23783 => Loss: 47.85223888562924798862\n",
      "Iteration 23784 => Loss: 47.85206377261681609525\n",
      "Iteration 23785 => Loss: 47.85188866097864490712\n",
      "Iteration 23786 => Loss: 47.85171355071473442422\n",
      "Iteration 23787 => Loss: 47.85153844182509175198\n",
      "Iteration 23788 => Loss: 47.85136333430972399583\n",
      "Iteration 23789 => Loss: 47.85118822816856720692\n",
      "Iteration 23790 => Loss: 47.85101312340160006897\n",
      "Iteration 23791 => Loss: 47.85083802000888653083\n",
      "Iteration 23792 => Loss: 47.85066291799036264365\n",
      "Iteration 23793 => Loss: 47.85048781734602840743\n",
      "Iteration 23794 => Loss: 47.85031271807589092759\n",
      "Iteration 23795 => Loss: 47.85013762017990757158\n",
      "Iteration 23796 => Loss: 47.84996252365809965568\n",
      "Iteration 23797 => Loss: 47.84978742851041744188\n",
      "Iteration 23798 => Loss: 47.84961233473687514106\n",
      "Iteration 23799 => Loss: 47.84943724233747985863\n",
      "Iteration 23800 => Loss: 47.84926215131217475118\n",
      "Iteration 23801 => Loss: 47.84908706166098113499\n",
      "Iteration 23802 => Loss: 47.84891197338389901006\n",
      "Iteration 23803 => Loss: 47.84873688648089284925\n",
      "Iteration 23804 => Loss: 47.84856180095195554713\n",
      "Iteration 23805 => Loss: 47.84838671679708710371\n",
      "Iteration 23806 => Loss: 47.84821163401625909728\n",
      "Iteration 23807 => Loss: 47.84803655260947863326\n",
      "Iteration 23808 => Loss: 47.84786147257674571165\n",
      "Iteration 23809 => Loss: 47.84768639391798927818\n",
      "Iteration 23810 => Loss: 47.84751131663326617627\n",
      "Iteration 23811 => Loss: 47.84733624072254798421\n",
      "Iteration 23812 => Loss: 47.84716116618579206943\n",
      "Iteration 23813 => Loss: 47.84698609302301974822\n",
      "Iteration 23814 => Loss: 47.84681102123421680972\n",
      "Iteration 23815 => Loss: 47.84663595081939746478\n",
      "Iteration 23816 => Loss: 47.84646088177849776457\n",
      "Iteration 23817 => Loss: 47.84628581411151060365\n",
      "Iteration 23818 => Loss: 47.84611074781847150916\n",
      "Iteration 23819 => Loss: 47.84593568289933074311\n",
      "Iteration 23820 => Loss: 47.84576061935407409464\n",
      "Iteration 23821 => Loss: 47.84558555718272998547\n",
      "Iteration 23822 => Loss: 47.84541049638526288845\n",
      "Iteration 23823 => Loss: 47.84523543696166569816\n",
      "Iteration 23824 => Loss: 47.84506037891190288747\n",
      "Iteration 23825 => Loss: 47.84488532223602419435\n",
      "Iteration 23826 => Loss: 47.84471026693397988083\n",
      "Iteration 23827 => Loss: 47.84453521300571310348\n",
      "Iteration 23828 => Loss: 47.84436016045129491658\n",
      "Iteration 23829 => Loss: 47.84418510927068268757\n",
      "Iteration 23830 => Loss: 47.84401005946384088929\n",
      "Iteration 23831 => Loss: 47.84383501103080504890\n",
      "Iteration 23832 => Loss: 47.84365996397151121755\n",
      "Iteration 23833 => Loss: 47.84348491828601623865\n",
      "Iteration 23834 => Loss: 47.84330987397424195251\n",
      "Iteration 23835 => Loss: 47.84313483103620967540\n",
      "Iteration 23836 => Loss: 47.84295978947192651276\n",
      "Iteration 23837 => Loss: 47.84278474928132141031\n",
      "Iteration 23838 => Loss: 47.84260971046445831689\n",
      "Iteration 23839 => Loss: 47.84243467302126617824\n",
      "Iteration 23840 => Loss: 47.84225963695178052149\n",
      "Iteration 23841 => Loss: 47.84208460225595871407\n",
      "Iteration 23842 => Loss: 47.84190956893379365056\n",
      "Iteration 23843 => Loss: 47.84173453698527822553\n",
      "Iteration 23844 => Loss: 47.84155950641043375526\n",
      "Iteration 23845 => Loss: 47.84138447720918918549\n",
      "Iteration 23846 => Loss: 47.84120944938155162163\n",
      "Iteration 23847 => Loss: 47.84103442292756369625\n",
      "Iteration 23848 => Loss: 47.84085939784716856593\n",
      "Iteration 23849 => Loss: 47.84068437414033070354\n",
      "Iteration 23850 => Loss: 47.84050935180709274164\n",
      "Iteration 23851 => Loss: 47.84033433084743336394\n",
      "Iteration 23852 => Loss: 47.84015931126128862161\n",
      "Iteration 23853 => Loss: 47.83998429304871535805\n",
      "Iteration 23854 => Loss: 47.83980927620967094072\n",
      "Iteration 23855 => Loss: 47.83963426074414826417\n",
      "Iteration 23856 => Loss: 47.83945924665214022298\n",
      "Iteration 23857 => Loss: 47.83928423393363971172\n",
      "Iteration 23858 => Loss: 47.83910922258861830869\n",
      "Iteration 23859 => Loss: 47.83893421261707601388\n",
      "Iteration 23860 => Loss: 47.83875920401901282730\n",
      "Iteration 23861 => Loss: 47.83858419679440743266\n",
      "Iteration 23862 => Loss: 47.83840919094323140826\n",
      "Iteration 23863 => Loss: 47.83823418646552028122\n",
      "Iteration 23864 => Loss: 47.83805918336121010270\n",
      "Iteration 23865 => Loss: 47.83788418163032218899\n",
      "Iteration 23866 => Loss: 47.83770918127284232924\n",
      "Iteration 23867 => Loss: 47.83753418228877762886\n",
      "Iteration 23868 => Loss: 47.83735918467806413901\n",
      "Iteration 23869 => Loss: 47.83718418844073028140\n",
      "Iteration 23870 => Loss: 47.83700919357676184518\n",
      "Iteration 23871 => Loss: 47.83683420008614461949\n",
      "Iteration 23872 => Loss: 47.83665920796886439348\n",
      "Iteration 23873 => Loss: 47.83648421722489985086\n",
      "Iteration 23874 => Loss: 47.83630922785426520250\n",
      "Iteration 23875 => Loss: 47.83613423985694623752\n",
      "Iteration 23876 => Loss: 47.83595925323290742881\n",
      "Iteration 23877 => Loss: 47.83578426798217719806\n",
      "Iteration 23878 => Loss: 47.83560928410470580729\n",
      "Iteration 23879 => Loss: 47.83543430160050036193\n",
      "Iteration 23880 => Loss: 47.83525932046955375654\n",
      "Iteration 23881 => Loss: 47.83508434071183756942\n",
      "Iteration 23882 => Loss: 47.83490936232737311684\n",
      "Iteration 23883 => Loss: 47.83473438531611776625\n",
      "Iteration 23884 => Loss: 47.83455940967807151765\n",
      "Iteration 23885 => Loss: 47.83438443541322726560\n",
      "Iteration 23886 => Loss: 47.83420946252156369383\n",
      "Iteration 23887 => Loss: 47.83403449100309501318\n",
      "Iteration 23888 => Loss: 47.83385952085777859111\n",
      "Iteration 23889 => Loss: 47.83368455208560732217\n",
      "Iteration 23890 => Loss: 47.83350958468661673351\n",
      "Iteration 23891 => Loss: 47.83333461866074998170\n",
      "Iteration 23892 => Loss: 47.83315965400797864504\n",
      "Iteration 23893 => Loss: 47.83298469072835956695\n",
      "Iteration 23894 => Loss: 47.83280972882182879857\n",
      "Iteration 23895 => Loss: 47.83263476828837212906\n",
      "Iteration 23896 => Loss: 47.83245980912801798013\n",
      "Iteration 23897 => Loss: 47.83228485134073082463\n",
      "Iteration 23898 => Loss: 47.83210989492649645172\n",
      "Iteration 23899 => Loss: 47.83193493988530065053\n",
      "Iteration 23900 => Loss: 47.83175998621715052650\n",
      "Iteration 23901 => Loss: 47.83158503392203897420\n",
      "Iteration 23902 => Loss: 47.83141008299994467734\n",
      "Iteration 23903 => Loss: 47.83123513345084631965\n",
      "Iteration 23904 => Loss: 47.83106018527475100655\n",
      "Iteration 23905 => Loss: 47.83088523847164452718\n",
      "Iteration 23906 => Loss: 47.83071029304149135442\n",
      "Iteration 23907 => Loss: 47.83053534898430569910\n",
      "Iteration 23908 => Loss: 47.83036040630008756125\n",
      "Iteration 23909 => Loss: 47.83018546498878720286\n",
      "Iteration 23910 => Loss: 47.83001052505044015106\n",
      "Iteration 23911 => Loss: 47.82983558648501087873\n",
      "Iteration 23912 => Loss: 47.82966064929247096416\n",
      "Iteration 23913 => Loss: 47.82948571347283461819\n",
      "Iteration 23914 => Loss: 47.82931077902609473540\n",
      "Iteration 23915 => Loss: 47.82913584595223710494\n",
      "Iteration 23916 => Loss: 47.82896091425122619967\n",
      "Iteration 23917 => Loss: 47.82878598392306912501\n",
      "Iteration 23918 => Loss: 47.82861105496778009183\n",
      "Iteration 23919 => Loss: 47.82843612738528804584\n",
      "Iteration 23920 => Loss: 47.82826120117566404133\n",
      "Iteration 23921 => Loss: 47.82808627633882281316\n",
      "Iteration 23922 => Loss: 47.82791135287477146676\n",
      "Iteration 23923 => Loss: 47.82773643078353131841\n",
      "Iteration 23924 => Loss: 47.82756151006505973555\n",
      "Iteration 23925 => Loss: 47.82738659071937092904\n",
      "Iteration 23926 => Loss: 47.82721167274642937173\n",
      "Iteration 23927 => Loss: 47.82703675614624216905\n",
      "Iteration 23928 => Loss: 47.82686184091878089930\n",
      "Iteration 23929 => Loss: 47.82668692706404556247\n",
      "Iteration 23930 => Loss: 47.82651201458202905314\n",
      "Iteration 23931 => Loss: 47.82633710347273847674\n",
      "Iteration 23932 => Loss: 47.82616219373609567356\n",
      "Iteration 23933 => Loss: 47.82598728537217169787\n",
      "Iteration 23934 => Loss: 47.82581237838090970627\n",
      "Iteration 23935 => Loss: 47.82563747276229548788\n",
      "Iteration 23936 => Loss: 47.82546256851634325358\n",
      "Iteration 23937 => Loss: 47.82528766564303168707\n",
      "Iteration 23938 => Loss: 47.82511276414233947207\n",
      "Iteration 23939 => Loss: 47.82493786401428081945\n",
      "Iteration 23940 => Loss: 47.82476296525882020205\n",
      "Iteration 23941 => Loss: 47.82458806787595051446\n",
      "Iteration 23942 => Loss: 47.82441317186567886210\n",
      "Iteration 23943 => Loss: 47.82423827722796261241\n",
      "Iteration 23944 => Loss: 47.82406338396282308167\n",
      "Iteration 23945 => Loss: 47.82388849207023895360\n",
      "Iteration 23946 => Loss: 47.82371360155018180649\n",
      "Iteration 23947 => Loss: 47.82353871240265874576\n",
      "Iteration 23948 => Loss: 47.82336382462766977142\n",
      "Iteration 23949 => Loss: 47.82318893822520067260\n",
      "Iteration 23950 => Loss: 47.82301405319520881676\n",
      "Iteration 23951 => Loss: 47.82283916953770841474\n",
      "Iteration 23952 => Loss: 47.82266428725268525568\n",
      "Iteration 23953 => Loss: 47.82248940634015355045\n",
      "Iteration 23954 => Loss: 47.82231452680005645561\n",
      "Iteration 23955 => Loss: 47.82213964863240107661\n",
      "Iteration 23956 => Loss: 47.82196477183717320258\n",
      "Iteration 23957 => Loss: 47.82178989641439414982\n",
      "Iteration 23958 => Loss: 47.82161502236401418031\n",
      "Iteration 23959 => Loss: 47.82144014968604750493\n",
      "Iteration 23960 => Loss: 47.82126527838043728025\n",
      "Iteration 23961 => Loss: 47.82109040844724034969\n",
      "Iteration 23962 => Loss: 47.82091553988642829154\n",
      "Iteration 23963 => Loss: 47.82074067269795136781\n",
      "Iteration 23964 => Loss: 47.82056580688181668393\n",
      "Iteration 23965 => Loss: 47.82039094243804555617\n",
      "Iteration 23966 => Loss: 47.82021607936658114113\n",
      "Iteration 23967 => Loss: 47.82004121766742343880\n",
      "Iteration 23968 => Loss: 47.81986635734057955460\n",
      "Iteration 23969 => Loss: 47.81969149838604238312\n",
      "Iteration 23970 => Loss: 47.81951664080379771349\n",
      "Iteration 23971 => Loss: 47.81934178459378159687\n",
      "Iteration 23972 => Loss: 47.81916692975606508753\n",
      "Iteration 23973 => Loss: 47.81899207629059134206\n",
      "Iteration 23974 => Loss: 47.81881722419736746588\n",
      "Iteration 23975 => Loss: 47.81864237347635793185\n",
      "Iteration 23976 => Loss: 47.81846752412759116169\n",
      "Iteration 23977 => Loss: 47.81829267615101031197\n",
      "Iteration 23978 => Loss: 47.81811782954662248812\n",
      "Iteration 23979 => Loss: 47.81794298431442058472\n",
      "Iteration 23980 => Loss: 47.81776814045441881262\n",
      "Iteration 23981 => Loss: 47.81759329796657453926\n",
      "Iteration 23982 => Loss: 47.81741845685088776463\n",
      "Iteration 23983 => Loss: 47.81724361710732296160\n",
      "Iteration 23984 => Loss: 47.81706877873592276273\n",
      "Iteration 23985 => Loss: 47.81689394173662321919\n",
      "Iteration 23986 => Loss: 47.81671910610943143638\n",
      "Iteration 23987 => Loss: 47.81654427185434741432\n",
      "Iteration 23988 => Loss: 47.81636943897135694215\n",
      "Iteration 23989 => Loss: 47.81619460746044580901\n",
      "Iteration 23990 => Loss: 47.81601977732159269863\n",
      "Iteration 23991 => Loss: 47.81584494855481892728\n",
      "Iteration 23992 => Loss: 47.81567012116007475697\n",
      "Iteration 23993 => Loss: 47.81549529513737439856\n",
      "Iteration 23994 => Loss: 47.81532047048668943034\n",
      "Iteration 23995 => Loss: 47.81514564720802695774\n",
      "Iteration 23996 => Loss: 47.81497082530136566447\n",
      "Iteration 23997 => Loss: 47.81479600476669844511\n",
      "Iteration 23998 => Loss: 47.81462118560402529965\n",
      "Iteration 23999 => Loss: 47.81444636781330359554\n",
      "Iteration 24000 => Loss: 47.81427155139454754362\n",
      "Iteration 24001 => Loss: 47.81409673634775003848\n",
      "Iteration 24002 => Loss: 47.81392192267287555296\n",
      "Iteration 24003 => Loss: 47.81374711036995250879\n",
      "Iteration 24004 => Loss: 47.81357229943894537882\n",
      "Iteration 24005 => Loss: 47.81339748987982574135\n",
      "Iteration 24006 => Loss: 47.81322268169260780724\n",
      "Iteration 24007 => Loss: 47.81304787487728447104\n",
      "Iteration 24008 => Loss: 47.81287306943383441649\n",
      "Iteration 24009 => Loss: 47.81269826536224343272\n",
      "Iteration 24010 => Loss: 47.81252346266250441431\n",
      "Iteration 24011 => Loss: 47.81234866133461736126\n",
      "Iteration 24012 => Loss: 47.81217386137854674644\n",
      "Iteration 24013 => Loss: 47.81199906279429967526\n",
      "Iteration 24014 => Loss: 47.81182426558187614773\n",
      "Iteration 24015 => Loss: 47.81164946974125484758\n",
      "Iteration 24016 => Loss: 47.81147467527238603680\n",
      "Iteration 24017 => Loss: 47.81129988217533366424\n",
      "Iteration 24018 => Loss: 47.81112509045004088648\n",
      "Iteration 24019 => Loss: 47.81095030009648638725\n",
      "Iteration 24020 => Loss: 47.81077551111469858824\n",
      "Iteration 24021 => Loss: 47.81060072350462064605\n",
      "Iteration 24022 => Loss: 47.81042593726629519324\n",
      "Iteration 24023 => Loss: 47.81025115239966538638\n",
      "Iteration 24024 => Loss: 47.81007636890473833091\n",
      "Iteration 24025 => Loss: 47.80990158678150692140\n",
      "Iteration 24026 => Loss: 47.80972680602997826327\n",
      "Iteration 24027 => Loss: 47.80955202665009551311\n",
      "Iteration 24028 => Loss: 47.80937724864185867091\n",
      "Iteration 24029 => Loss: 47.80920247200529615839\n",
      "Iteration 24030 => Loss: 47.80902769674035113212\n",
      "Iteration 24031 => Loss: 47.80885292284705201382\n",
      "Iteration 24032 => Loss: 47.80867815032536327635\n",
      "Iteration 24033 => Loss: 47.80850337917527781428\n",
      "Iteration 24034 => Loss: 47.80832860939678141676\n",
      "Iteration 24035 => Loss: 47.80815384098987408379\n",
      "Iteration 24036 => Loss: 47.80797907395454870993\n",
      "Iteration 24037 => Loss: 47.80780430829077687349\n",
      "Iteration 24038 => Loss: 47.80762954399855146903\n",
      "Iteration 24039 => Loss: 47.80745478107785828570\n",
      "Iteration 24040 => Loss: 47.80728001952873285063\n",
      "Iteration 24041 => Loss: 47.80710525935110410956\n",
      "Iteration 24042 => Loss: 47.80693050054497916790\n",
      "Iteration 24043 => Loss: 47.80675574311036513109\n",
      "Iteration 24044 => Loss: 47.80658098704722647199\n",
      "Iteration 24045 => Loss: 47.80640623235554897974\n",
      "Iteration 24046 => Loss: 47.80623147903537528691\n",
      "Iteration 24047 => Loss: 47.80605672708662012838\n",
      "Iteration 24048 => Loss: 47.80588197650934034755\n",
      "Iteration 24049 => Loss: 47.80570722730348620644\n",
      "Iteration 24050 => Loss: 47.80553247946903638876\n",
      "Iteration 24051 => Loss: 47.80535773300600510538\n",
      "Iteration 24052 => Loss: 47.80518298791439946172\n",
      "Iteration 24053 => Loss: 47.80500824419414840349\n",
      "Iteration 24054 => Loss: 47.80483350184530166871\n",
      "Iteration 24055 => Loss: 47.80465876086780951937\n",
      "Iteration 24056 => Loss: 47.80448402126169327175\n",
      "Iteration 24057 => Loss: 47.80430928302691029330\n",
      "Iteration 24058 => Loss: 47.80413454616345347858\n",
      "Iteration 24059 => Loss: 47.80395981067131572217\n",
      "Iteration 24060 => Loss: 47.80378507655053965664\n",
      "Iteration 24061 => Loss: 47.80361034380102580599\n",
      "Iteration 24062 => Loss: 47.80343561242283811907\n",
      "Iteration 24063 => Loss: 47.80326088241591264705\n",
      "Iteration 24064 => Loss: 47.80308615378023517906\n",
      "Iteration 24065 => Loss: 47.80291142651586966394\n",
      "Iteration 24066 => Loss: 47.80273670062273083659\n",
      "Iteration 24067 => Loss: 47.80256197610083290783\n",
      "Iteration 24068 => Loss: 47.80238725295014745598\n",
      "Iteration 24069 => Loss: 47.80221253117068158645\n",
      "Iteration 24070 => Loss: 47.80203781076244951009\n",
      "Iteration 24071 => Loss: 47.80186309172540148893\n",
      "Iteration 24072 => Loss: 47.80168837405953752295\n",
      "Iteration 24073 => Loss: 47.80151365776484340131\n",
      "Iteration 24074 => Loss: 47.80133894284131201857\n",
      "Iteration 24075 => Loss: 47.80116422928895048017\n",
      "Iteration 24076 => Loss: 47.80098951710770904810\n",
      "Iteration 24077 => Loss: 47.80081480629762324952\n",
      "Iteration 24078 => Loss: 47.80064009685864334642\n",
      "Iteration 24079 => Loss: 47.80046538879077644424\n",
      "Iteration 24080 => Loss: 47.80029068209400122669\n",
      "Iteration 24081 => Loss: 47.80011597676833190462\n",
      "Iteration 24082 => Loss: 47.79994127281374005634\n",
      "Iteration 24083 => Loss: 47.79976657023019015469\n",
      "Iteration 24084 => Loss: 47.79959186901773193767\n",
      "Iteration 24085 => Loss: 47.79941716917630145645\n",
      "Iteration 24086 => Loss: 47.79924247070591292186\n",
      "Iteration 24087 => Loss: 47.79906777360654501763\n",
      "Iteration 24088 => Loss: 47.79889307787816932205\n",
      "Iteration 24089 => Loss: 47.79871838352082846768\n",
      "Iteration 24090 => Loss: 47.79854369053446561111\n",
      "Iteration 24091 => Loss: 47.79836899891908785776\n",
      "Iteration 24092 => Loss: 47.79819430867468810220\n",
      "Iteration 24093 => Loss: 47.79801961980124502816\n",
      "Iteration 24094 => Loss: 47.79784493229874442477\n",
      "Iteration 24095 => Loss: 47.79767024616719339747\n",
      "Iteration 24096 => Loss: 47.79749556140654220826\n",
      "Iteration 24097 => Loss: 47.79732087801682638428\n",
      "Iteration 24098 => Loss: 47.79714619599803171468\n",
      "Iteration 24099 => Loss: 47.79697151535008714518\n",
      "Iteration 24100 => Loss: 47.79679683607307794091\n",
      "Iteration 24101 => Loss: 47.79662215816691883674\n",
      "Iteration 24102 => Loss: 47.79644748163162404353\n",
      "Iteration 24103 => Loss: 47.79627280646716513957\n",
      "Iteration 24104 => Loss: 47.79609813267358475741\n",
      "Iteration 24105 => Loss: 47.79592346025081184280\n",
      "Iteration 24106 => Loss: 47.79574878919886060658\n",
      "Iteration 24107 => Loss: 47.79557411951771683789\n",
      "Iteration 24108 => Loss: 47.79539945120738053674\n",
      "Iteration 24109 => Loss: 47.79522478426783038685\n",
      "Iteration 24110 => Loss: 47.79505011869903086108\n",
      "Iteration 24111 => Loss: 47.79487545450103880285\n",
      "Iteration 24112 => Loss: 47.79470079167377605245\n",
      "Iteration 24113 => Loss: 47.79452613021727103160\n",
      "Iteration 24114 => Loss: 47.79435147013149531858\n",
      "Iteration 24115 => Loss: 47.79417681141642049170\n",
      "Iteration 24116 => Loss: 47.79400215407209628893\n",
      "Iteration 24117 => Loss: 47.79382749809845165601\n",
      "Iteration 24118 => Loss: 47.79365284349550080378\n",
      "Iteration 24119 => Loss: 47.79347819026322241598\n",
      "Iteration 24120 => Loss: 47.79330353840163780887\n",
      "Iteration 24121 => Loss: 47.79312888791070434991\n",
      "Iteration 24122 => Loss: 47.79295423879040782822\n",
      "Iteration 24123 => Loss: 47.79277959104075534924\n",
      "Iteration 24124 => Loss: 47.79260494466173270212\n",
      "Iteration 24125 => Loss: 47.79243029965331857056\n",
      "Iteration 24126 => Loss: 47.79225565601547742745\n",
      "Iteration 24127 => Loss: 47.79208101374828032704\n",
      "Iteration 24128 => Loss: 47.79190637285164910963\n",
      "Iteration 24129 => Loss: 47.79173173332559088067\n",
      "Iteration 24130 => Loss: 47.79155709517009142928\n",
      "Iteration 24131 => Loss: 47.79138245838514365005\n",
      "Iteration 24132 => Loss: 47.79120782297073333211\n",
      "Iteration 24133 => Loss: 47.79103318892686047548\n",
      "Iteration 24134 => Loss: 47.79085855625349665843\n",
      "Iteration 24135 => Loss: 47.79068392495064898640\n",
      "Iteration 24136 => Loss: 47.79050929501831035395\n",
      "Iteration 24137 => Loss: 47.79033466645642391768\n",
      "Iteration 24138 => Loss: 47.79016003926504652100\n",
      "Iteration 24139 => Loss: 47.78998541344410000420\n",
      "Iteration 24140 => Loss: 47.78981078899364121071\n",
      "Iteration 24141 => Loss: 47.78963616591361329711\n",
      "Iteration 24142 => Loss: 47.78946154420401626339\n",
      "Iteration 24143 => Loss: 47.78928692386484300414\n",
      "Iteration 24144 => Loss: 47.78911230489609351935\n",
      "Iteration 24145 => Loss: 47.78893768729772517645\n",
      "Iteration 24146 => Loss: 47.78876307106975929173\n",
      "Iteration 24147 => Loss: 47.78858845621215323263\n",
      "Iteration 24148 => Loss: 47.78841384272492831542\n",
      "Iteration 24149 => Loss: 47.78823923060807743468\n",
      "Iteration 24150 => Loss: 47.78806461986155795785\n",
      "Iteration 24151 => Loss: 47.78789001048536988492\n",
      "Iteration 24152 => Loss: 47.78771540247950611047\n",
      "Iteration 24153 => Loss: 47.78754079584395952907\n",
      "Iteration 24154 => Loss: 47.78736619057871592986\n",
      "Iteration 24155 => Loss: 47.78719158668377531285\n",
      "Iteration 24156 => Loss: 47.78701698415910925632\n",
      "Iteration 24157 => Loss: 47.78684238300471065486\n",
      "Iteration 24158 => Loss: 47.78666778322058661388\n",
      "Iteration 24159 => Loss: 47.78649318480670160625\n",
      "Iteration 24160 => Loss: 47.78631858776304852654\n",
      "Iteration 24161 => Loss: 47.78614399208963448018\n",
      "Iteration 24162 => Loss: 47.78596939778645236174\n",
      "Iteration 24163 => Loss: 47.78579480485344532781\n",
      "Iteration 24164 => Loss: 47.78562021329064180009\n",
      "Iteration 24165 => Loss: 47.78544562309804177858\n",
      "Iteration 24166 => Loss: 47.78527103427561684157\n",
      "Iteration 24167 => Loss: 47.78509644682332435650\n",
      "Iteration 24168 => Loss: 47.78492186074119985051\n",
      "Iteration 24169 => Loss: 47.78474727602923621816\n",
      "Iteration 24170 => Loss: 47.78457269268737661605\n",
      "Iteration 24171 => Loss: 47.78439811071566367673\n",
      "Iteration 24172 => Loss: 47.78422353011406187306\n",
      "Iteration 24173 => Loss: 47.78404895088255699420\n",
      "Iteration 24174 => Loss: 47.78387437302111351300\n",
      "Iteration 24175 => Loss: 47.78369979652976695661\n",
      "Iteration 24176 => Loss: 47.78352522140848890331\n",
      "Iteration 24177 => Loss: 47.78335064765726514224\n",
      "Iteration 24178 => Loss: 47.78317607527606014628\n",
      "Iteration 24179 => Loss: 47.78300150426493786426\n",
      "Iteration 24180 => Loss: 47.78282693462380592564\n",
      "Iteration 24181 => Loss: 47.78265236635271406840\n",
      "Iteration 24182 => Loss: 47.78247779945160544912\n",
      "Iteration 24183 => Loss: 47.78230323392050138409\n",
      "Iteration 24184 => Loss: 47.78212866975936634617\n",
      "Iteration 24185 => Loss: 47.78195410696820744079\n",
      "Iteration 24186 => Loss: 47.78177954554700335166\n",
      "Iteration 24187 => Loss: 47.78160498549573276250\n",
      "Iteration 24188 => Loss: 47.78143042681444541131\n",
      "Iteration 24189 => Loss: 47.78125586950305603295\n",
      "Iteration 24190 => Loss: 47.78108131356157883829\n",
      "Iteration 24191 => Loss: 47.78090675899000672189\n",
      "Iteration 24192 => Loss: 47.78073220578835389460\n",
      "Iteration 24193 => Loss: 47.78055765395654930217\n",
      "Iteration 24194 => Loss: 47.78038310349464978799\n",
      "Iteration 24195 => Loss: 47.78020855440259850866\n",
      "Iteration 24196 => Loss: 47.78003400668040256960\n",
      "Iteration 24197 => Loss: 47.77985946032804775996\n",
      "Iteration 24198 => Loss: 47.77968491534550565802\n",
      "Iteration 24199 => Loss: 47.77951037173281179093\n",
      "Iteration 24200 => Loss: 47.77933582948992352613\n",
      "Iteration 24201 => Loss: 47.77916128861683375817\n",
      "Iteration 24202 => Loss: 47.77898674911351406536\n",
      "Iteration 24203 => Loss: 47.77881221097997865854\n",
      "Iteration 24204 => Loss: 47.77863767421621332687\n",
      "Iteration 24205 => Loss: 47.77846313882220385949\n",
      "Iteration 24206 => Loss: 47.77828860479792894012\n",
      "Iteration 24207 => Loss: 47.77811407214340277960\n",
      "Iteration 24208 => Loss: 47.77793954085859695624\n",
      "Iteration 24209 => Loss: 47.77776501094350436460\n",
      "Iteration 24210 => Loss: 47.77759048239809658298\n",
      "Iteration 24211 => Loss: 47.77741595522240203309\n",
      "Iteration 24212 => Loss: 47.77724142941638518778\n",
      "Iteration 24213 => Loss: 47.77706690498001762535\n",
      "Iteration 24214 => Loss: 47.77689238191330645122\n",
      "Iteration 24215 => Loss: 47.77671786021626587626\n",
      "Iteration 24216 => Loss: 47.77654333988884616247\n",
      "Iteration 24217 => Loss: 47.77636882093106862612\n",
      "Iteration 24218 => Loss: 47.77619430334290484552\n",
      "Iteration 24219 => Loss: 47.77601978712431929353\n",
      "Iteration 24220 => Loss: 47.77584527227534749727\n",
      "Iteration 24221 => Loss: 47.77567075879596814048\n",
      "Iteration 24222 => Loss: 47.77549624668615280143\n",
      "Iteration 24223 => Loss: 47.77532173594590858556\n",
      "Iteration 24224 => Loss: 47.77514722657519996574\n",
      "Iteration 24225 => Loss: 47.77497271857403404738\n",
      "Iteration 24226 => Loss: 47.77479821194239661963\n",
      "Iteration 24227 => Loss: 47.77462370668029478793\n",
      "Iteration 24228 => Loss: 47.77444920278770013056\n",
      "Iteration 24229 => Loss: 47.77427470026456290952\n",
      "Iteration 24230 => Loss: 47.77410019911094707368\n",
      "Iteration 24231 => Loss: 47.77392569932680288503\n",
      "Iteration 24232 => Loss: 47.77375120091213034357\n",
      "Iteration 24233 => Loss: 47.77357670386689392217\n",
      "Iteration 24234 => Loss: 47.77340220819112204254\n",
      "Iteration 24235 => Loss: 47.77322771388477207211\n",
      "Iteration 24236 => Loss: 47.77305322094783690545\n",
      "Iteration 24237 => Loss: 47.77287872938030943715\n",
      "Iteration 24238 => Loss: 47.77270423918221098347\n",
      "Iteration 24239 => Loss: 47.77252975035346338473\n",
      "Iteration 24240 => Loss: 47.77235526289413058976\n",
      "Iteration 24241 => Loss: 47.77218077680414864972\n",
      "Iteration 24242 => Loss: 47.77200629208352467003\n",
      "Iteration 24243 => Loss: 47.77183180873223733443\n",
      "Iteration 24244 => Loss: 47.77165732675032217003\n",
      "Iteration 24245 => Loss: 47.77148284613770812257\n",
      "Iteration 24246 => Loss: 47.77130836689441650833\n",
      "Iteration 24247 => Loss: 47.77113388902042601103\n",
      "Iteration 24248 => Loss: 47.77095941251570110353\n",
      "Iteration 24249 => Loss: 47.77078493738029862925\n",
      "Iteration 24250 => Loss: 47.77061046361414042849\n",
      "Iteration 24251 => Loss: 47.77043599121725492296\n",
      "Iteration 24252 => Loss: 47.77026152018962790180\n",
      "Iteration 24253 => Loss: 47.77008705053123094331\n",
      "Iteration 24254 => Loss: 47.76991258224207115290\n",
      "Iteration 24255 => Loss: 47.76973811532212010889\n",
      "Iteration 24256 => Loss: 47.76956364977137070582\n",
      "Iteration 24257 => Loss: 47.76938918558982294371\n",
      "Iteration 24258 => Loss: 47.76921472277746971713\n",
      "Iteration 24259 => Loss: 47.76904026133427549894\n",
      "Iteration 24260 => Loss: 47.76886580126027581628\n",
      "Iteration 24261 => Loss: 47.76869134255539250944\n",
      "Iteration 24262 => Loss: 47.76851688521966821099\n",
      "Iteration 24263 => Loss: 47.76834242925308160466\n",
      "Iteration 24264 => Loss: 47.76816797465561137415\n",
      "Iteration 24265 => Loss: 47.76799352142724330861\n",
      "Iteration 24266 => Loss: 47.76781906956797740804\n",
      "Iteration 24267 => Loss: 47.76764461907780656702\n",
      "Iteration 24268 => Loss: 47.76747016995670946926\n",
      "Iteration 24269 => Loss: 47.76729572220468611476\n",
      "Iteration 24270 => Loss: 47.76712127582172229268\n",
      "Iteration 24271 => Loss: 47.76694683080778958129\n",
      "Iteration 24272 => Loss: 47.76677238716291640230\n",
      "Iteration 24273 => Loss: 47.76659794488704591231\n",
      "Iteration 24274 => Loss: 47.76642350398019942759\n",
      "Iteration 24275 => Loss: 47.76624906444234142100\n",
      "Iteration 24276 => Loss: 47.76607462627349320883\n",
      "Iteration 24277 => Loss: 47.76590018947361215851\n",
      "Iteration 24278 => Loss: 47.76572575404271248090\n",
      "Iteration 24279 => Loss: 47.76555131998077996514\n",
      "Iteration 24280 => Loss: 47.76537688728777908409\n",
      "Iteration 24281 => Loss: 47.76520245596373115404\n",
      "Iteration 24282 => Loss: 47.76502802600860775328\n",
      "Iteration 24283 => Loss: 47.76485359742238756553\n",
      "Iteration 24284 => Loss: 47.76467917020509190706\n",
      "Iteration 24285 => Loss: 47.76450474435667814532\n",
      "Iteration 24286 => Loss: 47.76433031987715338573\n",
      "Iteration 24287 => Loss: 47.76415589676649631201\n",
      "Iteration 24288 => Loss: 47.76398147502472113501\n",
      "Iteration 24289 => Loss: 47.76380705465179943303\n",
      "Iteration 24290 => Loss: 47.76363263564768857350\n",
      "Iteration 24291 => Loss: 47.76345821801244539984\n",
      "Iteration 24292 => Loss: 47.76328380174600596320\n",
      "Iteration 24293 => Loss: 47.76310938684836315815\n",
      "Iteration 24294 => Loss: 47.76293497331953119556\n",
      "Iteration 24295 => Loss: 47.76276056115950296999\n",
      "Iteration 24296 => Loss: 47.76258615036822874345\n",
      "Iteration 24297 => Loss: 47.76241174094574404307\n",
      "Iteration 24298 => Loss: 47.76223733289198492002\n",
      "Iteration 24299 => Loss: 47.76206292620699400686\n",
      "Iteration 24300 => Loss: 47.76188852089072156559\n",
      "Iteration 24301 => Loss: 47.76171411694318180707\n",
      "Iteration 24302 => Loss: 47.76153971436436762588\n",
      "Iteration 24303 => Loss: 47.76136531315423638944\n",
      "Iteration 24304 => Loss: 47.76119091331280230861\n",
      "Iteration 24305 => Loss: 47.76101651484006538340\n",
      "Iteration 24306 => Loss: 47.76084211773597587580\n",
      "Iteration 24307 => Loss: 47.76066772200054799669\n",
      "Iteration 24308 => Loss: 47.76049332763378174604\n",
      "Iteration 24309 => Loss: 47.76031893463564159674\n",
      "Iteration 24310 => Loss: 47.76014454300612044335\n",
      "Iteration 24311 => Loss: 47.75997015274524670758\n",
      "Iteration 24312 => Loss: 47.75979576385294933516\n",
      "Iteration 24313 => Loss: 47.75962137632927095865\n",
      "Iteration 24314 => Loss: 47.75944699017415473463\n",
      "Iteration 24315 => Loss: 47.75927260538761487396\n",
      "Iteration 24316 => Loss: 47.75909822196965848207\n",
      "Iteration 24317 => Loss: 47.75892383992022161010\n",
      "Iteration 24318 => Loss: 47.75874945923935399605\n",
      "Iteration 24319 => Loss: 47.75857507992700590194\n",
      "Iteration 24320 => Loss: 47.75840070198317732775\n",
      "Iteration 24321 => Loss: 47.75822632540785406263\n",
      "Iteration 24322 => Loss: 47.75805195020104321202\n",
      "Iteration 24323 => Loss: 47.75787757636269503791\n",
      "Iteration 24324 => Loss: 47.75770320389285217288\n",
      "Iteration 24325 => Loss: 47.75752883279145066808\n",
      "Iteration 24326 => Loss: 47.75735446305851894522\n",
      "Iteration 24327 => Loss: 47.75718009469402858258\n",
      "Iteration 24328 => Loss: 47.75700572769796536932\n",
      "Iteration 24329 => Loss: 47.75683136207032220000\n",
      "Iteration 24330 => Loss: 47.75665699781111328548\n",
      "Iteration 24331 => Loss: 47.75648263492028888777\n",
      "Iteration 24332 => Loss: 47.75630827339786321772\n",
      "Iteration 24333 => Loss: 47.75613391324380785363\n",
      "Iteration 24334 => Loss: 47.75595955445813700635\n",
      "Iteration 24335 => Loss: 47.75578519704080804331\n",
      "Iteration 24336 => Loss: 47.75561084099182806995\n",
      "Iteration 24337 => Loss: 47.75543648631118998082\n",
      "Iteration 24338 => Loss: 47.75526213299887956509\n",
      "Iteration 24339 => Loss: 47.75508778105488261190\n",
      "Iteration 24340 => Loss: 47.75491343047919201581\n",
      "Iteration 24341 => Loss: 47.75473908127180067140\n",
      "Iteration 24342 => Loss: 47.75456473343268726239\n",
      "Iteration 24343 => Loss: 47.75439038696184468336\n",
      "Iteration 24344 => Loss: 47.75421604185925872343\n",
      "Iteration 24345 => Loss: 47.75404169812492938263\n",
      "Iteration 24346 => Loss: 47.75386735575884955551\n",
      "Iteration 24347 => Loss: 47.75369301476099082038\n",
      "Iteration 24348 => Loss: 47.75351867513133896637\n",
      "Iteration 24349 => Loss: 47.75334433686992241519\n",
      "Iteration 24350 => Loss: 47.75316999997669142886\n",
      "Iteration 24351 => Loss: 47.75299566445164600736\n",
      "Iteration 24352 => Loss: 47.75282133029475772901\n",
      "Iteration 24353 => Loss: 47.75264699750606212092\n",
      "Iteration 24354 => Loss: 47.75247266608550944511\n",
      "Iteration 24355 => Loss: 47.75229833603309970158\n",
      "Iteration 24356 => Loss: 47.75212400734883999576\n",
      "Iteration 24357 => Loss: 47.75194968003268769507\n",
      "Iteration 24358 => Loss: 47.75177535408464279953\n",
      "Iteration 24359 => Loss: 47.75160102950469820371\n",
      "Iteration 24360 => Loss: 47.75142670629283969674\n",
      "Iteration 24361 => Loss: 47.75125238444908859492\n",
      "Iteration 24362 => Loss: 47.75107806397339516025\n",
      "Iteration 24363 => Loss: 47.75090374486574518187\n",
      "Iteration 24364 => Loss: 47.75072942712614576521\n",
      "Iteration 24365 => Loss: 47.75055511075458980486\n",
      "Iteration 24366 => Loss: 47.75038079575105598451\n",
      "Iteration 24367 => Loss: 47.75020648211554430418\n",
      "Iteration 24368 => Loss: 47.75003216984802634215\n",
      "Iteration 24369 => Loss: 47.74985785894850920386\n",
      "Iteration 24370 => Loss: 47.74968354941697867844\n",
      "Iteration 24371 => Loss: 47.74950924125339923876\n",
      "Iteration 24372 => Loss: 47.74933493445779930653\n",
      "Iteration 24373 => Loss: 47.74916062903012914376\n",
      "Iteration 24374 => Loss: 47.74898632497043138301\n",
      "Iteration 24375 => Loss: 47.74881202227864918086\n",
      "Iteration 24376 => Loss: 47.74863772095477543189\n",
      "Iteration 24377 => Loss: 47.74846342099882434695\n",
      "Iteration 24378 => Loss: 47.74828912241074618805\n",
      "Iteration 24379 => Loss: 47.74811482519058358776\n",
      "Iteration 24380 => Loss: 47.74794052933827970264\n",
      "Iteration 24381 => Loss: 47.74776623485384874357\n",
      "Iteration 24382 => Loss: 47.74759194173724807797\n",
      "Iteration 24383 => Loss: 47.74741764998852744384\n",
      "Iteration 24384 => Loss: 47.74724335960761578690\n",
      "Iteration 24385 => Loss: 47.74706907059454863429\n",
      "Iteration 24386 => Loss: 47.74689478294925493174\n",
      "Iteration 24387 => Loss: 47.74672049667177020638\n",
      "Iteration 24388 => Loss: 47.74654621176209445821\n",
      "Iteration 24389 => Loss: 47.74637192822019926552\n",
      "Iteration 24390 => Loss: 47.74619764604606331204\n",
      "Iteration 24391 => Loss: 47.74602336523968659776\n",
      "Iteration 24392 => Loss: 47.74584908580104780640\n",
      "Iteration 24393 => Loss: 47.74567480773014693796\n",
      "Iteration 24394 => Loss: 47.74550053102696978158\n",
      "Iteration 24395 => Loss: 47.74532625569152344269\n",
      "Iteration 24396 => Loss: 47.74515198172377239416\n",
      "Iteration 24397 => Loss: 47.74497770912370953056\n",
      "Iteration 24398 => Loss: 47.74480343789131353560\n",
      "Iteration 24399 => Loss: 47.74462916802661283100\n",
      "Iteration 24400 => Loss: 47.74445489952956478419\n",
      "Iteration 24401 => Loss: 47.74428063240016939517\n",
      "Iteration 24402 => Loss: 47.74410636663840534766\n",
      "Iteration 24403 => Loss: 47.74393210224427264166\n",
      "Iteration 24404 => Loss: 47.74375783921777838259\n",
      "Iteration 24405 => Loss: 47.74358357755886572704\n",
      "Iteration 24406 => Loss: 47.74340931726756309672\n",
      "Iteration 24407 => Loss: 47.74323505834383496449\n",
      "Iteration 24408 => Loss: 47.74306080078768843578\n",
      "Iteration 24409 => Loss: 47.74288654459910219430\n",
      "Iteration 24410 => Loss: 47.74271228977806913463\n",
      "Iteration 24411 => Loss: 47.74253803632458215134\n",
      "Iteration 24412 => Loss: 47.74236378423861992815\n",
      "Iteration 24413 => Loss: 47.74218953352021088676\n",
      "Iteration 24414 => Loss: 47.74201528416926976206\n",
      "Iteration 24415 => Loss: 47.74184103618586050288\n",
      "Iteration 24416 => Loss: 47.74166678956991916039\n",
      "Iteration 24417 => Loss: 47.74149254432145283999\n",
      "Iteration 24418 => Loss: 47.74131830044046864714\n",
      "Iteration 24419 => Loss: 47.74114405792693816011\n",
      "Iteration 24420 => Loss: 47.74096981678084716805\n",
      "Iteration 24421 => Loss: 47.74079557700218856553\n",
      "Iteration 24422 => Loss: 47.74062133859098366884\n",
      "Iteration 24423 => Loss: 47.74044710154716142370\n",
      "Iteration 24424 => Loss: 47.74027286587075735724\n",
      "Iteration 24425 => Loss: 47.74009863156172173149\n",
      "Iteration 24426 => Loss: 47.73992439862009717899\n",
      "Iteration 24427 => Loss: 47.73975016704582685634\n",
      "Iteration 24428 => Loss: 47.73957593683893918524\n",
      "Iteration 24429 => Loss: 47.73940170799937732227\n",
      "Iteration 24430 => Loss: 47.73922748052715547828\n",
      "Iteration 24431 => Loss: 47.73905325442227365329\n",
      "Iteration 24432 => Loss: 47.73887902968470342557\n",
      "Iteration 24433 => Loss: 47.73870480631445190056\n",
      "Iteration 24434 => Loss: 47.73853058431147644569\n",
      "Iteration 24435 => Loss: 47.73835636367576995553\n",
      "Iteration 24436 => Loss: 47.73818214440736795723\n",
      "Iteration 24437 => Loss: 47.73800792650622071278\n",
      "Iteration 24438 => Loss: 47.73783370997234243305\n",
      "Iteration 24439 => Loss: 47.73765949480568338004\n",
      "Iteration 24440 => Loss: 47.73748528100626487003\n",
      "Iteration 24441 => Loss: 47.73731106857407269217\n",
      "Iteration 24442 => Loss: 47.73713685750908553018\n",
      "Iteration 24443 => Loss: 47.73696264781130338406\n",
      "Iteration 24444 => Loss: 47.73678843948069072667\n",
      "Iteration 24445 => Loss: 47.73661423251726887429\n",
      "Iteration 24446 => Loss: 47.73644002692101651064\n",
      "Iteration 24447 => Loss: 47.73626582269192653030\n",
      "Iteration 24448 => Loss: 47.73609161982996340612\n",
      "Iteration 24449 => Loss: 47.73591741833515555982\n",
      "Iteration 24450 => Loss: 47.73574321820743193712\n",
      "Iteration 24451 => Loss: 47.73556901944687069772\n",
      "Iteration 24452 => Loss: 47.73539482205339368193\n",
      "Iteration 24453 => Loss: 47.73522062602701510059\n",
      "Iteration 24454 => Loss: 47.73504643136769942657\n",
      "Iteration 24455 => Loss: 47.73487223807546087073\n",
      "Iteration 24456 => Loss: 47.73469804615028522221\n",
      "Iteration 24457 => Loss: 47.73452385559216537558\n",
      "Iteration 24458 => Loss: 47.73434966640107290914\n",
      "Iteration 24459 => Loss: 47.73417547857702203373\n",
      "Iteration 24460 => Loss: 47.73400129211996301137\n",
      "Iteration 24461 => Loss: 47.73382710702994558005\n",
      "Iteration 24462 => Loss: 47.73365292330689868550\n",
      "Iteration 24463 => Loss: 47.73347874095082943313\n",
      "Iteration 24464 => Loss: 47.73330455996175913924\n",
      "Iteration 24465 => Loss: 47.73313038033964517126\n",
      "Iteration 24466 => Loss: 47.73295620208447331834\n",
      "Iteration 24467 => Loss: 47.73278202519624358047\n",
      "Iteration 24468 => Loss: 47.73260784967494885223\n",
      "Iteration 24469 => Loss: 47.73243367552057492276\n",
      "Iteration 24470 => Loss: 47.73225950273310758121\n",
      "Iteration 24471 => Loss: 47.73208533131255393300\n",
      "Iteration 24472 => Loss: 47.73191116125885713473\n",
      "Iteration 24473 => Loss: 47.73173699257208113522\n",
      "Iteration 24474 => Loss: 47.73156282525211224765\n",
      "Iteration 24475 => Loss: 47.73138865929904994800\n",
      "Iteration 24476 => Loss: 47.73121449471282318200\n",
      "Iteration 24477 => Loss: 47.73104033149343194964\n",
      "Iteration 24478 => Loss: 47.73086616964086914550\n",
      "Iteration 24479 => Loss: 47.73069200915509213701\n",
      "Iteration 24480 => Loss: 47.73051785003615066216\n",
      "Iteration 24481 => Loss: 47.73034369228396656126\n",
      "Iteration 24482 => Loss: 47.73016953589859667773\n",
      "Iteration 24483 => Loss: 47.72999538087996995728\n",
      "Iteration 24484 => Loss: 47.72982122722811482163\n",
      "Iteration 24485 => Loss: 47.72964707494300995450\n",
      "Iteration 24486 => Loss: 47.72947292402464114502\n",
      "Iteration 24487 => Loss: 47.72929877447300839322\n",
      "Iteration 24488 => Loss: 47.72912462628806196108\n",
      "Iteration 24489 => Loss: 47.72895047946984448117\n",
      "Iteration 24490 => Loss: 47.72877633401832753179\n",
      "Iteration 24491 => Loss: 47.72860218993348269123\n",
      "Iteration 24492 => Loss: 47.72842804721530285406\n",
      "Iteration 24493 => Loss: 47.72825390586381644198\n",
      "Iteration 24494 => Loss: 47.72807976587895950615\n",
      "Iteration 24495 => Loss: 47.72790562726074625743\n",
      "Iteration 24496 => Loss: 47.72773149000914116868\n",
      "Iteration 24497 => Loss: 47.72755735412421529418\n",
      "Iteration 24498 => Loss: 47.72738321960585494708\n",
      "Iteration 24499 => Loss: 47.72720908645410275994\n",
      "Iteration 24500 => Loss: 47.72703495466893741650\n",
      "Iteration 24501 => Loss: 47.72686082425035891674\n",
      "Iteration 24502 => Loss: 47.72668669519833173354\n",
      "Iteration 24503 => Loss: 47.72651256751285586688\n",
      "Iteration 24504 => Loss: 47.72633844119394552763\n",
      "Iteration 24505 => Loss: 47.72616431624153676694\n",
      "Iteration 24506 => Loss: 47.72599019265567221737\n",
      "Iteration 24507 => Loss: 47.72581607043634477350\n",
      "Iteration 24508 => Loss: 47.72564194958350469733\n",
      "Iteration 24509 => Loss: 47.72546783009713067258\n",
      "Iteration 24510 => Loss: 47.72529371197725112097\n",
      "Iteration 24511 => Loss: 47.72511959522385893706\n",
      "Iteration 24512 => Loss: 47.72494547983691148829\n",
      "Iteration 24513 => Loss: 47.72477136581640166924\n",
      "Iteration 24514 => Loss: 47.72459725316235790160\n",
      "Iteration 24515 => Loss: 47.72442314187470202569\n",
      "Iteration 24516 => Loss: 47.72424903195349799034\n",
      "Iteration 24517 => Loss: 47.72407492339868184672\n",
      "Iteration 24518 => Loss: 47.72390081621026780567\n",
      "Iteration 24519 => Loss: 47.72372671038823455092\n",
      "Iteration 24520 => Loss: 47.72355260593256076618\n",
      "Iteration 24521 => Loss: 47.72337850284326776773\n",
      "Iteration 24522 => Loss: 47.72320440112032713387\n",
      "Iteration 24523 => Loss: 47.72303030076371754831\n",
      "Iteration 24524 => Loss: 47.72285620177345322190\n",
      "Iteration 24525 => Loss: 47.72268210414949152209\n",
      "Iteration 24526 => Loss: 47.72250800789183244888\n",
      "Iteration 24527 => Loss: 47.72233391300049731854\n",
      "Iteration 24528 => Loss: 47.72215981947543639308\n",
      "Iteration 24529 => Loss: 47.72198572731664967250\n",
      "Iteration 24530 => Loss: 47.72181163652412294596\n",
      "Iteration 24531 => Loss: 47.72163754709787042430\n",
      "Iteration 24532 => Loss: 47.72146345903784947495\n",
      "Iteration 24533 => Loss: 47.72128937234406720336\n",
      "Iteration 24534 => Loss: 47.72111528701651650408\n",
      "Iteration 24535 => Loss: 47.72094120305516184999\n",
      "Iteration 24536 => Loss: 47.72076712046001745193\n",
      "Iteration 24537 => Loss: 47.72059303923105488821\n",
      "Iteration 24538 => Loss: 47.72041895936828126423\n",
      "Iteration 24539 => Loss: 47.72024488087168236916\n",
      "Iteration 24540 => Loss: 47.72007080374123688671\n",
      "Iteration 24541 => Loss: 47.71989672797694481687\n",
      "Iteration 24542 => Loss: 47.71972265357877063252\n",
      "Iteration 24543 => Loss: 47.71954858054674275536\n",
      "Iteration 24544 => Loss: 47.71937450888081855283\n",
      "Iteration 24545 => Loss: 47.71920043858101223577\n",
      "Iteration 24546 => Loss: 47.71902636964729538249\n",
      "Iteration 24547 => Loss: 47.71885230207966088756\n",
      "Iteration 24548 => Loss: 47.71867823587809454011\n",
      "Iteration 24549 => Loss: 47.71850417104258923473\n",
      "Iteration 24550 => Loss: 47.71833010757315207684\n",
      "Iteration 24551 => Loss: 47.71815604546974043387\n",
      "Iteration 24552 => Loss: 47.71798198473236851669\n",
      "Iteration 24553 => Loss: 47.71780792536100079815\n",
      "Iteration 24554 => Loss: 47.71763386735565859453\n",
      "Iteration 24555 => Loss: 47.71745981071631348414\n",
      "Iteration 24556 => Loss: 47.71728575544295125610\n",
      "Iteration 24557 => Loss: 47.71711170153556480500\n",
      "Iteration 24558 => Loss: 47.71693764899413991998\n",
      "Iteration 24559 => Loss: 47.71676359781869791732\n",
      "Iteration 24560 => Loss: 47.71658954800917484818\n",
      "Iteration 24561 => Loss: 47.71641549956558492340\n",
      "Iteration 24562 => Loss: 47.71624145248790682672\n",
      "Iteration 24563 => Loss: 47.71606740677616187440\n",
      "Iteration 24564 => Loss: 47.71589336243031453932\n",
      "Iteration 24565 => Loss: 47.71571931945035771605\n",
      "Iteration 24566 => Loss: 47.71554527783629140458\n",
      "Iteration 24567 => Loss: 47.71537123758808007778\n",
      "Iteration 24568 => Loss: 47.71519719870571663023\n",
      "Iteration 24569 => Loss: 47.71502316118922237820\n",
      "Iteration 24570 => Loss: 47.71484912503856179455\n",
      "Iteration 24571 => Loss: 47.71467509025369935216\n",
      "Iteration 24572 => Loss: 47.71450105683467768358\n",
      "Iteration 24573 => Loss: 47.71432702478145415625\n",
      "Iteration 24574 => Loss: 47.71415299409405008646\n",
      "Iteration 24575 => Loss: 47.71397896477240863078\n",
      "Iteration 24576 => Loss: 47.71380493681654400007\n",
      "Iteration 24577 => Loss: 47.71363091022644198347\n",
      "Iteration 24578 => Loss: 47.71345688500208126470\n",
      "Iteration 24579 => Loss: 47.71328286114349026548\n",
      "Iteration 24580 => Loss: 47.71310883865059082609\n",
      "Iteration 24581 => Loss: 47.71293481752343268454\n",
      "Iteration 24582 => Loss: 47.71276079776198031368\n",
      "Iteration 24583 => Loss: 47.71258677936621239724\n",
      "Iteration 24584 => Loss: 47.71241276233613604063\n",
      "Iteration 24585 => Loss: 47.71223874667175124387\n",
      "Iteration 24586 => Loss: 47.71206473237302247981\n",
      "Iteration 24587 => Loss: 47.71189071943995685388\n",
      "Iteration 24588 => Loss: 47.71171670787254015522\n",
      "Iteration 24589 => Loss: 47.71154269767074396214\n",
      "Iteration 24590 => Loss: 47.71136868883456827461\n",
      "Iteration 24591 => Loss: 47.71119468136400598723\n",
      "Iteration 24592 => Loss: 47.71102067525906420542\n",
      "Iteration 24593 => Loss: 47.71084667051970029661\n",
      "Iteration 24594 => Loss: 47.71067266714588583909\n",
      "Iteration 24595 => Loss: 47.71049866513767767628\n",
      "Iteration 24596 => Loss: 47.71032466449501896477\n",
      "Iteration 24597 => Loss: 47.71015066521791680998\n",
      "Iteration 24598 => Loss: 47.70997666730632857934\n",
      "Iteration 24599 => Loss: 47.70980267076028980000\n",
      "Iteration 24600 => Loss: 47.70962867557977205024\n",
      "Iteration 24601 => Loss: 47.70945468176473980293\n",
      "Iteration 24602 => Loss: 47.70928068931520016349\n",
      "Iteration 24603 => Loss: 47.70910669823116023736\n",
      "Iteration 24604 => Loss: 47.70893270851259160281\n",
      "Iteration 24605 => Loss: 47.70875872015947294358\n",
      "Iteration 24606 => Loss: 47.70858473317179004880\n",
      "Iteration 24607 => Loss: 47.70841074754959265647\n",
      "Iteration 24608 => Loss: 47.70823676329278839603\n",
      "Iteration 24609 => Loss: 47.70806278040141990004\n",
      "Iteration 24610 => Loss: 47.70788879887545164138\n",
      "Iteration 24611 => Loss: 47.70771481871486940918\n",
      "Iteration 24612 => Loss: 47.70754083991970873058\n",
      "Iteration 24613 => Loss: 47.70736686248990565673\n",
      "Iteration 24614 => Loss: 47.70719288642547439849\n",
      "Iteration 24615 => Loss: 47.70701891172637232330\n",
      "Iteration 24616 => Loss: 47.70684493839266338000\n",
      "Iteration 24617 => Loss: 47.70667096642423388175\n",
      "Iteration 24618 => Loss: 47.70649699582116909369\n",
      "Iteration 24619 => Loss: 47.70632302658341217239\n",
      "Iteration 24620 => Loss: 47.70614905871094180156\n",
      "Iteration 24621 => Loss: 47.70597509220375798122\n",
      "Iteration 24622 => Loss: 47.70580112706185360594\n",
      "Iteration 24623 => Loss: 47.70562716328521446485\n",
      "Iteration 24624 => Loss: 47.70545320087386187424\n",
      "Iteration 24625 => Loss: 47.70527923982773899070\n",
      "Iteration 24626 => Loss: 47.70510528014686713050\n",
      "Iteration 24627 => Loss: 47.70493132183121076650\n",
      "Iteration 24628 => Loss: 47.70475736488076279329\n",
      "Iteration 24629 => Loss: 47.70458340929553742171\n",
      "Iteration 24630 => Loss: 47.70440945507548491378\n",
      "Iteration 24631 => Loss: 47.70423550222061948034\n",
      "Iteration 24632 => Loss: 47.70406155073092691055\n",
      "Iteration 24633 => Loss: 47.70388760060642141525\n",
      "Iteration 24634 => Loss: 47.70371365184703194018\n",
      "Iteration 24635 => Loss: 47.70353970445280822332\n",
      "Iteration 24636 => Loss: 47.70336575842371473755\n",
      "Iteration 24637 => Loss: 47.70319181375972306114\n",
      "Iteration 24638 => Loss: 47.70301787046086161581\n",
      "Iteration 24639 => Loss: 47.70284392852705934729\n",
      "Iteration 24640 => Loss: 47.70266998795838730985\n",
      "Iteration 24641 => Loss: 47.70249604875476734378\n",
      "Iteration 24642 => Loss: 47.70232211091622787080\n",
      "Iteration 24643 => Loss: 47.70214817444273336378\n",
      "Iteration 24644 => Loss: 47.70197423933428382270\n",
      "Iteration 24645 => Loss: 47.70180030559087214215\n",
      "Iteration 24646 => Loss: 47.70162637321248411126\n",
      "Iteration 24647 => Loss: 47.70145244219909841377\n",
      "Iteration 24648 => Loss: 47.70127851255071504966\n",
      "Iteration 24649 => Loss: 47.70110458426733401893\n",
      "Iteration 24650 => Loss: 47.70093065734892689989\n",
      "Iteration 24651 => Loss: 47.70075673179549369252\n",
      "Iteration 24652 => Loss: 47.70058280760702018597\n",
      "Iteration 24653 => Loss: 47.70040888478347795854\n",
      "Iteration 24654 => Loss: 47.70023496332489543192\n",
      "Iteration 24655 => Loss: 47.70006104323122286814\n",
      "Iteration 24656 => Loss: 47.69988712450248158348\n",
      "Iteration 24657 => Loss: 47.69971320713862894536\n",
      "Iteration 24658 => Loss: 47.69953929113967916464\n",
      "Iteration 24659 => Loss: 47.69936537650559671420\n",
      "Iteration 24660 => Loss: 47.69919146323642422658\n",
      "Iteration 24661 => Loss: 47.69901755133206933124\n",
      "Iteration 24662 => Loss: 47.69884364079258887159\n",
      "Iteration 24663 => Loss: 47.69866973161795442593\n",
      "Iteration 24664 => Loss: 47.69849582380814467797\n",
      "Iteration 24665 => Loss: 47.69832191736315962771\n",
      "Iteration 24666 => Loss: 47.69814801228295664259\n",
      "Iteration 24667 => Loss: 47.69797410856757124975\n",
      "Iteration 24668 => Loss: 47.69780020621698923833\n",
      "Iteration 24669 => Loss: 47.69762630523116797576\n",
      "Iteration 24670 => Loss: 47.69745240561009325120\n",
      "Iteration 24671 => Loss: 47.69727850735380059177\n",
      "Iteration 24672 => Loss: 47.69710461046225447035\n",
      "Iteration 24673 => Loss: 47.69693071493541935979\n",
      "Iteration 24674 => Loss: 47.69675682077330947095\n",
      "Iteration 24675 => Loss: 47.69658292797593190926\n",
      "Iteration 24676 => Loss: 47.69640903654323693672\n",
      "Iteration 24677 => Loss: 47.69623514647525297505\n",
      "Iteration 24678 => Loss: 47.69606125777195160254\n",
      "Iteration 24679 => Loss: 47.69588737043328308118\n",
      "Iteration 24680 => Loss: 47.69571348445929714899\n",
      "Iteration 24681 => Loss: 47.69553959984996538424\n",
      "Iteration 24682 => Loss: 47.69536571660525936522\n",
      "Iteration 24683 => Loss: 47.69519183472517198652\n",
      "Iteration 24684 => Loss: 47.69501795420972456441\n",
      "Iteration 24685 => Loss: 47.69484407505886025547\n",
      "Iteration 24686 => Loss: 47.69467019727260037598\n",
      "Iteration 24687 => Loss: 47.69449632085092360967\n",
      "Iteration 24688 => Loss: 47.69432244579381574567\n",
      "Iteration 24689 => Loss: 47.69414857210129099485\n",
      "Iteration 24690 => Loss: 47.69397469977329961921\n",
      "Iteration 24691 => Loss: 47.69380082880985582960\n",
      "Iteration 24692 => Loss: 47.69362695921093120432\n",
      "Iteration 24693 => Loss: 47.69345309097653995423\n",
      "Iteration 24694 => Loss: 47.69327922410662523589\n",
      "Iteration 24695 => Loss: 47.69310535860123678731\n",
      "Iteration 24696 => Loss: 47.69293149446034618677\n",
      "Iteration 24697 => Loss: 47.69275763168391790714\n",
      "Iteration 24698 => Loss: 47.69258377027195194842\n",
      "Iteration 24699 => Loss: 47.69240991022442699432\n",
      "Iteration 24700 => Loss: 47.69223605154137857198\n",
      "Iteration 24701 => Loss: 47.69206219422273562714\n",
      "Iteration 24702 => Loss: 47.69188833826854789777\n",
      "Iteration 24703 => Loss: 47.69171448367873722418\n",
      "Iteration 24704 => Loss: 47.69154063045335334436\n",
      "Iteration 24705 => Loss: 47.69136677859234652033\n",
      "Iteration 24706 => Loss: 47.69119292809572385750\n",
      "Iteration 24707 => Loss: 47.69101907896347114502\n",
      "Iteration 24708 => Loss: 47.69084523119558127746\n",
      "Iteration 24709 => Loss: 47.69067138479203293855\n",
      "Iteration 24710 => Loss: 47.69049753975283323371\n",
      "Iteration 24711 => Loss: 47.69032369607795374122\n",
      "Iteration 24712 => Loss: 47.69014985376739446110\n",
      "Iteration 24713 => Loss: 47.68997601282114118249\n",
      "Iteration 24714 => Loss: 47.68980217323917258909\n",
      "Iteration 24715 => Loss: 47.68962833502148868092\n",
      "Iteration 24716 => Loss: 47.68945449816807524712\n",
      "Iteration 24717 => Loss: 47.68928066267892518226\n",
      "Iteration 24718 => Loss: 47.68910682855404559177\n",
      "Iteration 24719 => Loss: 47.68893299579339384309\n",
      "Iteration 24720 => Loss: 47.68875916439696993621\n",
      "Iteration 24721 => Loss: 47.68858533436476676570\n",
      "Iteration 24722 => Loss: 47.68841150569677012072\n",
      "Iteration 24723 => Loss: 47.68823767839297289584\n",
      "Iteration 24724 => Loss: 47.68806385245337509105\n",
      "Iteration 24725 => Loss: 47.68789002787791986293\n",
      "Iteration 24726 => Loss: 47.68771620466665694948\n",
      "Iteration 24727 => Loss: 47.68754238281956503442\n",
      "Iteration 24728 => Loss: 47.68736856233660148519\n",
      "Iteration 24729 => Loss: 47.68719474321776630177\n",
      "Iteration 24730 => Loss: 47.68702092546305948417\n",
      "Iteration 24731 => Loss: 47.68684710907245971612\n",
      "Iteration 24732 => Loss: 47.68667329404595989217\n",
      "Iteration 24733 => Loss: 47.68649948038358132862\n",
      "Iteration 24734 => Loss: 47.68632566808524586577\n",
      "Iteration 24735 => Loss: 47.68615185715099613617\n",
      "Iteration 24736 => Loss: 47.68597804758080371812\n",
      "Iteration 24737 => Loss: 47.68580423937466861162\n",
      "Iteration 24738 => Loss: 47.68563043253253397324\n",
      "Iteration 24739 => Loss: 47.68545662705447085727\n",
      "Iteration 24740 => Loss: 47.68528282294040820943\n",
      "Iteration 24741 => Loss: 47.68510902019036024058\n",
      "Iteration 24742 => Loss: 47.68493521880429852899\n",
      "Iteration 24743 => Loss: 47.68476141878221596926\n",
      "Iteration 24744 => Loss: 47.68458762012410545594\n",
      "Iteration 24745 => Loss: 47.68441382282995988362\n",
      "Iteration 24746 => Loss: 47.68424002689977214686\n",
      "Iteration 24747 => Loss: 47.68406623233353514024\n",
      "Iteration 24748 => Loss: 47.68389243913121333662\n",
      "Iteration 24749 => Loss: 47.68371864729281384143\n",
      "Iteration 24750 => Loss: 47.68354485681832954924\n",
      "Iteration 24751 => Loss: 47.68337106770772493292\n",
      "Iteration 24752 => Loss: 47.68319727996101420331\n",
      "Iteration 24753 => Loss: 47.68302349357820446585\n",
      "Iteration 24754 => Loss: 47.68284970855922466626\n",
      "Iteration 24755 => Loss: 47.68267592490413164796\n",
      "Iteration 24756 => Loss: 47.68250214261286856754\n",
      "Iteration 24757 => Loss: 47.68232836168545674127\n",
      "Iteration 24758 => Loss: 47.68215458212183932574\n",
      "Iteration 24759 => Loss: 47.68198080392207316436\n",
      "Iteration 24760 => Loss: 47.68180702708608009743\n",
      "Iteration 24761 => Loss: 47.68163325161387433582\n",
      "Iteration 24762 => Loss: 47.68145947750547719579\n",
      "Iteration 24763 => Loss: 47.68128570476081762308\n",
      "Iteration 24764 => Loss: 47.68111193337992403940\n",
      "Iteration 24765 => Loss: 47.68093816336280355017\n",
      "Iteration 24766 => Loss: 47.68076439470940641741\n",
      "Iteration 24767 => Loss: 47.68059062741973264110\n",
      "Iteration 24768 => Loss: 47.68041686149378222126\n",
      "Iteration 24769 => Loss: 47.68024309693152673617\n",
      "Iteration 24770 => Loss: 47.68006933373297329126\n",
      "Iteration 24771 => Loss: 47.67989557189810057025\n",
      "Iteration 24772 => Loss: 47.67972181142690857314\n",
      "Iteration 24773 => Loss: 47.67954805231937598364\n",
      "Iteration 24774 => Loss: 47.67937429457550280176\n",
      "Iteration 24775 => Loss: 47.67920053819526771122\n",
      "Iteration 24776 => Loss: 47.67902678317864939572\n",
      "Iteration 24777 => Loss: 47.67885302952566917156\n",
      "Iteration 24778 => Loss: 47.67867927723629151160\n",
      "Iteration 24779 => Loss: 47.67850552631050931041\n",
      "Iteration 24780 => Loss: 47.67833177674831546256\n",
      "Iteration 24781 => Loss: 47.67815802854969575719\n",
      "Iteration 24782 => Loss: 47.67798428171466440517\n",
      "Iteration 24783 => Loss: 47.67781053624318587936\n",
      "Iteration 24784 => Loss: 47.67763679213522465261\n",
      "Iteration 24785 => Loss: 47.67746304939081625207\n",
      "Iteration 24786 => Loss: 47.67728930800993225603\n",
      "Iteration 24787 => Loss: 47.67711556799257266448\n",
      "Iteration 24788 => Loss: 47.67694182933869484486\n",
      "Iteration 24789 => Loss: 47.67676809204831300804\n",
      "Iteration 24790 => Loss: 47.67659435612139873228\n",
      "Iteration 24791 => Loss: 47.67642062155798043932\n",
      "Iteration 24792 => Loss: 47.67624688835800839115\n",
      "Iteration 24793 => Loss: 47.67607315652148969320\n",
      "Iteration 24794 => Loss: 47.67589942604841013463\n",
      "Iteration 24795 => Loss: 47.67572569693874839913\n",
      "Iteration 24796 => Loss: 47.67555196919252580301\n",
      "Iteration 24797 => Loss: 47.67537824280968550283\n",
      "Iteration 24798 => Loss: 47.67520451779027013117\n",
      "Iteration 24799 => Loss: 47.67503079413421573918\n",
      "Iteration 24800 => Loss: 47.67485707184152943228\n",
      "Iteration 24801 => Loss: 47.67468335091222542133\n",
      "Iteration 24802 => Loss: 47.67450963134626107376\n",
      "Iteration 24803 => Loss: 47.67433591314363638958\n",
      "Iteration 24804 => Loss: 47.67416219630433715793\n",
      "Iteration 24805 => Loss: 47.67398848082838469509\n",
      "Iteration 24806 => Loss: 47.67381476671573636850\n",
      "Iteration 24807 => Loss: 47.67364105396638507273\n",
      "Iteration 24808 => Loss: 47.67346734258031659692\n",
      "Iteration 24809 => Loss: 47.67329363255751673023\n",
      "Iteration 24810 => Loss: 47.67311992389799968350\n",
      "Iteration 24811 => Loss: 47.67294621660172282418\n",
      "Iteration 24812 => Loss: 47.67277251066870746854\n",
      "Iteration 24813 => Loss: 47.67259880609891808945\n",
      "Iteration 24814 => Loss: 47.67242510289236179233\n",
      "Iteration 24815 => Loss: 47.67225140104902436633\n",
      "Iteration 24816 => Loss: 47.67207770056886317889\n",
      "Iteration 24817 => Loss: 47.67190400145190665171\n",
      "Iteration 24818 => Loss: 47.67173030369814767937\n",
      "Iteration 24819 => Loss: 47.67155660730753652388\n",
      "Iteration 24820 => Loss: 47.67138291228010160694\n",
      "Iteration 24821 => Loss: 47.67120921861580029599\n",
      "Iteration 24822 => Loss: 47.67103552631465390732\n",
      "Iteration 24823 => Loss: 47.67086183537663401921\n",
      "Iteration 24824 => Loss: 47.67068814580172642081\n",
      "Iteration 24825 => Loss: 47.67051445758992400670\n",
      "Iteration 24826 => Loss: 47.67034077074121967144\n",
      "Iteration 24827 => Loss: 47.67016708525559920417\n",
      "Iteration 24828 => Loss: 47.66999340113305549949\n",
      "Iteration 24829 => Loss: 47.66981971837358145194\n",
      "Iteration 24830 => Loss: 47.66964603697715574526\n",
      "Iteration 24831 => Loss: 47.66947235694375706316\n",
      "Iteration 24832 => Loss: 47.66929867827342093278\n",
      "Iteration 24833 => Loss: 47.66912500096609051070\n",
      "Iteration 24834 => Loss: 47.66895132502175869149\n",
      "Iteration 24835 => Loss: 47.66877765044043258058\n",
      "Iteration 24836 => Loss: 47.66860397722210507254\n",
      "Iteration 24837 => Loss: 47.66843030536674774567\n",
      "Iteration 24838 => Loss: 47.66825663487436770538\n",
      "Iteration 24839 => Loss: 47.66808296574495074083\n",
      "Iteration 24840 => Loss: 47.66790929797844000859\n",
      "Iteration 24841 => Loss: 47.66773563157489235209\n",
      "Iteration 24842 => Loss: 47.66756196653427224419\n",
      "Iteration 24843 => Loss: 47.66738830285655126318\n",
      "Iteration 24844 => Loss: 47.66721464054175783076\n",
      "Iteration 24845 => Loss: 47.66704097958984220895\n",
      "Iteration 24846 => Loss: 47.66686732000080439775\n",
      "Iteration 24847 => Loss: 47.66669366177464439716\n",
      "Iteration 24848 => Loss: 47.66652000491134799631\n",
      "Iteration 24849 => Loss: 47.66634634941089387894\n",
      "Iteration 24850 => Loss: 47.66617269527328915046\n",
      "Iteration 24851 => Loss: 47.66599904249849117832\n",
      "Iteration 24852 => Loss: 47.66582539108652127879\n",
      "Iteration 24853 => Loss: 47.66565174103737945188\n",
      "Iteration 24854 => Loss: 47.66547809235100885417\n",
      "Iteration 24855 => Loss: 47.66530444502744501278\n",
      "Iteration 24856 => Loss: 47.66513079906664529517\n",
      "Iteration 24857 => Loss: 47.66495715446860970133\n",
      "Iteration 24858 => Loss: 47.66478351123333112582\n",
      "Iteration 24859 => Loss: 47.66460986936078825238\n",
      "Iteration 24860 => Loss: 47.66443622885098818642\n",
      "Iteration 24861 => Loss: 47.66426258970388829539\n",
      "Iteration 24862 => Loss: 47.66408895191951700099\n",
      "Iteration 24863 => Loss: 47.66391531549783877608\n",
      "Iteration 24864 => Loss: 47.66374168043886072610\n",
      "Iteration 24865 => Loss: 47.66356804674255442933\n",
      "Iteration 24866 => Loss: 47.66339441440890567492\n",
      "Iteration 24867 => Loss: 47.66322078343792156829\n",
      "Iteration 24868 => Loss: 47.66304715382959500403\n",
      "Iteration 24869 => Loss: 47.66287352558389045498\n",
      "Iteration 24870 => Loss: 47.66269989870082213201\n",
      "Iteration 24871 => Loss: 47.66252627318036871884\n",
      "Iteration 24872 => Loss: 47.66235264902251600461\n",
      "Iteration 24873 => Loss: 47.66217902622724977846\n",
      "Iteration 24874 => Loss: 47.66200540479457714582\n",
      "Iteration 24875 => Loss: 47.66183178472446968499\n",
      "Iteration 24876 => Loss: 47.66165816601692739596\n",
      "Iteration 24877 => Loss: 47.66148454867192896245\n",
      "Iteration 24878 => Loss: 47.66131093268948859532\n",
      "Iteration 24879 => Loss: 47.66113731806955655657\n",
      "Iteration 24880 => Loss: 47.66096370481214705705\n",
      "Iteration 24881 => Loss: 47.66079009291725299136\n",
      "Iteration 24882 => Loss: 47.66061648238485304319\n",
      "Iteration 24883 => Loss: 47.66044287321492589626\n",
      "Iteration 24884 => Loss: 47.66026926540747865602\n",
      "Iteration 24885 => Loss: 47.66009565896250421702\n",
      "Iteration 24886 => Loss: 47.65992205387998126298\n",
      "Iteration 24887 => Loss: 47.65974845015990979391\n",
      "Iteration 24888 => Loss: 47.65957484780226138810\n",
      "Iteration 24889 => Loss: 47.65940124680705025639\n",
      "Iteration 24890 => Loss: 47.65922764717421244995\n",
      "Iteration 24891 => Loss: 47.65905404890381902305\n",
      "Iteration 24892 => Loss: 47.65888045199579181599\n",
      "Iteration 24893 => Loss: 47.65870685645015214504\n",
      "Iteration 24894 => Loss: 47.65853326226688579936\n",
      "Iteration 24895 => Loss: 47.65835966944597146266\n",
      "Iteration 24896 => Loss: 47.65818607798738781867\n",
      "Iteration 24897 => Loss: 47.65801248789116328908\n",
      "Iteration 24898 => Loss: 47.65783889915724813591\n",
      "Iteration 24899 => Loss: 47.65766531178568499172\n",
      "Iteration 24900 => Loss: 47.65749172577638859138\n",
      "Iteration 24901 => Loss: 47.65731814112940156747\n",
      "Iteration 24902 => Loss: 47.65714455784469549826\n",
      "Iteration 24903 => Loss: 47.65697097592224906748\n",
      "Iteration 24904 => Loss: 47.65679739536208359141\n",
      "Iteration 24905 => Loss: 47.65662381616415643748\n",
      "Iteration 24906 => Loss: 47.65645023832848181655\n",
      "Iteration 24907 => Loss: 47.65627666185500999063\n",
      "Iteration 24908 => Loss: 47.65610308674378359228\n",
      "Iteration 24909 => Loss: 47.65592951299475288351\n",
      "Iteration 24910 => Loss: 47.65575594060793207518\n",
      "Iteration 24911 => Loss: 47.65558236958329274557\n",
      "Iteration 24912 => Loss: 47.65540879992082778926\n",
      "Iteration 24913 => Loss: 47.65523523162053720625\n",
      "Iteration 24914 => Loss: 47.65506166468238546940\n",
      "Iteration 24915 => Loss: 47.65488809910638678957\n",
      "Iteration 24916 => Loss: 47.65471453489251274505\n",
      "Iteration 24917 => Loss: 47.65454097204077044125\n",
      "Iteration 24918 => Loss: 47.65436741055114566734\n",
      "Iteration 24919 => Loss: 47.65419385042363131788\n",
      "Iteration 24920 => Loss: 47.65402029165817765488\n",
      "Iteration 24921 => Loss: 47.65384673425479888920\n",
      "Iteration 24922 => Loss: 47.65367317821352344254\n",
      "Iteration 24923 => Loss: 47.65349962353429447148\n",
      "Iteration 24924 => Loss: 47.65332607021711908146\n",
      "Iteration 24925 => Loss: 47.65315251826195463991\n",
      "Iteration 24926 => Loss: 47.65297896766884377939\n",
      "Iteration 24927 => Loss: 47.65280541843774386734\n",
      "Iteration 24928 => Loss: 47.65263187056863358748\n",
      "Iteration 24929 => Loss: 47.65245832406154136152\n",
      "Iteration 24930 => Loss: 47.65228477891643166231\n",
      "Iteration 24931 => Loss: 47.65211123513326896273\n",
      "Iteration 24932 => Loss: 47.65193769271208878990\n",
      "Iteration 24933 => Loss: 47.65176415165286272213\n",
      "Iteration 24934 => Loss: 47.65159061195556944313\n",
      "Iteration 24935 => Loss: 47.65141707362021605832\n",
      "Iteration 24936 => Loss: 47.65124353664675993514\n",
      "Iteration 24937 => Loss: 47.65107000103524370616\n",
      "Iteration 24938 => Loss: 47.65089646678560342252\n",
      "Iteration 24939 => Loss: 47.65072293389785329509\n",
      "Iteration 24940 => Loss: 47.65054940237197911301\n",
      "Iteration 24941 => Loss: 47.65037587220798798171\n",
      "Iteration 24942 => Loss: 47.65020234340582305776\n",
      "Iteration 24943 => Loss: 47.65002881596551986831\n",
      "Iteration 24944 => Loss: 47.64985528988707130793\n",
      "Iteration 24945 => Loss: 47.64968176517041342777\n",
      "Iteration 24946 => Loss: 47.64950824181556043868\n",
      "Iteration 24947 => Loss: 47.64933471982254076238\n",
      "Iteration 24948 => Loss: 47.64916119919131176630\n",
      "Iteration 24949 => Loss: 47.64898767992185213416\n",
      "Iteration 24950 => Loss: 47.64881416201416897138\n",
      "Iteration 24951 => Loss: 47.64864064546825517255\n",
      "Iteration 24952 => Loss: 47.64846713028406810508\n",
      "Iteration 24953 => Loss: 47.64829361646161487442\n",
      "Iteration 24954 => Loss: 47.64812010400090258599\n",
      "Iteration 24955 => Loss: 47.64794659290190281808\n",
      "Iteration 24956 => Loss: 47.64777308316462267612\n",
      "Iteration 24957 => Loss: 47.64759957478901952754\n",
      "Iteration 24958 => Loss: 47.64742606777510047777\n",
      "Iteration 24959 => Loss: 47.64725256212287263224\n",
      "Iteration 24960 => Loss: 47.64707905783230756924\n",
      "Iteration 24961 => Loss: 47.64690555490337686706\n",
      "Iteration 24962 => Loss: 47.64673205333609473655\n",
      "Iteration 24963 => Loss: 47.64655855313043986143\n",
      "Iteration 24964 => Loss: 47.64638505428641934714\n",
      "Iteration 24965 => Loss: 47.64621155680400477195\n",
      "Iteration 24966 => Loss: 47.64603806068318192501\n",
      "Iteration 24967 => Loss: 47.64586456592395791176\n",
      "Iteration 24968 => Loss: 47.64569107252629720506\n",
      "Iteration 24969 => Loss: 47.64551758049022112118\n",
      "Iteration 24970 => Loss: 47.64534408981567992214\n",
      "Iteration 24971 => Loss: 47.64517060050269492422\n",
      "Iteration 24972 => Loss: 47.64499711255124481113\n",
      "Iteration 24973 => Loss: 47.64482362596130826660\n",
      "Iteration 24974 => Loss: 47.64465014073292081775\n",
      "Iteration 24975 => Loss: 47.64447665686599719947\n",
      "Iteration 24976 => Loss: 47.64430317436060136060\n",
      "Iteration 24977 => Loss: 47.64412969321664803601\n",
      "Iteration 24978 => Loss: 47.64395621343419406912\n",
      "Iteration 24979 => Loss: 47.64378273501318261651\n",
      "Iteration 24980 => Loss: 47.64360925795362788904\n",
      "Iteration 24981 => Loss: 47.64343578225551567584\n",
      "Iteration 24982 => Loss: 47.64326230791883176607\n",
      "Iteration 24983 => Loss: 47.64308883494354773802\n",
      "Iteration 24984 => Loss: 47.64291536332967780254\n",
      "Iteration 24985 => Loss: 47.64274189307722195963\n",
      "Iteration 24986 => Loss: 47.64256842418614468215\n",
      "Iteration 24987 => Loss: 47.64239495665643175926\n",
      "Iteration 24988 => Loss: 47.64222149048809740179\n",
      "Iteration 24989 => Loss: 47.64204802568109897720\n",
      "Iteration 24990 => Loss: 47.64187456223546490719\n",
      "Iteration 24991 => Loss: 47.64170110015113834834\n",
      "Iteration 24992 => Loss: 47.64152763942813351150\n",
      "Iteration 24993 => Loss: 47.64135418006647881839\n",
      "Iteration 24994 => Loss: 47.64118072206607479302\n",
      "Iteration 24995 => Loss: 47.64100726542697827881\n",
      "Iteration 24996 => Loss: 47.64083381014917506491\n",
      "Iteration 24997 => Loss: 47.64066035623263672960\n",
      "Iteration 24998 => Loss: 47.64048690367734195661\n",
      "Iteration 24999 => Loss: 47.64031345248330495679\n",
      "Iteration 25000 => Loss: 47.64014000265049730842\n",
      "Iteration 25001 => Loss: 47.63996655417890480066\n",
      "Iteration 25002 => Loss: 47.63979310706852743351\n",
      "Iteration 25003 => Loss: 47.63961966131937941782\n",
      "Iteration 25004 => Loss: 47.63944621693139680474\n",
      "Iteration 25005 => Loss: 47.63927277390460801598\n",
      "Iteration 25006 => Loss: 47.63909933223899173527\n",
      "Iteration 25007 => Loss: 47.63892589193454796259\n",
      "Iteration 25008 => Loss: 47.63875245299122695997\n",
      "Iteration 25009 => Loss: 47.63857901540907135995\n",
      "Iteration 25010 => Loss: 47.63840557918801721371\n",
      "Iteration 25011 => Loss: 47.63823214432811425922\n",
      "Iteration 25012 => Loss: 47.63805871082929854765\n",
      "Iteration 25013 => Loss: 47.63788527869157718442\n",
      "Iteration 25014 => Loss: 47.63771184791495727495\n",
      "Iteration 25015 => Loss: 47.63753841849939618669\n",
      "Iteration 25016 => Loss: 47.63736499044491523591\n",
      "Iteration 25017 => Loss: 47.63719156375148600091\n",
      "Iteration 25018 => Loss: 47.63701813841911558711\n",
      "Iteration 25019 => Loss: 47.63684471444774715110\n",
      "Iteration 25020 => Loss: 47.63667129183741622001\n",
      "Iteration 25021 => Loss: 47.63649787058808726670\n",
      "Iteration 25022 => Loss: 47.63632445069975318575\n",
      "Iteration 25023 => Loss: 47.63615103217242818801\n",
      "Iteration 25024 => Loss: 47.63597761500607674634\n",
      "Iteration 25025 => Loss: 47.63580419920070596618\n",
      "Iteration 25026 => Loss: 47.63563078475625900410\n",
      "Iteration 25027 => Loss: 47.63545737167278559809\n",
      "Iteration 25028 => Loss: 47.63528395995025022103\n",
      "Iteration 25029 => Loss: 47.63511054958863155662\n",
      "Iteration 25030 => Loss: 47.63493714058795092114\n",
      "Iteration 25031 => Loss: 47.63476373294812304948\n",
      "Iteration 25032 => Loss: 47.63459032666922610133\n",
      "Iteration 25033 => Loss: 47.63441692175121744413\n",
      "Iteration 25034 => Loss: 47.63424351819407576158\n",
      "Iteration 25035 => Loss: 47.63407011599780105371\n",
      "Iteration 25036 => Loss: 47.63389671516235779336\n",
      "Iteration 25037 => Loss: 47.63372331568776729682\n",
      "Iteration 25038 => Loss: 47.63354991757400114238\n",
      "Iteration 25039 => Loss: 47.63337652082106643547\n",
      "Iteration 25040 => Loss: 47.63320312542894185981\n",
      "Iteration 25041 => Loss: 47.63302973139759188825\n",
      "Iteration 25042 => Loss: 47.63285633872705204794\n",
      "Iteration 25043 => Loss: 47.63268294741727970631\n",
      "Iteration 25044 => Loss: 47.63250955746827486337\n",
      "Iteration 25045 => Loss: 47.63233616888002330825\n",
      "Iteration 25046 => Loss: 47.63216278165251793553\n",
      "Iteration 25047 => Loss: 47.63198939578573032350\n",
      "Iteration 25048 => Loss: 47.63181601127969599929\n",
      "Iteration 25049 => Loss: 47.63164262813435811950\n",
      "Iteration 25050 => Loss: 47.63146924634970957868\n",
      "Iteration 25051 => Loss: 47.63129586592577879856\n",
      "Iteration 25052 => Loss: 47.63112248686251604113\n",
      "Iteration 25053 => Loss: 47.63094910915992130640\n",
      "Iteration 25054 => Loss: 47.63077573281797327809\n",
      "Iteration 25055 => Loss: 47.63060235783672169418\n",
      "Iteration 25056 => Loss: 47.63042898421604576242\n",
      "Iteration 25057 => Loss: 47.63025561195603074793\n",
      "Iteration 25058 => Loss: 47.63008224105661980730\n",
      "Iteration 25059 => Loss: 47.62990887151782004594\n",
      "Iteration 25060 => Loss: 47.62973550333961014758\n",
      "Iteration 25061 => Loss: 47.62956213652199721764\n",
      "Iteration 25062 => Loss: 47.62938877106493862357\n",
      "Iteration 25063 => Loss: 47.62921540696846989249\n",
      "Iteration 25064 => Loss: 47.62904204423254128642\n",
      "Iteration 25065 => Loss: 47.62886868285715991078\n",
      "Iteration 25066 => Loss: 47.62869532284229023844\n",
      "Iteration 25067 => Loss: 47.62852196418794648025\n",
      "Iteration 25068 => Loss: 47.62834860689412153079\n",
      "Iteration 25069 => Loss: 47.62817525096078696834\n",
      "Iteration 25070 => Loss: 47.62800189638794989833\n",
      "Iteration 25071 => Loss: 47.62782854317558189905\n",
      "Iteration 25072 => Loss: 47.62765519132369007593\n",
      "Iteration 25073 => Loss: 47.62748184083225311269\n",
      "Iteration 25074 => Loss: 47.62730849170124258762\n",
      "Iteration 25075 => Loss: 47.62713514393069402786\n",
      "Iteration 25076 => Loss: 47.62696179752055769541\n",
      "Iteration 25077 => Loss: 47.62678845247084069570\n",
      "Iteration 25078 => Loss: 47.62661510878151460702\n",
      "Iteration 25079 => Loss: 47.62644176645257232394\n",
      "Iteration 25080 => Loss: 47.62626842548404226818\n",
      "Iteration 25081 => Loss: 47.62609508587585338546\n",
      "Iteration 25082 => Loss: 47.62592174762805541377\n",
      "Iteration 25083 => Loss: 47.62574841074057729884\n",
      "Iteration 25084 => Loss: 47.62557507521345456780\n",
      "Iteration 25085 => Loss: 47.62540174104664458810\n",
      "Iteration 25086 => Loss: 47.62522840824016157057\n",
      "Iteration 25087 => Loss: 47.62505507679401262067\n",
      "Iteration 25088 => Loss: 47.62488174670811247324\n",
      "Iteration 25089 => Loss: 47.62470841798251086630\n",
      "Iteration 25090 => Loss: 47.62453509061720069440\n",
      "Iteration 25091 => Loss: 47.62436176461214643041\n",
      "Iteration 25092 => Loss: 47.62418843996734096891\n",
      "Iteration 25093 => Loss: 47.62401511668278430989\n",
      "Iteration 25094 => Loss: 47.62384179475847645335\n",
      "Iteration 25095 => Loss: 47.62366847419436055588\n",
      "Iteration 25096 => Loss: 47.62349515499046503919\n",
      "Iteration 25097 => Loss: 47.62332183714676858699\n",
      "Iteration 25098 => Loss: 47.62314852066325698843\n",
      "Iteration 25099 => Loss: 47.62297520553993024350\n",
      "Iteration 25100 => Loss: 47.62280189177678124679\n",
      "Iteration 25101 => Loss: 47.62262857937378157658\n",
      "Iteration 25102 => Loss: 47.62245526833091702201\n",
      "Iteration 25103 => Loss: 47.62228195864819468852\n",
      "Iteration 25104 => Loss: 47.62210865032558615439\n",
      "Iteration 25105 => Loss: 47.62193534336311984134\n",
      "Iteration 25106 => Loss: 47.62176203776076022223\n",
      "Iteration 25107 => Loss: 47.62158873351846466448\n",
      "Iteration 25108 => Loss: 47.62141543063627580068\n",
      "Iteration 25109 => Loss: 47.62124212911413678739\n",
      "Iteration 25110 => Loss: 47.62106882895207604633\n",
      "Iteration 25111 => Loss: 47.62089553015006515579\n",
      "Iteration 25112 => Loss: 47.62072223270807569406\n",
      "Iteration 25113 => Loss: 47.62054893662613608285\n",
      "Iteration 25114 => Loss: 47.62037564190421079502\n",
      "Iteration 25115 => Loss: 47.62020234854228561971\n",
      "Iteration 25116 => Loss: 47.62002905654035345151\n",
      "Iteration 25117 => Loss: 47.61985576589842850126\n",
      "Iteration 25118 => Loss: 47.61968247661645392554\n",
      "Iteration 25119 => Loss: 47.61950918869447946236\n",
      "Iteration 25120 => Loss: 47.61933590213243405742\n",
      "Iteration 25121 => Loss: 47.61916261693033192159\n",
      "Iteration 25122 => Loss: 47.61898933308816594945\n",
      "Iteration 25123 => Loss: 47.61881605060591482470\n",
      "Iteration 25124 => Loss: 47.61864276948359275821\n",
      "Iteration 25125 => Loss: 47.61846948972115711740\n",
      "Iteration 25126 => Loss: 47.61829621131862211314\n",
      "Iteration 25127 => Loss: 47.61812293427594511286\n",
      "Iteration 25128 => Loss: 47.61794965859317585455\n",
      "Iteration 25129 => Loss: 47.61777638427024328394\n",
      "Iteration 25130 => Loss: 47.61760311130715450645\n",
      "Iteration 25131 => Loss: 47.61742983970390241666\n",
      "Iteration 25132 => Loss: 47.61725656946047990914\n",
      "Iteration 25133 => Loss: 47.61708330057688698389\n",
      "Iteration 25134 => Loss: 47.61691003305308811377\n",
      "Iteration 25135 => Loss: 47.61673676688909040422\n",
      "Iteration 25136 => Loss: 47.61656350208487253894\n",
      "Iteration 25137 => Loss: 47.61639023864041320167\n",
      "Iteration 25138 => Loss: 47.61621697655571239238\n",
      "Iteration 25139 => Loss: 47.61604371583079142738\n",
      "Iteration 25140 => Loss: 47.61587045646560056866\n",
      "Iteration 25141 => Loss: 47.61569719846012560538\n",
      "Iteration 25142 => Loss: 47.61552394181439495924\n",
      "Iteration 25143 => Loss: 47.61535068652835178682\n",
      "Iteration 25144 => Loss: 47.61517743260203161526\n",
      "Iteration 25145 => Loss: 47.61500418003537049572\n",
      "Iteration 25146 => Loss: 47.61483092882839684989\n",
      "Iteration 25147 => Loss: 47.61465767898109646694\n",
      "Iteration 25148 => Loss: 47.61448443049344803057\n",
      "Iteration 25149 => Loss: 47.61431118336544443537\n",
      "Iteration 25150 => Loss: 47.61413793759707147046\n",
      "Iteration 25151 => Loss: 47.61396469318832913586\n",
      "Iteration 25152 => Loss: 47.61379145013920322071\n",
      "Iteration 25153 => Loss: 47.61361820844967240873\n",
      "Iteration 25154 => Loss: 47.61344496811972248906\n",
      "Iteration 25155 => Loss: 47.61327172914936056713\n",
      "Iteration 25156 => Loss: 47.61309849153858664295\n",
      "Iteration 25157 => Loss: 47.61292525528735808393\n",
      "Iteration 25158 => Loss: 47.61275202039568199552\n",
      "Iteration 25159 => Loss: 47.61257878686352285058\n",
      "Iteration 25160 => Loss: 47.61240555469092328167\n",
      "Iteration 25161 => Loss: 47.61223232387784065622\n",
      "Iteration 25162 => Loss: 47.61205909442422523625\n",
      "Iteration 25163 => Loss: 47.61188586633012675975\n",
      "Iteration 25164 => Loss: 47.61171263959553812128\n",
      "Iteration 25165 => Loss: 47.61153941422039537201\n",
      "Iteration 25166 => Loss: 47.61136619020473403907\n",
      "Iteration 25167 => Loss: 47.61119296754850438447\n",
      "Iteration 25168 => Loss: 47.61101974625171351363\n",
      "Iteration 25169 => Loss: 47.61084652631438984827\n",
      "Iteration 25170 => Loss: 47.61067330773646233411\n",
      "Iteration 25171 => Loss: 47.61050009051796649828\n",
      "Iteration 25172 => Loss: 47.61032687465881707567\n",
      "Iteration 25173 => Loss: 47.61015366015910643682\n",
      "Iteration 25174 => Loss: 47.60998044701877063289\n",
      "Iteration 25175 => Loss: 47.60980723523779545303\n",
      "Iteration 25176 => Loss: 47.60963402481615958095\n",
      "Iteration 25177 => Loss: 47.60946081575388433293\n",
      "Iteration 25178 => Loss: 47.60928760805094128727\n",
      "Iteration 25179 => Loss: 47.60911440170733754940\n",
      "Iteration 25180 => Loss: 47.60894119672302338131\n",
      "Iteration 25181 => Loss: 47.60876799309802720472\n",
      "Iteration 25182 => Loss: 47.60859479083233480878\n",
      "Iteration 25183 => Loss: 47.60842158992589645550\n",
      "Iteration 25184 => Loss: 47.60824839037876188286\n",
      "Iteration 25185 => Loss: 47.60807519219086714202\n",
      "Iteration 25186 => Loss: 47.60790199536224065469\n",
      "Iteration 25187 => Loss: 47.60772879989281136659\n",
      "Iteration 25188 => Loss: 47.60755560578266454286\n",
      "Iteration 25189 => Loss: 47.60738241303170781293\n",
      "Iteration 25190 => Loss: 47.60720922163996249310\n",
      "Iteration 25191 => Loss: 47.60703603160740726707\n",
      "Iteration 25192 => Loss: 47.60686284293405634571\n",
      "Iteration 25193 => Loss: 47.60668965561986709645\n",
      "Iteration 25194 => Loss: 47.60651646966484662471\n",
      "Iteration 25195 => Loss: 47.60634328506896650879\n",
      "Iteration 25196 => Loss: 47.60617010183224806497\n",
      "Iteration 25197 => Loss: 47.60599691995465576611\n",
      "Iteration 25198 => Loss: 47.60582373943618961221\n",
      "Iteration 25199 => Loss: 47.60565056027682828699\n",
      "Iteration 25200 => Loss: 47.60547738247657889588\n",
      "Iteration 25201 => Loss: 47.60530420603541301716\n",
      "Iteration 25202 => Loss: 47.60513103095333065085\n",
      "Iteration 25203 => Loss: 47.60495785723031758607\n",
      "Iteration 25204 => Loss: 47.60478468486635250656\n",
      "Iteration 25205 => Loss: 47.60461151386144251774\n",
      "Iteration 25206 => Loss: 47.60443834421557340875\n",
      "Iteration 25207 => Loss: 47.60426517592871675788\n",
      "Iteration 25208 => Loss: 47.60409200900088677599\n",
      "Iteration 25209 => Loss: 47.60391884343206214680\n",
      "Iteration 25210 => Loss: 47.60374567922221444860\n",
      "Iteration 25211 => Loss: 47.60357251637136499767\n",
      "Iteration 25212 => Loss: 47.60339935487949247772\n",
      "Iteration 25213 => Loss: 47.60322619474658978334\n",
      "Iteration 25214 => Loss: 47.60305303597262138737\n",
      "Iteration 25215 => Loss: 47.60287987855760150069\n",
      "Iteration 25216 => Loss: 47.60270672250149459614\n",
      "Iteration 25217 => Loss: 47.60253356780432909545\n",
      "Iteration 25218 => Loss: 47.60236041446605526062\n",
      "Iteration 25219 => Loss: 47.60218726248671572421\n",
      "Iteration 25220 => Loss: 47.60201411186623232652\n",
      "Iteration 25221 => Loss: 47.60184096260461927841\n",
      "Iteration 25222 => Loss: 47.60166781470189789616\n",
      "Iteration 25223 => Loss: 47.60149466815800423092\n",
      "Iteration 25224 => Loss: 47.60132152297298091526\n",
      "Iteration 25225 => Loss: 47.60114837914678531661\n",
      "Iteration 25226 => Loss: 47.60097523667940322412\n",
      "Iteration 25227 => Loss: 47.60080209557083463778\n",
      "Iteration 25228 => Loss: 47.60062895582108666304\n",
      "Iteration 25229 => Loss: 47.60045581743010956188\n",
      "Iteration 25230 => Loss: 47.60028268039792465061\n",
      "Iteration 25231 => Loss: 47.60010954472448929664\n",
      "Iteration 25232 => Loss: 47.59993641040983902712\n",
      "Iteration 25233 => Loss: 47.59976327745394542035\n",
      "Iteration 25234 => Loss: 47.59959014585676584375\n",
      "Iteration 25235 => Loss: 47.59941701561832871903\n",
      "Iteration 25236 => Loss: 47.59924388673859851906\n",
      "Iteration 25237 => Loss: 47.59907075921757524384\n",
      "Iteration 25238 => Loss: 47.59889763305525889336\n",
      "Iteration 25239 => Loss: 47.59872450825161394050\n",
      "Iteration 25240 => Loss: 47.59855138480665459610\n",
      "Iteration 25241 => Loss: 47.59837826272035954389\n",
      "Iteration 25242 => Loss: 47.59820514199270746758\n",
      "Iteration 25243 => Loss: 47.59803202262370547260\n",
      "Iteration 25244 => Loss: 47.59785890461332513723\n",
      "Iteration 25245 => Loss: 47.59768578796158777777\n",
      "Iteration 25246 => Loss: 47.59751267266843655079\n",
      "Iteration 25247 => Loss: 47.59733955873388566715\n",
      "Iteration 25248 => Loss: 47.59716644615792802142\n",
      "Iteration 25249 => Loss: 47.59699333494056361360\n",
      "Iteration 25250 => Loss: 47.59682022508174270570\n",
      "Iteration 25251 => Loss: 47.59664711658150793028\n",
      "Iteration 25252 => Loss: 47.59647400943978823307\n",
      "Iteration 25253 => Loss: 47.59630090365662624663\n",
      "Iteration 25254 => Loss: 47.59612779923199354926\n",
      "Iteration 25255 => Loss: 47.59595469616584750838\n",
      "Iteration 25256 => Loss: 47.59578159445823075657\n",
      "Iteration 25257 => Loss: 47.59560849410910776669\n",
      "Iteration 25258 => Loss: 47.59543539511844301160\n",
      "Iteration 25259 => Loss: 47.59526229748626491300\n",
      "Iteration 25260 => Loss: 47.59508920121255926006\n",
      "Iteration 25261 => Loss: 47.59491610629728342019\n",
      "Iteration 25262 => Loss: 47.59474301274048002597\n",
      "Iteration 25263 => Loss: 47.59456992054207091769\n",
      "Iteration 25264 => Loss: 47.59439682970208451707\n",
      "Iteration 25265 => Loss: 47.59422374022050661324\n",
      "Iteration 25266 => Loss: 47.59405065209733720621\n",
      "Iteration 25267 => Loss: 47.59387756533254076885\n",
      "Iteration 25268 => Loss: 47.59370447992612440657\n",
      "Iteration 25269 => Loss: 47.59353139587808101396\n",
      "Iteration 25270 => Loss: 47.59335831318839638016\n",
      "Iteration 25271 => Loss: 47.59318523185705629430\n",
      "Iteration 25272 => Loss: 47.59301215188403233469\n",
      "Iteration 25273 => Loss: 47.59283907326934581761\n",
      "Iteration 25274 => Loss: 47.59266599601295411048\n",
      "Iteration 25275 => Loss: 47.59249292011487852960\n",
      "Iteration 25276 => Loss: 47.59231984557510486411\n",
      "Iteration 25277 => Loss: 47.59214677239356916516\n",
      "Iteration 25278 => Loss: 47.59197370057034959245\n",
      "Iteration 25279 => Loss: 47.59180063010536798629\n",
      "Iteration 25280 => Loss: 47.59162756099862434667\n",
      "Iteration 25281 => Loss: 47.59145449325013288444\n",
      "Iteration 25282 => Loss: 47.59128142685985807248\n",
      "Iteration 25283 => Loss: 47.59110836182780701620\n",
      "Iteration 25284 => Loss: 47.59093529815395129390\n",
      "Iteration 25285 => Loss: 47.59076223583829801100\n",
      "Iteration 25286 => Loss: 47.59058917488083295666\n",
      "Iteration 25287 => Loss: 47.59041611528154902544\n",
      "Iteration 25288 => Loss: 47.59024305704040358478\n",
      "Iteration 25289 => Loss: 47.59007000015741084553\n",
      "Iteration 25290 => Loss: 47.58989694463257791313\n",
      "Iteration 25291 => Loss: 47.58972389046586215500\n",
      "Iteration 25292 => Loss: 47.58955083765727067657\n",
      "Iteration 25293 => Loss: 47.58937778620678926700\n",
      "Iteration 25294 => Loss: 47.58920473611441792627\n",
      "Iteration 25295 => Loss: 47.58903168738013533812\n",
      "Iteration 25296 => Loss: 47.58885864000389176454\n",
      "Iteration 25297 => Loss: 47.58868559398575115438\n",
      "Iteration 25298 => Loss: 47.58851254932564245337\n",
      "Iteration 25299 => Loss: 47.58833950602360118864\n",
      "Iteration 25300 => Loss: 47.58816646407959183307\n",
      "Iteration 25301 => Loss: 47.58799342349360017579\n",
      "Iteration 25302 => Loss: 47.58782038426561911137\n",
      "Iteration 25303 => Loss: 47.58764734639564863983\n",
      "Iteration 25304 => Loss: 47.58747430988368165572\n",
      "Iteration 25305 => Loss: 47.58730127472966131563\n",
      "Iteration 25306 => Loss: 47.58712824093365156841\n",
      "Iteration 25307 => Loss: 47.58695520849556714893\n",
      "Iteration 25308 => Loss: 47.58678217741544358432\n",
      "Iteration 25309 => Loss: 47.58660914769325955831\n",
      "Iteration 25310 => Loss: 47.58643611932900086003\n",
      "Iteration 25311 => Loss: 47.58626309232267459493\n",
      "Iteration 25312 => Loss: 47.58609006667424523584\n",
      "Iteration 25313 => Loss: 47.58591704238371988822\n",
      "Iteration 25314 => Loss: 47.58574401945107013034\n",
      "Iteration 25315 => Loss: 47.58557099787630306764\n",
      "Iteration 25316 => Loss: 47.58539797765938317298\n",
      "Iteration 25317 => Loss: 47.58522495880033176263\n",
      "Iteration 25318 => Loss: 47.58505194129913462575\n",
      "Iteration 25319 => Loss: 47.58487892515575623520\n",
      "Iteration 25320 => Loss: 47.58470591037017527469\n",
      "Iteration 25321 => Loss: 47.58453289694242727137\n",
      "Iteration 25322 => Loss: 47.58435988487249090895\n",
      "Iteration 25323 => Loss: 47.58418687416033066029\n",
      "Iteration 25324 => Loss: 47.58401386480596073625\n",
      "Iteration 25325 => Loss: 47.58384085680935271512\n",
      "Iteration 25326 => Loss: 47.58366785017049238604\n",
      "Iteration 25327 => Loss: 47.58349484488939395987\n",
      "Iteration 25328 => Loss: 47.58332184096602901491\n",
      "Iteration 25329 => Loss: 47.58314883840038334029\n",
      "Iteration 25330 => Loss: 47.58297583719244983058\n",
      "Iteration 25331 => Loss: 47.58280283734222138037\n",
      "Iteration 25332 => Loss: 47.58262983884967667336\n",
      "Iteration 25333 => Loss: 47.58245684171485123670\n",
      "Iteration 25334 => Loss: 47.58228384593767401611\n",
      "Iteration 25335 => Loss: 47.58211085151815211702\n",
      "Iteration 25336 => Loss: 47.58193785845630685571\n",
      "Iteration 25337 => Loss: 47.58176486675206717791\n",
      "Iteration 25338 => Loss: 47.58159187640548282161\n",
      "Iteration 25339 => Loss: 47.58141888741651115424\n",
      "Iteration 25340 => Loss: 47.58124589978515928124\n",
      "Iteration 25341 => Loss: 47.58107291351139167546\n",
      "Iteration 25342 => Loss: 47.58089992859520123147\n",
      "Iteration 25343 => Loss: 47.58072694503660216014\n",
      "Iteration 25344 => Loss: 47.58055396283557314518\n",
      "Iteration 25345 => Loss: 47.58038098199209997574\n",
      "Iteration 25346 => Loss: 47.58020800250613291382\n",
      "Iteration 25347 => Loss: 47.58003502437773590827\n",
      "Iteration 25348 => Loss: 47.57986204760686632653\n",
      "Iteration 25349 => Loss: 47.57968907219350285231\n",
      "Iteration 25350 => Loss: 47.57951609813763127477\n",
      "Iteration 25351 => Loss: 47.57934312543924448846\n",
      "Iteration 25352 => Loss: 47.57917015409835670425\n",
      "Iteration 25353 => Loss: 47.57899718411493950043\n",
      "Iteration 25354 => Loss: 47.57882421548897866614\n",
      "Iteration 25355 => Loss: 47.57865124822045999053\n",
      "Iteration 25356 => Loss: 47.57847828230938347360\n",
      "Iteration 25357 => Loss: 47.57830531775572779907\n",
      "Iteration 25358 => Loss: 47.57813235455949296693\n",
      "Iteration 25359 => Loss: 47.57795939272067897718\n",
      "Iteration 25360 => Loss: 47.57778643223925030270\n",
      "Iteration 25361 => Loss: 47.57761347311519983805\n",
      "Iteration 25362 => Loss: 47.57744051534851337237\n",
      "Iteration 25363 => Loss: 47.57726755893919801110\n",
      "Iteration 25364 => Loss: 47.57709460388723954338\n",
      "Iteration 25365 => Loss: 47.57692165019261665293\n",
      "Iteration 25366 => Loss: 47.57674869785534355060\n",
      "Iteration 25367 => Loss: 47.57657574687538470926\n",
      "Iteration 25368 => Loss: 47.57640279725272591804\n",
      "Iteration 25369 => Loss: 47.57622984898738138781\n",
      "Iteration 25370 => Loss: 47.57605690207932269686\n",
      "Iteration 25371 => Loss: 47.57588395652854273976\n",
      "Iteration 25372 => Loss: 47.57571101233501309480\n",
      "Iteration 25373 => Loss: 47.57553806949874797283\n",
      "Iteration 25374 => Loss: 47.57536512801973316300\n",
      "Iteration 25375 => Loss: 47.57519218789796866531\n",
      "Iteration 25376 => Loss: 47.57501924913341184720\n",
      "Iteration 25377 => Loss: 47.57484631172605560323\n",
      "Iteration 25378 => Loss: 47.57467337567592835512\n",
      "Iteration 25379 => Loss: 47.57450044098300168116\n",
      "Iteration 25380 => Loss: 47.57432750764722584336\n",
      "Iteration 25381 => Loss: 47.57415457566863636885\n",
      "Iteration 25382 => Loss: 47.57398164504719773049\n",
      "Iteration 25383 => Loss: 47.57380871578293835000\n",
      "Iteration 25384 => Loss: 47.57363578787578717311\n",
      "Iteration 25385 => Loss: 47.57346286132578683237\n",
      "Iteration 25386 => Loss: 47.57328993613288758979\n",
      "Iteration 25387 => Loss: 47.57311701229711786709\n",
      "Iteration 25388 => Loss: 47.57294408981841371542\n",
      "Iteration 25389 => Loss: 47.57277116869683197820\n",
      "Iteration 25390 => Loss: 47.57259824893229449572\n",
      "Iteration 25391 => Loss: 47.57242533052485100598\n",
      "Iteration 25392 => Loss: 47.57225241347446598184\n",
      "Iteration 25393 => Loss: 47.57207949778108257988\n",
      "Iteration 25394 => Loss: 47.57190658344475053809\n",
      "Iteration 25395 => Loss: 47.57173367046545564563\n",
      "Iteration 25396 => Loss: 47.57156075884315526991\n",
      "Iteration 25397 => Loss: 47.57138784857785651639\n",
      "Iteration 25398 => Loss: 47.57121493966957359589\n",
      "Iteration 25399 => Loss: 47.57104203211824966502\n",
      "Iteration 25400 => Loss: 47.57086912592389182919\n",
      "Iteration 25401 => Loss: 47.57069622108650719383\n",
      "Iteration 25402 => Loss: 47.57052331760605312638\n",
      "Iteration 25403 => Loss: 47.57035041548256515398\n",
      "Iteration 25404 => Loss: 47.57017751471597222235\n",
      "Iteration 25405 => Loss: 47.57000461530631696405\n",
      "Iteration 25406 => Loss: 47.56983171725354964110\n",
      "Iteration 25407 => Loss: 47.56965882055769156977\n",
      "Iteration 25408 => Loss: 47.56948592521871432837\n",
      "Iteration 25409 => Loss: 47.56931303123661791687\n",
      "Iteration 25410 => Loss: 47.56914013861138101902\n",
      "Iteration 25411 => Loss: 47.56896724734298942394\n",
      "Iteration 25412 => Loss: 47.56879435743142892079\n",
      "Iteration 25413 => Loss: 47.56862146887670661499\n",
      "Iteration 25414 => Loss: 47.56844858167880829569\n",
      "Iteration 25415 => Loss: 47.56827569583771975203\n",
      "Iteration 25416 => Loss: 47.56810281135344098402\n",
      "Iteration 25417 => Loss: 47.56792992822592935909\n",
      "Iteration 25418 => Loss: 47.56775704645521329894\n",
      "Iteration 25419 => Loss: 47.56758416604125727645\n",
      "Iteration 25420 => Loss: 47.56741128698405418618\n",
      "Iteration 25421 => Loss: 47.56723840928360402813\n",
      "Iteration 25422 => Loss: 47.56706553293988548603\n",
      "Iteration 25423 => Loss: 47.56689265795290566530\n",
      "Iteration 25424 => Loss: 47.56671978432260772252\n",
      "Iteration 25425 => Loss: 47.56654691204902007939\n",
      "Iteration 25426 => Loss: 47.56637404113214273593\n",
      "Iteration 25427 => Loss: 47.56620117157193305957\n",
      "Iteration 25428 => Loss: 47.56602830336840526115\n",
      "Iteration 25429 => Loss: 47.56585543652153091898\n",
      "Iteration 25430 => Loss: 47.56568257103129582219\n",
      "Iteration 25431 => Loss: 47.56550970689773549793\n",
      "Iteration 25432 => Loss: 47.56533684412077889192\n",
      "Iteration 25433 => Loss: 47.56516398270045442587\n",
      "Iteration 25434 => Loss: 47.56499112263671236178\n",
      "Iteration 25435 => Loss: 47.56481826392958822680\n",
      "Iteration 25436 => Loss: 47.56464540657903938836\n",
      "Iteration 25437 => Loss: 47.56447255058506584646\n",
      "Iteration 25438 => Loss: 47.56429969594767470653\n",
      "Iteration 25439 => Loss: 47.56412684266680912515\n",
      "Iteration 25440 => Loss: 47.56395399074250462945\n",
      "Iteration 25441 => Loss: 47.56378114017471858688\n",
      "Iteration 25442 => Loss: 47.56360829096347231371\n",
      "Iteration 25443 => Loss: 47.56343544310873028280\n",
      "Iteration 25444 => Loss: 47.56326259661050670502\n",
      "Iteration 25445 => Loss: 47.56308975146873763151\n",
      "Iteration 25446 => Loss: 47.56291690768347990570\n",
      "Iteration 25447 => Loss: 47.56274406525466957874\n",
      "Iteration 25448 => Loss: 47.56257122418233507233\n",
      "Iteration 25449 => Loss: 47.56239838446643375391\n",
      "Iteration 25450 => Loss: 47.56222554610697272892\n",
      "Iteration 25451 => Loss: 47.56205270910393778649\n",
      "Iteration 25452 => Loss: 47.56187987345733603206\n",
      "Iteration 25453 => Loss: 47.56170703916711062220\n",
      "Iteration 25454 => Loss: 47.56153420623329708405\n",
      "Iteration 25455 => Loss: 47.56136137465585278505\n",
      "Iteration 25456 => Loss: 47.56118854443479193606\n",
      "Iteration 25457 => Loss: 47.56101571557010032620\n",
      "Iteration 25458 => Loss: 47.56084288806174953379\n",
      "Iteration 25459 => Loss: 47.56067006190974666424\n",
      "Iteration 25460 => Loss: 47.56049723711407750670\n",
      "Iteration 25461 => Loss: 47.56032441367471363947\n",
      "Iteration 25462 => Loss: 47.56015159159166216796\n",
      "Iteration 25463 => Loss: 47.55997877086492309218\n",
      "Iteration 25464 => Loss: 47.55980595149446088499\n",
      "Iteration 25465 => Loss: 47.55963313348028975724\n",
      "Iteration 25466 => Loss: 47.55946031682236707638\n",
      "Iteration 25467 => Loss: 47.55928750152072126411\n",
      "Iteration 25468 => Loss: 47.55911468757528837159\n",
      "Iteration 25469 => Loss: 47.55894187498611103138\n",
      "Iteration 25470 => Loss: 47.55876906375316082176\n",
      "Iteration 25471 => Loss: 47.55859625387641642646\n",
      "Iteration 25472 => Loss: 47.55842344535587784549\n",
      "Iteration 25473 => Loss: 47.55825063819153086797\n",
      "Iteration 25474 => Loss: 47.55807783238337549392\n",
      "Iteration 25475 => Loss: 47.55790502793138330162\n",
      "Iteration 25476 => Loss: 47.55773222483554718565\n",
      "Iteration 25477 => Loss: 47.55755942309586004058\n",
      "Iteration 25478 => Loss: 47.55738662271231476097\n",
      "Iteration 25479 => Loss: 47.55721382368489003056\n",
      "Iteration 25480 => Loss: 47.55704102601359295477\n",
      "Iteration 25481 => Loss: 47.55686822969840221731\n",
      "Iteration 25482 => Loss: 47.55669543473932492361\n",
      "Iteration 25483 => Loss: 47.55652264113629001940\n",
      "Iteration 25484 => Loss: 47.55634984888936855896\n",
      "Iteration 25485 => Loss: 47.55617705799848948800\n",
      "Iteration 25486 => Loss: 47.55600426846367412281\n",
      "Iteration 25487 => Loss: 47.55583148028490114712\n",
      "Iteration 25488 => Loss: 47.55565869346216345548\n",
      "Iteration 25489 => Loss: 47.55548590799544683705\n",
      "Iteration 25490 => Loss: 47.55531312388473708097\n",
      "Iteration 25491 => Loss: 47.55514034113001287096\n",
      "Iteration 25492 => Loss: 47.55496755973130262873\n",
      "Iteration 25493 => Loss: 47.55479477968856372172\n",
      "Iteration 25494 => Loss: 47.55462200100181036078\n",
      "Iteration 25495 => Loss: 47.55444922367098570248\n",
      "Iteration 25496 => Loss: 47.55427644769612527398\n",
      "Iteration 25497 => Loss: 47.55410367307720775898\n",
      "Iteration 25498 => Loss: 47.55393089981420473578\n",
      "Iteration 25499 => Loss: 47.55375812790710909894\n",
      "Iteration 25500 => Loss: 47.55358535735592795390\n",
      "Iteration 25501 => Loss: 47.55341258816063287895\n",
      "Iteration 25502 => Loss: 47.55323982032123808494\n",
      "Iteration 25503 => Loss: 47.55306705383771515017\n",
      "Iteration 25504 => Loss: 47.55289428871003565291\n",
      "Iteration 25505 => Loss: 47.55272152493823512032\n",
      "Iteration 25506 => Loss: 47.55254876252224960353\n",
      "Iteration 25507 => Loss: 47.55237600146209331342\n",
      "Iteration 25508 => Loss: 47.55220324175779467168\n",
      "Iteration 25509 => Loss: 47.55203048340928972948\n",
      "Iteration 25510 => Loss: 47.55185772641656427595\n",
      "Iteration 25511 => Loss: 47.55168497077961120567\n",
      "Iteration 25512 => Loss: 47.55151221649845183492\n",
      "Iteration 25513 => Loss: 47.55133946357307195285\n",
      "Iteration 25514 => Loss: 47.55116671200344313775\n",
      "Iteration 25515 => Loss: 47.55099396178955828418\n",
      "Iteration 25516 => Loss: 47.55082121293141739216\n",
      "Iteration 25517 => Loss: 47.55064846542897072368\n",
      "Iteration 25518 => Loss: 47.55047571928226801674\n",
      "Iteration 25519 => Loss: 47.55030297449125953335\n",
      "Iteration 25520 => Loss: 47.55013023105593816808\n",
      "Iteration 25521 => Loss: 47.54995748897630392094\n",
      "Iteration 25522 => Loss: 47.54978474825233547563\n",
      "Iteration 25523 => Loss: 47.54961200888402572673\n",
      "Iteration 25524 => Loss: 47.54943927087136046339\n",
      "Iteration 25525 => Loss: 47.54926653421436100189\n",
      "Iteration 25526 => Loss: 47.54909379891296339338\n",
      "Iteration 25527 => Loss: 47.54892106496719605957\n",
      "Iteration 25528 => Loss: 47.54874833237702347333\n",
      "Iteration 25529 => Loss: 47.54857560114245984551\n",
      "Iteration 25530 => Loss: 47.54840287126346964897\n",
      "Iteration 25531 => Loss: 47.54823014274005998914\n",
      "Iteration 25532 => Loss: 47.54805741557221665516\n",
      "Iteration 25533 => Loss: 47.54788468975992543619\n",
      "Iteration 25534 => Loss: 47.54771196530317212137\n",
      "Iteration 25535 => Loss: 47.54753924220194960526\n",
      "Iteration 25536 => Loss: 47.54736652045627920415\n",
      "Iteration 25537 => Loss: 47.54719380006608986378\n",
      "Iteration 25538 => Loss: 47.54702108103141000583\n",
      "Iteration 25539 => Loss: 47.54684836335221120862\n",
      "Iteration 25540 => Loss: 47.54667564702850057756\n",
      "Iteration 25541 => Loss: 47.54650293206025679638\n",
      "Iteration 25542 => Loss: 47.54633021844747275964\n",
      "Iteration 25543 => Loss: 47.54615750619014136191\n",
      "Iteration 25544 => Loss: 47.54598479528824839235\n",
      "Iteration 25545 => Loss: 47.54581208574174411297\n",
      "Iteration 25546 => Loss: 47.54563937755069247260\n",
      "Iteration 25547 => Loss: 47.54546667071501531154\n",
      "Iteration 25548 => Loss: 47.54529396523478368408\n",
      "Iteration 25549 => Loss: 47.54512126110989100880\n",
      "Iteration 25550 => Loss: 47.54494855834037991826\n",
      "Iteration 25551 => Loss: 47.54477585692625041247\n",
      "Iteration 25552 => Loss: 47.54460315686745275343\n",
      "Iteration 25553 => Loss: 47.54443045816401536285\n",
      "Iteration 25554 => Loss: 47.54425776081588850275\n",
      "Iteration 25555 => Loss: 47.54408506482310770025\n",
      "Iteration 25556 => Loss: 47.54391237018560190108\n",
      "Iteration 25557 => Loss: 47.54373967690340663239\n",
      "Iteration 25558 => Loss: 47.54356698497650057789\n",
      "Iteration 25559 => Loss: 47.54339429440486952672\n",
      "Iteration 25560 => Loss: 47.54322160518851347888\n",
      "Iteration 25561 => Loss: 47.54304891732738269639\n",
      "Iteration 25562 => Loss: 47.54287623082152691723\n",
      "Iteration 25563 => Loss: 47.54270354567091061426\n",
      "Iteration 25564 => Loss: 47.54253086187550536579\n",
      "Iteration 25565 => Loss: 47.54235817943531827723\n",
      "Iteration 25566 => Loss: 47.54218549835032803230\n",
      "Iteration 25567 => Loss: 47.54201281862054884186\n",
      "Iteration 25568 => Loss: 47.54184014024594517878\n",
      "Iteration 25569 => Loss: 47.54166746322648151590\n",
      "Iteration 25570 => Loss: 47.54149478756220759124\n",
      "Iteration 25571 => Loss: 47.54132211325308077221\n",
      "Iteration 25572 => Loss: 47.54114944029908684797\n",
      "Iteration 25573 => Loss: 47.54097676870021871309\n",
      "Iteration 25574 => Loss: 47.54080409845646926215\n",
      "Iteration 25575 => Loss: 47.54063142956783138970\n",
      "Iteration 25576 => Loss: 47.54045876203429799034\n",
      "Iteration 25577 => Loss: 47.54028609585582643149\n",
      "Iteration 25578 => Loss: 47.54011343103244513486\n",
      "Iteration 25579 => Loss: 47.53994076756411857332\n",
      "Iteration 25580 => Loss: 47.53976810545086806314\n",
      "Iteration 25581 => Loss: 47.53959544469265097177\n",
      "Iteration 25582 => Loss: 47.53942278528944598293\n",
      "Iteration 25583 => Loss: 47.53925012724128862374\n",
      "Iteration 25584 => Loss: 47.53907747054812205079\n",
      "Iteration 25585 => Loss: 47.53890481520996758036\n",
      "Iteration 25586 => Loss: 47.53873216122680389617\n",
      "Iteration 25587 => Loss: 47.53855950859860968194\n",
      "Iteration 25588 => Loss: 47.53838685732538493767\n",
      "Iteration 25589 => Loss: 47.53821420740714387421\n",
      "Iteration 25590 => Loss: 47.53804155884382964814\n",
      "Iteration 25591 => Loss: 47.53786891163545647032\n",
      "Iteration 25592 => Loss: 47.53769626578200302447\n",
      "Iteration 25593 => Loss: 47.53752362128347641601\n",
      "Iteration 25594 => Loss: 47.53735097813983401238\n",
      "Iteration 25595 => Loss: 47.53717833635111844615\n",
      "Iteration 25596 => Loss: 47.53700569591726576846\n",
      "Iteration 25597 => Loss: 47.53683305683829729560\n",
      "Iteration 25598 => Loss: 47.53666041911418460586\n",
      "Iteration 25599 => Loss: 47.53648778274489927753\n",
      "Iteration 25600 => Loss: 47.53631514773047683775\n",
      "Iteration 25601 => Loss: 47.53614251407088886481\n",
      "Iteration 25602 => Loss: 47.53596988176612114785\n",
      "Iteration 25603 => Loss: 47.53579725081618079230\n",
      "Iteration 25604 => Loss: 47.53562462122099674389\n",
      "Iteration 25605 => Loss: 47.53545199298061163518\n",
      "Iteration 25606 => Loss: 47.53527936609501836074\n",
      "Iteration 25607 => Loss: 47.53510674056418849887\n",
      "Iteration 25608 => Loss: 47.53493411638811494413\n",
      "Iteration 25609 => Loss: 47.53476149356677638025\n",
      "Iteration 25610 => Loss: 47.53458887210017991265\n",
      "Iteration 25611 => Loss: 47.53441625198831133048\n",
      "Iteration 25612 => Loss: 47.53424363323116352831\n",
      "Iteration 25613 => Loss: 47.53407101582870097900\n",
      "Iteration 25614 => Loss: 47.53389839978095210427\n",
      "Iteration 25615 => Loss: 47.53372578508785295526\n",
      "Iteration 25616 => Loss: 47.53355317174946037539\n",
      "Iteration 25617 => Loss: 47.53338055976570331040\n",
      "Iteration 25618 => Loss: 47.53320794913660307657\n",
      "Iteration 25619 => Loss: 47.53303533986212414675\n",
      "Iteration 25620 => Loss: 47.53286273194229494266\n",
      "Iteration 25621 => Loss: 47.53269012537708704258\n",
      "Iteration 25622 => Loss: 47.53251752016647913024\n",
      "Iteration 25623 => Loss: 47.53234491631047831106\n",
      "Iteration 25624 => Loss: 47.53217231380905616334\n",
      "Iteration 25625 => Loss: 47.53199971266219847621\n",
      "Iteration 25626 => Loss: 47.53182711286991946054\n",
      "Iteration 25627 => Loss: 47.53165451443218358918\n",
      "Iteration 25628 => Loss: 47.53148191734898375671\n",
      "Iteration 25629 => Loss: 47.53130932162033417399\n",
      "Iteration 25630 => Loss: 47.53113672724622063015\n",
      "Iteration 25631 => Loss: 47.53096413422660049264\n",
      "Iteration 25632 => Loss: 47.53079154256148086688\n",
      "Iteration 25633 => Loss: 47.53061895225084043659\n",
      "Iteration 25634 => Loss: 47.53044636329470762348\n",
      "Iteration 25635 => Loss: 47.53027377569301137328\n",
      "Iteration 25636 => Loss: 47.53010118944578010769\n",
      "Iteration 25637 => Loss: 47.52992860455301382672\n",
      "Iteration 25638 => Loss: 47.52975602101466989780\n",
      "Iteration 25639 => Loss: 47.52958343883077674263\n",
      "Iteration 25640 => Loss: 47.52941085800126330696\n",
      "Iteration 25641 => Loss: 47.52923827852617932876\n",
      "Iteration 25642 => Loss: 47.52906570040548928091\n",
      "Iteration 25643 => Loss: 47.52889312363917895254\n",
      "Iteration 25644 => Loss: 47.52872054822723413281\n",
      "Iteration 25645 => Loss: 47.52854797416967613799\n",
      "Iteration 25646 => Loss: 47.52837540146644101924\n",
      "Iteration 25647 => Loss: 47.52820283011757140912\n",
      "Iteration 25648 => Loss: 47.52803026012301046421\n",
      "Iteration 25649 => Loss: 47.52785769148278660623\n",
      "Iteration 25650 => Loss: 47.52768512419686430803\n",
      "Iteration 25651 => Loss: 47.52751255826524356962\n",
      "Iteration 25652 => Loss: 47.52733999368791728557\n",
      "Iteration 25653 => Loss: 47.52716743046486413959\n",
      "Iteration 25654 => Loss: 47.52699486859607702627\n",
      "Iteration 25655 => Loss: 47.52682230808152041845\n",
      "Iteration 25656 => Loss: 47.52664974892124405415\n",
      "Iteration 25657 => Loss: 47.52647719111520530078\n",
      "Iteration 25658 => Loss: 47.52630463466336152578\n",
      "Iteration 25659 => Loss: 47.52613207956576246715\n",
      "Iteration 25660 => Loss: 47.52595952582234417605\n",
      "Iteration 25661 => Loss: 47.52578697343312796875\n",
      "Iteration 25662 => Loss: 47.52561442239809963439\n",
      "Iteration 25663 => Loss: 47.52544187271723785670\n",
      "Iteration 25664 => Loss: 47.52526932439052842483\n",
      "Iteration 25665 => Loss: 47.52509677741796423334\n",
      "Iteration 25666 => Loss: 47.52492423179957370394\n",
      "Iteration 25667 => Loss: 47.52475168753527867693\n",
      "Iteration 25668 => Loss: 47.52457914462512178488\n",
      "Iteration 25669 => Loss: 47.52440660306907460608\n",
      "Iteration 25670 => Loss: 47.52423406286710161339\n",
      "Iteration 25671 => Loss: 47.52406152401923833395\n",
      "Iteration 25672 => Loss: 47.52388898652542081891\n",
      "Iteration 25673 => Loss: 47.52371645038569880626\n",
      "Iteration 25674 => Loss: 47.52354391560003676886\n",
      "Iteration 25675 => Loss: 47.52337138216837075788\n",
      "Iteration 25676 => Loss: 47.52319885009077182758\n",
      "Iteration 25677 => Loss: 47.52302631936720445083\n",
      "Iteration 25678 => Loss: 47.52285378999762599506\n",
      "Iteration 25679 => Loss: 47.52268126198207198740\n",
      "Iteration 25680 => Loss: 47.52250873532049979531\n",
      "Iteration 25681 => Loss: 47.52233621001289520791\n",
      "Iteration 25682 => Loss: 47.52216368605927954150\n",
      "Iteration 25683 => Loss: 47.52199116345961016350\n",
      "Iteration 25684 => Loss: 47.52181864221390128478\n",
      "Iteration 25685 => Loss: 47.52164612232211737819\n",
      "Iteration 25686 => Loss: 47.52147360378426554917\n",
      "Iteration 25687 => Loss: 47.52130108660032448142\n",
      "Iteration 25688 => Loss: 47.52112857077028706954\n",
      "Iteration 25689 => Loss: 47.52095605629415331350\n",
      "Iteration 25690 => Loss: 47.52078354317189479161\n",
      "Iteration 25691 => Loss: 47.52061103140351860930\n",
      "Iteration 25692 => Loss: 47.52043852098902476655\n",
      "Iteration 25693 => Loss: 47.52026601192836352539\n",
      "Iteration 25694 => Loss: 47.52009350422152778037\n",
      "Iteration 25695 => Loss: 47.51992099786853884780\n",
      "Iteration 25696 => Loss: 47.51974849286938251680\n",
      "Iteration 25697 => Loss: 47.51957598922402326025\n",
      "Iteration 25698 => Loss: 47.51940348693246107814\n",
      "Iteration 25699 => Loss: 47.51923098599469597048\n",
      "Iteration 25700 => Loss: 47.51905848641069951555\n",
      "Iteration 25701 => Loss: 47.51888598818047881878\n",
      "Iteration 25702 => Loss: 47.51871349130401966931\n",
      "Iteration 25703 => Loss: 47.51854099578130075088\n",
      "Iteration 25704 => Loss: 47.51836850161230785261\n",
      "Iteration 25705 => Loss: 47.51819600879705518537\n",
      "Iteration 25706 => Loss: 47.51802351733552143287\n",
      "Iteration 25707 => Loss: 47.51785102722767817340\n",
      "Iteration 25708 => Loss: 47.51767853847352540697\n",
      "Iteration 25709 => Loss: 47.51750605107306313357\n",
      "Iteration 25710 => Loss: 47.51733356502627003692\n",
      "Iteration 25711 => Loss: 47.51716108033316032788\n",
      "Iteration 25712 => Loss: 47.51698859699365584675\n",
      "Iteration 25713 => Loss: 47.51681611500781343693\n",
      "Iteration 25714 => Loss: 47.51664363437561888759\n",
      "Iteration 25715 => Loss: 47.51647115509700824987\n",
      "Iteration 25716 => Loss: 47.51629867717203126176\n",
      "Iteration 25717 => Loss: 47.51612620060064529071\n",
      "Iteration 25718 => Loss: 47.51595372538285033670\n",
      "Iteration 25719 => Loss: 47.51578125151861087261\n",
      "Iteration 25720 => Loss: 47.51560877900797663642\n",
      "Iteration 25721 => Loss: 47.51543630785087657387\n",
      "Iteration 25722 => Loss: 47.51526383804731779037\n",
      "Iteration 25723 => Loss: 47.51509136959730028593\n",
      "Iteration 25724 => Loss: 47.51491890250078853342\n",
      "Iteration 25725 => Loss: 47.51474643675781095453\n",
      "Iteration 25726 => Loss: 47.51457397236831070586\n",
      "Iteration 25727 => Loss: 47.51440150933231620911\n",
      "Iteration 25728 => Loss: 47.51422904764982746428\n",
      "Iteration 25729 => Loss: 47.51405658732078052253\n",
      "Iteration 25730 => Loss: 47.51388412834520380557\n",
      "Iteration 25731 => Loss: 47.51371167072306178625\n",
      "Iteration 25732 => Loss: 47.51353921445436157001\n",
      "Iteration 25733 => Loss: 47.51336675953910315684\n",
      "Iteration 25734 => Loss: 47.51319430597725101961\n",
      "Iteration 25735 => Loss: 47.51302185376880515832\n",
      "Iteration 25736 => Loss: 47.51284940291375846755\n",
      "Iteration 25737 => Loss: 47.51267695341206831472\n",
      "Iteration 25738 => Loss: 47.51250450526381285954\n",
      "Iteration 25739 => Loss: 47.51233205846889262602\n",
      "Iteration 25740 => Loss: 47.51215961302730050875\n",
      "Iteration 25741 => Loss: 47.51198716893908624570\n",
      "Iteration 25742 => Loss: 47.51181472620418588804\n",
      "Iteration 25743 => Loss: 47.51164228482261364661\n",
      "Iteration 25744 => Loss: 47.51146984479435531057\n",
      "Iteration 25745 => Loss: 47.51129740611939666906\n",
      "Iteration 25746 => Loss: 47.51112496879770930036\n",
      "Iteration 25747 => Loss: 47.51095253282930741534\n",
      "Iteration 25748 => Loss: 47.51078009821418390857\n",
      "Iteration 25749 => Loss: 47.51060766495233878004\n",
      "Iteration 25750 => Loss: 47.51043523304370097549\n",
      "Iteration 25751 => Loss: 47.51026280248833444375\n",
      "Iteration 25752 => Loss: 47.51009037328614681428\n",
      "Iteration 25753 => Loss: 47.50991794543721624677\n",
      "Iteration 25754 => Loss: 47.50974551894147879239\n",
      "Iteration 25755 => Loss: 47.50957309379892734569\n",
      "Iteration 25756 => Loss: 47.50940067000956901211\n",
      "Iteration 25757 => Loss: 47.50922824757336115908\n",
      "Iteration 25758 => Loss: 47.50905582649034641918\n",
      "Iteration 25759 => Loss: 47.50888340676048215983\n",
      "Iteration 25760 => Loss: 47.50871098838374706474\n",
      "Iteration 25761 => Loss: 47.50853857136014823936\n",
      "Iteration 25762 => Loss: 47.50836615568967147283\n",
      "Iteration 25763 => Loss: 47.50819374137228834343\n",
      "Iteration 25764 => Loss: 47.50802132840800595659\n",
      "Iteration 25765 => Loss: 47.50784891679682431231\n",
      "Iteration 25766 => Loss: 47.50767650653871498889\n",
      "Iteration 25767 => Loss: 47.50750409763366377547\n",
      "Iteration 25768 => Loss: 47.50733169008167067204\n",
      "Iteration 25769 => Loss: 47.50715928388273567862\n",
      "Iteration 25770 => Loss: 47.50698687903683037348\n",
      "Iteration 25771 => Loss: 47.50681447554394765120\n",
      "Iteration 25772 => Loss: 47.50664207340407330094\n",
      "Iteration 25773 => Loss: 47.50646967261720732267\n",
      "Iteration 25774 => Loss: 47.50629727318332129471\n",
      "Iteration 25775 => Loss: 47.50612487510242942790\n",
      "Iteration 25776 => Loss: 47.50595247837450330053\n",
      "Iteration 25777 => Loss: 47.50578008299954291260\n",
      "Iteration 25778 => Loss: 47.50560768897754115869\n",
      "Iteration 25779 => Loss: 47.50543529630846251166\n",
      "Iteration 25780 => Loss: 47.50526290499232118236\n",
      "Iteration 25781 => Loss: 47.50509051502909585452\n",
      "Iteration 25782 => Loss: 47.50491812641877942269\n",
      "Iteration 25783 => Loss: 47.50474573916132925433\n",
      "Iteration 25784 => Loss: 47.50457335325682350913\n",
      "Iteration 25785 => Loss: 47.50440096870516271110\n",
      "Iteration 25786 => Loss: 47.50422858550633975483\n",
      "Iteration 25787 => Loss: 47.50405620366042569458\n",
      "Iteration 25788 => Loss: 47.50388382316732105437\n",
      "Iteration 25789 => Loss: 47.50371144402704715048\n",
      "Iteration 25790 => Loss: 47.50353906623959687749\n",
      "Iteration 25791 => Loss: 47.50336668980497734083\n",
      "Iteration 25792 => Loss: 47.50319431472315301335\n",
      "Iteration 25793 => Loss: 47.50302194099411678962\n",
      "Iteration 25794 => Loss: 47.50284956861785445881\n",
      "Iteration 25795 => Loss: 47.50267719759438023175\n",
      "Iteration 25796 => Loss: 47.50250482792363726503\n",
      "Iteration 25797 => Loss: 47.50233245960564687493\n",
      "Iteration 25798 => Loss: 47.50216009264040195603\n",
      "Iteration 25799 => Loss: 47.50198772702789540290\n",
      "Iteration 25800 => Loss: 47.50181536276807747754\n",
      "Iteration 25801 => Loss: 47.50164299986099081252\n",
      "Iteration 25802 => Loss: 47.50147063830658566985\n",
      "Iteration 25803 => Loss: 47.50129827810486915496\n",
      "Iteration 25804 => Loss: 47.50112591925581995156\n",
      "Iteration 25805 => Loss: 47.50095356175945227051\n",
      "Iteration 25806 => Loss: 47.50078120561571637381\n",
      "Iteration 25807 => Loss: 47.50060885082462647233\n",
      "Iteration 25808 => Loss: 47.50043649738616835521\n",
      "Iteration 25809 => Loss: 47.50026414530033491701\n",
      "Iteration 25810 => Loss: 47.50009179456712615774\n",
      "Iteration 25811 => Loss: 47.49991944518649233942\n",
      "Iteration 25812 => Loss: 47.49974709715846188374\n",
      "Iteration 25813 => Loss: 47.49957475048299926357\n",
      "Iteration 25814 => Loss: 47.49940240516011868976\n",
      "Iteration 25815 => Loss: 47.49923006118977042433\n",
      "Iteration 25816 => Loss: 47.49905771857198999442\n",
      "Iteration 25817 => Loss: 47.49888537730672766202\n",
      "Iteration 25818 => Loss: 47.49871303739401184885\n",
      "Iteration 25819 => Loss: 47.49854069883377860606\n",
      "Iteration 25820 => Loss: 47.49836836162608477707\n",
      "Iteration 25821 => Loss: 47.49819602577087351847\n",
      "Iteration 25822 => Loss: 47.49802369126815904110\n",
      "Iteration 25823 => Loss: 47.49785135811789160698\n",
      "Iteration 25824 => Loss: 47.49767902632009253239\n",
      "Iteration 25825 => Loss: 47.49750669587473339561\n",
      "Iteration 25826 => Loss: 47.49733436678183551294\n",
      "Iteration 25827 => Loss: 47.49716203904136335723\n",
      "Iteration 25828 => Loss: 47.49698971265329561220\n",
      "Iteration 25829 => Loss: 47.49681738761766780499\n",
      "Iteration 25830 => Loss: 47.49664506393441598675\n",
      "Iteration 25831 => Loss: 47.49647274160353305206\n",
      "Iteration 25832 => Loss: 47.49630042062505452805\n",
      "Iteration 25833 => Loss: 47.49612810099893067672\n",
      "Iteration 25834 => Loss: 47.49595578272516149809\n",
      "Iteration 25835 => Loss: 47.49578346580373988672\n",
      "Iteration 25836 => Loss: 47.49561115023465873719\n",
      "Iteration 25837 => Loss: 47.49543883601789673321\n",
      "Iteration 25838 => Loss: 47.49526652315345387478\n",
      "Iteration 25839 => Loss: 47.49509421164130174020\n",
      "Iteration 25840 => Loss: 47.49492190148143322403\n",
      "Iteration 25841 => Loss: 47.49474959267385543171\n",
      "Iteration 25842 => Loss: 47.49457728521855415238\n",
      "Iteration 25843 => Loss: 47.49440497911551517518\n",
      "Iteration 25844 => Loss: 47.49423267436471718383\n",
      "Iteration 25845 => Loss: 47.49406037096615307291\n",
      "Iteration 25846 => Loss: 47.49388806891982284242\n",
      "Iteration 25847 => Loss: 47.49371576822571938692\n",
      "Iteration 25848 => Loss: 47.49354346888379296843\n",
      "Iteration 25849 => Loss: 47.49337117089408621950\n",
      "Iteration 25850 => Loss: 47.49319887425656361302\n",
      "Iteration 25851 => Loss: 47.49302657897123225439\n",
      "Iteration 25852 => Loss: 47.49285428503804240563\n",
      "Iteration 25853 => Loss: 47.49268199245700117217\n",
      "Iteration 25854 => Loss: 47.49250970122812987029\n",
      "Iteration 25855 => Loss: 47.49233741135136455114\n",
      "Iteration 25856 => Loss: 47.49216512282672653100\n",
      "Iteration 25857 => Loss: 47.49199283565420870445\n",
      "Iteration 25858 => Loss: 47.49182054983377554436\n",
      "Iteration 25859 => Loss: 47.49164826536545547242\n",
      "Iteration 25860 => Loss: 47.49147598224919875065\n",
      "Iteration 25861 => Loss: 47.49130370048502669533\n",
      "Iteration 25862 => Loss: 47.49113142007287535762\n",
      "Iteration 25863 => Loss: 47.49095914101280158093\n",
      "Iteration 25864 => Loss: 47.49078686330476983812\n",
      "Iteration 25865 => Loss: 47.49061458694875881292\n",
      "Iteration 25866 => Loss: 47.49044231194476139990\n",
      "Iteration 25867 => Loss: 47.49027003829277049363\n",
      "Iteration 25868 => Loss: 47.49009776599277188325\n",
      "Iteration 25869 => Loss: 47.48992549504474425248\n",
      "Iteration 25870 => Loss: 47.48975322544873023389\n",
      "Iteration 25871 => Loss: 47.48958095720463035150\n",
      "Iteration 25872 => Loss: 47.48940869031250144872\n",
      "Iteration 25873 => Loss: 47.48923642477231510384\n",
      "Iteration 25874 => Loss: 47.48906416058406421143\n",
      "Iteration 25875 => Loss: 47.48889189774774166608\n",
      "Iteration 25876 => Loss: 47.48871963626330483521\n",
      "Iteration 25877 => Loss: 47.48854737613076792968\n",
      "Iteration 25878 => Loss: 47.48837511735015226577\n",
      "Iteration 25879 => Loss: 47.48820285992138678921\n",
      "Iteration 25880 => Loss: 47.48803060384450702713\n",
      "Iteration 25881 => Loss: 47.48785834911946324155\n",
      "Iteration 25882 => Loss: 47.48768609574627674874\n",
      "Iteration 25883 => Loss: 47.48751384372491912700\n",
      "Iteration 25884 => Loss: 47.48734159305540458718\n",
      "Iteration 25885 => Loss: 47.48716934373767628585\n",
      "Iteration 25886 => Loss: 47.48699709577176264474\n",
      "Iteration 25887 => Loss: 47.48682484915765655842\n",
      "Iteration 25888 => Loss: 47.48665260389531539431\n",
      "Iteration 25889 => Loss: 47.48648035998473204700\n",
      "Iteration 25890 => Loss: 47.48630811742594204361\n",
      "Iteration 25891 => Loss: 47.48613587621889564616\n",
      "Iteration 25892 => Loss: 47.48596363636358574922\n",
      "Iteration 25893 => Loss: 47.48579139785999814194\n",
      "Iteration 25894 => Loss: 47.48561916070813282431\n",
      "Iteration 25895 => Loss: 47.48544692490797558548\n",
      "Iteration 25896 => Loss: 47.48527469045950510917\n",
      "Iteration 25897 => Loss: 47.48510245736274271167\n",
      "Iteration 25898 => Loss: 47.48493022561765286582\n",
      "Iteration 25899 => Loss: 47.48475799522420714993\n",
      "Iteration 25900 => Loss: 47.48458576618244819656\n",
      "Iteration 25901 => Loss: 47.48441353849231916229\n",
      "Iteration 25902 => Loss: 47.48424131215381294169\n",
      "Iteration 25903 => Loss: 47.48406908716693664019\n",
      "Iteration 25904 => Loss: 47.48389686353167604693\n",
      "Iteration 25905 => Loss: 47.48372464124801695107\n",
      "Iteration 25906 => Loss: 47.48355242031595224717\n",
      "Iteration 25907 => Loss: 47.48338020073546772437\n",
      "Iteration 25908 => Loss: 47.48320798250655627726\n",
      "Iteration 25909 => Loss: 47.48303576562919658954\n",
      "Iteration 25910 => Loss: 47.48286355010338155580\n",
      "Iteration 25911 => Loss: 47.48269133592911117603\n",
      "Iteration 25912 => Loss: 47.48251912310639255566\n",
      "Iteration 25913 => Loss: 47.48234691163514042955\n",
      "Iteration 25914 => Loss: 47.48217470151543295742\n",
      "Iteration 25915 => Loss: 47.48200249274721329584\n",
      "Iteration 25916 => Loss: 47.48183028533046723396\n",
      "Iteration 25917 => Loss: 47.48165807926520187721\n",
      "Iteration 25918 => Loss: 47.48148587455140301472\n",
      "Iteration 25919 => Loss: 47.48131367118906354108\n",
      "Iteration 25920 => Loss: 47.48114146917816214000\n",
      "Iteration 25921 => Loss: 47.48096926851871302233\n",
      "Iteration 25922 => Loss: 47.48079706921063092295\n",
      "Iteration 25923 => Loss: 47.48062487125401531785\n",
      "Iteration 25924 => Loss: 47.48045267464877383645\n",
      "Iteration 25925 => Loss: 47.48028047939492779506\n",
      "Iteration 25926 => Loss: 47.48010828549246298280\n",
      "Iteration 25927 => Loss: 47.47993609294137229426\n",
      "Iteration 25928 => Loss: 47.47976390174162020230\n",
      "Iteration 25929 => Loss: 47.47959171189323512863\n",
      "Iteration 25930 => Loss: 47.47941952339616733525\n",
      "Iteration 25931 => Loss: 47.47924733625043813845\n",
      "Iteration 25932 => Loss: 47.47907515045602622195\n",
      "Iteration 25933 => Loss: 47.47890296601292448031\n",
      "Iteration 25934 => Loss: 47.47873078292109028098\n",
      "Iteration 25935 => Loss: 47.47855860118056625652\n",
      "Iteration 25936 => Loss: 47.47838642079131687979\n",
      "Iteration 25937 => Loss: 47.47821424175332083450\n",
      "Iteration 25938 => Loss: 47.47804206406657812067\n",
      "Iteration 25939 => Loss: 47.47786988773108873829\n",
      "Iteration 25940 => Loss: 47.47769771274681716022\n",
      "Iteration 25941 => Loss: 47.47752553911375628104\n",
      "Iteration 25942 => Loss: 47.47735336683192741702\n",
      "Iteration 25943 => Loss: 47.47718119590127372476\n",
      "Iteration 25944 => Loss: 47.47700902632183073138\n",
      "Iteration 25945 => Loss: 47.47683685809355580432\n",
      "Iteration 25946 => Loss: 47.47666469121642762730\n",
      "Iteration 25947 => Loss: 47.47649252569048883288\n",
      "Iteration 25948 => Loss: 47.47632036151568968307\n",
      "Iteration 25949 => Loss: 47.47614819869200886160\n",
      "Iteration 25950 => Loss: 47.47597603721946768474\n",
      "Iteration 25951 => Loss: 47.47580387709802351992\n",
      "Iteration 25952 => Loss: 47.47563171832771189429\n",
      "Iteration 25953 => Loss: 47.47545956090847596442\n",
      "Iteration 25954 => Loss: 47.47528740484030862490\n",
      "Iteration 25955 => Loss: 47.47511525012323829742\n",
      "Iteration 25956 => Loss: 47.47494309675720813857\n",
      "Iteration 25957 => Loss: 47.47477094474224657006\n",
      "Iteration 25958 => Loss: 47.47459879407831806475\n",
      "Iteration 25959 => Loss: 47.47442664476540841179\n",
      "Iteration 25960 => Loss: 47.47425449680354603288\n",
      "Iteration 25961 => Loss: 47.47408235019265987376\n",
      "Iteration 25962 => Loss: 47.47391020493277835612\n",
      "Iteration 25963 => Loss: 47.47373806102390147998\n",
      "Iteration 25964 => Loss: 47.47356591846599371820\n",
      "Iteration 25965 => Loss: 47.47339377725905507077\n",
      "Iteration 25966 => Loss: 47.47322163740305711599\n",
      "Iteration 25967 => Loss: 47.47304949889801406471\n",
      "Iteration 25968 => Loss: 47.47287736174389038979\n",
      "Iteration 25969 => Loss: 47.47270522594070030209\n",
      "Iteration 25970 => Loss: 47.47253309148842248533\n",
      "Iteration 25971 => Loss: 47.47236095838704983407\n",
      "Iteration 25972 => Loss: 47.47218882663656813747\n",
      "Iteration 25973 => Loss: 47.47201669623697029010\n",
      "Iteration 25974 => Loss: 47.47184456718824208110\n",
      "Iteration 25975 => Loss: 47.47167243949036219419\n",
      "Iteration 25976 => Loss: 47.47150031314333062937\n",
      "Iteration 25977 => Loss: 47.47132818814716159750\n",
      "Iteration 25978 => Loss: 47.47115606450179825515\n",
      "Iteration 25979 => Loss: 47.47098394220725481318\n",
      "Iteration 25980 => Loss: 47.47081182126351706074\n",
      "Iteration 25981 => Loss: 47.47063970167057789240\n",
      "Iteration 25982 => Loss: 47.47046758342843020273\n",
      "Iteration 25983 => Loss: 47.47029546653705978088\n",
      "Iteration 25984 => Loss: 47.47012335099645952141\n",
      "Iteration 25985 => Loss: 47.46995123680659389720\n",
      "Iteration 25986 => Loss: 47.46977912396747001367\n",
      "Iteration 25987 => Loss: 47.46960701247909497624\n",
      "Iteration 25988 => Loss: 47.46943490234142615236\n",
      "Iteration 25989 => Loss: 47.46926279355449196373\n",
      "Iteration 25990 => Loss: 47.46909068611823556694\n",
      "Iteration 25991 => Loss: 47.46891858003267827826\n",
      "Iteration 25992 => Loss: 47.46874647529779167598\n",
      "Iteration 25993 => Loss: 47.46857437191357576012\n",
      "Iteration 25994 => Loss: 47.46840226988004474151\n",
      "Iteration 25995 => Loss: 47.46823016919713467132\n",
      "Iteration 25996 => Loss: 47.46805806986486686583\n",
      "Iteration 25997 => Loss: 47.46788597188322711418\n",
      "Iteration 25998 => Loss: 47.46771387525220120551\n",
      "Iteration 25999 => Loss: 47.46754177997177492898\n",
      "Iteration 26000 => Loss: 47.46736968604194828458\n",
      "Iteration 26001 => Loss: 47.46719759346271416689\n",
      "Iteration 26002 => Loss: 47.46702550223405836505\n",
      "Iteration 26003 => Loss: 47.46685341235594535192\n",
      "Iteration 26004 => Loss: 47.46668132382841065464\n",
      "Iteration 26005 => Loss: 47.46650923665137611351\n",
      "Iteration 26006 => Loss: 47.46633715082490567738\n",
      "Iteration 26007 => Loss: 47.46616506634893539740\n",
      "Iteration 26008 => Loss: 47.46599298322348658985\n",
      "Iteration 26009 => Loss: 47.46582090144853793845\n",
      "Iteration 26010 => Loss: 47.46564882102408233777\n",
      "Iteration 26011 => Loss: 47.46547674195010557696\n",
      "Iteration 26012 => Loss: 47.46530466422657923431\n",
      "Iteration 26013 => Loss: 47.46513258785351752067\n",
      "Iteration 26014 => Loss: 47.46496051283092043604\n",
      "Iteration 26015 => Loss: 47.46478843915872403159\n",
      "Iteration 26016 => Loss: 47.46461636683698515071\n",
      "Iteration 26017 => Loss: 47.46444429586564695001\n",
      "Iteration 26018 => Loss: 47.46427222624472364032\n",
      "Iteration 26019 => Loss: 47.46410015797415837824\n",
      "Iteration 26020 => Loss: 47.46392809105400090175\n",
      "Iteration 26021 => Loss: 47.46375602548422278915\n",
      "Iteration 26022 => Loss: 47.46358396126480982957\n",
      "Iteration 26023 => Loss: 47.46341189839574070675\n",
      "Iteration 26024 => Loss: 47.46323983687699410439\n",
      "Iteration 26025 => Loss: 47.46306777670859844420\n",
      "Iteration 26026 => Loss: 47.46289571789051109363\n",
      "Iteration 26027 => Loss: 47.46272366042274626352\n",
      "Iteration 26028 => Loss: 47.46255160430526132131\n",
      "Iteration 26029 => Loss: 47.46237954953807758329\n",
      "Iteration 26030 => Loss: 47.46220749612118083860\n",
      "Iteration 26031 => Loss: 47.46203544405451424382\n",
      "Iteration 26032 => Loss: 47.46186339333811332608\n",
      "Iteration 26033 => Loss: 47.46169134397197808539\n",
      "Iteration 26034 => Loss: 47.46151929595605878376\n",
      "Iteration 26035 => Loss: 47.46134724929037673746\n",
      "Iteration 26036 => Loss: 47.46117520397491063022\n",
      "Iteration 26037 => Loss: 47.46100316000963914576\n",
      "Iteration 26038 => Loss: 47.46083111739453386235\n",
      "Iteration 26039 => Loss: 47.46065907612966583429\n",
      "Iteration 26040 => Loss: 47.46048703621492137472\n",
      "Iteration 26041 => Loss: 47.46031499765035732707\n",
      "Iteration 26042 => Loss: 47.46014296043594526964\n",
      "Iteration 26043 => Loss: 47.45997092457166388613\n",
      "Iteration 26044 => Loss: 47.45979889005752028197\n",
      "Iteration 26045 => Loss: 47.45962685689347182461\n",
      "Iteration 26046 => Loss: 47.45945482507956114659\n",
      "Iteration 26047 => Loss: 47.45928279461572429909\n",
      "Iteration 26048 => Loss: 47.45911076550197549295\n",
      "Iteration 26049 => Loss: 47.45893873773830762275\n",
      "Iteration 26050 => Loss: 47.45876671132472068848\n",
      "Iteration 26051 => Loss: 47.45859468626116495216\n",
      "Iteration 26052 => Loss: 47.45842266254764751920\n",
      "Iteration 26053 => Loss: 47.45825064018418970591\n",
      "Iteration 26054 => Loss: 47.45807861917073466884\n",
      "Iteration 26055 => Loss: 47.45790659950729661887\n",
      "Iteration 26056 => Loss: 47.45773458119386845055\n",
      "Iteration 26057 => Loss: 47.45756256423040753134\n",
      "Iteration 26058 => Loss: 47.45739054861694228293\n",
      "Iteration 26059 => Loss: 47.45721853435346559991\n",
      "Iteration 26060 => Loss: 47.45704652143990642799\n",
      "Iteration 26061 => Loss: 47.45687450987633582145\n",
      "Iteration 26062 => Loss: 47.45670249966267562058\n",
      "Iteration 26063 => Loss: 47.45653049079896845797\n",
      "Iteration 26064 => Loss: 47.45635848328514327932\n",
      "Iteration 26065 => Loss: 47.45618647712123561178\n",
      "Iteration 26066 => Loss: 47.45601447230724545534\n",
      "Iteration 26067 => Loss: 47.45584246884313017745\n",
      "Iteration 26068 => Loss: 47.45567046672886135639\n",
      "Iteration 26069 => Loss: 47.45549846596448873015\n",
      "Iteration 26070 => Loss: 47.45532646654996256075\n",
      "Iteration 26071 => Loss: 47.45515446848526153190\n",
      "Iteration 26072 => Loss: 47.45498247177041406530\n",
      "Iteration 26073 => Loss: 47.45481047640537042298\n",
      "Iteration 26074 => Loss: 47.45463848239014481578\n",
      "Iteration 26075 => Loss: 47.45446648972471592742\n",
      "Iteration 26076 => Loss: 47.45429449840909086333\n",
      "Iteration 26077 => Loss: 47.45412250844324120180\n",
      "Iteration 26078 => Loss: 47.45395051982713852112\n",
      "Iteration 26079 => Loss: 47.45377853256080413757\n",
      "Iteration 26080 => Loss: 47.45360654664423094573\n",
      "Iteration 26081 => Loss: 47.45343456207737631303\n",
      "Iteration 26082 => Loss: 47.45326257886026155575\n",
      "Iteration 26083 => Loss: 47.45309059699284404132\n",
      "Iteration 26084 => Loss: 47.45291861647513798061\n",
      "Iteration 26085 => Loss: 47.45274663730712916276\n",
      "Iteration 26086 => Loss: 47.45257465948879627149\n",
      "Iteration 26087 => Loss: 47.45240268302014641222\n",
      "Iteration 26088 => Loss: 47.45223070790115826867\n",
      "Iteration 26089 => Loss: 47.45205873413183894627\n",
      "Iteration 26090 => Loss: 47.45188676171213160160\n",
      "Iteration 26091 => Loss: 47.45171479064208597265\n",
      "Iteration 26092 => Loss: 47.45154282092162389972\n",
      "Iteration 26093 => Loss: 47.45137085255078801538\n",
      "Iteration 26094 => Loss: 47.45119888552954989791\n",
      "Iteration 26095 => Loss: 47.45102691985788112561\n",
      "Iteration 26096 => Loss: 47.45085495553581722561\n",
      "Iteration 26097 => Loss: 47.45068299256331556535\n",
      "Iteration 26098 => Loss: 47.45051103094036903940\n",
      "Iteration 26099 => Loss: 47.45033907066696343691\n",
      "Iteration 26100 => Loss: 47.45016711174309875787\n",
      "Iteration 26101 => Loss: 47.44999515416874658058\n",
      "Iteration 26102 => Loss: 47.44982319794392822132\n",
      "Iteration 26103 => Loss: 47.44965124306860104753\n",
      "Iteration 26104 => Loss: 47.44947928954275795377\n",
      "Iteration 26105 => Loss: 47.44930733736640604548\n",
      "Iteration 26106 => Loss: 47.44913538653951690094\n",
      "Iteration 26107 => Loss: 47.44896343706211894187\n",
      "Iteration 26108 => Loss: 47.44879148893414821941\n",
      "Iteration 26109 => Loss: 47.44861954215559762815\n",
      "Iteration 26110 => Loss: 47.44844759672649558979\n",
      "Iteration 26111 => Loss: 47.44827565264682789348\n",
      "Iteration 26112 => Loss: 47.44810370991656611750\n",
      "Iteration 26113 => Loss: 47.44793176853568184015\n",
      "Iteration 26114 => Loss: 47.44775982850418927228\n",
      "Iteration 26115 => Loss: 47.44758788982209551932\n",
      "Iteration 26116 => Loss: 47.44741595248931531614\n",
      "Iteration 26117 => Loss: 47.44724401650593392787\n",
      "Iteration 26118 => Loss: 47.44707208187189451110\n",
      "Iteration 26119 => Loss: 47.44690014858719706581\n",
      "Iteration 26120 => Loss: 47.44672821665179895945\n",
      "Iteration 26121 => Loss: 47.44655628606572861372\n",
      "Iteration 26122 => Loss: 47.44638435682895050149\n",
      "Iteration 26123 => Loss: 47.44621242894145041191\n",
      "Iteration 26124 => Loss: 47.44604050240324966126\n",
      "Iteration 26125 => Loss: 47.44586857721433403867\n",
      "Iteration 26126 => Loss: 47.44569665337464670074\n",
      "Iteration 26127 => Loss: 47.44552473088423738545\n",
      "Iteration 26128 => Loss: 47.44535280974304924939\n",
      "Iteration 26129 => Loss: 47.44518088995109650341\n",
      "Iteration 26130 => Loss: 47.44500897150834362037\n",
      "Iteration 26131 => Loss: 47.44483705441481902199\n",
      "Iteration 26132 => Loss: 47.44466513867048718112\n",
      "Iteration 26133 => Loss: 47.44449322427534099234\n",
      "Iteration 26134 => Loss: 47.44432131122936624479\n",
      "Iteration 26135 => Loss: 47.44414939953254872762\n",
      "Iteration 26136 => Loss: 47.44397748918490975711\n",
      "Iteration 26137 => Loss: 47.44380558018638538442\n",
      "Iteration 26138 => Loss: 47.44363367253701113668\n",
      "Iteration 26139 => Loss: 47.44346176623675148676\n",
      "Iteration 26140 => Loss: 47.44328986128560643465\n",
      "Iteration 26141 => Loss: 47.44311795768354755864\n",
      "Iteration 26142 => Loss: 47.44294605543060328046\n",
      "Iteration 26143 => Loss: 47.44277415452673096752\n",
      "Iteration 26144 => Loss: 47.44260225497191640898\n",
      "Iteration 26145 => Loss: 47.44243035676618092111\n",
      "Iteration 26146 => Loss: 47.44225845990947476594\n",
      "Iteration 26147 => Loss: 47.44208656440181925973\n",
      "Iteration 26148 => Loss: 47.44191467024317176993\n",
      "Iteration 26149 => Loss: 47.44174277743357492909\n",
      "Iteration 26150 => Loss: 47.44157088597294347210\n",
      "Iteration 26151 => Loss: 47.44139899586134134779\n",
      "Iteration 26152 => Loss: 47.44122710709869750190\n",
      "Iteration 26153 => Loss: 47.44105521968503325070\n",
      "Iteration 26154 => Loss: 47.44088333362035569962\n",
      "Iteration 26155 => Loss: 47.44071144890460089982\n",
      "Iteration 26156 => Loss: 47.44053956553779016758\n",
      "Iteration 26157 => Loss: 47.44036768351992350290\n",
      "Iteration 26158 => Loss: 47.44019580285097248407\n",
      "Iteration 26159 => Loss: 47.44002392353095132194\n",
      "Iteration 26160 => Loss: 47.43985204555980317309\n",
      "Iteration 26161 => Loss: 47.43968016893754224839\n",
      "Iteration 26162 => Loss: 47.43950829366418275868\n",
      "Iteration 26163 => Loss: 47.43933641973968917682\n",
      "Iteration 26164 => Loss: 47.43916454716404729197\n",
      "Iteration 26165 => Loss: 47.43899267593724289327\n",
      "Iteration 26166 => Loss: 47.43882080605929019157\n",
      "Iteration 26167 => Loss: 47.43864893753017497602\n",
      "Iteration 26168 => Loss: 47.43847707034984750862\n",
      "Iteration 26169 => Loss: 47.43830520451831489481\n",
      "Iteration 26170 => Loss: 47.43813334003559845087\n",
      "Iteration 26171 => Loss: 47.43796147690165554422\n",
      "Iteration 26172 => Loss: 47.43778961511649328031\n",
      "Iteration 26173 => Loss: 47.43761775468009034284\n",
      "Iteration 26174 => Loss: 47.43744589559244673183\n",
      "Iteration 26175 => Loss: 47.43727403785352692012\n",
      "Iteration 26176 => Loss: 47.43710218146335222400\n",
      "Iteration 26177 => Loss: 47.43693032642189422177\n",
      "Iteration 26178 => Loss: 47.43675847272913870256\n",
      "Iteration 26179 => Loss: 47.43658662038509277181\n",
      "Iteration 26180 => Loss: 47.43641476938972090238\n",
      "Iteration 26181 => Loss: 47.43624291974304441055\n",
      "Iteration 26182 => Loss: 47.43607107144502066376\n",
      "Iteration 26183 => Loss: 47.43589922449567097829\n",
      "Iteration 26184 => Loss: 47.43572737889493851071\n",
      "Iteration 26185 => Loss: 47.43555553464286589360\n",
      "Iteration 26186 => Loss: 47.43538369173939628354\n",
      "Iteration 26187 => Loss: 47.43521185018455810223\n",
      "Iteration 26188 => Loss: 47.43504000997830871711\n",
      "Iteration 26189 => Loss: 47.43486817112066944446\n",
      "Iteration 26190 => Loss: 47.43469633361160475715\n",
      "Iteration 26191 => Loss: 47.43452449745111465518\n",
      "Iteration 26192 => Loss: 47.43435266263919913854\n",
      "Iteration 26193 => Loss: 47.43418082917580846924\n",
      "Iteration 26194 => Loss: 47.43400899706095685815\n",
      "Iteration 26195 => Loss: 47.43383716629465141068\n",
      "Iteration 26196 => Loss: 47.43366533687685659970\n",
      "Iteration 26197 => Loss: 47.43349350880757242521\n",
      "Iteration 26198 => Loss: 47.43332168208677046550\n",
      "Iteration 26199 => Loss: 47.43314985671449335314\n",
      "Iteration 26200 => Loss: 47.43297803269067003384\n",
      "Iteration 26201 => Loss: 47.43280621001530050762\n",
      "Iteration 26202 => Loss: 47.43263438868841319618\n",
      "Iteration 26203 => Loss: 47.43246256870995125610\n",
      "Iteration 26204 => Loss: 47.43229075007992179280\n",
      "Iteration 26205 => Loss: 47.43211893279832480630\n",
      "Iteration 26206 => Loss: 47.43194711686515319116\n",
      "Iteration 26207 => Loss: 47.43177530228036431481\n",
      "Iteration 26208 => Loss: 47.43160348904395817726\n",
      "Iteration 26209 => Loss: 47.43143167715594898937\n",
      "Iteration 26210 => Loss: 47.43125986661630832941\n",
      "Iteration 26211 => Loss: 47.43108805742503619740\n",
      "Iteration 26212 => Loss: 47.43091624958209706620\n",
      "Iteration 26213 => Loss: 47.43074444308749804122\n",
      "Iteration 26214 => Loss: 47.43057263794123912248\n",
      "Iteration 26215 => Loss: 47.43040083414329188827\n",
      "Iteration 26216 => Loss: 47.43022903169365633858\n",
      "Iteration 26217 => Loss: 47.43005723059231826255\n",
      "Iteration 26218 => Loss: 47.42988543083925634392\n",
      "Iteration 26219 => Loss: 47.42971363243447768809\n",
      "Iteration 26220 => Loss: 47.42954183537794676795\n",
      "Iteration 26221 => Loss: 47.42937003966969911062\n",
      "Iteration 26222 => Loss: 47.42919824530967787268\n",
      "Iteration 26223 => Loss: 47.42902645229789015957\n",
      "Iteration 26224 => Loss: 47.42885466063432176043\n",
      "Iteration 26225 => Loss: 47.42868287031898688610\n",
      "Iteration 26226 => Loss: 47.42851108135182158776\n",
      "Iteration 26227 => Loss: 47.42833929373286849795\n",
      "Iteration 26228 => Loss: 47.42816750746209919498\n",
      "Iteration 26229 => Loss: 47.42799572253948525713\n",
      "Iteration 26230 => Loss: 47.42782393896502668440\n",
      "Iteration 26231 => Loss: 47.42765215673872347679\n",
      "Iteration 26232 => Loss: 47.42748037586057563431\n",
      "Iteration 26233 => Loss: 47.42730859633052631352\n",
      "Iteration 26234 => Loss: 47.42713681814861104158\n",
      "Iteration 26235 => Loss: 47.42696504131479429134\n",
      "Iteration 26236 => Loss: 47.42679326582908316823\n",
      "Iteration 26237 => Loss: 47.42662149169144925054\n",
      "Iteration 26238 => Loss: 47.42644971890189964370\n",
      "Iteration 26239 => Loss: 47.42627794746039882057\n",
      "Iteration 26240 => Loss: 47.42610617736696099200\n",
      "Iteration 26241 => Loss: 47.42593440862155773630\n",
      "Iteration 26242 => Loss: 47.42576264122419615887\n",
      "Iteration 26243 => Loss: 47.42559087517483362717\n",
      "Iteration 26244 => Loss: 47.42541911047349856290\n",
      "Iteration 26245 => Loss: 47.42524734712019096605\n",
      "Iteration 26246 => Loss: 47.42507558511483267694\n",
      "Iteration 26247 => Loss: 47.42490382445746632811\n",
      "Iteration 26248 => Loss: 47.42473206514807060330\n",
      "Iteration 26249 => Loss: 47.42456030718663839707\n",
      "Iteration 26250 => Loss: 47.42438855057313418229\n",
      "Iteration 26251 => Loss: 47.42421679530758638066\n",
      "Iteration 26252 => Loss: 47.42404504138994525420\n",
      "Iteration 26253 => Loss: 47.42387328882023922461\n",
      "Iteration 26254 => Loss: 47.42370153759843276475\n",
      "Iteration 26255 => Loss: 47.42352978772454008549\n",
      "Iteration 26256 => Loss: 47.42335803919849723798\n",
      "Iteration 26257 => Loss: 47.42318629202034685477\n",
      "Iteration 26258 => Loss: 47.42301454619004630331\n",
      "Iteration 26259 => Loss: 47.42284280170760979445\n",
      "Iteration 26260 => Loss: 47.42267105857303022276\n",
      "Iteration 26261 => Loss: 47.42249931678625074483\n",
      "Iteration 26262 => Loss: 47.42232757634729978236\n",
      "Iteration 26263 => Loss: 47.42215583725615601907\n",
      "Iteration 26264 => Loss: 47.42198409951282656039\n",
      "Iteration 26265 => Loss: 47.42181236311727587918\n",
      "Iteration 26266 => Loss: 47.42164062806949687001\n",
      "Iteration 26267 => Loss: 47.42146889436948242746\n",
      "Iteration 26268 => Loss: 47.42129716201723965696\n",
      "Iteration 26269 => Loss: 47.42112543101274724222\n",
      "Iteration 26270 => Loss: 47.42095370135598386696\n",
      "Iteration 26271 => Loss: 47.42078197304693532033\n",
      "Iteration 26272 => Loss: 47.42061024608563002403\n",
      "Iteration 26273 => Loss: 47.42043852047200402922\n",
      "Iteration 26274 => Loss: 47.42026679620607865218\n",
      "Iteration 26275 => Loss: 47.42009507328783968205\n",
      "Iteration 26276 => Loss: 47.41992335171725869714\n",
      "Iteration 26277 => Loss: 47.41975163149436411913\n",
      "Iteration 26278 => Loss: 47.41957991261909910463\n",
      "Iteration 26279 => Loss: 47.41940819509147075905\n",
      "Iteration 26280 => Loss: 47.41923647891149329325\n",
      "Iteration 26281 => Loss: 47.41906476407912407467\n",
      "Iteration 26282 => Loss: 47.41889305059436310330\n",
      "Iteration 26283 => Loss: 47.41872133845720327372\n",
      "Iteration 26284 => Loss: 47.41854962766763748050\n",
      "Iteration 26285 => Loss: 47.41837791822563730193\n",
      "Iteration 26286 => Loss: 47.41820621013118852716\n",
      "Iteration 26287 => Loss: 47.41803450338434089417\n",
      "Iteration 26288 => Loss: 47.41786279798500203242\n",
      "Iteration 26289 => Loss: 47.41769109393320746904\n",
      "Iteration 26290 => Loss: 47.41751939122895009859\n",
      "Iteration 26291 => Loss: 47.41734768987219439396\n",
      "Iteration 26292 => Loss: 47.41717598986294035512\n",
      "Iteration 26293 => Loss: 47.41700429120117377124\n",
      "Iteration 26294 => Loss: 47.41683259388690174774\n",
      "Iteration 26295 => Loss: 47.41666089792011717918\n",
      "Iteration 26296 => Loss: 47.41648920330075611673\n",
      "Iteration 26297 => Loss: 47.41631751002886829838\n",
      "Iteration 26298 => Loss: 47.41614581810441109155\n",
      "Iteration 26299 => Loss: 47.41597412752737739083\n",
      "Iteration 26300 => Loss: 47.41580243829779561793\n",
      "Iteration 26301 => Loss: 47.41563075041557340228\n",
      "Iteration 26302 => Loss: 47.41545906388079600902\n",
      "Iteration 26303 => Loss: 47.41528737869337106758\n",
      "Iteration 26304 => Loss: 47.41511569485333410512\n",
      "Iteration 26305 => Loss: 47.41494401236067801619\n",
      "Iteration 26306 => Loss: 47.41477233121535306282\n",
      "Iteration 26307 => Loss: 47.41460065141736635042\n",
      "Iteration 26308 => Loss: 47.41442897296673208984\n",
      "Iteration 26309 => Loss: 47.41425729586342896482\n",
      "Iteration 26310 => Loss: 47.41408562010741434278\n",
      "Iteration 26311 => Loss: 47.41391394569873085629\n",
      "Iteration 26312 => Loss: 47.41374227263732876736\n",
      "Iteration 26313 => Loss: 47.41357060092320807598\n",
      "Iteration 26314 => Loss: 47.41339893055634036045\n",
      "Iteration 26315 => Loss: 47.41322726153674693705\n",
      "Iteration 26316 => Loss: 47.41305559386440648950\n",
      "Iteration 26317 => Loss: 47.41288392753928349066\n",
      "Iteration 26318 => Loss: 47.41271226256141346767\n",
      "Iteration 26319 => Loss: 47.41254059893075378795\n",
      "Iteration 26320 => Loss: 47.41236893664729024067\n",
      "Iteration 26321 => Loss: 47.41219727571104414210\n",
      "Iteration 26322 => Loss: 47.41202561612197285967\n",
      "Iteration 26323 => Loss: 47.41185395788009770968\n",
      "Iteration 26324 => Loss: 47.41168230098534053241\n",
      "Iteration 26325 => Loss: 47.41151064543775817128\n",
      "Iteration 26326 => Loss: 47.41133899123732220460\n",
      "Iteration 26327 => Loss: 47.41116733838403263235\n",
      "Iteration 26328 => Loss: 47.41099568687784682197\n",
      "Iteration 26329 => Loss: 47.41082403671880030060\n",
      "Iteration 26330 => Loss: 47.41065238790681490855\n",
      "Iteration 26331 => Loss: 47.41048074044194748922\n",
      "Iteration 26332 => Loss: 47.41030909432414830462\n",
      "Iteration 26333 => Loss: 47.41013744955343867105\n",
      "Iteration 26334 => Loss: 47.40996580612976885050\n",
      "Iteration 26335 => Loss: 47.40979416405315305383\n",
      "Iteration 26336 => Loss: 47.40962252332356996476\n",
      "Iteration 26337 => Loss: 47.40945088394101958329\n",
      "Iteration 26338 => Loss: 47.40927924590549480399\n",
      "Iteration 26339 => Loss: 47.40910760921694588887\n",
      "Iteration 26340 => Loss: 47.40893597387542257593\n",
      "Iteration 26341 => Loss: 47.40876433988088223259\n",
      "Iteration 26342 => Loss: 47.40859270723330354258\n",
      "Iteration 26343 => Loss: 47.40842107593270782218\n",
      "Iteration 26344 => Loss: 47.40824944597903822796\n",
      "Iteration 26345 => Loss: 47.40807781737232318164\n",
      "Iteration 26346 => Loss: 47.40790619011254847237\n",
      "Iteration 26347 => Loss: 47.40773456419968567843\n",
      "Iteration 26348 => Loss: 47.40756293963375611611\n",
      "Iteration 26349 => Loss: 47.40739131641471715284\n",
      "Iteration 26350 => Loss: 47.40721969454256168319\n",
      "Iteration 26351 => Loss: 47.40704807401726128546\n",
      "Iteration 26352 => Loss: 47.40687645483885859221\n",
      "Iteration 26353 => Loss: 47.40670483700731097088\n",
      "Iteration 26354 => Loss: 47.40653322052262552688\n",
      "Iteration 26355 => Loss: 47.40636160538473831139\n",
      "Iteration 26356 => Loss: 47.40618999159371327323\n",
      "Iteration 26357 => Loss: 47.40601837914949356900\n",
      "Iteration 26358 => Loss: 47.40584676805207209327\n",
      "Iteration 26359 => Loss: 47.40567515830145595146\n",
      "Iteration 26360 => Loss: 47.40550354989760251101\n",
      "Iteration 26361 => Loss: 47.40533194284054729906\n",
      "Iteration 26362 => Loss: 47.40516033713024057761\n",
      "Iteration 26363 => Loss: 47.40498873276669655752\n",
      "Iteration 26364 => Loss: 47.40481712974988681708\n",
      "Iteration 26365 => Loss: 47.40464552807980425086\n",
      "Iteration 26366 => Loss: 47.40447392775646306973\n",
      "Iteration 26367 => Loss: 47.40430232877982774653\n",
      "Iteration 26368 => Loss: 47.40413073114986985956\n",
      "Iteration 26369 => Loss: 47.40395913486660361968\n",
      "Iteration 26370 => Loss: 47.40378753993004323775\n",
      "Iteration 26371 => Loss: 47.40361594634013187033\n",
      "Iteration 26372 => Loss: 47.40344435409687662286\n",
      "Iteration 26373 => Loss: 47.40327276320028460077\n",
      "Iteration 26374 => Loss: 47.40310117365032027692\n",
      "Iteration 26375 => Loss: 47.40292958544696233503\n",
      "Iteration 26376 => Loss: 47.40275799859024630223\n",
      "Iteration 26377 => Loss: 47.40258641308011533511\n",
      "Iteration 26378 => Loss: 47.40241482891660496080\n",
      "Iteration 26379 => Loss: 47.40224324609965123045\n",
      "Iteration 26380 => Loss: 47.40207166462927546036\n",
      "Iteration 26381 => Loss: 47.40190008450547765051\n",
      "Iteration 26382 => Loss: 47.40172850572820095749\n",
      "Iteration 26383 => Loss: 47.40155692829748801387\n",
      "Iteration 26384 => Loss: 47.40138535221331750336\n",
      "Iteration 26385 => Loss: 47.40121377747564679339\n",
      "Iteration 26386 => Loss: 47.40104220408448298940\n",
      "Iteration 26387 => Loss: 47.40087063203983319681\n",
      "Iteration 26388 => Loss: 47.40069906134164767764\n",
      "Iteration 26389 => Loss: 47.40052749198997616986\n",
      "Iteration 26390 => Loss: 47.40035592398475472464\n",
      "Iteration 26391 => Loss: 47.40018435732597623655\n",
      "Iteration 26392 => Loss: 47.40001279201365491645\n",
      "Iteration 26393 => Loss: 47.39984122804775523718\n",
      "Iteration 26394 => Loss: 47.39966966542829851505\n",
      "Iteration 26395 => Loss: 47.39949810415527053920\n",
      "Iteration 26396 => Loss: 47.39932654422861446619\n",
      "Iteration 26397 => Loss: 47.39915498564837292861\n",
      "Iteration 26398 => Loss: 47.39898342841450329388\n",
      "Iteration 26399 => Loss: 47.39881187252699845658\n",
      "Iteration 26400 => Loss: 47.39864031798588683841\n",
      "Iteration 26401 => Loss: 47.39846876479110449054\n",
      "Iteration 26402 => Loss: 47.39829721294264430753\n",
      "Iteration 26403 => Loss: 47.39812566244054181652\n",
      "Iteration 26404 => Loss: 47.39795411328474727952\n",
      "Iteration 26405 => Loss: 47.39778256547527490739\n",
      "Iteration 26406 => Loss: 47.39761101901207496212\n",
      "Iteration 26407 => Loss: 47.39743947389517586544\n",
      "Iteration 26408 => Loss: 47.39726793012455630105\n",
      "Iteration 26409 => Loss: 47.39709638770020205811\n",
      "Iteration 26410 => Loss: 47.39692484662211313662\n",
      "Iteration 26411 => Loss: 47.39675330689026111486\n",
      "Iteration 26412 => Loss: 47.39658176850465309826\n",
      "Iteration 26413 => Loss: 47.39641023146525355969\n",
      "Iteration 26414 => Loss: 47.39623869577206249915\n",
      "Iteration 26415 => Loss: 47.39606716142507281120\n",
      "Iteration 26416 => Loss: 47.39589562842429870670\n",
      "Iteration 26417 => Loss: 47.39572409676969755310\n",
      "Iteration 26418 => Loss: 47.39555256646127645581\n",
      "Iteration 26419 => Loss: 47.39538103749899988770\n",
      "Iteration 26420 => Loss: 47.39520950988288205963\n",
      "Iteration 26421 => Loss: 47.39503798361288744445\n",
      "Iteration 26422 => Loss: 47.39486645868905156931\n",
      "Iteration 26423 => Loss: 47.39469493511132469621\n",
      "Iteration 26424 => Loss: 47.39452341287968550887\n",
      "Iteration 26425 => Loss: 47.39435189199416242900\n",
      "Iteration 26426 => Loss: 47.39418037245471992946\n",
      "Iteration 26427 => Loss: 47.39400885426135090484\n",
      "Iteration 26428 => Loss: 47.39383733741407667139\n",
      "Iteration 26429 => Loss: 47.39366582191281906944\n",
      "Iteration 26430 => Loss: 47.39349430775762073154\n",
      "Iteration 26431 => Loss: 47.39332279494844613055\n",
      "Iteration 26432 => Loss: 47.39315128348531658276\n",
      "Iteration 26433 => Loss: 47.39297977336818945560\n",
      "Iteration 26434 => Loss: 47.39280826459706474907\n",
      "Iteration 26435 => Loss: 47.39263675717193535775\n",
      "Iteration 26436 => Loss: 47.39246525109277285992\n",
      "Iteration 26437 => Loss: 47.39229374635958436102\n",
      "Iteration 26438 => Loss: 47.39212224297234854475\n",
      "Iteration 26439 => Loss: 47.39195074093110093827\n",
      "Iteration 26440 => Loss: 47.39177924023577048729\n",
      "Iteration 26441 => Loss: 47.39160774088635719181\n",
      "Iteration 26442 => Loss: 47.39143624288288236812\n",
      "Iteration 26443 => Loss: 47.39126474622528917280\n",
      "Iteration 26444 => Loss: 47.39109325091362023841\n",
      "Iteration 26445 => Loss: 47.39092175694780451067\n",
      "Iteration 26446 => Loss: 47.39075026432789172759\n",
      "Iteration 26447 => Loss: 47.39057877305383215116\n",
      "Iteration 26448 => Loss: 47.39040728312563999225\n",
      "Iteration 26449 => Loss: 47.39023579454327261828\n",
      "Iteration 26450 => Loss: 47.39006430730675134555\n",
      "Iteration 26451 => Loss: 47.38989282141605485776\n",
      "Iteration 26452 => Loss: 47.38972133687115473322\n",
      "Iteration 26453 => Loss: 47.38954985367206518276\n",
      "Iteration 26454 => Loss: 47.38937837181878620640\n",
      "Iteration 26455 => Loss: 47.38920689131126096072\n",
      "Iteration 26456 => Loss: 47.38903541214951076199\n",
      "Iteration 26457 => Loss: 47.38886393433352139937\n",
      "Iteration 26458 => Loss: 47.38869245786327866199\n",
      "Iteration 26459 => Loss: 47.38852098273878254986\n",
      "Iteration 26460 => Loss: 47.38834950896001885212\n",
      "Iteration 26461 => Loss: 47.38817803652696625250\n",
      "Iteration 26462 => Loss: 47.38800656543961764555\n",
      "Iteration 26463 => Loss: 47.38783509569795171501\n",
      "Iteration 26464 => Loss: 47.38766362730199688258\n",
      "Iteration 26465 => Loss: 47.38749216025168209399\n",
      "Iteration 26466 => Loss: 47.38732069454707129808\n",
      "Iteration 26467 => Loss: 47.38714923018810054600\n",
      "Iteration 26468 => Loss: 47.38697776717476273234\n",
      "Iteration 26469 => Loss: 47.38680630550707206794\n",
      "Iteration 26470 => Loss: 47.38663484518498592024\n",
      "Iteration 26471 => Loss: 47.38646338620854692181\n",
      "Iteration 26472 => Loss: 47.38629192857766980751\n",
      "Iteration 26473 => Loss: 47.38612047229241142077\n",
      "Iteration 26474 => Loss: 47.38594901735270070731\n",
      "Iteration 26475 => Loss: 47.38577756375858029969\n",
      "Iteration 26476 => Loss: 47.38560611151000756536\n",
      "Iteration 26477 => Loss: 47.38543466060700382059\n",
      "Iteration 26478 => Loss: 47.38526321104951932739\n",
      "Iteration 26479 => Loss: 47.38509176283758250747\n",
      "Iteration 26480 => Loss: 47.38492031597115072827\n",
      "Iteration 26481 => Loss: 47.38474887045022398979\n",
      "Iteration 26482 => Loss: 47.38457742627478808117\n",
      "Iteration 26483 => Loss: 47.38440598344483589699\n",
      "Iteration 26484 => Loss: 47.38423454196036033181\n",
      "Iteration 26485 => Loss: 47.38406310182134717479\n",
      "Iteration 26486 => Loss: 47.38389166302778932049\n",
      "Iteration 26487 => Loss: 47.38372022557967255807\n",
      "Iteration 26488 => Loss: 47.38354878947698267666\n",
      "Iteration 26489 => Loss: 47.38337735471972678170\n",
      "Iteration 26490 => Loss: 47.38320592130788355689\n",
      "Iteration 26491 => Loss: 47.38303448924144589682\n",
      "Iteration 26492 => Loss: 47.38286305852037116892\n",
      "Iteration 26493 => Loss: 47.38269162914470200576\n",
      "Iteration 26494 => Loss: 47.38252020111437445848\n",
      "Iteration 26495 => Loss: 47.38234877442941694881\n",
      "Iteration 26496 => Loss: 47.38217734908981526587\n",
      "Iteration 26497 => Loss: 47.38200592509554809340\n",
      "Iteration 26498 => Loss: 47.38183450244661543138\n",
      "Iteration 26499 => Loss: 47.38166308114298175269\n",
      "Iteration 26500 => Loss: 47.38149166118466126818\n",
      "Iteration 26501 => Loss: 47.38132024257163266157\n",
      "Iteration 26502 => Loss: 47.38114882530388172199\n",
      "Iteration 26503 => Loss: 47.38097740938141555489\n",
      "Iteration 26504 => Loss: 47.38080599480421284397\n",
      "Iteration 26505 => Loss: 47.38063458157226648382\n",
      "Iteration 26506 => Loss: 47.38046316968554094728\n",
      "Iteration 26507 => Loss: 47.38029175914407176151\n",
      "Iteration 26508 => Loss: 47.38012034994780918851\n",
      "Iteration 26509 => Loss: 47.37994894209677454455\n",
      "Iteration 26510 => Loss: 47.37977753559092519708\n",
      "Iteration 26511 => Loss: 47.37960613043025404068\n",
      "Iteration 26512 => Loss: 47.37943472661476818075\n",
      "Iteration 26513 => Loss: 47.37926332414446761732\n",
      "Iteration 26514 => Loss: 47.37909192301930261237\n",
      "Iteration 26515 => Loss: 47.37892052323929448221\n",
      "Iteration 26516 => Loss: 47.37874912480442901597\n",
      "Iteration 26517 => Loss: 47.37857772771467779194\n",
      "Iteration 26518 => Loss: 47.37840633197006212640\n",
      "Iteration 26519 => Loss: 47.37823493757053228137\n",
      "Iteration 26520 => Loss: 47.37806354451608825684\n",
      "Iteration 26521 => Loss: 47.37789215280675136910\n",
      "Iteration 26522 => Loss: 47.37772076244247188015\n",
      "Iteration 26523 => Loss: 47.37754937342324978999\n",
      "Iteration 26524 => Loss: 47.37737798574909930949\n",
      "Iteration 26525 => Loss: 47.37720659941997780606\n",
      "Iteration 26526 => Loss: 47.37703521443588527973\n",
      "Iteration 26527 => Loss: 47.37686383079683594133\n",
      "Iteration 26528 => Loss: 47.37669244850275873659\n",
      "Iteration 26529 => Loss: 47.37652106755370340352\n",
      "Iteration 26530 => Loss: 47.37634968794963441496\n",
      "Iteration 26531 => Loss: 47.37617830969055177093\n",
      "Iteration 26532 => Loss: 47.37600693277642704970\n",
      "Iteration 26533 => Loss: 47.37583555720725314586\n",
      "Iteration 26534 => Loss: 47.37566418298304427026\n",
      "Iteration 26535 => Loss: 47.37549281010375068490\n",
      "Iteration 26536 => Loss: 47.37532143856940081150\n",
      "Iteration 26537 => Loss: 47.37515006837994491207\n",
      "Iteration 26538 => Loss: 47.37497869953541140831\n",
      "Iteration 26539 => Loss: 47.37480733203575056223\n",
      "Iteration 26540 => Loss: 47.37463596588100500639\n",
      "Iteration 26541 => Loss: 47.37446460107110368654\n",
      "Iteration 26542 => Loss: 47.37429323760608923521\n",
      "Iteration 26543 => Loss: 47.37412187548589770358\n",
      "Iteration 26544 => Loss: 47.37395051471055040793\n",
      "Iteration 26545 => Loss: 47.37377915528005445367\n",
      "Iteration 26546 => Loss: 47.37360779719436010282\n",
      "Iteration 26547 => Loss: 47.37343644045348156624\n",
      "Iteration 26548 => Loss: 47.37326508505740463306\n",
      "Iteration 26549 => Loss: 47.37309373100611509244\n",
      "Iteration 26550 => Loss: 47.37292237829962715523\n",
      "Iteration 26551 => Loss: 47.37275102693786266173\n",
      "Iteration 26552 => Loss: 47.37257967692087845535\n",
      "Iteration 26553 => Loss: 47.37240832824863190353\n",
      "Iteration 26554 => Loss: 47.37223698092110879543\n",
      "Iteration 26555 => Loss: 47.37206563493833755274\n",
      "Iteration 26556 => Loss: 47.37189429030026133205\n",
      "Iteration 26557 => Loss: 47.37172294700689434421\n",
      "Iteration 26558 => Loss: 47.37155160505823658923\n",
      "Iteration 26559 => Loss: 47.37138026445424543454\n",
      "Iteration 26560 => Loss: 47.37120892519492798556\n",
      "Iteration 26561 => Loss: 47.37103758728026292601\n",
      "Iteration 26562 => Loss: 47.37086625071026446676\n",
      "Iteration 26563 => Loss: 47.37069491548487576438\n",
      "Iteration 26564 => Loss: 47.37052358160416076771\n",
      "Iteration 26565 => Loss: 47.37035224906803421163\n",
      "Iteration 26566 => Loss: 47.37018091787653162328\n",
      "Iteration 26567 => Loss: 47.37000958802963168637\n",
      "Iteration 26568 => Loss: 47.36983825952732729547\n",
      "Iteration 26569 => Loss: 47.36966693236955450175\n",
      "Iteration 26570 => Loss: 47.36949560655638435946\n",
      "Iteration 26571 => Loss: 47.36932428208774581435\n",
      "Iteration 26572 => Loss: 47.36915295896368149897\n",
      "Iteration 26573 => Loss: 47.36898163718413456991\n",
      "Iteration 26574 => Loss: 47.36881031674912634344\n",
      "Iteration 26575 => Loss: 47.36863899765862839786\n",
      "Iteration 26576 => Loss: 47.36846767991262652231\n",
      "Iteration 26577 => Loss: 47.36829636351112782222\n",
      "Iteration 26578 => Loss: 47.36812504845409677046\n",
      "Iteration 26579 => Loss: 47.36795373474152626159\n",
      "Iteration 26580 => Loss: 47.36778242237343050647\n",
      "Iteration 26581 => Loss: 47.36761111134981661053\n",
      "Iteration 26582 => Loss: 47.36743980167059220321\n",
      "Iteration 26583 => Loss: 47.36726849333582833879\n",
      "Iteration 26584 => Loss: 47.36709718634546817384\n",
      "Iteration 26585 => Loss: 47.36692588069952591923\n",
      "Iteration 26586 => Loss: 47.36675457639798736409\n",
      "Iteration 26587 => Loss: 47.36658327344081698129\n",
      "Iteration 26588 => Loss: 47.36641197182802187626\n",
      "Iteration 26589 => Loss: 47.36624067155959494357\n",
      "Iteration 26590 => Loss: 47.36606937263553618322\n",
      "Iteration 26591 => Loss: 47.36589807505582427893\n",
      "Iteration 26592 => Loss: 47.36572677882044501985\n",
      "Iteration 26593 => Loss: 47.36555548392937708968\n",
      "Iteration 26594 => Loss: 47.36538419038262759386\n",
      "Iteration 26595 => Loss: 47.36521289818018232154\n",
      "Iteration 26596 => Loss: 47.36504160732204127271\n",
      "Iteration 26597 => Loss: 47.36487031780818313109\n",
      "Iteration 26598 => Loss: 47.36469902963857236955\n",
      "Iteration 26599 => Loss: 47.36452774281323030436\n",
      "Iteration 26600 => Loss: 47.36435645733212851383\n",
      "Iteration 26601 => Loss: 47.36418517319529541965\n",
      "Iteration 26602 => Loss: 47.36401389040265996755\n",
      "Iteration 26603 => Loss: 47.36384260895426479010\n",
      "Iteration 26604 => Loss: 47.36367132885006014931\n",
      "Iteration 26605 => Loss: 47.36350005009009578316\n",
      "Iteration 26606 => Loss: 47.36332877267426511025\n",
      "Iteration 26607 => Loss: 47.36315749660262497400\n",
      "Iteration 26608 => Loss: 47.36298622187515405813\n",
      "Iteration 26609 => Loss: 47.36281494849185236262\n",
      "Iteration 26610 => Loss: 47.36264367645268436036\n",
      "Iteration 26611 => Loss: 47.36247240575763584047\n",
      "Iteration 26612 => Loss: 47.36230113640672811925\n",
      "Iteration 26613 => Loss: 47.36212986839993277499\n",
      "Iteration 26614 => Loss: 47.36195860173722849140\n",
      "Iteration 26615 => Loss: 47.36178733641863658477\n",
      "Iteration 26616 => Loss: 47.36161607244410021167\n",
      "Iteration 26617 => Loss: 47.36144480981364068839\n",
      "Iteration 26618 => Loss: 47.36127354852726512036\n",
      "Iteration 26619 => Loss: 47.36110228858490245329\n",
      "Iteration 26620 => Loss: 47.36093102998660953062\n",
      "Iteration 26621 => Loss: 47.36075977273234371978\n",
      "Iteration 26622 => Loss: 47.36058851682206238820\n",
      "Iteration 26623 => Loss: 47.36041726225582948473\n",
      "Iteration 26624 => Loss: 47.36024600903357395509\n",
      "Iteration 26625 => Loss: 47.36007475715530290472\n",
      "Iteration 26626 => Loss: 47.35990350662100212276\n",
      "Iteration 26627 => Loss: 47.35973225743067871463\n",
      "Iteration 26628 => Loss: 47.35956100958429715320\n",
      "Iteration 26629 => Loss: 47.35938976308187164932\n",
      "Iteration 26630 => Loss: 47.35921851792337378129\n",
      "Iteration 26631 => Loss: 47.35904727410881065452\n",
      "Iteration 26632 => Loss: 47.35887603163816095275\n",
      "Iteration 26633 => Loss: 47.35870479051138914883\n",
      "Iteration 26634 => Loss: 47.35853355072853787533\n",
      "Iteration 26635 => Loss: 47.35836231228954318340\n",
      "Iteration 26636 => Loss: 47.35819107519442638932\n",
      "Iteration 26637 => Loss: 47.35801983944318038766\n",
      "Iteration 26638 => Loss: 47.35784860503576254587\n",
      "Iteration 26639 => Loss: 47.35767737197218707479\n",
      "Iteration 26640 => Loss: 47.35750614025246107985\n",
      "Iteration 26641 => Loss: 47.35733490987654903392\n",
      "Iteration 26642 => Loss: 47.35716368084441540987\n",
      "Iteration 26643 => Loss: 47.35699245315610284024\n",
      "Iteration 26644 => Loss: 47.35682122681157579791\n",
      "Iteration 26645 => Loss: 47.35665000181081296660\n",
      "Iteration 26646 => Loss: 47.35647877815382145172\n",
      "Iteration 26647 => Loss: 47.35630755584058704244\n",
      "Iteration 26648 => Loss: 47.35613633487109552789\n",
      "Iteration 26649 => Loss: 47.35596511524532559179\n",
      "Iteration 26650 => Loss: 47.35579389696327723414\n",
      "Iteration 26651 => Loss: 47.35562268002496466579\n",
      "Iteration 26652 => Loss: 47.35545146443033814876\n",
      "Iteration 26653 => Loss: 47.35528025017940478847\n",
      "Iteration 26654 => Loss: 47.35510903727214326864\n",
      "Iteration 26655 => Loss: 47.35493782570858201098\n",
      "Iteration 26656 => Loss: 47.35476661548863575035\n",
      "Iteration 26657 => Loss: 47.35459540661237554104\n",
      "Iteration 26658 => Loss: 47.35442419907971611792\n",
      "Iteration 26659 => Loss: 47.35425299289070721898\n",
      "Iteration 26660 => Loss: 47.35408178804532042250\n",
      "Iteration 26661 => Loss: 47.35391058454352020135\n",
      "Iteration 26662 => Loss: 47.35373938238534208267\n",
      "Iteration 26663 => Loss: 47.35356818157072211761\n",
      "Iteration 26664 => Loss: 47.35339698209971004417\n",
      "Iteration 26665 => Loss: 47.35322578397224191349\n",
      "Iteration 26666 => Loss: 47.35305458718832483100\n",
      "Iteration 26667 => Loss: 47.35288339174795879671\n",
      "Iteration 26668 => Loss: 47.35271219765112959976\n",
      "Iteration 26669 => Loss: 47.35254100489781592387\n",
      "Iteration 26670 => Loss: 47.35236981348799645275\n",
      "Iteration 26671 => Loss: 47.35219862342169960812\n",
      "Iteration 26672 => Loss: 47.35202743469890407368\n",
      "Iteration 26673 => Loss: 47.35185624731958142775\n",
      "Iteration 26674 => Loss: 47.35168506128371745945\n",
      "Iteration 26675 => Loss: 47.35151387659130506336\n",
      "Iteration 26676 => Loss: 47.35134269324235845033\n",
      "Iteration 26677 => Loss: 47.35117151123685630409\n",
      "Iteration 26678 => Loss: 47.35100033057475599207\n",
      "Iteration 26679 => Loss: 47.35082915125607172513\n",
      "Iteration 26680 => Loss: 47.35065797328080350326\n",
      "Iteration 26681 => Loss: 47.35048679664894422103\n",
      "Iteration 26682 => Loss: 47.35031562136047256217\n",
      "Iteration 26683 => Loss: 47.35014444741535299954\n",
      "Iteration 26684 => Loss: 47.34997327481362106028\n",
      "Iteration 26685 => Loss: 47.34980210355521990095\n",
      "Iteration 26686 => Loss: 47.34963093364017794329\n",
      "Iteration 26687 => Loss: 47.34945976506846676557\n",
      "Iteration 26688 => Loss: 47.34928859784006505151\n",
      "Iteration 26689 => Loss: 47.34911743195498701198\n",
      "Iteration 26690 => Loss: 47.34894626741319711982\n",
      "Iteration 26691 => Loss: 47.34877510421471669133\n",
      "Iteration 26692 => Loss: 47.34860394235950309394\n",
      "Iteration 26693 => Loss: 47.34843278184756343308\n",
      "Iteration 26694 => Loss: 47.34826162267886218160\n",
      "Iteration 26695 => Loss: 47.34809046485344907751\n",
      "Iteration 26696 => Loss: 47.34791930837123885567\n",
      "Iteration 26697 => Loss: 47.34774815323227414865\n",
      "Iteration 26698 => Loss: 47.34757699943651232388\n",
      "Iteration 26699 => Loss: 47.34740584698396048680\n",
      "Iteration 26700 => Loss: 47.34723469587461153196\n",
      "Iteration 26701 => Loss: 47.34706354610844414310\n",
      "Iteration 26702 => Loss: 47.34689239768544410936\n",
      "Iteration 26703 => Loss: 47.34672125060562564158\n",
      "Iteration 26704 => Loss: 47.34655010486893900179\n",
      "Iteration 26705 => Loss: 47.34637896047541261169\n",
      "Iteration 26706 => Loss: 47.34620781742501094413\n",
      "Iteration 26707 => Loss: 47.34603667571773399914\n",
      "Iteration 26708 => Loss: 47.34586553535356756583\n",
      "Iteration 26709 => Loss: 47.34569439633249743338\n",
      "Iteration 26710 => Loss: 47.34552325865451649634\n",
      "Iteration 26711 => Loss: 47.34535212231961054385\n",
      "Iteration 26712 => Loss: 47.34518098732779378679\n",
      "Iteration 26713 => Loss: 47.34500985367901648715\n",
      "Iteration 26714 => Loss: 47.34483872137329285579\n",
      "Iteration 26715 => Loss: 47.34466759041060157642\n",
      "Iteration 26716 => Loss: 47.34449646079096396534\n",
      "Iteration 26717 => Loss: 47.34432533251430896826\n",
      "Iteration 26718 => Loss: 47.34415420558067211232\n",
      "Iteration 26719 => Loss: 47.34398307999002497581\n",
      "Iteration 26720 => Loss: 47.34381195574237466417\n",
      "Iteration 26721 => Loss: 47.34364083283768565025\n",
      "Iteration 26722 => Loss: 47.34346971127596503948\n",
      "Iteration 26723 => Loss: 47.34329859105719151557\n",
      "Iteration 26724 => Loss: 47.34312747218137218397\n",
      "Iteration 26725 => Loss: 47.34295635464849283380\n",
      "Iteration 26726 => Loss: 47.34278523845849662166\n",
      "Iteration 26727 => Loss: 47.34261412361145460181\n",
      "Iteration 26728 => Loss: 47.34244301010728150914\n",
      "Iteration 26729 => Loss: 47.34227189794601287076\n",
      "Iteration 26730 => Loss: 47.34210078712762026498\n",
      "Iteration 26731 => Loss: 47.34192967765209658637\n",
      "Iteration 26732 => Loss: 47.34175856951945604578\n",
      "Iteration 26733 => Loss: 47.34158746272963469437\n",
      "Iteration 26734 => Loss: 47.34141635728261832128\n",
      "Iteration 26735 => Loss: 47.34124525317851350792\n",
      "Iteration 26736 => Loss: 47.34107415041715682946\n",
      "Iteration 26737 => Loss: 47.34090304899861934018\n",
      "Iteration 26738 => Loss: 47.34073194892287972380\n",
      "Iteration 26739 => Loss: 47.34056085018993798030\n",
      "Iteration 26740 => Loss: 47.34038975279975147714\n",
      "Iteration 26741 => Loss: 47.34021865675233442516\n",
      "Iteration 26742 => Loss: 47.34004756204767971894\n",
      "Iteration 26743 => Loss: 47.33987646868574472592\n",
      "Iteration 26744 => Loss: 47.33970537666657207865\n",
      "Iteration 26745 => Loss: 47.33953428599009782829\n",
      "Iteration 26746 => Loss: 47.33936319665634329112\n",
      "Iteration 26747 => Loss: 47.33919210866528715087\n",
      "Iteration 26748 => Loss: 47.33902102201690098582\n",
      "Iteration 26749 => Loss: 47.33884993671124163939\n",
      "Iteration 26750 => Loss: 47.33867885274820963559\n",
      "Iteration 26751 => Loss: 47.33850777012785471243\n",
      "Iteration 26752 => Loss: 47.33833668885014134275\n",
      "Iteration 26753 => Loss: 47.33816560891506952657\n",
      "Iteration 26754 => Loss: 47.33799453032261084218\n",
      "Iteration 26755 => Loss: 47.33782345307276528956\n",
      "Iteration 26756 => Loss: 47.33765237716553997416\n",
      "Iteration 26757 => Loss: 47.33748130260090647425\n",
      "Iteration 26758 => Loss: 47.33731022937885057900\n",
      "Iteration 26759 => Loss: 47.33713915749940071009\n",
      "Iteration 26760 => Loss: 47.33696808696247160242\n",
      "Iteration 26761 => Loss: 47.33679701776809878311\n",
      "Iteration 26762 => Loss: 47.33662594991627514673\n",
      "Iteration 26763 => Loss: 47.33645488340699358787\n",
      "Iteration 26764 => Loss: 47.33628381824022568480\n",
      "Iteration 26765 => Loss: 47.33611275441596433211\n",
      "Iteration 26766 => Loss: 47.33594169193420952979\n",
      "Iteration 26767 => Loss: 47.33577063079495417242\n",
      "Iteration 26768 => Loss: 47.33559957099816983828\n",
      "Iteration 26769 => Loss: 47.33542851254384942195\n",
      "Iteration 26770 => Loss: 47.33525745543198581800\n",
      "Iteration 26771 => Loss: 47.33508639966255771014\n",
      "Iteration 26772 => Loss: 47.33491534523557220382\n",
      "Iteration 26773 => Loss: 47.33474429215102219359\n",
      "Iteration 26774 => Loss: 47.33457324040888636318\n",
      "Iteration 26775 => Loss: 47.33440219000915760716\n",
      "Iteration 26776 => Loss: 47.33423114095181460925\n",
      "Iteration 26777 => Loss: 47.33406009323685736945\n",
      "Iteration 26778 => Loss: 47.33388904686428588775\n",
      "Iteration 26779 => Loss: 47.33371800183407174245\n",
      "Iteration 26780 => Loss: 47.33354695814617940641\n",
      "Iteration 26781 => Loss: 47.33337591580067993391\n",
      "Iteration 26782 => Loss: 47.33320487479747384896\n",
      "Iteration 26783 => Loss: 47.33303383513659667869\n",
      "Iteration 26784 => Loss: 47.33286279681804131769\n",
      "Iteration 26785 => Loss: 47.33269175984177223881\n",
      "Iteration 26786 => Loss: 47.33252072420781786377\n",
      "Iteration 26787 => Loss: 47.33234968991612134914\n",
      "Iteration 26788 => Loss: 47.33217865696668269493\n",
      "Iteration 26789 => Loss: 47.33200762535952321741\n",
      "Iteration 26790 => Loss: 47.33183659509460738946\n",
      "Iteration 26791 => Loss: 47.33166556617192810563\n",
      "Iteration 26792 => Loss: 47.33149453859145694423\n",
      "Iteration 26793 => Loss: 47.33132351235321522154\n",
      "Iteration 26794 => Loss: 47.33115248745716741041\n",
      "Iteration 26795 => Loss: 47.33098146390333482714\n",
      "Iteration 26796 => Loss: 47.33081044169167483915\n",
      "Iteration 26797 => Loss: 47.33063942082219455187\n",
      "Iteration 26798 => Loss: 47.33046840129487975446\n",
      "Iteration 26799 => Loss: 47.33029738310970202519\n",
      "Iteration 26800 => Loss: 47.33012636626666846951\n",
      "Iteration 26801 => Loss: 47.32995535076577908740\n",
      "Iteration 26802 => Loss: 47.32978433660699124630\n",
      "Iteration 26803 => Loss: 47.32961332379031915707\n",
      "Iteration 26804 => Loss: 47.32944231231574860885\n",
      "Iteration 26805 => Loss: 47.32927130218327960165\n",
      "Iteration 26806 => Loss: 47.32910029339287660832\n",
      "Iteration 26807 => Loss: 47.32892928594453962887\n",
      "Iteration 26808 => Loss: 47.32875827983826155787\n",
      "Iteration 26809 => Loss: 47.32858727507403528989\n",
      "Iteration 26810 => Loss: 47.32841627165186082493\n",
      "Iteration 26811 => Loss: 47.32824526957168842500\n",
      "Iteration 26812 => Loss: 47.32807426883353940639\n",
      "Iteration 26813 => Loss: 47.32790326943737824195\n",
      "Iteration 26814 => Loss: 47.32773227138323335339\n",
      "Iteration 26815 => Loss: 47.32756127467106921358\n",
      "Iteration 26816 => Loss: 47.32739027930087161167\n",
      "Iteration 26817 => Loss: 47.32721928527262633679\n",
      "Iteration 26818 => Loss: 47.32704829258635470524\n",
      "Iteration 26819 => Loss: 47.32687730124203540072\n",
      "Iteration 26820 => Loss: 47.32670631123960447439\n",
      "Iteration 26821 => Loss: 47.32653532257913298054\n",
      "Iteration 26822 => Loss: 47.32636433526055697030\n",
      "Iteration 26823 => Loss: 47.32619334928386933825\n",
      "Iteration 26824 => Loss: 47.32602236464907008440\n",
      "Iteration 26825 => Loss: 47.32585138135617341959\n",
      "Iteration 26826 => Loss: 47.32568039940511539498\n",
      "Iteration 26827 => Loss: 47.32550941879593153772\n",
      "Iteration 26828 => Loss: 47.32533843952860763693\n",
      "Iteration 26829 => Loss: 47.32516746160310106006\n",
      "Iteration 26830 => Loss: 47.32499648501943312340\n",
      "Iteration 26831 => Loss: 47.32482550977756119437\n",
      "Iteration 26832 => Loss: 47.32465453587750658926\n",
      "Iteration 26833 => Loss: 47.32448356331926220264\n",
      "Iteration 26834 => Loss: 47.32431259210277119109\n",
      "Iteration 26835 => Loss: 47.32414162222806197633\n",
      "Iteration 26836 => Loss: 47.32397065369512745292\n",
      "Iteration 26837 => Loss: 47.32379968650393919916\n",
      "Iteration 26838 => Loss: 47.32362872065449010961\n",
      "Iteration 26839 => Loss: 47.32345775614678728971\n",
      "Iteration 26840 => Loss: 47.32328679298076679061\n",
      "Iteration 26841 => Loss: 47.32311583115647124487\n",
      "Iteration 26842 => Loss: 47.32294487067388644164\n",
      "Iteration 26843 => Loss: 47.32277391153298395921\n",
      "Iteration 26844 => Loss: 47.32260295373377800843\n",
      "Iteration 26845 => Loss: 47.32243199727622595674\n",
      "Iteration 26846 => Loss: 47.32226104216032780414\n",
      "Iteration 26847 => Loss: 47.32209008838606933978\n",
      "Iteration 26848 => Loss: 47.32191913595347187993\n",
      "Iteration 26849 => Loss: 47.32174818486247147575\n",
      "Iteration 26850 => Loss: 47.32157723511310365438\n",
      "Iteration 26851 => Loss: 47.32140628670531867783\n",
      "Iteration 26852 => Loss: 47.32123533963916628409\n",
      "Iteration 26853 => Loss: 47.32106439391456120802\n",
      "Iteration 26854 => Loss: 47.32089344953154608220\n",
      "Iteration 26855 => Loss: 47.32072250649009248491\n",
      "Iteration 26856 => Loss: 47.32055156479018620530\n",
      "Iteration 26857 => Loss: 47.32038062443184145422\n",
      "Iteration 26858 => Loss: 47.32020968541500138826\n",
      "Iteration 26859 => Loss: 47.32003874773968021827\n",
      "Iteration 26860 => Loss: 47.31986781140589215511\n",
      "Iteration 26861 => Loss: 47.31969687641360167163\n",
      "Iteration 26862 => Loss: 47.31952594276276613527\n",
      "Iteration 26863 => Loss: 47.31935501045346370574\n",
      "Iteration 26864 => Loss: 47.31918407948558069620\n",
      "Iteration 26865 => Loss: 47.31901314985916684464\n",
      "Iteration 26866 => Loss: 47.31884222157421504562\n",
      "Iteration 26867 => Loss: 47.31867129463066845574\n",
      "Iteration 26868 => Loss: 47.31850036902859812926\n",
      "Iteration 26869 => Loss: 47.31832944476789748478\n",
      "Iteration 26870 => Loss: 47.31815852184863757657\n",
      "Iteration 26871 => Loss: 47.31798760027072603407\n",
      "Iteration 26872 => Loss: 47.31781668003423391156\n",
      "Iteration 26873 => Loss: 47.31764576113909726018\n",
      "Iteration 26874 => Loss: 47.31747484358533739623\n",
      "Iteration 26875 => Loss: 47.31730392737292589800\n",
      "Iteration 26876 => Loss: 47.31713301250184144919\n",
      "Iteration 26877 => Loss: 47.31696209897210536610\n",
      "Iteration 26878 => Loss: 47.31679118678368212159\n",
      "Iteration 26879 => Loss: 47.31662027593656461022\n",
      "Iteration 26880 => Loss: 47.31644936643075993743\n",
      "Iteration 26881 => Loss: 47.31627845826623968151\n",
      "Iteration 26882 => Loss: 47.31610755144296831531\n",
      "Iteration 26883 => Loss: 47.31593664596101689312\n",
      "Iteration 26884 => Loss: 47.31576574182028593896\n",
      "Iteration 26885 => Loss: 47.31559483902081097995\n",
      "Iteration 26886 => Loss: 47.31542393756257069981\n",
      "Iteration 26887 => Loss: 47.31525303744556509855\n",
      "Iteration 26888 => Loss: 47.31508213866975864903\n",
      "Iteration 26889 => Loss: 47.31491124123517266753\n",
      "Iteration 26890 => Loss: 47.31474034514177162691\n",
      "Iteration 26891 => Loss: 47.31456945038956263261\n",
      "Iteration 26892 => Loss: 47.31439855697851015748\n",
      "Iteration 26893 => Loss: 47.31422766490862841238\n",
      "Iteration 26894 => Loss: 47.31405677417989608102\n",
      "Iteration 26895 => Loss: 47.31388588479232026884\n",
      "Iteration 26896 => Loss: 47.31371499674585834327\n",
      "Iteration 26897 => Loss: 47.31354411004053162060\n",
      "Iteration 26898 => Loss: 47.31337322467629746825\n",
      "Iteration 26899 => Loss: 47.31320234065318430794\n",
      "Iteration 26900 => Loss: 47.31303145797113529625\n",
      "Iteration 26901 => Loss: 47.31286057663017885488\n",
      "Iteration 26902 => Loss: 47.31268969663030077299\n",
      "Iteration 26903 => Loss: 47.31251881797145131259\n",
      "Iteration 26904 => Loss: 47.31234794065366600080\n",
      "Iteration 26905 => Loss: 47.31217706467690931049\n",
      "Iteration 26906 => Loss: 47.31200619004120255795\n",
      "Iteration 26907 => Loss: 47.31183531674648889975\n",
      "Iteration 26908 => Loss: 47.31166444479277544133\n",
      "Iteration 26909 => Loss: 47.31149357418008349896\n",
      "Iteration 26910 => Loss: 47.31132270490834912380\n",
      "Iteration 26911 => Loss: 47.31115183697757231585\n",
      "Iteration 26912 => Loss: 47.31098097038779570767\n",
      "Iteration 26913 => Loss: 47.31081010513894824498\n",
      "Iteration 26914 => Loss: 47.31063924123104413866\n",
      "Iteration 26915 => Loss: 47.31046837866408338868\n",
      "Iteration 26916 => Loss: 47.31029751743803757336\n",
      "Iteration 26917 => Loss: 47.31012665755289958724\n",
      "Iteration 26918 => Loss: 47.30995579900866232492\n",
      "Iteration 26919 => Loss: 47.30978494180531868096\n",
      "Iteration 26920 => Loss: 47.30961408594284023366\n",
      "Iteration 26921 => Loss: 47.30944323142121987757\n",
      "Iteration 26922 => Loss: 47.30927237824049313986\n",
      "Iteration 26923 => Loss: 47.30910152640058896623\n",
      "Iteration 26924 => Loss: 47.30893067590153577839\n",
      "Iteration 26925 => Loss: 47.30875982674328383837\n",
      "Iteration 26926 => Loss: 47.30858897892586867329\n",
      "Iteration 26927 => Loss: 47.30841813244925475601\n",
      "Iteration 26928 => Loss: 47.30824728731342787569\n",
      "Iteration 26929 => Loss: 47.30807644351838803232\n",
      "Iteration 26930 => Loss: 47.30790560106413522590\n",
      "Iteration 26931 => Loss: 47.30773475995061971844\n",
      "Iteration 26932 => Loss: 47.30756392017786282622\n",
      "Iteration 26933 => Loss: 47.30739308174586454925\n",
      "Iteration 26934 => Loss: 47.30722224465457514953\n",
      "Iteration 26935 => Loss: 47.30705140890400883791\n",
      "Iteration 26936 => Loss: 47.30688057449415140354\n",
      "Iteration 26937 => Loss: 47.30670974142500995185\n",
      "Iteration 26938 => Loss: 47.30653890969655606114\n",
      "Iteration 26939 => Loss: 47.30636807930875420425\n",
      "Iteration 26940 => Loss: 47.30619725026164701376\n",
      "Iteration 26941 => Loss: 47.30602642255520606795\n",
      "Iteration 26942 => Loss: 47.30585559618938873427\n",
      "Iteration 26943 => Loss: 47.30568477116421632900\n",
      "Iteration 26944 => Loss: 47.30551394747966753584\n",
      "Iteration 26945 => Loss: 47.30534312513574946024\n",
      "Iteration 26946 => Loss: 47.30517230413239104792\n",
      "Iteration 26947 => Loss: 47.30500148446967756399\n",
      "Iteration 26948 => Loss: 47.30483066614754505963\n",
      "Iteration 26949 => Loss: 47.30465984916594379683\n",
      "Iteration 26950 => Loss: 47.30448903352493061902\n",
      "Iteration 26951 => Loss: 47.30431821922446289364\n",
      "Iteration 26952 => Loss: 47.30414740626456193695\n",
      "Iteration 26953 => Loss: 47.30397659464516380012\n",
      "Iteration 26954 => Loss: 47.30380578436628979944\n",
      "Iteration 26955 => Loss: 47.30363497542791861861\n",
      "Iteration 26956 => Loss: 47.30346416783007867934\n",
      "Iteration 26957 => Loss: 47.30329336157271313823\n",
      "Iteration 26958 => Loss: 47.30312255665580067898\n",
      "Iteration 26959 => Loss: 47.30295175307939814502\n",
      "Iteration 26960 => Loss: 47.30278095084342737664\n",
      "Iteration 26961 => Loss: 47.30261014994791679555\n",
      "Iteration 26962 => Loss: 47.30243935039283087463\n",
      "Iteration 26963 => Loss: 47.30226855217816250843\n",
      "Iteration 26964 => Loss: 47.30209775530391880238\n",
      "Iteration 26965 => Loss: 47.30192695977008554564\n",
      "Iteration 26966 => Loss: 47.30175616557664852735\n",
      "Iteration 26967 => Loss: 47.30158537272360064208\n",
      "Iteration 26968 => Loss: 47.30141458121092767897\n",
      "Iteration 26969 => Loss: 47.30124379103858700546\n",
      "Iteration 26970 => Loss: 47.30107300220661414869\n",
      "Iteration 26971 => Loss: 47.30090221471498068695\n",
      "Iteration 26972 => Loss: 47.30073142856368662024\n",
      "Iteration 26973 => Loss: 47.30056064375271063227\n",
      "Iteration 26974 => Loss: 47.30038986028203140677\n",
      "Iteration 26975 => Loss: 47.30021907815166315459\n",
      "Iteration 26976 => Loss: 47.30004829736161298115\n",
      "Iteration 26977 => Loss: 47.29987751791181693761\n",
      "Iteration 26978 => Loss: 47.29970673980228212940\n",
      "Iteration 26979 => Loss: 47.29953596303299434567\n",
      "Iteration 26980 => Loss: 47.29936518760397490269\n",
      "Iteration 26981 => Loss: 47.29919441351518827332\n",
      "Iteration 26982 => Loss: 47.29902364076663445758\n",
      "Iteration 26983 => Loss: 47.29885286935827792831\n",
      "Iteration 26984 => Loss: 47.29868209929012579096\n",
      "Iteration 26985 => Loss: 47.29851133056217804551\n",
      "Iteration 26986 => Loss: 47.29834056317441337569\n",
      "Iteration 26987 => Loss: 47.29816979712683178150\n",
      "Iteration 26988 => Loss: 47.29799903241939773579\n",
      "Iteration 26989 => Loss: 47.29782826905212544943\n",
      "Iteration 26990 => Loss: 47.29765750702500071156\n",
      "Iteration 26991 => Loss: 47.29748674633798088962\n",
      "Iteration 26992 => Loss: 47.29731598699110861617\n",
      "Iteration 26993 => Loss: 47.29714522898434125864\n",
      "Iteration 26994 => Loss: 47.29697447231767881703\n",
      "Iteration 26995 => Loss: 47.29680371699107865879\n",
      "Iteration 26996 => Loss: 47.29663296300458341648\n",
      "Iteration 26997 => Loss: 47.29646221035815045752\n",
      "Iteration 26998 => Loss: 47.29629145905175846565\n",
      "Iteration 26999 => Loss: 47.29612070908543586256\n",
      "Iteration 27000 => Loss: 47.29594996045914712113\n",
      "Iteration 27001 => Loss: 47.29577921317287803049\n",
      "Iteration 27002 => Loss: 47.29560846722664280151\n",
      "Iteration 27003 => Loss: 47.29543772262038459075\n",
      "Iteration 27004 => Loss: 47.29526697935413892537\n",
      "Iteration 27005 => Loss: 47.29509623742785606737\n",
      "Iteration 27006 => Loss: 47.29492549684157154388\n",
      "Iteration 27007 => Loss: 47.29475475759524272235\n",
      "Iteration 27008 => Loss: 47.29458401968886960276\n",
      "Iteration 27009 => Loss: 47.29441328312243797427\n",
      "Iteration 27010 => Loss: 47.29424254789593362602\n",
      "Iteration 27011 => Loss: 47.29407181400934234716\n",
      "Iteration 27012 => Loss: 47.29390108146267834854\n",
      "Iteration 27013 => Loss: 47.29373035025590610303\n",
      "Iteration 27014 => Loss: 47.29355962038901139977\n",
      "Iteration 27015 => Loss: 47.29338889186201555503\n",
      "Iteration 27016 => Loss: 47.29321816467489014713\n",
      "Iteration 27017 => Loss: 47.29304743882759964890\n",
      "Iteration 27018 => Loss: 47.29287671432017248208\n",
      "Iteration 27019 => Loss: 47.29270599115258022493\n",
      "Iteration 27020 => Loss: 47.29253526932482998291\n",
      "Iteration 27021 => Loss: 47.29236454883685780715\n",
      "Iteration 27022 => Loss: 47.29219382968872054107\n",
      "Iteration 27023 => Loss: 47.29202311188036844669\n",
      "Iteration 27024 => Loss: 47.29185239541180152401\n",
      "Iteration 27025 => Loss: 47.29168168028301977301\n",
      "Iteration 27026 => Loss: 47.29151096649397345573\n",
      "Iteration 27027 => Loss: 47.29134025404471231013\n",
      "Iteration 27028 => Loss: 47.29116954293517238739\n",
      "Iteration 27029 => Loss: 47.29099883316537500377\n",
      "Iteration 27030 => Loss: 47.29082812473530594843\n",
      "Iteration 27031 => Loss: 47.29065741764493679966\n",
      "Iteration 27032 => Loss: 47.29048671189426045203\n",
      "Iteration 27033 => Loss: 47.29031600748327690553\n",
      "Iteration 27034 => Loss: 47.29014530441197194932\n",
      "Iteration 27035 => Loss: 47.28997460268034558339\n",
      "Iteration 27036 => Loss: 47.28980390228836938604\n",
      "Iteration 27037 => Loss: 47.28963320323603625184\n",
      "Iteration 27038 => Loss: 47.28946250552336039163\n",
      "Iteration 27039 => Loss: 47.28929180915029917287\n",
      "Iteration 27040 => Loss: 47.28912111411685970097\n",
      "Iteration 27041 => Loss: 47.28895042042300644880\n",
      "Iteration 27042 => Loss: 47.28877972806874652179\n",
      "Iteration 27043 => Loss: 47.28860903705410123621\n",
      "Iteration 27044 => Loss: 47.28843834737902085408\n",
      "Iteration 27045 => Loss: 47.28826765904349116454\n",
      "Iteration 27046 => Loss: 47.28809697204751927302\n",
      "Iteration 27047 => Loss: 47.28792628639109807409\n",
      "Iteration 27048 => Loss: 47.28775560207421335690\n",
      "Iteration 27049 => Loss: 47.28758491909682248888\n",
      "Iteration 27050 => Loss: 47.28741423745894678632\n",
      "Iteration 27051 => Loss: 47.28724355716061467092\n",
      "Iteration 27052 => Loss: 47.28707287820174087756\n",
      "Iteration 27053 => Loss: 47.28690220058234672251\n",
      "Iteration 27054 => Loss: 47.28673152430241799493\n",
      "Iteration 27055 => Loss: 47.28656084936195469481\n",
      "Iteration 27056 => Loss: 47.28639017576092840045\n",
      "Iteration 27057 => Loss: 47.28621950349937463898\n",
      "Iteration 27058 => Loss: 47.28604883257718682898\n",
      "Iteration 27059 => Loss: 47.28587816299445023560\n",
      "Iteration 27060 => Loss: 47.28570749475113643712\n",
      "Iteration 27061 => Loss: 47.28553682784720280097\n",
      "Iteration 27062 => Loss: 47.28536616228264222173\n",
      "Iteration 27063 => Loss: 47.28519549805746891025\n",
      "Iteration 27064 => Loss: 47.28502483517166865568\n",
      "Iteration 27065 => Loss: 47.28485417362520593088\n",
      "Iteration 27066 => Loss: 47.28468351341808073585\n",
      "Iteration 27067 => Loss: 47.28451285455030728144\n",
      "Iteration 27068 => Loss: 47.28434219702184293510\n",
      "Iteration 27069 => Loss: 47.28417154083268059139\n",
      "Iteration 27070 => Loss: 47.28400088598285577746\n",
      "Iteration 27071 => Loss: 47.28383023247226901731\n",
      "Iteration 27072 => Loss: 47.28365958030100557608\n",
      "Iteration 27073 => Loss: 47.28348892946898018863\n",
      "Iteration 27074 => Loss: 47.28331827997623548754\n",
      "Iteration 27075 => Loss: 47.28314763182273594566\n",
      "Iteration 27076 => Loss: 47.28297698500846735215\n",
      "Iteration 27077 => Loss: 47.28280633953342260156\n",
      "Iteration 27078 => Loss: 47.28263569539760169391\n",
      "Iteration 27079 => Loss: 47.28246505260098331291\n",
      "Iteration 27080 => Loss: 47.28229441114356035314\n",
      "Iteration 27081 => Loss: 47.28212377102533281459\n",
      "Iteration 27082 => Loss: 47.28195313224628648641\n",
      "Iteration 27083 => Loss: 47.28178249480637873603\n",
      "Iteration 27084 => Loss: 47.28161185870565219602\n",
      "Iteration 27085 => Loss: 47.28144122394404291754\n",
      "Iteration 27086 => Loss: 47.28127059052156511143\n",
      "Iteration 27087 => Loss: 47.28109995843822588313\n",
      "Iteration 27088 => Loss: 47.28092932769398970549\n",
      "Iteration 27089 => Loss: 47.28075869828886368396\n",
      "Iteration 27090 => Loss: 47.28058807022281229138\n",
      "Iteration 27091 => Loss: 47.28041744349586394947\n",
      "Iteration 27092 => Loss: 47.28024681810796892023\n",
      "Iteration 27093 => Loss: 47.28007619405912720367\n",
      "Iteration 27094 => Loss: 47.27990557134934590522\n",
      "Iteration 27095 => Loss: 47.27973494997861791944\n",
      "Iteration 27096 => Loss: 47.27956432994688640292\n",
      "Iteration 27097 => Loss: 47.27939371125419398822\n",
      "Iteration 27098 => Loss: 47.27922309390049093736\n",
      "Iteration 27099 => Loss: 47.27905247788577725032\n",
      "Iteration 27100 => Loss: 47.27888186321006003254\n",
      "Iteration 27101 => Loss: 47.27871124987334638945\n",
      "Iteration 27102 => Loss: 47.27854063787555816134\n",
      "Iteration 27103 => Loss: 47.27837002721673798078\n",
      "Iteration 27104 => Loss: 47.27819941789687874234\n",
      "Iteration 27105 => Loss: 47.27802880991593070803\n",
      "Iteration 27106 => Loss: 47.27785820327390098328\n",
      "Iteration 27107 => Loss: 47.27768759797078246265\n",
      "Iteration 27108 => Loss: 47.27751699400658935701\n",
      "Iteration 27109 => Loss: 47.27734639138126482294\n",
      "Iteration 27110 => Loss: 47.27717579009483017671\n",
      "Iteration 27111 => Loss: 47.27700519014727120748\n",
      "Iteration 27112 => Loss: 47.27683459153855949353\n",
      "Iteration 27113 => Loss: 47.27666399426870924572\n",
      "Iteration 27114 => Loss: 47.27649339833769204233\n",
      "Iteration 27115 => Loss: 47.27632280374547946167\n",
      "Iteration 27116 => Loss: 47.27615221049210703086\n",
      "Iteration 27117 => Loss: 47.27598161857753922277\n",
      "Iteration 27118 => Loss: 47.27581102800176893197\n",
      "Iteration 27119 => Loss: 47.27564043876479615847\n",
      "Iteration 27120 => Loss: 47.27546985086657826969\n",
      "Iteration 27121 => Loss: 47.27529926430712947649\n",
      "Iteration 27122 => Loss: 47.27512867908644267345\n",
      "Iteration 27123 => Loss: 47.27495809520448943886\n",
      "Iteration 27124 => Loss: 47.27478751266126266728\n",
      "Iteration 27125 => Loss: 47.27461693145679788586\n",
      "Iteration 27126 => Loss: 47.27444635159101693489\n",
      "Iteration 27127 => Loss: 47.27427577306392691980\n",
      "Iteration 27128 => Loss: 47.27410519587555626231\n",
      "Iteration 27129 => Loss: 47.27393462002584101356\n",
      "Iteration 27130 => Loss: 47.27376404551480248983\n",
      "Iteration 27131 => Loss: 47.27359347234244779656\n",
      "Iteration 27132 => Loss: 47.27342290050869877405\n",
      "Iteration 27133 => Loss: 47.27325233001361226570\n",
      "Iteration 27134 => Loss: 47.27308176085715274439\n",
      "Iteration 27135 => Loss: 47.27291119303932731555\n",
      "Iteration 27136 => Loss: 47.27274062656009334660\n",
      "Iteration 27137 => Loss: 47.27257006141946504840\n",
      "Iteration 27138 => Loss: 47.27239949761739978840\n",
      "Iteration 27139 => Loss: 47.27222893515393309372\n",
      "Iteration 27140 => Loss: 47.27205837402902233180\n",
      "Iteration 27141 => Loss: 47.27188781424266750264\n",
      "Iteration 27142 => Loss: 47.27171725579484728996\n",
      "Iteration 27143 => Loss: 47.27154669868556879919\n",
      "Iteration 27144 => Loss: 47.27137614291482492490\n",
      "Iteration 27145 => Loss: 47.27120558848258013995\n",
      "Iteration 27146 => Loss: 47.27103503538883444435\n",
      "Iteration 27147 => Loss: 47.27086448363358073266\n",
      "Iteration 27148 => Loss: 47.27069393321684032117\n",
      "Iteration 27149 => Loss: 47.27052338413852794474\n",
      "Iteration 27150 => Loss: 47.27035283639869334138\n",
      "Iteration 27151 => Loss: 47.27018228999731519480\n",
      "Iteration 27152 => Loss: 47.27001174493436508328\n",
      "Iteration 27153 => Loss: 47.26984120120983590141\n",
      "Iteration 27154 => Loss: 47.26967065882374896546\n",
      "Iteration 27155 => Loss: 47.26950011777606164287\n",
      "Iteration 27156 => Loss: 47.26932957806675261736\n",
      "Iteration 27157 => Loss: 47.26915903969586452149\n",
      "Iteration 27158 => Loss: 47.26898850266332630099\n",
      "Iteration 27159 => Loss: 47.26881796696914506128\n",
      "Iteration 27160 => Loss: 47.26864743261332790780\n",
      "Iteration 27161 => Loss: 47.26847689959587484054\n",
      "Iteration 27162 => Loss: 47.26830636791674322694\n",
      "Iteration 27163 => Loss: 47.26813583757593306700\n",
      "Iteration 27164 => Loss: 47.26796530857343725529\n",
      "Iteration 27165 => Loss: 47.26779478090924868638\n",
      "Iteration 27166 => Loss: 47.26762425458333893857\n",
      "Iteration 27167 => Loss: 47.26745372959572222271\n",
      "Iteration 27168 => Loss: 47.26728320594638432794\n",
      "Iteration 27169 => Loss: 47.26711268363528262171\n",
      "Iteration 27170 => Loss: 47.26694216266245973657\n",
      "Iteration 27171 => Loss: 47.26677164302785172367\n",
      "Iteration 27172 => Loss: 47.26660112473148700474\n",
      "Iteration 27173 => Loss: 47.26643060777334426348\n",
      "Iteration 27174 => Loss: 47.26626009215339507818\n",
      "Iteration 27175 => Loss: 47.26608957787163944886\n",
      "Iteration 27176 => Loss: 47.26591906492809158635\n",
      "Iteration 27177 => Loss: 47.26574855332270885810\n",
      "Iteration 27178 => Loss: 47.26557804305551258039\n",
      "Iteration 27179 => Loss: 47.26540753412643880438\n",
      "Iteration 27180 => Loss: 47.26523702653552305719\n",
      "Iteration 27181 => Loss: 47.26506652028273691712\n",
      "Iteration 27182 => Loss: 47.26489601536810170046\n",
      "Iteration 27183 => Loss: 47.26472551179154635292\n",
      "Iteration 27184 => Loss: 47.26455500955310640165\n",
      "Iteration 27185 => Loss: 47.26438450865276053037\n",
      "Iteration 27186 => Loss: 47.26421400909050163364\n",
      "Iteration 27187 => Loss: 47.26404351086630128975\n",
      "Iteration 27188 => Loss: 47.26387301398017370957\n",
      "Iteration 27189 => Loss: 47.26370251843209757681\n",
      "Iteration 27190 => Loss: 47.26353202422205868061\n",
      "Iteration 27191 => Loss: 47.26336153135004281012\n",
      "Iteration 27192 => Loss: 47.26319103981604285991\n",
      "Iteration 27193 => Loss: 47.26302054962007304084\n",
      "Iteration 27194 => Loss: 47.26285006076207650949\n",
      "Iteration 27195 => Loss: 47.26267957324208168757\n",
      "Iteration 27196 => Loss: 47.26250908706005304794\n",
      "Iteration 27197 => Loss: 47.26233860221601190688\n",
      "Iteration 27198 => Loss: 47.26216811870990852640\n",
      "Iteration 27199 => Loss: 47.26199763654175711736\n",
      "Iteration 27200 => Loss: 47.26182715571154346890\n",
      "Iteration 27201 => Loss: 47.26165667621923915931\n",
      "Iteration 27202 => Loss: 47.26148619806487261030\n",
      "Iteration 27203 => Loss: 47.26131572124840118931\n",
      "Iteration 27204 => Loss: 47.26114524576979647463\n",
      "Iteration 27205 => Loss: 47.26097477162912241511\n",
      "Iteration 27206 => Loss: 47.26080429882627953475\n",
      "Iteration 27207 => Loss: 47.26063382736132467699\n",
      "Iteration 27208 => Loss: 47.26046335723420810382\n",
      "Iteration 27209 => Loss: 47.26029288844492981525\n",
      "Iteration 27210 => Loss: 47.26012242099348270585\n",
      "Iteration 27211 => Loss: 47.25995195487985967020\n",
      "Iteration 27212 => Loss: 47.25978149010406070829\n",
      "Iteration 27213 => Loss: 47.25961102666602897671\n",
      "Iteration 27214 => Loss: 47.25944056456579289716\n",
      "Iteration 27215 => Loss: 47.25927010380335246964\n",
      "Iteration 27216 => Loss: 47.25909964437867927245\n",
      "Iteration 27217 => Loss: 47.25892918629173777845\n",
      "Iteration 27218 => Loss: 47.25875872954254930391\n",
      "Iteration 27219 => Loss: 47.25858827413110674343\n",
      "Iteration 27220 => Loss: 47.25841782005740299155\n",
      "Iteration 27221 => Loss: 47.25824736732138120487\n",
      "Iteration 27222 => Loss: 47.25807691592308401596\n",
      "Iteration 27223 => Loss: 47.25790646586248300309\n",
      "Iteration 27224 => Loss: 47.25773601713955685000\n",
      "Iteration 27225 => Loss: 47.25756556975429845124\n",
      "Iteration 27226 => Loss: 47.25739512370670780683\n",
      "Iteration 27227 => Loss: 47.25722467899677070591\n",
      "Iteration 27228 => Loss: 47.25705423562446583219\n",
      "Iteration 27229 => Loss: 47.25688379358980029110\n",
      "Iteration 27230 => Loss: 47.25671335289276697722\n",
      "Iteration 27231 => Loss: 47.25654291353330194170\n",
      "Iteration 27232 => Loss: 47.25637247551149044966\n",
      "Iteration 27233 => Loss: 47.25620203882721881428\n",
      "Iteration 27234 => Loss: 47.25603160348055808981\n",
      "Iteration 27235 => Loss: 47.25586116947146564371\n",
      "Iteration 27236 => Loss: 47.25569073679991305426\n",
      "Iteration 27237 => Loss: 47.25552030546590742688\n",
      "Iteration 27238 => Loss: 47.25534987546944165615\n",
      "Iteration 27239 => Loss: 47.25517944681050863664\n",
      "Iteration 27240 => Loss: 47.25500901948908705208\n",
      "Iteration 27241 => Loss: 47.25483859350515558617\n",
      "Iteration 27242 => Loss: 47.25466816885873555520\n",
      "Iteration 27243 => Loss: 47.25449774554979853747\n",
      "Iteration 27244 => Loss: 47.25432732357833032211\n",
      "Iteration 27245 => Loss: 47.25415690294431669827\n",
      "Iteration 27246 => Loss: 47.25398648364777187680\n",
      "Iteration 27247 => Loss: 47.25381606568865322515\n",
      "Iteration 27248 => Loss: 47.25364564906698205959\n",
      "Iteration 27249 => Loss: 47.25347523378272285299\n",
      "Iteration 27250 => Loss: 47.25330481983586849992\n",
      "Iteration 27251 => Loss: 47.25313440722641900038\n",
      "Iteration 27252 => Loss: 47.25296399595436014351\n",
      "Iteration 27253 => Loss: 47.25279358601966350761\n",
      "Iteration 27254 => Loss: 47.25262317742233619811\n",
      "Iteration 27255 => Loss: 47.25245277016241374213\n",
      "Iteration 27256 => Loss: 47.25228236423979666370\n",
      "Iteration 27257 => Loss: 47.25211195965451338452\n",
      "Iteration 27258 => Loss: 47.25194155640657101003\n",
      "Iteration 27259 => Loss: 47.25177115449594822394\n",
      "Iteration 27260 => Loss: 47.25160075392261660454\n",
      "Iteration 27261 => Loss: 47.25143035468659036269\n",
      "Iteration 27262 => Loss: 47.25125995678784818210\n",
      "Iteration 27263 => Loss: 47.25108956022637585193\n",
      "Iteration 27264 => Loss: 47.25091916500215916130\n",
      "Iteration 27265 => Loss: 47.25074877111520521566\n",
      "Iteration 27266 => Loss: 47.25057837856549980415\n",
      "Iteration 27267 => Loss: 47.25040798735301450506\n",
      "Iteration 27268 => Loss: 47.25023759747774221296\n",
      "Iteration 27269 => Loss: 47.25006720893969003328\n",
      "Iteration 27270 => Loss: 47.24989682173885086058\n",
      "Iteration 27271 => Loss: 47.24972643587518916775\n",
      "Iteration 27272 => Loss: 47.24955605134871206019\n",
      "Iteration 27273 => Loss: 47.24938566815939111621\n",
      "Iteration 27274 => Loss: 47.24921528630724054665\n",
      "Iteration 27275 => Loss: 47.24904490579223903524\n",
      "Iteration 27276 => Loss: 47.24887452661436526569\n",
      "Iteration 27277 => Loss: 47.24870414877362634343\n",
      "Iteration 27278 => Loss: 47.24853377227000805760\n",
      "Iteration 27279 => Loss: 47.24836339710348909193\n",
      "Iteration 27280 => Loss: 47.24819302327406944642\n",
      "Iteration 27281 => Loss: 47.24802265078171359391\n",
      "Iteration 27282 => Loss: 47.24785227962645706157\n",
      "Iteration 27283 => Loss: 47.24768190980825011138\n",
      "Iteration 27284 => Loss: 47.24751154132710695421\n",
      "Iteration 27285 => Loss: 47.24734117418299916835\n",
      "Iteration 27286 => Loss: 47.24717080837591964837\n",
      "Iteration 27287 => Loss: 47.24700044390588260512\n",
      "Iteration 27288 => Loss: 47.24683008077283119519\n",
      "Iteration 27289 => Loss: 47.24665971897679384028\n",
      "Iteration 27290 => Loss: 47.24648935851773501327\n",
      "Iteration 27291 => Loss: 47.24631899939566181956\n",
      "Iteration 27292 => Loss: 47.24614864161056715375\n",
      "Iteration 27293 => Loss: 47.24597828516241548868\n",
      "Iteration 27294 => Loss: 47.24580793005124945694\n",
      "Iteration 27295 => Loss: 47.24563757627699089880\n",
      "Iteration 27296 => Loss: 47.24546722383967534142\n",
      "Iteration 27297 => Loss: 47.24529687273924594137\n",
      "Iteration 27298 => Loss: 47.24512652297576664751\n",
      "Iteration 27299 => Loss: 47.24495617454914508926\n",
      "Iteration 27300 => Loss: 47.24478582745941679377\n",
      "Iteration 27301 => Loss: 47.24461548170656755019\n",
      "Iteration 27302 => Loss: 47.24444513729060446394\n",
      "Iteration 27303 => Loss: 47.24427479421145648075\n",
      "Iteration 27304 => Loss: 47.24410445246919465490\n",
      "Iteration 27305 => Loss: 47.24393411206372661582\n",
      "Iteration 27306 => Loss: 47.24376377299509499608\n",
      "Iteration 27307 => Loss: 47.24359343526328558482\n",
      "Iteration 27308 => Loss: 47.24342309886826996035\n",
      "Iteration 27309 => Loss: 47.24325276381004101722\n",
      "Iteration 27310 => Loss: 47.24308243008860586087\n",
      "Iteration 27311 => Loss: 47.24291209770393606959\n",
      "Iteration 27312 => Loss: 47.24274176665601032710\n",
      "Iteration 27313 => Loss: 47.24257143694484994967\n",
      "Iteration 27314 => Loss: 47.24240110857040519932\n",
      "Iteration 27315 => Loss: 47.24223078153272581403\n",
      "Iteration 27316 => Loss: 47.24206045583174073954\n",
      "Iteration 27317 => Loss: 47.24189013146747129213\n",
      "Iteration 27318 => Loss: 47.24171980843988905008\n",
      "Iteration 27319 => Loss: 47.24154948674900111882\n",
      "Iteration 27320 => Loss: 47.24137916639479328751\n",
      "Iteration 27321 => Loss: 47.24120884737724423985\n",
      "Iteration 27322 => Loss: 47.24103852969634687042\n",
      "Iteration 27323 => Loss: 47.24086821335208696837\n",
      "Iteration 27324 => Loss: 47.24069789834446453369\n",
      "Iteration 27325 => Loss: 47.24052758467347956639\n",
      "Iteration 27326 => Loss: 47.24035727233910364475\n",
      "Iteration 27327 => Loss: 47.24018696134131545250\n",
      "Iteration 27328 => Loss: 47.24001665168012920049\n",
      "Iteration 27329 => Loss: 47.23984634335553067785\n",
      "Iteration 27330 => Loss: 47.23967603636749856832\n",
      "Iteration 27331 => Loss: 47.23950573071601155561\n",
      "Iteration 27332 => Loss: 47.23933542640108385058\n",
      "Iteration 27333 => Loss: 47.23916512342269413693\n",
      "Iteration 27334 => Loss: 47.23899482178086373096\n",
      "Iteration 27335 => Loss: 47.23882452147549315669\n",
      "Iteration 27336 => Loss: 47.23865422250666767923\n",
      "Iteration 27337 => Loss: 47.23848392487433045517\n",
      "Iteration 27338 => Loss: 47.23831362857850280079\n",
      "Iteration 27339 => Loss: 47.23814333361912076725\n",
      "Iteration 27340 => Loss: 47.23797303999622698711\n",
      "Iteration 27341 => Loss: 47.23780274770976461696\n",
      "Iteration 27342 => Loss: 47.23763245675976207849\n",
      "Iteration 27343 => Loss: 47.23746216714620516086\n",
      "Iteration 27344 => Loss: 47.23729187886905833693\n",
      "Iteration 27345 => Loss: 47.23712159192831450127\n",
      "Iteration 27346 => Loss: 47.23695130632400207560\n",
      "Iteration 27347 => Loss: 47.23678102205605711106\n",
      "Iteration 27348 => Loss: 47.23661073912450092394\n",
      "Iteration 27349 => Loss: 47.23644045752931930338\n",
      "Iteration 27350 => Loss: 47.23627017727049093310\n",
      "Iteration 27351 => Loss: 47.23609989834800160224\n",
      "Iteration 27352 => Loss: 47.23592962076188683795\n",
      "Iteration 27353 => Loss: 47.23575934451206848053\n",
      "Iteration 27354 => Loss: 47.23558906959859626795\n",
      "Iteration 27355 => Loss: 47.23541879602144177852\n",
      "Iteration 27356 => Loss: 47.23524852378054106339\n",
      "Iteration 27357 => Loss: 47.23507825287595096597\n",
      "Iteration 27358 => Loss: 47.23490798330764306456\n",
      "Iteration 27359 => Loss: 47.23473771507560314831\n",
      "Iteration 27360 => Loss: 47.23456744817980990092\n",
      "Iteration 27361 => Loss: 47.23439718262026332241\n",
      "Iteration 27362 => Loss: 47.23422691839694209648\n",
      "Iteration 27363 => Loss: 47.23405665550986753942\n",
      "Iteration 27364 => Loss: 47.23388639395898991324\n",
      "Iteration 27365 => Loss: 47.23371613374432342880\n",
      "Iteration 27366 => Loss: 47.23354587486584676981\n",
      "Iteration 27367 => Loss: 47.23337561732356704169\n",
      "Iteration 27368 => Loss: 47.23320536111745582275\n",
      "Iteration 27369 => Loss: 47.23303510624749179669\n",
      "Iteration 27370 => Loss: 47.23286485271368206895\n",
      "Iteration 27371 => Loss: 47.23269460051602663953\n",
      "Iteration 27372 => Loss: 47.23252434965448287585\n",
      "Iteration 27373 => Loss: 47.23235410012907209421\n",
      "Iteration 27374 => Loss: 47.23218385193975166203\n",
      "Iteration 27375 => Loss: 47.23201360508655000103\n",
      "Iteration 27376 => Loss: 47.23184335956943158408\n",
      "Iteration 27377 => Loss: 47.23167311538838930574\n",
      "Iteration 27378 => Loss: 47.23150287254342316601\n",
      "Iteration 27379 => Loss: 47.23133263103449763776\n",
      "Iteration 27380 => Loss: 47.23116239086164114269\n",
      "Iteration 27381 => Loss: 47.23099215202481815368\n",
      "Iteration 27382 => Loss: 47.23082191452400024900\n",
      "Iteration 27383 => Loss: 47.23065167835920874495\n",
      "Iteration 27384 => Loss: 47.23048144353042232524\n",
      "Iteration 27385 => Loss: 47.23031121003762677901\n",
      "Iteration 27386 => Loss: 47.23014097788080789542\n",
      "Iteration 27387 => Loss: 47.22997074705997277988\n",
      "Iteration 27388 => Loss: 47.22980051757509301069\n",
      "Iteration 27389 => Loss: 47.22963028942618279871\n",
      "Iteration 27390 => Loss: 47.22946006261317819508\n",
      "Iteration 27391 => Loss: 47.22928983713614314865\n",
      "Iteration 27392 => Loss: 47.22911961299501371059\n",
      "Iteration 27393 => Loss: 47.22894939018977567002\n",
      "Iteration 27394 => Loss: 47.22877916872045034324\n",
      "Iteration 27395 => Loss: 47.22860894858702351939\n",
      "Iteration 27396 => Loss: 47.22843872978947388219\n",
      "Iteration 27397 => Loss: 47.22826851232780143164\n",
      "Iteration 27398 => Loss: 47.22809829620197064060\n",
      "Iteration 27399 => Loss: 47.22792808141198150906\n",
      "Iteration 27400 => Loss: 47.22775786795784824790\n",
      "Iteration 27401 => Loss: 47.22758765583952111911\n",
      "Iteration 27402 => Loss: 47.22741744505702854440\n",
      "Iteration 27403 => Loss: 47.22724723561032078578\n",
      "Iteration 27404 => Loss: 47.22707702749941915954\n",
      "Iteration 27405 => Loss: 47.22690682072430234939\n",
      "Iteration 27406 => Loss: 47.22673661528496324991\n",
      "Iteration 27407 => Loss: 47.22656641118137343938\n",
      "Iteration 27408 => Loss: 47.22639620841356133951\n",
      "Iteration 27409 => Loss: 47.22622600698147010689\n",
      "Iteration 27410 => Loss: 47.22605580688511395238\n",
      "Iteration 27411 => Loss: 47.22588560812449287596\n",
      "Iteration 27412 => Loss: 47.22571541069956424508\n",
      "Iteration 27413 => Loss: 47.22554521461035648144\n",
      "Iteration 27414 => Loss: 47.22537501985680563621\n",
      "Iteration 27415 => Loss: 47.22520482643896144737\n",
      "Iteration 27416 => Loss: 47.22503463435677417692\n",
      "Iteration 27417 => Loss: 47.22486444361025803573\n",
      "Iteration 27418 => Loss: 47.22469425419936328581\n",
      "Iteration 27419 => Loss: 47.22452406612413966513\n",
      "Iteration 27420 => Loss: 47.22435387938454454115\n",
      "Iteration 27421 => Loss: 47.22418369398052817587\n",
      "Iteration 27422 => Loss: 47.22401350991213320185\n",
      "Iteration 27423 => Loss: 47.22384332717934540824\n",
      "Iteration 27424 => Loss: 47.22367314578214347875\n",
      "Iteration 27425 => Loss: 47.22350296572050609711\n",
      "Iteration 27426 => Loss: 47.22333278699444747417\n",
      "Iteration 27427 => Loss: 47.22316260960393208279\n",
      "Iteration 27428 => Loss: 47.22299243354895992297\n",
      "Iteration 27429 => Loss: 47.22282225882950967843\n",
      "Iteration 27430 => Loss: 47.22265208544559556003\n",
      "Iteration 27431 => Loss: 47.22248191339719625148\n",
      "Iteration 27432 => Loss: 47.22231174268429043650\n",
      "Iteration 27433 => Loss: 47.22214157330687811509\n",
      "Iteration 27434 => Loss: 47.22197140526493797097\n",
      "Iteration 27435 => Loss: 47.22180123855849842585\n",
      "Iteration 27436 => Loss: 47.22163107318747421459\n",
      "Iteration 27437 => Loss: 47.22146090915191507520\n",
      "Iteration 27438 => Loss: 47.22129074645180679681\n",
      "Iteration 27439 => Loss: 47.22112058508712806315\n",
      "Iteration 27440 => Loss: 47.22095042505785045250\n",
      "Iteration 27441 => Loss: 47.22078026636398107030\n",
      "Iteration 27442 => Loss: 47.22061010900551281111\n",
      "Iteration 27443 => Loss: 47.22043995298243146408\n",
      "Iteration 27444 => Loss: 47.22026979829472992378\n",
      "Iteration 27445 => Loss: 47.22009964494238687394\n",
      "Iteration 27446 => Loss: 47.21992949292540231454\n",
      "Iteration 27447 => Loss: 47.21975934224376203474\n",
      "Iteration 27448 => Loss: 47.21958919289743761283\n",
      "Iteration 27449 => Loss: 47.21941904488645036508\n",
      "Iteration 27450 => Loss: 47.21924889821079318608\n",
      "Iteration 27451 => Loss: 47.21907875287040923240\n",
      "Iteration 27452 => Loss: 47.21890860886533403118\n",
      "Iteration 27453 => Loss: 47.21873846619553916071\n",
      "Iteration 27454 => Loss: 47.21856832486101041013\n",
      "Iteration 27455 => Loss: 47.21839818486174067402\n",
      "Iteration 27456 => Loss: 47.21822804619772284696\n",
      "Iteration 27457 => Loss: 47.21805790886893561265\n",
      "Iteration 27458 => Loss: 47.21788777287539318195\n",
      "Iteration 27459 => Loss: 47.21771763821706713316\n",
      "Iteration 27460 => Loss: 47.21754750489393614998\n",
      "Iteration 27461 => Loss: 47.21737737290601444329\n",
      "Iteration 27462 => Loss: 47.21720724225328069679\n",
      "Iteration 27463 => Loss: 47.21703711293572069962\n",
      "Iteration 27464 => Loss: 47.21686698495332734637\n",
      "Iteration 27465 => Loss: 47.21669685830607221533\n",
      "Iteration 27466 => Loss: 47.21652673299398372819\n",
      "Iteration 27467 => Loss: 47.21635660901701925241\n",
      "Iteration 27468 => Loss: 47.21618648637517168254\n",
      "Iteration 27469 => Loss: 47.21601636506846233488\n",
      "Iteration 27470 => Loss: 47.21584624509683436600\n",
      "Iteration 27471 => Loss: 47.21567612646031619761\n",
      "Iteration 27472 => Loss: 47.21550600915885098630\n",
      "Iteration 27473 => Loss: 47.21533589319249557548\n",
      "Iteration 27474 => Loss: 47.21516577856115048917\n",
      "Iteration 27475 => Loss: 47.21499566526491520335\n",
      "Iteration 27476 => Loss: 47.21482555330367603119\n",
      "Iteration 27477 => Loss: 47.21465544267748271068\n",
      "Iteration 27478 => Loss: 47.21448533338630682010\n",
      "Iteration 27479 => Loss: 47.21431522543014835946\n",
      "Iteration 27480 => Loss: 47.21414511880897180163\n",
      "Iteration 27481 => Loss: 47.21397501352279135745\n",
      "Iteration 27482 => Loss: 47.21380490957158571064\n",
      "Iteration 27483 => Loss: 47.21363480695536196663\n",
      "Iteration 27484 => Loss: 47.21346470567409170371\n",
      "Iteration 27485 => Loss: 47.21329460572775360561\n",
      "Iteration 27486 => Loss: 47.21312450711636898859\n",
      "Iteration 27487 => Loss: 47.21295440983988811467\n",
      "Iteration 27488 => Loss: 47.21278431389832519471\n",
      "Iteration 27489 => Loss: 47.21261421929166601785\n",
      "Iteration 27490 => Loss: 47.21244412601991058409\n",
      "Iteration 27491 => Loss: 47.21227403408303757715\n",
      "Iteration 27492 => Loss: 47.21210394348103278617\n",
      "Iteration 27493 => Loss: 47.21193385421387489487\n",
      "Iteration 27494 => Loss: 47.21176376628159232496\n",
      "Iteration 27495 => Loss: 47.21159367968414244388\n",
      "Iteration 27496 => Loss: 47.21142359442151814619\n",
      "Iteration 27497 => Loss: 47.21125351049373364276\n",
      "Iteration 27498 => Loss: 47.21108342790072498474\n",
      "Iteration 27499 => Loss: 47.21091334664255612097\n",
      "Iteration 27500 => Loss: 47.21074326671914178633\n",
      "Iteration 27501 => Loss: 47.21057318813051750794\n",
      "Iteration 27502 => Loss: 47.21040311087666196954\n",
      "Iteration 27503 => Loss: 47.21023303495756096027\n",
      "Iteration 27504 => Loss: 47.21006296037320026926\n",
      "Iteration 27505 => Loss: 47.20989288712360831823\n",
      "Iteration 27506 => Loss: 47.20972281520870694749\n",
      "Iteration 27507 => Loss: 47.20955274462853168416\n",
      "Iteration 27508 => Loss: 47.20938267538306121196\n",
      "Iteration 27509 => Loss: 47.20921260747228842547\n",
      "Iteration 27510 => Loss: 47.20904254089620621926\n",
      "Iteration 27511 => Loss: 47.20887247565477196076\n",
      "Iteration 27512 => Loss: 47.20870241174803538797\n",
      "Iteration 27513 => Loss: 47.20853234917591123576\n",
      "Iteration 27514 => Loss: 47.20836228793848476926\n",
      "Iteration 27515 => Loss: 47.20819222803563519619\n",
      "Iteration 27516 => Loss: 47.20802216946741935999\n",
      "Iteration 27517 => Loss: 47.20785211223385147150\n",
      "Iteration 27518 => Loss: 47.20768205633485337103\n",
      "Iteration 27519 => Loss: 47.20751200177044637485\n",
      "Iteration 27520 => Loss: 47.20734194854061627211\n",
      "Iteration 27521 => Loss: 47.20717189664537016824\n",
      "Iteration 27522 => Loss: 47.20700184608465121983\n",
      "Iteration 27523 => Loss: 47.20683179685850205942\n",
      "Iteration 27524 => Loss: 47.20666174896688715990\n",
      "Iteration 27525 => Loss: 47.20649170240979941582\n",
      "Iteration 27526 => Loss: 47.20632165718723882719\n",
      "Iteration 27527 => Loss: 47.20615161329916276145\n",
      "Iteration 27528 => Loss: 47.20598157074560674573\n",
      "Iteration 27529 => Loss: 47.20581152952650683119\n",
      "Iteration 27530 => Loss: 47.20564148964189854496\n",
      "Iteration 27531 => Loss: 47.20547145109175346533\n",
      "Iteration 27532 => Loss: 47.20530141387607159231\n",
      "Iteration 27533 => Loss: 47.20513137799483160961\n",
      "Iteration 27534 => Loss: 47.20496134344801930638\n",
      "Iteration 27535 => Loss: 47.20479131023562047176\n",
      "Iteration 27536 => Loss: 47.20462127835762800032\n",
      "Iteration 27537 => Loss: 47.20445124781404189207\n",
      "Iteration 27538 => Loss: 47.20428121860484793615\n",
      "Iteration 27539 => Loss: 47.20411119073003902713\n",
      "Iteration 27540 => Loss: 47.20394116418958674330\n",
      "Iteration 27541 => Loss: 47.20377113898352661181\n",
      "Iteration 27542 => Loss: 47.20360111511178757837\n",
      "Iteration 27543 => Loss: 47.20343109257438385384\n",
      "Iteration 27544 => Loss: 47.20326107137132254365\n",
      "Iteration 27545 => Loss: 47.20309105150257522610\n",
      "Iteration 27546 => Loss: 47.20292103296814190116\n",
      "Iteration 27547 => Loss: 47.20275101576798704173\n",
      "Iteration 27548 => Loss: 47.20258099990213196406\n",
      "Iteration 27549 => Loss: 47.20241098537055535189\n",
      "Iteration 27550 => Loss: 47.20224097217322878350\n",
      "Iteration 27551 => Loss: 47.20207096031015936433\n",
      "Iteration 27552 => Loss: 47.20190094978133998893\n",
      "Iteration 27553 => Loss: 47.20173094058677065732\n",
      "Iteration 27554 => Loss: 47.20156093272639452607\n",
      "Iteration 27555 => Loss: 47.20139092620025422775\n",
      "Iteration 27556 => Loss: 47.20122092100830002437\n",
      "Iteration 27557 => Loss: 47.20105091715054612678\n",
      "Iteration 27558 => Loss: 47.20088091462697121869\n",
      "Iteration 27559 => Loss: 47.20071091343756108927\n",
      "Iteration 27560 => Loss: 47.20054091358231573849\n",
      "Iteration 27561 => Loss: 47.20037091506124227180\n",
      "Iteration 27562 => Loss: 47.20020091787427674035\n",
      "Iteration 27563 => Loss: 47.20003092202144046041\n",
      "Iteration 27564 => Loss: 47.19986092750274053742\n",
      "Iteration 27565 => Loss: 47.19969093431814144424\n",
      "Iteration 27566 => Loss: 47.19952094246764318086\n",
      "Iteration 27567 => Loss: 47.19935095195122443101\n",
      "Iteration 27568 => Loss: 47.19918096276887808926\n",
      "Iteration 27569 => Loss: 47.19901097492061126104\n",
      "Iteration 27570 => Loss: 47.19884098840640973549\n",
      "Iteration 27571 => Loss: 47.19867100322622377462\n",
      "Iteration 27572 => Loss: 47.19850101938009601099\n",
      "Iteration 27573 => Loss: 47.19833103686797670662\n",
      "Iteration 27574 => Loss: 47.19816105568989428320\n",
      "Iteration 27575 => Loss: 47.19799107584580610819\n",
      "Iteration 27576 => Loss: 47.19782109733569086529\n",
      "Iteration 27577 => Loss: 47.19765112015957697622\n",
      "Iteration 27578 => Loss: 47.19748114431742891384\n",
      "Iteration 27579 => Loss: 47.19731116980923957271\n",
      "Iteration 27580 => Loss: 47.19714119663500184743\n",
      "Iteration 27581 => Loss: 47.19697122479470863254\n",
      "Iteration 27582 => Loss: 47.19680125428835282264\n",
      "Iteration 27583 => Loss: 47.19663128511590599601\n",
      "Iteration 27584 => Loss: 47.19646131727736104722\n",
      "Iteration 27585 => Loss: 47.19629135077273218712\n",
      "Iteration 27586 => Loss: 47.19612138560197678316\n",
      "Iteration 27587 => Loss: 47.19595142176511615162\n",
      "Iteration 27588 => Loss: 47.19578145926210765992\n",
      "Iteration 27589 => Loss: 47.19561149809295841351\n",
      "Iteration 27590 => Loss: 47.19544153825765420152\n",
      "Iteration 27591 => Loss: 47.19527157975618791852\n",
      "Iteration 27592 => Loss: 47.19510162258855956452\n",
      "Iteration 27593 => Loss: 47.19493166675472650695\n",
      "Iteration 27594 => Loss: 47.19476171225471716753\n",
      "Iteration 27595 => Loss: 47.19459175908849601910\n",
      "Iteration 27596 => Loss: 47.19442180725604174540\n",
      "Iteration 27597 => Loss: 47.19425185675736855728\n",
      "Iteration 27598 => Loss: 47.19408190759246224388\n",
      "Iteration 27599 => Loss: 47.19391195976131569978\n",
      "Iteration 27600 => Loss: 47.19374201326390760869\n",
      "Iteration 27601 => Loss: 47.19357206810023086518\n",
      "Iteration 27602 => Loss: 47.19340212427024994213\n",
      "Iteration 27603 => Loss: 47.19323218177401457751\n",
      "Iteration 27604 => Loss: 47.19306224061143950621\n",
      "Iteration 27605 => Loss: 47.19289230078260288792\n",
      "Iteration 27606 => Loss: 47.19272236228739814123\n",
      "Iteration 27607 => Loss: 47.19255242512588210957\n",
      "Iteration 27608 => Loss: 47.19238248929803347664\n",
      "Iteration 27609 => Loss: 47.19221255480383092618\n",
      "Iteration 27610 => Loss: 47.19204262164325314188\n",
      "Iteration 27611 => Loss: 47.19187268981630722919\n",
      "Iteration 27612 => Loss: 47.19170275932296476640\n",
      "Iteration 27613 => Loss: 47.19153283016324706978\n",
      "Iteration 27614 => Loss: 47.19136290233712571762\n",
      "Iteration 27615 => Loss: 47.19119297584458649908\n",
      "Iteration 27616 => Loss: 47.19102305068560809787\n",
      "Iteration 27617 => Loss: 47.19085312686019761941\n",
      "Iteration 27618 => Loss: 47.19068320436834795828\n",
      "Iteration 27619 => Loss: 47.19051328321003779820\n",
      "Iteration 27620 => Loss: 47.19034336338526003374\n",
      "Iteration 27621 => Loss: 47.19017344489398624319\n",
      "Iteration 27622 => Loss: 47.19000352773625195368\n",
      "Iteration 27623 => Loss: 47.18983361191200032181\n",
      "Iteration 27624 => Loss: 47.18966369742124555842\n",
      "Iteration 27625 => Loss: 47.18949378426398055808\n",
      "Iteration 27626 => Loss: 47.18932387244017689909\n",
      "Iteration 27627 => Loss: 47.18915396194982747602\n",
      "Iteration 27628 => Loss: 47.18898405279294649972\n",
      "Iteration 27629 => Loss: 47.18881414496949133763\n",
      "Iteration 27630 => Loss: 47.18864423847943356805\n",
      "Iteration 27631 => Loss: 47.18847433332282292895\n",
      "Iteration 27632 => Loss: 47.18830442949961678778\n",
      "Iteration 27633 => Loss: 47.18813452700980803911\n",
      "Iteration 27634 => Loss: 47.18796462585338957751\n",
      "Iteration 27635 => Loss: 47.18779472603034008671\n",
      "Iteration 27636 => Loss: 47.18762482754065956669\n",
      "Iteration 27637 => Loss: 47.18745493038432670119\n",
      "Iteration 27638 => Loss: 47.18728503456132017391\n",
      "Iteration 27639 => Loss: 47.18711514007167551199\n",
      "Iteration 27640 => Loss: 47.18694524691534297745\n",
      "Iteration 27641 => Loss: 47.18677535509233678113\n",
      "Iteration 27642 => Loss: 47.18660546460261429047\n",
      "Iteration 27643 => Loss: 47.18643557544618971633\n",
      "Iteration 27644 => Loss: 47.18626568762303463700\n",
      "Iteration 27645 => Loss: 47.18609580113317747418\n",
      "Iteration 27646 => Loss: 47.18592591597655427904\n",
      "Iteration 27647 => Loss: 47.18575603215320768413\n",
      "Iteration 27648 => Loss: 47.18558614966308084604\n",
      "Iteration 27649 => Loss: 47.18541626850618087019\n",
      "Iteration 27650 => Loss: 47.18524638868250065116\n",
      "Iteration 27651 => Loss: 47.18507651019202597809\n",
      "Iteration 27652 => Loss: 47.18490663303477106183\n",
      "Iteration 27653 => Loss: 47.18473675721068616440\n",
      "Iteration 27654 => Loss: 47.18456688271977128579\n",
      "Iteration 27655 => Loss: 47.18439700956204774229\n",
      "Iteration 27656 => Loss: 47.18422713773745158505\n",
      "Iteration 27657 => Loss: 47.18405726724600413036\n",
      "Iteration 27658 => Loss: 47.18388739808771248363\n",
      "Iteration 27659 => Loss: 47.18371753026252690688\n",
      "Iteration 27660 => Loss: 47.18354766377044029468\n",
      "Iteration 27661 => Loss: 47.18337779861148817417\n",
      "Iteration 27662 => Loss: 47.18320793478562080736\n",
      "Iteration 27663 => Loss: 47.18303807229281687796\n",
      "Iteration 27664 => Loss: 47.18286821113310480769\n",
      "Iteration 27665 => Loss: 47.18269835130645617483\n",
      "Iteration 27666 => Loss: 47.18252849281284966310\n",
      "Iteration 27667 => Loss: 47.18235863565228527250\n",
      "Iteration 27668 => Loss: 47.18218877982474168675\n",
      "Iteration 27669 => Loss: 47.18201892533024022214\n",
      "Iteration 27670 => Loss: 47.18184907216873114066\n",
      "Iteration 27671 => Loss: 47.18167922034023575861\n",
      "Iteration 27672 => Loss: 47.18150936984471144342\n",
      "Iteration 27673 => Loss: 47.18133952068217240594\n",
      "Iteration 27674 => Loss: 47.18116967285259732989\n",
      "Iteration 27675 => Loss: 47.18099982635597910985\n",
      "Iteration 27676 => Loss: 47.18082998119229642953\n",
      "Iteration 27677 => Loss: 47.18066013736156349978\n",
      "Iteration 27678 => Loss: 47.18049029486375900433\n",
      "Iteration 27679 => Loss: 47.18032045369887583774\n",
      "Iteration 27680 => Loss: 47.18015061386686426204\n",
      "Iteration 27681 => Loss: 47.17998077536778112062\n",
      "Iteration 27682 => Loss: 47.17981093820156957008\n",
      "Iteration 27683 => Loss: 47.17964110236822250499\n",
      "Iteration 27684 => Loss: 47.17947126786773992535\n",
      "Iteration 27685 => Loss: 47.17930143470014314744\n",
      "Iteration 27686 => Loss: 47.17913160286535401156\n",
      "Iteration 27687 => Loss: 47.17896177236339383398\n",
      "Iteration 27688 => Loss: 47.17879194319426261472\n",
      "Iteration 27689 => Loss: 47.17862211535793903749\n",
      "Iteration 27690 => Loss: 47.17845228885442310229\n",
      "Iteration 27691 => Loss: 47.17828246368369349284\n",
      "Iteration 27692 => Loss: 47.17811263984573599828\n",
      "Iteration 27693 => Loss: 47.17794281734058614575\n",
      "Iteration 27694 => Loss: 47.17777299616813735383\n",
      "Iteration 27695 => Loss: 47.17760317632844646596\n",
      "Iteration 27696 => Loss: 47.17743335782152769298\n",
      "Iteration 27697 => Loss: 47.17726354064730287519\n",
      "Iteration 27698 => Loss: 47.17709372480580753972\n",
      "Iteration 27699 => Loss: 47.17692391029701326488\n",
      "Iteration 27700 => Loss: 47.17675409712092005066\n",
      "Iteration 27701 => Loss: 47.17658428527749947534\n",
      "Iteration 27702 => Loss: 47.17641447476677285522\n",
      "Iteration 27703 => Loss: 47.17624466558868334687\n",
      "Iteration 27704 => Loss: 47.17607485774327358286\n",
      "Iteration 27705 => Loss: 47.17590505123050093061\n",
      "Iteration 27706 => Loss: 47.17573524605034407386\n",
      "Iteration 27707 => Loss: 47.17556544220283853974\n",
      "Iteration 27708 => Loss: 47.17539563968792748483\n",
      "Iteration 27709 => Loss: 47.17522583850561801455\n",
      "Iteration 27710 => Loss: 47.17505603865590302348\n",
      "Iteration 27711 => Loss: 47.17488624013875408991\n",
      "Iteration 27712 => Loss: 47.17471644295419253012\n",
      "Iteration 27713 => Loss: 47.17454664710217571155\n",
      "Iteration 27714 => Loss: 47.17437685258273916133\n",
      "Iteration 27715 => Loss: 47.17420705939579761434\n",
      "Iteration 27716 => Loss: 47.17403726754140791400\n",
      "Iteration 27717 => Loss: 47.17386747701952032230\n",
      "Iteration 27718 => Loss: 47.17369768783016326097\n",
      "Iteration 27719 => Loss: 47.17352789997327278115\n",
      "Iteration 27720 => Loss: 47.17335811344889862085\n",
      "Iteration 27721 => Loss: 47.17318832825699814748\n",
      "Iteration 27722 => Loss: 47.17301854439755004478\n",
      "Iteration 27723 => Loss: 47.17284876187056141816\n",
      "Iteration 27724 => Loss: 47.17267898067601095136\n",
      "Iteration 27725 => Loss: 47.17250920081390574978\n",
      "Iteration 27726 => Loss: 47.17233942228421028631\n",
      "Iteration 27727 => Loss: 47.17216964508694587721\n",
      "Iteration 27728 => Loss: 47.17199986922205567907\n",
      "Iteration 27729 => Loss: 47.17183009468958942989\n",
      "Iteration 27730 => Loss: 47.17166032148949028624\n",
      "Iteration 27731 => Loss: 47.17149054962175114269\n",
      "Iteration 27732 => Loss: 47.17132077908640042097\n",
      "Iteration 27733 => Loss: 47.17115100988337417220\n",
      "Iteration 27734 => Loss: 47.17098124201270792355\n",
      "Iteration 27735 => Loss: 47.17081147547433772615\n",
      "Iteration 27736 => Loss: 47.17064171026830621258\n",
      "Iteration 27737 => Loss: 47.17047194639457785570\n",
      "Iteration 27738 => Loss: 47.17030218385317397178\n",
      "Iteration 27739 => Loss: 47.17013242264402350656\n",
      "Iteration 27740 => Loss: 47.16996266276716198718\n",
      "Iteration 27741 => Loss: 47.16979290422257520277\n",
      "Iteration 27742 => Loss: 47.16962314701024894248\n",
      "Iteration 27743 => Loss: 47.16945339113014057375\n",
      "Iteration 27744 => Loss: 47.16928363658229272914\n",
      "Iteration 27745 => Loss: 47.16911388336667698695\n",
      "Iteration 27746 => Loss: 47.16894413148323650375\n",
      "Iteration 27747 => Loss: 47.16877438093204233382\n",
      "Iteration 27748 => Loss: 47.16860463171300921204\n",
      "Iteration 27749 => Loss: 47.16843488382617266552\n",
      "Iteration 27750 => Loss: 47.16826513727151137800\n",
      "Iteration 27751 => Loss: 47.16809539204901824405\n",
      "Iteration 27752 => Loss: 47.16792564815866484196\n",
      "Iteration 27753 => Loss: 47.16775590560045827715\n",
      "Iteration 27754 => Loss: 47.16758616437438433877\n",
      "Iteration 27755 => Loss: 47.16741642448042171054\n",
      "Iteration 27756 => Loss: 47.16724668591857749789\n",
      "Iteration 27757 => Loss: 47.16707694868882327910\n",
      "Iteration 27758 => Loss: 47.16690721279116615960\n",
      "Iteration 27759 => Loss: 47.16673747822557061227\n",
      "Iteration 27760 => Loss: 47.16656774499205795337\n",
      "Iteration 27761 => Loss: 47.16639801309059976120\n",
      "Iteration 27762 => Loss: 47.16622828252119603576\n",
      "Iteration 27763 => Loss: 47.16605855328381835534\n",
      "Iteration 27764 => Loss: 47.16588882537848093079\n",
      "Iteration 27765 => Loss: 47.16571909880514112956\n",
      "Iteration 27766 => Loss: 47.16554937356382026792\n",
      "Iteration 27767 => Loss: 47.16537964965448992416\n",
      "Iteration 27768 => Loss: 47.16520992707714299286\n",
      "Iteration 27769 => Loss: 47.16504020583177236858\n",
      "Iteration 27770 => Loss: 47.16487048591837805134\n",
      "Iteration 27771 => Loss: 47.16470076733690319770\n",
      "Iteration 27772 => Loss: 47.16453105008740465109\n",
      "Iteration 27773 => Loss: 47.16436133416981135724\n",
      "Iteration 27774 => Loss: 47.16419161958415884328\n",
      "Iteration 27775 => Loss: 47.16402190633039737122\n",
      "Iteration 27776 => Loss: 47.16385219440854115192\n",
      "Iteration 27777 => Loss: 47.16368248381859018536\n",
      "Iteration 27778 => Loss: 47.16351277456050894443\n",
      "Iteration 27779 => Loss: 47.16334306663432585083\n",
      "Iteration 27780 => Loss: 47.16317336003994853399\n",
      "Iteration 27781 => Loss: 47.16300365477745515363\n",
      "Iteration 27782 => Loss: 47.16283395084679597176\n",
      "Iteration 27783 => Loss: 47.16266424824796388293\n",
      "Iteration 27784 => Loss: 47.16249454698093046545\n",
      "Iteration 27785 => Loss: 47.16232484704571703560\n",
      "Iteration 27786 => Loss: 47.16215514844229517166\n",
      "Iteration 27787 => Loss: 47.16198545117067197907\n",
      "Iteration 27788 => Loss: 47.16181575523080482526\n",
      "Iteration 27789 => Loss: 47.16164606062272923737\n",
      "Iteration 27790 => Loss: 47.16147636734638837197\n",
      "Iteration 27791 => Loss: 47.16130667540179643993\n",
      "Iteration 27792 => Loss: 47.16113698478895344124\n",
      "Iteration 27793 => Loss: 47.16096729550780253248\n",
      "Iteration 27794 => Loss: 47.16079760755837213537\n",
      "Iteration 27795 => Loss: 47.16062792094065514448\n",
      "Iteration 27796 => Loss: 47.16045823565461603266\n",
      "Iteration 27797 => Loss: 47.16028855170027611621\n",
      "Iteration 27798 => Loss: 47.16011886907758565712\n",
      "Iteration 27799 => Loss: 47.15994918778658018255\n",
      "Iteration 27800 => Loss: 47.15977950782720284906\n",
      "Iteration 27801 => Loss: 47.15960982919946786751\n",
      "Iteration 27802 => Loss: 47.15944015190336813248\n",
      "Iteration 27803 => Loss: 47.15927047593888943311\n",
      "Iteration 27804 => Loss: 47.15910080130601045312\n",
      "Iteration 27805 => Loss: 47.15893112800473829793\n",
      "Iteration 27806 => Loss: 47.15876145603504454584\n",
      "Iteration 27807 => Loss: 47.15859178539695051313\n",
      "Iteration 27808 => Loss: 47.15842211609039935638\n",
      "Iteration 27809 => Loss: 47.15825244811541239187\n",
      "Iteration 27810 => Loss: 47.15808278147196830332\n",
      "Iteration 27811 => Loss: 47.15791311616005287988\n",
      "Iteration 27812 => Loss: 47.15774345217966612154\n",
      "Iteration 27813 => Loss: 47.15757378953080802830\n",
      "Iteration 27814 => Loss: 47.15740412821342886218\n",
      "Iteration 27815 => Loss: 47.15723446822755704488\n",
      "Iteration 27816 => Loss: 47.15706480957316415470\n",
      "Iteration 27817 => Loss: 47.15689515225024308620\n",
      "Iteration 27818 => Loss: 47.15672549625878673396\n",
      "Iteration 27819 => Loss: 47.15655584159878088713\n",
      "Iteration 27820 => Loss: 47.15638618827021133484\n",
      "Iteration 27821 => Loss: 47.15621653627305676082\n",
      "Iteration 27822 => Loss: 47.15604688560735979763\n",
      "Iteration 27823 => Loss: 47.15587723627304939100\n",
      "Iteration 27824 => Loss: 47.15570758827013975178\n",
      "Iteration 27825 => Loss: 47.15553794159861666913\n",
      "Iteration 27826 => Loss: 47.15536829625849435388\n",
      "Iteration 27827 => Loss: 47.15519865224971596263\n",
      "Iteration 27828 => Loss: 47.15502900957229570622\n",
      "Iteration 27829 => Loss: 47.15485936822624779552\n",
      "Iteration 27830 => Loss: 47.15468972821149407082\n",
      "Iteration 27831 => Loss: 47.15452008952808427011\n",
      "Iteration 27832 => Loss: 47.15435045217600418255\n",
      "Iteration 27833 => Loss: 47.15418081615520407013\n",
      "Iteration 27834 => Loss: 47.15401118146571945999\n",
      "Iteration 27835 => Loss: 47.15384154810750061415\n",
      "Iteration 27836 => Loss: 47.15367191608058305974\n",
      "Iteration 27837 => Loss: 47.15350228538490995334\n",
      "Iteration 27838 => Loss: 47.15333265602050261123\n",
      "Iteration 27839 => Loss: 47.15316302798731840085\n",
      "Iteration 27840 => Loss: 47.15299340128535732219\n",
      "Iteration 27841 => Loss: 47.15282377591463358613\n",
      "Iteration 27842 => Loss: 47.15265415187513298179\n",
      "Iteration 27843 => Loss: 47.15248452916680577118\n",
      "Iteration 27844 => Loss: 47.15231490778970169231\n",
      "Iteration 27845 => Loss: 47.15214528774377100717\n",
      "Iteration 27846 => Loss: 47.15197566902899950492\n",
      "Iteration 27847 => Loss: 47.15180605164538008012\n",
      "Iteration 27848 => Loss: 47.15163643559290562735\n",
      "Iteration 27849 => Loss: 47.15146682087159035746\n",
      "Iteration 27850 => Loss: 47.15129720748139163788\n",
      "Iteration 27851 => Loss: 47.15112759542230946863\n",
      "Iteration 27852 => Loss: 47.15095798469432253341\n",
      "Iteration 27853 => Loss: 47.15078837529744504309\n",
      "Iteration 27854 => Loss: 47.15061876723165568137\n",
      "Iteration 27855 => Loss: 47.15044916049694023741\n",
      "Iteration 27856 => Loss: 47.15027955509329160577\n",
      "Iteration 27857 => Loss: 47.15010995102067425933\n",
      "Iteration 27858 => Loss: 47.14994034827912372521\n",
      "Iteration 27859 => Loss: 47.14977074686860447628\n",
      "Iteration 27860 => Loss: 47.14960114678910230168\n",
      "Iteration 27861 => Loss: 47.14943154804062430685\n",
      "Iteration 27862 => Loss: 47.14926195062312785922\n",
      "Iteration 27863 => Loss: 47.14909235453662716964\n",
      "Iteration 27864 => Loss: 47.14892275978110802725\n",
      "Iteration 27865 => Loss: 47.14875316635657043207\n",
      "Iteration 27866 => Loss: 47.14858357426299306780\n",
      "Iteration 27867 => Loss: 47.14841398350036172360\n",
      "Iteration 27868 => Loss: 47.14824439406866218860\n",
      "Iteration 27869 => Loss: 47.14807480596791577909\n",
      "Iteration 27870 => Loss: 47.14790521919805144080\n",
      "Iteration 27871 => Loss: 47.14773563375912601714\n",
      "Iteration 27872 => Loss: 47.14756604965108266470\n",
      "Iteration 27873 => Loss: 47.14739646687393559432\n",
      "Iteration 27874 => Loss: 47.14722688542767059516\n",
      "Iteration 27875 => Loss: 47.14705730531225214008\n",
      "Iteration 27876 => Loss: 47.14688772652770154536\n",
      "Iteration 27877 => Loss: 47.14671814907398328387\n",
      "Iteration 27878 => Loss: 47.14654857295111156645\n",
      "Iteration 27879 => Loss: 47.14637899815905797141\n",
      "Iteration 27880 => Loss: 47.14620942469781539330\n",
      "Iteration 27881 => Loss: 47.14603985256739093757\n",
      "Iteration 27882 => Loss: 47.14587028176774197163\n",
      "Iteration 27883 => Loss: 47.14570071229889691722\n",
      "Iteration 27884 => Loss: 47.14553114416082024718\n",
      "Iteration 27885 => Loss: 47.14536157735349064524\n",
      "Iteration 27886 => Loss: 47.14519201187691521682\n",
      "Iteration 27887 => Loss: 47.14502244773109396192\n",
      "Iteration 27888 => Loss: 47.14485288491599135341\n",
      "Iteration 27889 => Loss: 47.14468332343160739129\n",
      "Iteration 27890 => Loss: 47.14451376327795628640\n",
      "Iteration 27891 => Loss: 47.14434420445497408991\n",
      "Iteration 27892 => Loss: 47.14417464696269632896\n",
      "Iteration 27893 => Loss: 47.14400509080108747639\n",
      "Iteration 27894 => Loss: 47.14383553597015463765\n",
      "Iteration 27895 => Loss: 47.14366598246986228560\n",
      "Iteration 27896 => Loss: 47.14349643030024594736\n",
      "Iteration 27897 => Loss: 47.14332687946124877953\n",
      "Iteration 27898 => Loss: 47.14315732995287788754\n",
      "Iteration 27899 => Loss: 47.14298778177514748222\n",
      "Iteration 27900 => Loss: 47.14281823492797940389\n",
      "Iteration 27901 => Loss: 47.14264868941143049597\n",
      "Iteration 27902 => Loss: 47.14247914522546523131\n",
      "Iteration 27903 => Loss: 47.14230960237006939906\n",
      "Iteration 27904 => Loss: 47.14214006084524299922\n",
      "Iteration 27905 => Loss: 47.14197052065095761009\n",
      "Iteration 27906 => Loss: 47.14180098178722033708\n",
      "Iteration 27907 => Loss: 47.14163144425401696935\n",
      "Iteration 27908 => Loss: 47.14146190805133329604\n",
      "Iteration 27909 => Loss: 47.14129237317916221173\n",
      "Iteration 27910 => Loss: 47.14112283963749661098\n",
      "Iteration 27911 => Loss: 47.14095330742632228294\n",
      "Iteration 27912 => Loss: 47.14078377654561080590\n",
      "Iteration 27913 => Loss: 47.14061424699538349614\n",
      "Iteration 27914 => Loss: 47.14044471877561903739\n",
      "Iteration 27915 => Loss: 47.14027519188630321878\n",
      "Iteration 27916 => Loss: 47.14010566632740761861\n",
      "Iteration 27917 => Loss: 47.13993614209895355316\n",
      "Iteration 27918 => Loss: 47.13976661920089128444\n",
      "Iteration 27919 => Loss: 47.13959709763326344500\n",
      "Iteration 27920 => Loss: 47.13942757739602740230\n",
      "Iteration 27921 => Loss: 47.13925805848917605090\n",
      "Iteration 27922 => Loss: 47.13908854091271649622\n",
      "Iteration 27923 => Loss: 47.13891902466661321114\n",
      "Iteration 27924 => Loss: 47.13874950975083777394\n",
      "Iteration 27925 => Loss: 47.13857999616544702803\n",
      "Iteration 27926 => Loss: 47.13841048391034860288\n",
      "Iteration 27927 => Loss: 47.13824097298559934188\n",
      "Iteration 27928 => Loss: 47.13807146339115661249\n",
      "Iteration 27929 => Loss: 47.13790195512701330927\n",
      "Iteration 27930 => Loss: 47.13773244819316943222\n",
      "Iteration 27931 => Loss: 47.13756294258958945420\n",
      "Iteration 27932 => Loss: 47.13739343831630890236\n",
      "Iteration 27933 => Loss: 47.13722393537327803870\n",
      "Iteration 27934 => Loss: 47.13705443376048975779\n",
      "Iteration 27935 => Loss: 47.13688493347793695420\n",
      "Iteration 27936 => Loss: 47.13671543452561962795\n",
      "Iteration 27937 => Loss: 47.13654593690353067359\n",
      "Iteration 27938 => Loss: 47.13637644061163456399\n",
      "Iteration 27939 => Loss: 47.13620694564993129916\n",
      "Iteration 27940 => Loss: 47.13603745201844219537\n",
      "Iteration 27941 => Loss: 47.13586795971711751463\n",
      "Iteration 27942 => Loss: 47.13569846874596436237\n",
      "Iteration 27943 => Loss: 47.13552897910495431688\n",
      "Iteration 27944 => Loss: 47.13535949079410869444\n",
      "Iteration 27945 => Loss: 47.13519000381335644079\n",
      "Iteration 27946 => Loss: 47.13502051816277571561\n",
      "Iteration 27947 => Loss: 47.13485103384230967549\n",
      "Iteration 27948 => Loss: 47.13468155085192989873\n",
      "Iteration 27949 => Loss: 47.13451206919163638531\n",
      "Iteration 27950 => Loss: 47.13434258886142913525\n",
      "Iteration 27951 => Loss: 47.13417310986131525397\n",
      "Iteration 27952 => Loss: 47.13400363219123079261\n",
      "Iteration 27953 => Loss: 47.13383415585123259461\n",
      "Iteration 27954 => Loss: 47.13366468084125671112\n",
      "Iteration 27955 => Loss: 47.13349520716131024756\n",
      "Iteration 27956 => Loss: 47.13332573481137899307\n",
      "Iteration 27957 => Loss: 47.13315626379145584224\n",
      "Iteration 27958 => Loss: 47.13298679410156211134\n",
      "Iteration 27959 => Loss: 47.13281732574164095695\n",
      "Iteration 27960 => Loss: 47.13264785871169948450\n",
      "Iteration 27961 => Loss: 47.13247839301170927229\n",
      "Iteration 27962 => Loss: 47.13230892864168453116\n",
      "Iteration 27963 => Loss: 47.13213946560161815569\n",
      "Iteration 27964 => Loss: 47.13197000389149593502\n",
      "Iteration 27965 => Loss: 47.13180054351126813117\n",
      "Iteration 27966 => Loss: 47.13163108446099158755\n",
      "Iteration 27967 => Loss: 47.13146162674060235531\n",
      "Iteration 27968 => Loss: 47.13129217035011464532\n",
      "Iteration 27969 => Loss: 47.13112271528950714128\n",
      "Iteration 27970 => Loss: 47.13095326155878694863\n",
      "Iteration 27971 => Loss: 47.13078380915791854022\n",
      "Iteration 27972 => Loss: 47.13061435808690902149\n",
      "Iteration 27973 => Loss: 47.13044490834572286531\n",
      "Iteration 27974 => Loss: 47.13027545993438849337\n",
      "Iteration 27975 => Loss: 47.13010601285289169482\n",
      "Iteration 27976 => Loss: 47.12993656710117562625\n",
      "Iteration 27977 => Loss: 47.12976712267928292022\n",
      "Iteration 27978 => Loss: 47.12959767958716383873\n",
      "Iteration 27979 => Loss: 47.12942823782483259265\n",
      "Iteration 27980 => Loss: 47.12925879739225365483\n",
      "Iteration 27981 => Loss: 47.12908935828946965785\n",
      "Iteration 27982 => Loss: 47.12891992051640954742\n",
      "Iteration 27983 => Loss: 47.12875048407309463983\n",
      "Iteration 27984 => Loss: 47.12858104895951782964\n",
      "Iteration 27985 => Loss: 47.12841161517565780059\n",
      "Iteration 27986 => Loss: 47.12824218272147902553\n",
      "Iteration 27987 => Loss: 47.12807275159703124245\n",
      "Iteration 27988 => Loss: 47.12790332180223629166\n",
      "Iteration 27989 => Loss: 47.12773389333715101657\n",
      "Iteration 27990 => Loss: 47.12756446620169725747\n",
      "Iteration 27991 => Loss: 47.12739504039594606866\n",
      "Iteration 27992 => Loss: 47.12722561591979797413\n",
      "Iteration 27993 => Loss: 47.12705619277330271188\n",
      "Iteration 27994 => Loss: 47.12688677095641054393\n",
      "Iteration 27995 => Loss: 47.12671735046914989198\n",
      "Iteration 27996 => Loss: 47.12654793131148522889\n",
      "Iteration 27997 => Loss: 47.12637851348341655466\n",
      "Iteration 27998 => Loss: 47.12620909698495808016\n",
      "Iteration 27999 => Loss: 47.12603968181603164567\n",
      "Iteration 28000 => Loss: 47.12587026797669409461\n",
      "Iteration 28001 => Loss: 47.12570085546687437272\n",
      "Iteration 28002 => Loss: 47.12553144428662221799\n",
      "Iteration 28003 => Loss: 47.12536203443588078699\n",
      "Iteration 28004 => Loss: 47.12519262591466429058\n",
      "Iteration 28005 => Loss: 47.12502321872297983418\n",
      "Iteration 28006 => Loss: 47.12485381286076346896\n",
      "Iteration 28007 => Loss: 47.12468440832805072205\n",
      "Iteration 28008 => Loss: 47.12451500512482027716\n",
      "Iteration 28009 => Loss: 47.12434560325102950173\n",
      "Iteration 28010 => Loss: 47.12417620270673523919\n",
      "Iteration 28011 => Loss: 47.12400680349187354068\n",
      "Iteration 28012 => Loss: 47.12383740560644440620\n",
      "Iteration 28013 => Loss: 47.12366800905043362491\n",
      "Iteration 28014 => Loss: 47.12349861382385540765\n",
      "Iteration 28015 => Loss: 47.12332921992666001643\n",
      "Iteration 28016 => Loss: 47.12315982735885455668\n",
      "Iteration 28017 => Loss: 47.12299043612047455554\n",
      "Iteration 28018 => Loss: 47.12282104621142764245\n",
      "Iteration 28019 => Loss: 47.12265165763177776626\n",
      "Iteration 28020 => Loss: 47.12248227038145387269\n",
      "Iteration 28021 => Loss: 47.12231288446047727803\n",
      "Iteration 28022 => Loss: 47.12214349986882666599\n",
      "Iteration 28023 => Loss: 47.12197411660650203657\n",
      "Iteration 28024 => Loss: 47.12180473467347496808\n",
      "Iteration 28025 => Loss: 47.12163535406978809306\n",
      "Iteration 28026 => Loss: 47.12146597479537035724\n",
      "Iteration 28027 => Loss: 47.12129659685022176063\n",
      "Iteration 28028 => Loss: 47.12112722023434230323\n",
      "Iteration 28029 => Loss: 47.12095784494773198503\n",
      "Iteration 28030 => Loss: 47.12078847099036948975\n",
      "Iteration 28031 => Loss: 47.12061909836224060655\n",
      "Iteration 28032 => Loss: 47.12044972706335954626\n",
      "Iteration 28033 => Loss: 47.12028035709366946548\n",
      "Iteration 28034 => Loss: 47.12011098845319168049\n",
      "Iteration 28035 => Loss: 47.11994162114191198043\n",
      "Iteration 28036 => Loss: 47.11977225515981615445\n",
      "Iteration 28037 => Loss: 47.11960289050689709711\n",
      "Iteration 28038 => Loss: 47.11943352718316191385\n",
      "Iteration 28039 => Loss: 47.11926416518854665583\n",
      "Iteration 28040 => Loss: 47.11909480452307974474\n",
      "Iteration 28041 => Loss: 47.11892544518677539145\n",
      "Iteration 28042 => Loss: 47.11875608717956964711\n",
      "Iteration 28043 => Loss: 47.11858673050149093342\n",
      "Iteration 28044 => Loss: 47.11841737515251793411\n",
      "Iteration 28045 => Loss: 47.11824802113261512204\n",
      "Iteration 28046 => Loss: 47.11807866844181802435\n",
      "Iteration 28047 => Loss: 47.11790931708006979761\n",
      "Iteration 28048 => Loss: 47.11773996704739886354\n",
      "Iteration 28049 => Loss: 47.11757061834375548415\n",
      "Iteration 28050 => Loss: 47.11740127096916808114\n",
      "Iteration 28051 => Loss: 47.11723192492360823280\n",
      "Iteration 28052 => Loss: 47.11706258020706883372\n",
      "Iteration 28053 => Loss: 47.11689323681955698930\n",
      "Iteration 28054 => Loss: 47.11672389476100164529\n",
      "Iteration 28055 => Loss: 47.11655455403145964510\n",
      "Iteration 28056 => Loss: 47.11638521463088835617\n",
      "Iteration 28057 => Loss: 47.11621587655929488392\n",
      "Iteration 28058 => Loss: 47.11604653981664370122\n",
      "Iteration 28059 => Loss: 47.11587720440294191349\n",
      "Iteration 28060 => Loss: 47.11570787031818241530\n",
      "Iteration 28061 => Loss: 47.11553853756235099581\n",
      "Iteration 28062 => Loss: 47.11536920613540502245\n",
      "Iteration 28063 => Loss: 47.11519987603740133864\n",
      "Iteration 28064 => Loss: 47.11503054726826889009\n",
      "Iteration 28065 => Loss: 47.11486121982801478225\n",
      "Iteration 28066 => Loss: 47.11469189371664612054\n",
      "Iteration 28067 => Loss: 47.11452256893414869410\n",
      "Iteration 28068 => Loss: 47.11435324548047987037\n",
      "Iteration 28069 => Loss: 47.11418392335566096563\n",
      "Iteration 28070 => Loss: 47.11401460255968487445\n",
      "Iteration 28071 => Loss: 47.11384528309252317513\n",
      "Iteration 28072 => Loss: 47.11367596495416876223\n",
      "Iteration 28073 => Loss: 47.11350664814460742491\n",
      "Iteration 28074 => Loss: 47.11333733266386047944\n",
      "Iteration 28075 => Loss: 47.11316801851185687156\n",
      "Iteration 28076 => Loss: 47.11299870568865344467\n",
      "Iteration 28077 => Loss: 47.11282939419419335536\n",
      "Iteration 28078 => Loss: 47.11266008402849081449\n",
      "Iteration 28079 => Loss: 47.11249077519151029492\n",
      "Iteration 28080 => Loss: 47.11232146768325890207\n",
      "Iteration 28081 => Loss: 47.11215216150373663595\n",
      "Iteration 28082 => Loss: 47.11198285665289375856\n",
      "Iteration 28083 => Loss: 47.11181355313077290248\n",
      "Iteration 28084 => Loss: 47.11164425093734564598\n",
      "Iteration 28085 => Loss: 47.11147495007256935651\n",
      "Iteration 28086 => Loss: 47.11130565053646535034\n",
      "Iteration 28087 => Loss: 47.11113635232900520577\n",
      "Iteration 28088 => Loss: 47.11096705545019602823\n",
      "Iteration 28089 => Loss: 47.11079775990003071229\n",
      "Iteration 28090 => Loss: 47.11062846567847373080\n",
      "Iteration 28091 => Loss: 47.11045917278552508378\n",
      "Iteration 28092 => Loss: 47.11028988122119187665\n",
      "Iteration 28093 => Loss: 47.11012059098544568769\n",
      "Iteration 28094 => Loss: 47.10995130207829362234\n",
      "Iteration 28095 => Loss: 47.10978201449968594261\n",
      "Iteration 28096 => Loss: 47.10961272824965107020\n",
      "Iteration 28097 => Loss: 47.10944344332816058341\n",
      "Iteration 28098 => Loss: 47.10927415973522869308\n",
      "Iteration 28099 => Loss: 47.10910487747079145038\n",
      "Iteration 28100 => Loss: 47.10893559653490569872\n",
      "Iteration 28101 => Loss: 47.10876631692748617297\n",
      "Iteration 28102 => Loss: 47.10859703864860392741\n",
      "Iteration 28103 => Loss: 47.10842776169820922405\n",
      "Iteration 28104 => Loss: 47.10825848607625943032\n",
      "Iteration 28105 => Loss: 47.10808921178281138964\n",
      "Iteration 28106 => Loss: 47.10791993881779404774\n",
      "Iteration 28107 => Loss: 47.10775066718124293175\n",
      "Iteration 28108 => Loss: 47.10758139687310119825\n",
      "Iteration 28109 => Loss: 47.10741212789341147982\n",
      "Iteration 28110 => Loss: 47.10724286024210982760\n",
      "Iteration 28111 => Loss: 47.10707359391923176872\n",
      "Iteration 28112 => Loss: 47.10690432892474177606\n",
      "Iteration 28113 => Loss: 47.10673506525863274419\n",
      "Iteration 28114 => Loss: 47.10656580292088335682\n",
      "Iteration 28115 => Loss: 47.10639654191150071938\n",
      "Iteration 28116 => Loss: 47.10622728223047062102\n",
      "Iteration 28117 => Loss: 47.10605802387779306173\n",
      "Iteration 28118 => Loss: 47.10588876685343961981\n",
      "Iteration 28119 => Loss: 47.10571951115741740068\n",
      "Iteration 28120 => Loss: 47.10555025678968377179\n",
      "Iteration 28121 => Loss: 47.10538100375026715483\n",
      "Iteration 28122 => Loss: 47.10521175203913202267\n",
      "Iteration 28123 => Loss: 47.10504250165627126989\n",
      "Iteration 28124 => Loss: 47.10487325260167779106\n",
      "Iteration 28125 => Loss: 47.10470400487536579703\n",
      "Iteration 28126 => Loss: 47.10453475847725712811\n",
      "Iteration 28127 => Loss: 47.10436551340741573313\n",
      "Iteration 28128 => Loss: 47.10419626966580608496\n",
      "Iteration 28129 => Loss: 47.10402702725240686732\n",
      "Iteration 28130 => Loss: 47.10385778616718965850\n",
      "Iteration 28131 => Loss: 47.10368854641018998564\n",
      "Iteration 28132 => Loss: 47.10351930798136521616\n",
      "Iteration 28133 => Loss: 47.10335007088072245551\n",
      "Iteration 28134 => Loss: 47.10318083510824038740\n",
      "Iteration 28135 => Loss: 47.10301160066392611725\n",
      "Iteration 28136 => Loss: 47.10284236754774411793\n",
      "Iteration 28137 => Loss: 47.10267313575968017858\n",
      "Iteration 28138 => Loss: 47.10250390529976272092\n",
      "Iteration 28139 => Loss: 47.10233467616792779609\n",
      "Iteration 28140 => Loss: 47.10216544836422514209\n",
      "Iteration 28141 => Loss: 47.10199622188859081007\n",
      "Iteration 28142 => Loss: 47.10182699674104611631\n",
      "Iteration 28143 => Loss: 47.10165777292156263911\n",
      "Iteration 28144 => Loss: 47.10148855043016169475\n",
      "Iteration 28145 => Loss: 47.10131932926680775608\n",
      "Iteration 28146 => Loss: 47.10115010943147240141\n",
      "Iteration 28147 => Loss: 47.10098089092415563073\n",
      "Iteration 28148 => Loss: 47.10081167374489297117\n",
      "Iteration 28149 => Loss: 47.10064245789360626304\n",
      "Iteration 28150 => Loss: 47.10047324337033813890\n",
      "Iteration 28151 => Loss: 47.10030403017503886076\n",
      "Iteration 28152 => Loss: 47.10013481830772263947\n",
      "Iteration 28153 => Loss: 47.09996560776837526419\n",
      "Iteration 28154 => Loss: 47.09979639855698962947\n",
      "Iteration 28155 => Loss: 47.09962719067354441904\n",
      "Iteration 28156 => Loss: 47.09945798411802542205\n",
      "Iteration 28157 => Loss: 47.09928877889044684935\n",
      "Iteration 28158 => Loss: 47.09911957499076606837\n",
      "Iteration 28159 => Loss: 47.09895037241899018454\n",
      "Iteration 28160 => Loss: 47.09878117117509077616\n",
      "Iteration 28161 => Loss: 47.09861197125912468664\n",
      "Iteration 28162 => Loss: 47.09844277267099244000\n",
      "Iteration 28163 => Loss: 47.09827357541072956337\n",
      "Iteration 28164 => Loss: 47.09810437947833605676\n",
      "Iteration 28165 => Loss: 47.09793518487375507675\n",
      "Iteration 28166 => Loss: 47.09776599159700083419\n",
      "Iteration 28167 => Loss: 47.09759679964807332908\n",
      "Iteration 28168 => Loss: 47.09742760902697966685\n",
      "Iteration 28169 => Loss: 47.09725841973363458237\n",
      "Iteration 28170 => Loss: 47.09708923176812334077\n",
      "Iteration 28171 => Loss: 47.09692004513037488778\n",
      "Iteration 28172 => Loss: 47.09675085982040343424\n",
      "Iteration 28173 => Loss: 47.09658167583818766389\n",
      "Iteration 28174 => Loss: 47.09641249318372047128\n",
      "Iteration 28175 => Loss: 47.09624331185698764557\n",
      "Iteration 28176 => Loss: 47.09607413185796076505\n",
      "Iteration 28177 => Loss: 47.09590495318666825142\n",
      "Iteration 28178 => Loss: 47.09573577584308878841\n",
      "Iteration 28179 => Loss: 47.09556659982718684887\n",
      "Iteration 28180 => Loss: 47.09539742513897664367\n",
      "Iteration 28181 => Loss: 47.09522825177845817279\n",
      "Iteration 28182 => Loss: 47.09505907974556748741\n",
      "Iteration 28183 => Loss: 47.09488990904034011464\n",
      "Iteration 28184 => Loss: 47.09472073966279026536\n",
      "Iteration 28185 => Loss: 47.09455157161283267442\n",
      "Iteration 28186 => Loss: 47.09438240489050997439\n",
      "Iteration 28187 => Loss: 47.09421323949580084900\n",
      "Iteration 28188 => Loss: 47.09404407542868398195\n",
      "Iteration 28189 => Loss: 47.09387491268916647869\n",
      "Iteration 28190 => Loss: 47.09370575127721281206\n",
      "Iteration 28191 => Loss: 47.09353659119285140378\n",
      "Iteration 28192 => Loss: 47.09336743243603962128\n",
      "Iteration 28193 => Loss: 47.09319827500679167542\n",
      "Iteration 28194 => Loss: 47.09302911890507203907\n",
      "Iteration 28195 => Loss: 47.09285996413087360679\n",
      "Iteration 28196 => Loss: 47.09269081068420348402\n",
      "Iteration 28197 => Loss: 47.09252165856501903818\n",
      "Iteration 28198 => Loss: 47.09235250777334869099\n",
      "Iteration 28199 => Loss: 47.09218335830916402074\n",
      "Iteration 28200 => Loss: 47.09201421017245792200\n",
      "Iteration 28201 => Loss: 47.09184506336322328934\n",
      "Iteration 28202 => Loss: 47.09167591788142459563\n",
      "Iteration 28203 => Loss: 47.09150677372708315715\n",
      "Iteration 28204 => Loss: 47.09133763090017765762\n",
      "Iteration 28205 => Loss: 47.09116848940070809704\n",
      "Iteration 28206 => Loss: 47.09099934922861763198\n",
      "Iteration 28207 => Loss: 47.09083021038394889501\n",
      "Iteration 28208 => Loss: 47.09066107286669478071\n",
      "Iteration 28209 => Loss: 47.09049193667677712938\n",
      "Iteration 28210 => Loss: 47.09032280181425988985\n",
      "Iteration 28211 => Loss: 47.09015366827910753500\n",
      "Iteration 28212 => Loss: 47.08998453607128453768\n",
      "Iteration 28213 => Loss: 47.08981540519081931961\n",
      "Iteration 28214 => Loss: 47.08964627563769056451\n",
      "Iteration 28215 => Loss: 47.08947714741186985066\n",
      "Iteration 28216 => Loss: 47.08930802051337849434\n",
      "Iteration 28217 => Loss: 47.08913889494215965215\n",
      "Iteration 28218 => Loss: 47.08896977069822753492\n",
      "Iteration 28219 => Loss: 47.08880064778160345895\n",
      "Iteration 28220 => Loss: 47.08863152619222347539\n",
      "Iteration 28221 => Loss: 47.08846240593010179509\n",
      "Iteration 28222 => Loss: 47.08829328699523131263\n",
      "Iteration 28223 => Loss: 47.08812416938759071172\n",
      "Iteration 28224 => Loss: 47.08795505310719420322\n",
      "Iteration 28225 => Loss: 47.08778593815399204914\n",
      "Iteration 28226 => Loss: 47.08761682452800556575\n",
      "Iteration 28227 => Loss: 47.08744771222920633136\n",
      "Iteration 28228 => Loss: 47.08727860125760145138\n",
      "Iteration 28229 => Loss: 47.08710949161316250411\n",
      "Iteration 28230 => Loss: 47.08694038329590370040\n",
      "Iteration 28231 => Loss: 47.08677127630577530226\n",
      "Iteration 28232 => Loss: 47.08660217064280573140\n",
      "Iteration 28233 => Loss: 47.08643306630695946069\n",
      "Iteration 28234 => Loss: 47.08626396329825780640\n",
      "Iteration 28235 => Loss: 47.08609486161663681969\n",
      "Iteration 28236 => Loss: 47.08592576126213202770\n",
      "Iteration 28237 => Loss: 47.08575666223470790328\n",
      "Iteration 28238 => Loss: 47.08558756453436444644\n",
      "Iteration 28239 => Loss: 47.08541846816110876262\n",
      "Iteration 28240 => Loss: 47.08524937311489821923\n",
      "Iteration 28241 => Loss: 47.08508027939573992171\n",
      "Iteration 28242 => Loss: 47.08491118700363387006\n",
      "Iteration 28243 => Loss: 47.08474209593854453715\n",
      "Iteration 28244 => Loss: 47.08457300620045771211\n",
      "Iteration 28245 => Loss: 47.08440391778938050038\n",
      "Iteration 28246 => Loss: 47.08423483070532000738\n",
      "Iteration 28247 => Loss: 47.08406574494824070598\n",
      "Iteration 28248 => Loss: 47.08389666051813549075\n",
      "Iteration 28249 => Loss: 47.08372757741499015083\n",
      "Iteration 28250 => Loss: 47.08355849563881179165\n",
      "Iteration 28251 => Loss: 47.08338941518955067522\n",
      "Iteration 28252 => Loss: 47.08322033606724943411\n",
      "Iteration 28253 => Loss: 47.08305125827186543574\n",
      "Iteration 28254 => Loss: 47.08288218180340578556\n",
      "Iteration 28255 => Loss: 47.08271310666183495641\n",
      "Iteration 28256 => Loss: 47.08254403284716005373\n",
      "Iteration 28257 => Loss: 47.08237496035938818295\n",
      "Iteration 28258 => Loss: 47.08220588919845539522\n",
      "Iteration 28259 => Loss: 47.08203681936441142852\n",
      "Iteration 28260 => Loss: 47.08186775085718522860\n",
      "Iteration 28261 => Loss: 47.08169868367681942800\n",
      "Iteration 28262 => Loss: 47.08152961782328560503\n",
      "Iteration 28263 => Loss: 47.08136055329657665425\n",
      "Iteration 28264 => Loss: 47.08119149009665704853\n",
      "Iteration 28265 => Loss: 47.08102242822356231500\n",
      "Iteration 28266 => Loss: 47.08085336767724271567\n",
      "Iteration 28267 => Loss: 47.08068430845771246140\n",
      "Iteration 28268 => Loss: 47.08051525056492891963\n",
      "Iteration 28269 => Loss: 47.08034619399891340663\n",
      "Iteration 28270 => Loss: 47.08017713875964460613\n",
      "Iteration 28271 => Loss: 47.08000808484712962354\n",
      "Iteration 28272 => Loss: 47.07983903226131872088\n",
      "Iteration 28273 => Loss: 47.07966998100221900359\n",
      "Iteration 28274 => Loss: 47.07950093106984468250\n",
      "Iteration 28275 => Loss: 47.07933188246416023048\n",
      "Iteration 28276 => Loss: 47.07916283518514433126\n",
      "Iteration 28277 => Loss: 47.07899378923282540654\n",
      "Iteration 28278 => Loss: 47.07882474460716082376\n",
      "Iteration 28279 => Loss: 47.07865570130812926664\n",
      "Iteration 28280 => Loss: 47.07848665933577336773\n",
      "Iteration 28281 => Loss: 47.07831761869003628362\n",
      "Iteration 28282 => Loss: 47.07814857937091801432\n",
      "Iteration 28283 => Loss: 47.07797954137842566524\n",
      "Iteration 28284 => Loss: 47.07781050471250949840\n",
      "Iteration 28285 => Loss: 47.07764146937319793551\n",
      "Iteration 28286 => Loss: 47.07747243536047676571\n",
      "Iteration 28287 => Loss: 47.07730340267431046186\n",
      "Iteration 28288 => Loss: 47.07713437131470612940\n",
      "Iteration 28289 => Loss: 47.07696534128164245203\n",
      "Iteration 28290 => Loss: 47.07679631257514074605\n",
      "Iteration 28291 => Loss: 47.07662728519516548431\n",
      "Iteration 28292 => Loss: 47.07645825914170956139\n",
      "Iteration 28293 => Loss: 47.07628923441474455558\n",
      "Iteration 28294 => Loss: 47.07612021101427757230\n",
      "Iteration 28295 => Loss: 47.07595118894028729528\n",
      "Iteration 28296 => Loss: 47.07578216819280214622\n",
      "Iteration 28297 => Loss: 47.07561314877175817628\n",
      "Iteration 28298 => Loss: 47.07544413067719801802\n",
      "Iteration 28299 => Loss: 47.07527511390905772259\n",
      "Iteration 28300 => Loss: 47.07510609846734439543\n",
      "Iteration 28301 => Loss: 47.07493708435207224738\n",
      "Iteration 28302 => Loss: 47.07476807156320575132\n",
      "Iteration 28303 => Loss: 47.07459906010075201266\n",
      "Iteration 28304 => Loss: 47.07443004996470392598\n",
      "Iteration 28305 => Loss: 47.07426104115502596414\n",
      "Iteration 28306 => Loss: 47.07409203367171812715\n",
      "Iteration 28307 => Loss: 47.07392302751476620415\n",
      "Iteration 28308 => Loss: 47.07375402268416308971\n",
      "Iteration 28309 => Loss: 47.07358501917991588925\n",
      "Iteration 28310 => Loss: 47.07341601700200328651\n",
      "Iteration 28311 => Loss: 47.07324701615039685976\n",
      "Iteration 28312 => Loss: 47.07307801662508239815\n",
      "Iteration 28313 => Loss: 47.07290901842608832339\n",
      "Iteration 28314 => Loss: 47.07274002155339331921\n",
      "Iteration 28315 => Loss: 47.07257102600696896388\n",
      "Iteration 28316 => Loss: 47.07240203178680815199\n",
      "Iteration 28317 => Loss: 47.07223303889291088353\n",
      "Iteration 28318 => Loss: 47.07206404732524873680\n",
      "Iteration 28319 => Loss: 47.07189505708384302807\n",
      "Iteration 28320 => Loss: 47.07172606816864401935\n",
      "Iteration 28321 => Loss: 47.07155708057966592150\n",
      "Iteration 28322 => Loss: 47.07138809431691583995\n",
      "Iteration 28323 => Loss: 47.07121910938033693128\n",
      "Iteration 28324 => Loss: 47.07105012576995051177\n",
      "Iteration 28325 => Loss: 47.07088114348573526513\n",
      "Iteration 28326 => Loss: 47.07071216252769119137\n",
      "Iteration 28327 => Loss: 47.07054318289578276335\n",
      "Iteration 28328 => Loss: 47.07037420459003129736\n",
      "Iteration 28329 => Loss: 47.07020522761041547710\n",
      "Iteration 28330 => Loss: 47.07003625195691398631\n",
      "Iteration 28331 => Loss: 47.06986727762954103582\n",
      "Iteration 28332 => Loss: 47.06969830462823978223\n",
      "Iteration 28333 => Loss: 47.06952933295305996353\n",
      "Iteration 28334 => Loss: 47.06936036260394473629\n",
      "Iteration 28335 => Loss: 47.06919139358089410052\n",
      "Iteration 28336 => Loss: 47.06902242588392226708\n",
      "Iteration 28337 => Loss: 47.06885345951298660339\n",
      "Iteration 28338 => Loss: 47.06868449446810842574\n",
      "Iteration 28339 => Loss: 47.06851553074924510156\n",
      "Iteration 28340 => Loss: 47.06834656835639663086\n",
      "Iteration 28341 => Loss: 47.06817760728955590821\n",
      "Iteration 28342 => Loss: 47.06800864754872293361\n",
      "Iteration 28343 => Loss: 47.06783968913384796906\n",
      "Iteration 28344 => Loss: 47.06767073204498785799\n",
      "Iteration 28345 => Loss: 47.06750177628206444069\n",
      "Iteration 28346 => Loss: 47.06733282184512034974\n",
      "Iteration 28347 => Loss: 47.06716386873412005798\n",
      "Iteration 28348 => Loss: 47.06699491694902803829\n",
      "Iteration 28349 => Loss: 47.06682596648989402865\n",
      "Iteration 28350 => Loss: 47.06665701735665408023\n",
      "Iteration 28351 => Loss: 47.06648806954932950930\n",
      "Iteration 28352 => Loss: 47.06631912306789189415\n",
      "Iteration 28353 => Loss: 47.06615017791233412936\n",
      "Iteration 28354 => Loss: 47.06598123408266332035\n",
      "Iteration 28355 => Loss: 47.06581229157882972913\n",
      "Iteration 28356 => Loss: 47.06564335040086177742\n",
      "Iteration 28357 => Loss: 47.06547441054873814892\n",
      "Iteration 28358 => Loss: 47.06530547202245173821\n",
      "Iteration 28359 => Loss: 47.06513653482198122902\n",
      "Iteration 28360 => Loss: 47.06496759894731241047\n",
      "Iteration 28361 => Loss: 47.06479866439843817716\n",
      "Iteration 28362 => Loss: 47.06462973117535852907\n",
      "Iteration 28363 => Loss: 47.06446079927807346621\n",
      "Iteration 28364 => Loss: 47.06429186870656167230\n",
      "Iteration 28365 => Loss: 47.06412293946078762019\n",
      "Iteration 28366 => Loss: 47.06395401154075841532\n",
      "Iteration 28367 => Loss: 47.06378508494648116312\n",
      "Iteration 28368 => Loss: 47.06361615967792744186\n",
      "Iteration 28369 => Loss: 47.06344723573509014614\n",
      "Iteration 28370 => Loss: 47.06327831311794085423\n",
      "Iteration 28371 => Loss: 47.06310939182651509327\n",
      "Iteration 28372 => Loss: 47.06294047186077023071\n",
      "Iteration 28373 => Loss: 47.06277155322069916110\n",
      "Iteration 28374 => Loss: 47.06260263590627346275\n",
      "Iteration 28375 => Loss: 47.06243371991752155736\n",
      "Iteration 28376 => Loss: 47.06226480525440791780\n",
      "Iteration 28377 => Loss: 47.06209589191692543864\n",
      "Iteration 28378 => Loss: 47.06192697990505280359\n",
      "Iteration 28379 => Loss: 47.06175806921881843436\n",
      "Iteration 28380 => Loss: 47.06158915985817259298\n",
      "Iteration 28381 => Loss: 47.06142025182311527942\n",
      "Iteration 28382 => Loss: 47.06125134511365359913\n",
      "Iteration 28383 => Loss: 47.06108243972974491953\n",
      "Iteration 28384 => Loss: 47.06091353567141766234\n",
      "Iteration 28385 => Loss: 47.06074463293862919500\n",
      "Iteration 28386 => Loss: 47.06057573153136530664\n",
      "Iteration 28387 => Loss: 47.06040683144965441898\n",
      "Iteration 28388 => Loss: 47.06023793269345389945\n",
      "Iteration 28389 => Loss: 47.06006903526276374805\n",
      "Iteration 28390 => Loss: 47.05990013915756264851\n",
      "Iteration 28391 => Loss: 47.05973124437785770624\n",
      "Iteration 28392 => Loss: 47.05956235092364181583\n",
      "Iteration 28393 => Loss: 47.05939345879485813384\n",
      "Iteration 28394 => Loss: 47.05922456799156350371\n",
      "Iteration 28395 => Loss: 47.05905567851370818744\n",
      "Iteration 28396 => Loss: 47.05888679036127797417\n",
      "Iteration 28397 => Loss: 47.05871790353429418019\n",
      "Iteration 28398 => Loss: 47.05854901803269996208\n",
      "Iteration 28399 => Loss: 47.05838013385651663611\n",
      "Iteration 28400 => Loss: 47.05821125100574420230\n",
      "Iteration 28401 => Loss: 47.05804236948033292265\n",
      "Iteration 28402 => Loss: 47.05787348928029700801\n",
      "Iteration 28403 => Loss: 47.05770461040565066924\n",
      "Iteration 28404 => Loss: 47.05753573285633706291\n",
      "Iteration 28405 => Loss: 47.05736685663237039989\n",
      "Iteration 28406 => Loss: 47.05719798173372225847\n",
      "Iteration 28407 => Loss: 47.05702910816040684949\n",
      "Iteration 28408 => Loss: 47.05686023591240285668\n",
      "Iteration 28409 => Loss: 47.05669136498969606919\n",
      "Iteration 28410 => Loss: 47.05652249539227227615\n",
      "Iteration 28411 => Loss: 47.05635362712015279385\n",
      "Iteration 28412 => Loss: 47.05618476017328788430\n",
      "Iteration 28413 => Loss: 47.05601589455167044207\n",
      "Iteration 28414 => Loss: 47.05584703025531467802\n",
      "Iteration 28415 => Loss: 47.05567816728418506500\n",
      "Iteration 28416 => Loss: 47.05550930563829581388\n",
      "Iteration 28417 => Loss: 47.05534044531761139751\n",
      "Iteration 28418 => Loss: 47.05517158632213892133\n",
      "Iteration 28419 => Loss: 47.05500272865187127991\n",
      "Iteration 28420 => Loss: 47.05483387230679426239\n",
      "Iteration 28421 => Loss: 47.05466501728688655248\n",
      "Iteration 28422 => Loss: 47.05449616359211972849\n",
      "Iteration 28423 => Loss: 47.05432731122254352840\n",
      "Iteration 28424 => Loss: 47.05415846017810110880\n",
      "Iteration 28425 => Loss: 47.05398961045879246967\n",
      "Iteration 28426 => Loss: 47.05382076206460340018\n",
      "Iteration 28427 => Loss: 47.05365191499552679488\n",
      "Iteration 28428 => Loss: 47.05348306925154133751\n",
      "Iteration 28429 => Loss: 47.05331422483268255519\n",
      "Iteration 28430 => Loss: 47.05314538173887939365\n",
      "Iteration 28431 => Loss: 47.05297653997014606375\n",
      "Iteration 28432 => Loss: 47.05280769952648967092\n",
      "Iteration 28433 => Loss: 47.05263886040786047715\n",
      "Iteration 28434 => Loss: 47.05247002261429400960\n",
      "Iteration 28435 => Loss: 47.05230118614575474112\n",
      "Iteration 28436 => Loss: 47.05213235100222846086\n",
      "Iteration 28437 => Loss: 47.05196351718371516881\n",
      "Iteration 28438 => Loss: 47.05179468469021486499\n",
      "Iteration 28439 => Loss: 47.05162585352167781139\n",
      "Iteration 28440 => Loss: 47.05145702367813242972\n",
      "Iteration 28441 => Loss: 47.05128819515954319286\n",
      "Iteration 28442 => Loss: 47.05111936796593141707\n",
      "Iteration 28443 => Loss: 47.05095054209724736438\n",
      "Iteration 28444 => Loss: 47.05078171755350524563\n",
      "Iteration 28445 => Loss: 47.05061289433468374455\n",
      "Iteration 28446 => Loss: 47.05044407244078286112\n",
      "Iteration 28447 => Loss: 47.05027525187180259536\n",
      "Iteration 28448 => Loss: 47.05010643262769320927\n",
      "Iteration 28449 => Loss: 47.04993761470849022999\n",
      "Iteration 28450 => Loss: 47.04976879811416523580\n",
      "Iteration 28451 => Loss: 47.04959998284469691043\n",
      "Iteration 28452 => Loss: 47.04943116890005683217\n",
      "Iteration 28453 => Loss: 47.04926235628025921187\n",
      "Iteration 28454 => Loss: 47.04909354498533247124\n",
      "Iteration 28455 => Loss: 47.04892473501519134516\n",
      "Iteration 28456 => Loss: 47.04875592636988557160\n",
      "Iteration 28457 => Loss: 47.04858711904937251802\n",
      "Iteration 28458 => Loss: 47.04841831305365928984\n",
      "Iteration 28459 => Loss: 47.04824950838271035991\n",
      "Iteration 28460 => Loss: 47.04808070503656125538\n",
      "Iteration 28461 => Loss: 47.04791190301513381655\n",
      "Iteration 28462 => Loss: 47.04774310231847778141\n",
      "Iteration 28463 => Loss: 47.04757430294654341196\n",
      "Iteration 28464 => Loss: 47.04740550489935912992\n",
      "Iteration 28465 => Loss: 47.04723670817687519730\n",
      "Iteration 28466 => Loss: 47.04706791277911293037\n",
      "Iteration 28467 => Loss: 47.04689911870605101285\n",
      "Iteration 28468 => Loss: 47.04673032595766812847\n",
      "Iteration 28469 => Loss: 47.04656153453395717179\n",
      "Iteration 28470 => Loss: 47.04639274443491103739\n",
      "Iteration 28471 => Loss: 47.04622395566054393612\n",
      "Iteration 28472 => Loss: 47.04605516821079902456\n",
      "Iteration 28473 => Loss: 47.04588638208569761900\n",
      "Iteration 28474 => Loss: 47.04571759728522550859\n",
      "Iteration 28475 => Loss: 47.04554881380935427160\n",
      "Iteration 28476 => Loss: 47.04538003165809101347\n",
      "Iteration 28477 => Loss: 47.04521125083142152334\n",
      "Iteration 28478 => Loss: 47.04504247132934580122\n",
      "Iteration 28479 => Loss: 47.04487369315184253082\n",
      "Iteration 28480 => Loss: 47.04470491629887618501\n",
      "Iteration 28481 => Loss: 47.04453614077048939635\n",
      "Iteration 28482 => Loss: 47.04436736656661111056\n",
      "Iteration 28483 => Loss: 47.04419859368730527649\n",
      "Iteration 28484 => Loss: 47.04402982213247952359\n",
      "Iteration 28485 => Loss: 47.04386105190221201156\n",
      "Iteration 28486 => Loss: 47.04369228299640326441\n",
      "Iteration 28487 => Loss: 47.04352351541511723099\n",
      "Iteration 28488 => Loss: 47.04335474915826864617\n",
      "Iteration 28489 => Loss: 47.04318598422591435337\n",
      "Iteration 28490 => Loss: 47.04301722061801882546\n",
      "Iteration 28491 => Loss: 47.04284845833456074615\n",
      "Iteration 28492 => Loss: 47.04267969737556853715\n",
      "Iteration 28493 => Loss: 47.04251093774097114419\n",
      "Iteration 28494 => Loss: 47.04234217943080409441\n",
      "Iteration 28495 => Loss: 47.04217342244503896609\n",
      "Iteration 28496 => Loss: 47.04200466678366865381\n",
      "Iteration 28497 => Loss: 47.04183591244669315756\n",
      "Iteration 28498 => Loss: 47.04166715943407695022\n",
      "Iteration 28499 => Loss: 47.04149840774584134806\n",
      "Iteration 28500 => Loss: 47.04132965738194371852\n",
      "Iteration 28501 => Loss: 47.04116090834240537788\n",
      "Iteration 28502 => Loss: 47.04099216062719079900\n",
      "Iteration 28503 => Loss: 47.04082341423630708732\n",
      "Iteration 28504 => Loss: 47.04065466916973292655\n",
      "Iteration 28505 => Loss: 47.04048592542746121126\n",
      "Iteration 28506 => Loss: 47.04031718300947773059\n",
      "Iteration 28507 => Loss: 47.04014844191578958998\n",
      "Iteration 28508 => Loss: 47.03997970214635415687\n",
      "Iteration 28509 => Loss: 47.03981096370118564209\n",
      "Iteration 28510 => Loss: 47.03964222658026983481\n",
      "Iteration 28511 => Loss: 47.03947349078358541874\n",
      "Iteration 28512 => Loss: 47.03930475631115371016\n",
      "Iteration 28513 => Loss: 47.03913602316292497107\n",
      "Iteration 28514 => Loss: 47.03896729133891341235\n",
      "Iteration 28515 => Loss: 47.03879856083908350683\n",
      "Iteration 28516 => Loss: 47.03862983166346367625\n",
      "Iteration 28517 => Loss: 47.03846110381200418260\n",
      "Iteration 28518 => Loss: 47.03829237728473344760\n",
      "Iteration 28519 => Loss: 47.03812365208158041696\n",
      "Iteration 28520 => Loss: 47.03795492820261614497\n",
      "Iteration 28521 => Loss: 47.03778620564775536650\n",
      "Iteration 28522 => Loss: 47.03761748441702650325\n",
      "Iteration 28523 => Loss: 47.03744876451042955523\n",
      "Iteration 28524 => Loss: 47.03728004592792899530\n",
      "Iteration 28525 => Loss: 47.03711132866952482345\n",
      "Iteration 28526 => Loss: 47.03694261273518151256\n",
      "Iteration 28527 => Loss: 47.03677389812495590604\n",
      "Iteration 28528 => Loss: 47.03660518483876984419\n",
      "Iteration 28529 => Loss: 47.03643647287663043244\n",
      "Iteration 28530 => Loss: 47.03626776223854477621\n",
      "Iteration 28531 => Loss: 47.03609905292447734837\n",
      "Iteration 28532 => Loss: 47.03593034493444946520\n",
      "Iteration 28533 => Loss: 47.03576163826841849414\n",
      "Iteration 28534 => Loss: 47.03559293292640575146\n",
      "Iteration 28535 => Loss: 47.03542422890837571003\n",
      "Iteration 28536 => Loss: 47.03525552621431415901\n",
      "Iteration 28537 => Loss: 47.03508682484423530923\n",
      "Iteration 28538 => Loss: 47.03491812479811073899\n",
      "Iteration 28539 => Loss: 47.03474942607594044830\n",
      "Iteration 28540 => Loss: 47.03458072867771733172\n",
      "Iteration 28541 => Loss: 47.03441203260340586212\n",
      "Iteration 28542 => Loss: 47.03424333785300603950\n",
      "Iteration 28543 => Loss: 47.03407464442653207470\n",
      "Iteration 28544 => Loss: 47.03390595232394844061\n",
      "Iteration 28545 => Loss: 47.03373726154524803178\n",
      "Iteration 28546 => Loss: 47.03356857209043084822\n",
      "Iteration 28547 => Loss: 47.03339988395946846822\n",
      "Iteration 28548 => Loss: 47.03323119715236799721\n",
      "Iteration 28549 => Loss: 47.03306251166910101347\n",
      "Iteration 28550 => Loss: 47.03289382750969593872\n",
      "Iteration 28551 => Loss: 47.03272514467410303496\n",
      "Iteration 28552 => Loss: 47.03255646316232940762\n",
      "Iteration 28553 => Loss: 47.03238778297433952957\n",
      "Iteration 28554 => Loss: 47.03221910411016892795\n",
      "Iteration 28555 => Loss: 47.03205042656976075932\n",
      "Iteration 28556 => Loss: 47.03188175035314344541\n",
      "Iteration 28557 => Loss: 47.03171307546025303736\n",
      "Iteration 28558 => Loss: 47.03154440189114637860\n",
      "Iteration 28559 => Loss: 47.03137572964577373114\n",
      "Iteration 28560 => Loss: 47.03120705872412088411\n",
      "Iteration 28561 => Loss: 47.03103838912620915380\n",
      "Iteration 28562 => Loss: 47.03086972085198880222\n",
      "Iteration 28563 => Loss: 47.03070105390148114566\n",
      "Iteration 28564 => Loss: 47.03053238827465776239\n",
      "Iteration 28565 => Loss: 47.03036372397151865243\n",
      "Iteration 28566 => Loss: 47.03019506099202828864\n",
      "Iteration 28567 => Loss: 47.03002639933622219814\n",
      "Iteration 28568 => Loss: 47.02985773900405064296\n",
      "Iteration 28569 => Loss: 47.02968907999551362309\n",
      "Iteration 28570 => Loss: 47.02952042231061113853\n",
      "Iteration 28571 => Loss: 47.02935176594932897842\n",
      "Iteration 28572 => Loss: 47.02918311091165293192\n",
      "Iteration 28573 => Loss: 47.02901445719755457731\n",
      "Iteration 28574 => Loss: 47.02884580480704812544\n",
      "Iteration 28575 => Loss: 47.02867715374014068175\n",
      "Iteration 28576 => Loss: 47.02850850399676119196\n",
      "Iteration 28577 => Loss: 47.02833985557695939406\n",
      "Iteration 28578 => Loss: 47.02817120848069265548\n",
      "Iteration 28579 => Loss: 47.02800256270796808167\n",
      "Iteration 28580 => Loss: 47.02783391825875725090\n",
      "Iteration 28581 => Loss: 47.02766527513304595232\n",
      "Iteration 28582 => Loss: 47.02749663333086971306\n",
      "Iteration 28583 => Loss: 47.02732799285217879515\n",
      "Iteration 28584 => Loss: 47.02715935369696609314\n",
      "Iteration 28585 => Loss: 47.02699071586521029076\n",
      "Iteration 28586 => Loss: 47.02682207935691849343\n",
      "Iteration 28587 => Loss: 47.02665344417207649030\n",
      "Iteration 28588 => Loss: 47.02648481031069138680\n",
      "Iteration 28589 => Loss: 47.02631617777272055037\n",
      "Iteration 28590 => Loss: 47.02614754655815687556\n",
      "Iteration 28591 => Loss: 47.02597891666702878410\n",
      "Iteration 28592 => Loss: 47.02581028809929364343\n",
      "Iteration 28593 => Loss: 47.02564166085493013725\n",
      "Iteration 28594 => Loss: 47.02547303493395958185\n",
      "Iteration 28595 => Loss: 47.02530441033636776638\n",
      "Iteration 28596 => Loss: 47.02513578706213337455\n",
      "Iteration 28597 => Loss: 47.02496716511119245752\n",
      "Iteration 28598 => Loss: 47.02479854448365870212\n",
      "Iteration 28599 => Loss: 47.02462992517939710524\n",
      "Iteration 28600 => Loss: 47.02446130719847872115\n",
      "Iteration 28601 => Loss: 47.02429269054087512814\n",
      "Iteration 28602 => Loss: 47.02412407520652948278\n",
      "Iteration 28603 => Loss: 47.02395546119549152309\n",
      "Iteration 28604 => Loss: 47.02378684850773993276\n",
      "Iteration 28605 => Loss: 47.02361823714322497381\n",
      "Iteration 28606 => Loss: 47.02344962710194664623\n",
      "Iteration 28607 => Loss: 47.02328101838396889889\n",
      "Iteration 28608 => Loss: 47.02311241098919936121\n",
      "Iteration 28609 => Loss: 47.02294380491763803320\n",
      "Iteration 28610 => Loss: 47.02277520016927780944\n",
      "Iteration 28611 => Loss: 47.02260659674416132248\n",
      "Iteration 28612 => Loss: 47.02243799464219620177\n",
      "Iteration 28613 => Loss: 47.02226939386343218530\n",
      "Iteration 28614 => Loss: 47.02210079440783374594\n",
      "Iteration 28615 => Loss: 47.02193219627540088368\n",
      "Iteration 28616 => Loss: 47.02176359946610517682\n",
      "Iteration 28617 => Loss: 47.02159500397994662535\n",
      "Iteration 28618 => Loss: 47.02142640981691812385\n",
      "Iteration 28619 => Loss: 47.02125781697701256689\n",
      "Iteration 28620 => Loss: 47.02108922546021574362\n",
      "Iteration 28621 => Loss: 47.02092063526652054861\n",
      "Iteration 28622 => Loss: 47.02075204639589145472\n",
      "Iteration 28623 => Loss: 47.02058345884836398909\n",
      "Iteration 28624 => Loss: 47.02041487262390973001\n",
      "Iteration 28625 => Loss: 47.02024628772247893949\n",
      "Iteration 28626 => Loss: 47.02007770414411425008\n",
      "Iteration 28627 => Loss: 47.01990912188878724010\n",
      "Iteration 28628 => Loss: 47.01974054095648369866\n",
      "Iteration 28629 => Loss: 47.01957196134717520408\n",
      "Iteration 28630 => Loss: 47.01940338306088307263\n",
      "Iteration 28631 => Loss: 47.01923480609758598803\n",
      "Iteration 28632 => Loss: 47.01906623045726973942\n",
      "Iteration 28633 => Loss: 47.01889765613993432680\n",
      "Iteration 28634 => Loss: 47.01872908314555132847\n",
      "Iteration 28635 => Loss: 47.01856051147412074442\n",
      "Iteration 28636 => Loss: 47.01839194112562836381\n",
      "Iteration 28637 => Loss: 47.01822337210007418662\n",
      "Iteration 28638 => Loss: 47.01805480439743689658\n",
      "Iteration 28639 => Loss: 47.01788623801769517740\n",
      "Iteration 28640 => Loss: 47.01771767296091297794\n",
      "Iteration 28641 => Loss: 47.01754910922694818964\n",
      "Iteration 28642 => Loss: 47.01738054681590739392\n",
      "Iteration 28643 => Loss: 47.01721198572771953650\n",
      "Iteration 28644 => Loss: 47.01704342596238461738\n",
      "Iteration 28645 => Loss: 47.01687486751990974199\n",
      "Iteration 28646 => Loss: 47.01670631040027359404\n",
      "Iteration 28647 => Loss: 47.01653775460345485726\n",
      "Iteration 28648 => Loss: 47.01636920012946063707\n",
      "Iteration 28649 => Loss: 47.01620064697826251177\n",
      "Iteration 28650 => Loss: 47.01603209514987469220\n",
      "Iteration 28651 => Loss: 47.01586354464426165123\n",
      "Iteration 28652 => Loss: 47.01569499546143759972\n",
      "Iteration 28653 => Loss: 47.01552644760136701052\n",
      "Iteration 28654 => Loss: 47.01535790106405698907\n",
      "Iteration 28655 => Loss: 47.01518935584948621909\n",
      "Iteration 28656 => Loss: 47.01502081195766180599\n",
      "Iteration 28657 => Loss: 47.01485226938855532808\n",
      "Iteration 28658 => Loss: 47.01468372814214546906\n",
      "Iteration 28659 => Loss: 47.01451518821846065066\n",
      "Iteration 28660 => Loss: 47.01434664961746534573\n",
      "Iteration 28661 => Loss: 47.01417811233913113256\n",
      "Iteration 28662 => Loss: 47.01400957638347222201\n",
      "Iteration 28663 => Loss: 47.01384104175048150864\n",
      "Iteration 28664 => Loss: 47.01367250844015188704\n",
      "Iteration 28665 => Loss: 47.01350397645246204092\n",
      "Iteration 28666 => Loss: 47.01333544578739065400\n",
      "Iteration 28667 => Loss: 47.01316691644493772628\n",
      "Iteration 28668 => Loss: 47.01299838842511036319\n",
      "Iteration 28669 => Loss: 47.01282986172787303758\n",
      "Iteration 28670 => Loss: 47.01266133635322574946\n",
      "Iteration 28671 => Loss: 47.01249281230114718255\n",
      "Iteration 28672 => Loss: 47.01232428957163733685\n",
      "Iteration 28673 => Loss: 47.01215576816471752863\n",
      "Iteration 28674 => Loss: 47.01198724808030959821\n",
      "Iteration 28675 => Loss: 47.01181872931844196728\n",
      "Iteration 28676 => Loss: 47.01165021187910753042\n",
      "Iteration 28677 => Loss: 47.01148169576229918221\n",
      "Iteration 28678 => Loss: 47.01131318096796718464\n",
      "Iteration 28679 => Loss: 47.01114466749615417029\n",
      "Iteration 28680 => Loss: 47.01097615534683171745\n",
      "Iteration 28681 => Loss: 47.01080764451997140441\n",
      "Iteration 28682 => Loss: 47.01063913501558033659\n",
      "Iteration 28683 => Loss: 47.01047062683363719771\n",
      "Iteration 28684 => Loss: 47.01030211997412777691\n",
      "Iteration 28685 => Loss: 47.01013361443705917964\n",
      "Iteration 28686 => Loss: 47.00996511022242430045\n",
      "Iteration 28687 => Loss: 47.00979660733019471763\n",
      "Iteration 28688 => Loss: 47.00962810576037043120\n",
      "Iteration 28689 => Loss: 47.00945960551291591401\n",
      "Iteration 28690 => Loss: 47.00929110658786669319\n",
      "Iteration 28691 => Loss: 47.00912260898518013619\n",
      "Iteration 28692 => Loss: 47.00895411270486334843\n",
      "Iteration 28693 => Loss: 47.00878561774688790820\n",
      "Iteration 28694 => Loss: 47.00861712411126092093\n",
      "Iteration 28695 => Loss: 47.00844863179795396491\n",
      "Iteration 28696 => Loss: 47.00828014080695282928\n",
      "Iteration 28697 => Loss: 47.00811165113828593576\n",
      "Iteration 28698 => Loss: 47.00794316279190354635\n",
      "Iteration 28699 => Loss: 47.00777467576780566105\n",
      "Iteration 28700 => Loss: 47.00760619006598517444\n",
      "Iteration 28701 => Loss: 47.00743770568644919194\n",
      "Iteration 28702 => Loss: 47.00726922262913376471\n",
      "Iteration 28703 => Loss: 47.00710074089409573617\n",
      "Iteration 28704 => Loss: 47.00693226048129957917\n",
      "Iteration 28705 => Loss: 47.00676378139071687201\n",
      "Iteration 28706 => Loss: 47.00659530362234050926\n",
      "Iteration 28707 => Loss: 47.00642682717617049093\n",
      "Iteration 28708 => Loss: 47.00625835205220681701\n",
      "Iteration 28709 => Loss: 47.00608987825041396036\n",
      "Iteration 28710 => Loss: 47.00592140577079902641\n",
      "Iteration 28711 => Loss: 47.00575293461335490974\n",
      "Iteration 28712 => Loss: 47.00558446477804608321\n",
      "Iteration 28713 => Loss: 47.00541599626490096853\n",
      "Iteration 28714 => Loss: 47.00524752907386982770\n",
      "Iteration 28715 => Loss: 47.00507906320498108244\n",
      "Iteration 28716 => Loss: 47.00491059865817788932\n",
      "Iteration 28717 => Loss: 47.00474213543348867006\n",
      "Iteration 28718 => Loss: 47.00457367353088500295\n",
      "Iteration 28719 => Loss: 47.00440521295038820426\n",
      "Iteration 28720 => Loss: 47.00423675369192721973\n",
      "Iteration 28721 => Loss: 47.00406829575553757650\n",
      "Iteration 28722 => Loss: 47.00389983914119795827\n",
      "Iteration 28723 => Loss: 47.00373138384888704877\n",
      "Iteration 28724 => Loss: 47.00356292987860484800\n",
      "Iteration 28725 => Loss: 47.00339447723036556681\n",
      "Iteration 28726 => Loss: 47.00322602590410525636\n",
      "Iteration 28727 => Loss: 47.00305757589985944378\n",
      "Iteration 28728 => Loss: 47.00288912721759260194\n",
      "Iteration 28729 => Loss: 47.00272067985731183626\n",
      "Iteration 28730 => Loss: 47.00255223381898161961\n",
      "Iteration 28731 => Loss: 47.00238378910263747912\n",
      "Iteration 28732 => Loss: 47.00221534570819414967\n",
      "Iteration 28733 => Loss: 47.00204690363570847467\n",
      "Iteration 28734 => Loss: 47.00187846288513782156\n",
      "Iteration 28735 => Loss: 47.00171002345649640120\n",
      "Iteration 28736 => Loss: 47.00154158534975579187\n",
      "Iteration 28737 => Loss: 47.00137314856490178272\n",
      "Iteration 28738 => Loss: 47.00120471310194858461\n",
      "Iteration 28739 => Loss: 47.00103627896083935411\n",
      "Iteration 28740 => Loss: 47.00086784614161672380\n",
      "Iteration 28741 => Loss: 47.00069941464423806110\n",
      "Iteration 28742 => Loss: 47.00053098446869626059\n",
      "Iteration 28743 => Loss: 47.00036255561499132227\n",
      "Iteration 28744 => Loss: 47.00019412808309482443\n",
      "Iteration 28745 => Loss: 47.00002570187300676707\n",
      "Iteration 28746 => Loss: 46.99985727698473425562\n",
      "Iteration 28747 => Loss: 46.99968885341824886837\n",
      "Iteration 28748 => Loss: 46.99952043117355060531\n",
      "Iteration 28749 => Loss: 46.99935201025061104474\n",
      "Iteration 28750 => Loss: 46.99918359064941597580\n",
      "Iteration 28751 => Loss: 46.99901517236999382021\n",
      "Iteration 28752 => Loss: 46.99884675541230194540\n",
      "Iteration 28753 => Loss: 46.99867833977634745679\n",
      "Iteration 28754 => Loss: 46.99850992546207351097\n",
      "Iteration 28755 => Loss: 46.99834151246952984593\n",
      "Iteration 28756 => Loss: 46.99817310079869514539\n",
      "Iteration 28757 => Loss: 46.99800469044952677677\n",
      "Iteration 28758 => Loss: 46.99783628142202474010\n",
      "Iteration 28759 => Loss: 46.99766787371622456249\n",
      "Iteration 28760 => Loss: 46.99749946733206229510\n",
      "Iteration 28761 => Loss: 46.99733106226953793794\n",
      "Iteration 28762 => Loss: 46.99716265852864438557\n",
      "Iteration 28763 => Loss: 46.99699425610939584885\n",
      "Iteration 28764 => Loss: 46.99682585501172837894\n",
      "Iteration 28765 => Loss: 46.99665745523567750297\n",
      "Iteration 28766 => Loss: 46.99648905678122901008\n",
      "Iteration 28767 => Loss: 46.99632065964836158400\n",
      "Iteration 28768 => Loss: 46.99615226383704680302\n",
      "Iteration 28769 => Loss: 46.99598386934729177256\n",
      "Iteration 28770 => Loss: 46.99581547617913201975\n",
      "Iteration 28771 => Loss: 46.99564708433248227948\n",
      "Iteration 28772 => Loss: 46.99547869380734965716\n",
      "Iteration 28773 => Loss: 46.99531030460376967994\n",
      "Iteration 28774 => Loss: 46.99514191672167129354\n",
      "Iteration 28775 => Loss: 46.99497353016108291968\n",
      "Iteration 28776 => Loss: 46.99480514492198324206\n",
      "Iteration 28777 => Loss: 46.99463676100436515526\n",
      "Iteration 28778 => Loss: 46.99446837840822155385\n",
      "Iteration 28779 => Loss: 46.99429999713351691071\n",
      "Iteration 28780 => Loss: 46.99413161718025122582\n",
      "Iteration 28781 => Loss: 46.99396323854845292090\n",
      "Iteration 28782 => Loss: 46.99379486123807936337\n",
      "Iteration 28783 => Loss: 46.99362648524910923697\n",
      "Iteration 28784 => Loss: 46.99345811058155675255\n",
      "Iteration 28785 => Loss: 46.99328973723537217211\n",
      "Iteration 28786 => Loss: 46.99312136521058391736\n",
      "Iteration 28787 => Loss: 46.99295299450717777745\n",
      "Iteration 28788 => Loss: 46.99278462512514664695\n",
      "Iteration 28789 => Loss: 46.99261625706445499873\n",
      "Iteration 28790 => Loss: 46.99244789032512414906\n",
      "Iteration 28791 => Loss: 46.99227952490709725453\n",
      "Iteration 28792 => Loss: 46.99211116081040984227\n",
      "Iteration 28793 => Loss: 46.99194279803504059601\n",
      "Iteration 28794 => Loss: 46.99177443658096109402\n",
      "Iteration 28795 => Loss: 46.99160607644818554718\n",
      "Iteration 28796 => Loss: 46.99143771763669263919\n",
      "Iteration 28797 => Loss: 46.99126936014646105377\n",
      "Iteration 28798 => Loss: 46.99110100397747658008\n",
      "Iteration 28799 => Loss: 46.99093264912977474523\n",
      "Iteration 28800 => Loss: 46.99076429560328449497\n",
      "Iteration 28801 => Loss: 46.99059594339804135643\n",
      "Iteration 28802 => Loss: 46.99042759251400269704\n",
      "Iteration 28803 => Loss: 46.99025924295119693852\n",
      "Iteration 28804 => Loss: 46.99009089470956723744\n",
      "Iteration 28805 => Loss: 46.98992254778914201552\n",
      "Iteration 28806 => Loss: 46.98975420218987153476\n",
      "Iteration 28807 => Loss: 46.98958585791178421687\n",
      "Iteration 28808 => Loss: 46.98941751495485164014\n",
      "Iteration 28809 => Loss: 46.98924917331906669915\n",
      "Iteration 28810 => Loss: 46.98908083300441518304\n",
      "Iteration 28811 => Loss: 46.98891249401090419724\n",
      "Iteration 28812 => Loss: 46.98874415633848400375\n",
      "Iteration 28813 => Loss: 46.98857581998719723515\n",
      "Iteration 28814 => Loss: 46.98840748495698704801\n",
      "Iteration 28815 => Loss: 46.98823915124785344233\n",
      "Iteration 28816 => Loss: 46.98807081885981773439\n",
      "Iteration 28817 => Loss: 46.98790248779281597535\n",
      "Iteration 28818 => Loss: 46.98773415804691211406\n",
      "Iteration 28819 => Loss: 46.98756582962201377995\n",
      "Iteration 28820 => Loss: 46.98739750251814228932\n",
      "Iteration 28821 => Loss: 46.98722917673530474758\n",
      "Iteration 28822 => Loss: 46.98706085227349404931\n",
      "Iteration 28823 => Loss: 46.98689252913267466738\n",
      "Iteration 28824 => Loss: 46.98672420731285370721\n",
      "Iteration 28825 => Loss: 46.98655588681398143081\n",
      "Iteration 28826 => Loss: 46.98638756763611468159\n",
      "Iteration 28827 => Loss: 46.98621924977921082700\n",
      "Iteration 28828 => Loss: 46.98605093324322723447\n",
      "Iteration 28829 => Loss: 46.98588261802819943114\n",
      "Iteration 28830 => Loss: 46.98571430413409899529\n",
      "Iteration 28831 => Loss: 46.98554599156090461065\n",
      "Iteration 28832 => Loss: 46.98537768030863759350\n",
      "Iteration 28833 => Loss: 46.98520937037726952212\n",
      "Iteration 28834 => Loss: 46.98504106176677908024\n",
      "Iteration 28835 => Loss: 46.98487275447717337329\n",
      "Iteration 28836 => Loss: 46.98470444850841687412\n",
      "Iteration 28837 => Loss: 46.98453614386055221530\n",
      "Iteration 28838 => Loss: 46.98436784053350123713\n",
      "Iteration 28839 => Loss: 46.98419953852730657218\n",
      "Iteration 28840 => Loss: 46.98403123784189716616\n",
      "Iteration 28841 => Loss: 46.98386293847734407336\n",
      "Iteration 28842 => Loss: 46.98369464043359045036\n",
      "Iteration 28843 => Loss: 46.98352634371060077001\n",
      "Iteration 28844 => Loss: 46.98335804830842477031\n",
      "Iteration 28845 => Loss: 46.98318975422701981870\n",
      "Iteration 28846 => Loss: 46.98302146146637170432\n",
      "Iteration 28847 => Loss: 46.98285317002646621631\n",
      "Iteration 28848 => Loss: 46.98268487990733888182\n",
      "Iteration 28849 => Loss: 46.98251659110889022486\n",
      "Iteration 28850 => Loss: 46.98234830363121972141\n",
      "Iteration 28851 => Loss: 46.98218001747422079006\n",
      "Iteration 28852 => Loss: 46.98201173263792895796\n",
      "Iteration 28853 => Loss: 46.98184344912233711966\n",
      "Iteration 28854 => Loss: 46.98167516692742395890\n",
      "Iteration 28855 => Loss: 46.98150688605317526481\n",
      "Iteration 28856 => Loss: 46.98133860649959103739\n",
      "Iteration 28857 => Loss: 46.98117032826665706580\n",
      "Iteration 28858 => Loss: 46.98100205135435913917\n",
      "Iteration 28859 => Loss: 46.98083377576269725751\n",
      "Iteration 28860 => Loss: 46.98066550149162878824\n",
      "Iteration 28861 => Loss: 46.98049722854118215309\n",
      "Iteration 28862 => Loss: 46.98032895691134314120\n",
      "Iteration 28863 => Loss: 46.98016068660208333085\n",
      "Iteration 28864 => Loss: 46.97999241761340272205\n",
      "Iteration 28865 => Loss: 46.97982414994527289309\n",
      "Iteration 28866 => Loss: 46.97965588359772937110\n",
      "Iteration 28867 => Loss: 46.97948761857070820724\n",
      "Iteration 28868 => Loss: 46.97931935486423782322\n",
      "Iteration 28869 => Loss: 46.97915109247825427019\n",
      "Iteration 28870 => Loss: 46.97898283141280728614\n",
      "Iteration 28871 => Loss: 46.97881457166786844937\n",
      "Iteration 28872 => Loss: 46.97864631324343065444\n",
      "Iteration 28873 => Loss: 46.97847805613947969050\n",
      "Iteration 28874 => Loss: 46.97830980035600134670\n",
      "Iteration 28875 => Loss: 46.97814154589294588504\n",
      "Iteration 28876 => Loss: 46.97797329275039146523\n",
      "Iteration 28877 => Loss: 46.97780504092825992757\n",
      "Iteration 28878 => Loss: 46.97763679042656548290\n",
      "Iteration 28879 => Loss: 46.97746854124527260410\n",
      "Iteration 28880 => Loss: 46.97730029338440971287\n",
      "Iteration 28881 => Loss: 46.97713204684394128208\n",
      "Iteration 28882 => Loss: 46.97696380162386020629\n",
      "Iteration 28883 => Loss: 46.97679555772415938009\n",
      "Iteration 28884 => Loss: 46.97662731514482459261\n",
      "Iteration 28885 => Loss: 46.97645907388585584386\n",
      "Iteration 28886 => Loss: 46.97629083394725313383\n",
      "Iteration 28887 => Loss: 46.97612259532894540826\n",
      "Iteration 28888 => Loss: 46.97595435803098951055\n",
      "Iteration 28889 => Loss: 46.97578612205334991359\n",
      "Iteration 28890 => Loss: 46.97561788739602661735\n",
      "Iteration 28891 => Loss: 46.97544965405898409472\n",
      "Iteration 28892 => Loss: 46.97528142204223655654\n",
      "Iteration 28893 => Loss: 46.97511319134577689738\n",
      "Iteration 28894 => Loss: 46.97494496196956248468\n",
      "Iteration 28895 => Loss: 46.97477673391361463473\n",
      "Iteration 28896 => Loss: 46.97460850717789782038\n",
      "Iteration 28897 => Loss: 46.97444028176241914707\n",
      "Iteration 28898 => Loss: 46.97427205766718572022\n",
      "Iteration 28899 => Loss: 46.97410383489214069641\n",
      "Iteration 28900 => Loss: 46.97393561343731249735\n",
      "Iteration 28901 => Loss: 46.97376739330267270134\n",
      "Iteration 28902 => Loss: 46.97359917448821420294\n",
      "Iteration 28903 => Loss: 46.97343095699393700215\n",
      "Iteration 28904 => Loss: 46.97326274081980557185\n",
      "Iteration 28905 => Loss: 46.97309452596586965001\n",
      "Iteration 28906 => Loss: 46.97292631243201554980\n",
      "Iteration 28907 => Loss: 46.97275810021832853636\n",
      "Iteration 28908 => Loss: 46.97258988932474466083\n",
      "Iteration 28909 => Loss: 46.97242167975127813406\n",
      "Iteration 28910 => Loss: 46.97225347149792895607\n",
      "Iteration 28911 => Loss: 46.97208526456464028342\n",
      "Iteration 28912 => Loss: 46.97191705895144764327\n",
      "Iteration 28913 => Loss: 46.97174885465832261389\n",
      "Iteration 28914 => Loss: 46.97158065168525098443\n",
      "Iteration 28915 => Loss: 46.97141245003222564947\n",
      "Iteration 28916 => Loss: 46.97124424969923239814\n",
      "Iteration 28917 => Loss: 46.97107605068629965217\n",
      "Iteration 28918 => Loss: 46.97090785299334214642\n",
      "Iteration 28919 => Loss: 46.97073965662040961888\n",
      "Iteration 28920 => Loss: 46.97057146156747364785\n",
      "Iteration 28921 => Loss: 46.97040326783452002246\n",
      "Iteration 28922 => Loss: 46.97023507542156295358\n",
      "Iteration 28923 => Loss: 46.97006688432853138693\n",
      "Iteration 28924 => Loss: 46.96989869455548216592\n",
      "Iteration 28925 => Loss: 46.96973050610236555258\n",
      "Iteration 28926 => Loss: 46.96956231896918865232\n",
      "Iteration 28927 => Loss: 46.96939413315595146514\n",
      "Iteration 28928 => Loss: 46.96922594866259714763\n",
      "Iteration 28929 => Loss: 46.96905776548916122692\n",
      "Iteration 28930 => Loss: 46.96888958363561528131\n",
      "Iteration 28931 => Loss: 46.96872140310195931079\n",
      "Iteration 28932 => Loss: 46.96855322388816489365\n",
      "Iteration 28933 => Loss: 46.96838504599425334618\n",
      "Iteration 28934 => Loss: 46.96821686942016071953\n",
      "Iteration 28935 => Loss: 46.96804869416590832998\n",
      "Iteration 28936 => Loss: 46.96788052023154591552\n",
      "Iteration 28937 => Loss: 46.96771234761694557847\n",
      "Iteration 28938 => Loss: 46.96754417632215705680\n",
      "Iteration 28939 => Loss: 46.96737600634718035053\n",
      "Iteration 28940 => Loss: 46.96720783769200835422\n",
      "Iteration 28941 => Loss: 46.96703967035658422446\n",
      "Iteration 28942 => Loss: 46.96687150434093638296\n",
      "Iteration 28943 => Loss: 46.96670333964508614599\n",
      "Iteration 28944 => Loss: 46.96653517626893403758\n",
      "Iteration 28945 => Loss: 46.96636701421252269029\n",
      "Iteration 28946 => Loss: 46.96619885347588052582\n",
      "Iteration 28947 => Loss: 46.96603069405890096277\n",
      "Iteration 28948 => Loss: 46.96586253596166216084\n",
      "Iteration 28949 => Loss: 46.96569437918411438204\n",
      "Iteration 28950 => Loss: 46.96552622372626473179\n",
      "Iteration 28951 => Loss: 46.96535806958804215583\n",
      "Iteration 28952 => Loss: 46.96518991676954613013\n",
      "Iteration 28953 => Loss: 46.96502176527066296785\n",
      "Iteration 28954 => Loss: 46.96485361509142819614\n",
      "Iteration 28955 => Loss: 46.96468546623184181499\n",
      "Iteration 28956 => Loss: 46.96451731869188250812\n",
      "Iteration 28957 => Loss: 46.96434917247152185382\n",
      "Iteration 28958 => Loss: 46.96418102757076695752\n",
      "Iteration 28959 => Loss: 46.96401288398960360837\n",
      "Iteration 28960 => Loss: 46.96384474172802470093\n",
      "Iteration 28961 => Loss: 46.96367660078602312979\n",
      "Iteration 28962 => Loss: 46.96350846116357047322\n",
      "Iteration 28963 => Loss: 46.96334032286065962580\n",
      "Iteration 28964 => Loss: 46.96317218587731900925\n",
      "Iteration 28965 => Loss: 46.96300405021349178014\n",
      "Iteration 28966 => Loss: 46.96283591586919925476\n",
      "Iteration 28967 => Loss: 46.96266778284439880053\n",
      "Iteration 28968 => Loss: 46.96249965113909041747\n",
      "Iteration 28969 => Loss: 46.96233152075328121100\n",
      "Iteration 28970 => Loss: 46.96216339168695697026\n",
      "Iteration 28971 => Loss: 46.96199526394008927355\n",
      "Iteration 28972 => Loss: 46.96182713751268522628\n",
      "Iteration 28973 => Loss: 46.96165901240473061762\n",
      "Iteration 28974 => Loss: 46.96149088861620413127\n",
      "Iteration 28975 => Loss: 46.96132276614712708351\n",
      "Iteration 28976 => Loss: 46.96115464499742842008\n",
      "Iteration 28977 => Loss: 46.96098652516716498440\n",
      "Iteration 28978 => Loss: 46.96081840665629414389\n",
      "Iteration 28979 => Loss: 46.96065028946480168770\n",
      "Iteration 28980 => Loss: 46.96048217359270182669\n",
      "Iteration 28981 => Loss: 46.96031405903995192830\n",
      "Iteration 28982 => Loss: 46.96014594580653778166\n",
      "Iteration 28983 => Loss: 46.95997783389248780850\n",
      "Iteration 28984 => Loss: 46.95980972329777358709\n",
      "Iteration 28985 => Loss: 46.95964161402238801202\n",
      "Iteration 28986 => Loss: 46.95947350606628134528\n",
      "Iteration 28987 => Loss: 46.95930539942951043031\n",
      "Iteration 28988 => Loss: 46.95913729411201842368\n",
      "Iteration 28989 => Loss: 46.95896919011381953624\n",
      "Iteration 28990 => Loss: 46.95880108743489955714\n",
      "Iteration 28991 => Loss: 46.95863298607520874839\n",
      "Iteration 28992 => Loss: 46.95846488603477553170\n",
      "Iteration 28993 => Loss: 46.95829678731359990707\n",
      "Iteration 28994 => Loss: 46.95812868991163213650\n",
      "Iteration 28995 => Loss: 46.95796059382890774714\n",
      "Iteration 28996 => Loss: 46.95779249906536989556\n",
      "Iteration 28997 => Loss: 46.95762440562104700348\n",
      "Iteration 28998 => Loss: 46.95745631349591064918\n",
      "Iteration 28999 => Loss: 46.95728822268993241096\n",
      "Iteration 29000 => Loss: 46.95712013320316913223\n",
      "Iteration 29001 => Loss: 46.95695204503552133701\n",
      "Iteration 29002 => Loss: 46.95678395818703876330\n",
      "Iteration 29003 => Loss: 46.95661587265769298938\n",
      "Iteration 29004 => Loss: 46.95644778844745559354\n",
      "Iteration 29005 => Loss: 46.95627970555635499750\n",
      "Iteration 29006 => Loss: 46.95611162398434146326\n",
      "Iteration 29007 => Loss: 46.95594354373144341253\n",
      "Iteration 29008 => Loss: 46.95577546479761821274\n",
      "Iteration 29009 => Loss: 46.95560738718288007476\n",
      "Iteration 29010 => Loss: 46.95543931088719347144\n",
      "Iteration 29011 => Loss: 46.95527123591055840279\n",
      "Iteration 29012 => Loss: 46.95510316225296776338\n",
      "Iteration 29013 => Loss: 46.95493508991442155320\n",
      "Iteration 29014 => Loss: 46.95476701889487713970\n",
      "Iteration 29015 => Loss: 46.95459894919436294458\n",
      "Iteration 29016 => Loss: 46.95443088081287186242\n",
      "Iteration 29017 => Loss: 46.95426281375033283894\n",
      "Iteration 29018 => Loss: 46.95409474800678850670\n",
      "Iteration 29019 => Loss: 46.95392668358221754943\n",
      "Iteration 29020 => Loss: 46.95375862047660575627\n",
      "Iteration 29021 => Loss: 46.95359055868994602179\n",
      "Iteration 29022 => Loss: 46.95342249822222413513\n",
      "Iteration 29023 => Loss: 46.95325443907344009631\n",
      "Iteration 29024 => Loss: 46.95308638124355837817\n",
      "Iteration 29025 => Loss: 46.95291832473260740244\n",
      "Iteration 29026 => Loss: 46.95275026954053032568\n",
      "Iteration 29027 => Loss: 46.95258221566736267505\n",
      "Iteration 29028 => Loss: 46.95241416311306181797\n",
      "Iteration 29029 => Loss: 46.95224611187764907072\n",
      "Iteration 29030 => Loss: 46.95207806196106758989\n",
      "Iteration 29031 => Loss: 46.95191001336333158633\n",
      "Iteration 29032 => Loss: 46.95174196608444816547\n",
      "Iteration 29033 => Loss: 46.95157392012440311646\n",
      "Iteration 29034 => Loss: 46.95140587548315380673\n",
      "Iteration 29035 => Loss: 46.95123783216070734170\n",
      "Iteration 29036 => Loss: 46.95106979015706372138\n",
      "Iteration 29037 => Loss: 46.95090174947219452406\n",
      "Iteration 29038 => Loss: 46.95073371010612106602\n",
      "Iteration 29039 => Loss: 46.95056567205877229298\n",
      "Iteration 29040 => Loss: 46.95039763533020504838\n",
      "Iteration 29041 => Loss: 46.95022959992039091048\n",
      "Iteration 29042 => Loss: 46.95006156582929435217\n",
      "Iteration 29043 => Loss: 46.94989353305692247886\n",
      "Iteration 29044 => Loss: 46.94972550160326818514\n",
      "Iteration 29045 => Loss: 46.94955747146831726013\n",
      "Iteration 29046 => Loss: 46.94938944265205549300\n",
      "Iteration 29047 => Loss: 46.94922141515448288374\n",
      "Iteration 29048 => Loss: 46.94905338897555679978\n",
      "Iteration 29049 => Loss: 46.94888536411530566284\n",
      "Iteration 29050 => Loss: 46.94871734057369394577\n",
      "Iteration 29051 => Loss: 46.94854931835074296487\n",
      "Iteration 29052 => Loss: 46.94838129744641719299\n",
      "Iteration 29053 => Loss: 46.94821327786069531385\n",
      "Iteration 29054 => Loss: 46.94804525959359864373\n",
      "Iteration 29055 => Loss: 46.94787724264508455008\n",
      "Iteration 29056 => Loss: 46.94770922701516724374\n",
      "Iteration 29057 => Loss: 46.94754121270384672471\n",
      "Iteration 29058 => Loss: 46.94737319971105904415\n",
      "Iteration 29059 => Loss: 46.94720518803683972919\n",
      "Iteration 29060 => Loss: 46.94703717768118167442\n",
      "Iteration 29061 => Loss: 46.94686916864404224725\n",
      "Iteration 29062 => Loss: 46.94670116092543565856\n",
      "Iteration 29063 => Loss: 46.94653315452534769747\n",
      "Iteration 29064 => Loss: 46.94636514944377836400\n",
      "Iteration 29065 => Loss: 46.94619714568068502558\n",
      "Iteration 29066 => Loss: 46.94602914323608189306\n",
      "Iteration 29067 => Loss: 46.94586114210994765017\n",
      "Iteration 29068 => Loss: 46.94569314230228229690\n",
      "Iteration 29069 => Loss: 46.94552514381307872782\n",
      "Iteration 29070 => Loss: 46.94535714664230141580\n",
      "Iteration 29071 => Loss: 46.94518915078997167711\n",
      "Iteration 29072 => Loss: 46.94502115625603977378\n",
      "Iteration 29073 => Loss: 46.94485316304054833836\n",
      "Iteration 29074 => Loss: 46.94468517114344763286\n",
      "Iteration 29075 => Loss: 46.94451718056474476271\n",
      "Iteration 29076 => Loss: 46.94434919130441130619\n",
      "Iteration 29077 => Loss: 46.94418120336245436874\n",
      "Iteration 29078 => Loss: 46.94401321673885263408\n",
      "Iteration 29079 => Loss: 46.94384523143360610220\n",
      "Iteration 29080 => Loss: 46.94367724744670766768\n",
      "Iteration 29081 => Loss: 46.94350926477812890880\n",
      "Iteration 29082 => Loss: 46.94334128342789114186\n",
      "Iteration 29083 => Loss: 46.94317330339592331256\n",
      "Iteration 29084 => Loss: 46.94300532468228936978\n",
      "Iteration 29085 => Loss: 46.94283734728692536464\n",
      "Iteration 29086 => Loss: 46.94266937120983840259\n",
      "Iteration 29087 => Loss: 46.94250139645102137820\n",
      "Iteration 29088 => Loss: 46.94233342301048139689\n",
      "Iteration 29089 => Loss: 46.94216545088815450981\n",
      "Iteration 29090 => Loss: 46.94199748008406913868\n",
      "Iteration 29091 => Loss: 46.94182951059821817807\n",
      "Iteration 29092 => Loss: 46.94166154243058741713\n",
      "Iteration 29093 => Loss: 46.94149357558115553957\n",
      "Iteration 29094 => Loss: 46.94132561004992965081\n",
      "Iteration 29095 => Loss: 46.94115764583688843459\n",
      "Iteration 29096 => Loss: 46.94098968294199636375\n",
      "Iteration 29097 => Loss: 46.94082172136529607087\n",
      "Iteration 29098 => Loss: 46.94065376110672360710\n",
      "Iteration 29099 => Loss: 46.94048580216632160500\n",
      "Iteration 29100 => Loss: 46.94031784454404032658\n",
      "Iteration 29101 => Loss: 46.94014988823988687727\n",
      "Iteration 29102 => Loss: 46.93998193325383994079\n",
      "Iteration 29103 => Loss: 46.93981397958588530628\n",
      "Iteration 29104 => Loss: 46.93964602723604429002\n",
      "Iteration 29105 => Loss: 46.93947807620426004860\n",
      "Iteration 29106 => Loss: 46.93931012649056810915\n",
      "Iteration 29107 => Loss: 46.93914217809492583910\n",
      "Iteration 29108 => Loss: 46.93897423101734034390\n",
      "Iteration 29109 => Loss: 46.93880628525778320181\n",
      "Iteration 29110 => Loss: 46.93863834081625441286\n",
      "Iteration 29111 => Loss: 46.93847039769276108245\n",
      "Iteration 29112 => Loss: 46.93830245588725347261\n",
      "Iteration 29113 => Loss: 46.93813451539977421589\n",
      "Iteration 29114 => Loss: 46.93796657623027357431\n",
      "Iteration 29115 => Loss: 46.93779863837874444243\n",
      "Iteration 29116 => Loss: 46.93763070184517260941\n",
      "Iteration 29117 => Loss: 46.93746276662957228609\n",
      "Iteration 29118 => Loss: 46.93729483273190794534\n",
      "Iteration 29119 => Loss: 46.93712690015219379802\n",
      "Iteration 29120 => Loss: 46.93695896889040852784\n",
      "Iteration 29121 => Loss: 46.93679103894650239681\n",
      "Iteration 29122 => Loss: 46.93662311032053224835\n",
      "Iteration 29123 => Loss: 46.93645518301247676618\n",
      "Iteration 29124 => Loss: 46.93628725702225068517\n",
      "Iteration 29125 => Loss: 46.93611933234995348130\n",
      "Iteration 29126 => Loss: 46.93595140899548567859\n",
      "Iteration 29127 => Loss: 46.93578348695886859332\n",
      "Iteration 29128 => Loss: 46.93561556624011643635\n",
      "Iteration 29129 => Loss: 46.93544764683920078596\n",
      "Iteration 29130 => Loss: 46.93527972875610032588\n",
      "Iteration 29131 => Loss: 46.93511181199081505611\n",
      "Iteration 29132 => Loss: 46.93494389654330944950\n",
      "Iteration 29133 => Loss: 46.93477598241361903320\n",
      "Iteration 29134 => Loss: 46.93460806960169406921\n",
      "Iteration 29135 => Loss: 46.93444015810756297924\n",
      "Iteration 29136 => Loss: 46.93427224793118313073\n",
      "Iteration 29137 => Loss: 46.93410433907254031283\n",
      "Iteration 29138 => Loss: 46.93393643153163452553\n",
      "Iteration 29139 => Loss: 46.93376852530847287426\n",
      "Iteration 29140 => Loss: 46.93360062040302693731\n",
      "Iteration 29141 => Loss: 46.93343271681528960926\n",
      "Iteration 29142 => Loss: 46.93326481454526799553\n",
      "Iteration 29143 => Loss: 46.93309691359289104184\n",
      "Iteration 29144 => Loss: 46.93292901395823690791\n",
      "Iteration 29145 => Loss: 46.93276111564122032860\n",
      "Iteration 29146 => Loss: 46.93259321864186972562\n",
      "Iteration 29147 => Loss: 46.93242532296017088811\n",
      "Iteration 29148 => Loss: 46.93225742859610960522\n",
      "Iteration 29149 => Loss: 46.93208953554967166610\n",
      "Iteration 29150 => Loss: 46.93192164382082154361\n",
      "Iteration 29151 => Loss: 46.93175375340962318660\n",
      "Iteration 29152 => Loss: 46.93158586431600554079\n",
      "Iteration 29153 => Loss: 46.93141797653997571160\n",
      "Iteration 29154 => Loss: 46.93125009008148396106\n",
      "Iteration 29155 => Loss: 46.93108220494060134342\n",
      "Iteration 29156 => Loss: 46.93091432111725680443\n",
      "Iteration 29157 => Loss: 46.93074643861145744950\n",
      "Iteration 29158 => Loss: 46.93057855742318196235\n",
      "Iteration 29159 => Loss: 46.93041067755244455384\n",
      "Iteration 29160 => Loss: 46.93024279899920259140\n",
      "Iteration 29161 => Loss: 46.93007492176347739132\n",
      "Iteration 29162 => Loss: 46.92990704584523342646\n",
      "Iteration 29163 => Loss: 46.92973917124448490767\n",
      "Iteration 29164 => Loss: 46.92957129796118920240\n",
      "Iteration 29165 => Loss: 46.92940342599534631063\n",
      "Iteration 29166 => Loss: 46.92923555534697754865\n",
      "Iteration 29167 => Loss: 46.92906768601603317848\n",
      "Iteration 29168 => Loss: 46.92889981800254162181\n",
      "Iteration 29169 => Loss: 46.92873195130643892981\n",
      "Iteration 29170 => Loss: 46.92856408592777484046\n",
      "Iteration 29171 => Loss: 46.92839622186649251034\n",
      "Iteration 29172 => Loss: 46.92822835912260615032\n",
      "Iteration 29173 => Loss: 46.92806049769609444411\n",
      "Iteration 29174 => Loss: 46.92789263758693607542\n",
      "Iteration 29175 => Loss: 46.92772477879515236054\n",
      "Iteration 29176 => Loss: 46.92755692132070066691\n",
      "Iteration 29177 => Loss: 46.92738906516358809995\n",
      "Iteration 29178 => Loss: 46.92722121032382176509\n",
      "Iteration 29179 => Loss: 46.92705335680137324061\n",
      "Iteration 29180 => Loss: 46.92688550459619989397\n",
      "Iteration 29181 => Loss: 46.92671765370833014686\n",
      "Iteration 29182 => Loss: 46.92654980413775689385\n",
      "Iteration 29183 => Loss: 46.92638195588444460782\n",
      "Iteration 29184 => Loss: 46.92621410894841460504\n",
      "Iteration 29185 => Loss: 46.92604626332963135837\n",
      "Iteration 29186 => Loss: 46.92587841902808776240\n",
      "Iteration 29187 => Loss: 46.92571057604377671169\n",
      "Iteration 29188 => Loss: 46.92554273437670531166\n",
      "Iteration 29189 => Loss: 46.92537489402681671891\n",
      "Iteration 29190 => Loss: 46.92520705499416067141\n",
      "Iteration 29191 => Loss: 46.92503921727866611491\n",
      "Iteration 29192 => Loss: 46.92487138088037568195\n",
      "Iteration 29193 => Loss: 46.92470354579923963456\n",
      "Iteration 29194 => Loss: 46.92453571203529349987\n",
      "Iteration 29195 => Loss: 46.92436787958847332902\n",
      "Iteration 29196 => Loss: 46.92420004845880754374\n",
      "Iteration 29197 => Loss: 46.92403221864623930060\n",
      "Iteration 29198 => Loss: 46.92386439015082544302\n",
      "Iteration 29199 => Loss: 46.92369656297250912758\n",
      "Iteration 29200 => Loss: 46.92352873711129745971\n",
      "Iteration 29201 => Loss: 46.92336091256718333398\n",
      "Iteration 29202 => Loss: 46.92319308934012411783\n",
      "Iteration 29203 => Loss: 46.92302526743013402211\n",
      "Iteration 29204 => Loss: 46.92285744683722015225\n",
      "Iteration 29205 => Loss: 46.92268962756132566483\n",
      "Iteration 29206 => Loss: 46.92252180960250740327\n",
      "Iteration 29207 => Loss: 46.92235399296066589159\n",
      "Iteration 29208 => Loss: 46.92218617763588639491\n",
      "Iteration 29209 => Loss: 46.92201836362809075354\n",
      "Iteration 29210 => Loss: 46.92185055093729317832\n",
      "Iteration 29211 => Loss: 46.92168273956347235298\n",
      "Iteration 29212 => Loss: 46.92151492950664248838\n",
      "Iteration 29213 => Loss: 46.92134712076676805736\n",
      "Iteration 29214 => Loss: 46.92117931334385616537\n",
      "Iteration 29215 => Loss: 46.92101150723788549612\n",
      "Iteration 29216 => Loss: 46.92084370244883473333\n",
      "Iteration 29217 => Loss: 46.92067589897673229871\n",
      "Iteration 29218 => Loss: 46.92050809682152134883\n",
      "Iteration 29219 => Loss: 46.92034029598320898913\n",
      "Iteration 29220 => Loss: 46.92017249646180232503\n",
      "Iteration 29221 => Loss: 46.92000469825728004025\n",
      "Iteration 29222 => Loss: 46.91983690136962792394\n",
      "Iteration 29223 => Loss: 46.91966910579881755439\n",
      "Iteration 29224 => Loss: 46.91950131154487735330\n",
      "Iteration 29225 => Loss: 46.91933351860777889897\n",
      "Iteration 29226 => Loss: 46.91916572698750087511\n",
      "Iteration 29227 => Loss: 46.91899793668405038716\n",
      "Iteration 29228 => Loss: 46.91883014769739190797\n",
      "Iteration 29229 => Loss: 46.91866236002756096468\n",
      "Iteration 29230 => Loss: 46.91849457367450071388\n",
      "Iteration 29231 => Loss: 46.91832678863821826099\n",
      "Iteration 29232 => Loss: 46.91815900491871360600\n",
      "Iteration 29233 => Loss: 46.91799122251595832722\n",
      "Iteration 29234 => Loss: 46.91782344142994531921\n",
      "Iteration 29235 => Loss: 46.91765566166068168741\n",
      "Iteration 29236 => Loss: 46.91748788320812479924\n",
      "Iteration 29237 => Loss: 46.91732010607230307642\n",
      "Iteration 29238 => Loss: 46.91715233025319520266\n",
      "Iteration 29239 => Loss: 46.91698455575075854540\n",
      "Iteration 29240 => Loss: 46.91681678256503573721\n",
      "Iteration 29241 => Loss: 46.91664901069596282923\n",
      "Iteration 29242 => Loss: 46.91648124014357534861\n",
      "Iteration 29243 => Loss: 46.91631347090783066278\n",
      "Iteration 29244 => Loss: 46.91614570298873587717\n",
      "Iteration 29245 => Loss: 46.91597793638626967549\n",
      "Iteration 29246 => Loss: 46.91581017110042495233\n",
      "Iteration 29247 => Loss: 46.91564240713119460224\n",
      "Iteration 29248 => Loss: 46.91547464447857151981\n",
      "Iteration 29249 => Loss: 46.91530688314254149418\n",
      "Iteration 29250 => Loss: 46.91513912312309031449\n",
      "Iteration 29251 => Loss: 46.91497136442021087532\n",
      "Iteration 29252 => Loss: 46.91480360703389607124\n",
      "Iteration 29253 => Loss: 46.91463585096411748054\n",
      "Iteration 29254 => Loss: 46.91446809621089641951\n",
      "Iteration 29255 => Loss: 46.91430034277419736100\n",
      "Iteration 29256 => Loss: 46.91413259065403451586\n",
      "Iteration 29257 => Loss: 46.91396483985036525155\n",
      "Iteration 29258 => Loss: 46.91379709036320377891\n",
      "Iteration 29259 => Loss: 46.91362934219252167622\n",
      "Iteration 29260 => Loss: 46.91346159533831894350\n",
      "Iteration 29261 => Loss: 46.91329384980058136989\n",
      "Iteration 29262 => Loss: 46.91312610557931606081\n",
      "Iteration 29263 => Loss: 46.91295836267449459456\n",
      "Iteration 29264 => Loss: 46.91279062108610986570\n",
      "Iteration 29265 => Loss: 46.91262288081415476881\n",
      "Iteration 29266 => Loss: 46.91245514185860088219\n",
      "Iteration 29267 => Loss: 46.91228740421946241668\n",
      "Iteration 29268 => Loss: 46.91211966789671805600\n",
      "Iteration 29269 => Loss: 46.91195193289038201101\n",
      "Iteration 29270 => Loss: 46.91178419920040454372\n",
      "Iteration 29271 => Loss: 46.91161646682677144327\n",
      "Iteration 29272 => Loss: 46.91144873576951113137\n",
      "Iteration 29273 => Loss: 46.91128100602860939716\n",
      "Iteration 29274 => Loss: 46.91111327760403071352\n",
      "Iteration 29275 => Loss: 46.91094555049576086958\n",
      "Iteration 29276 => Loss: 46.91077782470382118163\n",
      "Iteration 29277 => Loss: 46.91061010022819033338\n",
      "Iteration 29278 => Loss: 46.91044237706884700856\n",
      "Iteration 29279 => Loss: 46.91027465522576989088\n",
      "Iteration 29280 => Loss: 46.91010693469899450747\n",
      "Iteration 29281 => Loss: 46.90993921548845690950\n",
      "Iteration 29282 => Loss: 46.90977149759417841324\n",
      "Iteration 29283 => Loss: 46.90960378101615191326\n",
      "Iteration 29284 => Loss: 46.90943606575433477701\n",
      "Iteration 29285 => Loss: 46.90926835180875542619\n",
      "Iteration 29286 => Loss: 46.90910063917937122824\n",
      "Iteration 29287 => Loss: 46.90893292786619639401\n",
      "Iteration 29288 => Loss: 46.90876521786920960722\n",
      "Iteration 29289 => Loss: 46.90859750918839665701\n",
      "Iteration 29290 => Loss: 46.90842980182376464882\n",
      "Iteration 29291 => Loss: 46.90826209577527805550\n",
      "Iteration 29292 => Loss: 46.90809439104295108791\n",
      "Iteration 29293 => Loss: 46.90792668762676953520\n",
      "Iteration 29294 => Loss: 46.90775898552670497565\n",
      "Iteration 29295 => Loss: 46.90759128474274319842\n",
      "Iteration 29296 => Loss: 46.90742358527491262521\n",
      "Iteration 29297 => Loss: 46.90725588712314930717\n",
      "Iteration 29298 => Loss: 46.90708819028750298230\n",
      "Iteration 29299 => Loss: 46.90692049476789549090\n",
      "Iteration 29300 => Loss: 46.90675280056438367637\n",
      "Iteration 29301 => Loss: 46.90658510767693201160\n",
      "Iteration 29302 => Loss: 46.90641741610550496944\n",
      "Iteration 29303 => Loss: 46.90624972585013807702\n",
      "Iteration 29304 => Loss: 46.90608203691078870179\n",
      "Iteration 29305 => Loss: 46.90591434928742842203\n",
      "Iteration 29306 => Loss: 46.90574666298010697574\n",
      "Iteration 29307 => Loss: 46.90557897798875330864\n",
      "Iteration 29308 => Loss: 46.90541129431339584244\n",
      "Iteration 29309 => Loss: 46.90524361195399194457\n",
      "Iteration 29310 => Loss: 46.90507593091055582590\n",
      "Iteration 29311 => Loss: 46.90490825118308748642\n",
      "Iteration 29312 => Loss: 46.90474057277153008272\n",
      "Iteration 29313 => Loss: 46.90457289567595466906\n",
      "Iteration 29314 => Loss: 46.90440521989624755861\n",
      "Iteration 29315 => Loss: 46.90423754543247270021\n",
      "Iteration 29316 => Loss: 46.90406987228460877759\n",
      "Iteration 29317 => Loss: 46.90390220045263447446\n",
      "Iteration 29318 => Loss: 46.90373452993654268539\n",
      "Iteration 29319 => Loss: 46.90356686073628367240\n",
      "Iteration 29320 => Loss: 46.90339919285191427889\n",
      "Iteration 29321 => Loss: 46.90323152628340608317\n",
      "Iteration 29322 => Loss: 46.90306386103070934723\n",
      "Iteration 29323 => Loss: 46.90289619709384538737\n",
      "Iteration 29324 => Loss: 46.90272853447281420358\n",
      "Iteration 29325 => Loss: 46.90256087316758026873\n",
      "Iteration 29326 => Loss: 46.90239321317812937195\n",
      "Iteration 29327 => Loss: 46.90222555450449704040\n",
      "Iteration 29328 => Loss: 46.90205789714661221979\n",
      "Iteration 29329 => Loss: 46.90189024110449622640\n",
      "Iteration 29330 => Loss: 46.90172258637814195481\n",
      "Iteration 29331 => Loss: 46.90155493296754229959\n",
      "Iteration 29332 => Loss: 46.90138728087267594447\n",
      "Iteration 29333 => Loss: 46.90121963009353578400\n",
      "Iteration 29334 => Loss: 46.90105198063008629106\n",
      "Iteration 29335 => Loss: 46.90088433248237720363\n",
      "Iteration 29336 => Loss: 46.90071668565033746745\n",
      "Iteration 29337 => Loss: 46.90054904013400260965\n",
      "Iteration 29338 => Loss: 46.90038139593331578681\n",
      "Iteration 29339 => Loss: 46.90021375304829831521\n",
      "Iteration 29340 => Loss: 46.90004611147893598400\n",
      "Iteration 29341 => Loss: 46.89987847122520037146\n",
      "Iteration 29342 => Loss: 46.89971083228713411017\n",
      "Iteration 29343 => Loss: 46.89954319466465193500\n",
      "Iteration 29344 => Loss: 46.89937555835780358393\n",
      "Iteration 29345 => Loss: 46.89920792336655352983\n",
      "Iteration 29346 => Loss: 46.89904028969089466727\n",
      "Iteration 29347 => Loss: 46.89887265733079857455\n",
      "Iteration 29348 => Loss: 46.89870502628630077879\n",
      "Iteration 29349 => Loss: 46.89853739655734443659\n",
      "Iteration 29350 => Loss: 46.89836976814392954793\n",
      "Iteration 29351 => Loss: 46.89820214104606321825\n",
      "Iteration 29352 => Loss: 46.89803451526373123670\n",
      "Iteration 29353 => Loss: 46.89786689079691228699\n",
      "Iteration 29354 => Loss: 46.89769926764561347454\n",
      "Iteration 29355 => Loss: 46.89753164580978506137\n",
      "Iteration 29356 => Loss: 46.89736402528946257462\n",
      "Iteration 29357 => Loss: 46.89719640608462469800\n",
      "Iteration 29358 => Loss: 46.89702878819523590437\n",
      "Iteration 29359 => Loss: 46.89686117162131751002\n",
      "Iteration 29360 => Loss: 46.89669355636283398781\n",
      "Iteration 29361 => Loss: 46.89652594241977823231\n",
      "Iteration 29362 => Loss: 46.89635832979216445437\n",
      "Iteration 29363 => Loss: 46.89619071847997133773\n",
      "Iteration 29364 => Loss: 46.89602310848315624980\n",
      "Iteration 29365 => Loss: 46.89585549980176892859\n",
      "Iteration 29366 => Loss: 46.89568789243574542525\n",
      "Iteration 29367 => Loss: 46.89552028638509995062\n",
      "Iteration 29368 => Loss: 46.89535268164982539929\n",
      "Iteration 29369 => Loss: 46.89518507822988624412\n",
      "Iteration 29370 => Loss: 46.89501747612530380138\n",
      "Iteration 29371 => Loss: 46.89484987533604964938\n",
      "Iteration 29372 => Loss: 46.89468227586210247182\n",
      "Iteration 29373 => Loss: 46.89451467770351200670\n",
      "Iteration 29374 => Loss: 46.89434708086018588347\n",
      "Iteration 29375 => Loss: 46.89417948533214541840\n",
      "Iteration 29376 => Loss: 46.89401189111940482235\n",
      "Iteration 29377 => Loss: 46.89384429822192856818\n",
      "Iteration 29378 => Loss: 46.89367670663971665590\n",
      "Iteration 29379 => Loss: 46.89350911637274776922\n",
      "Iteration 29380 => Loss: 46.89334152742102190814\n",
      "Iteration 29381 => Loss: 46.89317393978451775638\n",
      "Iteration 29382 => Loss: 46.89300635346324241937\n",
      "Iteration 29383 => Loss: 46.89283876845718879167\n",
      "Iteration 29384 => Loss: 46.89267118476630002988\n",
      "Iteration 29385 => Loss: 46.89250360239061876655\n",
      "Iteration 29386 => Loss: 46.89233602133010236912\n",
      "Iteration 29387 => Loss: 46.89216844158476504845\n",
      "Iteration 29388 => Loss: 46.89200086315459259367\n",
      "Iteration 29389 => Loss: 46.89183328603954947766\n",
      "Iteration 29390 => Loss: 46.89166571023966412213\n",
      "Iteration 29391 => Loss: 46.89149813575487968365\n",
      "Iteration 29392 => Loss: 46.89133056258524590021\n",
      "Iteration 29393 => Loss: 46.89116299073067750669\n",
      "Iteration 29394 => Loss: 46.89099542019122424108\n",
      "Iteration 29395 => Loss: 46.89082785096685768167\n",
      "Iteration 29396 => Loss: 46.89066028305757072303\n",
      "Iteration 29397 => Loss: 46.89049271646332783803\n",
      "Iteration 29398 => Loss: 46.89032515118413613209\n",
      "Iteration 29399 => Loss: 46.89015758722000271064\n",
      "Iteration 29400 => Loss: 46.88999002457090625740\n",
      "Iteration 29401 => Loss: 46.88982246323682545608\n",
      "Iteration 29402 => Loss: 46.88965490321776030669\n",
      "Iteration 29403 => Loss: 46.88948734451370370380\n",
      "Iteration 29404 => Loss: 46.88931978712463433112\n",
      "Iteration 29405 => Loss: 46.88915223105053797781\n",
      "Iteration 29406 => Loss: 46.88898467629140753843\n",
      "Iteration 29407 => Loss: 46.88881712284725722384\n",
      "Iteration 29408 => Loss: 46.88864957071804440147\n",
      "Iteration 29409 => Loss: 46.88848201990376907133\n",
      "Iteration 29410 => Loss: 46.88831447040444544427\n",
      "Iteration 29411 => Loss: 46.88814692222003088773\n",
      "Iteration 29412 => Loss: 46.88797937535050408542\n",
      "Iteration 29413 => Loss: 46.88781182979590056448\n",
      "Iteration 29414 => Loss: 46.88764428555617058691\n",
      "Iteration 29415 => Loss: 46.88747674263133546901\n",
      "Iteration 29416 => Loss: 46.88730920102136678906\n",
      "Iteration 29417 => Loss: 46.88714166072624323078\n",
      "Iteration 29418 => Loss: 46.88697412174596479417\n",
      "Iteration 29419 => Loss: 46.88680658408054569009\n",
      "Iteration 29420 => Loss: 46.88663904772992907510\n",
      "Iteration 29421 => Loss: 46.88647151269415047636\n",
      "Iteration 29422 => Loss: 46.88630397897317436673\n",
      "Iteration 29423 => Loss: 46.88613644656697232449\n",
      "Iteration 29424 => Loss: 46.88596891547557987678\n",
      "Iteration 29425 => Loss: 46.88580138569894728562\n",
      "Iteration 29426 => Loss: 46.88563385723709586728\n",
      "Iteration 29427 => Loss: 46.88546633008997588377\n",
      "Iteration 29428 => Loss: 46.88529880425760865137\n",
      "Iteration 29429 => Loss: 46.88513127973998706466\n",
      "Iteration 29430 => Loss: 46.88496375653708270193\n",
      "Iteration 29431 => Loss: 46.88479623464888135231\n",
      "Iteration 29432 => Loss: 46.88462871407539722668\n",
      "Iteration 29433 => Loss: 46.88446119481661611417\n",
      "Iteration 29434 => Loss: 46.88429367687249538221\n",
      "Iteration 29435 => Loss: 46.88412616024303503082\n",
      "Iteration 29436 => Loss: 46.88395864492827058712\n",
      "Iteration 29437 => Loss: 46.88379113092813099684\n",
      "Iteration 29438 => Loss: 46.88362361824265889254\n",
      "Iteration 29439 => Loss: 46.88345610687177611453\n",
      "Iteration 29440 => Loss: 46.88328859681556082251\n",
      "Iteration 29441 => Loss: 46.88312108807394196219\n",
      "Iteration 29442 => Loss: 46.88295358064690532274\n",
      "Iteration 29443 => Loss: 46.88278607453445090414\n",
      "Iteration 29444 => Loss: 46.88261856973660712811\n",
      "Iteration 29445 => Loss: 46.88245106625330294037\n",
      "Iteration 29446 => Loss: 46.88228356408458097349\n",
      "Iteration 29447 => Loss: 46.88211606323039148947\n",
      "Iteration 29448 => Loss: 46.88194856369074869917\n",
      "Iteration 29449 => Loss: 46.88178106546562418089\n",
      "Iteration 29450 => Loss: 46.88161356855502504004\n",
      "Iteration 29451 => Loss: 46.88144607295893706578\n",
      "Iteration 29452 => Loss: 46.88127857867733894182\n",
      "Iteration 29453 => Loss: 46.88111108571023777358\n",
      "Iteration 29454 => Loss: 46.88094359405759092851\n",
      "Iteration 29455 => Loss: 46.88077610371941261747\n",
      "Iteration 29456 => Loss: 46.88060861469571705129\n",
      "Iteration 29457 => Loss: 46.88044112698642607029\n",
      "Iteration 29458 => Loss: 46.88027364059159651788\n",
      "Iteration 29459 => Loss: 46.88010615551119997235\n",
      "Iteration 29460 => Loss: 46.87993867174519380114\n",
      "Iteration 29461 => Loss: 46.87977118929359932054\n",
      "Iteration 29462 => Loss: 46.87960370815640942510\n",
      "Iteration 29463 => Loss: 46.87943622833360279856\n",
      "Iteration 29464 => Loss: 46.87926874982514391377\n",
      "Iteration 29465 => Loss: 46.87910127263106829787\n",
      "Iteration 29466 => Loss: 46.87893379675134042373\n",
      "Iteration 29467 => Loss: 46.87876632218595318591\n",
      "Iteration 29468 => Loss: 46.87859884893489947899\n",
      "Iteration 29469 => Loss: 46.87843137699817930297\n",
      "Iteration 29470 => Loss: 46.87826390637575713072\n",
      "Iteration 29471 => Loss: 46.87809643706762585680\n",
      "Iteration 29472 => Loss: 46.87792896907380679750\n",
      "Iteration 29473 => Loss: 46.87776150239424310939\n",
      "Iteration 29474 => Loss: 46.87759403702894900334\n",
      "Iteration 29475 => Loss: 46.87742657297794579563\n",
      "Iteration 29476 => Loss: 46.87725911024116953740\n",
      "Iteration 29477 => Loss: 46.87709164881862022867\n",
      "Iteration 29478 => Loss: 46.87692418871032629113\n",
      "Iteration 29479 => Loss: 46.87675672991623088137\n",
      "Iteration 29480 => Loss: 46.87658927243637663196\n",
      "Iteration 29481 => Loss: 46.87642181627067827776\n",
      "Iteration 29482 => Loss: 46.87625436141916424049\n",
      "Iteration 29483 => Loss: 46.87608690788185583642\n",
      "Iteration 29484 => Loss: 46.87591945565871753843\n",
      "Iteration 29485 => Loss: 46.87575200474971381936\n",
      "Iteration 29486 => Loss: 46.87558455515487310095\n",
      "Iteration 29487 => Loss: 46.87541710687415985603\n",
      "Iteration 29488 => Loss: 46.87524965990756697920\n",
      "Iteration 29489 => Loss: 46.87508221425507315416\n",
      "Iteration 29490 => Loss: 46.87491476991672101349\n",
      "Iteration 29491 => Loss: 46.87474732689244660833\n",
      "Iteration 29492 => Loss: 46.87457988518224283325\n",
      "Iteration 29493 => Loss: 46.87441244478613810998\n",
      "Iteration 29494 => Loss: 46.87424500570407559508\n",
      "Iteration 29495 => Loss: 46.87407756793607660484\n",
      "Iteration 29496 => Loss: 46.87391013148211271755\n",
      "Iteration 29497 => Loss: 46.87374269634219814407\n",
      "Iteration 29498 => Loss: 46.87357526251629735725\n",
      "Iteration 29499 => Loss: 46.87340783000440325168\n",
      "Iteration 29500 => Loss: 46.87324039880650872192\n",
      "Iteration 29501 => Loss: 46.87307296892260666255\n",
      "Iteration 29502 => Loss: 46.87290554035270417899\n",
      "Iteration 29503 => Loss: 46.87273811309675153325\n",
      "Iteration 29504 => Loss: 46.87257068715476293619\n",
      "Iteration 29505 => Loss: 46.87240326252673128238\n",
      "Iteration 29506 => Loss: 46.87223583921263525554\n",
      "Iteration 29507 => Loss: 46.87206841721246775023\n",
      "Iteration 29508 => Loss: 46.87190099652620745019\n",
      "Iteration 29509 => Loss: 46.87173357715384724997\n",
      "Iteration 29510 => Loss: 46.87156615909543688758\n",
      "Iteration 29511 => Loss: 46.87139874235086978160\n",
      "Iteration 29512 => Loss: 46.87123132692020277545\n",
      "Iteration 29513 => Loss: 46.87106391280337902572\n",
      "Iteration 29514 => Loss: 46.87089650000044827038\n",
      "Iteration 29515 => Loss: 46.87072908851133945518\n",
      "Iteration 29516 => Loss: 46.87056167833606679096\n",
      "Iteration 29517 => Loss: 46.87039426947462317230\n",
      "Iteration 29518 => Loss: 46.87022686192700149377\n",
      "Iteration 29519 => Loss: 46.87005945569318043908\n",
      "Iteration 29520 => Loss: 46.86989205077316711368\n",
      "Iteration 29521 => Loss: 46.86972464716690467412\n",
      "Iteration 29522 => Loss: 46.86955724487444285842\n",
      "Iteration 29523 => Loss: 46.86938984389574613942\n",
      "Iteration 29524 => Loss: 46.86922244423080030629\n",
      "Iteration 29525 => Loss: 46.86905504587959114815\n",
      "Iteration 29526 => Loss: 46.86888764884211866502\n",
      "Iteration 29527 => Loss: 46.86872025311838996231\n",
      "Iteration 29528 => Loss: 46.86855285870834109119\n",
      "Iteration 29529 => Loss: 46.86838546561202178964\n",
      "Iteration 29530 => Loss: 46.86821807382937521425\n",
      "Iteration 29531 => Loss: 46.86805068336042978672\n",
      "Iteration 29532 => Loss: 46.86788329420512866363\n",
      "Iteration 29533 => Loss: 46.86771590636350026671\n",
      "Iteration 29534 => Loss: 46.86754851983554459594\n",
      "Iteration 29535 => Loss: 46.86738113462121191333\n",
      "Iteration 29536 => Loss: 46.86721375072051642974\n",
      "Iteration 29537 => Loss: 46.86704636813341551260\n",
      "Iteration 29538 => Loss: 46.86687898685994468906\n",
      "Iteration 29539 => Loss: 46.86671160690006132654\n",
      "Iteration 29540 => Loss: 46.86654422825379384676\n",
      "Iteration 29541 => Loss: 46.86637685092108540630\n",
      "Iteration 29542 => Loss: 46.86620947490195021601\n",
      "Iteration 29543 => Loss: 46.86604210019638827589\n",
      "Iteration 29544 => Loss: 46.86587472680433563710\n",
      "Iteration 29545 => Loss: 46.86570735472584203762\n",
      "Iteration 29546 => Loss: 46.86553998396087905576\n",
      "Iteration 29547 => Loss: 46.86537261450943958607\n",
      "Iteration 29548 => Loss: 46.86520524637148810143\n",
      "Iteration 29549 => Loss: 46.86503787954703170726\n",
      "Iteration 29550 => Loss: 46.86487051403607040356\n",
      "Iteration 29551 => Loss: 46.86470314983859708491\n",
      "Iteration 29552 => Loss: 46.86453578695459043502\n",
      "Iteration 29553 => Loss: 46.86436842538401492675\n",
      "Iteration 29554 => Loss: 46.86420106512689898182\n",
      "Iteration 29555 => Loss: 46.86403370618321417851\n",
      "Iteration 29556 => Loss: 46.86386634855295341140\n",
      "Iteration 29557 => Loss: 46.86369899223609536421\n",
      "Iteration 29558 => Loss: 46.86353163723266135321\n",
      "Iteration 29559 => Loss: 46.86336428354261585127\n",
      "Iteration 29560 => Loss: 46.86319693116593754212\n",
      "Iteration 29561 => Loss: 46.86302958010265484745\n",
      "Iteration 29562 => Loss: 46.86286223035272513471\n",
      "Iteration 29563 => Loss: 46.86269488191614840389\n",
      "Iteration 29564 => Loss: 46.86252753479289623328\n",
      "Iteration 29565 => Loss: 46.86236018898301125546\n",
      "Iteration 29566 => Loss: 46.86219284448640820528\n",
      "Iteration 29567 => Loss: 46.86202550130314392618\n",
      "Iteration 29568 => Loss: 46.86185815943316157473\n",
      "Iteration 29569 => Loss: 46.86169081887648957263\n",
      "Iteration 29570 => Loss: 46.86152347963306397105\n",
      "Iteration 29571 => Loss: 46.86135614170294161340\n",
      "Iteration 29572 => Loss: 46.86118880508605144541\n",
      "Iteration 29573 => Loss: 46.86102146978243609965\n",
      "Iteration 29574 => Loss: 46.86085413579206004897\n",
      "Iteration 29575 => Loss: 46.86068680311488066081\n",
      "Iteration 29576 => Loss: 46.86051947175095477860\n",
      "Iteration 29577 => Loss: 46.86035214170021134805\n",
      "Iteration 29578 => Loss: 46.86018481296269300174\n",
      "Iteration 29579 => Loss: 46.86001748553831447452\n",
      "Iteration 29580 => Loss: 46.85985015942714682069\n",
      "Iteration 29581 => Loss: 46.85968283462916161852\n",
      "Iteration 29582 => Loss: 46.85951551114430202460\n",
      "Iteration 29583 => Loss: 46.85934818897258935522\n",
      "Iteration 29584 => Loss: 46.85918086811402361036\n",
      "Iteration 29585 => Loss: 46.85901354856859057918\n",
      "Iteration 29586 => Loss: 46.85884623033626894539\n",
      "Iteration 29587 => Loss: 46.85867891341703028729\n",
      "Iteration 29588 => Loss: 46.85851159781090302658\n",
      "Iteration 29589 => Loss: 46.85834428351785163613\n",
      "Iteration 29590 => Loss: 46.85817697053789743222\n",
      "Iteration 29591 => Loss: 46.85800965887098357143\n",
      "Iteration 29592 => Loss: 46.85784234851713137004\n",
      "Iteration 29593 => Loss: 46.85767503947631240635\n",
      "Iteration 29594 => Loss: 46.85750773174855510206\n",
      "Iteration 29595 => Loss: 46.85734042533377419204\n",
      "Iteration 29596 => Loss: 46.85717312023202651972\n",
      "Iteration 29597 => Loss: 46.85700581644329787423\n",
      "Iteration 29598 => Loss: 46.85683851396753851759\n",
      "Iteration 29599 => Loss: 46.85667121280477687151\n",
      "Iteration 29600 => Loss: 46.85650391295496319799\n",
      "Iteration 29601 => Loss: 46.85633661441813302417\n",
      "Iteration 29602 => Loss: 46.85616931719424371749\n",
      "Iteration 29603 => Loss: 46.85600202128329527795\n",
      "Iteration 29604 => Loss: 46.85583472668527349470\n",
      "Iteration 29605 => Loss: 46.85566743340015705144\n",
      "Iteration 29606 => Loss: 46.85550014142798858074\n",
      "Iteration 29607 => Loss: 46.85533285076868992292\n",
      "Iteration 29608 => Loss: 46.85516556142226818338\n",
      "Iteration 29609 => Loss: 46.85499827338873757299\n",
      "Iteration 29610 => Loss: 46.85483098666808388089\n",
      "Iteration 29611 => Loss: 46.85466370126028579080\n",
      "Iteration 29612 => Loss: 46.85449641716533619729\n",
      "Iteration 29613 => Loss: 46.85432913438322799493\n",
      "Iteration 29614 => Loss: 46.85416185291391855117\n",
      "Iteration 29615 => Loss: 46.85399457275745760398\n",
      "Iteration 29616 => Loss: 46.85382729391378120454\n",
      "Iteration 29617 => Loss: 46.85366001638290356368\n",
      "Iteration 29618 => Loss: 46.85349274016481757599\n",
      "Iteration 29619 => Loss: 46.85332546525950903060\n",
      "Iteration 29620 => Loss: 46.85315819166694950582\n",
      "Iteration 29621 => Loss: 46.85299091938714610706\n",
      "Iteration 29622 => Loss: 46.85282364842009883432\n",
      "Iteration 29623 => Loss: 46.85265637876579347676\n",
      "Iteration 29624 => Loss: 46.85248911042420161266\n",
      "Iteration 29625 => Loss: 46.85232184339531613659\n",
      "Iteration 29626 => Loss: 46.85215457767913704856\n",
      "Iteration 29627 => Loss: 46.85198731327563592686\n",
      "Iteration 29628 => Loss: 46.85182005018482698233\n",
      "Iteration 29629 => Loss: 46.85165278840671021499\n",
      "Iteration 29630 => Loss: 46.85148552794124299226\n",
      "Iteration 29631 => Loss: 46.85131826878842531414\n",
      "Iteration 29632 => Loss: 46.85115101094825718064\n",
      "Iteration 29633 => Loss: 46.85098375442071017005\n",
      "Iteration 29634 => Loss: 46.85081649920577717694\n",
      "Iteration 29635 => Loss: 46.85064924530344399045\n",
      "Iteration 29636 => Loss: 46.85048199271373192687\n",
      "Iteration 29637 => Loss: 46.85031474143661256448\n",
      "Iteration 29638 => Loss: 46.85014749147207169244\n",
      "Iteration 29639 => Loss: 46.84998024282008799446\n",
      "Iteration 29640 => Loss: 46.84981299548067568139\n",
      "Iteration 29641 => Loss: 46.84964574945377790982\n",
      "Iteration 29642 => Loss: 46.84947850473946573402\n",
      "Iteration 29643 => Loss: 46.84931126133763967800\n",
      "Iteration 29644 => Loss: 46.84914401924837079605\n",
      "Iteration 29645 => Loss: 46.84897677847158803388\n",
      "Iteration 29646 => Loss: 46.84880953900728428607\n",
      "Iteration 29647 => Loss: 46.84864230085550218519\n",
      "Iteration 29648 => Loss: 46.84847506401618488781\n",
      "Iteration 29649 => Loss: 46.84830782848932528850\n",
      "Iteration 29650 => Loss: 46.84814059427491628185\n",
      "Iteration 29651 => Loss: 46.84797336137297207870\n",
      "Iteration 29652 => Loss: 46.84780612978344294106\n",
      "Iteration 29653 => Loss: 46.84763889950634307979\n",
      "Iteration 29654 => Loss: 46.84747167054166538946\n",
      "Iteration 29655 => Loss: 46.84730444288938855379\n",
      "Iteration 29656 => Loss: 46.84713721654950546736\n",
      "Iteration 29657 => Loss: 46.84696999152200191929\n",
      "Iteration 29658 => Loss: 46.84680276780687790961\n",
      "Iteration 29659 => Loss: 46.84663554540411922744\n",
      "Iteration 29660 => Loss: 46.84646832431371166194\n",
      "Iteration 29661 => Loss: 46.84630110453562679140\n",
      "Iteration 29662 => Loss: 46.84613388606990014296\n",
      "Iteration 29663 => Loss: 46.84596666891647487319\n",
      "Iteration 29664 => Loss: 46.84579945307537940380\n",
      "Iteration 29665 => Loss: 46.84563223854657110223\n",
      "Iteration 29666 => Loss: 46.84546502533005707392\n",
      "Iteration 29667 => Loss: 46.84529781342582310799\n",
      "Iteration 29668 => Loss: 46.84513060283387630989\n",
      "Iteration 29669 => Loss: 46.84496339355417404704\n",
      "Iteration 29670 => Loss: 46.84479618558672342488\n",
      "Iteration 29671 => Loss: 46.84462897893150312711\n",
      "Iteration 29672 => Loss: 46.84446177358852025918\n",
      "Iteration 29673 => Loss: 46.84429456955775350480\n",
      "Iteration 29674 => Loss: 46.84412736683920996938\n",
      "Iteration 29675 => Loss: 46.84396016543284702038\n",
      "Iteration 29676 => Loss: 46.84379296533867176322\n",
      "Iteration 29677 => Loss: 46.84362576655668419789\n",
      "Iteration 29678 => Loss: 46.84345856908684879727\n",
      "Iteration 29679 => Loss: 46.84329137292919398305\n",
      "Iteration 29680 => Loss: 46.84312417808366291183\n",
      "Iteration 29681 => Loss: 46.84295698455028400531\n",
      "Iteration 29682 => Loss: 46.84278979232902173635\n",
      "Iteration 29683 => Loss: 46.84262260141987610496\n",
      "Iteration 29684 => Loss: 46.84245541182284000570\n",
      "Iteration 29685 => Loss: 46.84228822353789922772\n",
      "Iteration 29686 => Loss: 46.84212103656503956017\n",
      "Iteration 29687 => Loss: 46.84195385090425389762\n",
      "Iteration 29688 => Loss: 46.84178666655554934550\n",
      "Iteration 29689 => Loss: 46.84161948351887616582\n",
      "Iteration 29690 => Loss: 46.84145230179425567485\n",
      "Iteration 29691 => Loss: 46.84128512138166655632\n",
      "Iteration 29692 => Loss: 46.84111794228108749394\n",
      "Iteration 29693 => Loss: 46.84095076449254690942\n",
      "Iteration 29694 => Loss: 46.84078358801600217021\n",
      "Iteration 29695 => Loss: 46.84061641285143196001\n",
      "Iteration 29696 => Loss: 46.84044923899885759511\n",
      "Iteration 29697 => Loss: 46.84028206645825775922\n",
      "Iteration 29698 => Loss: 46.84011489522961824150\n",
      "Iteration 29699 => Loss: 46.83994772531291772566\n",
      "Iteration 29700 => Loss: 46.83978055670817042255\n",
      "Iteration 29701 => Loss: 46.83961338941534791047\n",
      "Iteration 29702 => Loss: 46.83944622343445729484\n",
      "Iteration 29703 => Loss: 46.83927905876544883768\n",
      "Iteration 29704 => Loss: 46.83911189540836517153\n",
      "Iteration 29705 => Loss: 46.83894473336317076928\n",
      "Iteration 29706 => Loss: 46.83877757262984431463\n",
      "Iteration 29707 => Loss: 46.83861041320838580759\n",
      "Iteration 29708 => Loss: 46.83844325509878814273\n",
      "Iteration 29709 => Loss: 46.83827609830103000377\n",
      "Iteration 29710 => Loss: 46.83810894281511139070\n",
      "Iteration 29711 => Loss: 46.83794178864105361981\n",
      "Iteration 29712 => Loss: 46.83777463577876432055\n",
      "Iteration 29713 => Loss: 46.83760748422832165261\n",
      "Iteration 29714 => Loss: 46.83744033398964745629\n",
      "Iteration 29715 => Loss: 46.83727318506277015331\n",
      "Iteration 29716 => Loss: 46.83710603744768263823\n",
      "Iteration 29717 => Loss: 46.83693889114433517307\n",
      "Iteration 29718 => Loss: 46.83677174615277039038\n",
      "Iteration 29719 => Loss: 46.83660460247291723590\n",
      "Iteration 29720 => Loss: 46.83643746010482544762\n",
      "Iteration 29721 => Loss: 46.83627031904845239296\n",
      "Iteration 29722 => Loss: 46.83610317930379096651\n",
      "Iteration 29723 => Loss: 46.83593604087084116827\n",
      "Iteration 29724 => Loss: 46.83576890374956747110\n",
      "Iteration 29725 => Loss: 46.83560176793999119127\n",
      "Iteration 29726 => Loss: 46.83543463344209101251\n",
      "Iteration 29727 => Loss: 46.83526750025582430226\n",
      "Iteration 29728 => Loss: 46.83510036838124079850\n",
      "Iteration 29729 => Loss: 46.83493323781831207953\n",
      "Iteration 29730 => Loss: 46.83476610856696709106\n",
      "Iteration 29731 => Loss: 46.83459898062727688739\n",
      "Iteration 29732 => Loss: 46.83443185399919883594\n",
      "Iteration 29733 => Loss: 46.83426472868271872585\n",
      "Iteration 29734 => Loss: 46.83409760467782234628\n",
      "Iteration 29735 => Loss: 46.83393048198450969721\n",
      "Iteration 29736 => Loss: 46.83376336060275946238\n",
      "Iteration 29737 => Loss: 46.83359624053257874721\n",
      "Iteration 29738 => Loss: 46.83342912177394623541\n",
      "Iteration 29739 => Loss: 46.83326200432685482156\n",
      "Iteration 29740 => Loss: 46.83309488819129029480\n",
      "Iteration 29741 => Loss: 46.83292777336725265513\n",
      "Iteration 29742 => Loss: 46.83276065985472058628\n",
      "Iteration 29743 => Loss: 46.83259354765366566653\n",
      "Iteration 29744 => Loss: 46.83242643676410921216\n",
      "Iteration 29745 => Loss: 46.83225932718604411775\n",
      "Iteration 29746 => Loss: 46.83209221891942064531\n",
      "Iteration 29747 => Loss: 46.83192511196428853282\n",
      "Iteration 29748 => Loss: 46.83175800632057672601\n",
      "Iteration 29749 => Loss: 46.83159090198830654117\n",
      "Iteration 29750 => Loss: 46.83142379896746376744\n",
      "Iteration 29751 => Loss: 46.83125669725803419396\n",
      "Iteration 29752 => Loss: 46.83108959686002492617\n",
      "Iteration 29753 => Loss: 46.83092249777340043693\n",
      "Iteration 29754 => Loss: 46.83075539999814651537\n",
      "Iteration 29755 => Loss: 46.83058830353428447779\n",
      "Iteration 29756 => Loss: 46.83042120838178590247\n",
      "Iteration 29757 => Loss: 46.83025411454064368399\n",
      "Iteration 29758 => Loss: 46.83008702201082229521\n",
      "Iteration 29759 => Loss: 46.82991993079234305242\n",
      "Iteration 29760 => Loss: 46.82975284088519885017\n",
      "Iteration 29761 => Loss: 46.82958575228936837220\n",
      "Iteration 29762 => Loss: 46.82941866500483030222\n",
      "Iteration 29763 => Loss: 46.82925157903160595652\n",
      "Iteration 29764 => Loss: 46.82908449436965270252\n",
      "Iteration 29765 => Loss: 46.82891741101895632937\n",
      "Iteration 29766 => Loss: 46.82875032897951683708\n",
      "Iteration 29767 => Loss: 46.82858324825136264735\n",
      "Iteration 29768 => Loss: 46.82841616883442270591\n",
      "Iteration 29769 => Loss: 46.82824909072871122362\n",
      "Iteration 29770 => Loss: 46.82808201393423530590\n",
      "Iteration 29771 => Loss: 46.82791493845095232018\n",
      "Iteration 29772 => Loss: 46.82774786427886937190\n",
      "Iteration 29773 => Loss: 46.82758079141800067191\n",
      "Iteration 29774 => Loss: 46.82741371986828937679\n",
      "Iteration 29775 => Loss: 46.82724664962975680282\n",
      "Iteration 29776 => Loss: 46.82707958070237452830\n",
      "Iteration 29777 => Loss: 46.82691251308615676407\n",
      "Iteration 29778 => Loss: 46.82674544678104666673\n",
      "Iteration 29779 => Loss: 46.82657838178710107968\n",
      "Iteration 29780 => Loss: 46.82641131810423473780\n",
      "Iteration 29781 => Loss: 46.82624425573250448451\n",
      "Iteration 29782 => Loss: 46.82607719467184637097\n",
      "Iteration 29783 => Loss: 46.82591013492230302973\n",
      "Iteration 29784 => Loss: 46.82574307648381051195\n",
      "Iteration 29785 => Loss: 46.82557601935641145019\n",
      "Iteration 29786 => Loss: 46.82540896354004189561\n",
      "Iteration 29787 => Loss: 46.82524190903471605907\n",
      "Iteration 29788 => Loss: 46.82507485584044815141\n",
      "Iteration 29789 => Loss: 46.82490780395718132922\n",
      "Iteration 29790 => Loss: 46.82474075338493690879\n",
      "Iteration 29791 => Loss: 46.82457370412370778467\n",
      "Iteration 29792 => Loss: 46.82440665617346553518\n",
      "Iteration 29793 => Loss: 46.82423960953421016029\n",
      "Iteration 29794 => Loss: 46.82407256420590613288\n",
      "Iteration 29795 => Loss: 46.82390552018859608552\n",
      "Iteration 29796 => Loss: 46.82373847748223028020\n",
      "Iteration 29797 => Loss: 46.82357143608680161151\n",
      "Iteration 29798 => Loss: 46.82340439600229586858\n",
      "Iteration 29799 => Loss: 46.82323735722873436771\n",
      "Iteration 29800 => Loss: 46.82307031976605316004\n",
      "Iteration 29801 => Loss: 46.82290328361429487813\n",
      "Iteration 29802 => Loss: 46.82273624877342399486\n",
      "Iteration 29803 => Loss: 46.82256921524344051022\n",
      "Iteration 29804 => Loss: 46.82240218302431600250\n",
      "Iteration 29805 => Loss: 46.82223515211606468256\n",
      "Iteration 29806 => Loss: 46.82206812251865102326\n",
      "Iteration 29807 => Loss: 46.82190109423208213002\n",
      "Iteration 29808 => Loss: 46.82173406725634379200\n",
      "Iteration 29809 => Loss: 46.82156704159140758748\n",
      "Iteration 29810 => Loss: 46.82140001723730193817\n",
      "Iteration 29811 => Loss: 46.82123299419397710608\n",
      "Iteration 29812 => Loss: 46.82106597246144730207\n",
      "Iteration 29813 => Loss: 46.82089895203970542070\n",
      "Iteration 29814 => Loss: 46.82073193292873725113\n",
      "Iteration 29815 => Loss: 46.82056491512849305536\n",
      "Iteration 29816 => Loss: 46.82039789863902257139\n",
      "Iteration 29817 => Loss: 46.82023088346026895579\n",
      "Iteration 29818 => Loss: 46.82006386959226773570\n",
      "Iteration 29819 => Loss: 46.81989685703496917313\n",
      "Iteration 29820 => Loss: 46.81972984578837326808\n",
      "Iteration 29821 => Loss: 46.81956283585247291512\n",
      "Iteration 29822 => Loss: 46.81939582722725390340\n",
      "Iteration 29823 => Loss: 46.81922881991273044378\n",
      "Iteration 29824 => Loss: 46.81906181390885279825\n",
      "Iteration 29825 => Loss: 46.81889480921563517768\n",
      "Iteration 29826 => Loss: 46.81872780583304205493\n",
      "Iteration 29827 => Loss: 46.81856080376110895713\n",
      "Iteration 29828 => Loss: 46.81839380299979325173\n",
      "Iteration 29829 => Loss: 46.81822680354909493872\n",
      "Iteration 29830 => Loss: 46.81805980540898559639\n",
      "Iteration 29831 => Loss: 46.81789280857947233017\n",
      "Iteration 29832 => Loss: 46.81772581306056224548\n",
      "Iteration 29833 => Loss: 46.81755881885219139349\n",
      "Iteration 29834 => Loss: 46.81739182595439530132\n",
      "Iteration 29835 => Loss: 46.81722483436715975813\n",
      "Iteration 29836 => Loss: 46.81705784409046344763\n",
      "Iteration 29837 => Loss: 46.81689085512429215896\n",
      "Iteration 29838 => Loss: 46.81672386746863878670\n",
      "Iteration 29839 => Loss: 46.81655688112350333085\n",
      "Iteration 29840 => Loss: 46.81638989608887158056\n",
      "Iteration 29841 => Loss: 46.81622291236469379783\n",
      "Iteration 29842 => Loss: 46.81605592995104814236\n",
      "Iteration 29843 => Loss: 46.81588894884784224359\n",
      "Iteration 29844 => Loss: 46.81572196905510452325\n",
      "Iteration 29845 => Loss: 46.81555499057279234876\n",
      "Iteration 29846 => Loss: 46.81538801340095545811\n",
      "Iteration 29847 => Loss: 46.81522103753953700789\n",
      "Iteration 29848 => Loss: 46.81505406298852989266\n",
      "Iteration 29849 => Loss: 46.81488708974793411244\n",
      "Iteration 29850 => Loss: 46.81472011781772124550\n",
      "Iteration 29851 => Loss: 46.81455314719789839728\n",
      "Iteration 29852 => Loss: 46.81438617788845846235\n",
      "Iteration 29853 => Loss: 46.81421920988938012442\n",
      "Iteration 29854 => Loss: 46.81405224320066338350\n",
      "Iteration 29855 => Loss: 46.81388527782230823959\n",
      "Iteration 29856 => Loss: 46.81371831375425784927\n",
      "Iteration 29857 => Loss: 46.81355135099654773967\n",
      "Iteration 29858 => Loss: 46.81338438954916369994\n",
      "Iteration 29859 => Loss: 46.81321742941205599209\n",
      "Iteration 29860 => Loss: 46.81305047058525303783\n",
      "Iteration 29861 => Loss: 46.81288351306875483715\n",
      "Iteration 29862 => Loss: 46.81271655686251165207\n",
      "Iteration 29863 => Loss: 46.81254960196653058802\n",
      "Iteration 29864 => Loss: 46.81238264838081875041\n",
      "Iteration 29865 => Loss: 46.81221569610532640127\n",
      "Iteration 29866 => Loss: 46.81204874514007485686\n",
      "Iteration 29867 => Loss: 46.81188179548505701177\n",
      "Iteration 29868 => Loss: 46.81171484714025154972\n",
      "Iteration 29869 => Loss: 46.81154790010563715441\n",
      "Iteration 29870 => Loss: 46.81138095438121382585\n",
      "Iteration 29871 => Loss: 46.81121400996698156405\n",
      "Iteration 29872 => Loss: 46.81104706686291905271\n",
      "Iteration 29873 => Loss: 46.81088012506899787013\n",
      "Iteration 29874 => Loss: 46.81071318458523933259\n",
      "Iteration 29875 => Loss: 46.81054624541162922924\n",
      "Iteration 29876 => Loss: 46.81037930754816045464\n",
      "Iteration 29877 => Loss: 46.81021237099479037624\n",
      "Iteration 29878 => Loss: 46.81004543575152609947\n",
      "Iteration 29879 => Loss: 46.80987850181834630803\n",
      "Iteration 29880 => Loss: 46.80971156919528652907\n",
      "Iteration 29881 => Loss: 46.80954463788231834087\n",
      "Iteration 29882 => Loss: 46.80937770787937068917\n",
      "Iteration 29883 => Loss: 46.80921077918652173366\n",
      "Iteration 29884 => Loss: 46.80904385180368620922\n",
      "Iteration 29885 => Loss: 46.80887692573092806470\n",
      "Iteration 29886 => Loss: 46.80871000096816914038\n",
      "Iteration 29887 => Loss: 46.80854307751543075256\n",
      "Iteration 29888 => Loss: 46.80837615537269158494\n",
      "Iteration 29889 => Loss: 46.80820923453995163754\n",
      "Iteration 29890 => Loss: 46.80804231501721801578\n",
      "Iteration 29891 => Loss: 46.80787539680443387624\n",
      "Iteration 29892 => Loss: 46.80770847990161342977\n",
      "Iteration 29893 => Loss: 46.80754156430877088724\n",
      "Iteration 29894 => Loss: 46.80737465002587072149\n",
      "Iteration 29895 => Loss: 46.80720773705289161626\n",
      "Iteration 29896 => Loss: 46.80704082538985488782\n",
      "Iteration 29897 => Loss: 46.80687391503672500903\n",
      "Iteration 29898 => Loss: 46.80670700599348066362\n",
      "Iteration 29899 => Loss: 46.80654009826016448415\n",
      "Iteration 29900 => Loss: 46.80637319183669120548\n",
      "Iteration 29901 => Loss: 46.80620628672311056562\n",
      "Iteration 29902 => Loss: 46.80603938291939414285\n",
      "Iteration 29903 => Loss: 46.80587248042552772631\n",
      "Iteration 29904 => Loss: 46.80570557924148999973\n",
      "Iteration 29905 => Loss: 46.80553867936730938482\n",
      "Iteration 29906 => Loss: 46.80537178080293614357\n",
      "Iteration 29907 => Loss: 46.80520488354837027600\n",
      "Iteration 29908 => Loss: 46.80503798760361888753\n",
      "Iteration 29909 => Loss: 46.80487109296865355645\n",
      "Iteration 29910 => Loss: 46.80470419964347428277\n",
      "Iteration 29911 => Loss: 46.80453730762803843390\n",
      "Iteration 29912 => Loss: 46.80437041692238153701\n",
      "Iteration 29913 => Loss: 46.80420352752646806493\n",
      "Iteration 29914 => Loss: 46.80403663944031222854\n",
      "Iteration 29915 => Loss: 46.80386975266385718442\n",
      "Iteration 29916 => Loss: 46.80370286719713135426\n",
      "Iteration 29917 => Loss: 46.80353598304012763265\n",
      "Iteration 29918 => Loss: 46.80336910019281049244\n",
      "Iteration 29919 => Loss: 46.80320221865517993365\n",
      "Iteration 29920 => Loss: 46.80303533842723595626\n",
      "Iteration 29921 => Loss: 46.80286845950895013857\n",
      "Iteration 29922 => Loss: 46.80270158190031537515\n",
      "Iteration 29923 => Loss: 46.80253470560132456058\n",
      "Iteration 29924 => Loss: 46.80236783061198480027\n",
      "Iteration 29925 => Loss: 46.80220095693227477796\n",
      "Iteration 29926 => Loss: 46.80203408456217317735\n",
      "Iteration 29927 => Loss: 46.80186721350168710387\n",
      "Iteration 29928 => Loss: 46.80170034375075971411\n",
      "Iteration 29929 => Loss: 46.80153347530946916777\n",
      "Iteration 29930 => Loss: 46.80136660817773019971\n",
      "Iteration 29931 => Loss: 46.80119974235554280995\n",
      "Iteration 29932 => Loss: 46.80103287784292120932\n",
      "Iteration 29933 => Loss: 46.80086601463984408156\n",
      "Iteration 29934 => Loss: 46.80069915274629721580\n",
      "Iteration 29935 => Loss: 46.80053229216226640119\n",
      "Iteration 29936 => Loss: 46.80036543288775874316\n",
      "Iteration 29937 => Loss: 46.80019857492276003086\n",
      "Iteration 29938 => Loss: 46.80003171826724184257\n",
      "Iteration 29939 => Loss: 46.79986486292120417829\n",
      "Iteration 29940 => Loss: 46.79969800888465414346\n",
      "Iteration 29941 => Loss: 46.79953115615754910550\n",
      "Iteration 29942 => Loss: 46.79936430473990327528\n",
      "Iteration 29943 => Loss: 46.79919745463168823107\n",
      "Iteration 29944 => Loss: 46.79903060583292528918\n",
      "Iteration 29945 => Loss: 46.79886375834357181702\n",
      "Iteration 29946 => Loss: 46.79869691216361360375\n",
      "Iteration 29947 => Loss: 46.79853006729308617651\n",
      "Iteration 29948 => Loss: 46.79836322373192558643\n",
      "Iteration 29949 => Loss: 46.79819638148015314982\n",
      "Iteration 29950 => Loss: 46.79802954053776886667\n",
      "Iteration 29951 => Loss: 46.79786270090471589356\n",
      "Iteration 29952 => Loss: 46.79769586258100844134\n",
      "Iteration 29953 => Loss: 46.79752902556663940459\n",
      "Iteration 29954 => Loss: 46.79736218986163009959\n",
      "Iteration 29955 => Loss: 46.79719535546591657749\n",
      "Iteration 29956 => Loss: 46.79702852237951304915\n",
      "Iteration 29957 => Loss: 46.79686169060240530371\n",
      "Iteration 29958 => Loss: 46.79669486013457913032\n",
      "Iteration 29959 => Loss: 46.79652803097602031812\n",
      "Iteration 29960 => Loss: 46.79636120312673597255\n",
      "Iteration 29961 => Loss: 46.79619437658671898816\n",
      "Iteration 29962 => Loss: 46.79602755135595515412\n",
      "Iteration 29963 => Loss: 46.79586072743440894328\n",
      "Iteration 29964 => Loss: 46.79569390482209456650\n",
      "Iteration 29965 => Loss: 46.79552708351899070749\n",
      "Iteration 29966 => Loss: 46.79536026352510447168\n",
      "Iteration 29967 => Loss: 46.79519344484040743737\n",
      "Iteration 29968 => Loss: 46.79502662746487828827\n",
      "Iteration 29969 => Loss: 46.79485981139854544608\n",
      "Iteration 29970 => Loss: 46.79469299664135206740\n",
      "Iteration 29971 => Loss: 46.79452618319333367936\n",
      "Iteration 29972 => Loss: 46.79435937105444764939\n",
      "Iteration 29973 => Loss: 46.79419256022470818834\n",
      "Iteration 29974 => Loss: 46.79402575070407976909\n",
      "Iteration 29975 => Loss: 46.79385894249256949706\n",
      "Iteration 29976 => Loss: 46.79369213559014895054\n",
      "Iteration 29977 => Loss: 46.79352532999684655124\n",
      "Iteration 29978 => Loss: 46.79335852571259124488\n",
      "Iteration 29979 => Loss: 46.79319172273743276946\n",
      "Iteration 29980 => Loss: 46.79302492107134270327\n",
      "Iteration 29981 => Loss: 46.79285812071427130832\n",
      "Iteration 29982 => Loss: 46.79269132166626121716\n",
      "Iteration 29983 => Loss: 46.79252452392727690267\n",
      "Iteration 29984 => Loss: 46.79235772749728283770\n",
      "Iteration 29985 => Loss: 46.79219093237634297111\n",
      "Iteration 29986 => Loss: 46.79202413856438624862\n",
      "Iteration 29987 => Loss: 46.79185734606142688108\n",
      "Iteration 29988 => Loss: 46.79169055486742934136\n",
      "Iteration 29989 => Loss: 46.79152376498240784031\n",
      "Iteration 29990 => Loss: 46.79135697640634106165\n",
      "Iteration 29991 => Loss: 46.79119018913923611080\n",
      "Iteration 29992 => Loss: 46.79102340318105746064\n",
      "Iteration 29993 => Loss: 46.79085661853181932202\n",
      "Iteration 29994 => Loss: 46.79068983519146485150\n",
      "Iteration 29995 => Loss: 46.79052305316005799796\n",
      "Iteration 29996 => Loss: 46.79035627243752060167\n",
      "Iteration 29997 => Loss: 46.79018949302386687350\n",
      "Iteration 29998 => Loss: 46.79002271491911812973\n",
      "Iteration 29999 => Loss: 46.78985593812321752694\n",
      "Iteration 30000 => Loss: 46.78968916263617217055\n",
      "Iteration 30001 => Loss: 46.78952238845795363886\n",
      "Iteration 30002 => Loss: 46.78935561558859035358\n",
      "Iteration 30003 => Loss: 46.78918884402806810385\n",
      "Iteration 30004 => Loss: 46.78902207377633004626\n",
      "Iteration 30005 => Loss: 46.78885530483341170793\n",
      "Iteration 30006 => Loss: 46.78868853719929177259\n",
      "Iteration 30007 => Loss: 46.78852177087394181854\n",
      "Iteration 30008 => Loss: 46.78835500585736895118\n",
      "Iteration 30009 => Loss: 46.78818824214957317054\n",
      "Iteration 30010 => Loss: 46.78802147975051894946\n",
      "Iteration 30011 => Loss: 46.78785471866018497167\n",
      "Iteration 30012 => Loss: 46.78768795887860676430\n",
      "Iteration 30013 => Loss: 46.78752120040575590565\n",
      "Iteration 30014 => Loss: 46.78735444324160397400\n",
      "Iteration 30015 => Loss: 46.78718768738617228564\n",
      "Iteration 30016 => Loss: 46.78702093283940399715\n",
      "Iteration 30017 => Loss: 46.78685417960133463566\n",
      "Iteration 30018 => Loss: 46.78668742767194999033\n",
      "Iteration 30019 => Loss: 46.78652067705120032315\n",
      "Iteration 30020 => Loss: 46.78635392773909984498\n",
      "Iteration 30021 => Loss: 46.78618717973565566126\n",
      "Iteration 30022 => Loss: 46.78602043304082513941\n",
      "Iteration 30023 => Loss: 46.78585368765463670115\n",
      "Iteration 30024 => Loss: 46.78568694357703350306\n",
      "Iteration 30025 => Loss: 46.78552020080804396684\n",
      "Iteration 30026 => Loss: 46.78535345934763967080\n",
      "Iteration 30027 => Loss: 46.78518671919581350949\n",
      "Iteration 30028 => Loss: 46.78501998035253706121\n",
      "Iteration 30029 => Loss: 46.78485324281784585310\n",
      "Iteration 30030 => Loss: 46.78468650659169014716\n",
      "Iteration 30031 => Loss: 46.78451977167407704883\n",
      "Iteration 30032 => Loss: 46.78435303806498524182\n",
      "Iteration 30033 => Loss: 46.78418630576439340985\n",
      "Iteration 30034 => Loss: 46.78401957477234418548\n",
      "Iteration 30035 => Loss: 46.78385284508876651444\n",
      "Iteration 30036 => Loss: 46.78368611671368881844\n",
      "Iteration 30037 => Loss: 46.78351938964706135948\n",
      "Iteration 30038 => Loss: 46.78335266388891966471\n",
      "Iteration 30039 => Loss: 46.78318593943921399614\n",
      "Iteration 30040 => Loss: 46.78301921629797988089\n",
      "Iteration 30041 => Loss: 46.78285249446516047556\n",
      "Iteration 30042 => Loss: 46.78268577394076999099\n",
      "Iteration 30043 => Loss: 46.78251905472482263804\n",
      "Iteration 30044 => Loss: 46.78235233681721894072\n",
      "Iteration 30045 => Loss: 46.78218562021803705875\n",
      "Iteration 30046 => Loss: 46.78201890492724857040\n",
      "Iteration 30047 => Loss: 46.78185219094483215940\n",
      "Iteration 30048 => Loss: 46.78168547827078782575\n",
      "Iteration 30049 => Loss: 46.78151876690505162060\n",
      "Iteration 30050 => Loss: 46.78135205684771591450\n",
      "Iteration 30051 => Loss: 46.78118534809868123148\n",
      "Iteration 30052 => Loss: 46.78101864065798309866\n",
      "Iteration 30053 => Loss: 46.78085193452557177807\n",
      "Iteration 30054 => Loss: 46.78068522970148279683\n",
      "Iteration 30055 => Loss: 46.78051852618564510067\n",
      "Iteration 30056 => Loss: 46.78035182397813684929\n",
      "Iteration 30057 => Loss: 46.78018512307886567214\n",
      "Iteration 30058 => Loss: 46.78001842348788130721\n",
      "Iteration 30059 => Loss: 46.77985172520511980565\n",
      "Iteration 30060 => Loss: 46.77968502823062380003\n",
      "Iteration 30061 => Loss: 46.77951833256433644692\n",
      "Iteration 30062 => Loss: 46.77935163820627906262\n",
      "Iteration 30063 => Loss: 46.77918494515643033083\n",
      "Iteration 30064 => Loss: 46.77901825341474761899\n",
      "Iteration 30065 => Loss: 46.77885156298131619224\n",
      "Iteration 30066 => Loss: 46.77868487385600104744\n",
      "Iteration 30067 => Loss: 46.77851818603890166060\n",
      "Iteration 30068 => Loss: 46.77835149952994697742\n",
      "Iteration 30069 => Loss: 46.77818481432911568163\n",
      "Iteration 30070 => Loss: 46.77801813043642908951\n",
      "Iteration 30071 => Loss: 46.77785144785188720107\n",
      "Iteration 30072 => Loss: 46.77768476657544027830\n",
      "Iteration 30073 => Loss: 46.77751808660712384835\n",
      "Iteration 30074 => Loss: 46.77735140794688106780\n",
      "Iteration 30075 => Loss: 46.77718473059472614750\n",
      "Iteration 30076 => Loss: 46.77701805455064487660\n",
      "Iteration 30077 => Loss: 46.77685137981463725509\n",
      "Iteration 30078 => Loss: 46.77668470638668907213\n",
      "Iteration 30079 => Loss: 46.77651803426678611686\n",
      "Iteration 30080 => Loss: 46.77635136345490707299\n",
      "Iteration 30081 => Loss: 46.77618469395104483510\n",
      "Iteration 30082 => Loss: 46.77601802575519940319\n",
      "Iteration 30083 => Loss: 46.77585135886736367183\n",
      "Iteration 30084 => Loss: 46.77568469328751632474\n",
      "Iteration 30085 => Loss: 46.77551802901564315107\n",
      "Iteration 30086 => Loss: 46.77535136605175836166\n",
      "Iteration 30087 => Loss: 46.77518470439583353482\n",
      "Iteration 30088 => Loss: 46.77501804404785445968\n",
      "Iteration 30089 => Loss: 46.77485138500782824167\n",
      "Iteration 30090 => Loss: 46.77468472727573356451\n",
      "Iteration 30091 => Loss: 46.77451807085152779564\n",
      "Iteration 30092 => Loss: 46.77435141573526777847\n",
      "Iteration 30093 => Loss: 46.77418476192688245874\n",
      "Iteration 30094 => Loss: 46.77401810942640736357\n",
      "Iteration 30095 => Loss: 46.77385145823382117669\n",
      "Iteration 30096 => Loss: 46.77368480834908126553\n",
      "Iteration 30097 => Loss: 46.77351815977220894638\n",
      "Iteration 30098 => Loss: 46.77335151250319000837\n",
      "Iteration 30099 => Loss: 46.77318486654201024066\n",
      "Iteration 30100 => Loss: 46.77301822188866964325\n",
      "Iteration 30101 => Loss: 46.77285157854311847814\n",
      "Iteration 30102 => Loss: 46.77268493650539937789\n",
      "Iteration 30103 => Loss: 46.77251829577547681538\n",
      "Iteration 30104 => Loss: 46.77235165635332947431\n",
      "Iteration 30105 => Loss: 46.77218501823896446012\n",
      "Iteration 30106 => Loss: 46.77201838143236756196\n",
      "Iteration 30107 => Loss: 46.77185174593351035810\n",
      "Iteration 30108 => Loss: 46.77168511174242837569\n",
      "Iteration 30109 => Loss: 46.77151847885907187674\n",
      "Iteration 30110 => Loss: 46.77135184728344796667\n",
      "Iteration 30111 => Loss: 46.77118521701553532921\n",
      "Iteration 30112 => Loss: 46.77101858805532685892\n",
      "Iteration 30113 => Loss: 46.77085196040280123952\n",
      "Iteration 30114 => Loss: 46.77068533405797978730\n",
      "Iteration 30115 => Loss: 46.77051870902081986969\n",
      "Iteration 30116 => Loss: 46.77035208529134280298\n",
      "Iteration 30117 => Loss: 46.77018546286948463830\n",
      "Iteration 30118 => Loss: 46.77001884175531642995\n",
      "Iteration 30119 => Loss: 46.76985222194875291279\n",
      "Iteration 30120 => Loss: 46.76968560344980829768\n",
      "Iteration 30121 => Loss: 46.76951898625849679547\n",
      "Iteration 30122 => Loss: 46.76935237037477577360\n",
      "Iteration 30123 => Loss: 46.76918575579864523206\n",
      "Iteration 30124 => Loss: 46.76901914253010517086\n",
      "Iteration 30125 => Loss: 46.76885253056914137915\n",
      "Iteration 30126 => Loss: 46.76868591991573254063\n",
      "Iteration 30127 => Loss: 46.76851931056987154989\n",
      "Iteration 30128 => Loss: 46.76835270253157261777\n",
      "Iteration 30129 => Loss: 46.76818609580076469001\n",
      "Iteration 30130 => Loss: 46.76801949037751171545\n",
      "Iteration 30131 => Loss: 46.76785288626174263982\n",
      "Iteration 30132 => Loss: 46.76768628345350009567\n",
      "Iteration 30133 => Loss: 46.76751968195272723960\n",
      "Iteration 30134 => Loss: 46.76735308175945249332\n",
      "Iteration 30135 => Loss: 46.76718648287364032967\n",
      "Iteration 30136 => Loss: 46.76701988529529074867\n",
      "Iteration 30137 => Loss: 46.76685328902436822318\n",
      "Iteration 30138 => Loss: 46.76668669406091538576\n",
      "Iteration 30139 => Loss: 46.76652010040488249842\n",
      "Iteration 30140 => Loss: 46.76635350805624824488\n",
      "Iteration 30141 => Loss: 46.76618691701502683600\n",
      "Iteration 30142 => Loss: 46.76602032728122537719\n",
      "Iteration 30143 => Loss: 46.76585373885480123590\n",
      "Iteration 30144 => Loss: 46.76568715173574730670\n",
      "Iteration 30145 => Loss: 46.76552056592407069502\n",
      "Iteration 30146 => Loss: 46.76535398141973587371\n",
      "Iteration 30147 => Loss: 46.76518739822278547535\n",
      "Iteration 30148 => Loss: 46.76502081633312712938\n",
      "Iteration 30149 => Loss: 46.76485423575080346836\n",
      "Iteration 30150 => Loss: 46.76468765647579317601\n",
      "Iteration 30151 => Loss: 46.76452107850810335776\n",
      "Iteration 30152 => Loss: 46.76435450184769848647\n",
      "Iteration 30153 => Loss: 46.76418792649458566757\n",
      "Iteration 30154 => Loss: 46.76402135244874358477\n",
      "Iteration 30155 => Loss: 46.76385477971017223808\n",
      "Iteration 30156 => Loss: 46.76368820827884320579\n",
      "Iteration 30157 => Loss: 46.76352163815477069875\n",
      "Iteration 30158 => Loss: 46.76335506933790497897\n",
      "Iteration 30159 => Loss: 46.76318850182830288986\n",
      "Iteration 30160 => Loss: 46.76302193562587916631\n",
      "Iteration 30161 => Loss: 46.76285537073066223002\n",
      "Iteration 30162 => Loss: 46.76268880714265208098\n",
      "Iteration 30163 => Loss: 46.76252224486183450836\n",
      "Iteration 30164 => Loss: 46.76235568388815977414\n",
      "Iteration 30165 => Loss: 46.76218912422167051091\n",
      "Iteration 30166 => Loss: 46.76202256586232408608\n",
      "Iteration 30167 => Loss: 46.76185600881011339425\n",
      "Iteration 30168 => Loss: 46.76168945306503843540\n",
      "Iteration 30169 => Loss: 46.76152289862708499868\n",
      "Iteration 30170 => Loss: 46.76135634549624597867\n",
      "Iteration 30171 => Loss: 46.76118979367250005907\n",
      "Iteration 30172 => Loss: 46.76102324315584723990\n",
      "Iteration 30173 => Loss: 46.76085669394627331030\n",
      "Iteration 30174 => Loss: 46.76069014604375695399\n",
      "Iteration 30175 => Loss: 46.76052359944833369809\n",
      "Iteration 30176 => Loss: 46.76035705415992538292\n",
      "Iteration 30177 => Loss: 46.76019051017856043018\n",
      "Iteration 30178 => Loss: 46.76002396750425305072\n",
      "Iteration 30179 => Loss: 46.75985742613693219027\n",
      "Iteration 30180 => Loss: 46.75969088607662627055\n",
      "Iteration 30181 => Loss: 46.75952434732333529155\n",
      "Iteration 30182 => Loss: 46.75935780987698819899\n",
      "Iteration 30183 => Loss: 46.75919127373765604716\n",
      "Iteration 30184 => Loss: 46.75902473890529620348\n",
      "Iteration 30185 => Loss: 46.75885820537987314083\n",
      "Iteration 30186 => Loss: 46.75869167316138685919\n",
      "Iteration 30187 => Loss: 46.75852514224985156943\n",
      "Iteration 30188 => Loss: 46.75835861264524595526\n",
      "Iteration 30189 => Loss: 46.75819208434755580583\n",
      "Iteration 30190 => Loss: 46.75802555735677401572\n",
      "Iteration 30191 => Loss: 46.75785903167286505777\n",
      "Iteration 30192 => Loss: 46.75769250729586445914\n",
      "Iteration 30193 => Loss: 46.75752598422572958725\n",
      "Iteration 30194 => Loss: 46.75735946246246044211\n",
      "Iteration 30195 => Loss: 46.75719294200605702372\n",
      "Iteration 30196 => Loss: 46.75702642285646248865\n",
      "Iteration 30197 => Loss: 46.75685990501371946948\n",
      "Iteration 30198 => Loss: 46.75669338847781375534\n",
      "Iteration 30199 => Loss: 46.75652687324873113539\n",
      "Iteration 30200 => Loss: 46.75636035932642187163\n",
      "Iteration 30201 => Loss: 46.75619384671091438577\n",
      "Iteration 30202 => Loss: 46.75602733540217315067\n",
      "Iteration 30203 => Loss: 46.75586082540024079890\n",
      "Iteration 30204 => Loss: 46.75569431670504627618\n",
      "Iteration 30205 => Loss: 46.75552780931660379338\n",
      "Iteration 30206 => Loss: 46.75536130323490624505\n",
      "Iteration 30207 => Loss: 46.75519479845992520950\n",
      "Iteration 30208 => Loss: 46.75502829499168200300\n",
      "Iteration 30209 => Loss: 46.75486179283015530928\n",
      "Iteration 30210 => Loss: 46.75469529197530960118\n",
      "Iteration 30211 => Loss: 46.75452879242717330044\n",
      "Iteration 30212 => Loss: 46.75436229418570377447\n",
      "Iteration 30213 => Loss: 46.75419579725089391786\n",
      "Iteration 30214 => Loss: 46.75402930162276504689\n",
      "Iteration 30215 => Loss: 46.75386280730128163441\n",
      "Iteration 30216 => Loss: 46.75369631428642946958\n",
      "Iteration 30217 => Loss: 46.75352982257820855239\n",
      "Iteration 30218 => Loss: 46.75336333217660467199\n",
      "Iteration 30219 => Loss: 46.75319684308161072295\n",
      "Iteration 30220 => Loss: 46.75303035529319828356\n",
      "Iteration 30221 => Loss: 46.75286386881139577554\n",
      "Iteration 30222 => Loss: 46.75269738363615346088\n",
      "Iteration 30223 => Loss: 46.75253089976748555046\n",
      "Iteration 30224 => Loss: 46.75236441720537072797\n",
      "Iteration 30225 => Loss: 46.75219793594982320428\n",
      "Iteration 30226 => Loss: 46.75203145600080034683\n",
      "Iteration 30227 => Loss: 46.75186497735828794475\n",
      "Iteration 30228 => Loss: 46.75169850002229310348\n",
      "Iteration 30229 => Loss: 46.75153202399281582302\n",
      "Iteration 30230 => Loss: 46.75136554926982768166\n",
      "Iteration 30231 => Loss: 46.75119907585332867939\n",
      "Iteration 30232 => Loss: 46.75103260374330460536\n",
      "Iteration 30233 => Loss: 46.75086613293974835415\n",
      "Iteration 30234 => Loss: 46.75069966344263150404\n",
      "Iteration 30235 => Loss: 46.75053319525196116047\n",
      "Iteration 30236 => Loss: 46.75036672836774442885\n",
      "Iteration 30237 => Loss: 46.75020026278993867663\n",
      "Iteration 30238 => Loss: 46.75003379851852969296\n",
      "Iteration 30239 => Loss: 46.74986733555355300496\n",
      "Iteration 30240 => Loss: 46.74970087389495887464\n",
      "Iteration 30241 => Loss: 46.74953441354272598574\n",
      "Iteration 30242 => Loss: 46.74936795449688275994\n",
      "Iteration 30243 => Loss: 46.74920149675740077555\n",
      "Iteration 30244 => Loss: 46.74903504032427292714\n",
      "Iteration 30245 => Loss: 46.74886858519746368756\n",
      "Iteration 30246 => Loss: 46.74870213137703700568\n",
      "Iteration 30247 => Loss: 46.74853567886288630007\n",
      "Iteration 30248 => Loss: 46.74836922765505420330\n",
      "Iteration 30249 => Loss: 46.74820277775354071537\n",
      "Iteration 30250 => Loss: 46.74803632915829609829\n",
      "Iteration 30251 => Loss: 46.74786988186934166833\n",
      "Iteration 30252 => Loss: 46.74770343588664900381\n",
      "Iteration 30253 => Loss: 46.74753699121022521012\n",
      "Iteration 30254 => Loss: 46.74737054784004897101\n",
      "Iteration 30255 => Loss: 46.74720410577609897018\n",
      "Iteration 30256 => Loss: 46.74703766501839652392\n",
      "Iteration 30257 => Loss: 46.74687122556689899966\n",
      "Iteration 30258 => Loss: 46.74670478742161350283\n",
      "Iteration 30259 => Loss: 46.74653835058253292800\n",
      "Iteration 30260 => Loss: 46.74637191504962174804\n",
      "Iteration 30261 => Loss: 46.74620548082289417380\n",
      "Iteration 30262 => Loss: 46.74603904790235020528\n",
      "Iteration 30263 => Loss: 46.74587261628794010448\n",
      "Iteration 30264 => Loss: 46.74570618597969939856\n",
      "Iteration 30265 => Loss: 46.74553975697757124408\n",
      "Iteration 30266 => Loss: 46.74537332928158406276\n",
      "Iteration 30267 => Loss: 46.74520690289170943288\n",
      "Iteration 30268 => Loss: 46.74504047780794024902\n",
      "Iteration 30269 => Loss: 46.74487405403026940576\n",
      "Iteration 30270 => Loss: 46.74470763155868269223\n",
      "Iteration 30271 => Loss: 46.74454121039317300301\n",
      "Iteration 30272 => Loss: 46.74437479053371902182\n",
      "Iteration 30273 => Loss: 46.74420837198032785409\n",
      "Iteration 30274 => Loss: 46.74404195473297107810\n",
      "Iteration 30275 => Loss: 46.74387553879165579929\n",
      "Iteration 30276 => Loss: 46.74370912415637491222\n",
      "Iteration 30277 => Loss: 46.74354271082708578433\n",
      "Iteration 30278 => Loss: 46.74337629880381683734\n",
      "Iteration 30279 => Loss: 46.74320988808651833324\n",
      "Iteration 30280 => Loss: 46.74304347867521869375\n",
      "Iteration 30281 => Loss: 46.74287707056989660259\n",
      "Iteration 30282 => Loss: 46.74271066377052363805\n",
      "Iteration 30283 => Loss: 46.74254425827710690555\n",
      "Iteration 30284 => Loss: 46.74237785408963219425\n",
      "Iteration 30285 => Loss: 46.74221145120809239870\n",
      "Iteration 30286 => Loss: 46.74204504963246620264\n",
      "Iteration 30287 => Loss: 46.74187864936276781691\n",
      "Iteration 30288 => Loss: 46.74171225039895460895\n",
      "Iteration 30289 => Loss: 46.74154585274103368420\n",
      "Iteration 30290 => Loss: 46.74137945638898372636\n",
      "Iteration 30291 => Loss: 46.74121306134280473543\n",
      "Iteration 30292 => Loss: 46.74104666760249671142\n",
      "Iteration 30293 => Loss: 46.74088027516805254891\n",
      "Iteration 30294 => Loss: 46.74071388403942250989\n",
      "Iteration 30295 => Loss: 46.74054749421663501607\n",
      "Iteration 30296 => Loss: 46.74038110569964743490\n",
      "Iteration 30297 => Loss: 46.74021471848848108266\n",
      "Iteration 30298 => Loss: 46.74004833258311464306\n",
      "Iteration 30299 => Loss: 46.73988194798352679982\n",
      "Iteration 30300 => Loss: 46.73971556468972465836\n",
      "Iteration 30301 => Loss: 46.73954918270167979699\n",
      "Iteration 30302 => Loss: 46.73938280201940642655\n",
      "Iteration 30303 => Loss: 46.73921642264288323076\n",
      "Iteration 30304 => Loss: 46.73905004457210310420\n",
      "Iteration 30305 => Loss: 46.73888366780703762515\n",
      "Iteration 30306 => Loss: 46.73871729234767258276\n",
      "Iteration 30307 => Loss: 46.73855091819401508246\n",
      "Iteration 30308 => Loss: 46.73838454534606512425\n",
      "Iteration 30309 => Loss: 46.73821817380380139184\n",
      "Iteration 30310 => Loss: 46.73805180356719546353\n",
      "Iteration 30311 => Loss: 46.73788543463629707730\n",
      "Iteration 30312 => Loss: 46.73771906701102096804\n",
      "Iteration 30313 => Loss: 46.73755270069138134659\n",
      "Iteration 30314 => Loss: 46.73738633567739952923\n",
      "Iteration 30315 => Loss: 46.73721997196903288341\n",
      "Iteration 30316 => Loss: 46.73705360956626719826\n",
      "Iteration 30317 => Loss: 46.73688724846910247379\n",
      "Iteration 30318 => Loss: 46.73672088867755292085\n",
      "Iteration 30319 => Loss: 46.73655453019159011774\n",
      "Iteration 30320 => Loss: 46.73638817301117853731\n",
      "Iteration 30321 => Loss: 46.73622181713633949585\n",
      "Iteration 30322 => Loss: 46.73605546256703036079\n",
      "Iteration 30323 => Loss: 46.73588910930330797555\n",
      "Iteration 30324 => Loss: 46.73572275734507286415\n",
      "Iteration 30325 => Loss: 46.73555640669239608087\n",
      "Iteration 30326 => Loss: 46.73539005734519946600\n",
      "Iteration 30327 => Loss: 46.73522370930352565210\n",
      "Iteration 30328 => Loss: 46.73505736256733911205\n",
      "Iteration 30329 => Loss: 46.73489101713663274040\n",
      "Iteration 30330 => Loss: 46.73472467301137811546\n",
      "Iteration 30331 => Loss: 46.73455833019158234265\n",
      "Iteration 30332 => Loss: 46.73439198867725963282\n",
      "Iteration 30333 => Loss: 46.73422564846837445884\n",
      "Iteration 30334 => Loss: 46.73405930956490550443\n",
      "Iteration 30335 => Loss: 46.73389297196686698044\n",
      "Iteration 30336 => Loss: 46.73372663567424467601\n",
      "Iteration 30337 => Loss: 46.73356030068699595859\n",
      "Iteration 30338 => Loss: 46.73339396700514214444\n",
      "Iteration 30339 => Loss: 46.73322763462868323359\n",
      "Iteration 30340 => Loss: 46.73306130355756948802\n",
      "Iteration 30341 => Loss: 46.73289497379182932946\n",
      "Iteration 30342 => Loss: 46.73272864533141301990\n",
      "Iteration 30343 => Loss: 46.73256231817637029735\n",
      "Iteration 30344 => Loss: 46.73239599232663721295\n",
      "Iteration 30345 => Loss: 46.73222966778222797757\n",
      "Iteration 30346 => Loss: 46.73206334454309995863\n",
      "Iteration 30347 => Loss: 46.73189702260929578870\n",
      "Iteration 30348 => Loss: 46.73173070198075862436\n",
      "Iteration 30349 => Loss: 46.73156438265750267647\n",
      "Iteration 30350 => Loss: 46.73139806463951373416\n",
      "Iteration 30351 => Loss: 46.73123174792678469203\n",
      "Iteration 30352 => Loss: 46.73106543251929423377\n",
      "Iteration 30353 => Loss: 46.73089911841702814854\n",
      "Iteration 30354 => Loss: 46.73073280562001485805\n",
      "Iteration 30355 => Loss: 46.73056649412819751888\n",
      "Iteration 30356 => Loss: 46.73040018394156902559\n",
      "Iteration 30357 => Loss: 46.73023387506016490534\n",
      "Iteration 30358 => Loss: 46.73006756748392831469\n",
      "Iteration 30359 => Loss: 46.72990126121285214822\n",
      "Iteration 30360 => Loss: 46.72973495624696482764\n",
      "Iteration 30361 => Loss: 46.72956865258622372039\n",
      "Iteration 30362 => Loss: 46.72940235023059329933\n",
      "Iteration 30363 => Loss: 46.72923604918014461873\n",
      "Iteration 30364 => Loss: 46.72906974943479241347\n",
      "Iteration 30365 => Loss: 46.72890345099456510525\n",
      "Iteration 30366 => Loss: 46.72873715385942006151\n",
      "Iteration 30367 => Loss: 46.72857085802935728225\n",
      "Iteration 30368 => Loss: 46.72840456350441940003\n",
      "Iteration 30369 => Loss: 46.72823827028451404431\n",
      "Iteration 30370 => Loss: 46.72807197836968384763\n",
      "Iteration 30371 => Loss: 46.72790568775987907202\n",
      "Iteration 30372 => Loss: 46.72773939845514235003\n",
      "Iteration 30373 => Loss: 46.72757311045543104910\n",
      "Iteration 30374 => Loss: 46.72740682376074516924\n",
      "Iteration 30375 => Loss: 46.72724053837104918330\n",
      "Iteration 30376 => Loss: 46.72707425428636440756\n",
      "Iteration 30377 => Loss: 46.72690797150667663118\n",
      "Iteration 30378 => Loss: 46.72674169003193611616\n",
      "Iteration 30379 => Loss: 46.72657540986219970591\n",
      "Iteration 30380 => Loss: 46.72640913099740345160\n",
      "Iteration 30381 => Loss: 46.72624285343755445865\n",
      "Iteration 30382 => Loss: 46.72607657718264562163\n",
      "Iteration 30383 => Loss: 46.72591030223266272969\n",
      "Iteration 30384 => Loss: 46.72574402858761288826\n",
      "Iteration 30385 => Loss: 46.72557775624745346477\n",
      "Iteration 30386 => Loss: 46.72541148521217024836\n",
      "Iteration 30387 => Loss: 46.72524521548180587160\n",
      "Iteration 30388 => Loss: 46.72507894705632480736\n",
      "Iteration 30389 => Loss: 46.72491267993568442307\n",
      "Iteration 30390 => Loss: 46.72474641411991314044\n",
      "Iteration 30391 => Loss: 46.72458014960898964318\n",
      "Iteration 30392 => Loss: 46.72441388640287840417\n",
      "Iteration 30393 => Loss: 46.72424762450160073968\n",
      "Iteration 30394 => Loss: 46.72408136390515664971\n",
      "Iteration 30395 => Loss: 46.72391510461351771255\n",
      "Iteration 30396 => Loss: 46.72374884662664129564\n",
      "Iteration 30397 => Loss: 46.72358258994456292612\n",
      "Iteration 30398 => Loss: 46.72341633456726839313\n",
      "Iteration 30399 => Loss: 46.72325008049472927496\n",
      "Iteration 30400 => Loss: 46.72308382772694557161\n",
      "Iteration 30401 => Loss: 46.72291757626390307223\n",
      "Iteration 30402 => Loss: 46.72275132610560888224\n",
      "Iteration 30403 => Loss: 46.72258507725202036909\n",
      "Iteration 30404 => Loss: 46.72241882970314463819\n",
      "Iteration 30405 => Loss: 46.72225258345896037326\n",
      "Iteration 30406 => Loss: 46.72208633851950310145\n",
      "Iteration 30407 => Loss: 46.72192009488469466305\n",
      "Iteration 30408 => Loss: 46.72175385255455637434\n",
      "Iteration 30409 => Loss: 46.72158761152910244618\n",
      "Iteration 30410 => Loss: 46.72142137180828314058\n",
      "Iteration 30411 => Loss: 46.72125513339210556296\n",
      "Iteration 30412 => Loss: 46.72108889628056971333\n",
      "Iteration 30413 => Loss: 46.72092266047364006454\n",
      "Iteration 30414 => Loss: 46.72075642597133082745\n",
      "Iteration 30415 => Loss: 46.72059019277361358036\n",
      "Iteration 30416 => Loss: 46.72042396088048832326\n",
      "Iteration 30417 => Loss: 46.72025773029194795072\n",
      "Iteration 30418 => Loss: 46.72009150100797114646\n",
      "Iteration 30419 => Loss: 46.71992527302855080507\n",
      "Iteration 30420 => Loss: 46.71975904635367982110\n",
      "Iteration 30421 => Loss: 46.71959282098334398370\n",
      "Iteration 30422 => Loss: 46.71942659691753618745\n",
      "Iteration 30423 => Loss: 46.71926037415626353777\n",
      "Iteration 30424 => Loss: 46.71909415269947629668\n",
      "Iteration 30425 => Loss: 46.71892793254720999130\n",
      "Iteration 30426 => Loss: 46.71876171369940777822\n",
      "Iteration 30427 => Loss: 46.71859549615608386830\n",
      "Iteration 30428 => Loss: 46.71842927991723826153\n",
      "Iteration 30429 => Loss: 46.71826306498284964164\n",
      "Iteration 30430 => Loss: 46.71809685135290379776\n",
      "Iteration 30431 => Loss: 46.71793063902738651905\n",
      "Iteration 30432 => Loss: 46.71776442800629780550\n",
      "Iteration 30433 => Loss: 46.71759821828961634083\n",
      "Iteration 30434 => Loss: 46.71743200987735633589\n",
      "Iteration 30435 => Loss: 46.71726580276948936898\n",
      "Iteration 30436 => Loss: 46.71709959696599412382\n",
      "Iteration 30437 => Loss: 46.71693339246687060040\n",
      "Iteration 30438 => Loss: 46.71676718927213300958\n",
      "Iteration 30439 => Loss: 46.71660098738173871880\n",
      "Iteration 30440 => Loss: 46.71643478679569483347\n",
      "Iteration 30441 => Loss: 46.71626858751396582647\n",
      "Iteration 30442 => Loss: 46.71610238953656590866\n",
      "Iteration 30443 => Loss: 46.71593619286348797459\n",
      "Iteration 30444 => Loss: 46.71576999749470360257\n",
      "Iteration 30445 => Loss: 46.71560380343023410887\n",
      "Iteration 30446 => Loss: 46.71543761067002975551\n",
      "Iteration 30447 => Loss: 46.71527141921409054248\n",
      "Iteration 30448 => Loss: 46.71510522906242357521\n",
      "Iteration 30449 => Loss: 46.71493904021501464285\n",
      "Iteration 30450 => Loss: 46.71477285267182821826\n",
      "Iteration 30451 => Loss: 46.71460666643287851230\n",
      "Iteration 30452 => Loss: 46.71444048149815131410\n",
      "Iteration 30453 => Loss: 46.71427429786764662367\n",
      "Iteration 30454 => Loss: 46.71410811554131470302\n",
      "Iteration 30455 => Loss: 46.71394193451920529014\n",
      "Iteration 30456 => Loss: 46.71377575480126154162\n",
      "Iteration 30457 => Loss: 46.71360957638748345744\n",
      "Iteration 30458 => Loss: 46.71344339927787814304\n",
      "Iteration 30459 => Loss: 46.71327722347240296585\n",
      "Iteration 30460 => Loss: 46.71311104897106503131\n",
      "Iteration 30461 => Loss: 46.71294487577386433941\n",
      "Iteration 30462 => Loss: 46.71277870388079378472\n",
      "Iteration 30463 => Loss: 46.71261253329181073468\n",
      "Iteration 30464 => Loss: 46.71244636400695782186\n",
      "Iteration 30465 => Loss: 46.71228019602615688655\n",
      "Iteration 30466 => Loss: 46.71211402934945766674\n",
      "Iteration 30467 => Loss: 46.71194786397681042445\n",
      "Iteration 30468 => Loss: 46.71178169990822937052\n",
      "Iteration 30469 => Loss: 46.71161553714369318868\n",
      "Iteration 30470 => Loss: 46.71144937568318766807\n",
      "Iteration 30471 => Loss: 46.71128321552671991412\n",
      "Iteration 30472 => Loss: 46.71111705667424729427\n",
      "Iteration 30473 => Loss: 46.71095089912580533564\n",
      "Iteration 30474 => Loss: 46.71078474288133719483\n",
      "Iteration 30475 => Loss: 46.71061858794088550439\n",
      "Iteration 30476 => Loss: 46.71045243430438631549\n",
      "Iteration 30477 => Loss: 46.71028628197185383897\n",
      "Iteration 30478 => Loss: 46.71012013094328807483\n",
      "Iteration 30479 => Loss: 46.70995398121865349594\n",
      "Iteration 30480 => Loss: 46.70978783279794299688\n",
      "Iteration 30481 => Loss: 46.70962168568117078848\n",
      "Iteration 30482 => Loss: 46.70945553986830134363\n",
      "Iteration 30483 => Loss: 46.70928939535937018945\n",
      "Iteration 30484 => Loss: 46.70912325215431337710\n",
      "Iteration 30485 => Loss: 46.70895711025310959030\n",
      "Iteration 30486 => Loss: 46.70879096965581567247\n",
      "Iteration 30487 => Loss: 46.70862483036237478018\n",
      "Iteration 30488 => Loss: 46.70845869237276559716\n",
      "Iteration 30489 => Loss: 46.70829255568704496682\n",
      "Iteration 30490 => Loss: 46.70812642030510630775\n",
      "Iteration 30491 => Loss: 46.70796028622702777966\n",
      "Iteration 30492 => Loss: 46.70779415345273122284\n",
      "Iteration 30493 => Loss: 46.70762802198224505901\n",
      "Iteration 30494 => Loss: 46.70746189181556218273\n",
      "Iteration 30495 => Loss: 46.70729576295265417230\n",
      "Iteration 30496 => Loss: 46.70712963539350681685\n",
      "Iteration 30497 => Loss: 46.70696350913813432726\n",
      "Iteration 30498 => Loss: 46.70679738418650117637\n",
      "Iteration 30499 => Loss: 46.70663126053861446962\n",
      "Iteration 30500 => Loss: 46.70646513819445289073\n",
      "Iteration 30501 => Loss: 46.70629901715400933426\n",
      "Iteration 30502 => Loss: 46.70613289741726958937\n",
      "Iteration 30503 => Loss: 46.70596677898423365605\n",
      "Iteration 30504 => Loss: 46.70580066185488732344\n",
      "Iteration 30505 => Loss: 46.70563454602923059156\n",
      "Iteration 30506 => Loss: 46.70546843150723503868\n",
      "Iteration 30507 => Loss: 46.70530231828890066481\n",
      "Iteration 30508 => Loss: 46.70513620637421325910\n",
      "Iteration 30509 => Loss: 46.70497009576314439983\n",
      "Iteration 30510 => Loss: 46.70480398645571540328\n",
      "Iteration 30511 => Loss: 46.70463787845192626946\n",
      "Iteration 30512 => Loss: 46.70447177175170594410\n",
      "Iteration 30513 => Loss: 46.70430566635509705975\n",
      "Iteration 30514 => Loss: 46.70413956226209961642\n",
      "Iteration 30515 => Loss: 46.70397345947264255983\n",
      "Iteration 30516 => Loss: 46.70380735798677562798\n",
      "Iteration 30517 => Loss: 46.70364125780445618830\n",
      "Iteration 30518 => Loss: 46.70347515892567002993\n",
      "Iteration 30519 => Loss: 46.70330906135043846916\n",
      "Iteration 30520 => Loss: 46.70314296507871176800\n",
      "Iteration 30521 => Loss: 46.70297687011051124273\n",
      "Iteration 30522 => Loss: 46.70281077644581557706\n",
      "Iteration 30523 => Loss: 46.70264468408460345472\n",
      "Iteration 30524 => Loss: 46.70247859302688908656\n",
      "Iteration 30525 => Loss: 46.70231250327265826172\n",
      "Iteration 30526 => Loss: 46.70214641482186124222\n",
      "Iteration 30527 => Loss: 46.70198032767454066061\n",
      "Iteration 30528 => Loss: 46.70181424183064677891\n",
      "Iteration 30529 => Loss: 46.70164815729020091339\n",
      "Iteration 30530 => Loss: 46.70148207405316043150\n",
      "Iteration 30531 => Loss: 46.70131599211954664952\n",
      "Iteration 30532 => Loss: 46.70114991148935246201\n",
      "Iteration 30533 => Loss: 46.70098383216252813099\n",
      "Iteration 30534 => Loss: 46.70081775413908076189\n",
      "Iteration 30535 => Loss: 46.70065167741902456555\n",
      "Iteration 30536 => Loss: 46.70048560200231690942\n",
      "Iteration 30537 => Loss: 46.70031952788896489892\n",
      "Iteration 30538 => Loss: 46.70015345507894011234\n",
      "Iteration 30539 => Loss: 46.69998738357224254969\n",
      "Iteration 30540 => Loss: 46.69982131336890773810\n",
      "Iteration 30541 => Loss: 46.69965524446883620158\n",
      "Iteration 30542 => Loss: 46.69948917687208478355\n",
      "Iteration 30543 => Loss: 46.69932311057861085146\n",
      "Iteration 30544 => Loss: 46.69915704558844993244\n",
      "Iteration 30545 => Loss: 46.69899098190152386678\n",
      "Iteration 30546 => Loss: 46.69882491951787528706\n",
      "Iteration 30547 => Loss: 46.69865885843746866612\n",
      "Iteration 30548 => Loss: 46.69849279866028268771\n",
      "Iteration 30549 => Loss: 46.69832674018634577351\n",
      "Iteration 30550 => Loss: 46.69816068301563660725\n",
      "Iteration 30551 => Loss: 46.69799462714811966180\n",
      "Iteration 30552 => Loss: 46.69782857258380204257\n",
      "Iteration 30553 => Loss: 46.69766251932267664415\n",
      "Iteration 30554 => Loss: 46.69749646736472215025\n",
      "Iteration 30555 => Loss: 46.69733041670993856087\n",
      "Iteration 30556 => Loss: 46.69716436735829745430\n",
      "Iteration 30557 => Loss: 46.69699831930982014683\n",
      "Iteration 30558 => Loss: 46.69683227256447821674\n",
      "Iteration 30559 => Loss: 46.69666622712225745317\n",
      "Iteration 30560 => Loss: 46.69650018298315785614\n",
      "Iteration 30561 => Loss: 46.69633414014716521478\n",
      "Iteration 30562 => Loss: 46.69616809861423689654\n",
      "Iteration 30563 => Loss: 46.69600205838444395567\n",
      "Iteration 30564 => Loss: 46.69583601945770112707\n",
      "Iteration 30565 => Loss: 46.69566998183401551614\n",
      "Iteration 30566 => Loss: 46.69550394551339422833\n",
      "Iteration 30567 => Loss: 46.69533791049581594734\n",
      "Iteration 30568 => Loss: 46.69517187678128067319\n",
      "Iteration 30569 => Loss: 46.69500584436975998415\n",
      "Iteration 30570 => Loss: 46.69483981326124677480\n",
      "Iteration 30571 => Loss: 46.69467378345574104515\n",
      "Iteration 30572 => Loss: 46.69450775495323568975\n",
      "Iteration 30573 => Loss: 46.69434172775369518149\n",
      "Iteration 30574 => Loss: 46.69417570185714794206\n",
      "Iteration 30575 => Loss: 46.69400967726355133891\n",
      "Iteration 30576 => Loss: 46.69384365397291247746\n",
      "Iteration 30577 => Loss: 46.69367763198521714685\n",
      "Iteration 30578 => Loss: 46.69351161130047245251\n",
      "Iteration 30579 => Loss: 46.69334559191860023475\n",
      "Iteration 30580 => Loss: 46.69317957383969286411\n",
      "Iteration 30581 => Loss: 46.69301355706365797005\n",
      "Iteration 30582 => Loss: 46.69284754159052397426\n",
      "Iteration 30583 => Loss: 46.69268152742025534963\n",
      "Iteration 30584 => Loss: 46.69251551455286630699\n",
      "Iteration 30585 => Loss: 46.69234950298832842464\n",
      "Iteration 30586 => Loss: 46.69218349272664880800\n",
      "Iteration 30587 => Loss: 46.69201748376782035166\n",
      "Iteration 30588 => Loss: 46.69185147611180042304\n",
      "Iteration 30589 => Loss: 46.69168546975861033843\n",
      "Iteration 30590 => Loss: 46.69151946470822878155\n",
      "Iteration 30591 => Loss: 46.69135346096063443611\n",
      "Iteration 30592 => Loss: 46.69118745851585572382\n",
      "Iteration 30593 => Loss: 46.69102145737382869584\n",
      "Iteration 30594 => Loss: 46.69085545753459598473\n",
      "Iteration 30595 => Loss: 46.69068945899810785249\n",
      "Iteration 30596 => Loss: 46.69052346176434298286\n",
      "Iteration 30597 => Loss: 46.69035746583334400839\n",
      "Iteration 30598 => Loss: 46.69019147120507540194\n",
      "Iteration 30599 => Loss: 46.69002547787951584723\n",
      "Iteration 30600 => Loss: 46.68985948585667244970\n",
      "Iteration 30601 => Loss: 46.68969349513650968220\n",
      "Iteration 30602 => Loss: 46.68952750571902043930\n",
      "Iteration 30603 => Loss: 46.68936151760425445900\n",
      "Iteration 30604 => Loss: 46.68919553079212647617\n",
      "Iteration 30605 => Loss: 46.68902954528264359624\n",
      "Iteration 30606 => Loss: 46.68886356107581292463\n",
      "Iteration 30607 => Loss: 46.68869757817162735591\n",
      "Iteration 30608 => Loss: 46.68853159657006557381\n",
      "Iteration 30609 => Loss: 46.68836561627111336747\n",
      "Iteration 30610 => Loss: 46.68819963727476363147\n",
      "Iteration 30611 => Loss: 46.68803365958101636579\n",
      "Iteration 30612 => Loss: 46.68786768318985025417\n",
      "Iteration 30613 => Loss: 46.68770170810125108574\n",
      "Iteration 30614 => Loss: 46.68753573431521175507\n",
      "Iteration 30615 => Loss: 46.68736976183173936761\n",
      "Iteration 30616 => Loss: 46.68720379065080550163\n",
      "Iteration 30617 => Loss: 46.68703782077241015713\n",
      "Iteration 30618 => Loss: 46.68687185219652491242\n",
      "Iteration 30619 => Loss: 46.68670588492317818918\n",
      "Iteration 30620 => Loss: 46.68653991895230603859\n",
      "Iteration 30621 => Loss: 46.68637395428395109320\n",
      "Iteration 30622 => Loss: 46.68620799091804940417\n",
      "Iteration 30623 => Loss: 46.68604202885462939321\n",
      "Iteration 30624 => Loss: 46.68587606809366263860\n",
      "Iteration 30625 => Loss: 46.68571010863516335121\n",
      "Iteration 30626 => Loss: 46.68554415047911732017\n",
      "Iteration 30627 => Loss: 46.68537819362547480750\n",
      "Iteration 30628 => Loss: 46.68521223807427134034\n",
      "Iteration 30629 => Loss: 46.68504628382546428611\n",
      "Iteration 30630 => Loss: 46.68488033087906075025\n",
      "Iteration 30631 => Loss: 46.68471437923504652190\n",
      "Iteration 30632 => Loss: 46.68454842889342160106\n",
      "Iteration 30633 => Loss: 46.68438247985417177688\n",
      "Iteration 30634 => Loss: 46.68421653211726152222\n",
      "Iteration 30635 => Loss: 46.68405058568271215336\n",
      "Iteration 30636 => Loss: 46.68388464055048814316\n",
      "Iteration 30637 => Loss: 46.68371869672061080792\n",
      "Iteration 30638 => Loss: 46.68355275419303040962\n",
      "Iteration 30639 => Loss: 46.68338681296778247543\n",
      "Iteration 30640 => Loss: 46.68322087304481726733\n",
      "Iteration 30641 => Loss: 46.68305493442414899619\n",
      "Iteration 30642 => Loss: 46.68288899710577055657\n",
      "Iteration 30643 => Loss: 46.68272306108963931592\n",
      "Iteration 30644 => Loss: 46.68255712637576948509\n",
      "Iteration 30645 => Loss: 46.68239119296413264237\n",
      "Iteration 30646 => Loss: 46.68222526085475720947\n",
      "Iteration 30647 => Loss: 46.68205933004757213212\n",
      "Iteration 30648 => Loss: 46.68189340054265557001\n",
      "Iteration 30649 => Loss: 46.68172747233990094173\n",
      "Iteration 30650 => Loss: 46.68156154543937219614\n",
      "Iteration 30651 => Loss: 46.68139561984101959524\n",
      "Iteration 30652 => Loss: 46.68122969554482182275\n",
      "Iteration 30653 => Loss: 46.68106377255080730038\n",
      "Iteration 30654 => Loss: 46.68089785085894050098\n",
      "Iteration 30655 => Loss: 46.68073193046922853000\n",
      "Iteration 30656 => Loss: 46.68056601138165717657\n",
      "Iteration 30657 => Loss: 46.68040009359617670270\n",
      "Iteration 30658 => Loss: 46.68023417711282974096\n",
      "Iteration 30659 => Loss: 46.68006826193160208049\n",
      "Iteration 30660 => Loss: 46.67990234805245108873\n",
      "Iteration 30661 => Loss: 46.67973643547539097653\n",
      "Iteration 30662 => Loss: 46.67957052420039332219\n",
      "Iteration 30663 => Loss: 46.67940461422747944198\n",
      "Iteration 30664 => Loss: 46.67923870555660670334\n",
      "Iteration 30665 => Loss: 46.67907279818778221170\n",
      "Iteration 30666 => Loss: 46.67890689212096333449\n",
      "Iteration 30667 => Loss: 46.67874098735618559886\n",
      "Iteration 30668 => Loss: 46.67857508389342058308\n",
      "Iteration 30669 => Loss: 46.67840918173266118174\n",
      "Iteration 30670 => Loss: 46.67824328087389318398\n",
      "Iteration 30671 => Loss: 46.67807738131709527352\n",
      "Iteration 30672 => Loss: 46.67791148306227455578\n",
      "Iteration 30673 => Loss: 46.67774558610941681991\n",
      "Iteration 30674 => Loss: 46.67757969045850074963\n",
      "Iteration 30675 => Loss: 46.67741379610954055579\n",
      "Iteration 30676 => Loss: 46.67724790306248650040\n",
      "Iteration 30677 => Loss: 46.67708201131738121603\n",
      "Iteration 30678 => Loss: 46.67691612087418207011\n",
      "Iteration 30679 => Loss: 46.67675023173285353550\n",
      "Iteration 30680 => Loss: 46.67658434389343824478\n",
      "Iteration 30681 => Loss: 46.67641845735590067079\n",
      "Iteration 30682 => Loss: 46.67625257212021239184\n",
      "Iteration 30683 => Loss: 46.67608668818641604048\n",
      "Iteration 30684 => Loss: 46.67592080555446187873\n",
      "Iteration 30685 => Loss: 46.67575492422431437944\n",
      "Iteration 30686 => Loss: 46.67558904419602328062\n",
      "Iteration 30687 => Loss: 46.67542316546953884426\n",
      "Iteration 30688 => Loss: 46.67525728804485396495\n",
      "Iteration 30689 => Loss: 46.67509141192198285353\n",
      "Iteration 30690 => Loss: 46.67492553710088998287\n",
      "Iteration 30691 => Loss: 46.67475966358157535296\n",
      "Iteration 30692 => Loss: 46.67459379136402475297\n",
      "Iteration 30693 => Loss: 46.67442792044822397202\n",
      "Iteration 30694 => Loss: 46.67426205083420143183\n",
      "Iteration 30695 => Loss: 46.67409618252189318355\n",
      "Iteration 30696 => Loss: 46.67393031551132054346\n",
      "Iteration 30697 => Loss: 46.67376444980244087901\n",
      "Iteration 30698 => Loss: 46.67359858539528261190\n",
      "Iteration 30699 => Loss: 46.67343272228981021499\n",
      "Iteration 30700 => Loss: 46.67326686048602368828\n",
      "Iteration 30701 => Loss: 46.67310099998392303178\n",
      "Iteration 30702 => Loss: 46.67293514078347982377\n",
      "Iteration 30703 => Loss: 46.67276928288469406425\n",
      "Iteration 30704 => Loss: 46.67260342628755154237\n",
      "Iteration 30705 => Loss: 46.67243757099204515271\n",
      "Iteration 30706 => Loss: 46.67227171699814647354\n",
      "Iteration 30707 => Loss: 46.67210586430588392659\n",
      "Iteration 30708 => Loss: 46.67194001291521487929\n",
      "Iteration 30709 => Loss: 46.67177416282613933163\n",
      "Iteration 30710 => Loss: 46.67160831403865017819\n",
      "Iteration 30711 => Loss: 46.67144246655272610269\n",
      "Iteration 30712 => Loss: 46.67127662036836710513\n",
      "Iteration 30713 => Loss: 46.67111077548555897465\n",
      "Iteration 30714 => Loss: 46.67094493190428750040\n",
      "Iteration 30715 => Loss: 46.67077908962456689324\n",
      "Iteration 30716 => Loss: 46.67061324864633320431\n",
      "Iteration 30717 => Loss: 46.67044740896963617161\n",
      "Iteration 30718 => Loss: 46.67028157059443316257\n",
      "Iteration 30719 => Loss: 46.67011573352073838805\n",
      "Iteration 30720 => Loss: 46.66994989774851632092\n",
      "Iteration 30721 => Loss: 46.66978406327773853945\n",
      "Iteration 30722 => Loss: 46.66961823010845478166\n",
      "Iteration 30723 => Loss: 46.66945239824059399325\n",
      "Iteration 30724 => Loss: 46.66928656767419170137\n",
      "Iteration 30725 => Loss: 46.66912073840921948431\n",
      "Iteration 30726 => Loss: 46.66895491044566313121\n",
      "Iteration 30727 => Loss: 46.66878908378350843122\n",
      "Iteration 30728 => Loss: 46.66862325842276248977\n",
      "Iteration 30729 => Loss: 46.66845743436340399057\n",
      "Iteration 30730 => Loss: 46.66829161160541872277\n",
      "Iteration 30731 => Loss: 46.66812579014879247552\n",
      "Iteration 30732 => Loss: 46.66795996999353945967\n",
      "Iteration 30733 => Loss: 46.66779415113963835893\n",
      "Iteration 30734 => Loss: 46.66762833358706785702\n",
      "Iteration 30735 => Loss: 46.66746251733581374310\n",
      "Iteration 30736 => Loss: 46.66729670238589733344\n",
      "Iteration 30737 => Loss: 46.66713088873727599548\n",
      "Iteration 30738 => Loss: 46.66696507638994972922\n",
      "Iteration 30739 => Loss: 46.66679926534391853465\n",
      "Iteration 30740 => Loss: 46.66663345559913977922\n",
      "Iteration 30741 => Loss: 46.66646764715564899006\n",
      "Iteration 30742 => Loss: 46.66630184001340353461\n",
      "Iteration 30743 => Loss: 46.66613603417240341287\n",
      "Iteration 30744 => Loss: 46.66597022963266994111\n",
      "Iteration 30745 => Loss: 46.66580442639412495964\n",
      "Iteration 30746 => Loss: 46.66563862445681110103\n",
      "Iteration 30747 => Loss: 46.66547282382069994355\n",
      "Iteration 30748 => Loss: 46.66530702448577727637\n",
      "Iteration 30749 => Loss: 46.66514122645207152118\n",
      "Iteration 30750 => Loss: 46.66497542971948320201\n",
      "Iteration 30751 => Loss: 46.66480963428808337312\n",
      "Iteration 30752 => Loss: 46.66464384015785782367\n",
      "Iteration 30753 => Loss: 46.66447804732875681566\n",
      "Iteration 30754 => Loss: 46.66431225580078745452\n",
      "Iteration 30755 => Loss: 46.66414646557395684567\n",
      "Iteration 30756 => Loss: 46.66398067664822235656\n",
      "Iteration 30757 => Loss: 46.66381488902360530346\n",
      "Iteration 30758 => Loss: 46.66364910270007726467\n",
      "Iteration 30759 => Loss: 46.66348331767760271305\n",
      "Iteration 30760 => Loss: 46.66331753395624559744\n",
      "Iteration 30761 => Loss: 46.66315175153591354729\n",
      "Iteration 30762 => Loss: 46.66298597041664919516\n",
      "Iteration 30763 => Loss: 46.66282019059841701392\n",
      "Iteration 30764 => Loss: 46.66265441208124542527\n",
      "Iteration 30765 => Loss: 46.66248863486507048037\n",
      "Iteration 30766 => Loss: 46.66232285894992060094\n",
      "Iteration 30767 => Loss: 46.66215708433575315439\n",
      "Iteration 30768 => Loss: 46.66199131102257524617\n",
      "Iteration 30769 => Loss: 46.66182553901039398170\n",
      "Iteration 30770 => Loss: 46.66165976829917383384\n",
      "Iteration 30771 => Loss: 46.66149399888891480259\n",
      "Iteration 30772 => Loss: 46.66132823077960267710\n",
      "Iteration 30773 => Loss: 46.66116246397123035194\n",
      "Iteration 30774 => Loss: 46.66099669846379072169\n",
      "Iteration 30775 => Loss: 46.66083093425728378634\n",
      "Iteration 30776 => Loss: 46.66066517135166691332\n",
      "Iteration 30777 => Loss: 46.66049940974695431350\n",
      "Iteration 30778 => Loss: 46.66033364944311756517\n",
      "Iteration 30779 => Loss: 46.66016789044017798460\n",
      "Iteration 30780 => Loss: 46.66000213273810004466\n",
      "Iteration 30781 => Loss: 46.65983637633687663993\n",
      "Iteration 30782 => Loss: 46.65967062123650066496\n",
      "Iteration 30783 => Loss: 46.65950486743696501435\n",
      "Iteration 30784 => Loss: 46.65933911493824837180\n",
      "Iteration 30785 => Loss: 46.65917336374037915903\n",
      "Iteration 30786 => Loss: 46.65900761384327921633\n",
      "Iteration 30787 => Loss: 46.65884186524697696541\n",
      "Iteration 30788 => Loss: 46.65867611795146530085\n",
      "Iteration 30789 => Loss: 46.65851037195675843350\n",
      "Iteration 30790 => Loss: 46.65834462726279241451\n",
      "Iteration 30791 => Loss: 46.65817888386958145475\n",
      "Iteration 30792 => Loss: 46.65801314177713265963\n",
      "Iteration 30793 => Loss: 46.65784740098539629116\n",
      "Iteration 30794 => Loss: 46.65768166149440077106\n",
      "Iteration 30795 => Loss: 46.65751592330411767762\n",
      "Iteration 30796 => Loss: 46.65735018641452569454\n",
      "Iteration 30797 => Loss: 46.65718445082563903270\n",
      "Iteration 30798 => Loss: 46.65701871653743637580\n",
      "Iteration 30799 => Loss: 46.65685298354991772385\n",
      "Iteration 30800 => Loss: 46.65668725186304044428\n",
      "Iteration 30801 => Loss: 46.65652152147683295880\n",
      "Iteration 30802 => Loss: 46.65635579239128105655\n",
      "Iteration 30803 => Loss: 46.65619006460632078870\n",
      "Iteration 30804 => Loss: 46.65602433812202320951\n",
      "Iteration 30805 => Loss: 46.65585861293831726471\n",
      "Iteration 30806 => Loss: 46.65569288905521005972\n",
      "Iteration 30807 => Loss: 46.65552716647271580541\n",
      "Iteration 30808 => Loss: 46.65536144519078476378\n",
      "Iteration 30809 => Loss: 46.65519572520944535654\n",
      "Iteration 30810 => Loss: 46.65503000652864074027\n",
      "Iteration 30811 => Loss: 46.65486428914838512583\n",
      "Iteration 30812 => Loss: 46.65469857306872114577\n",
      "Iteration 30813 => Loss: 46.65453285828954221870\n",
      "Iteration 30814 => Loss: 46.65436714481091229345\n",
      "Iteration 30815 => Loss: 46.65420143263278163204\n",
      "Iteration 30816 => Loss: 46.65403572175514312903\n",
      "Iteration 30817 => Loss: 46.65387001217798967900\n",
      "Iteration 30818 => Loss: 46.65370430390133549281\n",
      "Iteration 30819 => Loss: 46.65353859692515214874\n",
      "Iteration 30820 => Loss: 46.65337289124940411966\n",
      "Iteration 30821 => Loss: 46.65320718687411982728\n",
      "Iteration 30822 => Loss: 46.65304148379928506074\n",
      "Iteration 30823 => Loss: 46.65287578202485718748\n",
      "Iteration 30824 => Loss: 46.65271008155086462921\n",
      "Iteration 30825 => Loss: 46.65254438237727896421\n",
      "Iteration 30826 => Loss: 46.65237868450407887622\n",
      "Iteration 30827 => Loss: 46.65221298793127147064\n",
      "Iteration 30828 => Loss: 46.65204729265884964207\n",
      "Iteration 30829 => Loss: 46.65188159868680628506\n",
      "Iteration 30830 => Loss: 46.65171590601509166163\n",
      "Iteration 30831 => Loss: 46.65155021464374840434\n",
      "Iteration 30832 => Loss: 46.65138452457274809149\n",
      "Iteration 30833 => Loss: 46.65121883580204809050\n",
      "Iteration 30834 => Loss: 46.65105314833168392852\n",
      "Iteration 30835 => Loss: 46.65088746216162718383\n",
      "Iteration 30836 => Loss: 46.65072177729185654016\n",
      "Iteration 30837 => Loss: 46.65055609372236489207\n",
      "Iteration 30838 => Loss: 46.65039041145315934500\n",
      "Iteration 30839 => Loss: 46.65022473048421858266\n",
      "Iteration 30840 => Loss: 46.65005905081554971048\n",
      "Iteration 30841 => Loss: 46.64989337244709588504\n",
      "Iteration 30842 => Loss: 46.64972769537889973890\n",
      "Iteration 30843 => Loss: 46.64956201961091153407\n",
      "Iteration 30844 => Loss: 46.64939634514315258684\n",
      "Iteration 30845 => Loss: 46.64923067197558737007\n",
      "Iteration 30846 => Loss: 46.64906500010822298918\n",
      "Iteration 30847 => Loss: 46.64889932954103812790\n",
      "Iteration 30848 => Loss: 46.64873366027403989165\n",
      "Iteration 30849 => Loss: 46.64856799230719275329\n",
      "Iteration 30850 => Loss: 46.64840232564051092368\n",
      "Iteration 30851 => Loss: 46.64823666027395887568\n",
      "Iteration 30852 => Loss: 46.64807099620753660929\n",
      "Iteration 30853 => Loss: 46.64790533344123701909\n",
      "Iteration 30854 => Loss: 46.64773967197507431592\n",
      "Iteration 30855 => Loss: 46.64757401180899165638\n",
      "Iteration 30856 => Loss: 46.64740835294301746217\n",
      "Iteration 30857 => Loss: 46.64724269537709488986\n",
      "Iteration 30858 => Loss: 46.64707703911129499375\n",
      "Iteration 30859 => Loss: 46.64691138414551119240\n",
      "Iteration 30860 => Loss: 46.64674573047979322382\n",
      "Iteration 30861 => Loss: 46.64658007811411266630\n",
      "Iteration 30862 => Loss: 46.64641442704846951983\n",
      "Iteration 30863 => Loss: 46.64624877728285667899\n",
      "Iteration 30864 => Loss: 46.64608312881723151122\n",
      "Iteration 30865 => Loss: 46.64591748165162243822\n",
      "Iteration 30866 => Loss: 46.64575183578600103829\n",
      "Iteration 30867 => Loss: 46.64558619122036020599\n",
      "Iteration 30868 => Loss: 46.64542054795470704676\n",
      "Iteration 30869 => Loss: 46.64525490598897050631\n",
      "Iteration 30870 => Loss: 46.64508926532322163894\n",
      "Iteration 30871 => Loss: 46.64492362595738228492\n",
      "Iteration 30872 => Loss: 46.64475798789148797141\n",
      "Iteration 30873 => Loss: 46.64459235112552448754\n",
      "Iteration 30874 => Loss: 46.64442671565944209533\n",
      "Iteration 30875 => Loss: 46.64426108149329053276\n",
      "Iteration 30876 => Loss: 46.64409544862699874557\n",
      "Iteration 30877 => Loss: 46.64392981706058094460\n",
      "Iteration 30878 => Loss: 46.64376418679405134071\n",
      "Iteration 30879 => Loss: 46.64359855782738861762\n",
      "Iteration 30880 => Loss: 46.64343293016055014277\n",
      "Iteration 30881 => Loss: 46.64326730379356433787\n",
      "Iteration 30882 => Loss: 46.64310167872640278119\n",
      "Iteration 30883 => Loss: 46.64293605495905836733\n",
      "Iteration 30884 => Loss: 46.64277043249149556914\n",
      "Iteration 30885 => Loss: 46.64260481132374991375\n",
      "Iteration 30886 => Loss: 46.64243919145578587404\n",
      "Iteration 30887 => Loss: 46.64227357288759634457\n",
      "Iteration 30888 => Loss: 46.64210795561919553620\n",
      "Iteration 30889 => Loss: 46.64194233965052660551\n",
      "Iteration 30890 => Loss: 46.64177672498160376335\n",
      "Iteration 30891 => Loss: 46.64161111161243411516\n",
      "Iteration 30892 => Loss: 46.64144549954297502836\n",
      "Iteration 30893 => Loss: 46.64127988877321939754\n",
      "Iteration 30894 => Loss: 46.64111427930318853896\n",
      "Iteration 30895 => Loss: 46.64094867113282560922\n",
      "Iteration 30896 => Loss: 46.64078306426217324088\n",
      "Iteration 30897 => Loss: 46.64061745869121011765\n",
      "Iteration 30898 => Loss: 46.64045185441987939612\n",
      "Iteration 30899 => Loss: 46.64028625144820949799\n",
      "Iteration 30900 => Loss: 46.64012064977617200157\n",
      "Iteration 30901 => Loss: 46.63995504940379532854\n",
      "Iteration 30902 => Loss: 46.63978945033102263551\n",
      "Iteration 30903 => Loss: 46.63962385255785392246\n",
      "Iteration 30904 => Loss: 46.63945825608431761111\n",
      "Iteration 30905 => Loss: 46.63929266091035685804\n",
      "Iteration 30906 => Loss: 46.63912706703597166324\n",
      "Iteration 30907 => Loss: 46.63896147446116913216\n",
      "Iteration 30908 => Loss: 46.63879588318592084306\n",
      "Iteration 30909 => Loss: 46.63863029321023390139\n",
      "Iteration 30910 => Loss: 46.63846470453407278001\n",
      "Iteration 30911 => Loss: 46.63829911715745168976\n",
      "Iteration 30912 => Loss: 46.63813353108036352523\n",
      "Iteration 30913 => Loss: 46.63796794630278697014\n",
      "Iteration 30914 => Loss: 46.63780236282467228648\n",
      "Iteration 30915 => Loss: 46.63763678064608342311\n",
      "Iteration 30916 => Loss: 46.63747119976697774746\n",
      "Iteration 30917 => Loss: 46.63730562018732683782\n",
      "Iteration 30918 => Loss: 46.63714004190713069420\n",
      "Iteration 30919 => Loss: 46.63697446492639642202\n",
      "Iteration 30920 => Loss: 46.63680888924508138871\n",
      "Iteration 30921 => Loss: 46.63664331486322822684\n",
      "Iteration 30922 => Loss: 46.63647774178078009299\n",
      "Iteration 30923 => Loss: 46.63631216999775119803\n",
      "Iteration 30924 => Loss: 46.63614659951409890937\n",
      "Iteration 30925 => Loss: 46.63598103032984454330\n",
      "Iteration 30926 => Loss: 46.63581546244495967812\n",
      "Iteration 30927 => Loss: 46.63564989585945141926\n",
      "Iteration 30928 => Loss: 46.63548433057331266127\n",
      "Iteration 30929 => Loss: 46.63531876658651498246\n",
      "Iteration 30930 => Loss: 46.63515320389902996112\n",
      "Iteration 30931 => Loss: 46.63498764251089312438\n",
      "Iteration 30932 => Loss: 46.63482208242207605053\n",
      "Iteration 30933 => Loss: 46.63465652363255031787\n",
      "Iteration 30934 => Loss: 46.63449096614235855895\n",
      "Iteration 30935 => Loss: 46.63432540995142261409\n",
      "Iteration 30936 => Loss: 46.63415985505977090497\n",
      "Iteration 30937 => Loss: 46.63399430146737500991\n",
      "Iteration 30938 => Loss: 46.63382874917424913974\n",
      "Iteration 30939 => Loss: 46.63366319818036487277\n",
      "Iteration 30940 => Loss: 46.63349764848570089271\n",
      "Iteration 30941 => Loss: 46.63333210009027851584\n",
      "Iteration 30942 => Loss: 46.63316655299407642588\n",
      "Iteration 30943 => Loss: 46.63300100719705909569\n",
      "Iteration 30944 => Loss: 46.63283546269923363070\n",
      "Iteration 30945 => Loss: 46.63266991950062134720\n",
      "Iteration 30946 => Loss: 46.63250437760116540176\n",
      "Iteration 30947 => Loss: 46.63233883700088711066\n",
      "Iteration 30948 => Loss: 46.63217329769974384135\n",
      "Iteration 30949 => Loss: 46.63200775969775691010\n",
      "Iteration 30950 => Loss: 46.63184222299490500063\n",
      "Iteration 30951 => Loss: 46.63167668759118100752\n",
      "Iteration 30952 => Loss: 46.63151115348654940362\n",
      "Iteration 30953 => Loss: 46.63134562068101729437\n",
      "Iteration 30954 => Loss: 46.63118008917459889062\n",
      "Iteration 30955 => Loss: 46.63101455896724445438\n",
      "Iteration 30956 => Loss: 46.63084903005898951278\n",
      "Iteration 30957 => Loss: 46.63068350244978432784\n",
      "Iteration 30958 => Loss: 46.63051797613962179412\n",
      "Iteration 30959 => Loss: 46.63035245112849480620\n",
      "Iteration 30960 => Loss: 46.63018692741643178579\n",
      "Iteration 30961 => Loss: 46.63002140500335457318\n",
      "Iteration 30962 => Loss: 46.62985588388932001180\n",
      "Iteration 30963 => Loss: 46.62969036407424994195\n",
      "Iteration 30964 => Loss: 46.62952484555820120704\n",
      "Iteration 30965 => Loss: 46.62935932834113827994\n",
      "Iteration 30966 => Loss: 46.62919381242301142265\n",
      "Iteration 30967 => Loss: 46.62902829780386326775\n",
      "Iteration 30968 => Loss: 46.62886278448367249894\n",
      "Iteration 30969 => Loss: 46.62869727246242490537\n",
      "Iteration 30970 => Loss: 46.62853176174008495991\n",
      "Iteration 30971 => Loss: 46.62836625231668108427\n",
      "Iteration 30972 => Loss: 46.62820074419217775130\n",
      "Iteration 30973 => Loss: 46.62803523736656785559\n",
      "Iteration 30974 => Loss: 46.62786973183985850255\n",
      "Iteration 30975 => Loss: 46.62770422761203548134\n",
      "Iteration 30976 => Loss: 46.62753872468307037025\n",
      "Iteration 30977 => Loss: 46.62737322305296316927\n",
      "Iteration 30978 => Loss: 46.62720772272170677297\n",
      "Iteration 30979 => Loss: 46.62704222368929407594\n",
      "Iteration 30980 => Loss: 46.62687672595568955103\n",
      "Iteration 30981 => Loss: 46.62671122952093583081\n",
      "Iteration 30982 => Loss: 46.62654573438494765014\n",
      "Iteration 30983 => Loss: 46.62638024054776764160\n",
      "Iteration 30984 => Loss: 46.62621474800940291061\n",
      "Iteration 30985 => Loss: 46.62604925676979661375\n",
      "Iteration 30986 => Loss: 46.62588376682894164560\n",
      "Iteration 30987 => Loss: 46.62571827818686642786\n",
      "Iteration 30988 => Loss: 46.62555279084350701169\n",
      "Iteration 30989 => Loss: 46.62538730479894155678\n",
      "Iteration 30990 => Loss: 46.62522182005304216545\n",
      "Iteration 30991 => Loss: 46.62505633660588699740\n",
      "Iteration 30992 => Loss: 46.62489085445744052549\n",
      "Iteration 30993 => Loss: 46.62472537360767432801\n",
      "Iteration 30994 => Loss: 46.62455989405658129954\n",
      "Iteration 30995 => Loss: 46.62439441580419696720\n",
      "Iteration 30996 => Loss: 46.62422893885045027673\n",
      "Iteration 30997 => Loss: 46.62406346319538386069\n",
      "Iteration 30998 => Loss: 46.62389798883894798109\n",
      "Iteration 30999 => Loss: 46.62373251578114263793\n",
      "Iteration 31000 => Loss: 46.62356704402196783121\n",
      "Iteration 31001 => Loss: 46.62340157356139513922\n",
      "Iteration 31002 => Loss: 46.62323610439944587824\n",
      "Iteration 31003 => Loss: 46.62307063653606320486\n",
      "Iteration 31004 => Loss: 46.62290516997126843535\n",
      "Iteration 31005 => Loss: 46.62273970470507578057\n",
      "Iteration 31006 => Loss: 46.62257424073742129167\n",
      "Iteration 31007 => Loss: 46.62240877806831207408\n",
      "Iteration 31008 => Loss: 46.62224331669775523324\n",
      "Iteration 31009 => Loss: 46.62207785662574366370\n",
      "Iteration 31010 => Loss: 46.62191239785224183834\n",
      "Iteration 31011 => Loss: 46.62174694037724975715\n",
      "Iteration 31012 => Loss: 46.62158148420076031471\n",
      "Iteration 31013 => Loss: 46.62141602932277351101\n",
      "Iteration 31014 => Loss: 46.62125057574323960807\n",
      "Iteration 31015 => Loss: 46.62108512346219413303\n",
      "Iteration 31016 => Loss: 46.62091967247961576959\n",
      "Iteration 31017 => Loss: 46.62075422279547609605\n",
      "Iteration 31018 => Loss: 46.62058877440978221784\n",
      "Iteration 31019 => Loss: 46.62042332732252702954\n",
      "Iteration 31020 => Loss: 46.62025788153368921485\n",
      "Iteration 31021 => Loss: 46.62009243704324745750\n",
      "Iteration 31022 => Loss: 46.61992699385123017919\n",
      "Iteration 31023 => Loss: 46.61976155195758764194\n",
      "Iteration 31024 => Loss: 46.61959611136231984574\n",
      "Iteration 31025 => Loss: 46.61943067206540547431\n",
      "Iteration 31026 => Loss: 46.61926523406688005480\n",
      "Iteration 31027 => Loss: 46.61909979736668674377\n",
      "Iteration 31028 => Loss: 46.61893436196483264666\n",
      "Iteration 31029 => Loss: 46.61876892786132486890\n",
      "Iteration 31030 => Loss: 46.61860349505612788334\n",
      "Iteration 31031 => Loss: 46.61843806354923458457\n",
      "Iteration 31032 => Loss: 46.61827263334063076172\n",
      "Iteration 31033 => Loss: 46.61810720443032352023\n",
      "Iteration 31034 => Loss: 46.61794177681828443838\n",
      "Iteration 31035 => Loss: 46.61777635050452772703\n",
      "Iteration 31036 => Loss: 46.61761092548902496446\n",
      "Iteration 31037 => Loss: 46.61744550177174772898\n",
      "Iteration 31038 => Loss: 46.61728007935272444229\n",
      "Iteration 31039 => Loss: 46.61711465823193378810\n",
      "Iteration 31040 => Loss: 46.61694923840934734471\n",
      "Iteration 31041 => Loss: 46.61678381988497221755\n",
      "Iteration 31042 => Loss: 46.61661840265880130119\n",
      "Iteration 31043 => Loss: 46.61645298673079196305\n",
      "Iteration 31044 => Loss: 46.61628757210097973029\n",
      "Iteration 31045 => Loss: 46.61612215876932907577\n",
      "Iteration 31046 => Loss: 46.61595674673583289405\n",
      "Iteration 31047 => Loss: 46.61579133600048407970\n",
      "Iteration 31048 => Loss: 46.61562592656326131646\n",
      "Iteration 31049 => Loss: 46.61546051842417170974\n",
      "Iteration 31050 => Loss: 46.61529511158320104869\n",
      "Iteration 31051 => Loss: 46.61512970604030670074\n",
      "Iteration 31052 => Loss: 46.61496430179552419304\n",
      "Iteration 31053 => Loss: 46.61479889884882510387\n",
      "Iteration 31054 => Loss: 46.61463349720021653866\n",
      "Iteration 31055 => Loss: 46.61446809684964165399\n",
      "Iteration 31056 => Loss: 46.61430269779713597700\n",
      "Iteration 31057 => Loss: 46.61413730004267819140\n",
      "Iteration 31058 => Loss: 46.61397190358623987549\n",
      "Iteration 31059 => Loss: 46.61380650842782813470\n",
      "Iteration 31060 => Loss: 46.61364111456745007445\n",
      "Iteration 31061 => Loss: 46.61347572200504174589\n",
      "Iteration 31062 => Loss: 46.61331033074062446531\n",
      "Iteration 31063 => Loss: 46.61314494077421244356\n",
      "Iteration 31064 => Loss: 46.61297955210577015350\n",
      "Iteration 31065 => Loss: 46.61281416473526917343\n",
      "Iteration 31066 => Loss: 46.61264877866273792506\n",
      "Iteration 31067 => Loss: 46.61248339388815509210\n",
      "Iteration 31068 => Loss: 46.61231801041149225284\n",
      "Iteration 31069 => Loss: 46.61215262823275651272\n",
      "Iteration 31070 => Loss: 46.61198724735191945001\n",
      "Iteration 31071 => Loss: 46.61182186776899527558\n",
      "Iteration 31072 => Loss: 46.61165648948394846229\n",
      "Iteration 31073 => Loss: 46.61149111249679322100\n",
      "Iteration 31074 => Loss: 46.61132573680750112999\n",
      "Iteration 31075 => Loss: 46.61116036241605797841\n",
      "Iteration 31076 => Loss: 46.61099498932247797711\n",
      "Iteration 31077 => Loss: 46.61082961752673270439\n",
      "Iteration 31078 => Loss: 46.61066424702882216025\n",
      "Iteration 31079 => Loss: 46.61049887782871792297\n",
      "Iteration 31080 => Loss: 46.61033350992642709798\n",
      "Iteration 31081 => Loss: 46.61016814332195679071\n",
      "Iteration 31082 => Loss: 46.61000277801525726318\n",
      "Iteration 31083 => Loss: 46.60983741400633562080\n",
      "Iteration 31084 => Loss: 46.60967205129518475815\n",
      "Iteration 31085 => Loss: 46.60950668988179756980\n",
      "Iteration 31086 => Loss: 46.60934132976613852861\n",
      "Iteration 31087 => Loss: 46.60917597094822895087\n",
      "Iteration 31088 => Loss: 46.60901061342805462573\n",
      "Iteration 31089 => Loss: 46.60884525720558002604\n",
      "Iteration 31090 => Loss: 46.60867990228082646809\n",
      "Iteration 31091 => Loss: 46.60851454865375131931\n",
      "Iteration 31092 => Loss: 46.60834919632439010684\n",
      "Iteration 31093 => Loss: 46.60818384529267888183\n",
      "Iteration 31094 => Loss: 46.60801849555864606600\n",
      "Iteration 31095 => Loss: 46.60785314712228455392\n",
      "Iteration 31096 => Loss: 46.60768779998355171301\n",
      "Iteration 31097 => Loss: 46.60752245414244043786\n",
      "Iteration 31098 => Loss: 46.60735710959897915018\n",
      "Iteration 31099 => Loss: 46.60719176635313232282\n",
      "Iteration 31100 => Loss: 46.60702642440489995579\n",
      "Iteration 31101 => Loss: 46.60686108375421099481\n",
      "Iteration 31102 => Loss: 46.60669574440116491587\n",
      "Iteration 31103 => Loss: 46.60653040634566934841\n",
      "Iteration 31104 => Loss: 46.60636506958773139786\n",
      "Iteration 31105 => Loss: 46.60619973412735816964\n",
      "Iteration 31106 => Loss: 46.60603439996451413663\n",
      "Iteration 31107 => Loss: 46.60586906709923482595\n",
      "Iteration 31108 => Loss: 46.60570373553146339418\n",
      "Iteration 31109 => Loss: 46.60553840526118563048\n",
      "Iteration 31110 => Loss: 46.60537307628842995655\n",
      "Iteration 31111 => Loss: 46.60520774861316795068\n",
      "Iteration 31112 => Loss: 46.60504242223537829659\n",
      "Iteration 31113 => Loss: 46.60487709715506809971\n",
      "Iteration 31114 => Loss: 46.60471177337222314918\n",
      "Iteration 31115 => Loss: 46.60454645088682923415\n",
      "Iteration 31116 => Loss: 46.60438112969887924919\n",
      "Iteration 31117 => Loss: 46.60421580980835898345\n",
      "Iteration 31118 => Loss: 46.60405049121525422606\n",
      "Iteration 31119 => Loss: 46.60388517391957918790\n",
      "Iteration 31120 => Loss: 46.60371985792129123638\n",
      "Iteration 31121 => Loss: 46.60355454322038326609\n",
      "Iteration 31122 => Loss: 46.60338922981686948788\n",
      "Iteration 31123 => Loss: 46.60322391771072148003\n",
      "Iteration 31124 => Loss: 46.60305860690194634799\n",
      "Iteration 31125 => Loss: 46.60289329739051567003\n",
      "Iteration 31126 => Loss: 46.60272798917642234073\n",
      "Iteration 31127 => Loss: 46.60256268225966636010\n",
      "Iteration 31128 => Loss: 46.60239737664021930641\n",
      "Iteration 31129 => Loss: 46.60223207231810960138\n",
      "Iteration 31130 => Loss: 46.60206676929325197989\n",
      "Iteration 31131 => Loss: 46.60190146756571039077\n",
      "Iteration 31132 => Loss: 46.60173616713545641232\n",
      "Iteration 31133 => Loss: 46.60157086800246872826\n",
      "Iteration 31134 => Loss: 46.60140557016672602231\n",
      "Iteration 31135 => Loss: 46.60124027362824250531\n",
      "Iteration 31136 => Loss: 46.60107497838698975556\n",
      "Iteration 31137 => Loss: 46.60090968444298198392\n",
      "Iteration 31138 => Loss: 46.60074439179616234696\n",
      "Iteration 31139 => Loss: 46.60057910044658058268\n",
      "Iteration 31140 => Loss: 46.60041381039416563681\n",
      "Iteration 31141 => Loss: 46.60024852163896014190\n",
      "Iteration 31142 => Loss: 46.60008323418093567625\n",
      "Iteration 31143 => Loss: 46.59991794802006381815\n",
      "Iteration 31144 => Loss: 46.59975266315636588388\n",
      "Iteration 31145 => Loss: 46.59958737958981345173\n",
      "Iteration 31146 => Loss: 46.59942209732038520542\n",
      "Iteration 31147 => Loss: 46.59925681634808114495\n",
      "Iteration 31148 => Loss: 46.59909153667291548118\n",
      "Iteration 31149 => Loss: 46.59892625829484558153\n",
      "Iteration 31150 => Loss: 46.59876098121387144602\n",
      "Iteration 31151 => Loss: 46.59859570542996465292\n",
      "Iteration 31152 => Loss: 46.59843043094316072938\n",
      "Iteration 31153 => Loss: 46.59826515775340993741\n",
      "Iteration 31154 => Loss: 46.59809988586070517158\n",
      "Iteration 31155 => Loss: 46.59793461526506064274\n",
      "Iteration 31156 => Loss: 46.59776934596644082376\n",
      "Iteration 31157 => Loss: 46.59760407796484571463\n",
      "Iteration 31158 => Loss: 46.59743881126027531536\n",
      "Iteration 31159 => Loss: 46.59727354585270120424\n",
      "Iteration 31160 => Loss: 46.59710828174213759212\n",
      "Iteration 31161 => Loss: 46.59694301892852763558\n",
      "Iteration 31162 => Loss: 46.59677775741192817804\n",
      "Iteration 31163 => Loss: 46.59661249719226816524\n",
      "Iteration 31164 => Loss: 46.59644723826956891344\n",
      "Iteration 31165 => Loss: 46.59628198064378779009\n",
      "Iteration 31166 => Loss: 46.59611672431498163860\n",
      "Iteration 31167 => Loss: 46.59595146928306519385\n",
      "Iteration 31168 => Loss: 46.59578621554808819383\n",
      "Iteration 31169 => Loss: 46.59562096310998668969\n",
      "Iteration 31170 => Loss: 46.59545571196878910314\n",
      "Iteration 31171 => Loss: 46.59529046212447411790\n",
      "Iteration 31172 => Loss: 46.59512521357703462854\n",
      "Iteration 31173 => Loss: 46.59495996632646352964\n",
      "Iteration 31174 => Loss: 46.59479472037273239948\n",
      "Iteration 31175 => Loss: 46.59462947571585544893\n",
      "Iteration 31176 => Loss: 46.59446423235579715083\n",
      "Iteration 31177 => Loss: 46.59429899029257882148\n",
      "Iteration 31178 => Loss: 46.59413374952615072289\n",
      "Iteration 31179 => Loss: 46.59396851005651996047\n",
      "Iteration 31180 => Loss: 46.59380327188367232338\n",
      "Iteration 31181 => Loss: 46.59363803500763623333\n",
      "Iteration 31182 => Loss: 46.59347279942835484690\n",
      "Iteration 31183 => Loss: 46.59330756514585658579\n",
      "Iteration 31184 => Loss: 46.59314233216006329030\n",
      "Iteration 31185 => Loss: 46.59297710047104601472\n",
      "Iteration 31186 => Loss: 46.59281187007874081019\n",
      "Iteration 31187 => Loss: 46.59264664098316188756\n",
      "Iteration 31188 => Loss: 46.59248141318427371971\n",
      "Iteration 31189 => Loss: 46.59231618668211893919\n",
      "Iteration 31190 => Loss: 46.59215096147663359716\n",
      "Iteration 31191 => Loss: 46.59198573756782479904\n",
      "Iteration 31192 => Loss: 46.59182051495569254485\n",
      "Iteration 31193 => Loss: 46.59165529364020841285\n",
      "Iteration 31194 => Loss: 46.59149007362137240307\n",
      "Iteration 31195 => Loss: 46.59132485489919162092\n",
      "Iteration 31196 => Loss: 46.59115963747361632841\n",
      "Iteration 31197 => Loss: 46.59099442134468205268\n",
      "Iteration 31198 => Loss: 46.59082920651233195031\n",
      "Iteration 31199 => Loss: 46.59066399297658023215\n",
      "Iteration 31200 => Loss: 46.59049878073744821450\n",
      "Iteration 31201 => Loss: 46.59033356979485773763\n",
      "Iteration 31202 => Loss: 46.59016836014885853956\n",
      "Iteration 31203 => Loss: 46.59000315179938667143\n",
      "Iteration 31204 => Loss: 46.58983794474647055495\n",
      "Iteration 31205 => Loss: 46.58967273899011729554\n",
      "Iteration 31206 => Loss: 46.58950753453027715523\n",
      "Iteration 31207 => Loss: 46.58934233136695013400\n",
      "Iteration 31208 => Loss: 46.58917712950012202100\n",
      "Iteration 31209 => Loss: 46.58901192892980702709\n",
      "Iteration 31210 => Loss: 46.58884672965594120342\n",
      "Iteration 31211 => Loss: 46.58868153167857428798\n",
      "Iteration 31212 => Loss: 46.58851633499768496449\n",
      "Iteration 31213 => Loss: 46.58835113961323060039\n",
      "Iteration 31214 => Loss: 46.58818594552521830110\n",
      "Iteration 31215 => Loss: 46.58802075273366938291\n",
      "Iteration 31216 => Loss: 46.58785556123851279153\n",
      "Iteration 31217 => Loss: 46.58769037103979115955\n",
      "Iteration 31218 => Loss: 46.58752518213745474895\n",
      "Iteration 31219 => Loss: 46.58735999453152487604\n",
      "Iteration 31220 => Loss: 46.58719480822197311909\n",
      "Iteration 31221 => Loss: 46.58702962320879947811\n",
      "Iteration 31222 => Loss: 46.58686443949198974224\n",
      "Iteration 31223 => Loss: 46.58669925707154391148\n",
      "Iteration 31224 => Loss: 46.58653407594741935327\n",
      "Iteration 31225 => Loss: 46.58636889611962317304\n",
      "Iteration 31226 => Loss: 46.58620371758816247620\n",
      "Iteration 31227 => Loss: 46.58603854035301594649\n",
      "Iteration 31228 => Loss: 46.58587336441416937305\n",
      "Iteration 31229 => Loss: 46.58570818977161565044\n",
      "Iteration 31230 => Loss: 46.58554301642534767325\n",
      "Iteration 31231 => Loss: 46.58537784437535123061\n",
      "Iteration 31232 => Loss: 46.58521267362161211167\n",
      "Iteration 31233 => Loss: 46.58504750416412321101\n",
      "Iteration 31234 => Loss: 46.58488233600288452863\n",
      "Iteration 31235 => Loss: 46.58471716913786053738\n",
      "Iteration 31236 => Loss: 46.58455200356906544812\n",
      "Iteration 31237 => Loss: 46.58438683929649215543\n",
      "Iteration 31238 => Loss: 46.58422167632010513216\n",
      "Iteration 31239 => Loss: 46.58405651463990437833\n",
      "Iteration 31240 => Loss: 46.58389135425588989392\n",
      "Iteration 31241 => Loss: 46.58372619516804746809\n",
      "Iteration 31242 => Loss: 46.58356103737636999540\n",
      "Iteration 31243 => Loss: 46.58339588088082194872\n",
      "Iteration 31244 => Loss: 46.58323072568144596062\n",
      "Iteration 31245 => Loss: 46.58306557177817808224\n",
      "Iteration 31246 => Loss: 46.58290041917103962987\n",
      "Iteration 31247 => Loss: 46.58273526785998797095\n",
      "Iteration 31248 => Loss: 46.58257011784505863261\n",
      "Iteration 31249 => Loss: 46.58240496912621608772\n",
      "Iteration 31250 => Loss: 46.58223982170342480913\n",
      "Iteration 31251 => Loss: 46.58207467557672742942\n",
      "Iteration 31252 => Loss: 46.58190953074608131601\n",
      "Iteration 31253 => Loss: 46.58174438721149357434\n",
      "Iteration 31254 => Loss: 46.58157924497292867727\n",
      "Iteration 31255 => Loss: 46.58141410403039373023\n",
      "Iteration 31256 => Loss: 46.58124896438387452235\n",
      "Iteration 31257 => Loss: 46.58108382603339236994\n",
      "Iteration 31258 => Loss: 46.58091868897887621870\n",
      "Iteration 31259 => Loss: 46.58075355322035449035\n",
      "Iteration 31260 => Loss: 46.58058841875781297404\n",
      "Iteration 31261 => Loss: 46.58042328559124456433\n",
      "Iteration 31262 => Loss: 46.58025815372060662867\n",
      "Iteration 31263 => Loss: 46.58009302314592758876\n",
      "Iteration 31264 => Loss: 46.57992789386717902289\n",
      "Iteration 31265 => Loss: 46.57976276588437514192\n",
      "Iteration 31266 => Loss: 46.57959763919747331329\n",
      "Iteration 31267 => Loss: 46.57943251380648774784\n",
      "Iteration 31268 => Loss: 46.57926738971139002388\n",
      "Iteration 31269 => Loss: 46.57910226691217303596\n",
      "Iteration 31270 => Loss: 46.57893714540882257324\n",
      "Iteration 31271 => Loss: 46.57877202520136705743\n",
      "Iteration 31272 => Loss: 46.57860690628974964511\n",
      "Iteration 31273 => Loss: 46.57844178867397033628\n",
      "Iteration 31274 => Loss: 46.57827667235402913093\n",
      "Iteration 31275 => Loss: 46.57811155732993313450\n",
      "Iteration 31276 => Loss: 46.57794644360161129271\n",
      "Iteration 31277 => Loss: 46.57778133116912044898\n",
      "Iteration 31278 => Loss: 46.57761622003241086531\n",
      "Iteration 31279 => Loss: 46.57745111019149675258\n",
      "Iteration 31280 => Loss: 46.57728600164635679448\n",
      "Iteration 31281 => Loss: 46.57712089439696967474\n",
      "Iteration 31282 => Loss: 46.57695578844333539337\n",
      "Iteration 31283 => Loss: 46.57679068378544684492\n",
      "Iteration 31284 => Loss: 46.57662558042329692398\n",
      "Iteration 31285 => Loss: 46.57646047835685720884\n",
      "Iteration 31286 => Loss: 46.57629537758613480491\n",
      "Iteration 31287 => Loss: 46.57613027811111550136\n",
      "Iteration 31288 => Loss: 46.57596517993179219275\n",
      "Iteration 31289 => Loss: 46.57580008304815066822\n",
      "Iteration 31290 => Loss: 46.57563498746017671692\n",
      "Iteration 31291 => Loss: 46.57546989316786323343\n",
      "Iteration 31292 => Loss: 46.57530480017119600689\n",
      "Iteration 31293 => Loss: 46.57513970847021056443\n",
      "Iteration 31294 => Loss: 46.57497461806480032465\n",
      "Iteration 31295 => Loss: 46.57480952895504344724\n",
      "Iteration 31296 => Loss: 46.57464444114088308879\n",
      "Iteration 31297 => Loss: 46.57447935462231924930\n",
      "Iteration 31298 => Loss: 46.57431426939935192877\n",
      "Iteration 31299 => Loss: 46.57414918547195981091\n",
      "Iteration 31300 => Loss: 46.57398410284015000116\n",
      "Iteration 31301 => Loss: 46.57381902150390828865\n",
      "Iteration 31302 => Loss: 46.57365394146319914626\n",
      "Iteration 31303 => Loss: 46.57348886271802967940\n",
      "Iteration 31304 => Loss: 46.57332378526838567723\n",
      "Iteration 31305 => Loss: 46.57315870911426713974\n",
      "Iteration 31306 => Loss: 46.57299363425565985608\n",
      "Iteration 31307 => Loss: 46.57282856069254961540\n",
      "Iteration 31308 => Loss: 46.57266348842493641769\n",
      "Iteration 31309 => Loss: 46.57249841745278473581\n",
      "Iteration 31310 => Loss: 46.57233334777609456978\n",
      "Iteration 31311 => Loss: 46.57216827939489434129\n",
      "Iteration 31312 => Loss: 46.57200321230913431236\n",
      "Iteration 31313 => Loss: 46.57183814651878606128\n",
      "Iteration 31314 => Loss: 46.57167308202389222060\n",
      "Iteration 31315 => Loss: 46.57150801882441015778\n",
      "Iteration 31316 => Loss: 46.57134295692032566194\n",
      "Iteration 31317 => Loss: 46.57117789631163873310\n",
      "Iteration 31318 => Loss: 46.57101283699836358210\n",
      "Iteration 31319 => Loss: 46.57084777898042915467\n",
      "Iteration 31320 => Loss: 46.57068272225787097796\n",
      "Iteration 31321 => Loss: 46.57051766683067484109\n",
      "Iteration 31322 => Loss: 46.57035261269883363866\n",
      "Iteration 31323 => Loss: 46.57018755986232605437\n",
      "Iteration 31324 => Loss: 46.57002250832114498280\n",
      "Iteration 31325 => Loss: 46.56985745807525489681\n",
      "Iteration 31326 => Loss: 46.56969240912469842897\n",
      "Iteration 31327 => Loss: 46.56952736146944715756\n",
      "Iteration 31328 => Loss: 46.56936231510944423917\n",
      "Iteration 31329 => Loss: 46.56919727004472520093\n",
      "Iteration 31330 => Loss: 46.56903222627530425370\n",
      "Iteration 31331 => Loss: 46.56886718380110323778\n",
      "Iteration 31332 => Loss: 46.56870214262216478573\n",
      "Iteration 31333 => Loss: 46.56853710273845337042\n",
      "Iteration 31334 => Loss: 46.56837206414998320270\n",
      "Iteration 31335 => Loss: 46.56820702685667612286\n",
      "Iteration 31336 => Loss: 46.56804199085861739604\n",
      "Iteration 31337 => Loss: 46.56787695615575728425\n",
      "Iteration 31338 => Loss: 46.56771192274805315492\n",
      "Iteration 31339 => Loss: 46.56754689063554764061\n",
      "Iteration 31340 => Loss: 46.56738185981819810877\n",
      "Iteration 31341 => Loss: 46.56721683029600455939\n",
      "Iteration 31342 => Loss: 46.56705180206891725447\n",
      "Iteration 31343 => Loss: 46.56688677513700014288\n",
      "Iteration 31344 => Loss: 46.56672174950021059203\n",
      "Iteration 31345 => Loss: 46.56655672515852728566\n",
      "Iteration 31346 => Loss: 46.56639170211192180204\n",
      "Iteration 31347 => Loss: 46.56622668036043677375\n",
      "Iteration 31348 => Loss: 46.56606165990401535737\n",
      "Iteration 31349 => Loss: 46.56589664074268597460\n",
      "Iteration 31350 => Loss: 46.56573162287639888746\n",
      "Iteration 31351 => Loss: 46.56556660630516120136\n",
      "Iteration 31352 => Loss: 46.56540159102898712717\n",
      "Iteration 31353 => Loss: 46.56523657704784113776\n",
      "Iteration 31354 => Loss: 46.56507156436169481140\n",
      "Iteration 31355 => Loss: 46.56490655297056946438\n",
      "Iteration 31356 => Loss: 46.56474154287445799127\n",
      "Iteration 31357 => Loss: 46.56457653407331775952\n",
      "Iteration 31358 => Loss: 46.56441152656717719083\n",
      "Iteration 31359 => Loss: 46.56424652035598654720\n",
      "Iteration 31360 => Loss: 46.56408151543977425035\n",
      "Iteration 31361 => Loss: 46.56391651181849766772\n",
      "Iteration 31362 => Loss: 46.56375150949215679930\n",
      "Iteration 31363 => Loss: 46.56358650846077296137\n",
      "Iteration 31364 => Loss: 46.56342150872427509967\n",
      "Iteration 31365 => Loss: 46.56325651028270584675\n",
      "Iteration 31366 => Loss: 46.56309151313602967548\n",
      "Iteration 31367 => Loss: 46.56292651728424658586\n",
      "Iteration 31368 => Loss: 46.56276152272735657789\n",
      "Iteration 31369 => Loss: 46.56259652946528859729\n",
      "Iteration 31370 => Loss: 46.56243153749812790920\n",
      "Iteration 31371 => Loss: 46.56226654682577503763\n",
      "Iteration 31372 => Loss: 46.56210155744830814228\n",
      "Iteration 31373 => Loss: 46.56193656936562774717\n",
      "Iteration 31374 => Loss: 46.56177158257777648487\n",
      "Iteration 31375 => Loss: 46.56160659708474724994\n",
      "Iteration 31376 => Loss: 46.56144161288651162067\n",
      "Iteration 31377 => Loss: 46.56127662998302696451\n",
      "Iteration 31378 => Loss: 46.56111164837437854658\n",
      "Iteration 31379 => Loss: 46.56094666806045978547\n",
      "Iteration 31380 => Loss: 46.56078168904129199746\n",
      "Iteration 31381 => Loss: 46.56061671131689649883\n",
      "Iteration 31382 => Loss: 46.56045173488723065702\n",
      "Iteration 31383 => Loss: 46.56028675975227315575\n",
      "Iteration 31384 => Loss: 46.56012178591204531131\n",
      "Iteration 31385 => Loss: 46.55995681336651870197\n",
      "Iteration 31386 => Loss: 46.55979184211570753860\n",
      "Iteration 31387 => Loss: 46.55962687215954076692\n",
      "Iteration 31388 => Loss: 46.55946190349808944120\n",
      "Iteration 31389 => Loss: 46.55929693613130382346\n",
      "Iteration 31390 => Loss: 46.55913197005914128113\n",
      "Iteration 31391 => Loss: 46.55896700528165865762\n",
      "Iteration 31392 => Loss: 46.55880204179878489867\n",
      "Iteration 31393 => Loss: 46.55863707961052710971\n",
      "Iteration 31394 => Loss: 46.55847211871690660701\n",
      "Iteration 31395 => Loss: 46.55830715911788786343\n",
      "Iteration 31396 => Loss: 46.55814220081346377356\n",
      "Iteration 31397 => Loss: 46.55797724380361302110\n",
      "Iteration 31398 => Loss: 46.55781228808835692234\n",
      "Iteration 31399 => Loss: 46.55764733366764573930\n",
      "Iteration 31400 => Loss: 46.55748238054149368281\n",
      "Iteration 31401 => Loss: 46.55731742870988654204\n",
      "Iteration 31402 => Loss: 46.55715247817281721154\n",
      "Iteration 31403 => Loss: 46.55698752893025726962\n",
      "Iteration 31404 => Loss: 46.55682258098222092713\n",
      "Iteration 31405 => Loss: 46.55665763432867265692\n",
      "Iteration 31406 => Loss: 46.55649268896964088071\n",
      "Iteration 31407 => Loss: 46.55632774490506875509\n",
      "Iteration 31408 => Loss: 46.55616280213497759632\n",
      "Iteration 31409 => Loss: 46.55599786065937450985\n",
      "Iteration 31410 => Loss: 46.55583292047818844139\n",
      "Iteration 31411 => Loss: 46.55566798159145491809\n",
      "Iteration 31412 => Loss: 46.55550304399913841280\n",
      "Iteration 31413 => Loss: 46.55533810770127445267\n",
      "Iteration 31414 => Loss: 46.55517317269779908884\n",
      "Iteration 31415 => Loss: 46.55500823898874074303\n",
      "Iteration 31416 => Loss: 46.55484330657405678267\n",
      "Iteration 31417 => Loss: 46.55467837545376852404\n",
      "Iteration 31418 => Loss: 46.55451344562785465087\n",
      "Iteration 31419 => Loss: 46.55434851709628674143\n",
      "Iteration 31420 => Loss: 46.55418358985907900660\n",
      "Iteration 31421 => Loss: 46.55401866391620302466\n",
      "Iteration 31422 => Loss: 46.55385373926763747932\n",
      "Iteration 31423 => Loss: 46.55368881591341079229\n",
      "Iteration 31424 => Loss: 46.55352389385352296358\n",
      "Iteration 31425 => Loss: 46.55335897308788162263\n",
      "Iteration 31426 => Loss: 46.55319405361658624543\n",
      "Iteration 31427 => Loss: 46.55302913543953025055\n",
      "Iteration 31428 => Loss: 46.55286421855675627057\n",
      "Iteration 31429 => Loss: 46.55269930296825009464\n",
      "Iteration 31430 => Loss: 46.55253438867396198475\n",
      "Iteration 31431 => Loss: 46.55236947567393457348\n",
      "Iteration 31432 => Loss: 46.55220456396814654454\n",
      "Iteration 31433 => Loss: 46.55203965355654815994\n",
      "Iteration 31434 => Loss: 46.55187474443917494682\n",
      "Iteration 31435 => Loss: 46.55170983661601979975\n",
      "Iteration 31436 => Loss: 46.55154493008700455903\n",
      "Iteration 31437 => Loss: 46.55138002485220027893\n",
      "Iteration 31438 => Loss: 46.55121512091156432689\n",
      "Iteration 31439 => Loss: 46.55105021826508959748\n",
      "Iteration 31440 => Loss: 46.55088531691274056357\n",
      "Iteration 31441 => Loss: 46.55072041685453854143\n",
      "Iteration 31442 => Loss: 46.55055551809047642564\n",
      "Iteration 31443 => Loss: 46.55039062062051158364\n",
      "Iteration 31444 => Loss: 46.55022572444466533170\n",
      "Iteration 31445 => Loss: 46.55006082956291635355\n",
      "Iteration 31446 => Loss: 46.54989593597525043833\n",
      "Iteration 31447 => Loss: 46.54973104368163916433\n",
      "Iteration 31448 => Loss: 46.54956615268212516412\n",
      "Iteration 31449 => Loss: 46.54940126297665869970\n",
      "Iteration 31450 => Loss: 46.54923637456522556022\n",
      "Iteration 31451 => Loss: 46.54907148744783995653\n",
      "Iteration 31452 => Loss: 46.54890660162447346693\n",
      "Iteration 31453 => Loss: 46.54874171709512609141\n",
      "Iteration 31454 => Loss: 46.54857683385979782997\n",
      "Iteration 31455 => Loss: 46.54841195191844605006\n",
      "Iteration 31456 => Loss: 46.54824707127107075166\n",
      "Iteration 31457 => Loss: 46.54808219191768614564\n",
      "Iteration 31458 => Loss: 46.54791731385827091572\n",
      "Iteration 31459 => Loss: 46.54775243709278953474\n",
      "Iteration 31460 => Loss: 46.54758756162126331901\n",
      "Iteration 31461 => Loss: 46.54742268744368516309\n",
      "Iteration 31462 => Loss: 46.54725781456001243441\n",
      "Iteration 31463 => Loss: 46.54709294297026644927\n",
      "Iteration 31464 => Loss: 46.54692807267440457508\n",
      "Iteration 31465 => Loss: 46.54676320367244102272\n",
      "Iteration 31466 => Loss: 46.54659833596438289760\n",
      "Iteration 31467 => Loss: 46.54643346955018756717\n",
      "Iteration 31468 => Loss: 46.54626860442982660970\n",
      "Iteration 31469 => Loss: 46.54610374060335686863\n",
      "Iteration 31470 => Loss: 46.54593887807072860596\n",
      "Iteration 31471 => Loss: 46.54577401683190629456\n",
      "Iteration 31472 => Loss: 46.54560915688691835612\n",
      "Iteration 31473 => Loss: 46.54544429823573636895\n",
      "Iteration 31474 => Loss: 46.54527944087837454390\n",
      "Iteration 31475 => Loss: 46.54511458481478314297\n",
      "Iteration 31476 => Loss: 46.54494973004501190417\n",
      "Iteration 31477 => Loss: 46.54478487656896135150\n",
      "Iteration 31478 => Loss: 46.54462002438671675009\n",
      "Iteration 31479 => Loss: 46.54445517349817151853\n",
      "Iteration 31480 => Loss: 46.54429032390340381653\n",
      "Iteration 31481 => Loss: 46.54412547560237101152\n",
      "Iteration 31482 => Loss: 46.54396062859505178722\n",
      "Iteration 31483 => Loss: 46.54379578288143193276\n",
      "Iteration 31484 => Loss: 46.54363093846153276445\n",
      "Iteration 31485 => Loss: 46.54346609533529033342\n",
      "Iteration 31486 => Loss: 46.54330125350276858853\n",
      "Iteration 31487 => Loss: 46.54313641296390358093\n",
      "Iteration 31488 => Loss: 46.54297157371866688891\n",
      "Iteration 31489 => Loss: 46.54280673576711535588\n",
      "Iteration 31490 => Loss: 46.54264189910918503301\n",
      "Iteration 31491 => Loss: 46.54247706374489723657\n",
      "Iteration 31492 => Loss: 46.54231222967424486114\n",
      "Iteration 31493 => Loss: 46.54214739689716395787\n",
      "Iteration 31494 => Loss: 46.54198256541369715933\n",
      "Iteration 31495 => Loss: 46.54181773522382314923\n",
      "Iteration 31496 => Loss: 46.54165290632752061128\n",
      "Iteration 31497 => Loss: 46.54148807872480375636\n",
      "Iteration 31498 => Loss: 46.54132325241562995188\n",
      "Iteration 31499 => Loss: 46.54115842740000630329\n",
      "Iteration 31500 => Loss: 46.54099360367792570514\n",
      "Iteration 31501 => Loss: 46.54082878124934552488\n",
      "Iteration 31502 => Loss: 46.54066396011432971136\n",
      "Iteration 31503 => Loss: 46.54049914027280010487\n",
      "Iteration 31504 => Loss: 46.54033432172474959998\n",
      "Iteration 31505 => Loss: 46.54016950447022082926\n",
      "Iteration 31506 => Loss: 46.54000468850914984387\n",
      "Iteration 31507 => Loss: 46.53983987384153664379\n",
      "Iteration 31508 => Loss: 46.53967506046740254533\n",
      "Iteration 31509 => Loss: 46.53951024838670491590\n",
      "Iteration 31510 => Loss: 46.53934543759942954466\n",
      "Iteration 31511 => Loss: 46.53918062810560485332\n",
      "Iteration 31512 => Loss: 46.53901581990518110388\n",
      "Iteration 31513 => Loss: 46.53885101299815829634\n",
      "Iteration 31514 => Loss: 46.53868620738452932528\n",
      "Iteration 31515 => Loss: 46.53852140306432261241\n",
      "Iteration 31516 => Loss: 46.53835660003745999802\n",
      "Iteration 31517 => Loss: 46.53819179830396279840\n",
      "Iteration 31518 => Loss: 46.53802699786381680269\n",
      "Iteration 31519 => Loss: 46.53786219871704332718\n",
      "Iteration 31520 => Loss: 46.53769740086357131759\n",
      "Iteration 31521 => Loss: 46.53753260430345051191\n",
      "Iteration 31522 => Loss: 46.53736780903663827758\n",
      "Iteration 31523 => Loss: 46.53720301506311329831\n",
      "Iteration 31524 => Loss: 46.53703822238291110125\n",
      "Iteration 31525 => Loss: 46.53687343099596773754\n",
      "Iteration 31526 => Loss: 46.53670864090232583976\n",
      "Iteration 31527 => Loss: 46.53654385210192856448\n",
      "Iteration 31528 => Loss: 46.53637906459479722798\n",
      "Iteration 31529 => Loss: 46.53621427838090340856\n",
      "Iteration 31530 => Loss: 46.53604949346022578993\n",
      "Iteration 31531 => Loss: 46.53588470983278568838\n",
      "Iteration 31532 => Loss: 46.53571992749854757676\n",
      "Iteration 31533 => Loss: 46.53555514645752566594\n",
      "Iteration 31534 => Loss: 46.53539036670971285048\n",
      "Iteration 31535 => Loss: 46.53522558825506649782\n",
      "Iteration 31536 => Loss: 46.53506081109358660797\n",
      "Iteration 31537 => Loss: 46.53489603522527318091\n",
      "Iteration 31538 => Loss: 46.53473126065011200581\n",
      "Iteration 31539 => Loss: 46.53456648736808176636\n",
      "Iteration 31540 => Loss: 46.53440171537921088429\n",
      "Iteration 31541 => Loss: 46.53423694468343541075\n",
      "Iteration 31542 => Loss: 46.53407217528079797830\n",
      "Iteration 31543 => Loss: 46.53390740717123463810\n",
      "Iteration 31544 => Loss: 46.53374264035478802271\n",
      "Iteration 31545 => Loss: 46.53357787483140839413\n",
      "Iteration 31546 => Loss: 46.53341311060108864694\n",
      "Iteration 31547 => Loss: 46.53324834766384299201\n",
      "Iteration 31548 => Loss: 46.53308358601967142931\n",
      "Iteration 31549 => Loss: 46.53291882566849579916\n",
      "Iteration 31550 => Loss: 46.53275406661037294498\n",
      "Iteration 31551 => Loss: 46.53258930884526733962\n",
      "Iteration 31552 => Loss: 46.53242455237316477223\n",
      "Iteration 31553 => Loss: 46.53225979719407234825\n",
      "Iteration 31554 => Loss: 46.53209504330798296223\n",
      "Iteration 31555 => Loss: 46.53193029071484687620\n",
      "Iteration 31556 => Loss: 46.53176553941469961728\n",
      "Iteration 31557 => Loss: 46.53160078940749855292\n",
      "Iteration 31558 => Loss: 46.53143604069325789396\n",
      "Iteration 31559 => Loss: 46.53127129327195632413\n",
      "Iteration 31560 => Loss: 46.53110654714356542172\n",
      "Iteration 31561 => Loss: 46.53094180230810650301\n",
      "Iteration 31562 => Loss: 46.53077705876556535713\n",
      "Iteration 31563 => Loss: 46.53061231651591356240\n",
      "Iteration 31564 => Loss: 46.53044757555916532965\n",
      "Iteration 31565 => Loss: 46.53028283589527092090\n",
      "Iteration 31566 => Loss: 46.53011809752425165243\n",
      "Iteration 31567 => Loss: 46.52995336044609331339\n",
      "Iteration 31568 => Loss: 46.52978862466079590376\n",
      "Iteration 31569 => Loss: 46.52962389016832389643\n",
      "Iteration 31570 => Loss: 46.52945915696868439682\n",
      "Iteration 31571 => Loss: 46.52929442506184898320\n",
      "Iteration 31572 => Loss: 46.52912969444782476103\n",
      "Iteration 31573 => Loss: 46.52896496512661173028\n",
      "Iteration 31574 => Loss: 46.52880023709818146926\n",
      "Iteration 31575 => Loss: 46.52863551036252687254\n",
      "Iteration 31576 => Loss: 46.52847078491962662383\n",
      "Iteration 31577 => Loss: 46.52830606076950203942\n",
      "Iteration 31578 => Loss: 46.52814133791209627589\n",
      "Iteration 31579 => Loss: 46.52797661634744486037\n",
      "Iteration 31580 => Loss: 46.52781189607554068743\n",
      "Iteration 31581 => Loss: 46.52764717709631980824\n",
      "Iteration 31582 => Loss: 46.52748245940980353907\n",
      "Iteration 31583 => Loss: 46.52731774301600609078\n",
      "Iteration 31584 => Loss: 46.52715302791487772538\n",
      "Iteration 31585 => Loss: 46.52698831410643265372\n",
      "Iteration 31586 => Loss: 46.52682360159065666494\n",
      "Iteration 31587 => Loss: 46.52665889036750712648\n",
      "Iteration 31588 => Loss: 46.52649418043703377634\n",
      "Iteration 31589 => Loss: 46.52632947179920108738\n",
      "Iteration 31590 => Loss: 46.52616476445397353245\n",
      "Iteration 31591 => Loss: 46.52600005840137242785\n",
      "Iteration 31592 => Loss: 46.52583535364137645729\n",
      "Iteration 31593 => Loss: 46.52567065017395719906\n",
      "Iteration 31594 => Loss: 46.52550594799913596944\n",
      "Iteration 31595 => Loss: 46.52534124711689145215\n",
      "Iteration 31596 => Loss: 46.52517654752718812006\n",
      "Iteration 31597 => Loss: 46.52501184923005439487\n",
      "Iteration 31598 => Loss: 46.52484715222547606572\n",
      "Iteration 31599 => Loss: 46.52468245651341760549\n",
      "Iteration 31600 => Loss: 46.52451776209389322503\n",
      "Iteration 31601 => Loss: 46.52435306896686029177\n",
      "Iteration 31602 => Loss: 46.52418837713234012199\n",
      "Iteration 31603 => Loss: 46.52402368659032561027\n",
      "Iteration 31604 => Loss: 46.52385899734078122947\n",
      "Iteration 31605 => Loss: 46.52369430938371408502\n",
      "Iteration 31606 => Loss: 46.52352962271910286063\n",
      "Iteration 31607 => Loss: 46.52336493734694045088\n",
      "Iteration 31608 => Loss: 46.52320025326724106662\n",
      "Iteration 31609 => Loss: 46.52303557047996207530\n",
      "Iteration 31610 => Loss: 46.52287088898508926604\n",
      "Iteration 31611 => Loss: 46.52270620878264395515\n",
      "Iteration 31612 => Loss: 46.52254152987261193175\n",
      "Iteration 31613 => Loss: 46.52237685225495056329\n",
      "Iteration 31614 => Loss: 46.52221217592966695520\n",
      "Iteration 31615 => Loss: 46.52204750089678242375\n",
      "Iteration 31616 => Loss: 46.52188282715623302010\n",
      "Iteration 31617 => Loss: 46.52171815470804006054\n",
      "Iteration 31618 => Loss: 46.52155348355221065049\n",
      "Iteration 31619 => Loss: 46.52138881368868794652\n",
      "Iteration 31620 => Loss: 46.52122414511750037036\n",
      "Iteration 31621 => Loss: 46.52105947783859818401\n",
      "Iteration 31622 => Loss: 46.52089481185201691460\n",
      "Iteration 31623 => Loss: 46.52073014715770682415\n",
      "Iteration 31624 => Loss: 46.52056548375569633436\n",
      "Iteration 31625 => Loss: 46.52040082164594991809\n",
      "Iteration 31626 => Loss: 46.52023616082846046993\n",
      "Iteration 31627 => Loss: 46.52007150130321377901\n",
      "Iteration 31628 => Loss: 46.51990684307023116162\n",
      "Iteration 31629 => Loss: 46.51974218612945577433\n",
      "Iteration 31630 => Loss: 46.51957753048089472259\n",
      "Iteration 31631 => Loss: 46.51941287612456221723\n",
      "Iteration 31632 => Loss: 46.51924822306040852027\n",
      "Iteration 31633 => Loss: 46.51908357128845494799\n",
      "Iteration 31634 => Loss: 46.51891892080868018411\n",
      "Iteration 31635 => Loss: 46.51875427162107001777\n",
      "Iteration 31636 => Loss: 46.51858962372561734355\n",
      "Iteration 31637 => Loss: 46.51842497712232216145\n",
      "Iteration 31638 => Loss: 46.51826033181114894433\n",
      "Iteration 31639 => Loss: 46.51809568779211900846\n",
      "Iteration 31640 => Loss: 46.51793104506520393215\n",
      "Iteration 31641 => Loss: 46.51776640363038239911\n",
      "Iteration 31642 => Loss: 46.51760176348767572563\n",
      "Iteration 31643 => Loss: 46.51743712463704838456\n",
      "Iteration 31644 => Loss: 46.51727248707850037590\n",
      "Iteration 31645 => Loss: 46.51710785081201748881\n",
      "Iteration 31646 => Loss: 46.51694321583756419614\n",
      "Iteration 31647 => Loss: 46.51677858215521865759\n",
      "Iteration 31648 => Loss: 46.51661394976488850261\n",
      "Iteration 31649 => Loss: 46.51644931866654530950\n",
      "Iteration 31650 => Loss: 46.51628468886025302709\n",
      "Iteration 31651 => Loss: 46.51612006034595481196\n",
      "Iteration 31652 => Loss: 46.51595543312365066413\n",
      "Iteration 31653 => Loss: 46.51579080719333347815\n",
      "Iteration 31654 => Loss: 46.51562618255499614861\n",
      "Iteration 31655 => Loss: 46.51546155920863157007\n",
      "Iteration 31656 => Loss: 46.51529693715421842626\n",
      "Iteration 31657 => Loss: 46.51513231639174961174\n",
      "Iteration 31658 => Loss: 46.51496769692120381023\n",
      "Iteration 31659 => Loss: 46.51480307874258812717\n",
      "Iteration 31660 => Loss: 46.51463846185590966797\n",
      "Iteration 31661 => Loss: 46.51447384626111158923\n",
      "Iteration 31662 => Loss: 46.51430923195821520721\n",
      "Iteration 31663 => Loss: 46.51414461894719210022\n",
      "Iteration 31664 => Loss: 46.51398000722805647911\n",
      "Iteration 31665 => Loss: 46.51381539680077992216\n",
      "Iteration 31666 => Loss: 46.51365078766536953481\n",
      "Iteration 31667 => Loss: 46.51348617982178978991\n",
      "Iteration 31668 => Loss: 46.51332157327004779290\n",
      "Iteration 31669 => Loss: 46.51315696801012222750\n",
      "Iteration 31670 => Loss: 46.51299236404201309369\n",
      "Iteration 31671 => Loss: 46.51282776136571328607\n",
      "Iteration 31672 => Loss: 46.51266315998120859376\n",
      "Iteration 31673 => Loss: 46.51249855988847770050\n",
      "Iteration 31674 => Loss: 46.51233396108752771170\n",
      "Iteration 31675 => Loss: 46.51216936357832310023\n",
      "Iteration 31676 => Loss: 46.51200476736089228780\n",
      "Iteration 31677 => Loss: 46.51184017243517843099\n",
      "Iteration 31678 => Loss: 46.51167557880123126779\n",
      "Iteration 31679 => Loss: 46.51151098645898684936\n",
      "Iteration 31680 => Loss: 46.51134639540845938654\n",
      "Iteration 31681 => Loss: 46.51118180564962756307\n",
      "Iteration 31682 => Loss: 46.51101721718249137894\n",
      "Iteration 31683 => Loss: 46.51085263000704372871\n",
      "Iteration 31684 => Loss: 46.51068804412325619069\n",
      "Iteration 31685 => Loss: 46.51052345953113587029\n",
      "Iteration 31686 => Loss: 46.51035887623065434582\n",
      "Iteration 31687 => Loss: 46.51019429422184003897\n",
      "Iteration 31688 => Loss: 46.51002971350464321176\n",
      "Iteration 31689 => Loss: 46.50986513407906386419\n",
      "Iteration 31690 => Loss: 46.50970055594508067998\n",
      "Iteration 31691 => Loss: 46.50953597910272918625\n",
      "Iteration 31692 => Loss: 46.50937140355195253960\n",
      "Iteration 31693 => Loss: 46.50920682929274363460\n",
      "Iteration 31694 => Loss: 46.50904225632513089295\n",
      "Iteration 31695 => Loss: 46.50887768464907168209\n",
      "Iteration 31696 => Loss: 46.50871311426453758031\n",
      "Iteration 31697 => Loss: 46.50854854517156411475\n",
      "Iteration 31698 => Loss: 46.50838397737013707456\n",
      "Iteration 31699 => Loss: 46.50821941086020672174\n",
      "Iteration 31700 => Loss: 46.50805484564178726714\n",
      "Iteration 31701 => Loss: 46.50789028171487160535\n",
      "Iteration 31702 => Loss: 46.50772571907943131464\n",
      "Iteration 31703 => Loss: 46.50756115773546639502\n",
      "Iteration 31704 => Loss: 46.50739659768299105735\n",
      "Iteration 31705 => Loss: 46.50723203892197687992\n",
      "Iteration 31706 => Loss: 46.50706748145238123016\n",
      "Iteration 31707 => Loss: 46.50690292527425384606\n",
      "Iteration 31708 => Loss: 46.50673837038755209505\n",
      "Iteration 31709 => Loss: 46.50657381679226176630\n",
      "Iteration 31710 => Loss: 46.50640926448836154350\n",
      "Iteration 31711 => Loss: 46.50624471347587984837\n",
      "Iteration 31712 => Loss: 46.50608016375478825921\n",
      "Iteration 31713 => Loss: 46.50591561532507967058\n",
      "Iteration 31714 => Loss: 46.50575106818673276621\n",
      "Iteration 31715 => Loss: 46.50558652233974044066\n",
      "Iteration 31716 => Loss: 46.50542197778408137765\n",
      "Iteration 31717 => Loss: 46.50525743451976978804\n",
      "Iteration 31718 => Loss: 46.50509289254678435555\n",
      "Iteration 31719 => Loss: 46.50492835186510376388\n",
      "Iteration 31720 => Loss: 46.50476381247475643477\n",
      "Iteration 31721 => Loss: 46.50459927437569973563\n",
      "Iteration 31722 => Loss: 46.50443473756791945561\n",
      "Iteration 31723 => Loss: 46.50427020205140138387\n",
      "Iteration 31724 => Loss: 46.50410566782619525839\n",
      "Iteration 31725 => Loss: 46.50394113489220870861\n",
      "Iteration 31726 => Loss: 46.50377660324945594539\n",
      "Iteration 31727 => Loss: 46.50361207289796539044\n",
      "Iteration 31728 => Loss: 46.50344754383768730577\n",
      "Iteration 31729 => Loss: 46.50328301606862879680\n",
      "Iteration 31730 => Loss: 46.50311848959077565269\n",
      "Iteration 31731 => Loss: 46.50295396440412787342\n",
      "Iteration 31732 => Loss: 46.50278944050865703730\n",
      "Iteration 31733 => Loss: 46.50262491790436314432\n",
      "Iteration 31734 => Loss: 46.50246039659122487819\n",
      "Iteration 31735 => Loss: 46.50229587656925644978\n",
      "Iteration 31736 => Loss: 46.50213135783841522652\n",
      "Iteration 31737 => Loss: 46.50196684039870831384\n",
      "Iteration 31738 => Loss: 46.50180232425014281716\n",
      "Iteration 31739 => Loss: 46.50163780939267610393\n",
      "Iteration 31740 => Loss: 46.50147329582632949041\n",
      "Iteration 31741 => Loss: 46.50130878355107455491\n",
      "Iteration 31742 => Loss: 46.50114427256688998114\n",
      "Iteration 31743 => Loss: 46.50097976287378997995\n",
      "Iteration 31744 => Loss: 46.50081525447173191878\n",
      "Iteration 31745 => Loss: 46.50065074736075132478\n",
      "Iteration 31746 => Loss: 46.50048624154079845994\n",
      "Iteration 31747 => Loss: 46.50032173701188753512\n",
      "Iteration 31748 => Loss: 46.50015723377399723404\n",
      "Iteration 31749 => Loss: 46.49999273182711334584\n",
      "Iteration 31750 => Loss: 46.49982823117125008139\n",
      "Iteration 31751 => Loss: 46.49966373180637901896\n",
      "Iteration 31752 => Loss: 46.49949923373247173686\n",
      "Iteration 31753 => Loss: 46.49933473694953534050\n",
      "Iteration 31754 => Loss: 46.49917024145757693532\n",
      "Iteration 31755 => Loss: 46.49900574725653967789\n",
      "Iteration 31756 => Loss: 46.49884125434648041164\n",
      "Iteration 31757 => Loss: 46.49867676272734229315\n",
      "Iteration 31758 => Loss: 46.49851227239912532241\n",
      "Iteration 31759 => Loss: 46.49834778336182239400\n",
      "Iteration 31760 => Loss: 46.49818329561541219164\n",
      "Iteration 31761 => Loss: 46.49801880915990182075\n",
      "Iteration 31762 => Loss: 46.49785432399527707048\n",
      "Iteration 31763 => Loss: 46.49768984012150951912\n",
      "Iteration 31764 => Loss: 46.49752535753861337753\n",
      "Iteration 31765 => Loss: 46.49736087624656022399\n",
      "Iteration 31766 => Loss: 46.49719639624535005851\n",
      "Iteration 31767 => Loss: 46.49703191753496867022\n",
      "Iteration 31768 => Loss: 46.49686744011540184829\n",
      "Iteration 31769 => Loss: 46.49670296398665669813\n",
      "Iteration 31770 => Loss: 46.49653848914871900888\n",
      "Iteration 31771 => Loss: 46.49637401560154614799\n",
      "Iteration 31772 => Loss: 46.49620954334515943174\n",
      "Iteration 31773 => Loss: 46.49604507237955886012\n",
      "Iteration 31774 => Loss: 46.49588060270472311686\n",
      "Iteration 31775 => Loss: 46.49571613432059535853\n",
      "Iteration 31776 => Loss: 46.49555166722724663941\n",
      "Iteration 31777 => Loss: 46.49538720142460590523\n",
      "Iteration 31778 => Loss: 46.49522273691269447227\n",
      "Iteration 31779 => Loss: 46.49505827369148391881\n",
      "Iteration 31780 => Loss: 46.49489381176098135029\n",
      "Iteration 31781 => Loss: 46.49472935112115834499\n",
      "Iteration 31782 => Loss: 46.49456489177201490293\n",
      "Iteration 31783 => Loss: 46.49440043371355102408\n",
      "Iteration 31784 => Loss: 46.49423597694573118133\n",
      "Iteration 31785 => Loss: 46.49407152146856248009\n",
      "Iteration 31786 => Loss: 46.49390706728204492038\n",
      "Iteration 31787 => Loss: 46.49374261438615008046\n",
      "Iteration 31788 => Loss: 46.49357816278087796036\n",
      "Iteration 31789 => Loss: 46.49341371246619303292\n",
      "Iteration 31790 => Loss: 46.49324926344210950901\n",
      "Iteration 31791 => Loss: 46.49308481570862028320\n",
      "Iteration 31792 => Loss: 46.49292036926570403921\n",
      "Iteration 31793 => Loss: 46.49275592411336077703\n",
      "Iteration 31794 => Loss: 46.49259148025156918038\n",
      "Iteration 31795 => Loss: 46.49242703768032214384\n",
      "Iteration 31796 => Loss: 46.49226259639961966741\n",
      "Iteration 31797 => Loss: 46.49209815640944043480\n",
      "Iteration 31798 => Loss: 46.49193371770978444601\n",
      "Iteration 31799 => Loss: 46.49176928030062327935\n",
      "Iteration 31800 => Loss: 46.49160484418197825107\n",
      "Iteration 31801 => Loss: 46.49144040935379251778\n",
      "Iteration 31802 => Loss: 46.49127597581610871202\n",
      "Iteration 31803 => Loss: 46.49111154356886288497\n",
      "Iteration 31804 => Loss: 46.49094711261208345832\n",
      "Iteration 31805 => Loss: 46.49078268294574911579\n",
      "Iteration 31806 => Loss: 46.49061825456985275196\n",
      "Iteration 31807 => Loss: 46.49045382748438015597\n",
      "Iteration 31808 => Loss: 46.49028940168933843324\n",
      "Iteration 31809 => Loss: 46.49012497718468495123\n",
      "Iteration 31810 => Loss: 46.48996055397043392077\n",
      "Iteration 31811 => Loss: 46.48979613204654981473\n",
      "Iteration 31812 => Loss: 46.48963171141306105483\n",
      "Iteration 31813 => Loss: 46.48946729206993211392\n",
      "Iteration 31814 => Loss: 46.48930287401714167572\n",
      "Iteration 31815 => Loss: 46.48913845725472526738\n",
      "Iteration 31816 => Loss: 46.48897404178261183461\n",
      "Iteration 31817 => Loss: 46.48880962760084400998\n",
      "Iteration 31818 => Loss: 46.48864521470940047720\n",
      "Iteration 31819 => Loss: 46.48848080310821018202\n",
      "Iteration 31820 => Loss: 46.48831639279737260040\n",
      "Iteration 31821 => Loss: 46.48815198377678115094\n",
      "Iteration 31822 => Loss: 46.48798757604647846620\n",
      "Iteration 31823 => Loss: 46.48782316960642901904\n",
      "Iteration 31824 => Loss: 46.48765876445662570404\n",
      "Iteration 31825 => Loss: 46.48749436059708983748\n",
      "Iteration 31826 => Loss: 46.48732995802777168137\n",
      "Iteration 31827 => Loss: 46.48716555674867834114\n",
      "Iteration 31828 => Loss: 46.48700115675979560592\n",
      "Iteration 31829 => Loss: 46.48683675806111637030\n",
      "Iteration 31830 => Loss: 46.48667236065262642342\n",
      "Iteration 31831 => Loss: 46.48650796453432576527\n",
      "Iteration 31832 => Loss: 46.48634356970619307958\n",
      "Iteration 31833 => Loss: 46.48617917616822836635\n",
      "Iteration 31834 => Loss: 46.48601478392041030929\n",
      "Iteration 31835 => Loss: 46.48585039296273890841\n",
      "Iteration 31836 => Loss: 46.48568600329519995284\n",
      "Iteration 31837 => Loss: 46.48552161491777212632\n",
      "Iteration 31838 => Loss: 46.48535722783046253426\n",
      "Iteration 31839 => Loss: 46.48519284203324275495\n",
      "Iteration 31840 => Loss: 46.48502845752613410468\n",
      "Iteration 31841 => Loss: 46.48486407430908684546\n",
      "Iteration 31842 => Loss: 46.48469969238212939899\n",
      "Iteration 31843 => Loss: 46.48453531174520492186\n",
      "Iteration 31844 => Loss: 46.48437093239836315206\n",
      "Iteration 31845 => Loss: 46.48420655434154724617\n",
      "Iteration 31846 => Loss: 46.48404217757475720418\n",
      "Iteration 31847 => Loss: 46.48387780209799302611\n",
      "Iteration 31848 => Loss: 46.48371342791123339566\n",
      "Iteration 31849 => Loss: 46.48354905501447831284\n",
      "Iteration 31850 => Loss: 46.48338468340773488308\n",
      "Iteration 31851 => Loss: 46.48322031309093205209\n",
      "Iteration 31852 => Loss: 46.48305594406411245245\n",
      "Iteration 31853 => Loss: 46.48289157632724055702\n",
      "Iteration 31854 => Loss: 46.48272720988035899836\n",
      "Iteration 31855 => Loss: 46.48256284472339672220\n",
      "Iteration 31856 => Loss: 46.48239848085633241226\n",
      "Iteration 31857 => Loss: 46.48223411827922291195\n",
      "Iteration 31858 => Loss: 46.48206975699201137786\n",
      "Iteration 31859 => Loss: 46.48190539699467649370\n",
      "Iteration 31860 => Loss: 46.48174103828727510290\n",
      "Iteration 31861 => Loss: 46.48157668086971483490\n",
      "Iteration 31862 => Loss: 46.48141232474205253311\n",
      "Iteration 31863 => Loss: 46.48124796990423845955\n",
      "Iteration 31864 => Loss: 46.48108361635628682507\n",
      "Iteration 31865 => Loss: 46.48091926409814789167\n",
      "Iteration 31866 => Loss: 46.48075491312983587022\n",
      "Iteration 31867 => Loss: 46.48059056345134365529\n",
      "Iteration 31868 => Loss: 46.48042621506266414144\n",
      "Iteration 31869 => Loss: 46.48026186796378311783\n",
      "Iteration 31870 => Loss: 46.48009752215468637360\n",
      "Iteration 31871 => Loss: 46.47993317763536680332\n",
      "Iteration 31872 => Loss: 46.47976883440581730156\n",
      "Iteration 31873 => Loss: 46.47960449246603786833\n",
      "Iteration 31874 => Loss: 46.47944015181599297648\n",
      "Iteration 31875 => Loss: 46.47927581245567552060\n",
      "Iteration 31876 => Loss: 46.47911147438509260610\n",
      "Iteration 31877 => Loss: 46.47894713760422291671\n",
      "Iteration 31878 => Loss: 46.47878280211305934699\n",
      "Iteration 31879 => Loss: 46.47861846791158768610\n",
      "Iteration 31880 => Loss: 46.47845413499981503946\n",
      "Iteration 31881 => Loss: 46.47828980337772009079\n",
      "Iteration 31882 => Loss: 46.47812547304528862924\n",
      "Iteration 31883 => Loss: 46.47796114400251354937\n",
      "Iteration 31884 => Loss: 46.47779681624938064033\n",
      "Iteration 31885 => Loss: 46.47763248978588279670\n",
      "Iteration 31886 => Loss: 46.47746816461199159676\n",
      "Iteration 31887 => Loss: 46.47730384072773546222\n",
      "Iteration 31888 => Loss: 46.47713951813310728767\n",
      "Iteration 31889 => Loss: 46.47697519682801470253\n",
      "Iteration 31890 => Loss: 46.47681087681255718280\n",
      "Iteration 31891 => Loss: 46.47664655808664946335\n",
      "Iteration 31892 => Loss: 46.47648224065032707131\n",
      "Iteration 31893 => Loss: 46.47631792450354026869\n",
      "Iteration 31894 => Loss: 46.47615360964631747720\n",
      "Iteration 31895 => Loss: 46.47598929607860895885\n",
      "Iteration 31896 => Loss: 46.47582498380042892450\n",
      "Iteration 31897 => Loss: 46.47566067281177026871\n",
      "Iteration 31898 => Loss: 46.47549636311261878063\n",
      "Iteration 31899 => Loss: 46.47533205470296024941\n",
      "Iteration 31900 => Loss: 46.47516774758278046420\n",
      "Iteration 31901 => Loss: 46.47500344175206521413\n",
      "Iteration 31902 => Loss: 46.47483913721082160464\n",
      "Iteration 31903 => Loss: 46.47467483395904253030\n",
      "Iteration 31904 => Loss: 46.47451053199669246396\n",
      "Iteration 31905 => Loss: 46.47434623132377851107\n",
      "Iteration 31906 => Loss: 46.47418193194029356619\n",
      "Iteration 31907 => Loss: 46.47401763384621631303\n",
      "Iteration 31908 => Loss: 46.47385333704153964618\n",
      "Iteration 31909 => Loss: 46.47368904152626356563\n",
      "Iteration 31910 => Loss: 46.47352474730035254424\n",
      "Iteration 31911 => Loss: 46.47336045436382789831\n",
      "Iteration 31912 => Loss: 46.47319616271666831153\n",
      "Iteration 31913 => Loss: 46.47303187235885957307\n",
      "Iteration 31914 => Loss: 46.47286758329038747206\n",
      "Iteration 31915 => Loss: 46.47270329551125200851\n",
      "Iteration 31916 => Loss: 46.47253900902142476070\n",
      "Iteration 31917 => Loss: 46.47237472382092704493\n",
      "Iteration 31918 => Loss: 46.47221043990972333404\n",
      "Iteration 31919 => Loss: 46.47204615728782073347\n",
      "Iteration 31920 => Loss: 46.47188187595519082151\n",
      "Iteration 31921 => Loss: 46.47171759591181938731\n",
      "Iteration 31922 => Loss: 46.47155331715772774714\n",
      "Iteration 31923 => Loss: 46.47138903969287326845\n",
      "Iteration 31924 => Loss: 46.47122476351727016208\n",
      "Iteration 31925 => Loss: 46.47106048863089711176\n",
      "Iteration 31926 => Loss: 46.47089621503374701206\n",
      "Iteration 31927 => Loss: 46.47073194272580565212\n",
      "Iteration 31928 => Loss: 46.47056767170706592651\n",
      "Iteration 31929 => Loss: 46.47040340197750651896\n",
      "Iteration 31930 => Loss: 46.47023913353712742946\n",
      "Iteration 31931 => Loss: 46.47007486638592865802\n",
      "Iteration 31932 => Loss: 46.46991060052386046664\n",
      "Iteration 31933 => Loss: 46.46974633595100812045\n",
      "Iteration 31934 => Loss: 46.46958207266723661633\n",
      "Iteration 31935 => Loss: 46.46941781067261700855\n",
      "Iteration 31936 => Loss: 46.46925354996709955913\n",
      "Iteration 31937 => Loss: 46.46908929055069847891\n",
      "Iteration 31938 => Loss: 46.46892503242342087333\n",
      "Iteration 31939 => Loss: 46.46876077558521700439\n",
      "Iteration 31940 => Loss: 46.46859652003608687210\n",
      "Iteration 31941 => Loss: 46.46843226577602337102\n",
      "Iteration 31942 => Loss: 46.46826801280504071201\n",
      "Iteration 31943 => Loss: 46.46810376112307494623\n",
      "Iteration 31944 => Loss: 46.46793951073016160080\n",
      "Iteration 31945 => Loss: 46.46777526162628646489\n",
      "Iteration 31946 => Loss: 46.46761101381141401134\n",
      "Iteration 31947 => Loss: 46.46744676728555134559\n",
      "Iteration 31948 => Loss: 46.46728252204869846764\n",
      "Iteration 31949 => Loss: 46.46711827810081985035\n",
      "Iteration 31950 => Loss: 46.46695403544192259915\n",
      "Iteration 31951 => Loss: 46.46678979407201381946\n",
      "Iteration 31952 => Loss: 46.46662555399102956244\n",
      "Iteration 31953 => Loss: 46.46646131519901956608\n",
      "Iteration 31954 => Loss: 46.46629707769593409239\n",
      "Iteration 31955 => Loss: 46.46613284148178024680\n",
      "Iteration 31956 => Loss: 46.46596860655653671301\n",
      "Iteration 31957 => Loss: 46.46580437292021059648\n",
      "Iteration 31958 => Loss: 46.46564014057276637004\n",
      "Iteration 31959 => Loss: 46.46547590951421824457\n",
      "Iteration 31960 => Loss: 46.46531167974455200920\n",
      "Iteration 31961 => Loss: 46.46514745126374634765\n",
      "Iteration 31962 => Loss: 46.46498322407178704907\n",
      "Iteration 31963 => Loss: 46.46481899816869542974\n",
      "Iteration 31964 => Loss: 46.46465477355442175167\n",
      "Iteration 31965 => Loss: 46.46449055022898022571\n",
      "Iteration 31966 => Loss: 46.46432632819236374644\n",
      "Iteration 31967 => Loss: 46.46416210744456520843\n",
      "Iteration 31968 => Loss: 46.46399788798553487368\n",
      "Iteration 31969 => Loss: 46.46383366981530116391\n",
      "Iteration 31970 => Loss: 46.46366945293382144655\n",
      "Iteration 31971 => Loss: 46.46350523734113124874\n",
      "Iteration 31972 => Loss: 46.46334102303718793792\n",
      "Iteration 31973 => Loss: 46.46317681002198440865\n",
      "Iteration 31974 => Loss: 46.46301259829553487180\n",
      "Iteration 31975 => Loss: 46.46284838785779669479\n",
      "Iteration 31976 => Loss: 46.46268417870878408849\n",
      "Iteration 31977 => Loss: 46.46251997084846152575\n",
      "Iteration 31978 => Loss: 46.46235576427685032286\n",
      "Iteration 31979 => Loss: 46.46219155899390074183\n",
      "Iteration 31980 => Loss: 46.46202735499964830979\n",
      "Iteration 31981 => Loss: 46.46186315229404328875\n",
      "Iteration 31982 => Loss: 46.46169895087711410042\n",
      "Iteration 31983 => Loss: 46.46153475074880390139\n",
      "Iteration 31984 => Loss: 46.46137055190915532421\n",
      "Iteration 31985 => Loss: 46.46120635435810442004\n",
      "Iteration 31986 => Loss: 46.46104215809567250517\n",
      "Iteration 31987 => Loss: 46.46087796312185247416\n",
      "Iteration 31988 => Loss: 46.46071376943661590531\n",
      "Iteration 31989 => Loss: 46.46054957703996279861\n",
      "Iteration 31990 => Loss: 46.46038538593190025949\n",
      "Iteration 31991 => Loss: 46.46022119611237144454\n",
      "Iteration 31992 => Loss: 46.46005700758141898632\n",
      "Iteration 31993 => Loss: 46.45989282033900025226\n",
      "Iteration 31994 => Loss: 46.45972863438511524237\n",
      "Iteration 31995 => Loss: 46.45956444971977816749\n",
      "Iteration 31996 => Loss: 46.45940026634291086793\n",
      "Iteration 31997 => Loss: 46.45923608425457729254\n",
      "Iteration 31998 => Loss: 46.45907190345472770332\n",
      "Iteration 31999 => Loss: 46.45890772394334788942\n",
      "Iteration 32000 => Loss: 46.45874354572045916711\n",
      "Iteration 32001 => Loss: 46.45857936878603311470\n",
      "Iteration 32002 => Loss: 46.45841519314003420504\n",
      "Iteration 32003 => Loss: 46.45825101878249796528\n",
      "Iteration 32004 => Loss: 46.45808684571338886826\n",
      "Iteration 32005 => Loss: 46.45792267393271401943\n",
      "Iteration 32006 => Loss: 46.45775850344042368079\n",
      "Iteration 32007 => Loss: 46.45759433423654627404\n",
      "Iteration 32008 => Loss: 46.45743016632106758834\n",
      "Iteration 32009 => Loss: 46.45726599969395920198\n",
      "Iteration 32010 => Loss: 46.45710183435522822037\n",
      "Iteration 32011 => Loss: 46.45693767030485332725\n",
      "Iteration 32012 => Loss: 46.45677350754284873346\n",
      "Iteration 32013 => Loss: 46.45660934606916470102\n",
      "Iteration 32014 => Loss: 46.45644518588381544077\n",
      "Iteration 32015 => Loss: 46.45628102698678674187\n",
      "Iteration 32016 => Loss: 46.45611686937805728803\n",
      "Iteration 32017 => Loss: 46.45595271305763418468\n",
      "Iteration 32018 => Loss: 46.45578855802551032639\n",
      "Iteration 32019 => Loss: 46.45562440428166439688\n",
      "Iteration 32020 => Loss: 46.45546025182609639614\n",
      "Iteration 32021 => Loss: 46.45529610065877790248\n",
      "Iteration 32022 => Loss: 46.45513195077970181046\n",
      "Iteration 32023 => Loss: 46.45496780218888233094\n",
      "Iteration 32024 => Loss: 46.45480365488627683135\n",
      "Iteration 32025 => Loss: 46.45463950887190662797\n",
      "Iteration 32026 => Loss: 46.45447536414572198282\n",
      "Iteration 32027 => Loss: 46.45431122070776552846\n",
      "Iteration 32028 => Loss: 46.45414707855797331604\n",
      "Iteration 32029 => Loss: 46.45398293769636666184\n",
      "Iteration 32030 => Loss: 46.45381879812292424958\n",
      "Iteration 32031 => Loss: 46.45365465983766739555\n",
      "Iteration 32032 => Loss: 46.45349052284053925632\n",
      "Iteration 32033 => Loss: 46.45332638713156114818\n",
      "Iteration 32034 => Loss: 46.45316225271069754399\n",
      "Iteration 32035 => Loss: 46.45299811957794133832\n",
      "Iteration 32036 => Loss: 46.45283398773329963660\n",
      "Iteration 32037 => Loss: 46.45266985717676533341\n",
      "Iteration 32038 => Loss: 46.45250572790833132331\n",
      "Iteration 32039 => Loss: 46.45234159992796207916\n",
      "Iteration 32040 => Loss: 46.45217747323566470641\n",
      "Iteration 32041 => Loss: 46.45201334783139657247\n",
      "Iteration 32042 => Loss: 46.45184922371522162621\n",
      "Iteration 32043 => Loss: 46.45168510088704749705\n",
      "Iteration 32044 => Loss: 46.45152097934693102843\n",
      "Iteration 32045 => Loss: 46.45135685909482248235\n",
      "Iteration 32046 => Loss: 46.45119274013068633167\n",
      "Iteration 32047 => Loss: 46.45102862245458652524\n",
      "Iteration 32048 => Loss: 46.45086450606645911421\n",
      "Iteration 32049 => Loss: 46.45070039096631120401\n",
      "Iteration 32050 => Loss: 46.45053627715413568922\n",
      "Iteration 32051 => Loss: 46.45037216462991835897\n",
      "Iteration 32052 => Loss: 46.45020805339363789699\n",
      "Iteration 32053 => Loss: 46.45004394344531561956\n",
      "Iteration 32054 => Loss: 46.44987983478487336697\n",
      "Iteration 32055 => Loss: 46.44971572741237508808\n",
      "Iteration 32056 => Loss: 46.44955162132777815032\n",
      "Iteration 32057 => Loss: 46.44938751653109676454\n",
      "Iteration 32058 => Loss: 46.44922341302227408733\n",
      "Iteration 32059 => Loss: 46.44905931080133854039\n",
      "Iteration 32060 => Loss: 46.44889520986827591287\n",
      "Iteration 32061 => Loss: 46.44873111022305778306\n",
      "Iteration 32062 => Loss: 46.44856701186568415096\n",
      "Iteration 32063 => Loss: 46.44840291479615501657\n",
      "Iteration 32064 => Loss: 46.44823881901444195819\n",
      "Iteration 32065 => Loss: 46.44807472452055208123\n",
      "Iteration 32066 => Loss: 46.44791063131446406942\n",
      "Iteration 32067 => Loss: 46.44774653939617081733\n",
      "Iteration 32068 => Loss: 46.44758244876565811410\n",
      "Iteration 32069 => Loss: 46.44741835942291885431\n",
      "Iteration 32070 => Loss: 46.44725427136793172167\n",
      "Iteration 32071 => Loss: 46.44709018460074645418\n",
      "Iteration 32072 => Loss: 46.44692609912127068128\n",
      "Iteration 32073 => Loss: 46.44676201492953282468\n",
      "Iteration 32074 => Loss: 46.44659793202551867353\n",
      "Iteration 32075 => Loss: 46.44643385040922822782\n",
      "Iteration 32076 => Loss: 46.44626977008061885499\n",
      "Iteration 32077 => Loss: 46.44610569103974029304\n",
      "Iteration 32078 => Loss: 46.44594161328651438225\n",
      "Iteration 32079 => Loss: 46.44577753682096243892\n",
      "Iteration 32080 => Loss: 46.44561346164308446305\n",
      "Iteration 32081 => Loss: 46.44544938775285913835\n",
      "Iteration 32082 => Loss: 46.44528531515028646481\n",
      "Iteration 32083 => Loss: 46.44512124383533091532\n",
      "Iteration 32084 => Loss: 46.44495717380799248986\n",
      "Iteration 32085 => Loss: 46.44479310506827829386\n",
      "Iteration 32086 => Loss: 46.44462903761617411647\n",
      "Iteration 32087 => Loss: 46.44446497145163732512\n",
      "Iteration 32088 => Loss: 46.44430090657470344695\n",
      "Iteration 32089 => Loss: 46.44413684298535116568\n",
      "Iteration 32090 => Loss: 46.44397278068353784874\n",
      "Iteration 32091 => Loss: 46.44380871966930612871\n",
      "Iteration 32092 => Loss: 46.44364465994257784587\n",
      "Iteration 32093 => Loss: 46.44348060150340273822\n",
      "Iteration 32094 => Loss: 46.44331654435175238405\n",
      "Iteration 32095 => Loss: 46.44315248848761967793\n",
      "Iteration 32096 => Loss: 46.44298843391096909272\n",
      "Iteration 32097 => Loss: 46.44282438062184326100\n",
      "Iteration 32098 => Loss: 46.44266032862015691762\n",
      "Iteration 32099 => Loss: 46.44249627790595980059\n",
      "Iteration 32100 => Loss: 46.44233222847923769905\n",
      "Iteration 32101 => Loss: 46.44216818033994798043\n",
      "Iteration 32102 => Loss: 46.44200413348813327730\n",
      "Iteration 32103 => Loss: 46.44184008792370832452\n",
      "Iteration 32104 => Loss: 46.44167604364670864925\n",
      "Iteration 32105 => Loss: 46.44151200065714135690\n",
      "Iteration 32106 => Loss: 46.44134795895495670948\n",
      "Iteration 32107 => Loss: 46.44118391854017602327\n",
      "Iteration 32108 => Loss: 46.44101987941276377114\n",
      "Iteration 32109 => Loss: 46.44085584157273416395\n",
      "Iteration 32110 => Loss: 46.44069180502005167455\n",
      "Iteration 32111 => Loss: 46.44052776975473051380\n",
      "Iteration 32112 => Loss: 46.44036373577674936541\n",
      "Iteration 32113 => Loss: 46.44019970308609401854\n",
      "Iteration 32114 => Loss: 46.44003567168275026233\n",
      "Iteration 32115 => Loss: 46.43987164156671809678\n",
      "Iteration 32116 => Loss: 46.43970761273799752189\n",
      "Iteration 32117 => Loss: 46.43954358519657432680\n",
      "Iteration 32118 => Loss: 46.43937955894241298438\n",
      "Iteration 32119 => Loss: 46.43921553397552770548\n",
      "Iteration 32120 => Loss: 46.43905151029588296296\n",
      "Iteration 32121 => Loss: 46.43888748790350717854\n",
      "Iteration 32122 => Loss: 46.43872346679837903594\n",
      "Iteration 32123 => Loss: 46.43855944698046300800\n",
      "Iteration 32124 => Loss: 46.43839542844978041103\n",
      "Iteration 32125 => Loss: 46.43823141120628861245\n",
      "Iteration 32126 => Loss: 46.43806739524999471769\n",
      "Iteration 32127 => Loss: 46.43790338058092004303\n",
      "Iteration 32128 => Loss: 46.43773936719898642878\n",
      "Iteration 32129 => Loss: 46.43757535510423650749\n",
      "Iteration 32130 => Loss: 46.43741134429664896288\n",
      "Iteration 32131 => Loss: 46.43724733477620247868\n",
      "Iteration 32132 => Loss: 46.43708332654291126573\n",
      "Iteration 32133 => Loss: 46.43691931959673269148\n",
      "Iteration 32134 => Loss: 46.43675531393767386135\n",
      "Iteration 32135 => Loss: 46.43659130956572056448\n",
      "Iteration 32136 => Loss: 46.43642730648087280088\n",
      "Iteration 32137 => Loss: 46.43626330468308793797\n",
      "Iteration 32138 => Loss: 46.43609930417241571377\n",
      "Iteration 32139 => Loss: 46.43593530494877796855\n",
      "Iteration 32140 => Loss: 46.43577130701222444031\n",
      "Iteration 32141 => Loss: 46.43560731036271960193\n",
      "Iteration 32142 => Loss: 46.43544331500023503168\n",
      "Iteration 32143 => Loss: 46.43527932092477783499\n",
      "Iteration 32144 => Loss: 46.43511532813634801187\n",
      "Iteration 32145 => Loss: 46.43495133663491714060\n",
      "Iteration 32146 => Loss: 46.43478734642048522119\n",
      "Iteration 32147 => Loss: 46.43462335749303093735\n",
      "Iteration 32148 => Loss: 46.43445936985256139451\n",
      "Iteration 32149 => Loss: 46.43429538349906238182\n",
      "Iteration 32150 => Loss: 46.43413139843251968841\n",
      "Iteration 32151 => Loss: 46.43396741465292620887\n",
      "Iteration 32152 => Loss: 46.43380343216026062692\n",
      "Iteration 32153 => Loss: 46.43363945095452294254\n",
      "Iteration 32154 => Loss: 46.43347547103570605032\n",
      "Iteration 32155 => Loss: 46.43331149240378152854\n",
      "Iteration 32156 => Loss: 46.43314751505875648263\n",
      "Iteration 32157 => Loss: 46.43298353900061670174\n",
      "Iteration 32158 => Loss: 46.43281956422936218587\n",
      "Iteration 32159 => Loss: 46.43265559074497161873\n",
      "Iteration 32160 => Loss: 46.43249161854743078948\n",
      "Iteration 32161 => Loss: 46.43232764763673969810\n",
      "Iteration 32162 => Loss: 46.43216367801286281747\n",
      "Iteration 32163 => Loss: 46.43199970967582856929\n",
      "Iteration 32164 => Loss: 46.43183574262562274271\n",
      "Iteration 32165 => Loss: 46.43167177686220270516\n",
      "Iteration 32166 => Loss: 46.43150781238558266750\n",
      "Iteration 32167 => Loss: 46.43134384919576262973\n",
      "Iteration 32168 => Loss: 46.43117988729269285386\n",
      "Iteration 32169 => Loss: 46.43101592667639465617\n",
      "Iteration 32170 => Loss: 46.43085196734685382580\n",
      "Iteration 32171 => Loss: 46.43068800930405615190\n",
      "Iteration 32172 => Loss: 46.43052405254798031820\n",
      "Iteration 32173 => Loss: 46.43036009707864764096\n",
      "Iteration 32174 => Loss: 46.43019614289602969848\n",
      "Iteration 32175 => Loss: 46.43003219000009096362\n",
      "Iteration 32176 => Loss: 46.42986823839088117438\n",
      "Iteration 32177 => Loss: 46.42970428806833638191\n",
      "Iteration 32178 => Loss: 46.42954033903245658621\n",
      "Iteration 32179 => Loss: 46.42937639128325599813\n",
      "Iteration 32180 => Loss: 46.42921244482069198511\n",
      "Iteration 32181 => Loss: 46.42904849964478586344\n",
      "Iteration 32182 => Loss: 46.42888455575550921139\n",
      "Iteration 32183 => Loss: 46.42872061315286913441\n",
      "Iteration 32184 => Loss: 46.42855667183681589449\n",
      "Iteration 32185 => Loss: 46.42839273180737791336\n",
      "Iteration 32186 => Loss: 46.42822879306453387471\n",
      "Iteration 32187 => Loss: 46.42806485560826246228\n",
      "Iteration 32188 => Loss: 46.42790091943857788692\n",
      "Iteration 32189 => Loss: 46.42773698455543751606\n",
      "Iteration 32190 => Loss: 46.42757305095888398228\n",
      "Iteration 32191 => Loss: 46.42740911864883202043\n",
      "Iteration 32192 => Loss: 46.42724518762533847394\n",
      "Iteration 32193 => Loss: 46.42708125788834649939\n",
      "Iteration 32194 => Loss: 46.42691732943787741306\n",
      "Iteration 32195 => Loss: 46.42675340227390279324\n",
      "Iteration 32196 => Loss: 46.42658947639643685079\n",
      "Iteration 32197 => Loss: 46.42642555180543695315\n",
      "Iteration 32198 => Loss: 46.42626162850091731116\n",
      "Iteration 32199 => Loss: 46.42609770648284950312\n",
      "Iteration 32200 => Loss: 46.42593378575124063445\n",
      "Iteration 32201 => Loss: 46.42576986630608359974\n",
      "Iteration 32202 => Loss: 46.42560594814733576641\n",
      "Iteration 32203 => Loss: 46.42544203127503976702\n",
      "Iteration 32204 => Loss: 46.42527811568912454732\n",
      "Iteration 32205 => Loss: 46.42511420138962563442\n",
      "Iteration 32206 => Loss: 46.42495028837650750120\n",
      "Iteration 32207 => Loss: 46.42478637664977014765\n",
      "Iteration 32208 => Loss: 46.42462246620942778463\n",
      "Iteration 32209 => Loss: 46.42445855705541646330\n",
      "Iteration 32210 => Loss: 46.42429464918776460536\n",
      "Iteration 32211 => Loss: 46.42413074260646510538\n",
      "Iteration 32212 => Loss: 46.42396683731148243623\n",
      "Iteration 32213 => Loss: 46.42380293330280949249\n",
      "Iteration 32214 => Loss: 46.42363903058046759043\n",
      "Iteration 32215 => Loss: 46.42347512914442830834\n",
      "Iteration 32216 => Loss: 46.42331122899465611908\n",
      "Iteration 32217 => Loss: 46.42314733013118654981\n",
      "Iteration 32218 => Loss: 46.42298343255396275708\n",
      "Iteration 32219 => Loss: 46.42281953626299895177\n",
      "Iteration 32220 => Loss: 46.42265564125832355558\n",
      "Iteration 32221 => Loss: 46.42249174753983709252\n",
      "Iteration 32222 => Loss: 46.42232785510762482772\n",
      "Iteration 32223 => Loss: 46.42216396396160860149\n",
      "Iteration 32224 => Loss: 46.42200007410180262468\n",
      "Iteration 32225 => Loss: 46.42183618552819268643\n",
      "Iteration 32226 => Loss: 46.42167229824077168132\n",
      "Iteration 32227 => Loss: 46.42150841223953250392\n",
      "Iteration 32228 => Loss: 46.42134452752446094337\n",
      "Iteration 32229 => Loss: 46.42118064409554989425\n",
      "Iteration 32230 => Loss: 46.42101676195279935655\n",
      "Iteration 32231 => Loss: 46.42085288109615959229\n",
      "Iteration 32232 => Loss: 46.42068900152568033945\n",
      "Iteration 32233 => Loss: 46.42052512324129054377\n",
      "Iteration 32234 => Loss: 46.42036124624302573238\n",
      "Iteration 32235 => Loss: 46.42019737053085748357\n",
      "Iteration 32236 => Loss: 46.42003349610475737563\n",
      "Iteration 32237 => Loss: 46.41986962296476804113\n",
      "Iteration 32238 => Loss: 46.41970575111081842579\n",
      "Iteration 32239 => Loss: 46.41954188054295116217\n",
      "Iteration 32240 => Loss: 46.41937801126110940686\n",
      "Iteration 32241 => Loss: 46.41921414326532158157\n",
      "Iteration 32242 => Loss: 46.41905027655555926458\n",
      "Iteration 32243 => Loss: 46.41888641113181535047\n",
      "Iteration 32244 => Loss: 46.41872254699406141754\n",
      "Iteration 32245 => Loss: 46.41855868414230457120\n",
      "Iteration 32246 => Loss: 46.41839482257655191688\n",
      "Iteration 32247 => Loss: 46.41823096229677503288\n",
      "Iteration 32248 => Loss: 46.41806710330295260292\n",
      "Iteration 32249 => Loss: 46.41790324559507752156\n",
      "Iteration 32250 => Loss: 46.41773938917318531594\n",
      "Iteration 32251 => Loss: 46.41757553403721203722\n",
      "Iteration 32252 => Loss: 46.41741168018715768540\n",
      "Iteration 32253 => Loss: 46.41724782762302936590\n",
      "Iteration 32254 => Loss: 46.41708397634480576244\n",
      "Iteration 32255 => Loss: 46.41692012635247266417\n",
      "Iteration 32256 => Loss: 46.41675627764601586023\n",
      "Iteration 32257 => Loss: 46.41659243022544956148\n",
      "Iteration 32258 => Loss: 46.41642858409073824077\n",
      "Iteration 32259 => Loss: 46.41626473924191742526\n",
      "Iteration 32260 => Loss: 46.41610089567892316609\n",
      "Iteration 32261 => Loss: 46.41593705340174835783\n",
      "Iteration 32262 => Loss: 46.41577321241041431676\n",
      "Iteration 32263 => Loss: 46.41560937270489262119\n",
      "Iteration 32264 => Loss: 46.41544553428516195481\n",
      "Iteration 32265 => Loss: 46.41528169715124363393\n",
      "Iteration 32266 => Loss: 46.41511786130312344767\n",
      "Iteration 32267 => Loss: 46.41495402674074455263\n",
      "Iteration 32268 => Loss: 46.41479019346414247593\n",
      "Iteration 32269 => Loss: 46.41462636147331011216\n",
      "Iteration 32270 => Loss: 46.41446253076819772332\n",
      "Iteration 32271 => Loss: 46.41429870134884794197\n",
      "Iteration 32272 => Loss: 46.41413487321520392470\n",
      "Iteration 32273 => Loss: 46.41397104636727277693\n",
      "Iteration 32274 => Loss: 46.41380722080506870952\n",
      "Iteration 32275 => Loss: 46.41364339652854198448\n",
      "Iteration 32276 => Loss: 46.41347957353769260180\n",
      "Iteration 32277 => Loss: 46.41331575183252056149\n",
      "Iteration 32278 => Loss: 46.41315193141302586355\n",
      "Iteration 32279 => Loss: 46.41298811227918008626\n",
      "Iteration 32280 => Loss: 46.41282429443097612420\n",
      "Iteration 32281 => Loss: 46.41266047786840687195\n",
      "Iteration 32282 => Loss: 46.41249666259145101321\n",
      "Iteration 32283 => Loss: 46.41233284860012275885\n",
      "Iteration 32284 => Loss: 46.41216903589437237088\n",
      "Iteration 32285 => Loss: 46.41200522447426379813\n",
      "Iteration 32286 => Loss: 46.41184141433972598634\n",
      "Iteration 32287 => Loss: 46.41167760549073051379\n",
      "Iteration 32288 => Loss: 46.41151379792731290763\n",
      "Iteration 32289 => Loss: 46.41134999164943764072\n",
      "Iteration 32290 => Loss: 46.41118618665712602933\n",
      "Iteration 32291 => Loss: 46.41102238295032833548\n",
      "Iteration 32292 => Loss: 46.41085858052908008631\n",
      "Iteration 32293 => Loss: 46.41069477939332443839\n",
      "Iteration 32294 => Loss: 46.41053097954307560258\n",
      "Iteration 32295 => Loss: 46.41036718097831226260\n",
      "Iteration 32296 => Loss: 46.41020338369904862930\n",
      "Iteration 32297 => Loss: 46.41003958770524917554\n",
      "Iteration 32298 => Loss: 46.40987579299690679591\n",
      "Iteration 32299 => Loss: 46.40971199957401438496\n",
      "Iteration 32300 => Loss: 46.40954820743657904814\n",
      "Iteration 32301 => Loss: 46.40938441658455104744\n",
      "Iteration 32302 => Loss: 46.40922062701796591000\n",
      "Iteration 32303 => Loss: 46.40905683873679521412\n",
      "Iteration 32304 => Loss: 46.40889305174103185436\n",
      "Iteration 32305 => Loss: 46.40872926603062609274\n",
      "Iteration 32306 => Loss: 46.40856548160561345640\n",
      "Iteration 32307 => Loss: 46.40840169846598683989\n",
      "Iteration 32308 => Loss: 46.40823791661173913781\n",
      "Iteration 32309 => Loss: 46.40807413604279929586\n",
      "Iteration 32310 => Loss: 46.40791035675923126291\n",
      "Iteration 32311 => Loss: 46.40774657876097109011\n",
      "Iteration 32312 => Loss: 46.40758280204805430458\n",
      "Iteration 32313 => Loss: 46.40741902662043116834\n",
      "Iteration 32314 => Loss: 46.40725525247813010310\n",
      "Iteration 32315 => Loss: 46.40709147962110847629\n",
      "Iteration 32316 => Loss: 46.40692770804935207707\n",
      "Iteration 32317 => Loss: 46.40676393776289643256\n",
      "Iteration 32318 => Loss: 46.40660016876167048849\n",
      "Iteration 32319 => Loss: 46.40643640104572398286\n",
      "Iteration 32320 => Loss: 46.40627263461500007224\n",
      "Iteration 32321 => Loss: 46.40610886946949875664\n",
      "Iteration 32322 => Loss: 46.40594510560924135234\n",
      "Iteration 32323 => Loss: 46.40578134303418522677\n",
      "Iteration 32324 => Loss: 46.40561758174432327451\n",
      "Iteration 32325 => Loss: 46.40545382173965549555\n",
      "Iteration 32326 => Loss: 46.40529006302016767904\n",
      "Iteration 32327 => Loss: 46.40512630558583850870\n",
      "Iteration 32328 => Loss: 46.40496254943668219539\n",
      "Iteration 32329 => Loss: 46.40479879457267031739\n",
      "Iteration 32330 => Loss: 46.40463504099379576928\n",
      "Iteration 32331 => Loss: 46.40447128870005855106\n",
      "Iteration 32332 => Loss: 46.40430753769145866272\n",
      "Iteration 32333 => Loss: 46.40414378796791794457\n",
      "Iteration 32334 => Loss: 46.40398003952951455631\n",
      "Iteration 32335 => Loss: 46.40381629237619165451\n",
      "Iteration 32336 => Loss: 46.40365254650794923919\n",
      "Iteration 32337 => Loss: 46.40348880192478020490\n",
      "Iteration 32338 => Loss: 46.40332505862664902452\n",
      "Iteration 32339 => Loss: 46.40316131661356990890\n",
      "Iteration 32340 => Loss: 46.40299757588554996346\n",
      "Iteration 32341 => Loss: 46.40283383644254655565\n",
      "Iteration 32342 => Loss: 46.40267009828455968545\n",
      "Iteration 32343 => Loss: 46.40250636141160356374\n",
      "Iteration 32344 => Loss: 46.40234262582362845251\n",
      "Iteration 32345 => Loss: 46.40217889152062724634\n",
      "Iteration 32346 => Loss: 46.40201515850262126150\n",
      "Iteration 32347 => Loss: 46.40185142676958207630\n",
      "Iteration 32348 => Loss: 46.40168769632150258531\n",
      "Iteration 32349 => Loss: 46.40152396715835436680\n",
      "Iteration 32350 => Loss: 46.40136023928016584250\n",
      "Iteration 32351 => Loss: 46.40119651268690148527\n",
      "Iteration 32352 => Loss: 46.40103278737853287339\n",
      "Iteration 32353 => Loss: 46.40086906335509553401\n",
      "Iteration 32354 => Loss: 46.40070534061654683455\n",
      "Iteration 32355 => Loss: 46.40054161916288677503\n",
      "Iteration 32356 => Loss: 46.40037789899410825001\n",
      "Iteration 32357 => Loss: 46.40021418011018994321\n",
      "Iteration 32358 => Loss: 46.40005046251111764377\n",
      "Iteration 32359 => Loss: 46.39988674619691266798\n",
      "Iteration 32360 => Loss: 46.39972303116754659413\n",
      "Iteration 32361 => Loss: 46.39955931742299810594\n",
      "Iteration 32362 => Loss: 46.39939560496328141426\n",
      "Iteration 32363 => Loss: 46.39923189378834678109\n",
      "Iteration 32364 => Loss: 46.39906818389822973359\n",
      "Iteration 32365 => Loss: 46.39890447529289474460\n",
      "Iteration 32366 => Loss: 46.39874076797232049785\n",
      "Iteration 32367 => Loss: 46.39857706193652120419\n",
      "Iteration 32368 => Loss: 46.39841335718547554734\n",
      "Iteration 32369 => Loss: 46.39824965371917642187\n",
      "Iteration 32370 => Loss: 46.39808595153762382779\n",
      "Iteration 32371 => Loss: 46.39792225064080355423\n",
      "Iteration 32372 => Loss: 46.39775855102868717950\n",
      "Iteration 32373 => Loss: 46.39759485270127470358\n",
      "Iteration 32374 => Loss: 46.39743115565857323190\n",
      "Iteration 32375 => Loss: 46.39726745990052592106\n",
      "Iteration 32376 => Loss: 46.39710376542717540360\n",
      "Iteration 32377 => Loss: 46.39694007223850036326\n",
      "Iteration 32378 => Loss: 46.39677638033445106203\n",
      "Iteration 32379 => Loss: 46.39661268971507723791\n",
      "Iteration 32380 => Loss: 46.39644900038030783662\n",
      "Iteration 32381 => Loss: 46.39628531233018549074\n",
      "Iteration 32382 => Loss: 46.39612162556468888397\n",
      "Iteration 32383 => Loss: 46.39595794008377538375\n",
      "Iteration 32384 => Loss: 46.39579425588748762266\n",
      "Iteration 32385 => Loss: 46.39563057297574033555\n",
      "Iteration 32386 => Loss: 46.39546689134859036585\n",
      "Iteration 32387 => Loss: 46.39530321100600929185\n",
      "Iteration 32388 => Loss: 46.39513953194797579727\n",
      "Iteration 32389 => Loss: 46.39497585417447567124\n",
      "Iteration 32390 => Loss: 46.39481217768553023006\n",
      "Iteration 32391 => Loss: 46.39464850248110394659\n",
      "Iteration 32392 => Loss: 46.39448482856118971540\n",
      "Iteration 32393 => Loss: 46.39432115592578753649\n",
      "Iteration 32394 => Loss: 46.39415748457486898815\n",
      "Iteration 32395 => Loss: 46.39399381450844828123\n",
      "Iteration 32396 => Loss: 46.39383014572649699403\n",
      "Iteration 32397 => Loss: 46.39366647822900802112\n",
      "Iteration 32398 => Loss: 46.39350281201596715164\n",
      "Iteration 32399 => Loss: 46.39333914708735306931\n",
      "Iteration 32400 => Loss: 46.39317548344320130127\n",
      "Iteration 32401 => Loss: 46.39301182108346921495\n",
      "Iteration 32402 => Loss: 46.39284816000813549408\n",
      "Iteration 32403 => Loss: 46.39268450021722145493\n",
      "Iteration 32404 => Loss: 46.39252084171068446494\n",
      "Iteration 32405 => Loss: 46.39235718448853873497\n",
      "Iteration 32406 => Loss: 46.39219352855077715958\n",
      "Iteration 32407 => Loss: 46.39202987389736421164\n",
      "Iteration 32408 => Loss: 46.39186622052832120744\n",
      "Iteration 32409 => Loss: 46.39170256844359840898\n",
      "Iteration 32410 => Loss: 46.39153891764323134339\n",
      "Iteration 32411 => Loss: 46.39137526812716316726\n",
      "Iteration 32412 => Loss: 46.39121161989543651316\n",
      "Iteration 32413 => Loss: 46.39104797294800164309\n",
      "Iteration 32414 => Loss: 46.39088432728484434620\n",
      "Iteration 32415 => Loss: 46.39072068290597883333\n",
      "Iteration 32416 => Loss: 46.39055703981138378822\n",
      "Iteration 32417 => Loss: 46.39039339800105921086\n",
      "Iteration 32418 => Loss: 46.39022975747498378496\n",
      "Iteration 32419 => Loss: 46.39006611823314329968\n",
      "Iteration 32420 => Loss: 46.38990248027554486043\n",
      "Iteration 32421 => Loss: 46.38973884360215294009\n",
      "Iteration 32422 => Loss: 46.38957520821298885494\n",
      "Iteration 32423 => Loss: 46.38941157410802418326\n",
      "Iteration 32424 => Loss: 46.38924794128725892506\n",
      "Iteration 32425 => Loss: 46.38908430975065755320\n",
      "Iteration 32426 => Loss: 46.38892067949823427853\n",
      "Iteration 32427 => Loss: 46.38875705052996778477\n",
      "Iteration 32428 => Loss: 46.38859342284585807192\n",
      "Iteration 32429 => Loss: 46.38842979644589803456\n",
      "Iteration 32430 => Loss: 46.38826617133005925098\n",
      "Iteration 32431 => Loss: 46.38810254749835593202\n",
      "Iteration 32432 => Loss: 46.38793892495075255056\n",
      "Iteration 32433 => Loss: 46.38777530368723489573\n",
      "Iteration 32434 => Loss: 46.38761168370783849468\n",
      "Iteration 32435 => Loss: 46.38744806501248518771\n",
      "Iteration 32436 => Loss: 46.38728444760126023994\n",
      "Iteration 32437 => Loss: 46.38712083147404285910\n",
      "Iteration 32438 => Loss: 46.38695721663089699405\n",
      "Iteration 32439 => Loss: 46.38679360307178711764\n",
      "Iteration 32440 => Loss: 46.38662999079672033531\n",
      "Iteration 32441 => Loss: 46.38646637980566822534\n",
      "Iteration 32442 => Loss: 46.38630277009860947146\n",
      "Iteration 32443 => Loss: 46.38613916167557960080\n",
      "Iteration 32444 => Loss: 46.38597555453649334822\n",
      "Iteration 32445 => Loss: 46.38581194868144308430\n",
      "Iteration 32446 => Loss: 46.38564834411034354389\n",
      "Iteration 32447 => Loss: 46.38548474082318762157\n",
      "Iteration 32448 => Loss: 46.38532113881999663363\n",
      "Iteration 32449 => Loss: 46.38515753810074215835\n",
      "Iteration 32450 => Loss: 46.38499393866541709031\n",
      "Iteration 32451 => Loss: 46.38483034051399300779\n",
      "Iteration 32452 => Loss: 46.38466674364650543794\n",
      "Iteration 32453 => Loss: 46.38450314806291885361\n",
      "Iteration 32454 => Loss: 46.38433955376322614939\n",
      "Iteration 32455 => Loss: 46.38417596074739179812\n",
      "Iteration 32456 => Loss: 46.38401236901542290525\n",
      "Iteration 32457 => Loss: 46.38384877856733368162\n",
      "Iteration 32458 => Loss: 46.38368518940307438925\n",
      "Iteration 32459 => Loss: 46.38352160152266634441\n",
      "Iteration 32460 => Loss: 46.38335801492608823082\n",
      "Iteration 32461 => Loss: 46.38319442961332583764\n",
      "Iteration 32462 => Loss: 46.38303084558438627027\n",
      "Iteration 32463 => Loss: 46.38286726283923400160\n",
      "Iteration 32464 => Loss: 46.38270368137784771534\n",
      "Iteration 32465 => Loss: 46.38254010120027714947\n",
      "Iteration 32466 => Loss: 46.38237652230644414431\n",
      "Iteration 32467 => Loss: 46.38221294469638422697\n",
      "Iteration 32468 => Loss: 46.38204936837007608119\n",
      "Iteration 32469 => Loss: 46.38188579332751970696\n",
      "Iteration 32470 => Loss: 46.38172221956865826087\n",
      "Iteration 32471 => Loss: 46.38155864709354858633\n",
      "Iteration 32472 => Loss: 46.38139507590212673449\n",
      "Iteration 32473 => Loss: 46.38123150599438559993\n",
      "Iteration 32474 => Loss: 46.38106793737035360436\n",
      "Iteration 32475 => Loss: 46.38090437003001653693\n",
      "Iteration 32476 => Loss: 46.38074080397332465964\n",
      "Iteration 32477 => Loss: 46.38057723920029928877\n",
      "Iteration 32478 => Loss: 46.38041367571091910804\n",
      "Iteration 32479 => Loss: 46.38025011350518411746\n",
      "Iteration 32480 => Loss: 46.38008655258307300073\n",
      "Iteration 32481 => Loss: 46.37992299294455733616\n",
      "Iteration 32482 => Loss: 46.37975943458967975630\n",
      "Iteration 32483 => Loss: 46.37959587751839052316\n",
      "Iteration 32484 => Loss: 46.37943232173066832047\n",
      "Iteration 32485 => Loss: 46.37926876722654867535\n",
      "Iteration 32486 => Loss: 46.37910521400599606068\n",
      "Iteration 32487 => Loss: 46.37894166206898916016\n",
      "Iteration 32488 => Loss: 46.37877811141554218466\n",
      "Iteration 32489 => Loss: 46.37861456204559829075\n",
      "Iteration 32490 => Loss: 46.37845101395921432186\n",
      "Iteration 32491 => Loss: 46.37828746715632632913\n",
      "Iteration 32492 => Loss: 46.37812392163694852343\n",
      "Iteration 32493 => Loss: 46.37796037740109511560\n",
      "Iteration 32494 => Loss: 46.37779683444870926223\n",
      "Iteration 32495 => Loss: 46.37763329277980517418\n",
      "Iteration 32496 => Loss: 46.37746975239436153515\n",
      "Iteration 32497 => Loss: 46.37730621329236413430\n",
      "Iteration 32498 => Loss: 46.37714267547382007706\n",
      "Iteration 32499 => Loss: 46.37697913893872936342\n",
      "Iteration 32500 => Loss: 46.37681560368703514996\n",
      "Iteration 32501 => Loss: 46.37665206971878717468\n",
      "Iteration 32502 => Loss: 46.37648853703391438330\n",
      "Iteration 32503 => Loss: 46.37632500563245940839\n",
      "Iteration 32504 => Loss: 46.37616147551438672281\n",
      "Iteration 32505 => Loss: 46.37599794667968922113\n",
      "Iteration 32506 => Loss: 46.37583441912835269250\n",
      "Iteration 32507 => Loss: 46.37567089286036292606\n",
      "Iteration 32508 => Loss: 46.37550736787574123809\n",
      "Iteration 32509 => Loss: 46.37534384417444499604\n",
      "Iteration 32510 => Loss: 46.37518032175647419990\n",
      "Iteration 32511 => Loss: 46.37501680062182884967\n",
      "Iteration 32512 => Loss: 46.37485328077047341822\n",
      "Iteration 32513 => Loss: 46.37468976220240080011\n",
      "Iteration 32514 => Loss: 46.37452624491765362791\n",
      "Iteration 32515 => Loss: 46.37436272891613953107\n",
      "Iteration 32516 => Loss: 46.37419921419790824757\n",
      "Iteration 32517 => Loss: 46.37403570076293135571\n",
      "Iteration 32518 => Loss: 46.37387218861118753921\n",
      "Iteration 32519 => Loss: 46.37370867774271232520\n",
      "Iteration 32520 => Loss: 46.37354516815743465941\n",
      "Iteration 32521 => Loss: 46.37338165985538296354\n",
      "Iteration 32522 => Loss: 46.37321815283652171047\n",
      "Iteration 32523 => Loss: 46.37305464710087221647\n",
      "Iteration 32524 => Loss: 46.37289114264839895441\n",
      "Iteration 32525 => Loss: 46.37272763947909481885\n",
      "Iteration 32526 => Loss: 46.37256413759295980981\n",
      "Iteration 32527 => Loss: 46.37240063698997971642\n",
      "Iteration 32528 => Loss: 46.37223713767013322240\n",
      "Iteration 32529 => Loss: 46.37207363963343453861\n",
      "Iteration 32530 => Loss: 46.37191014287985524334\n",
      "Iteration 32531 => Loss: 46.37174664740938823115\n",
      "Iteration 32532 => Loss: 46.37158315322201929121\n",
      "Iteration 32533 => Loss: 46.37141966031775552892\n",
      "Iteration 32534 => Loss: 46.37125616869658273345\n",
      "Iteration 32535 => Loss: 46.37109267835847248307\n",
      "Iteration 32536 => Loss: 46.37092918930342477779\n",
      "Iteration 32537 => Loss: 46.37076570153141830133\n",
      "Iteration 32538 => Loss: 46.37060221504248858082\n",
      "Iteration 32539 => Loss: 46.37043872983657166742\n",
      "Iteration 32540 => Loss: 46.37027524591366045570\n",
      "Iteration 32541 => Loss: 46.37011176327378336737\n",
      "Iteration 32542 => Loss: 46.36994828191691908614\n",
      "Iteration 32543 => Loss: 46.36978480184301787403\n",
      "Iteration 32544 => Loss: 46.36962132305212236361\n",
      "Iteration 32545 => Loss: 46.36945784554419702772\n",
      "Iteration 32546 => Loss: 46.36929436931922765552\n",
      "Iteration 32547 => Loss: 46.36913089437720714159\n",
      "Iteration 32548 => Loss: 46.36896742071815680220\n",
      "Iteration 32549 => Loss: 46.36880394834200558307\n",
      "Iteration 32550 => Loss: 46.36864047724881743306\n",
      "Iteration 32551 => Loss: 46.36847700743850708704\n",
      "Iteration 32552 => Loss: 46.36831353891111007215\n",
      "Iteration 32553 => Loss: 46.36815007166659086124\n",
      "Iteration 32554 => Loss: 46.36798660570497787603\n",
      "Iteration 32555 => Loss: 46.36782314102621427310\n",
      "Iteration 32556 => Loss: 46.36765967763033557958\n",
      "Iteration 32557 => Loss: 46.36749621551729205748\n",
      "Iteration 32558 => Loss: 46.36733275468709791767\n",
      "Iteration 32559 => Loss: 46.36716929513972473842\n",
      "Iteration 32560 => Loss: 46.36700583687519383602\n",
      "Iteration 32561 => Loss: 46.36684237989347678877\n",
      "Iteration 32562 => Loss: 46.36667892419452385866\n",
      "Iteration 32563 => Loss: 46.36651546977840609998\n",
      "Iteration 32564 => Loss: 46.36635201664503824759\n",
      "Iteration 32565 => Loss: 46.36618856479447714491\n",
      "Iteration 32566 => Loss: 46.36602511422663752683\n",
      "Iteration 32567 => Loss: 46.36586166494157623674\n",
      "Iteration 32568 => Loss: 46.36569821693923643124\n",
      "Iteration 32569 => Loss: 46.36553477021965363747\n",
      "Iteration 32570 => Loss: 46.36537132478277101200\n",
      "Iteration 32571 => Loss: 46.36520788062860276568\n",
      "Iteration 32572 => Loss: 46.36504443775712758224\n",
      "Iteration 32573 => Loss: 46.36488099616835967254\n",
      "Iteration 32574 => Loss: 46.36471755586227772028\n",
      "Iteration 32575 => Loss: 46.36455411683884619833\n",
      "Iteration 32576 => Loss: 46.36439067909810063384\n",
      "Iteration 32577 => Loss: 46.36422724263997707794\n",
      "Iteration 32578 => Loss: 46.36406380746450395236\n",
      "Iteration 32579 => Loss: 46.36390037357167415166\n",
      "Iteration 32580 => Loss: 46.36373694096145214871\n",
      "Iteration 32581 => Loss: 46.36357350963385925979\n",
      "Iteration 32582 => Loss: 46.36341007958883864148\n",
      "Iteration 32583 => Loss: 46.36324665082643292635\n",
      "Iteration 32584 => Loss: 46.36308322334659237640\n",
      "Iteration 32585 => Loss: 46.36291979714933120249\n",
      "Iteration 32586 => Loss: 46.36275637223461387748\n",
      "Iteration 32587 => Loss: 46.36259294860245461223\n",
      "Iteration 32588 => Loss: 46.36242952625283209045\n",
      "Iteration 32589 => Loss: 46.36226610518575341757\n",
      "Iteration 32590 => Loss: 46.36210268540119017189\n",
      "Iteration 32591 => Loss: 46.36193926689913524797\n",
      "Iteration 32592 => Loss: 46.36177584967958154039\n",
      "Iteration 32593 => Loss: 46.36161243374252194371\n",
      "Iteration 32594 => Loss: 46.36144901908793514167\n",
      "Iteration 32595 => Loss: 46.36128560571582113425\n",
      "Iteration 32596 => Loss: 46.36112219362617992147\n",
      "Iteration 32597 => Loss: 46.36095878281894755446\n",
      "Iteration 32598 => Loss: 46.36079537329418087666\n",
      "Iteration 32599 => Loss: 46.36063196505183725549\n",
      "Iteration 32600 => Loss: 46.36046855809192379638\n",
      "Iteration 32601 => Loss: 46.36030515241440497221\n",
      "Iteration 32602 => Loss: 46.36014174801930209924\n",
      "Iteration 32603 => Loss: 46.35997834490659386120\n",
      "Iteration 32604 => Loss: 46.35981494307624473095\n",
      "Iteration 32605 => Loss: 46.35965154252826181391\n",
      "Iteration 32606 => Loss: 46.35948814326263800467\n",
      "Iteration 32607 => Loss: 46.35932474527938040865\n",
      "Iteration 32608 => Loss: 46.35916134857846060413\n",
      "Iteration 32609 => Loss: 46.35899795315985727484\n",
      "Iteration 32610 => Loss: 46.35883455902357752620\n",
      "Iteration 32611 => Loss: 46.35867116616960714737\n",
      "Iteration 32612 => Loss: 46.35850777459793192747\n",
      "Iteration 32613 => Loss: 46.35834438430854476110\n",
      "Iteration 32614 => Loss: 46.35818099530143854281\n",
      "Iteration 32615 => Loss: 46.35801760757659906176\n",
      "Iteration 32616 => Loss: 46.35785422113401921251\n",
      "Iteration 32617 => Loss: 46.35769083597369188965\n",
      "Iteration 32618 => Loss: 46.35752745209558867145\n",
      "Iteration 32619 => Loss: 46.35736406949973797964\n",
      "Iteration 32620 => Loss: 46.35720068818609007621\n",
      "Iteration 32621 => Loss: 46.35703730815463785575\n",
      "Iteration 32622 => Loss: 46.35687392940539552910\n",
      "Iteration 32623 => Loss: 46.35671055193834888541\n",
      "Iteration 32624 => Loss: 46.35654717575346239755\n",
      "Iteration 32625 => Loss: 46.35638380085076448722\n",
      "Iteration 32626 => Loss: 46.35622042723021252186\n",
      "Iteration 32627 => Loss: 46.35605705489181360690\n",
      "Iteration 32628 => Loss: 46.35589368383556063691\n",
      "Iteration 32629 => Loss: 46.35573031406140387389\n",
      "Iteration 32630 => Loss: 46.35556694556938595042\n",
      "Iteration 32631 => Loss: 46.35540357835947844478\n",
      "Iteration 32632 => Loss: 46.35524021243165293527\n",
      "Iteration 32633 => Loss: 46.35507684778592363273\n",
      "Iteration 32634 => Loss: 46.35491348442228343174\n",
      "Iteration 32635 => Loss: 46.35475012234069680517\n",
      "Iteration 32636 => Loss: 46.35458676154115664758\n",
      "Iteration 32637 => Loss: 46.35442340202369848612\n",
      "Iteration 32638 => Loss: 46.35426004378821573937\n",
      "Iteration 32639 => Loss: 46.35409668683481498874\n",
      "Iteration 32640 => Loss: 46.35393333116341807454\n",
      "Iteration 32641 => Loss: 46.35376997677400368048\n",
      "Iteration 32642 => Loss: 46.35360662366662864997\n",
      "Iteration 32643 => Loss: 46.35344327184120771790\n",
      "Iteration 32644 => Loss: 46.35327992129778351682\n",
      "Iteration 32645 => Loss: 46.35311657203634894131\n",
      "Iteration 32646 => Loss: 46.35295322405680451539\n",
      "Iteration 32647 => Loss: 46.35278987735924260960\n",
      "Iteration 32648 => Loss: 46.35262653194360638054\n",
      "Iteration 32649 => Loss: 46.35246318780990293362\n",
      "Iteration 32650 => Loss: 46.35229984495811095258\n",
      "Iteration 32651 => Loss: 46.35213650338823043739\n",
      "Iteration 32652 => Loss: 46.35197316310026138808\n",
      "Iteration 32653 => Loss: 46.35180982409414696122\n",
      "Iteration 32654 => Loss: 46.35164648636993689479\n",
      "Iteration 32655 => Loss: 46.35148314992758145081\n",
      "Iteration 32656 => Loss: 46.35131981476708773471\n",
      "Iteration 32657 => Loss: 46.35115648088842732477\n",
      "Iteration 32658 => Loss: 46.35099314829160022100\n",
      "Iteration 32659 => Loss: 46.35082981697660642340\n",
      "Iteration 32660 => Loss: 46.35066648694343172110\n",
      "Iteration 32661 => Loss: 46.35050315819205479784\n",
      "Iteration 32662 => Loss: 46.35033983072248275903\n",
      "Iteration 32663 => Loss: 46.35017650453470139382\n",
      "Iteration 32664 => Loss: 46.35001317962867517508\n",
      "Iteration 32665 => Loss: 46.34984985600441120823\n",
      "Iteration 32666 => Loss: 46.34968653366193791499\n",
      "Iteration 32667 => Loss: 46.34952321260117003021\n",
      "Iteration 32668 => Loss: 46.34935989282217150276\n",
      "Iteration 32669 => Loss: 46.34919657432488548920\n",
      "Iteration 32670 => Loss: 46.34903325710929067327\n",
      "Iteration 32671 => Loss: 46.34886994117542968752\n",
      "Iteration 32672 => Loss: 46.34870662652324568853\n",
      "Iteration 32673 => Loss: 46.34854331315275999259\n",
      "Iteration 32674 => Loss: 46.34838000106394417799\n",
      "Iteration 32675 => Loss: 46.34821669025679113929\n",
      "Iteration 32676 => Loss: 46.34805338073129377108\n",
      "Iteration 32677 => Loss: 46.34789007248745207335\n",
      "Iteration 32678 => Loss: 46.34772676552523762439\n",
      "Iteration 32679 => Loss: 46.34756345984462910792\n",
      "Iteration 32680 => Loss: 46.34740015544566205108\n",
      "Iteration 32681 => Loss: 46.34723685232826539959\n",
      "Iteration 32682 => Loss: 46.34707355049250310230\n",
      "Iteration 32683 => Loss: 46.34691024993829699952\n",
      "Iteration 32684 => Loss: 46.34674695066567551294\n",
      "Iteration 32685 => Loss: 46.34658365267461022086\n",
      "Iteration 32686 => Loss: 46.34642035596510822870\n",
      "Iteration 32687 => Loss: 46.34625706053715532562\n",
      "Iteration 32688 => Loss: 46.34609376639072308990\n",
      "Iteration 32689 => Loss: 46.34593047352581152154\n",
      "Iteration 32690 => Loss: 46.34576718194242772597\n",
      "Iteration 32691 => Loss: 46.34560389164054328148\n",
      "Iteration 32692 => Loss: 46.34544060262015108265\n",
      "Iteration 32693 => Loss: 46.34527731488125112946\n",
      "Iteration 32694 => Loss: 46.34511402842380078937\n",
      "Iteration 32695 => Loss: 46.34495074324784980035\n",
      "Iteration 32696 => Loss: 46.34478745935332000272\n",
      "Iteration 32697 => Loss: 46.34462417674024692360\n",
      "Iteration 32698 => Loss: 46.34446089540860214129\n",
      "Iteration 32699 => Loss: 46.34429761535839986664\n",
      "Iteration 32700 => Loss: 46.34413433658959746708\n",
      "Iteration 32701 => Loss: 46.34397105910217362634\n",
      "Iteration 32702 => Loss: 46.34380778289617097698\n",
      "Iteration 32703 => Loss: 46.34364450797156820272\n",
      "Iteration 32704 => Loss: 46.34348123432831556556\n",
      "Iteration 32705 => Loss: 46.34331796196640596008\n",
      "Iteration 32706 => Loss: 46.34315469088588912427\n",
      "Iteration 32707 => Loss: 46.34299142108667979301\n",
      "Iteration 32708 => Loss: 46.34282815256882770427\n",
      "Iteration 32709 => Loss: 46.34266488533230443636\n",
      "Iteration 32710 => Loss: 46.34250161937708156756\n",
      "Iteration 32711 => Loss: 46.34233835470314488703\n",
      "Iteration 32712 => Loss: 46.34217509131050860560\n",
      "Iteration 32713 => Loss: 46.34201182919916561787\n",
      "Iteration 32714 => Loss: 46.34184856836910881839\n",
      "Iteration 32715 => Loss: 46.34168530882028136375\n",
      "Iteration 32716 => Loss: 46.34152205055271878109\n",
      "Iteration 32717 => Loss: 46.34135879356640685955\n",
      "Iteration 32718 => Loss: 46.34119553786133138829\n",
      "Iteration 32719 => Loss: 46.34103228343746394557\n",
      "Iteration 32720 => Loss: 46.34086903029481874228\n",
      "Iteration 32721 => Loss: 46.34070577843336025126\n",
      "Iteration 32722 => Loss: 46.34054252785311689422\n",
      "Iteration 32723 => Loss: 46.34037927855401761690\n",
      "Iteration 32724 => Loss: 46.34021603053612636813\n",
      "Iteration 32725 => Loss: 46.34005278379937919908\n",
      "Iteration 32726 => Loss: 46.33988953834378321517\n",
      "Iteration 32727 => Loss: 46.33972629416935262725\n",
      "Iteration 32728 => Loss: 46.33956305127602348648\n",
      "Iteration 32729 => Loss: 46.33939980966383131999\n",
      "Iteration 32730 => Loss: 46.33923656933275481151\n",
      "Iteration 32731 => Loss: 46.33907333028276553932\n",
      "Iteration 32732 => Loss: 46.33891009251388481971\n",
      "Iteration 32733 => Loss: 46.33874685602606291468\n",
      "Iteration 32734 => Loss: 46.33858362081934956223\n",
      "Iteration 32735 => Loss: 46.33842038689365239179\n",
      "Iteration 32736 => Loss: 46.33825715424902824680\n",
      "Iteration 32737 => Loss: 46.33809392288544870553\n",
      "Iteration 32738 => Loss: 46.33793069280288534628\n",
      "Iteration 32739 => Loss: 46.33776746400136659076\n",
      "Iteration 32740 => Loss: 46.33760423648084270098\n",
      "Iteration 32741 => Loss: 46.33744101024131367694\n",
      "Iteration 32742 => Loss: 46.33727778528279372949\n",
      "Iteration 32743 => Loss: 46.33711456160525443693\n",
      "Iteration 32744 => Loss: 46.33695133920868158839\n",
      "Iteration 32745 => Loss: 46.33678811809306097302\n",
      "Iteration 32746 => Loss: 46.33662489825840680169\n",
      "Iteration 32747 => Loss: 46.33646167970467644182\n",
      "Iteration 32748 => Loss: 46.33629846243187699883\n",
      "Iteration 32749 => Loss: 46.33613524644000847275\n",
      "Iteration 32750 => Loss: 46.33597203172904244184\n",
      "Iteration 32751 => Loss: 46.33580881829897890611\n",
      "Iteration 32752 => Loss: 46.33564560614980365472\n",
      "Iteration 32753 => Loss: 46.33548239528150958222\n",
      "Iteration 32754 => Loss: 46.33531918569407537234\n",
      "Iteration 32755 => Loss: 46.33515597738752944679\n",
      "Iteration 32756 => Loss: 46.33499277036183627843\n",
      "Iteration 32757 => Loss: 46.33482956461696034012\n",
      "Iteration 32758 => Loss: 46.33466636015289452644\n",
      "Iteration 32759 => Loss: 46.33450315696969568080\n",
      "Iteration 32760 => Loss: 46.33433995506727853808\n",
      "Iteration 32761 => Loss: 46.33417675444565730913\n",
      "Iteration 32762 => Loss: 46.33401355510484620481\n",
      "Iteration 32763 => Loss: 46.33385035704480969798\n",
      "Iteration 32764 => Loss: 46.33368716026551936693\n",
      "Iteration 32765 => Loss: 46.33352396476703205508\n",
      "Iteration 32766 => Loss: 46.33336077054926960272\n",
      "Iteration 32767 => Loss: 46.33319757761223200987\n",
      "Iteration 32768 => Loss: 46.33303438595594059279\n",
      "Iteration 32769 => Loss: 46.33287119558035271893\n",
      "Iteration 32770 => Loss: 46.33270800648551812628\n",
      "Iteration 32771 => Loss: 46.33254481867134444428\n",
      "Iteration 32772 => Loss: 46.33238163213786009464\n",
      "Iteration 32773 => Loss: 46.33221844688507218279\n",
      "Iteration 32774 => Loss: 46.33205526291295228702\n",
      "Iteration 32775 => Loss: 46.33189208022147198562\n",
      "Iteration 32776 => Loss: 46.33172889881066680573\n",
      "Iteration 32777 => Loss: 46.33156571868049411478\n",
      "Iteration 32778 => Loss: 46.33140253983094680734\n",
      "Iteration 32779 => Loss: 46.33123936226201067257\n",
      "Iteration 32780 => Loss: 46.33107618597368571045\n",
      "Iteration 32781 => Loss: 46.33091301096596481557\n",
      "Iteration 32782 => Loss: 46.33074983723881956621\n",
      "Iteration 32783 => Loss: 46.33058666479227838408\n",
      "Iteration 32784 => Loss: 46.33042349362629153120\n",
      "Iteration 32785 => Loss: 46.33026032374086611298\n",
      "Iteration 32786 => Loss: 46.33009715513598791858\n",
      "Iteration 32787 => Loss: 46.32993398781163563172\n",
      "Iteration 32788 => Loss: 46.32977082176783767409\n",
      "Iteration 32789 => Loss: 46.32960765700454430771\n",
      "Iteration 32790 => Loss: 46.32944449352174842716\n",
      "Iteration 32791 => Loss: 46.32928133131945713785\n",
      "Iteration 32792 => Loss: 46.32911817039767043980\n",
      "Iteration 32793 => Loss: 46.32895501075634570043\n",
      "Iteration 32794 => Loss: 46.32879185239551134146\n",
      "Iteration 32795 => Loss: 46.32862869531508920318\n",
      "Iteration 32796 => Loss: 46.32846553951515744529\n",
      "Iteration 32797 => Loss: 46.32830238499565211896\n",
      "Iteration 32798 => Loss: 46.32813923175658032960\n",
      "Iteration 32799 => Loss: 46.32797607979789944466\n",
      "Iteration 32800 => Loss: 46.32781292911965920212\n",
      "Iteration 32801 => Loss: 46.32764977972179565313\n",
      "Iteration 32802 => Loss: 46.32748663160433011399\n",
      "Iteration 32803 => Loss: 46.32732348476724126840\n",
      "Iteration 32804 => Loss: 46.32716033921052911637\n",
      "Iteration 32805 => Loss: 46.32699719493416523619\n",
      "Iteration 32806 => Loss: 46.32683405193814252243\n",
      "Iteration 32807 => Loss: 46.32667091022246097509\n",
      "Iteration 32808 => Loss: 46.32650776978711348875\n",
      "Iteration 32809 => Loss: 46.32634463063209295797\n",
      "Iteration 32810 => Loss: 46.32618149275735675019\n",
      "Iteration 32811 => Loss: 46.32601835616292618170\n",
      "Iteration 32812 => Loss: 46.32585522084878704163\n",
      "Iteration 32813 => Loss: 46.32569208681492511914\n",
      "Iteration 32814 => Loss: 46.32552895406133330880\n",
      "Iteration 32815 => Loss: 46.32536582258797608347\n",
      "Iteration 32816 => Loss: 46.32520269239489607571\n",
      "Iteration 32817 => Loss: 46.32503956348205065296\n",
      "Iteration 32818 => Loss: 46.32487643584941849895\n",
      "Iteration 32819 => Loss: 46.32471330949699961366\n",
      "Iteration 32820 => Loss: 46.32455018442480820795\n",
      "Iteration 32821 => Loss: 46.32438706063278743841\n",
      "Iteration 32822 => Loss: 46.32422393812097283217\n",
      "Iteration 32823 => Loss: 46.32406081688933596752\n",
      "Iteration 32824 => Loss: 46.32389769693786263360\n",
      "Iteration 32825 => Loss: 46.32373457826653861957\n",
      "Iteration 32826 => Loss: 46.32357146087537103085\n",
      "Iteration 32827 => Loss: 46.32340834476433144573\n",
      "Iteration 32828 => Loss: 46.32324522993341986421\n",
      "Iteration 32829 => Loss: 46.32308211638263628629\n",
      "Iteration 32830 => Loss: 46.32291900411193807940\n",
      "Iteration 32831 => Loss: 46.32275589312135366526\n",
      "Iteration 32832 => Loss: 46.32259278341084751673\n",
      "Iteration 32833 => Loss: 46.32242967498042673924\n",
      "Iteration 32834 => Loss: 46.32226656783006291107\n",
      "Iteration 32835 => Loss: 46.32210346195975603223\n",
      "Iteration 32836 => Loss: 46.32194035736949189186\n",
      "Iteration 32837 => Loss: 46.32177725405927759539\n",
      "Iteration 32838 => Loss: 46.32161415202908472111\n",
      "Iteration 32839 => Loss: 46.32145105127891326902\n",
      "Iteration 32840 => Loss: 46.32128795180873481740\n",
      "Iteration 32841 => Loss: 46.32112485361856357713\n",
      "Iteration 32842 => Loss: 46.32096175670837112648\n",
      "Iteration 32843 => Loss: 46.32079866107815036003\n",
      "Iteration 32844 => Loss: 46.32063556672790838320\n",
      "Iteration 32845 => Loss: 46.32047247365762387972\n",
      "Iteration 32846 => Loss: 46.32030938186726842787\n",
      "Iteration 32847 => Loss: 46.32014629135684913308\n",
      "Iteration 32848 => Loss: 46.31998320212638020621\n",
      "Iteration 32849 => Loss: 46.31982011417581190926\n",
      "Iteration 32850 => Loss: 46.31965702750513003139\n",
      "Iteration 32851 => Loss: 46.31949394211436299429\n",
      "Iteration 32852 => Loss: 46.31933085800346816541\n",
      "Iteration 32853 => Loss: 46.31916777517247396645\n",
      "Iteration 32854 => Loss: 46.31900469362131644857\n",
      "Iteration 32855 => Loss: 46.31884161335003824433\n",
      "Iteration 32856 => Loss: 46.31867853435859672118\n",
      "Iteration 32857 => Loss: 46.31851545664699187910\n",
      "Iteration 32858 => Loss: 46.31835238021522371810\n",
      "Iteration 32859 => Loss: 46.31818930506325671104\n",
      "Iteration 32860 => Loss: 46.31802623119110506877\n",
      "Iteration 32861 => Loss: 46.31786315859874036960\n",
      "Iteration 32862 => Loss: 46.31770008728615550808\n",
      "Iteration 32863 => Loss: 46.31753701725335758965\n",
      "Iteration 32864 => Loss: 46.31737394850031108717\n",
      "Iteration 32865 => Loss: 46.31721088102700889522\n",
      "Iteration 32866 => Loss: 46.31704781483349364635\n",
      "Iteration 32867 => Loss: 46.31688474991968007544\n",
      "Iteration 32868 => Loss: 46.31672168628559660419\n",
      "Iteration 32869 => Loss: 46.31655862393123612719\n",
      "Iteration 32870 => Loss: 46.31639556285657022272\n",
      "Iteration 32871 => Loss: 46.31623250306159889078\n",
      "Iteration 32872 => Loss: 46.31606944454632213137\n",
      "Iteration 32873 => Loss: 46.31590638731071862821\n",
      "Iteration 32874 => Loss: 46.31574333135476706502\n",
      "Iteration 32875 => Loss: 46.31558027667847454723\n",
      "Iteration 32876 => Loss: 46.31541722328183396939\n",
      "Iteration 32877 => Loss: 46.31525417116483822610\n",
      "Iteration 32878 => Loss: 46.31509112032744468479\n",
      "Iteration 32879 => Loss: 46.31492807076969597802\n",
      "Iteration 32880 => Loss: 46.31476502249150684065\n",
      "Iteration 32881 => Loss: 46.31460197549294832697\n",
      "Iteration 32882 => Loss: 46.31443892977395648813\n",
      "Iteration 32883 => Loss: 46.31427588533453842956\n",
      "Iteration 32884 => Loss: 46.31411284217467994040\n",
      "Iteration 32885 => Loss: 46.31394980029438102065\n",
      "Iteration 32886 => Loss: 46.31378675969363456488\n",
      "Iteration 32887 => Loss: 46.31362372037241925682\n",
      "Iteration 32888 => Loss: 46.31346068233073509646\n",
      "Iteration 32889 => Loss: 46.31329764556856076752\n",
      "Iteration 32890 => Loss: 46.31313461008588916457\n",
      "Iteration 32891 => Loss: 46.31297157588269897133\n",
      "Iteration 32892 => Loss: 46.31280854295901860951\n",
      "Iteration 32893 => Loss: 46.31264551131477702484\n",
      "Iteration 32894 => Loss: 46.31248248095003816616\n",
      "Iteration 32895 => Loss: 46.31231945186471676834\n",
      "Iteration 32896 => Loss: 46.31215642405885546395\n",
      "Iteration 32897 => Loss: 46.31199339753241872586\n",
      "Iteration 32898 => Loss: 46.31183037228542787034\n",
      "Iteration 32899 => Loss: 46.31166734831782605397\n",
      "Iteration 32900 => Loss: 46.31150432562964880390\n",
      "Iteration 32901 => Loss: 46.31134130422086059298\n",
      "Iteration 32902 => Loss: 46.31117828409144010493\n",
      "Iteration 32903 => Loss: 46.31101526524140155061\n",
      "Iteration 32904 => Loss: 46.31085224767072361374\n",
      "Iteration 32905 => Loss: 46.31068923137940629431\n",
      "Iteration 32906 => Loss: 46.31052621636742117062\n",
      "Iteration 32907 => Loss: 46.31036320263478245352\n",
      "Iteration 32908 => Loss: 46.31020019018146172129\n",
      "Iteration 32909 => Loss: 46.31003717900746607938\n",
      "Iteration 32910 => Loss: 46.30987416911276710607\n",
      "Iteration 32911 => Loss: 46.30971116049735059050\n",
      "Iteration 32912 => Loss: 46.30954815316121653268\n",
      "Iteration 32913 => Loss: 46.30938514710435782717\n",
      "Iteration 32914 => Loss: 46.30922214232677447399\n",
      "Iteration 32915 => Loss: 46.30905913882842384055\n",
      "Iteration 32916 => Loss: 46.30889613660932724315\n",
      "Iteration 32917 => Loss: 46.30873313566946336550\n",
      "Iteration 32918 => Loss: 46.30857013600883220761\n",
      "Iteration 32919 => Loss: 46.30840713762739113690\n",
      "Iteration 32920 => Loss: 46.30824414052516857510\n",
      "Iteration 32921 => Loss: 46.30808114470215031133\n",
      "Iteration 32922 => Loss: 46.30791815015830792390\n",
      "Iteration 32923 => Loss: 46.30775515689362009653\n",
      "Iteration 32924 => Loss: 46.30759216490810814548\n",
      "Iteration 32925 => Loss: 46.30742917420172943821\n",
      "Iteration 32926 => Loss: 46.30726618477452660727\n",
      "Iteration 32927 => Loss: 46.30710319662642149297\n",
      "Iteration 32928 => Loss: 46.30694020975746383328\n",
      "Iteration 32929 => Loss: 46.30677722416761810109\n",
      "Iteration 32930 => Loss: 46.30661423985685587468\n",
      "Iteration 32931 => Loss: 46.30645125682521978661\n",
      "Iteration 32932 => Loss: 46.30628827507262457175\n",
      "Iteration 32933 => Loss: 46.30612529459912707352\n",
      "Iteration 32934 => Loss: 46.30596231540467755394\n",
      "Iteration 32935 => Loss: 46.30579933748928311843\n",
      "Iteration 32936 => Loss: 46.30563636085295087241\n",
      "Iteration 32937 => Loss: 46.30547338549562397247\n",
      "Iteration 32938 => Loss: 46.30531041141732373490\n",
      "Iteration 32939 => Loss: 46.30514743861805726510\n",
      "Iteration 32940 => Loss: 46.30498446709776061425\n",
      "Iteration 32941 => Loss: 46.30482149685649062576\n",
      "Iteration 32942 => Loss: 46.30465852789417624535\n",
      "Iteration 32943 => Loss: 46.30449556021085300017\n",
      "Iteration 32944 => Loss: 46.30433259380647115222\n",
      "Iteration 32945 => Loss: 46.30416962868103780693\n",
      "Iteration 32946 => Loss: 46.30400666483456006972\n",
      "Iteration 32947 => Loss: 46.30384370226701662432\n",
      "Iteration 32948 => Loss: 46.30368074097839325987\n",
      "Iteration 32949 => Loss: 46.30351778096868287093\n",
      "Iteration 32950 => Loss: 46.30335482223786414124\n",
      "Iteration 32951 => Loss: 46.30319186478595838707\n",
      "Iteration 32952 => Loss: 46.30302890861290876501\n",
      "Iteration 32953 => Loss: 46.30286595371875080218\n",
      "Iteration 32954 => Loss: 46.30270300010342765518\n",
      "Iteration 32955 => Loss: 46.30254004776698195656\n",
      "Iteration 32956 => Loss: 46.30237709670937817918\n",
      "Iteration 32957 => Loss: 46.30221414693058790135\n",
      "Iteration 32958 => Loss: 46.30205119843061112306\n",
      "Iteration 32959 => Loss: 46.30188825120947626601\n",
      "Iteration 32960 => Loss: 46.30172530526713359222\n",
      "Iteration 32961 => Loss: 46.30156236060357599627\n",
      "Iteration 32962 => Loss: 46.30139941721880347814\n",
      "Iteration 32963 => Loss: 46.30123647511279472155\n",
      "Iteration 32964 => Loss: 46.30107353428554262109\n",
      "Iteration 32965 => Loss: 46.30091059473704717675\n",
      "Iteration 32966 => Loss: 46.30074765646729417767\n",
      "Iteration 32967 => Loss: 46.30058471947627651844\n",
      "Iteration 32968 => Loss: 46.30042178376397288275\n",
      "Iteration 32969 => Loss: 46.30025884933038327063\n",
      "Iteration 32970 => Loss: 46.30009591617549347120\n",
      "Iteration 32971 => Loss: 46.29993298429929637905\n",
      "Iteration 32972 => Loss: 46.29977005370179199417\n",
      "Iteration 32973 => Loss: 46.29960712438293768400\n",
      "Iteration 32974 => Loss: 46.29944419634274765940\n",
      "Iteration 32975 => Loss: 46.29928126958122192036\n",
      "Iteration 32976 => Loss: 46.29911834409832493975\n",
      "Iteration 32977 => Loss: 46.29895541989406382299\n",
      "Iteration 32978 => Loss: 46.29879249696843146467\n",
      "Iteration 32979 => Loss: 46.29862957532139233763\n",
      "Iteration 32980 => Loss: 46.29846665495296065274\n",
      "Iteration 32981 => Loss: 46.29830373586310798828\n",
      "Iteration 32982 => Loss: 46.29814081805186276597\n",
      "Iteration 32983 => Loss: 46.29797790151916103696\n",
      "Iteration 32984 => Loss: 46.29781498626502411753\n",
      "Iteration 32985 => Loss: 46.29765207228945911311\n",
      "Iteration 32986 => Loss: 46.29748915959241628570\n",
      "Iteration 32987 => Loss: 46.29732624817389563532\n",
      "Iteration 32988 => Loss: 46.29716333803390426738\n",
      "Iteration 32989 => Loss: 46.29700042917242797103\n",
      "Iteration 32990 => Loss: 46.29683752158944542998\n",
      "Iteration 32991 => Loss: 46.29667461528497085510\n",
      "Iteration 32992 => Loss: 46.29651171025895450839\n",
      "Iteration 32993 => Loss: 46.29634880651140349528\n",
      "Iteration 32994 => Loss: 46.29618590404233913205\n",
      "Iteration 32995 => Loss: 46.29602300285170457528\n",
      "Iteration 32996 => Loss: 46.29586010293952114125\n",
      "Iteration 32997 => Loss: 46.29569720430576040826\n",
      "Iteration 32998 => Loss: 46.29553430695042948173\n",
      "Iteration 32999 => Loss: 46.29537141087351415081\n",
      "Iteration 33000 => Loss: 46.29520851607495757207\n",
      "Iteration 33001 => Loss: 46.29504562255483079980\n",
      "Iteration 33002 => Loss: 46.29488273031307699057\n",
      "Iteration 33003 => Loss: 46.29471983934968193353\n",
      "Iteration 33004 => Loss: 46.29455694966465273410\n",
      "Iteration 33005 => Loss: 46.29439406125796807601\n",
      "Iteration 33006 => Loss: 46.29423117412964217010\n",
      "Iteration 33007 => Loss: 46.29406828827961817296\n",
      "Iteration 33008 => Loss: 46.29390540370793871716\n",
      "Iteration 33009 => Loss: 46.29374252041453985385\n",
      "Iteration 33010 => Loss: 46.29357963839947132101\n",
      "Iteration 33011 => Loss: 46.29341675766267627523\n",
      "Iteration 33012 => Loss: 46.29325387820416182194\n",
      "Iteration 33013 => Loss: 46.29309100002392796114\n",
      "Iteration 33014 => Loss: 46.29292812312193206026\n",
      "Iteration 33015 => Loss: 46.29276524749819543558\n",
      "Iteration 33016 => Loss: 46.29260237315270387626\n",
      "Iteration 33017 => Loss: 46.29243950008543606600\n",
      "Iteration 33018 => Loss: 46.29227662829638489939\n",
      "Iteration 33019 => Loss: 46.29211375778553616556\n",
      "Iteration 33020 => Loss: 46.29195088855291118080\n",
      "Iteration 33021 => Loss: 46.29178802059846731254\n",
      "Iteration 33022 => Loss: 46.29162515392217613908\n",
      "Iteration 33023 => Loss: 46.29146228852408739840\n",
      "Iteration 33024 => Loss: 46.29129942440413714166\n",
      "Iteration 33025 => Loss: 46.29113656156234668515\n",
      "Iteration 33026 => Loss: 46.29097369999868050172\n",
      "Iteration 33027 => Loss: 46.29081083971317411851\n",
      "Iteration 33028 => Loss: 46.29064798070576358668\n",
      "Iteration 33029 => Loss: 46.29048512297645601166\n",
      "Iteration 33030 => Loss: 46.29032226652525849886\n",
      "Iteration 33031 => Loss: 46.29015941135214973201\n",
      "Iteration 33032 => Loss: 46.28999655745710839483\n",
      "Iteration 33033 => Loss: 46.28983370484015580359\n",
      "Iteration 33034 => Loss: 46.28967085350124932575\n",
      "Iteration 33035 => Loss: 46.28950800344038896128\n",
      "Iteration 33036 => Loss: 46.28934515465758892105\n",
      "Iteration 33037 => Loss: 46.28918230715279946708\n",
      "Iteration 33038 => Loss: 46.28901946092603481020\n",
      "Iteration 33039 => Loss: 46.28885661597725942329\n",
      "Iteration 33040 => Loss: 46.28869377230650172805\n",
      "Iteration 33041 => Loss: 46.28853092991371909193\n",
      "Iteration 33042 => Loss: 46.28836808879892572577\n",
      "Iteration 33043 => Loss: 46.28820524896210741872\n",
      "Iteration 33044 => Loss: 46.28804241040325706535\n",
      "Iteration 33045 => Loss: 46.28787957312232492768\n",
      "Iteration 33046 => Loss: 46.28771673711934653284\n",
      "Iteration 33047 => Loss: 46.28755390239428635368\n",
      "Iteration 33048 => Loss: 46.28739106894715149565\n",
      "Iteration 33049 => Loss: 46.28722823677791353703\n",
      "Iteration 33050 => Loss: 46.28706540588659379409\n",
      "Iteration 33051 => Loss: 46.28690257627316384514\n",
      "Iteration 33052 => Loss: 46.28673974793760947932\n",
      "Iteration 33053 => Loss: 46.28657692087989516949\n",
      "Iteration 33054 => Loss: 46.28641409510007775907\n",
      "Iteration 33055 => Loss: 46.28625127059808619379\n",
      "Iteration 33056 => Loss: 46.28608844737392757906\n",
      "Iteration 33057 => Loss: 46.28592562542761612576\n",
      "Iteration 33058 => Loss: 46.28576280475910920131\n",
      "Iteration 33059 => Loss: 46.28559998536842101657\n",
      "Iteration 33060 => Loss: 46.28543716725551604441\n",
      "Iteration 33061 => Loss: 46.28527435042042270652\n",
      "Iteration 33062 => Loss: 46.28511153486308415950\n",
      "Iteration 33063 => Loss: 46.28494872058352171962\n",
      "Iteration 33064 => Loss: 46.28478590758171407060\n",
      "Iteration 33065 => Loss: 46.28462309585764700159\n",
      "Iteration 33066 => Loss: 46.28446028541135603973\n",
      "Iteration 33067 => Loss: 46.28429747624274170903\n",
      "Iteration 33068 => Loss: 46.28413466835187506376\n",
      "Iteration 33069 => Loss: 46.28397186173871347137\n",
      "Iteration 33070 => Loss: 46.28380905640324272099\n",
      "Iteration 33071 => Loss: 46.28364625234545570720\n",
      "Iteration 33072 => Loss: 46.28348344956535243000\n",
      "Iteration 33073 => Loss: 46.28332064806292578396\n",
      "Iteration 33074 => Loss: 46.28315784783816155823\n",
      "Iteration 33075 => Loss: 46.28299504889102422567\n",
      "Iteration 33076 => Loss: 46.28283225122152799713\n",
      "Iteration 33077 => Loss: 46.28266945482964445091\n",
      "Iteration 33078 => Loss: 46.28250665971540911414\n",
      "Iteration 33079 => Loss: 46.28234386587877224883\n",
      "Iteration 33080 => Loss: 46.28218107331971253871\n",
      "Iteration 33081 => Loss: 46.28201828203827972175\n",
      "Iteration 33082 => Loss: 46.28185549203438853283\n",
      "Iteration 33083 => Loss: 46.28169270330806739366\n",
      "Iteration 33084 => Loss: 46.28152991585932340968\n",
      "Iteration 33085 => Loss: 46.28136712968812105373\n",
      "Iteration 33086 => Loss: 46.28120434479445322040\n",
      "Iteration 33087 => Loss: 46.28104156117830569883\n",
      "Iteration 33088 => Loss: 46.28087877883969269988\n",
      "Iteration 33089 => Loss: 46.28071599777856448554\n",
      "Iteration 33090 => Loss: 46.28055321799496368840\n",
      "Iteration 33091 => Loss: 46.28039043948883346502\n",
      "Iteration 33092 => Loss: 46.28022766226017381541\n",
      "Iteration 33093 => Loss: 46.28006488630899184500\n",
      "Iteration 33094 => Loss: 46.27990211163525202664\n",
      "Iteration 33095 => Loss: 46.27973933823897567663\n",
      "Iteration 33096 => Loss: 46.27957656612012016240\n",
      "Iteration 33097 => Loss: 46.27941379527870680022\n",
      "Iteration 33098 => Loss: 46.27925102571469295754\n",
      "Iteration 33099 => Loss: 46.27908825742811416148\n",
      "Iteration 33100 => Loss: 46.27892549041890646322\n",
      "Iteration 33101 => Loss: 46.27876272468709828445\n",
      "Iteration 33102 => Loss: 46.27859996023265409804\n",
      "Iteration 33103 => Loss: 46.27843719705559522026\n",
      "Iteration 33104 => Loss: 46.27827443515586480771\n",
      "Iteration 33105 => Loss: 46.27811167453351970380\n",
      "Iteration 33106 => Loss: 46.27794891518848885426\n",
      "Iteration 33107 => Loss: 46.27778615712079357536\n",
      "Iteration 33108 => Loss: 46.27762340033039833997\n",
      "Iteration 33109 => Loss: 46.27746064481733156981\n",
      "Iteration 33110 => Loss: 46.27729789058155773773\n",
      "Iteration 33111 => Loss: 46.27713513762304131660\n",
      "Iteration 33112 => Loss: 46.27697238594183914984\n",
      "Iteration 33113 => Loss: 46.27680963553786597231\n",
      "Iteration 33114 => Loss: 46.27664688641118573287\n",
      "Iteration 33115 => Loss: 46.27648413856174869352\n",
      "Iteration 33116 => Loss: 46.27632139198953353798\n",
      "Iteration 33117 => Loss: 46.27615864669454026625\n",
      "Iteration 33118 => Loss: 46.27599590267678308919\n",
      "Iteration 33119 => Loss: 46.27583315993621226880\n",
      "Iteration 33120 => Loss: 46.27567041847286333223\n",
      "Iteration 33121 => Loss: 46.27550767828667943604\n",
      "Iteration 33122 => Loss: 46.27534493937766058025\n",
      "Iteration 33123 => Loss: 46.27518220174581387028\n",
      "Iteration 33124 => Loss: 46.27501946539116062240\n",
      "Iteration 33125 => Loss: 46.27485673031362267693\n",
      "Iteration 33126 => Loss: 46.27469399651322135014\n",
      "Iteration 33127 => Loss: 46.27453126398996374746\n",
      "Iteration 33128 => Loss: 46.27436853274379302547\n",
      "Iteration 33129 => Loss: 46.27420580277475181674\n",
      "Iteration 33130 => Loss: 46.27404307408279748870\n",
      "Iteration 33131 => Loss: 46.27388034666793004135\n",
      "Iteration 33132 => Loss: 46.27371762053014947469\n",
      "Iteration 33133 => Loss: 46.27355489566944157787\n",
      "Iteration 33134 => Loss: 46.27339217208575661289\n",
      "Iteration 33135 => Loss: 46.27322944977913721232\n",
      "Iteration 33136 => Loss: 46.27306672874954784902\n",
      "Iteration 33137 => Loss: 46.27290400899699562842\n",
      "Iteration 33138 => Loss: 46.27274129052146633967\n",
      "Iteration 33139 => Loss: 46.27257857332291735020\n",
      "Iteration 33140 => Loss: 46.27241585740136997629\n",
      "Iteration 33141 => Loss: 46.27225314275681711251\n",
      "Iteration 33142 => Loss: 46.27209042938923744259\n",
      "Iteration 33143 => Loss: 46.27192771729862386110\n",
      "Iteration 33144 => Loss: 46.27176500648495505175\n",
      "Iteration 33145 => Loss: 46.27160229694824522539\n",
      "Iteration 33146 => Loss: 46.27143958868848727661\n",
      "Iteration 33147 => Loss: 46.27127688170563857284\n",
      "Iteration 33148 => Loss: 46.27111417599969200865\n",
      "Iteration 33149 => Loss: 46.27095147157066179489\n",
      "Iteration 33150 => Loss: 46.27078876841854082613\n",
      "Iteration 33151 => Loss: 46.27062606654329357525\n",
      "Iteration 33152 => Loss: 46.27046336594490583138\n",
      "Iteration 33153 => Loss: 46.27030066662341312167\n",
      "Iteration 33154 => Loss: 46.27013796857877281354\n",
      "Iteration 33155 => Loss: 46.26997527181096359072\n",
      "Iteration 33156 => Loss: 46.26981257631999255864\n",
      "Iteration 33157 => Loss: 46.26964988210585971729\n",
      "Iteration 33158 => Loss: 46.26948718916853664496\n",
      "Iteration 33159 => Loss: 46.26932449750801623622\n",
      "Iteration 33160 => Loss: 46.26916180712427006938\n",
      "Iteration 33161 => Loss: 46.26899911801734077699\n",
      "Iteration 33162 => Loss: 46.26883643018717151563\n",
      "Iteration 33163 => Loss: 46.26867374363376939073\n",
      "Iteration 33164 => Loss: 46.26851105835712729686\n",
      "Iteration 33165 => Loss: 46.26834837435724523402\n",
      "Iteration 33166 => Loss: 46.26818569163407346423\n",
      "Iteration 33167 => Loss: 46.26802301018764040919\n",
      "Iteration 33168 => Loss: 46.26786033001791054176\n",
      "Iteration 33169 => Loss: 46.26769765112489096737\n",
      "Iteration 33170 => Loss: 46.26753497350856747516\n",
      "Iteration 33171 => Loss: 46.26737229716894006515\n",
      "Iteration 33172 => Loss: 46.26720962210597321018\n",
      "Iteration 33173 => Loss: 46.26704694831968112112\n",
      "Iteration 33174 => Loss: 46.26688427581003537625\n",
      "Iteration 33175 => Loss: 46.26672160457705729186\n",
      "Iteration 33176 => Loss: 46.26655893462069002453\n",
      "Iteration 33177 => Loss: 46.26639626594096199597\n",
      "Iteration 33178 => Loss: 46.26623359853783767903\n",
      "Iteration 33179 => Loss: 46.26607093241131707373\n",
      "Iteration 33180 => Loss: 46.26590826756141439091\n",
      "Iteration 33181 => Loss: 46.26574560398807278716\n",
      "Iteration 33182 => Loss: 46.26558294169133489504\n",
      "Iteration 33183 => Loss: 46.26542028067112255485\n",
      "Iteration 33184 => Loss: 46.26525762092749261001\n",
      "Iteration 33185 => Loss: 46.26509496246040242795\n",
      "Iteration 33186 => Loss: 46.26493230526985200868\n",
      "Iteration 33187 => Loss: 46.26476964935580582505\n",
      "Iteration 33188 => Loss: 46.26460699471828519336\n",
      "Iteration 33189 => Loss: 46.26444434135728300816\n",
      "Iteration 33190 => Loss: 46.26428168927275663691\n",
      "Iteration 33191 => Loss: 46.26411903846473450130\n",
      "Iteration 33192 => Loss: 46.26395638893318107421\n",
      "Iteration 33193 => Loss: 46.26379374067806793391\n",
      "Iteration 33194 => Loss: 46.26363109369944481841\n",
      "Iteration 33195 => Loss: 46.26346844799724067343\n",
      "Iteration 33196 => Loss: 46.26330580357149102610\n",
      "Iteration 33197 => Loss: 46.26314316042216034930\n",
      "Iteration 33198 => Loss: 46.26298051854925574844\n",
      "Iteration 33199 => Loss: 46.26281787795273459096\n",
      "Iteration 33200 => Loss: 46.26265523863260398230\n",
      "Iteration 33201 => Loss: 46.26249260058888523872\n",
      "Iteration 33202 => Loss: 46.26232996382151441139\n",
      "Iteration 33203 => Loss: 46.26216732833052702745\n",
      "Iteration 33204 => Loss: 46.26200469411589466517\n",
      "Iteration 33205 => Loss: 46.26184206117761021915\n",
      "Iteration 33206 => Loss: 46.26167942951564526766\n",
      "Iteration 33207 => Loss: 46.26151679913002112698\n",
      "Iteration 33208 => Loss: 46.26135417002067384828\n",
      "Iteration 33209 => Loss: 46.26119154218767448583\n",
      "Iteration 33210 => Loss: 46.26102891563094487992\n",
      "Iteration 33211 => Loss: 46.26086629035052055769\n",
      "Iteration 33212 => Loss: 46.26070366634635888659\n",
      "Iteration 33213 => Loss: 46.26054104361845276117\n",
      "Iteration 33214 => Loss: 46.26037842216681639229\n",
      "Iteration 33215 => Loss: 46.26021580199142135825\n",
      "Iteration 33216 => Loss: 46.26005318309224634277\n",
      "Iteration 33217 => Loss: 46.25989056546931266212\n",
      "Iteration 33218 => Loss: 46.25972794912258478917\n",
      "Iteration 33219 => Loss: 46.25956533405207693477\n",
      "Iteration 33220 => Loss: 46.25940272025774646636\n",
      "Iteration 33221 => Loss: 46.25924010773960048937\n",
      "Iteration 33222 => Loss: 46.25907749649763900379\n",
      "Iteration 33223 => Loss: 46.25891488653184069335\n",
      "Iteration 33224 => Loss: 46.25875227784218424176\n",
      "Iteration 33225 => Loss: 46.25858967042868385988\n",
      "Iteration 33226 => Loss: 46.25842706429131823143\n",
      "Iteration 33227 => Loss: 46.25826445943008025097\n",
      "Iteration 33228 => Loss: 46.25810185584494860223\n",
      "Iteration 33229 => Loss: 46.25793925353593039063\n",
      "Iteration 33230 => Loss: 46.25777665250299008903\n",
      "Iteration 33231 => Loss: 46.25761405274614190830\n",
      "Iteration 33232 => Loss: 46.25745145426537874300\n",
      "Iteration 33233 => Loss: 46.25728885706065796057\n",
      "Iteration 33234 => Loss: 46.25712626113201508815\n",
      "Iteration 33235 => Loss: 46.25696366647939328232\n",
      "Iteration 33236 => Loss: 46.25680107310282807020\n",
      "Iteration 33237 => Loss: 46.25663848100228392468\n",
      "Iteration 33238 => Loss: 46.25647589017773952946\n",
      "Iteration 33239 => Loss: 46.25631330062920198998\n",
      "Iteration 33240 => Loss: 46.25615071235667841165\n",
      "Iteration 33241 => Loss: 46.25598812536012616192\n",
      "Iteration 33242 => Loss: 46.25582553963953102993\n",
      "Iteration 33243 => Loss: 46.25566295519492143740\n",
      "Iteration 33244 => Loss: 46.25550037202626896260\n",
      "Iteration 33245 => Loss: 46.25533779013353807841\n",
      "Iteration 33246 => Loss: 46.25517520951677141738\n",
      "Iteration 33247 => Loss: 46.25501263017591213611\n",
      "Iteration 33248 => Loss: 46.25485005211096734001\n",
      "Iteration 33249 => Loss: 46.25468747532190860738\n",
      "Iteration 33250 => Loss: 46.25452489980878567621\n",
      "Iteration 33251 => Loss: 46.25436232557151328137\n",
      "Iteration 33252 => Loss: 46.25419975261011984458\n",
      "Iteration 33253 => Loss: 46.25403718092459115496\n",
      "Iteration 33254 => Loss: 46.25387461051492721253\n",
      "Iteration 33255 => Loss: 46.25371204138109249016\n",
      "Iteration 33256 => Loss: 46.25354947352310830411\n",
      "Iteration 33257 => Loss: 46.25338690694093912725\n",
      "Iteration 33258 => Loss: 46.25322434163459917045\n",
      "Iteration 33259 => Loss: 46.25306177760403159027\n",
      "Iteration 33260 => Loss: 46.25289921484929323015\n",
      "Iteration 33261 => Loss: 46.25273665337029882494\n",
      "Iteration 33262 => Loss: 46.25257409316709811264\n",
      "Iteration 33263 => Loss: 46.25241153423969109326\n",
      "Iteration 33264 => Loss: 46.25224897658799960709\n",
      "Iteration 33265 => Loss: 46.25208642021206628669\n",
      "Iteration 33266 => Loss: 46.25192386511185560494\n",
      "Iteration 33267 => Loss: 46.25176131128737466724\n",
      "Iteration 33268 => Loss: 46.25159875873861636819\n",
      "Iteration 33269 => Loss: 46.25143620746554518064\n",
      "Iteration 33270 => Loss: 46.25127365746817531544\n",
      "Iteration 33271 => Loss: 46.25111110874649966718\n",
      "Iteration 33272 => Loss: 46.25094856130048981413\n",
      "Iteration 33273 => Loss: 46.25078601513013865087\n",
      "Iteration 33274 => Loss: 46.25062347023546038827\n",
      "Iteration 33275 => Loss: 46.25046092661638397203\n",
      "Iteration 33276 => Loss: 46.25029838427297335102\n",
      "Iteration 33277 => Loss: 46.25013584320519299808\n",
      "Iteration 33278 => Loss: 46.24997330341300738610\n",
      "Iteration 33279 => Loss: 46.24981076489643072591\n",
      "Iteration 33280 => Loss: 46.24964822765546301753\n",
      "Iteration 33281 => Loss: 46.24948569169006162838\n",
      "Iteration 33282 => Loss: 46.24932315700024787475\n",
      "Iteration 33283 => Loss: 46.24916062358600044035\n",
      "Iteration 33284 => Loss: 46.24899809144728379806\n",
      "Iteration 33285 => Loss: 46.24883556058411926415\n",
      "Iteration 33286 => Loss: 46.24867303099649262776\n",
      "Iteration 33287 => Loss: 46.24851050268439678348\n",
      "Iteration 33288 => Loss: 46.24834797564778909873\n",
      "Iteration 33289 => Loss: 46.24818544988671220608\n",
      "Iteration 33290 => Loss: 46.24802292540110926211\n",
      "Iteration 33291 => Loss: 46.24786040219100158311\n",
      "Iteration 33292 => Loss: 46.24769788025635364193\n",
      "Iteration 33293 => Loss: 46.24753535959720096571\n",
      "Iteration 33294 => Loss: 46.24737284021347250018\n",
      "Iteration 33295 => Loss: 46.24721032210521798334\n",
      "Iteration 33296 => Loss: 46.24704780527236636090\n",
      "Iteration 33297 => Loss: 46.24688528971493184372\n",
      "Iteration 33298 => Loss: 46.24672277543292153723\n",
      "Iteration 33299 => Loss: 46.24656026242633544143\n",
      "Iteration 33300 => Loss: 46.24639775069512381833\n",
      "Iteration 33301 => Loss: 46.24623524023931508964\n",
      "Iteration 33302 => Loss: 46.24607273105885241193\n",
      "Iteration 33303 => Loss: 46.24591022315377131235\n",
      "Iteration 33304 => Loss: 46.24574771652402915834\n",
      "Iteration 33305 => Loss: 46.24558521116963305531\n",
      "Iteration 33306 => Loss: 46.24542270709059721412\n",
      "Iteration 33307 => Loss: 46.24526020428686479136\n",
      "Iteration 33308 => Loss: 46.24509770275843578702\n",
      "Iteration 33309 => Loss: 46.24493520250531020110\n",
      "Iteration 33310 => Loss: 46.24477270352748803361\n",
      "Iteration 33311 => Loss: 46.24461020582494796827\n",
      "Iteration 33312 => Loss: 46.24444770939769000506\n",
      "Iteration 33313 => Loss: 46.24428521424568572229\n",
      "Iteration 33314 => Loss: 46.24412272036894222538\n",
      "Iteration 33315 => Loss: 46.24396022776744530347\n",
      "Iteration 33316 => Loss: 46.24379773644115232401\n",
      "Iteration 33317 => Loss: 46.24363524639011302497\n",
      "Iteration 33318 => Loss: 46.24347275761426345753\n",
      "Iteration 33319 => Loss: 46.24331027011363204338\n",
      "Iteration 33320 => Loss: 46.24314778388819746624\n",
      "Iteration 33321 => Loss: 46.24298529893794551526\n",
      "Iteration 33322 => Loss: 46.24282281526286197959\n",
      "Iteration 33323 => Loss: 46.24266033286294685922\n",
      "Iteration 33324 => Loss: 46.24249785173817883788\n",
      "Iteration 33325 => Loss: 46.24233537188855081013\n",
      "Iteration 33326 => Loss: 46.24217289331406277597\n",
      "Iteration 33327 => Loss: 46.24201041601470052456\n",
      "Iteration 33328 => Loss: 46.24184793999044984503\n",
      "Iteration 33329 => Loss: 46.24168546524128231567\n",
      "Iteration 33330 => Loss: 46.24152299176723346363\n",
      "Iteration 33331 => Loss: 46.24136051956824644549\n",
      "Iteration 33332 => Loss: 46.24119804864437099923\n",
      "Iteration 33333 => Loss: 46.24103557899554317601\n",
      "Iteration 33334 => Loss: 46.24087311062173455412\n",
      "Iteration 33335 => Loss: 46.24071064352300197697\n",
      "Iteration 33336 => Loss: 46.24054817769931702287\n",
      "Iteration 33337 => Loss: 46.24038571315060863753\n",
      "Iteration 33338 => Loss: 46.24022324987693366438\n",
      "Iteration 33339 => Loss: 46.24006078787827789256\n",
      "Iteration 33340 => Loss: 46.23989832715460579493\n",
      "Iteration 33341 => Loss: 46.23973586770591737150\n",
      "Iteration 33342 => Loss: 46.23957340953219130597\n",
      "Iteration 33343 => Loss: 46.23941095263343470378\n",
      "Iteration 33344 => Loss: 46.23924849700964045951\n",
      "Iteration 33345 => Loss: 46.23908604266078015144\n",
      "Iteration 33346 => Loss: 46.23892358958686088499\n",
      "Iteration 33347 => Loss: 46.23876113778785423847\n",
      "Iteration 33348 => Loss: 46.23859868726376021186\n",
      "Iteration 33349 => Loss: 46.23843623801457880518\n",
      "Iteration 33350 => Loss: 46.23827379004028870213\n",
      "Iteration 33351 => Loss: 46.23811134334087569187\n",
      "Iteration 33352 => Loss: 46.23794889791633977438\n",
      "Iteration 33353 => Loss: 46.23778645376665963340\n",
      "Iteration 33354 => Loss: 46.23762401089184947978\n",
      "Iteration 33355 => Loss: 46.23746156929186668094\n",
      "Iteration 33356 => Loss: 46.23729912896673255318\n",
      "Iteration 33357 => Loss: 46.23713668991640446393\n",
      "Iteration 33358 => Loss: 46.23697425214090372947\n",
      "Iteration 33359 => Loss: 46.23681181564019482266\n",
      "Iteration 33360 => Loss: 46.23664938041429195437\n",
      "Iteration 33361 => Loss: 46.23648694646315959744\n",
      "Iteration 33362 => Loss: 46.23632451378679064646\n",
      "Iteration 33363 => Loss: 46.23616208238521352314\n",
      "Iteration 33364 => Loss: 46.23599965225836427862\n",
      "Iteration 33365 => Loss: 46.23583722340627844005\n",
      "Iteration 33366 => Loss: 46.23567479582891337486\n",
      "Iteration 33367 => Loss: 46.23551236952628329391\n",
      "Iteration 33368 => Loss: 46.23534994449835977548\n",
      "Iteration 33369 => Loss: 46.23518752074513571415\n",
      "Iteration 33370 => Loss: 46.23502509826659689907\n",
      "Iteration 33371 => Loss: 46.23486267706272911937\n",
      "Iteration 33372 => Loss: 46.23470025713358921848\n",
      "Iteration 33373 => Loss: 46.23453783847905640414\n",
      "Iteration 33374 => Loss: 46.23437542109921594147\n",
      "Iteration 33375 => Loss: 46.23421300499398256534\n",
      "Iteration 33376 => Loss: 46.23405059016340601374\n",
      "Iteration 33377 => Loss: 46.23388817660745075955\n",
      "Iteration 33378 => Loss: 46.23372576432609548647\n",
      "Iteration 33379 => Loss: 46.23356335331936151078\n",
      "Iteration 33380 => Loss: 46.23340094358722041079\n",
      "Iteration 33381 => Loss: 46.23323853512963665935\n",
      "Iteration 33382 => Loss: 46.23307612794665288902\n",
      "Iteration 33383 => Loss: 46.23291372203822646725\n",
      "Iteration 33384 => Loss: 46.23275131740434318317\n",
      "Iteration 33385 => Loss: 46.23258891404500303679\n",
      "Iteration 33386 => Loss: 46.23242651196019892268\n",
      "Iteration 33387 => Loss: 46.23226411114993084084\n",
      "Iteration 33388 => Loss: 46.23210171161417036956\n",
      "Iteration 33389 => Loss: 46.23193931335288908713\n",
      "Iteration 33390 => Loss: 46.23177691636612962611\n",
      "Iteration 33391 => Loss: 46.23161452065383514309\n",
      "Iteration 33392 => Loss: 46.23145212621603405978\n",
      "Iteration 33393 => Loss: 46.23128973305267663818\n",
      "Iteration 33394 => Loss: 46.23112734116378419458\n",
      "Iteration 33395 => Loss: 46.23096495054933541269\n",
      "Iteration 33396 => Loss: 46.23080256120930897623\n",
      "Iteration 33397 => Loss: 46.23064017314371199063\n",
      "Iteration 33398 => Loss: 46.23047778635251603419\n",
      "Iteration 33399 => Loss: 46.23031540083573531774\n",
      "Iteration 33400 => Loss: 46.23015301659334852502\n",
      "Iteration 33401 => Loss: 46.22999063362534144517\n",
      "Iteration 33402 => Loss: 46.22982825193169986733\n",
      "Iteration 33403 => Loss: 46.22966587151243800236\n",
      "Iteration 33404 => Loss: 46.22950349236752742854\n",
      "Iteration 33405 => Loss: 46.22934111449695393503\n",
      "Iteration 33406 => Loss: 46.22917873790070331097\n",
      "Iteration 33407 => Loss: 46.22901636257878266179\n",
      "Iteration 33408 => Loss: 46.22885398853117067119\n",
      "Iteration 33409 => Loss: 46.22869161575786733920\n",
      "Iteration 33410 => Loss: 46.22852924425885845494\n",
      "Iteration 33411 => Loss: 46.22836687403412980757\n",
      "Iteration 33412 => Loss: 46.22820450508366718623\n",
      "Iteration 33413 => Loss: 46.22804213740748480177\n",
      "Iteration 33414 => Loss: 46.22787977100554002163\n",
      "Iteration 33415 => Loss: 46.22771740587785416210\n",
      "Iteration 33416 => Loss: 46.22755504202439169603\n",
      "Iteration 33417 => Loss: 46.22739267944515262343\n",
      "Iteration 33418 => Loss: 46.22723031814012983887\n",
      "Iteration 33419 => Loss: 46.22706795810930913149\n",
      "Iteration 33420 => Loss: 46.22690559935266918501\n",
      "Iteration 33421 => Loss: 46.22674324187021710486\n",
      "Iteration 33422 => Loss: 46.22658088566195289104\n",
      "Iteration 33423 => Loss: 46.22641853072784101641\n",
      "Iteration 33424 => Loss: 46.22625617706788858641\n",
      "Iteration 33425 => Loss: 46.22609382468207428474\n",
      "Iteration 33426 => Loss: 46.22593147357037679512\n",
      "Iteration 33427 => Loss: 46.22576912373282453927\n",
      "Iteration 33428 => Loss: 46.22560677516938199005\n",
      "Iteration 33429 => Loss: 46.22544442788003493661\n",
      "Iteration 33430 => Loss: 46.22528208186478337893\n",
      "Iteration 33431 => Loss: 46.22511973712359178990\n",
      "Iteration 33432 => Loss: 46.22495739365651701291\n",
      "Iteration 33433 => Loss: 46.22479505146349509914\n",
      "Iteration 33434 => Loss: 46.22463271054451894315\n",
      "Iteration 33435 => Loss: 46.22447037089956722866\n",
      "Iteration 33436 => Loss: 46.22430803252866837738\n",
      "Iteration 33437 => Loss: 46.22414569543179396760\n",
      "Iteration 33438 => Loss: 46.22398335960890847218\n",
      "Iteration 33439 => Loss: 46.22382102506004741826\n",
      "Iteration 33440 => Loss: 46.22365869178517527871\n",
      "Iteration 33441 => Loss: 46.22349635978429915895\n",
      "Iteration 33442 => Loss: 46.22333402905738353184\n",
      "Iteration 33443 => Loss: 46.22317169960442839738\n",
      "Iteration 33444 => Loss: 46.22300937142541954472\n",
      "Iteration 33445 => Loss: 46.22284704452037118472\n",
      "Iteration 33446 => Loss: 46.22268471888927621194\n",
      "Iteration 33447 => Loss: 46.22252239453203515041\n",
      "Iteration 33448 => Loss: 46.22236007144876168695\n",
      "Iteration 33449 => Loss: 46.22219774963939897816\n",
      "Iteration 33450 => Loss: 46.22203542910389728604\n",
      "Iteration 33451 => Loss: 46.22187310984229213773\n",
      "Iteration 33452 => Loss: 46.22171079185456221694\n",
      "Iteration 33453 => Loss: 46.22154847514065778569\n",
      "Iteration 33454 => Loss: 46.22138615970066410910\n",
      "Iteration 33455 => Loss: 46.22122384553447460576\n",
      "Iteration 33456 => Loss: 46.22106153264213901366\n",
      "Iteration 33457 => Loss: 46.22089922102360759482\n",
      "Iteration 33458 => Loss: 46.22073691067890166551\n",
      "Iteration 33459 => Loss: 46.22057460160800701487\n",
      "Iteration 33460 => Loss: 46.22041229381089522121\n",
      "Iteration 33461 => Loss: 46.22024998728757338995\n",
      "Iteration 33462 => Loss: 46.22008768203802020480\n",
      "Iteration 33463 => Loss: 46.21992537806222145491\n",
      "Iteration 33464 => Loss: 46.21976307536017003486\n",
      "Iteration 33465 => Loss: 46.21960077393189436634\n",
      "Iteration 33466 => Loss: 46.21943847377731628967\n",
      "Iteration 33467 => Loss: 46.21927617489647133198\n",
      "Iteration 33468 => Loss: 46.21911387728935949326\n",
      "Iteration 33469 => Loss: 46.21895158095591682468\n",
      "Iteration 33470 => Loss: 46.21878928589620727507\n",
      "Iteration 33471 => Loss: 46.21862699211013847389\n",
      "Iteration 33472 => Loss: 46.21846469959778147540\n",
      "Iteration 33473 => Loss: 46.21830240835907943620\n",
      "Iteration 33474 => Loss: 46.21814011839401814541\n",
      "Iteration 33475 => Loss: 46.21797782970259049762\n",
      "Iteration 33476 => Loss: 46.21781554228480359825\n",
      "Iteration 33477 => Loss: 46.21765325614066455273\n",
      "Iteration 33478 => Loss: 46.21749097127012362307\n",
      "Iteration 33479 => Loss: 46.21732868767317370384\n",
      "Iteration 33480 => Loss: 46.21716640534981479504\n",
      "Iteration 33481 => Loss: 46.21700412430004689668\n",
      "Iteration 33482 => Loss: 46.21684184452386290332\n",
      "Iteration 33483 => Loss: 46.21667956602121307697\n",
      "Iteration 33484 => Loss: 46.21651728879214715562\n",
      "Iteration 33485 => Loss: 46.21635501283662961214\n",
      "Iteration 33486 => Loss: 46.21619273815462491939\n",
      "Iteration 33487 => Loss: 46.21603046474614728822\n",
      "Iteration 33488 => Loss: 46.21586819261118250779\n",
      "Iteration 33489 => Loss: 46.21570592174971636723\n",
      "Iteration 33490 => Loss: 46.21554365216176307740\n",
      "Iteration 33491 => Loss: 46.21538138384726579488\n",
      "Iteration 33492 => Loss: 46.21521911680626004681\n",
      "Iteration 33493 => Loss: 46.21505685103871741148\n",
      "Iteration 33494 => Loss: 46.21489458654460946718\n",
      "Iteration 33495 => Loss: 46.21473232332395753019\n",
      "Iteration 33496 => Loss: 46.21457006137674738966\n",
      "Iteration 33497 => Loss: 46.21440780070292220216\n",
      "Iteration 33498 => Loss: 46.21424554130256012741\n",
      "Iteration 33499 => Loss: 46.21408328317559011111\n",
      "Iteration 33500 => Loss: 46.21392102632198373158\n",
      "Iteration 33501 => Loss: 46.21375877074180493764\n",
      "Iteration 33502 => Loss: 46.21359651643497556961\n",
      "Iteration 33503 => Loss: 46.21343426340150273290\n",
      "Iteration 33504 => Loss: 46.21327201164139353295\n",
      "Iteration 33505 => Loss: 46.21310976115459823177\n",
      "Iteration 33506 => Loss: 46.21294751194118077819\n",
      "Iteration 33507 => Loss: 46.21278526400106301253\n",
      "Iteration 33508 => Loss: 46.21262301733425914563\n",
      "Iteration 33509 => Loss: 46.21246077194076917749\n",
      "Iteration 33510 => Loss: 46.21229852782057179184\n",
      "Iteration 33511 => Loss: 46.21213628497366698866\n",
      "Iteration 33512 => Loss: 46.21197404339999792455\n",
      "Iteration 33513 => Loss: 46.21181180309962144293\n",
      "Iteration 33514 => Loss: 46.21164956407247359493\n",
      "Iteration 33515 => Loss: 46.21148732631858990771\n",
      "Iteration 33516 => Loss: 46.21132508983796327584\n",
      "Iteration 33517 => Loss: 46.21116285463051553961\n",
      "Iteration 33518 => Loss: 46.21100062069631064787\n",
      "Iteration 33519 => Loss: 46.21083838803528465178\n",
      "Iteration 33520 => Loss: 46.21067615664747307846\n",
      "Iteration 33521 => Loss: 46.21051392653282618994\n",
      "Iteration 33522 => Loss: 46.21035169769137240792\n",
      "Iteration 33523 => Loss: 46.21018947012306909983\n",
      "Iteration 33524 => Loss: 46.21002724382793047653\n",
      "Iteration 33525 => Loss: 46.20986501880592101088\n",
      "Iteration 33526 => Loss: 46.20970279505705491374\n",
      "Iteration 33527 => Loss: 46.20954057258130376340\n",
      "Iteration 33528 => Loss: 46.20937835137867466528\n",
      "Iteration 33529 => Loss: 46.20921613144914630311\n",
      "Iteration 33530 => Loss: 46.20905391279271157146\n",
      "Iteration 33531 => Loss: 46.20889169540936336489\n",
      "Iteration 33532 => Loss: 46.20872947929908747255\n",
      "Iteration 33533 => Loss: 46.20856726446185547275\n",
      "Iteration 33534 => Loss: 46.20840505089772420888\n",
      "Iteration 33535 => Loss: 46.20824283860657999412\n",
      "Iteration 33536 => Loss: 46.20808062758850809360\n",
      "Iteration 33537 => Loss: 46.20791841784345166388\n",
      "Iteration 33538 => Loss: 46.20775620937138938871\n",
      "Iteration 33539 => Loss: 46.20759400217234968977\n",
      "Iteration 33540 => Loss: 46.20743179624629703994\n",
      "Iteration 33541 => Loss: 46.20726959159323143922\n",
      "Iteration 33542 => Loss: 46.20710738821314578217\n",
      "Iteration 33543 => Loss: 46.20694518610600454167\n",
      "Iteration 33544 => Loss: 46.20678298527182192856\n",
      "Iteration 33545 => Loss: 46.20662078571060504828\n",
      "Iteration 33546 => Loss: 46.20645858742228995197\n",
      "Iteration 33547 => Loss: 46.20629639040693348306\n",
      "Iteration 33548 => Loss: 46.20613419466447879813\n",
      "Iteration 33549 => Loss: 46.20597200019490458089\n",
      "Iteration 33550 => Loss: 46.20580980699823925306\n",
      "Iteration 33551 => Loss: 46.20564761507446860378\n",
      "Iteration 33552 => Loss: 46.20548542442356421134\n",
      "Iteration 33553 => Loss: 46.20532323504551186488\n",
      "Iteration 33554 => Loss: 46.20516104694033288069\n",
      "Iteration 33555 => Loss: 46.20499886010797752078\n",
      "Iteration 33556 => Loss: 46.20483667454846710143\n",
      "Iteration 33557 => Loss: 46.20467449026176609550\n",
      "Iteration 33558 => Loss: 46.20451230724790292470\n",
      "Iteration 33559 => Loss: 46.20435012550683495647\n",
      "Iteration 33560 => Loss: 46.20418794503854797995\n",
      "Iteration 33561 => Loss: 46.20402576584305620599\n",
      "Iteration 33562 => Loss: 46.20386358792034542375\n",
      "Iteration 33563 => Loss: 46.20370141127040852780\n",
      "Iteration 33564 => Loss: 46.20353923589316735843\n",
      "Iteration 33565 => Loss: 46.20337706178872849705\n",
      "Iteration 33566 => Loss: 46.20321488895700667854\n",
      "Iteration 33567 => Loss: 46.20305271739797348118\n",
      "Iteration 33568 => Loss: 46.20289054711171417011\n",
      "Iteration 33569 => Loss: 46.20272837809812926935\n",
      "Iteration 33570 => Loss: 46.20256621035723298974\n",
      "Iteration 33571 => Loss: 46.20240404388903243671\n",
      "Iteration 33572 => Loss: 46.20224187869349918856\n",
      "Iteration 33573 => Loss: 46.20207971477064745613\n",
      "Iteration 33574 => Loss: 46.20191755212041329060\n",
      "Iteration 33575 => Loss: 46.20175539074285353536\n",
      "Iteration 33576 => Loss: 46.20159323063791845243\n",
      "Iteration 33577 => Loss: 46.20143107180560804181\n",
      "Iteration 33578 => Loss: 46.20126891424591519808\n",
      "Iteration 33579 => Loss: 46.20110675795881149952\n",
      "Iteration 33580 => Loss: 46.20094460294431826242\n",
      "Iteration 33581 => Loss: 46.20078244920239285420\n",
      "Iteration 33582 => Loss: 46.20062029673305659117\n",
      "Iteration 33583 => Loss: 46.20045814553628105159\n",
      "Iteration 33584 => Loss: 46.20029599561205913005\n",
      "Iteration 33585 => Loss: 46.20013384696038372113\n",
      "Iteration 33586 => Loss: 46.19997169958124061395\n",
      "Iteration 33587 => Loss: 46.19980955347461559768\n",
      "Iteration 33588 => Loss: 46.19964740864050156688\n",
      "Iteration 33589 => Loss: 46.19948526507891273241\n",
      "Iteration 33590 => Loss: 46.19932312278977803999\n",
      "Iteration 33591 => Loss: 46.19916098177316854390\n",
      "Iteration 33592 => Loss: 46.19899884202902740071\n",
      "Iteration 33593 => Loss: 46.19883670355733329416\n",
      "Iteration 33594 => Loss: 46.19867456635810043508\n",
      "Iteration 33595 => Loss: 46.19851243043131461263\n",
      "Iteration 33596 => Loss: 46.19835029577695451053\n",
      "Iteration 33597 => Loss: 46.19818816239501302334\n",
      "Iteration 33598 => Loss: 46.19802603028550436193\n",
      "Iteration 33599 => Loss: 46.19786389944839299915\n",
      "Iteration 33600 => Loss: 46.19770176988367182958\n",
      "Iteration 33601 => Loss: 46.19753964159134795864\n",
      "Iteration 33602 => Loss: 46.19737751457138585920\n",
      "Iteration 33603 => Loss: 46.19721538882380684754\n",
      "Iteration 33604 => Loss: 46.19705326434855408024\n",
      "Iteration 33605 => Loss: 46.19689114114567018987\n",
      "Iteration 33606 => Loss: 46.19672901921511254386\n",
      "Iteration 33607 => Loss: 46.19656689855688114221\n",
      "Iteration 33608 => Loss: 46.19640477917094756322\n",
      "Iteration 33609 => Loss: 46.19624266105733312315\n",
      "Iteration 33610 => Loss: 46.19608054421599518946\n",
      "Iteration 33611 => Loss: 46.19591842864696218385\n",
      "Iteration 33612 => Loss: 46.19575631435019147375\n",
      "Iteration 33613 => Loss: 46.19559420132570437545\n",
      "Iteration 33614 => Loss: 46.19543208957346536181\n",
      "Iteration 33615 => Loss: 46.19526997909346022197\n",
      "Iteration 33616 => Loss: 46.19510786988568185052\n",
      "Iteration 33617 => Loss: 46.19494576195014445830\n",
      "Iteration 33618 => Loss: 46.19478365528682672903\n",
      "Iteration 33619 => Loss: 46.19462154989570024100\n",
      "Iteration 33620 => Loss: 46.19445944577676499421\n",
      "Iteration 33621 => Loss: 46.19429734293001388323\n",
      "Iteration 33622 => Loss: 46.19413524135545401350\n",
      "Iteration 33623 => Loss: 46.19397314105303564702\n",
      "Iteration 33624 => Loss: 46.19381104202279431092\n",
      "Iteration 33625 => Loss: 46.19364894426470158351\n",
      "Iteration 33626 => Loss: 46.19348684777872193763\n",
      "Iteration 33627 => Loss: 46.19332475256486958415\n",
      "Iteration 33628 => Loss: 46.19316265862315162849\n",
      "Iteration 33629 => Loss: 46.19300056595352543809\n",
      "Iteration 33630 => Loss: 46.19283847455596969667\n",
      "Iteration 33631 => Loss: 46.19267638443054124764\n",
      "Iteration 33632 => Loss: 46.19251429557716193131\n",
      "Iteration 33633 => Loss: 46.19235220799586016938\n",
      "Iteration 33634 => Loss: 46.19219012168661464557\n",
      "Iteration 33635 => Loss: 46.19202803664940404360\n",
      "Iteration 33636 => Loss: 46.19186595288422836347\n",
      "Iteration 33637 => Loss: 46.19170387039108049976\n",
      "Iteration 33638 => Loss: 46.19154178916994624160\n",
      "Iteration 33639 => Loss: 46.19137970922083269443\n",
      "Iteration 33640 => Loss: 46.19121763054370433110\n",
      "Iteration 33641 => Loss: 46.19105555313853272992\n",
      "Iteration 33642 => Loss: 46.19089347700535341801\n",
      "Iteration 33643 => Loss: 46.19073140214415928995\n",
      "Iteration 33644 => Loss: 46.19056932855489350231\n",
      "Iteration 33645 => Loss: 46.19040725623759868768\n",
      "Iteration 33646 => Loss: 46.19024518519221089718\n",
      "Iteration 33647 => Loss: 46.19008311541876565798\n",
      "Iteration 33648 => Loss: 46.18992104691722744292\n",
      "Iteration 33649 => Loss: 46.18975897968760335743\n",
      "Iteration 33650 => Loss: 46.18959691372985787439\n",
      "Iteration 33651 => Loss: 46.18943484904401231006\n",
      "Iteration 33652 => Loss: 46.18927278563003824274\n",
      "Iteration 33653 => Loss: 46.18911072348793567244\n",
      "Iteration 33654 => Loss: 46.18894866261769038829\n",
      "Iteration 33655 => Loss: 46.18878660301928107401\n",
      "Iteration 33656 => Loss: 46.18862454469270772961\n",
      "Iteration 33657 => Loss: 46.18846248763796324965\n",
      "Iteration 33658 => Loss: 46.18830043185501921243\n",
      "Iteration 33659 => Loss: 46.18813837734389693424\n",
      "Iteration 33660 => Loss: 46.18797632410456088792\n",
      "Iteration 33661 => Loss: 46.18781427213701107348\n",
      "Iteration 33662 => Loss: 46.18765222144124749093\n",
      "Iteration 33663 => Loss: 46.18749017201724171855\n",
      "Iteration 33664 => Loss: 46.18732812386499375634\n",
      "Iteration 33665 => Loss: 46.18716607698448228803\n",
      "Iteration 33666 => Loss: 46.18700403137571441903\n",
      "Iteration 33667 => Loss: 46.18684198703866172764\n",
      "Iteration 33668 => Loss: 46.18667994397334553014\n",
      "Iteration 33669 => Loss: 46.18651790217970898311\n",
      "Iteration 33670 => Loss: 46.18635586165779471912\n",
      "Iteration 33671 => Loss: 46.18619382240753878932\n",
      "Iteration 33672 => Loss: 46.18603178442896961542\n",
      "Iteration 33673 => Loss: 46.18586974772206588113\n",
      "Iteration 33674 => Loss: 46.18570771228682048104\n",
      "Iteration 33675 => Loss: 46.18554567812321920428\n",
      "Iteration 33676 => Loss: 46.18538364523125494543\n",
      "Iteration 33677 => Loss: 46.18522161361092770449\n",
      "Iteration 33678 => Loss: 46.18505958326218774346\n",
      "Iteration 33679 => Loss: 46.18489755418507058948\n",
      "Iteration 33680 => Loss: 46.18473552637956913713\n",
      "Iteration 33681 => Loss: 46.18457349984561943756\n",
      "Iteration 33682 => Loss: 46.18441147458325701791\n",
      "Iteration 33683 => Loss: 46.18424945059246766732\n",
      "Iteration 33684 => Loss: 46.18408742787322296408\n",
      "Iteration 33685 => Loss: 46.18392540642553001362\n",
      "Iteration 33686 => Loss: 46.18376338624937460509\n",
      "Iteration 33687 => Loss: 46.18360136734474252762\n",
      "Iteration 33688 => Loss: 46.18343934971161957037\n",
      "Iteration 33689 => Loss: 46.18327733335001283876\n",
      "Iteration 33690 => Loss: 46.18311531825990812195\n",
      "Iteration 33691 => Loss: 46.18295330444128410363\n",
      "Iteration 33692 => Loss: 46.18279129189411236212\n",
      "Iteration 33693 => Loss: 46.18262928061844263539\n",
      "Iteration 33694 => Loss: 46.18246727061418965832\n",
      "Iteration 33695 => Loss: 46.18230526188141737975\n",
      "Iteration 33696 => Loss: 46.18214325442007606171\n",
      "Iteration 33697 => Loss: 46.18198124823015149332\n",
      "Iteration 33698 => Loss: 46.18181924331164367459\n",
      "Iteration 33699 => Loss: 46.18165723966454550009\n",
      "Iteration 33700 => Loss: 46.18149523728881433726\n",
      "Iteration 33701 => Loss: 46.18133323618453545123\n",
      "Iteration 33702 => Loss: 46.18117123635155962802\n",
      "Iteration 33703 => Loss: 46.18100923778999344904\n",
      "Iteration 33704 => Loss: 46.18084724049977296545\n",
      "Iteration 33705 => Loss: 46.18068524448089817724\n",
      "Iteration 33706 => Loss: 46.18052324973336908442\n",
      "Iteration 33707 => Loss: 46.18036125625714305443\n",
      "Iteration 33708 => Loss: 46.18019926405224140353\n",
      "Iteration 33709 => Loss: 46.18003727311865702632\n",
      "Iteration 33710 => Loss: 46.17987528345636150107\n",
      "Iteration 33711 => Loss: 46.17971329506536903864\n",
      "Iteration 33712 => Loss: 46.17955130794564411190\n",
      "Iteration 33713 => Loss: 46.17938932209715829913\n",
      "Iteration 33714 => Loss: 46.17922733751997554918\n",
      "Iteration 33715 => Loss: 46.17906535421401059693\n",
      "Iteration 33716 => Loss: 46.17890337217928475866\n",
      "Iteration 33717 => Loss: 46.17874139141577671808\n",
      "Iteration 33718 => Loss: 46.17857941192350779147\n",
      "Iteration 33719 => Loss: 46.17841743370241402999\n",
      "Iteration 33720 => Loss: 46.17825545675253806621\n",
      "Iteration 33721 => Loss: 46.17809348107387990012\n",
      "Iteration 33722 => Loss: 46.17793150666634005574\n",
      "Iteration 33723 => Loss: 46.17776953352998958735\n",
      "Iteration 33724 => Loss: 46.17760756166480717866\n",
      "Iteration 33725 => Loss: 46.17744559107075730253\n",
      "Iteration 33726 => Loss: 46.17728362174784706440\n",
      "Iteration 33727 => Loss: 46.17712165369606225340\n",
      "Iteration 33728 => Loss: 46.17695968691540286954\n",
      "Iteration 33729 => Loss: 46.17679772140584049112\n",
      "Iteration 33730 => Loss: 46.17663575716738932897\n",
      "Iteration 33731 => Loss: 46.17647379420002096140\n",
      "Iteration 33732 => Loss: 46.17631183250372117755\n",
      "Iteration 33733 => Loss: 46.17614987207848997741\n",
      "Iteration 33734 => Loss: 46.17598791292429893929\n",
      "Iteration 33735 => Loss: 46.17582595504119069574\n",
      "Iteration 33736 => Loss: 46.17566399842907998163\n",
      "Iteration 33737 => Loss: 46.17550204308802364039\n",
      "Iteration 33738 => Loss: 46.17534008901797903945\n",
      "Iteration 33739 => Loss: 46.17517813621891775711\n",
      "Iteration 33740 => Loss: 46.17501618469089663677\n",
      "Iteration 33741 => Loss: 46.17485423443383751874\n",
      "Iteration 33742 => Loss: 46.17469228544776171930\n",
      "Iteration 33743 => Loss: 46.17453033773263371131\n",
      "Iteration 33744 => Loss: 46.17436839128851033820\n",
      "Iteration 33745 => Loss: 46.17420644611528501855\n",
      "Iteration 33746 => Loss: 46.17404450221300749035\n",
      "Iteration 33747 => Loss: 46.17388255958167064819\n",
      "Iteration 33748 => Loss: 46.17372061822124607033\n",
      "Iteration 33749 => Loss: 46.17355867813172665137\n",
      "Iteration 33750 => Loss: 46.17339673931311949673\n",
      "Iteration 33751 => Loss: 46.17323480176537486841\n",
      "Iteration 33752 => Loss: 46.17307286548852118813\n",
      "Iteration 33753 => Loss: 46.17291093048252292874\n",
      "Iteration 33754 => Loss: 46.17274899674739430111\n",
      "Iteration 33755 => Loss: 46.17258706428312109438\n",
      "Iteration 33756 => Loss: 46.17242513308967488683\n",
      "Iteration 33757 => Loss: 46.17226320316705567848\n",
      "Iteration 33758 => Loss: 46.17210127451524215303\n",
      "Iteration 33759 => Loss: 46.17193934713426273220\n",
      "Iteration 33760 => Loss: 46.17177742102407478342\n",
      "Iteration 33761 => Loss: 46.17161549618465699041\n",
      "Iteration 33762 => Loss: 46.17145357261600935317\n",
      "Iteration 33763 => Loss: 46.17129165031816029341\n",
      "Iteration 33764 => Loss: 46.17112972929103875686\n",
      "Iteration 33765 => Loss: 46.17096780953469448150\n",
      "Iteration 33766 => Loss: 46.17080589104907062392\n",
      "Iteration 33767 => Loss: 46.17064397383419560583\n",
      "Iteration 33768 => Loss: 46.17048205788998416210\n",
      "Iteration 33769 => Loss: 46.17032014321652155786\n",
      "Iteration 33770 => Loss: 46.17015822981376516054\n",
      "Iteration 33771 => Loss: 46.16999631768168654844\n",
      "Iteration 33772 => Loss: 46.16983440682028572155\n",
      "Iteration 33773 => Loss: 46.16967249722954846902\n",
      "Iteration 33774 => Loss: 46.16951058890947479085\n",
      "Iteration 33775 => Loss: 46.16934868186005047619\n",
      "Iteration 33776 => Loss: 46.16918677608124710332\n",
      "Iteration 33777 => Loss: 46.16902487157307177768\n",
      "Iteration 33778 => Loss: 46.16886296833553871011\n",
      "Iteration 33779 => Loss: 46.16870106636860526805\n",
      "Iteration 33780 => Loss: 46.16853916567225724066\n",
      "Iteration 33781 => Loss: 46.16837726624650883878\n",
      "Iteration 33782 => Loss: 46.16821536809134585155\n",
      "Iteration 33783 => Loss: 46.16805347120673985728\n",
      "Iteration 33784 => Loss: 46.16789157559269085596\n",
      "Iteration 33785 => Loss: 46.16772968124917042587\n",
      "Iteration 33786 => Loss: 46.16756778817623541045\n",
      "Iteration 33787 => Loss: 46.16740589637378633370\n",
      "Iteration 33788 => Loss: 46.16724400584189424990\n",
      "Iteration 33789 => Loss: 46.16708211658047389392\n",
      "Iteration 33790 => Loss: 46.16692022858956789833\n",
      "Iteration 33791 => Loss: 46.16675834186915494683\n",
      "Iteration 33792 => Loss: 46.16659645641922082859\n",
      "Iteration 33793 => Loss: 46.16643457223972291104\n",
      "Iteration 33794 => Loss: 46.16627268933073224844\n",
      "Iteration 33795 => Loss: 46.16611080769216357567\n",
      "Iteration 33796 => Loss: 46.16594892732404531444\n",
      "Iteration 33797 => Loss: 46.16578704822634193761\n",
      "Iteration 33798 => Loss: 46.16562517039905344518\n",
      "Iteration 33799 => Loss: 46.16546329384219404801\n",
      "Iteration 33800 => Loss: 46.16530141855571400811\n",
      "Iteration 33801 => Loss: 46.16513954453963464175\n",
      "Iteration 33802 => Loss: 46.16497767179392752723\n",
      "Iteration 33803 => Loss: 46.16481580031859976998\n",
      "Iteration 33804 => Loss: 46.16465393011361584286\n",
      "Iteration 33805 => Loss: 46.16449206117899706214\n",
      "Iteration 33806 => Loss: 46.16433019351470790070\n",
      "Iteration 33807 => Loss: 46.16416832712074125311\n",
      "Iteration 33808 => Loss: 46.16400646199710422479\n",
      "Iteration 33809 => Loss: 46.16384459814376839404\n",
      "Iteration 33810 => Loss: 46.16368273556073376085\n",
      "Iteration 33811 => Loss: 46.16352087424800032522\n",
      "Iteration 33812 => Loss: 46.16335901420553966545\n",
      "Iteration 33813 => Loss: 46.16319715543333046526\n",
      "Iteration 33814 => Loss: 46.16303529793140114634\n",
      "Iteration 33815 => Loss: 46.16287344169971618157\n",
      "Iteration 33816 => Loss: 46.16271158673826846552\n",
      "Iteration 33817 => Loss: 46.16254973304705089276\n",
      "Iteration 33818 => Loss: 46.16238788062604214701\n",
      "Iteration 33819 => Loss: 46.16222602947525643913\n",
      "Iteration 33820 => Loss: 46.16206417959465113654\n",
      "Iteration 33821 => Loss: 46.16190233098426176639\n",
      "Iteration 33822 => Loss: 46.16174048364403859068\n",
      "Iteration 33823 => Loss: 46.16157863757398871485\n",
      "Iteration 33824 => Loss: 46.16141679277409082260\n",
      "Iteration 33825 => Loss: 46.16125494924434491395\n",
      "Iteration 33826 => Loss: 46.16109310698474388346\n",
      "Iteration 33827 => Loss: 46.16093126599527352028\n",
      "Iteration 33828 => Loss: 46.16076942627591250812\n",
      "Iteration 33829 => Loss: 46.16060758782666795241\n",
      "Iteration 33830 => Loss: 46.16044575064753274773\n",
      "Iteration 33831 => Loss: 46.16028391473847136695\n",
      "Iteration 33832 => Loss: 46.16012208009948381005\n",
      "Iteration 33833 => Loss: 46.15996024673059139332\n",
      "Iteration 33834 => Loss: 46.15979841463173016791\n",
      "Iteration 33835 => Loss: 46.15963658380291434469\n",
      "Iteration 33836 => Loss: 46.15947475424417945078\n",
      "Iteration 33837 => Loss: 46.15931292595543311563\n",
      "Iteration 33838 => Loss: 46.15915109893673218266\n",
      "Iteration 33839 => Loss: 46.15898927318803401931\n",
      "Iteration 33840 => Loss: 46.15882744870933862558\n",
      "Iteration 33841 => Loss: 46.15866562550063179060\n",
      "Iteration 33842 => Loss: 46.15850380356190640896\n",
      "Iteration 33843 => Loss: 46.15834198289314826980\n",
      "Iteration 33844 => Loss: 46.15818016349435026768\n",
      "Iteration 33845 => Loss: 46.15801834536550529720\n",
      "Iteration 33846 => Loss: 46.15785652850659914748\n",
      "Iteration 33847 => Loss: 46.15769471291760339682\n",
      "Iteration 33848 => Loss: 46.15753289859856067778\n",
      "Iteration 33849 => Loss: 46.15737108554942125238\n",
      "Iteration 33850 => Loss: 46.15720927377014959347\n",
      "Iteration 33851 => Loss: 46.15704746326080254448\n",
      "Iteration 33852 => Loss: 46.15688565402133747284\n",
      "Iteration 33853 => Loss: 46.15672384605172595684\n",
      "Iteration 33854 => Loss: 46.15656203935198220734\n",
      "Iteration 33855 => Loss: 46.15640023392210622433\n",
      "Iteration 33856 => Loss: 46.15623842976202695354\n",
      "Iteration 33857 => Loss: 46.15607662687181544925\n",
      "Iteration 33858 => Loss: 46.15591482525140065718\n",
      "Iteration 33859 => Loss: 46.15575302490081810447\n",
      "Iteration 33860 => Loss: 46.15559122582002515855\n",
      "Iteration 33861 => Loss: 46.15542942800902181943\n",
      "Iteration 33862 => Loss: 46.15526763146777966540\n",
      "Iteration 33863 => Loss: 46.15510583619634843444\n",
      "Iteration 33864 => Loss: 46.15494404219465707229\n",
      "Iteration 33865 => Loss: 46.15478224946271268436\n",
      "Iteration 33866 => Loss: 46.15462045800052237610\n",
      "Iteration 33867 => Loss: 46.15445866780804351492\n",
      "Iteration 33868 => Loss: 46.15429687888531162798\n",
      "Iteration 33869 => Loss: 46.15413509123226987185\n",
      "Iteration 33870 => Loss: 46.15397330484893245739\n",
      "Iteration 33871 => Loss: 46.15381151973528517374\n",
      "Iteration 33872 => Loss: 46.15364973589132802090\n",
      "Iteration 33873 => Loss: 46.15348795331703968259\n",
      "Iteration 33874 => Loss: 46.15332617201240594795\n",
      "Iteration 33875 => Loss: 46.15316439197744813328\n",
      "Iteration 33876 => Loss: 46.15300261321209518428\n",
      "Iteration 33877 => Loss: 46.15284083571638262811\n",
      "Iteration 33878 => Loss: 46.15267905949031046475\n",
      "Iteration 33879 => Loss: 46.15251728453383606166\n",
      "Iteration 33880 => Loss: 46.15235551084695941881\n",
      "Iteration 33881 => Loss: 46.15219373842968053623\n",
      "Iteration 33882 => Loss: 46.15203196728197809762\n",
      "Iteration 33883 => Loss: 46.15187019740384499755\n",
      "Iteration 33884 => Loss: 46.15170842879529544689\n",
      "Iteration 33885 => Loss: 46.15154666145626549678\n",
      "Iteration 33886 => Loss: 46.15138489538679777979\n",
      "Iteration 33887 => Loss: 46.15122313058685676879\n",
      "Iteration 33888 => Loss: 46.15106136705642114748\n",
      "Iteration 33889 => Loss: 46.15089960479551933759\n",
      "Iteration 33890 => Loss: 46.15073784380412291739\n",
      "Iteration 33891 => Loss: 46.15057608408219635976\n",
      "Iteration 33892 => Loss: 46.15041432562976808640\n",
      "Iteration 33893 => Loss: 46.15025256844680257018\n",
      "Iteration 33894 => Loss: 46.15009081253332112738\n",
      "Iteration 33895 => Loss: 46.14992905788925270372\n",
      "Iteration 33896 => Loss: 46.14976730451465414262\n",
      "Iteration 33897 => Loss: 46.14960555240948281153\n",
      "Iteration 33898 => Loss: 46.14944380157372449958\n",
      "Iteration 33899 => Loss: 46.14928205200740052305\n",
      "Iteration 33900 => Loss: 46.14912030371043982768\n",
      "Iteration 33901 => Loss: 46.14895855668291346774\n",
      "Iteration 33902 => Loss: 46.14879681092473617809\n",
      "Iteration 33903 => Loss: 46.14863506643594348589\n",
      "Iteration 33904 => Loss: 46.14847332321652828568\n",
      "Iteration 33905 => Loss: 46.14831158126644083950\n",
      "Iteration 33906 => Loss: 46.14814984058570956904\n",
      "Iteration 33907 => Loss: 46.14798810117431315803\n",
      "Iteration 33908 => Loss: 46.14782636303223739560\n",
      "Iteration 33909 => Loss: 46.14766462615944675463\n",
      "Iteration 33910 => Loss: 46.14750289055599097310\n",
      "Iteration 33911 => Loss: 46.14734115622181320759\n",
      "Iteration 33912 => Loss: 46.14717942315694187982\n",
      "Iteration 33913 => Loss: 46.14701769136130593552\n",
      "Iteration 33914 => Loss: 46.14685596083495511266\n",
      "Iteration 33915 => Loss: 46.14669423157785388412\n",
      "Iteration 33916 => Loss: 46.14653250358998803904\n",
      "Iteration 33917 => Loss: 46.14637077687135757742\n",
      "Iteration 33918 => Loss: 46.14620905142195539383\n",
      "Iteration 33919 => Loss: 46.14604732724177438286\n",
      "Iteration 33920 => Loss: 46.14588560433079322820\n",
      "Iteration 33921 => Loss: 46.14572388268899061359\n",
      "Iteration 33922 => Loss: 46.14556216231638074987\n",
      "Iteration 33923 => Loss: 46.14540044321293521534\n",
      "Iteration 33924 => Loss: 46.14523872537866111543\n",
      "Iteration 33925 => Loss: 46.14507700881353713385\n",
      "Iteration 33926 => Loss: 46.14491529351755616517\n",
      "Iteration 33927 => Loss: 46.14475357949071110397\n",
      "Iteration 33928 => Loss: 46.14459186673298773940\n",
      "Iteration 33929 => Loss: 46.14443015524438607144\n",
      "Iteration 33930 => Loss: 46.14426844502486346755\n",
      "Iteration 33931 => Loss: 46.14410673607444834943\n",
      "Iteration 33932 => Loss: 46.14394502839311229536\n",
      "Iteration 33933 => Loss: 46.14378332198086241078\n",
      "Iteration 33934 => Loss: 46.14362161683767027398\n",
      "Iteration 33935 => Loss: 46.14345991296352167410\n",
      "Iteration 33936 => Loss: 46.14329821035844503285\n",
      "Iteration 33937 => Loss: 46.14313650902236929596\n",
      "Iteration 33938 => Loss: 46.14297480895532999057\n",
      "Iteration 33939 => Loss: 46.14281311015729869496\n",
      "Iteration 33940 => Loss: 46.14265141262827540913\n",
      "Iteration 33941 => Loss: 46.14248971636824592224\n",
      "Iteration 33942 => Loss: 46.14232802137719602342\n",
      "Iteration 33943 => Loss: 46.14216632765513992354\n",
      "Iteration 33944 => Loss: 46.14200463520202788459\n",
      "Iteration 33945 => Loss: 46.14184294401787411743\n",
      "Iteration 33946 => Loss: 46.14168125410265730579\n",
      "Iteration 33947 => Loss: 46.14151956545637744966\n",
      "Iteration 33948 => Loss: 46.14135787807902033819\n",
      "Iteration 33949 => Loss: 46.14119619197058597138\n",
      "Iteration 33950 => Loss: 46.14103450713103882208\n",
      "Iteration 33951 => Loss: 46.14087282356042152287\n",
      "Iteration 33952 => Loss: 46.14071114125864170319\n",
      "Iteration 33953 => Loss: 46.14054946022575620646\n",
      "Iteration 33954 => Loss: 46.14038778046176503267\n",
      "Iteration 33955 => Loss: 46.14022610196660423298\n",
      "Iteration 33956 => Loss: 46.14006442474027380740\n",
      "Iteration 33957 => Loss: 46.13990274878278796677\n",
      "Iteration 33958 => Loss: 46.13974107409412539482\n",
      "Iteration 33959 => Loss: 46.13957940067427898612\n",
      "Iteration 33960 => Loss: 46.13941772852325584608\n",
      "Iteration 33961 => Loss: 46.13925605764099202588\n",
      "Iteration 33962 => Loss: 46.13909438802753015807\n",
      "Iteration 33963 => Loss: 46.13893271968284892637\n",
      "Iteration 33964 => Loss: 46.13877105260691990907\n",
      "Iteration 33965 => Loss: 46.13860938679975731702\n",
      "Iteration 33966 => Loss: 46.13844772226131851767\n",
      "Iteration 33967 => Loss: 46.13828605899164614357\n",
      "Iteration 33968 => Loss: 46.13812439699069045673\n",
      "Iteration 33969 => Loss: 46.13796273625842303545\n",
      "Iteration 33970 => Loss: 46.13780107679489361772\n",
      "Iteration 33971 => Loss: 46.13763941860003114925\n",
      "Iteration 33972 => Loss: 46.13747776167386405177\n",
      "Iteration 33973 => Loss: 46.13731610601637811442\n",
      "Iteration 33974 => Loss: 46.13715445162755202091\n",
      "Iteration 33975 => Loss: 46.13699279850739287667\n",
      "Iteration 33976 => Loss: 46.13683114665586515457\n",
      "Iteration 33977 => Loss: 46.13666949607296885461\n",
      "Iteration 33978 => Loss: 46.13650784675871818763\n",
      "Iteration 33979 => Loss: 46.13634619871307052108\n",
      "Iteration 33980 => Loss: 46.13618455193601164410\n",
      "Iteration 33981 => Loss: 46.13602290642757708383\n",
      "Iteration 33982 => Loss: 46.13586126218771710228\n",
      "Iteration 33983 => Loss: 46.13569961921643169944\n",
      "Iteration 33984 => Loss: 46.13553797751369955904\n",
      "Iteration 33985 => Loss: 46.13537633707953489193\n",
      "Iteration 33986 => Loss: 46.13521469791392348725\n",
      "Iteration 33987 => Loss: 46.13505306001682981787\n",
      "Iteration 33988 => Loss: 46.13489142338828941092\n",
      "Iteration 33989 => Loss: 46.13472978802822410671\n",
      "Iteration 33990 => Loss: 46.13456815393669785408\n",
      "Iteration 33991 => Loss: 46.13440652111365380961\n",
      "Iteration 33992 => Loss: 46.13424488955909197330\n",
      "Iteration 33993 => Loss: 46.13408325927301945057\n",
      "Iteration 33994 => Loss: 46.13392163025542913601\n",
      "Iteration 33995 => Loss: 46.13376000250625708077\n",
      "Iteration 33996 => Loss: 46.13359837602553170655\n",
      "Iteration 33997 => Loss: 46.13343675081326722420\n",
      "Iteration 33998 => Loss: 46.13327512686939968489\n",
      "Iteration 33999 => Loss: 46.13311350419398593203\n",
      "Iteration 34000 => Loss: 46.13295188278695491135\n",
      "Iteration 34001 => Loss: 46.13279026264833504456\n",
      "Iteration 34002 => Loss: 46.13262864377806948823\n",
      "Iteration 34003 => Loss: 46.13246702617620798037\n",
      "Iteration 34004 => Loss: 46.13230540984271499383\n",
      "Iteration 34005 => Loss: 46.13214379477758342318\n",
      "Iteration 34006 => Loss: 46.13198218098077063587\n",
      "Iteration 34007 => Loss: 46.13182056845231926445\n",
      "Iteration 34008 => Loss: 46.13165895719219378179\n",
      "Iteration 34009 => Loss: 46.13149734720034444990\n",
      "Iteration 34010 => Loss: 46.13133573847684942848\n",
      "Iteration 34011 => Loss: 46.13117413102163055783\n",
      "Iteration 34012 => Loss: 46.13101252483470915422\n",
      "Iteration 34013 => Loss: 46.13085091991604969053\n",
      "Iteration 34014 => Loss: 46.13068931626567348303\n",
      "Iteration 34015 => Loss: 46.13052771388353079374\n",
      "Iteration 34016 => Loss: 46.13036611276965004436\n",
      "Iteration 34017 => Loss: 46.13020451292401702403\n",
      "Iteration 34018 => Loss: 46.13004291434659620563\n",
      "Iteration 34019 => Loss: 46.12988131703739469458\n",
      "Iteration 34020 => Loss: 46.12971972099639828002\n",
      "Iteration 34021 => Loss: 46.12955812622360696196\n",
      "Iteration 34022 => Loss: 46.12939653271900652953\n",
      "Iteration 34023 => Loss: 46.12923494048257566646\n",
      "Iteration 34024 => Loss: 46.12907334951430016190\n",
      "Iteration 34025 => Loss: 46.12891175981420843755\n",
      "Iteration 34026 => Loss: 46.12875017138224364999\n",
      "Iteration 34027 => Loss: 46.12858858421841290465\n",
      "Iteration 34028 => Loss: 46.12842699832272330696\n",
      "Iteration 34029 => Loss: 46.12826541369516064606\n",
      "Iteration 34030 => Loss: 46.12810383033568939481\n",
      "Iteration 34031 => Loss: 46.12794224824430955323\n",
      "Iteration 34032 => Loss: 46.12778066742104954301\n",
      "Iteration 34033 => Loss: 46.12761908786585252074\n",
      "Iteration 34034 => Loss: 46.12745750957869006470\n",
      "Iteration 34035 => Loss: 46.12729593255962612375\n",
      "Iteration 34036 => Loss: 46.12713435680858964361\n",
      "Iteration 34037 => Loss: 46.12697278232559483513\n",
      "Iteration 34038 => Loss: 46.12681120911062038203\n",
      "Iteration 34039 => Loss: 46.12664963716367338975\n",
      "Iteration 34040 => Loss: 46.12648806648473964742\n",
      "Iteration 34041 => Loss: 46.12632649707379073334\n",
      "Iteration 34042 => Loss: 46.12616492893085506921\n",
      "Iteration 34043 => Loss: 46.12600336205587581162\n",
      "Iteration 34044 => Loss: 46.12584179644887427685\n",
      "Iteration 34045 => Loss: 46.12568023210982204318\n",
      "Iteration 34046 => Loss: 46.12551866903871200520\n",
      "Iteration 34047 => Loss: 46.12535710723555126833\n",
      "Iteration 34048 => Loss: 46.12519554670032562171\n",
      "Iteration 34049 => Loss: 46.12503398743300664364\n",
      "Iteration 34050 => Loss: 46.12487242943361565040\n",
      "Iteration 34051 => Loss: 46.12471087270211000941\n",
      "Iteration 34052 => Loss: 46.12454931723848261527\n",
      "Iteration 34053 => Loss: 46.12438776304274767881\n",
      "Iteration 34054 => Loss: 46.12422621011488388376\n",
      "Iteration 34055 => Loss: 46.12406465845486280841\n",
      "Iteration 34056 => Loss: 46.12390310806270576904\n",
      "Iteration 34057 => Loss: 46.12374155893838434395\n",
      "Iteration 34058 => Loss: 46.12358001108190563855\n",
      "Iteration 34059 => Loss: 46.12341846449321991486\n",
      "Iteration 34060 => Loss: 46.12325691917234138373\n",
      "Iteration 34061 => Loss: 46.12309537511929846687\n",
      "Iteration 34062 => Loss: 46.12293383233399879373\n",
      "Iteration 34063 => Loss: 46.12277229081650631315\n",
      "Iteration 34064 => Loss: 46.12261075056677128714\n",
      "Iteration 34065 => Loss: 46.12244921158480792656\n",
      "Iteration 34066 => Loss: 46.12228767387058780969\n",
      "Iteration 34067 => Loss: 46.12212613742410383111\n",
      "Iteration 34068 => Loss: 46.12196460224535599082\n",
      "Iteration 34069 => Loss: 46.12180306833431586711\n",
      "Iteration 34070 => Loss: 46.12164153569099767083\n",
      "Iteration 34071 => Loss: 46.12148000431538008570\n",
      "Iteration 34072 => Loss: 46.12131847420745600630\n",
      "Iteration 34073 => Loss: 46.12115694536720411634\n",
      "Iteration 34074 => Loss: 46.12099541779462441582\n",
      "Iteration 34075 => Loss: 46.12083389148968848303\n",
      "Iteration 34076 => Loss: 46.12067236645241763426\n",
      "Iteration 34077 => Loss: 46.12051084268278344780\n",
      "Iteration 34078 => Loss: 46.12034932018077171278\n",
      "Iteration 34079 => Loss: 46.12018779894638242922\n",
      "Iteration 34080 => Loss: 46.12002627897962270254\n",
      "Iteration 34081 => Loss: 46.11986476028045700559\n",
      "Iteration 34082 => Loss: 46.11970324284887112753\n",
      "Iteration 34083 => Loss: 46.11954172668486506836\n",
      "Iteration 34084 => Loss: 46.11938021178844593351\n",
      "Iteration 34085 => Loss: 46.11921869815956398497\n",
      "Iteration 34086 => Loss: 46.11905718579824764447\n",
      "Iteration 34087 => Loss: 46.11889567470445427944\n",
      "Iteration 34088 => Loss: 46.11873416487822652243\n",
      "Iteration 34089 => Loss: 46.11857265631949331919\n",
      "Iteration 34090 => Loss: 46.11841114902826888056\n",
      "Iteration 34091 => Loss: 46.11824964300455320654\n",
      "Iteration 34092 => Loss: 46.11808813824833919170\n",
      "Iteration 34093 => Loss: 46.11792663475955578178\n",
      "Iteration 34094 => Loss: 46.11776513253829534733\n",
      "Iteration 34095 => Loss: 46.11760363158448683407\n",
      "Iteration 34096 => Loss: 46.11744213189811603115\n",
      "Iteration 34097 => Loss: 46.11728063347919004400\n",
      "Iteration 34098 => Loss: 46.11711913632770887261\n",
      "Iteration 34099 => Loss: 46.11695764044362988443\n",
      "Iteration 34100 => Loss: 46.11679614582698150116\n",
      "Iteration 34101 => Loss: 46.11663465247772819566\n",
      "Iteration 34102 => Loss: 46.11647316039585575709\n",
      "Iteration 34103 => Loss: 46.11631166958137129086\n",
      "Iteration 34104 => Loss: 46.11615018003425348070\n",
      "Iteration 34105 => Loss: 46.11598869175448811575\n",
      "Iteration 34106 => Loss: 46.11582720474210361772\n",
      "Iteration 34107 => Loss: 46.11566571899704314319\n",
      "Iteration 34108 => Loss: 46.11550423451930669216\n",
      "Iteration 34109 => Loss: 46.11534275130889426464\n",
      "Iteration 34110 => Loss: 46.11518126936580586062\n",
      "Iteration 34111 => Loss: 46.11501978869002726924\n",
      "Iteration 34112 => Loss: 46.11485830928152296337\n",
      "Iteration 34113 => Loss: 46.11469683114031425930\n",
      "Iteration 34114 => Loss: 46.11453535426634431360\n",
      "Iteration 34115 => Loss: 46.11437387865966286427\n",
      "Iteration 34116 => Loss: 46.11421240432022727873\n",
      "Iteration 34117 => Loss: 46.11405093124804466242\n",
      "Iteration 34118 => Loss: 46.11388945944309369906\n",
      "Iteration 34119 => Loss: 46.11372798890535307237\n",
      "Iteration 34120 => Loss: 46.11356651963482278234\n",
      "Iteration 34121 => Loss: 46.11340505163150282897\n",
      "Iteration 34122 => Loss: 46.11324358489537189598\n",
      "Iteration 34123 => Loss: 46.11308211942642998338\n",
      "Iteration 34124 => Loss: 46.11292065522465577487\n",
      "Iteration 34125 => Loss: 46.11275919229004927047\n",
      "Iteration 34126 => Loss: 46.11259773062260336474\n",
      "Iteration 34127 => Loss: 46.11243627022226121426\n",
      "Iteration 34128 => Loss: 46.11227481108907255702\n",
      "Iteration 34129 => Loss: 46.11211335322302318218\n",
      "Iteration 34130 => Loss: 46.11195189662406335174\n",
      "Iteration 34131 => Loss: 46.11179044129222148740\n",
      "Iteration 34132 => Loss: 46.11162898722747627289\n",
      "Iteration 34133 => Loss: 46.11146753442981349735\n",
      "Iteration 34134 => Loss: 46.11130608289919763365\n",
      "Iteration 34135 => Loss: 46.11114463263568552520\n",
      "Iteration 34136 => Loss: 46.11098318363919190688\n",
      "Iteration 34137 => Loss: 46.11082173590976651667\n",
      "Iteration 34138 => Loss: 46.11066028944735251116\n",
      "Iteration 34139 => Loss: 46.11049884425197831206\n",
      "Iteration 34140 => Loss: 46.11033740032361549765\n",
      "Iteration 34141 => Loss: 46.11017595766223564624\n",
      "Iteration 34142 => Loss: 46.11001451626788139038\n",
      "Iteration 34143 => Loss: 46.10985307614048878122\n",
      "Iteration 34144 => Loss: 46.10969163728006492420\n",
      "Iteration 34145 => Loss: 46.10953019968663824102\n",
      "Iteration 34146 => Loss: 46.10936876336013057198\n",
      "Iteration 34147 => Loss: 46.10920732830057744422\n",
      "Iteration 34148 => Loss: 46.10904589450797175232\n",
      "Iteration 34149 => Loss: 46.10888446198226375827\n",
      "Iteration 34150 => Loss: 46.10872303072348898922\n",
      "Iteration 34151 => Loss: 46.10856160073161191804\n",
      "Iteration 34152 => Loss: 46.10840017200662543928\n",
      "Iteration 34153 => Loss: 46.10823874454852955296\n",
      "Iteration 34154 => Loss: 46.10807731835731715364\n",
      "Iteration 34155 => Loss: 46.10791589343293850334\n",
      "Iteration 34156 => Loss: 46.10775446977544334004\n",
      "Iteration 34157 => Loss: 46.10759304738478192576\n",
      "Iteration 34158 => Loss: 46.10743162626095426049\n",
      "Iteration 34159 => Loss: 46.10727020640396034423\n",
      "Iteration 34160 => Loss: 46.10710878781376464985\n",
      "Iteration 34161 => Loss: 46.10694737049038138821\n",
      "Iteration 34162 => Loss: 46.10678595443379634844\n",
      "Iteration 34163 => Loss: 46.10662453964397400341\n",
      "Iteration 34164 => Loss: 46.10646312612097119654\n",
      "Iteration 34165 => Loss: 46.10630171386470266270\n",
      "Iteration 34166 => Loss: 46.10614030287520392903\n",
      "Iteration 34167 => Loss: 46.10597889315241815211\n",
      "Iteration 34168 => Loss: 46.10581748469639506993\n",
      "Iteration 34169 => Loss: 46.10565607750709204993\n",
      "Iteration 34170 => Loss: 46.10549467158450198667\n",
      "Iteration 34171 => Loss: 46.10533326692862488017\n",
      "Iteration 34172 => Loss: 46.10517186353943941413\n",
      "Iteration 34173 => Loss: 46.10501046141693137770\n",
      "Iteration 34174 => Loss: 46.10484906056110077088\n",
      "Iteration 34175 => Loss: 46.10468766097192627740\n",
      "Iteration 34176 => Loss: 46.10452626264942921352\n",
      "Iteration 34177 => Loss: 46.10436486559355984127\n",
      "Iteration 34178 => Loss: 46.10420346980436079320\n",
      "Iteration 34179 => Loss: 46.10404207528174680419\n",
      "Iteration 34180 => Loss: 46.10388068202576761223\n",
      "Iteration 34181 => Loss: 46.10371929003638058475\n",
      "Iteration 34182 => Loss: 46.10355789931361414347\n",
      "Iteration 34183 => Loss: 46.10339650985741144495\n",
      "Iteration 34184 => Loss: 46.10323512166778670007\n",
      "Iteration 34185 => Loss: 46.10307373474473280339\n",
      "Iteration 34186 => Loss: 46.10291234908822133320\n",
      "Iteration 34187 => Loss: 46.10275096469828071122\n",
      "Iteration 34188 => Loss: 46.10258958157486119944\n",
      "Iteration 34189 => Loss: 46.10242819971797700873\n",
      "Iteration 34190 => Loss: 46.10226681912759971738\n",
      "Iteration 34191 => Loss: 46.10210543980372932538\n",
      "Iteration 34192 => Loss: 46.10194406174635872731\n",
      "Iteration 34193 => Loss: 46.10178268495547371231\n",
      "Iteration 34194 => Loss: 46.10162130943105296410\n",
      "Iteration 34195 => Loss: 46.10145993517312490440\n",
      "Iteration 34196 => Loss: 46.10129856218163979520\n",
      "Iteration 34197 => Loss: 46.10113719045659763651\n",
      "Iteration 34198 => Loss: 46.10097581999799842833\n",
      "Iteration 34199 => Loss: 46.10081445080582795981\n",
      "Iteration 34200 => Loss: 46.10065308288007912552\n",
      "Iteration 34201 => Loss: 46.10049171622071639831\n",
      "Iteration 34202 => Loss: 46.10033035082776819991\n",
      "Iteration 34203 => Loss: 46.10016898670119189774\n",
      "Iteration 34204 => Loss: 46.10000762384101591351\n",
      "Iteration 34205 => Loss: 46.09984626224718340382\n",
      "Iteration 34206 => Loss: 46.09968490191972989578\n",
      "Iteration 34207 => Loss: 46.09952354285859854599\n",
      "Iteration 34208 => Loss: 46.09936218506383198701\n",
      "Iteration 34209 => Loss: 46.09920082853534495371\n",
      "Iteration 34210 => Loss: 46.09903947327322981664\n",
      "Iteration 34211 => Loss: 46.09887811927740841611\n",
      "Iteration 34212 => Loss: 46.09871676654787364669\n",
      "Iteration 34213 => Loss: 46.09855541508462550837\n",
      "Iteration 34214 => Loss: 46.09839406488767821202\n",
      "Iteration 34215 => Loss: 46.09823271595696780878\n",
      "Iteration 34216 => Loss: 46.09807136829255114208\n",
      "Iteration 34217 => Loss: 46.09791002189434294678\n",
      "Iteration 34218 => Loss: 46.09774867676239296088\n",
      "Iteration 34219 => Loss: 46.09758733289666565724\n",
      "Iteration 34220 => Loss: 46.09742599029716814130\n",
      "Iteration 34221 => Loss: 46.09726464896386488590\n",
      "Iteration 34222 => Loss: 46.09710330889677010191\n",
      "Iteration 34223 => Loss: 46.09694197009586247304\n",
      "Iteration 34224 => Loss: 46.09678063256112778845\n",
      "Iteration 34225 => Loss: 46.09661929629256604812\n",
      "Iteration 34226 => Loss: 46.09645796129014883036\n",
      "Iteration 34227 => Loss: 46.09629662755390455686\n",
      "Iteration 34228 => Loss: 46.09613529508376927879\n",
      "Iteration 34229 => Loss: 46.09597396387978562871\n",
      "Iteration 34230 => Loss: 46.09581263394192518490\n",
      "Iteration 34231 => Loss: 46.09565130527015952566\n",
      "Iteration 34232 => Loss: 46.09548997786448154557\n",
      "Iteration 34233 => Loss: 46.09532865172491256089\n",
      "Iteration 34234 => Loss: 46.09516732685142414994\n",
      "Iteration 34235 => Loss: 46.09500600324399499641\n",
      "Iteration 34236 => Loss: 46.09484468090262510032\n",
      "Iteration 34237 => Loss: 46.09468335982732156708\n",
      "Iteration 34238 => Loss: 46.09452204001802755329\n",
      "Iteration 34239 => Loss: 46.09436072147477858607\n",
      "Iteration 34240 => Loss: 46.09419940419757466543\n",
      "Iteration 34241 => Loss: 46.09403808818633763167\n",
      "Iteration 34242 => Loss: 46.09387677344111011735\n",
      "Iteration 34243 => Loss: 46.09371545996189212246\n",
      "Iteration 34244 => Loss: 46.09355414774863390903\n",
      "Iteration 34245 => Loss: 46.09339283680135679333\n",
      "Iteration 34246 => Loss: 46.09323152712002524822\n",
      "Iteration 34247 => Loss: 46.09307021870466769542\n",
      "Iteration 34248 => Loss: 46.09290891155522729150\n",
      "Iteration 34249 => Loss: 46.09274760567172535275\n",
      "Iteration 34250 => Loss: 46.09258630105414766831\n",
      "Iteration 34251 => Loss: 46.09242499770246581647\n",
      "Iteration 34252 => Loss: 46.09226369561669400809\n",
      "Iteration 34253 => Loss: 46.09210239479681803232\n",
      "Iteration 34254 => Loss: 46.09194109524281657286\n",
      "Iteration 34255 => Loss: 46.09177979695468962973\n",
      "Iteration 34256 => Loss: 46.09161849993241588663\n",
      "Iteration 34257 => Loss: 46.09145720417600244900\n",
      "Iteration 34258 => Loss: 46.09129590968541378970\n",
      "Iteration 34259 => Loss: 46.09113461646067122501\n",
      "Iteration 34260 => Loss: 46.09097332450175343865\n",
      "Iteration 34261 => Loss: 46.09081203380863200891\n",
      "Iteration 34262 => Loss: 46.09065074438132114665\n",
      "Iteration 34263 => Loss: 46.09048945621977821929\n",
      "Iteration 34264 => Loss: 46.09032816932403875398\n",
      "Iteration 34265 => Loss: 46.09016688369405301273\n",
      "Iteration 34266 => Loss: 46.09000559932984941724\n",
      "Iteration 34267 => Loss: 46.08984431623139244039\n",
      "Iteration 34268 => Loss: 46.08968303439867497673\n",
      "Iteration 34269 => Loss: 46.08952175383169702627\n",
      "Iteration 34270 => Loss: 46.08936047453042306188\n",
      "Iteration 34271 => Loss: 46.08919919649487439983\n",
      "Iteration 34272 => Loss: 46.08903791972500130214\n",
      "Iteration 34273 => Loss: 46.08887664422085350679\n",
      "Iteration 34274 => Loss: 46.08871536998237417038\n",
      "Iteration 34275 => Loss: 46.08855409700956329289\n",
      "Iteration 34276 => Loss: 46.08839282530241376890\n",
      "Iteration 34277 => Loss: 46.08823155486090428212\n",
      "Iteration 34278 => Loss: 46.08807028568507035970\n",
      "Iteration 34279 => Loss: 46.08790901777483384194\n",
      "Iteration 34280 => Loss: 46.08774775113023736139\n",
      "Iteration 34281 => Loss: 46.08758648575124539093\n",
      "Iteration 34282 => Loss: 46.08742522163787924683\n",
      "Iteration 34283 => Loss: 46.08726395879008919110\n",
      "Iteration 34284 => Loss: 46.08710269720786811831\n",
      "Iteration 34285 => Loss: 46.08694143689123023933\n",
      "Iteration 34286 => Loss: 46.08678017784015423786\n",
      "Iteration 34287 => Loss: 46.08661892005464011390\n",
      "Iteration 34288 => Loss: 46.08645766353464523490\n",
      "Iteration 34289 => Loss: 46.08629640828020512799\n",
      "Iteration 34290 => Loss: 46.08613515429128426604\n",
      "Iteration 34291 => Loss: 46.08597390156785422732\n",
      "Iteration 34292 => Loss: 46.08581265010995053899\n",
      "Iteration 34293 => Loss: 46.08565139991754477933\n",
      "Iteration 34294 => Loss: 46.08549015099060852663\n",
      "Iteration 34295 => Loss: 46.08532890332915599174\n",
      "Iteration 34296 => Loss: 46.08516765693315875296\n",
      "Iteration 34297 => Loss: 46.08500641180260970486\n",
      "Iteration 34298 => Loss: 46.08484516793751595287\n",
      "Iteration 34299 => Loss: 46.08468392533784196985\n",
      "Iteration 34300 => Loss: 46.08452268400358775580\n",
      "Iteration 34301 => Loss: 46.08436144393477462700\n",
      "Iteration 34302 => Loss: 46.08420020513133152917\n",
      "Iteration 34303 => Loss: 46.08403896759330109489\n",
      "Iteration 34304 => Loss: 46.08387773132066200787\n",
      "Iteration 34305 => Loss: 46.08371649631337874098\n",
      "Iteration 34306 => Loss: 46.08355526257147261049\n",
      "Iteration 34307 => Loss: 46.08339403009490808927\n",
      "Iteration 34308 => Loss: 46.08323279888369938817\n",
      "Iteration 34309 => Loss: 46.08307156893782519091\n",
      "Iteration 34310 => Loss: 46.08291034025724997036\n",
      "Iteration 34311 => Loss: 46.08274911284203056994\n",
      "Iteration 34312 => Loss: 46.08258788669208882993\n",
      "Iteration 34313 => Loss: 46.08242666180744606663\n",
      "Iteration 34314 => Loss: 46.08226543818808806918\n",
      "Iteration 34315 => Loss: 46.08210421583400062673\n",
      "Iteration 34316 => Loss: 46.08194299474517663384\n",
      "Iteration 34317 => Loss: 46.08178177492162319595\n",
      "Iteration 34318 => Loss: 46.08162055636330478592\n",
      "Iteration 34319 => Loss: 46.08145933907021429832\n",
      "Iteration 34320 => Loss: 46.08129812304234462772\n",
      "Iteration 34321 => Loss: 46.08113690827971709041\n",
      "Iteration 34322 => Loss: 46.08097569478228194839\n",
      "Iteration 34323 => Loss: 46.08081448255002499081\n",
      "Iteration 34324 => Loss: 46.08065327158297463939\n",
      "Iteration 34325 => Loss: 46.08049206188109536697\n",
      "Iteration 34326 => Loss: 46.08033085344435875186\n",
      "Iteration 34327 => Loss: 46.08016964627279321576\n",
      "Iteration 34328 => Loss: 46.08000844036637744239\n",
      "Iteration 34329 => Loss: 46.07984723572510432632\n",
      "Iteration 34330 => Loss: 46.07968603234893834042\n",
      "Iteration 34331 => Loss: 46.07952483023789369554\n",
      "Iteration 34332 => Loss: 46.07936362939194196997\n",
      "Iteration 34333 => Loss: 46.07920242981111158542\n",
      "Iteration 34334 => Loss: 46.07904123149535990933\n",
      "Iteration 34335 => Loss: 46.07888003444467983627\n",
      "Iteration 34336 => Loss: 46.07871883865905715538\n",
      "Iteration 34337 => Loss: 46.07855764413849897210\n",
      "Iteration 34338 => Loss: 46.07839645088300528641\n",
      "Iteration 34339 => Loss: 46.07823525889251214949\n",
      "Iteration 34340 => Loss: 46.07807406816706929931\n",
      "Iteration 34341 => Loss: 46.07791287870664831416\n",
      "Iteration 34342 => Loss: 46.07775169051121366692\n",
      "Iteration 34343 => Loss: 46.07759050358078667387\n",
      "Iteration 34344 => Loss: 46.07742931791533180785\n",
      "Iteration 34345 => Loss: 46.07726813351486327974\n",
      "Iteration 34346 => Loss: 46.07710695037937398411\n",
      "Iteration 34347 => Loss: 46.07694576850882128838\n",
      "Iteration 34348 => Loss: 46.07678458790321940342\n",
      "Iteration 34349 => Loss: 46.07662340856256832922\n",
      "Iteration 34350 => Loss: 46.07646223048684674950\n",
      "Iteration 34351 => Loss: 46.07630105367601913713\n",
      "Iteration 34352 => Loss: 46.07613987813012812467\n",
      "Iteration 34353 => Loss: 46.07597870384910265784\n",
      "Iteration 34354 => Loss: 46.07581753083297115836\n",
      "Iteration 34355 => Loss: 46.07565635908174073165\n",
      "Iteration 34356 => Loss: 46.07549518859534742887\n",
      "Iteration 34357 => Loss: 46.07533401937384098801\n",
      "Iteration 34358 => Loss: 46.07517285141716456565\n",
      "Iteration 34359 => Loss: 46.07501168472531816178\n",
      "Iteration 34360 => Loss: 46.07485051929832309270\n",
      "Iteration 34361 => Loss: 46.07468935513611540955\n",
      "Iteration 34362 => Loss: 46.07452819223873063947\n",
      "Iteration 34363 => Loss: 46.07436703060614036076\n",
      "Iteration 34364 => Loss: 46.07420587023836588969\n",
      "Iteration 34365 => Loss: 46.07404471113534327742\n",
      "Iteration 34366 => Loss: 46.07388355329708673480\n",
      "Iteration 34367 => Loss: 46.07372239672359626184\n",
      "Iteration 34368 => Loss: 46.07356124141485054224\n",
      "Iteration 34369 => Loss: 46.07340008737084247059\n",
      "Iteration 34370 => Loss: 46.07323893459157204688\n",
      "Iteration 34371 => Loss: 46.07307778307700374398\n",
      "Iteration 34372 => Loss: 46.07291663282716598360\n",
      "Iteration 34373 => Loss: 46.07275548384200902774\n",
      "Iteration 34374 => Loss: 46.07259433612154708726\n",
      "Iteration 34375 => Loss: 46.07243318966576595130\n",
      "Iteration 34376 => Loss: 46.07227204447463719816\n",
      "Iteration 34377 => Loss: 46.07211090054818924955\n",
      "Iteration 34378 => Loss: 46.07194975788639368375\n",
      "Iteration 34379 => Loss: 46.07178861648920786820\n",
      "Iteration 34380 => Loss: 46.07162747635668154089\n",
      "Iteration 34381 => Loss: 46.07146633748875075298\n",
      "Iteration 34382 => Loss: 46.07130519988544392618\n",
      "Iteration 34383 => Loss: 46.07114406354672553334\n",
      "Iteration 34384 => Loss: 46.07098292847260267990\n",
      "Iteration 34385 => Loss: 46.07082179466305404958\n",
      "Iteration 34386 => Loss: 46.07066066211809385322\n",
      "Iteration 34387 => Loss: 46.07049953083770077455\n",
      "Iteration 34388 => Loss: 46.07033840082181797015\n",
      "Iteration 34389 => Loss: 46.07017727207048807259\n",
      "Iteration 34390 => Loss: 46.07001614458371108185\n",
      "Iteration 34391 => Loss: 46.06985501836141594367\n",
      "Iteration 34392 => Loss: 46.06969389340366660690\n",
      "Iteration 34393 => Loss: 46.06953276971040622811\n",
      "Iteration 34394 => Loss: 46.06937164728163480731\n",
      "Iteration 34395 => Loss: 46.06921052611733813364\n",
      "Iteration 34396 => Loss: 46.06904940621752331253\n",
      "Iteration 34397 => Loss: 46.06888828758216192227\n",
      "Iteration 34398 => Loss: 46.06872717021124685743\n",
      "Iteration 34399 => Loss: 46.06856605410478522344\n",
      "Iteration 34400 => Loss: 46.06840493926272728231\n",
      "Iteration 34401 => Loss: 46.06824382568510856117\n",
      "Iteration 34402 => Loss: 46.06808271337190774375\n",
      "Iteration 34403 => Loss: 46.06792160232310351375\n",
      "Iteration 34404 => Loss: 46.06776049253870297662\n",
      "Iteration 34405 => Loss: 46.06759938401866349977\n",
      "Iteration 34406 => Loss: 46.06743827676299218865\n",
      "Iteration 34407 => Loss: 46.06727717077168904325\n",
      "Iteration 34408 => Loss: 46.06711606604473985271\n",
      "Iteration 34409 => Loss: 46.06695496258213751162\n",
      "Iteration 34410 => Loss: 46.06679386038384649282\n",
      "Iteration 34411 => Loss: 46.06663275944989521804\n",
      "Iteration 34412 => Loss: 46.06647165978024816013\n",
      "Iteration 34413 => Loss: 46.06631056137490531910\n",
      "Iteration 34414 => Loss: 46.06614946423385958951\n",
      "Iteration 34415 => Loss: 46.06598836835710386595\n",
      "Iteration 34416 => Loss: 46.06582727374459551584\n",
      "Iteration 34417 => Loss: 46.06566618039635585546\n",
      "Iteration 34418 => Loss: 46.06550508831237777940\n",
      "Iteration 34419 => Loss: 46.06534399749263997137\n",
      "Iteration 34420 => Loss: 46.06518290793713532594\n",
      "Iteration 34421 => Loss: 46.06502181964582831597\n",
      "Iteration 34422 => Loss: 46.06486073261877578489\n",
      "Iteration 34423 => Loss: 46.06469964685589246756\n",
      "Iteration 34424 => Loss: 46.06453856235722099655\n",
      "Iteration 34425 => Loss: 46.06437747912270452844\n",
      "Iteration 34426 => Loss: 46.06421639715239280122\n",
      "Iteration 34427 => Loss: 46.06405531644623607690\n",
      "Iteration 34428 => Loss: 46.06389423700422725005\n",
      "Iteration 34429 => Loss: 46.06373315882635921525\n",
      "Iteration 34430 => Loss: 46.06357208191262486707\n",
      "Iteration 34431 => Loss: 46.06341100626301710008\n",
      "Iteration 34432 => Loss: 46.06324993187752170343\n",
      "Iteration 34433 => Loss: 46.06308885875612446625\n",
      "Iteration 34434 => Loss: 46.06292778689885381027\n",
      "Iteration 34435 => Loss: 46.06276671630563157578\n",
      "Iteration 34436 => Loss: 46.06260564697647907906\n",
      "Iteration 34437 => Loss: 46.06244457891139632011\n",
      "Iteration 34438 => Loss: 46.06228351211037619350\n",
      "Iteration 34439 => Loss: 46.06212244657339738296\n",
      "Iteration 34440 => Loss: 46.06196138230045278306\n",
      "Iteration 34441 => Loss: 46.06180031929151397208\n",
      "Iteration 34442 => Loss: 46.06163925754661647716\n",
      "Iteration 34443 => Loss: 46.06147819706570345488\n",
      "Iteration 34444 => Loss: 46.06131713784879622153\n",
      "Iteration 34445 => Loss: 46.06115607989587346083\n",
      "Iteration 34446 => Loss: 46.06099502320692096191\n",
      "Iteration 34447 => Loss: 46.06083396778193161936\n",
      "Iteration 34448 => Loss: 46.06067291362091253859\n",
      "Iteration 34449 => Loss: 46.06051186072381398162\n",
      "Iteration 34450 => Loss: 46.06035080909065726473\n",
      "Iteration 34451 => Loss: 46.06018975872142817707\n",
      "Iteration 34452 => Loss: 46.06002870961610540235\n",
      "Iteration 34453 => Loss: 46.05986766177469604600\n",
      "Iteration 34454 => Loss: 46.05970661519720010801\n",
      "Iteration 34455 => Loss: 46.05954556988356074498\n",
      "Iteration 34456 => Loss: 46.05938452583381348404\n",
      "Iteration 34457 => Loss: 46.05922348304791569262\n",
      "Iteration 34458 => Loss: 46.05906244152588868701\n",
      "Iteration 34459 => Loss: 46.05890140126768272921\n",
      "Iteration 34460 => Loss: 46.05874036227334755722\n",
      "Iteration 34461 => Loss: 46.05857932454281211676\n",
      "Iteration 34462 => Loss: 46.05841828807610482954\n",
      "Iteration 34463 => Loss: 46.05825725287318306300\n",
      "Iteration 34464 => Loss: 46.05809621893408944970\n",
      "Iteration 34465 => Loss: 46.05793518625878135708\n",
      "Iteration 34466 => Loss: 46.05777415484721615258\n",
      "Iteration 34467 => Loss: 46.05761312469942225789\n",
      "Iteration 34468 => Loss: 46.05745209581539967303\n",
      "Iteration 34469 => Loss: 46.05729106819512708171\n",
      "Iteration 34470 => Loss: 46.05713004183856895679\n",
      "Iteration 34471 => Loss: 46.05696901674576793084\n",
      "Iteration 34472 => Loss: 46.05680799291665294959\n",
      "Iteration 34473 => Loss: 46.05664697035126664559\n",
      "Iteration 34474 => Loss: 46.05648594904958059715\n",
      "Iteration 34475 => Loss: 46.05632492901157348797\n",
      "Iteration 34476 => Loss: 46.05616391023722400178\n",
      "Iteration 34477 => Loss: 46.05600289272655345485\n",
      "Iteration 34478 => Loss: 46.05584187647954053091\n",
      "Iteration 34479 => Loss: 46.05568086149618522995\n",
      "Iteration 34480 => Loss: 46.05551984777645913027\n",
      "Iteration 34481 => Loss: 46.05535883532035512644\n",
      "Iteration 34482 => Loss: 46.05519782412786611303\n",
      "Iteration 34483 => Loss: 46.05503681419897787919\n",
      "Iteration 34484 => Loss: 46.05487580553372595205\n",
      "Iteration 34485 => Loss: 46.05471479813204638276\n",
      "Iteration 34486 => Loss: 46.05455379199393206591\n",
      "Iteration 34487 => Loss: 46.05439278711936879063\n",
      "Iteration 34488 => Loss: 46.05423178350839208406\n",
      "Iteration 34489 => Loss: 46.05407078116094510278\n",
      "Iteration 34490 => Loss: 46.05390978007705626851\n",
      "Iteration 34491 => Loss: 46.05374878025666873782\n",
      "Iteration 34492 => Loss: 46.05358778169981093242\n",
      "Iteration 34493 => Loss: 46.05342678440647574689\n",
      "Iteration 34494 => Loss: 46.05326578837662765409\n",
      "Iteration 34495 => Loss: 46.05310479361028086487\n",
      "Iteration 34496 => Loss: 46.05294380010738564124\n",
      "Iteration 34497 => Loss: 46.05278280786797040491\n",
      "Iteration 34498 => Loss: 46.05262181689200673418\n",
      "Iteration 34499 => Loss: 46.05246082717949462904\n",
      "Iteration 34500 => Loss: 46.05229983873044119491\n",
      "Iteration 34501 => Loss: 46.05213885154480379924\n",
      "Iteration 34502 => Loss: 46.05197786562258244203\n",
      "Iteration 34503 => Loss: 46.05181688096378422870\n",
      "Iteration 34504 => Loss: 46.05165589756835231583\n",
      "Iteration 34505 => Loss: 46.05149491543636486313\n",
      "Iteration 34506 => Loss: 46.05133393456770818375\n",
      "Iteration 34507 => Loss: 46.05117295496242491026\n",
      "Iteration 34508 => Loss: 46.05101197662051504267\n",
      "Iteration 34509 => Loss: 46.05085099954195726468\n",
      "Iteration 34510 => Loss: 46.05069002372673026002\n",
      "Iteration 34511 => Loss: 46.05052904917482692326\n",
      "Iteration 34512 => Loss: 46.05036807588626146526\n",
      "Iteration 34513 => Loss: 46.05020710386098414801\n",
      "Iteration 34514 => Loss: 46.05004613309902339324\n",
      "Iteration 34515 => Loss: 46.04988516360035077923\n",
      "Iteration 34516 => Loss: 46.04972419536497341142\n",
      "Iteration 34517 => Loss: 46.04956322839282023551\n",
      "Iteration 34518 => Loss: 46.04940226268396230580\n",
      "Iteration 34519 => Loss: 46.04924129823837830600\n",
      "Iteration 34520 => Loss: 46.04908033505598297097\n",
      "Iteration 34521 => Loss: 46.04891937313684024957\n",
      "Iteration 34522 => Loss: 46.04875841248092172009\n",
      "Iteration 34523 => Loss: 46.04859745308822027710\n",
      "Iteration 34524 => Loss: 46.04843649495870039345\n",
      "Iteration 34525 => Loss: 46.04827553809237628002\n",
      "Iteration 34526 => Loss: 46.04811458248924083136\n",
      "Iteration 34527 => Loss: 46.04795362814926562578\n",
      "Iteration 34528 => Loss: 46.04779267507246487412\n",
      "Iteration 34529 => Loss: 46.04763172325879594382\n",
      "Iteration 34530 => Loss: 46.04747077270830146745\n",
      "Iteration 34531 => Loss: 46.04730982342091749615\n",
      "Iteration 34532 => Loss: 46.04714887539664402993\n",
      "Iteration 34533 => Loss: 46.04698792863550238508\n",
      "Iteration 34534 => Loss: 46.04682698313745703445\n",
      "Iteration 34535 => Loss: 46.04666603890250087261\n",
      "Iteration 34536 => Loss: 46.04650509593061968872\n",
      "Iteration 34537 => Loss: 46.04634415422182058819\n",
      "Iteration 34538 => Loss: 46.04618321377607514933\n",
      "Iteration 34539 => Loss: 46.04602227459339758298\n",
      "Iteration 34540 => Loss: 46.04586133667375236200\n",
      "Iteration 34541 => Loss: 46.04570040001713948641\n",
      "Iteration 34542 => Loss: 46.04553946462355895619\n",
      "Iteration 34543 => Loss: 46.04537853049297524421\n",
      "Iteration 34544 => Loss: 46.04521759762539545591\n",
      "Iteration 34545 => Loss: 46.04505666602080538041\n",
      "Iteration 34546 => Loss: 46.04489573567921212316\n",
      "Iteration 34547 => Loss: 46.04473480660058726244\n",
      "Iteration 34548 => Loss: 46.04457387878491658739\n",
      "Iteration 34549 => Loss: 46.04441295223221430888\n",
      "Iteration 34550 => Loss: 46.04425202694242358348\n",
      "Iteration 34551 => Loss: 46.04409110291560836004\n",
      "Iteration 34552 => Loss: 46.04393018015169758428\n",
      "Iteration 34553 => Loss: 46.04376925865069836163\n",
      "Iteration 34554 => Loss: 46.04360833841261069210\n",
      "Iteration 34555 => Loss: 46.04344741943738483769\n",
      "Iteration 34556 => Loss: 46.04328650172508474725\n",
      "Iteration 34557 => Loss: 46.04312558527562515565\n",
      "Iteration 34558 => Loss: 46.04296467008904869544\n",
      "Iteration 34559 => Loss: 46.04280375616532694494\n",
      "Iteration 34560 => Loss: 46.04264284350443858784\n",
      "Iteration 34561 => Loss: 46.04248193210639783501\n",
      "Iteration 34562 => Loss: 46.04232102197116205389\n",
      "Iteration 34563 => Loss: 46.04216011309875256075\n",
      "Iteration 34564 => Loss: 46.04199920548916935559\n",
      "Iteration 34565 => Loss: 46.04183829914235559500\n",
      "Iteration 34566 => Loss: 46.04167739405831838440\n",
      "Iteration 34567 => Loss: 46.04151649023705772379\n",
      "Iteration 34568 => Loss: 46.04135558767858782403\n",
      "Iteration 34569 => Loss: 46.04119468638283763084\n",
      "Iteration 34570 => Loss: 46.04103378634987819851\n",
      "Iteration 34571 => Loss: 46.04087288757960294561\n",
      "Iteration 34572 => Loss: 46.04071199007208292642\n",
      "Iteration 34573 => Loss: 46.04055109382726840295\n",
      "Iteration 34574 => Loss: 46.04039019884516648062\n",
      "Iteration 34575 => Loss: 46.04022930512575584316\n",
      "Iteration 34576 => Loss: 46.04006841266902227972\n",
      "Iteration 34577 => Loss: 46.03990752147497289570\n",
      "Iteration 34578 => Loss: 46.03974663154360058570\n",
      "Iteration 34579 => Loss: 46.03958574287486271714\n",
      "Iteration 34580 => Loss: 46.03942485546875218461\n",
      "Iteration 34581 => Loss: 46.03926396932534004236\n",
      "Iteration 34582 => Loss: 46.03910308444448418186\n",
      "Iteration 34583 => Loss: 46.03894220082629828994\n",
      "Iteration 34584 => Loss: 46.03878131847069710147\n",
      "Iteration 34585 => Loss: 46.03862043737768772189\n",
      "Iteration 34586 => Loss: 46.03845955754727725662\n",
      "Iteration 34587 => Loss: 46.03829867897944438937\n",
      "Iteration 34588 => Loss: 46.03813780167416780387\n",
      "Iteration 34589 => Loss: 46.03797692563144750011\n",
      "Iteration 34590 => Loss: 46.03781605085126216181\n",
      "Iteration 34591 => Loss: 46.03765517733365442155\n",
      "Iteration 34592 => Loss: 46.03749430507854611960\n",
      "Iteration 34593 => Loss: 46.03733343408595146684\n",
      "Iteration 34594 => Loss: 46.03717256435586335783\n",
      "Iteration 34595 => Loss: 46.03701169588828179258\n",
      "Iteration 34596 => Loss: 46.03685082868318545479\n",
      "Iteration 34597 => Loss: 46.03668996274055302820\n",
      "Iteration 34598 => Loss: 46.03652909806040582907\n",
      "Iteration 34599 => Loss: 46.03636823464270833028\n",
      "Iteration 34600 => Loss: 46.03620737248746053183\n",
      "Iteration 34601 => Loss: 46.03604651159463401200\n",
      "Iteration 34602 => Loss: 46.03588565196426429793\n",
      "Iteration 34603 => Loss: 46.03572479359630875706\n",
      "Iteration 34604 => Loss: 46.03556393649074607310\n",
      "Iteration 34605 => Loss: 46.03540308064759045692\n",
      "Iteration 34606 => Loss: 46.03524222606679927594\n",
      "Iteration 34607 => Loss: 46.03508137274842226816\n",
      "Iteration 34608 => Loss: 46.03492052069240969558\n",
      "Iteration 34609 => Loss: 46.03475966989872603108\n",
      "Iteration 34610 => Loss: 46.03459882036742811806\n",
      "Iteration 34611 => Loss: 46.03443797209844490226\n",
      "Iteration 34612 => Loss: 46.03427712509179769995\n",
      "Iteration 34613 => Loss: 46.03411627934742966772\n",
      "Iteration 34614 => Loss: 46.03395543486544028156\n",
      "Iteration 34615 => Loss: 46.03379459164570874918\n",
      "Iteration 34616 => Loss: 46.03363374968827059774\n",
      "Iteration 34617 => Loss: 46.03347290899311872181\n",
      "Iteration 34618 => Loss: 46.03331206956025312138\n",
      "Iteration 34619 => Loss: 46.03315123138961695304\n",
      "Iteration 34620 => Loss: 46.03299039448124574392\n",
      "Iteration 34621 => Loss: 46.03282955883508975603\n",
      "Iteration 34622 => Loss: 46.03266872445117741108\n",
      "Iteration 34623 => Loss: 46.03250789132950160365\n",
      "Iteration 34624 => Loss: 46.03234705947002680659\n",
      "Iteration 34625 => Loss: 46.03218622887273880906\n",
      "Iteration 34626 => Loss: 46.03202539953766603276\n",
      "Iteration 34627 => Loss: 46.03186457146475873969\n",
      "Iteration 34628 => Loss: 46.03170374465400982444\n",
      "Iteration 34629 => Loss: 46.03154291910544060329\n",
      "Iteration 34630 => Loss: 46.03138209481901554909\n",
      "Iteration 34631 => Loss: 46.03122127179473466185\n",
      "Iteration 34632 => Loss: 46.03106045003256241444\n",
      "Iteration 34633 => Loss: 46.03089962953252722855\n",
      "Iteration 34634 => Loss: 46.03073881029460778791\n",
      "Iteration 34635 => Loss: 46.03057799231878277624\n",
      "Iteration 34636 => Loss: 46.03041717560505219353\n",
      "Iteration 34637 => Loss: 46.03025636015340893437\n",
      "Iteration 34638 => Loss: 46.03009554596383878788\n",
      "Iteration 34639 => Loss: 46.02993473303631333238\n",
      "Iteration 34640 => Loss: 46.02977392137083967327\n",
      "Iteration 34641 => Loss: 46.02961311096741781057\n",
      "Iteration 34642 => Loss: 46.02945230182601221713\n",
      "Iteration 34643 => Loss: 46.02929149394664420925\n",
      "Iteration 34644 => Loss: 46.02913068732927115434\n",
      "Iteration 34645 => Loss: 46.02896988197392857955\n",
      "Iteration 34646 => Loss: 46.02880907788055964147\n",
      "Iteration 34647 => Loss: 46.02864827504917855094\n",
      "Iteration 34648 => Loss: 46.02848747347977109712\n",
      "Iteration 34649 => Loss: 46.02832667317232306914\n",
      "Iteration 34650 => Loss: 46.02816587412682025615\n",
      "Iteration 34651 => Loss: 46.02800507634325555273\n",
      "Iteration 34652 => Loss: 46.02784427982164316973\n",
      "Iteration 34653 => Loss: 46.02768348456192626372\n",
      "Iteration 34654 => Loss: 46.02752269056414036186\n",
      "Iteration 34655 => Loss: 46.02736189782827125327\n",
      "Iteration 34656 => Loss: 46.02720110635427630541\n",
      "Iteration 34657 => Loss: 46.02704031614216972912\n",
      "Iteration 34658 => Loss: 46.02687952719193731355\n",
      "Iteration 34659 => Loss: 46.02671873950354353155\n",
      "Iteration 34660 => Loss: 46.02655795307703101571\n",
      "Iteration 34661 => Loss: 46.02639716791236423887\n",
      "Iteration 34662 => Loss: 46.02623638400952188476\n",
      "Iteration 34663 => Loss: 46.02607560136849684795\n",
      "Iteration 34664 => Loss: 46.02591481998929623387\n",
      "Iteration 34665 => Loss: 46.02575403987190583166\n",
      "Iteration 34666 => Loss: 46.02559326101628300876\n",
      "Iteration 34667 => Loss: 46.02543248342246329230\n",
      "Iteration 34668 => Loss: 46.02527170709041826058\n",
      "Iteration 34669 => Loss: 46.02511093202012659731\n",
      "Iteration 34670 => Loss: 46.02495015821157409164\n",
      "Iteration 34671 => Loss: 46.02478938566481048156\n",
      "Iteration 34672 => Loss: 46.02462861437977892365\n",
      "Iteration 34673 => Loss: 46.02446784435642967992\n",
      "Iteration 34674 => Loss: 46.02430707559481959379\n",
      "Iteration 34675 => Loss: 46.02414630809492024355\n",
      "Iteration 34676 => Loss: 46.02398554185670320749\n",
      "Iteration 34677 => Loss: 46.02382477688016848560\n",
      "Iteration 34678 => Loss: 46.02366401316530897248\n",
      "Iteration 34679 => Loss: 46.02350325071212466810\n",
      "Iteration 34680 => Loss: 46.02334248952060136162\n",
      "Iteration 34681 => Loss: 46.02318172959071773676\n",
      "Iteration 34682 => Loss: 46.02302097092245958265\n",
      "Iteration 34683 => Loss: 46.02286021351582689931\n",
      "Iteration 34684 => Loss: 46.02269945737083389758\n",
      "Iteration 34685 => Loss: 46.02253870248740952320\n",
      "Iteration 34686 => Loss: 46.02237794886561772500\n",
      "Iteration 34687 => Loss: 46.02221719650538744872\n",
      "Iteration 34688 => Loss: 46.02205644540674001064\n",
      "Iteration 34689 => Loss: 46.02189569556965409447\n",
      "Iteration 34690 => Loss: 46.02173494699412970022\n",
      "Iteration 34691 => Loss: 46.02157419968014551159\n",
      "Iteration 34692 => Loss: 46.02141345362770152860\n",
      "Iteration 34693 => Loss: 46.02125270883680485667\n",
      "Iteration 34694 => Loss: 46.02109196530740575781\n",
      "Iteration 34695 => Loss: 46.02093122303951133745\n",
      "Iteration 34696 => Loss: 46.02077048203312159558\n",
      "Iteration 34697 => Loss: 46.02060974228819389964\n",
      "Iteration 34698 => Loss: 46.02044900380477798763\n",
      "Iteration 34699 => Loss: 46.02028826658280991069\n",
      "Iteration 34700 => Loss: 46.02012753062231809054\n",
      "Iteration 34701 => Loss: 46.01996679592323147290\n",
      "Iteration 34702 => Loss: 46.01980606248562821747\n",
      "Iteration 34703 => Loss: 46.01964533030943016456\n",
      "Iteration 34704 => Loss: 46.01948459939466573587\n",
      "Iteration 34705 => Loss: 46.01932386974129229884\n",
      "Iteration 34706 => Loss: 46.01916314134930985347\n",
      "Iteration 34707 => Loss: 46.01900241421873261061\n",
      "Iteration 34708 => Loss: 46.01884168834952504312\n",
      "Iteration 34709 => Loss: 46.01868096374168715101\n",
      "Iteration 34710 => Loss: 46.01852024039520472343\n",
      "Iteration 34711 => Loss: 46.01835951831007065493\n",
      "Iteration 34712 => Loss: 46.01819879748627784011\n",
      "Iteration 34713 => Loss: 46.01803807792381206809\n",
      "Iteration 34714 => Loss: 46.01787735962269465517\n",
      "Iteration 34715 => Loss: 46.01771664258284033622\n",
      "Iteration 34716 => Loss: 46.01755592680429884922\n",
      "Iteration 34717 => Loss: 46.01739521228704887790\n",
      "Iteration 34718 => Loss: 46.01723449903110463310\n",
      "Iteration 34719 => Loss: 46.01707378703638795514\n",
      "Iteration 34720 => Loss: 46.01691307630294858200\n",
      "Iteration 34721 => Loss: 46.01675236683076519739\n",
      "Iteration 34722 => Loss: 46.01659165861980937962\n",
      "Iteration 34723 => Loss: 46.01643095167009533952\n",
      "Iteration 34724 => Loss: 46.01627024598158044455\n",
      "Iteration 34725 => Loss: 46.01610954155428601098\n",
      "Iteration 34726 => Loss: 46.01594883838819782795\n",
      "Iteration 34727 => Loss: 46.01578813648329457919\n",
      "Iteration 34728 => Loss: 46.01562743583957626470\n",
      "Iteration 34729 => Loss: 46.01546673645702156819\n",
      "Iteration 34730 => Loss: 46.01530603833561627880\n",
      "Iteration 34731 => Loss: 46.01514534147538881825\n",
      "Iteration 34732 => Loss: 46.01498464587628234312\n",
      "Iteration 34733 => Loss: 46.01482395153831106427\n",
      "Iteration 34734 => Loss: 46.01466325846146787626\n",
      "Iteration 34735 => Loss: 46.01450256664573146281\n",
      "Iteration 34736 => Loss: 46.01434187609108761308\n",
      "Iteration 34737 => Loss: 46.01418118679753632705\n",
      "Iteration 34738 => Loss: 46.01402049876506339388\n",
      "Iteration 34739 => Loss: 46.01385981199368302441\n",
      "Iteration 34740 => Loss: 46.01369912648334548066\n",
      "Iteration 34741 => Loss: 46.01353844223407207892\n",
      "Iteration 34742 => Loss: 46.01337775924582729203\n",
      "Iteration 34743 => Loss: 46.01321707751861822544\n",
      "Iteration 34744 => Loss: 46.01305639705240935200\n",
      "Iteration 34745 => Loss: 46.01289571784725040970\n",
      "Iteration 34746 => Loss: 46.01273503990307034428\n",
      "Iteration 34747 => Loss: 46.01257436321989047201\n",
      "Iteration 34748 => Loss: 46.01241368779769658204\n",
      "Iteration 34749 => Loss: 46.01225301363647446351\n",
      "Iteration 34750 => Loss: 46.01209234073618858929\n",
      "Iteration 34751 => Loss: 46.01193166909687448651\n",
      "Iteration 34752 => Loss: 46.01177099871853215518\n",
      "Iteration 34753 => Loss: 46.01161032960108343559\n",
      "Iteration 34754 => Loss: 46.01144966174455674945\n",
      "Iteration 34755 => Loss: 46.01128899514896630762\n",
      "Iteration 34756 => Loss: 46.01112832981427658297\n",
      "Iteration 34757 => Loss: 46.01096766574046625919\n",
      "Iteration 34758 => Loss: 46.01080700292754954717\n",
      "Iteration 34759 => Loss: 46.01064634137549802517\n",
      "Iteration 34760 => Loss: 46.01048568108430458778\n",
      "Iteration 34761 => Loss: 46.01032502205396923500\n",
      "Iteration 34762 => Loss: 46.01016436428447775597\n",
      "Iteration 34763 => Loss: 46.01000370777582304527\n",
      "Iteration 34764 => Loss: 46.00984305252801931374\n",
      "Iteration 34765 => Loss: 46.00968239854098840169\n",
      "Iteration 34766 => Loss: 46.00952174581477294169\n",
      "Iteration 34767 => Loss: 46.00936109434936582829\n",
      "Iteration 34768 => Loss: 46.00920044414472442895\n",
      "Iteration 34769 => Loss: 46.00903979520086295452\n",
      "Iteration 34770 => Loss: 46.00887914751776008870\n",
      "Iteration 34771 => Loss: 46.00871850109540162066\n",
      "Iteration 34772 => Loss: 46.00855785593383728838\n",
      "Iteration 34773 => Loss: 46.00839721203295340501\n",
      "Iteration 34774 => Loss: 46.00823656939282102485\n",
      "Iteration 34775 => Loss: 46.00807592801341883160\n",
      "Iteration 34776 => Loss: 46.00791528789468287641\n",
      "Iteration 34777 => Loss: 46.00775464903665579186\n",
      "Iteration 34778 => Loss: 46.00759401143932336709\n",
      "Iteration 34779 => Loss: 46.00743337510267849666\n",
      "Iteration 34780 => Loss: 46.00727274002667144259\n",
      "Iteration 34781 => Loss: 46.00711210621131641574\n",
      "Iteration 34782 => Loss: 46.00695147365664183781\n",
      "Iteration 34783 => Loss: 46.00679084236258375995\n",
      "Iteration 34784 => Loss: 46.00663021232914928760\n",
      "Iteration 34785 => Loss: 46.00646958355633842075\n",
      "Iteration 34786 => Loss: 46.00630895604412984312\n",
      "Iteration 34787 => Loss: 46.00614832979250934386\n",
      "Iteration 34788 => Loss: 46.00598770480147692297\n",
      "Iteration 34789 => Loss: 46.00582708107102547501\n",
      "Iteration 34790 => Loss: 46.00566645860114078914\n",
      "Iteration 34791 => Loss: 46.00550583739181575993\n",
      "Iteration 34792 => Loss: 46.00534521744302907109\n",
      "Iteration 34793 => Loss: 46.00518459875479493348\n",
      "Iteration 34794 => Loss: 46.00502398132707781997\n",
      "Iteration 34795 => Loss: 46.00486336515987062512\n",
      "Iteration 34796 => Loss: 46.00470275025319466522\n",
      "Iteration 34797 => Loss: 46.00454213660697888599\n",
      "Iteration 34798 => Loss: 46.00438152422128013086\n",
      "Iteration 34799 => Loss: 46.00422091309604155640\n",
      "Iteration 34800 => Loss: 46.00406030323129158432\n",
      "Iteration 34801 => Loss: 46.00389969462697337121\n",
      "Iteration 34802 => Loss: 46.00373908728312244421\n",
      "Iteration 34803 => Loss: 46.00357848119971038159\n",
      "Iteration 34804 => Loss: 46.00341787637670876165\n",
      "Iteration 34805 => Loss: 46.00325727281413890069\n",
      "Iteration 34806 => Loss: 46.00309667051197237697\n",
      "Iteration 34807 => Loss: 46.00293606947020208509\n",
      "Iteration 34808 => Loss: 46.00277546968882091960\n",
      "Iteration 34809 => Loss: 46.00261487116782888052\n",
      "Iteration 34810 => Loss: 46.00245427390719044070\n",
      "Iteration 34811 => Loss: 46.00229367790692691642\n",
      "Iteration 34812 => Loss: 46.00213308316699567513\n",
      "Iteration 34813 => Loss: 46.00197248968741803310\n",
      "Iteration 34814 => Loss: 46.00181189746815846320\n",
      "Iteration 34815 => Loss: 46.00165130650923117628\n",
      "Iteration 34816 => Loss: 46.00149071681060775063\n",
      "Iteration 34817 => Loss: 46.00133012837227397540\n",
      "Iteration 34818 => Loss: 46.00116954119425116687\n",
      "Iteration 34819 => Loss: 46.00100895527648958705\n",
      "Iteration 34820 => Loss: 46.00084837061899634136\n",
      "Iteration 34821 => Loss: 46.00068778722176432439\n",
      "Iteration 34822 => Loss: 46.00052720508477932526\n",
      "Iteration 34823 => Loss: 46.00036662420806266027\n",
      "Iteration 34824 => Loss: 46.00020604459154327515\n",
      "Iteration 34825 => Loss: 46.00004546623526380245\n",
      "Iteration 34826 => Loss: 45.99988488913917450418\n",
      "Iteration 34827 => Loss: 45.99972431330329669663\n",
      "Iteration 34828 => Loss: 45.99956373872763037980\n",
      "Iteration 34829 => Loss: 45.99940316541211871026\n",
      "Iteration 34830 => Loss: 45.99924259335679010974\n",
      "Iteration 34831 => Loss: 45.99908202256160194565\n",
      "Iteration 34832 => Loss: 45.99892145302658263972\n",
      "Iteration 34833 => Loss: 45.99876088475171798109\n",
      "Iteration 34834 => Loss: 45.99860031773696533719\n",
      "Iteration 34835 => Loss: 45.99843975198234602431\n",
      "Iteration 34836 => Loss: 45.99827918748781030445\n",
      "Iteration 34837 => Loss: 45.99811862425342212646\n",
      "Iteration 34838 => Loss: 45.99795806227908911978\n",
      "Iteration 34839 => Loss: 45.99779750156484681156\n",
      "Iteration 34840 => Loss: 45.99763694211068809636\n",
      "Iteration 34841 => Loss: 45.99747638391658455248\n",
      "Iteration 34842 => Loss: 45.99731582698251486363\n",
      "Iteration 34843 => Loss: 45.99715527130851455695\n",
      "Iteration 34844 => Loss: 45.99699471689454099987\n",
      "Iteration 34845 => Loss: 45.99683416374057287612\n",
      "Iteration 34846 => Loss: 45.99667361184663860740\n",
      "Iteration 34847 => Loss: 45.99651306121269556115\n",
      "Iteration 34848 => Loss: 45.99635251183874373737\n",
      "Iteration 34849 => Loss: 45.99619196372479734691\n",
      "Iteration 34850 => Loss: 45.99603141687080665179\n",
      "Iteration 34851 => Loss: 45.99587087127677165199\n",
      "Iteration 34852 => Loss: 45.99571032694269234753\n",
      "Iteration 34853 => Loss: 45.99554978386856163297\n",
      "Iteration 34854 => Loss: 45.99538924205435819204\n",
      "Iteration 34855 => Loss: 45.99522870150009623558\n",
      "Iteration 34856 => Loss: 45.99506816220571892018\n",
      "Iteration 34857 => Loss: 45.99490762417127598383\n",
      "Iteration 34858 => Loss: 45.99474708739670347768\n",
      "Iteration 34859 => Loss: 45.99458655188202271802\n",
      "Iteration 34860 => Loss: 45.99442601762722659942\n",
      "Iteration 34861 => Loss: 45.99426548463229380559\n",
      "Iteration 34862 => Loss: 45.99410495289719591483\n",
      "Iteration 34863 => Loss: 45.99394442242196134885\n",
      "Iteration 34864 => Loss: 45.99378389320656168593\n",
      "Iteration 34865 => Loss: 45.99362336525097560980\n",
      "Iteration 34866 => Loss: 45.99346283855521022588\n",
      "Iteration 34867 => Loss: 45.99330231311925842874\n",
      "Iteration 34868 => Loss: 45.99314178894307758583\n",
      "Iteration 34869 => Loss: 45.99298126602671032970\n",
      "Iteration 34870 => Loss: 45.99282074437009271151\n",
      "Iteration 34871 => Loss: 45.99266022397326025839\n",
      "Iteration 34872 => Loss: 45.99249970483617744321\n",
      "Iteration 34873 => Loss: 45.99233918695883005512\n",
      "Iteration 34874 => Loss: 45.99217867034123941039\n",
      "Iteration 34875 => Loss: 45.99201815498335577104\n",
      "Iteration 34876 => Loss: 45.99185764088519334791\n",
      "Iteration 34877 => Loss: 45.99169712804673082474\n",
      "Iteration 34878 => Loss: 45.99153661646798951779\n",
      "Iteration 34879 => Loss: 45.99137610614891968908\n",
      "Iteration 34880 => Loss: 45.99121559708952133860\n",
      "Iteration 34881 => Loss: 45.99105508928978736094\n",
      "Iteration 34882 => Loss: 45.99089458274973196694\n",
      "Iteration 34883 => Loss: 45.99073407746929831319\n",
      "Iteration 34884 => Loss: 45.99057357344852192682\n",
      "Iteration 34885 => Loss: 45.99041307068733885899\n",
      "Iteration 34886 => Loss: 45.99025256918580595311\n",
      "Iteration 34887 => Loss: 45.99009206894387347120\n",
      "Iteration 34888 => Loss: 45.98993156996153430782\n",
      "Iteration 34889 => Loss: 45.98977107223878135756\n",
      "Iteration 34890 => Loss: 45.98961057577561462040\n",
      "Iteration 34891 => Loss: 45.98945008057199856921\n",
      "Iteration 34892 => Loss: 45.98928958662794741485\n",
      "Iteration 34893 => Loss: 45.98912909394343984104\n",
      "Iteration 34894 => Loss: 45.98896860251850426948\n",
      "Iteration 34895 => Loss: 45.98880811235305543505\n",
      "Iteration 34896 => Loss: 45.98864762344714307574\n",
      "Iteration 34897 => Loss: 45.98848713580073166440\n",
      "Iteration 34898 => Loss: 45.98832664941382120105\n",
      "Iteration 34899 => Loss: 45.98816616428641168568\n",
      "Iteration 34900 => Loss: 45.98800568041847469658\n",
      "Iteration 34901 => Loss: 45.98784519780999602290\n",
      "Iteration 34902 => Loss: 45.98768471646100408634\n",
      "Iteration 34903 => Loss: 45.98752423637142072721\n",
      "Iteration 34904 => Loss: 45.98736375754130989435\n",
      "Iteration 34905 => Loss: 45.98720327997060763892\n",
      "Iteration 34906 => Loss: 45.98704280365933527719\n",
      "Iteration 34907 => Loss: 45.98688232860747149289\n",
      "Iteration 34908 => Loss: 45.98672185481500207516\n",
      "Iteration 34909 => Loss: 45.98656138228193412942\n",
      "Iteration 34910 => Loss: 45.98640091100822502312\n",
      "Iteration 34911 => Loss: 45.98624044099391028340\n",
      "Iteration 34912 => Loss: 45.98607997223894017225\n",
      "Iteration 34913 => Loss: 45.98591950474333600596\n",
      "Iteration 34914 => Loss: 45.98575903850704094111\n",
      "Iteration 34915 => Loss: 45.98559857353011182113\n",
      "Iteration 34916 => Loss: 45.98543810981249180259\n",
      "Iteration 34917 => Loss: 45.98527764735418088549\n",
      "Iteration 34918 => Loss: 45.98511718615515775355\n",
      "Iteration 34919 => Loss: 45.98495672621542240677\n",
      "Iteration 34920 => Loss: 45.98479626753499616143\n",
      "Iteration 34921 => Loss: 45.98463581011381506869\n",
      "Iteration 34922 => Loss: 45.98447535395192886654\n",
      "Iteration 34923 => Loss: 45.98431489904928071155\n",
      "Iteration 34924 => Loss: 45.98415444540587060374\n",
      "Iteration 34925 => Loss: 45.98399399302167012138\n",
      "Iteration 34926 => Loss: 45.98383354189672900247\n",
      "Iteration 34927 => Loss: 45.98367309203098329817\n",
      "Iteration 34928 => Loss: 45.98351264342442590305\n",
      "Iteration 34929 => Loss: 45.98335219607707102796\n",
      "Iteration 34930 => Loss: 45.98319174998890446204\n",
      "Iteration 34931 => Loss: 45.98303130515989067817\n",
      "Iteration 34932 => Loss: 45.98287086159005809805\n",
      "Iteration 34933 => Loss: 45.98271041927937119453\n",
      "Iteration 34934 => Loss: 45.98254997822784417849\n",
      "Iteration 34935 => Loss: 45.98238953843542731192\n",
      "Iteration 34936 => Loss: 45.98222909990215612197\n",
      "Iteration 34937 => Loss: 45.98206866262797376521\n",
      "Iteration 34938 => Loss: 45.98190822661290866336\n",
      "Iteration 34939 => Loss: 45.98174779185691818384\n",
      "Iteration 34940 => Loss: 45.98158735836005206465\n",
      "Iteration 34941 => Loss: 45.98142692612221793524\n",
      "Iteration 34942 => Loss: 45.98126649514346553360\n",
      "Iteration 34943 => Loss: 45.98110606542378064887\n",
      "Iteration 34944 => Loss: 45.98094563696309933221\n",
      "Iteration 34945 => Loss: 45.98078520976148553245\n",
      "Iteration 34946 => Loss: 45.98062478381888951162\n",
      "Iteration 34947 => Loss: 45.98046435913531126971\n",
      "Iteration 34948 => Loss: 45.98030393571072949044\n",
      "Iteration 34949 => Loss: 45.98014351354515127923\n",
      "Iteration 34950 => Loss: 45.97998309263853400353\n",
      "Iteration 34951 => Loss: 45.97982267299092740132\n",
      "Iteration 34952 => Loss: 45.97966225460224620747\n",
      "Iteration 34953 => Loss: 45.97950183747256147626\n",
      "Iteration 34954 => Loss: 45.97934142160180215342\n",
      "Iteration 34955 => Loss: 45.97918100698996113351\n",
      "Iteration 34956 => Loss: 45.97902059363706683826\n",
      "Iteration 34957 => Loss: 45.97886018154310505679\n",
      "Iteration 34958 => Loss: 45.97869977070802605112\n",
      "Iteration 34959 => Loss: 45.97853936113182982126\n",
      "Iteration 34960 => Loss: 45.97837895281452347263\n",
      "Iteration 34961 => Loss: 45.97821854575612121607\n",
      "Iteration 34962 => Loss: 45.97805813995657331361\n",
      "Iteration 34963 => Loss: 45.97789773541587265981\n",
      "Iteration 34964 => Loss: 45.97773733213401925468\n",
      "Iteration 34965 => Loss: 45.97757693011099888736\n",
      "Iteration 34966 => Loss: 45.97741652934681155784\n",
      "Iteration 34967 => Loss: 45.97725612984142173900\n",
      "Iteration 34968 => Loss: 45.97709573159489337968\n",
      "Iteration 34969 => Loss: 45.97693533460709858218\n",
      "Iteration 34970 => Loss: 45.97677493887812971707\n",
      "Iteration 34971 => Loss: 45.97661454440791573006\n",
      "Iteration 34972 => Loss: 45.97645415119648504287\n",
      "Iteration 34973 => Loss: 45.97629375924380923379\n",
      "Iteration 34974 => Loss: 45.97613336854988830282\n",
      "Iteration 34975 => Loss: 45.97597297911468672282\n",
      "Iteration 34976 => Loss: 45.97581259093821870465\n",
      "Iteration 34977 => Loss: 45.97565220402046293202\n",
      "Iteration 34978 => Loss: 45.97549181836141940494\n",
      "Iteration 34979 => Loss: 45.97533143396108101797\n",
      "Iteration 34980 => Loss: 45.97517105081942645484\n",
      "Iteration 34981 => Loss: 45.97501066893645571554\n",
      "Iteration 34982 => Loss: 45.97485028831214037837\n",
      "Iteration 34983 => Loss: 45.97468990894651597046\n",
      "Iteration 34984 => Loss: 45.97452953083951143753\n",
      "Iteration 34985 => Loss: 45.97436915399111967417\n",
      "Iteration 34986 => Loss: 45.97420877840142594550\n",
      "Iteration 34987 => Loss: 45.97404840407032367011\n",
      "Iteration 34988 => Loss: 45.97388803099780574257\n",
      "Iteration 34989 => Loss: 45.97372765918390769002\n",
      "Iteration 34990 => Loss: 45.97356728862860819618\n",
      "Iteration 34991 => Loss: 45.97340691933187173390\n",
      "Iteration 34992 => Loss: 45.97324655129369830320\n",
      "Iteration 34993 => Loss: 45.97308618451410211492\n",
      "Iteration 34994 => Loss: 45.97292581899304053650\n",
      "Iteration 34995 => Loss: 45.97276545473052777879\n",
      "Iteration 34996 => Loss: 45.97260509172654252552\n",
      "Iteration 34997 => Loss: 45.97244472998107767125\n",
      "Iteration 34998 => Loss: 45.97228436949413321599\n",
      "Iteration 34999 => Loss: 45.97212401026568073803\n",
      "Iteration 35000 => Loss: 45.97196365229571313193\n",
      "Iteration 35001 => Loss: 45.97180329558424460856\n",
      "Iteration 35002 => Loss: 45.97164294013123253535\n",
      "Iteration 35003 => Loss: 45.97148258593667691230\n",
      "Iteration 35004 => Loss: 45.97132223300057773940\n",
      "Iteration 35005 => Loss: 45.97116188132294212210\n",
      "Iteration 35006 => Loss: 45.97100153090370611153\n",
      "Iteration 35007 => Loss: 45.97084118174289812941\n",
      "Iteration 35008 => Loss: 45.97068083384050396489\n",
      "Iteration 35009 => Loss: 45.97052048719653072339\n",
      "Iteration 35010 => Loss: 45.97036014181092866693\n",
      "Iteration 35011 => Loss: 45.97019979768371200635\n",
      "Iteration 35012 => Loss: 45.97003945481487363622\n",
      "Iteration 35013 => Loss: 45.96987911320440645113\n",
      "Iteration 35014 => Loss: 45.96971877285228202936\n",
      "Iteration 35015 => Loss: 45.96955843375847905463\n",
      "Iteration 35016 => Loss: 45.96939809592302594865\n",
      "Iteration 35017 => Loss: 45.96923775934588718428\n",
      "Iteration 35018 => Loss: 45.96907742402709828866\n",
      "Iteration 35019 => Loss: 45.96891708996655978581\n",
      "Iteration 35020 => Loss: 45.96875675716435694085\n",
      "Iteration 35021 => Loss: 45.96859642562042580494\n",
      "Iteration 35022 => Loss: 45.96843609533475927265\n",
      "Iteration 35023 => Loss: 45.96827576630736444940\n",
      "Iteration 35024 => Loss: 45.96811543853821291350\n",
      "Iteration 35025 => Loss: 45.96795511202730466493\n",
      "Iteration 35026 => Loss: 45.96779478677463970371\n",
      "Iteration 35027 => Loss: 45.96763446278020381897\n",
      "Iteration 35028 => Loss: 45.96747414004397569443\n",
      "Iteration 35029 => Loss: 45.96731381856596243551\n",
      "Iteration 35030 => Loss: 45.96715349834611430424\n",
      "Iteration 35031 => Loss: 45.96699317938448103860\n",
      "Iteration 35032 => Loss: 45.96683286168100579516\n",
      "Iteration 35033 => Loss: 45.96667254523570278479\n",
      "Iteration 35034 => Loss: 45.96651223004855069121\n",
      "Iteration 35035 => Loss: 45.96635191611954240898\n",
      "Iteration 35036 => Loss: 45.96619160344867083268\n",
      "Iteration 35037 => Loss: 45.96603129203593596230\n",
      "Iteration 35038 => Loss: 45.96587098188130227072\n",
      "Iteration 35039 => Loss: 45.96571067298476265250\n",
      "Iteration 35040 => Loss: 45.96555036534635263479\n",
      "Iteration 35041 => Loss: 45.96539005896601537415\n",
      "Iteration 35042 => Loss: 45.96522975384375797603\n",
      "Iteration 35043 => Loss: 45.96506944997953780785\n",
      "Iteration 35044 => Loss: 45.96490914737340460761\n",
      "Iteration 35045 => Loss: 45.96474884602530153188\n",
      "Iteration 35046 => Loss: 45.96458854593524989696\n",
      "Iteration 35047 => Loss: 45.96442824710320707027\n",
      "Iteration 35048 => Loss: 45.96426794952918726267\n",
      "Iteration 35049 => Loss: 45.96410765321316915788\n",
      "Iteration 35050 => Loss: 45.96394735815517407218\n",
      "Iteration 35051 => Loss: 45.96378706435514516215\n",
      "Iteration 35052 => Loss: 45.96362677181310374408\n",
      "Iteration 35053 => Loss: 45.96346648052901429082\n",
      "Iteration 35054 => Loss: 45.96330619050289811867\n",
      "Iteration 35055 => Loss: 45.96314590173472680590\n",
      "Iteration 35056 => Loss: 45.96298561422448614167\n",
      "Iteration 35057 => Loss: 45.96282532797215480969\n",
      "Iteration 35058 => Loss: 45.96266504297776123167\n",
      "Iteration 35059 => Loss: 45.96250475924129830219\n",
      "Iteration 35060 => Loss: 45.96234447676270207239\n",
      "Iteration 35061 => Loss: 45.96218419554200806942\n",
      "Iteration 35062 => Loss: 45.96202391557918787157\n",
      "Iteration 35063 => Loss: 45.96186363687423437341\n",
      "Iteration 35064 => Loss: 45.96170335942714757493\n",
      "Iteration 35065 => Loss: 45.96154308323790615987\n",
      "Iteration 35066 => Loss: 45.96138280830651723363\n",
      "Iteration 35067 => Loss: 45.96122253463292395281\n",
      "Iteration 35068 => Loss: 45.96106226221716184455\n",
      "Iteration 35069 => Loss: 45.96090199105923090883\n",
      "Iteration 35070 => Loss: 45.96074172115908851310\n",
      "Iteration 35071 => Loss: 45.96058145251673465737\n",
      "Iteration 35072 => Loss: 45.96042118513215513076\n",
      "Iteration 35073 => Loss: 45.96026091900534282786\n",
      "Iteration 35074 => Loss: 45.96010065413629774866\n",
      "Iteration 35075 => Loss: 45.95994039052500568232\n",
      "Iteration 35076 => Loss: 45.95978012817145952340\n",
      "Iteration 35077 => Loss: 45.95961986707563085020\n",
      "Iteration 35078 => Loss: 45.95945960723751966270\n",
      "Iteration 35079 => Loss: 45.95929934865714727721\n",
      "Iteration 35080 => Loss: 45.95913909133443553401\n",
      "Iteration 35081 => Loss: 45.95897883526941996024\n",
      "Iteration 35082 => Loss: 45.95881858046212187219\n",
      "Iteration 35083 => Loss: 45.95865832691247732100\n",
      "Iteration 35084 => Loss: 45.95849807462047920126\n",
      "Iteration 35085 => Loss: 45.95833782358614882924\n",
      "Iteration 35086 => Loss: 45.95817757380946488865\n",
      "Iteration 35087 => Loss: 45.95801732529039895780\n",
      "Iteration 35088 => Loss: 45.95785707802895103669\n",
      "Iteration 35089 => Loss: 45.95769683202512112530\n",
      "Iteration 35090 => Loss: 45.95753658727889501279\n",
      "Iteration 35091 => Loss: 45.95737634379026559373\n",
      "Iteration 35092 => Loss: 45.95721610155921155183\n",
      "Iteration 35093 => Loss: 45.95705586058573999253\n",
      "Iteration 35094 => Loss: 45.95689562086982959954\n",
      "Iteration 35095 => Loss: 45.95673538241145905658\n",
      "Iteration 35096 => Loss: 45.95657514521064967994\n",
      "Iteration 35097 => Loss: 45.95641490926735173161\n",
      "Iteration 35098 => Loss: 45.95625467458160073875\n",
      "Iteration 35099 => Loss: 45.95609444115333275249\n",
      "Iteration 35100 => Loss: 45.95593420898259751084\n",
      "Iteration 35101 => Loss: 45.95577397806934527580\n",
      "Iteration 35102 => Loss: 45.95561374841357604737\n",
      "Iteration 35103 => Loss: 45.95545352001526140384\n",
      "Iteration 35104 => Loss: 45.95529329287445108321\n",
      "Iteration 35105 => Loss: 45.95513306699107403119\n",
      "Iteration 35106 => Loss: 45.95497284236513024780\n",
      "Iteration 35107 => Loss: 45.95481261899664104931\n",
      "Iteration 35108 => Loss: 45.95465239688554959230\n",
      "Iteration 35109 => Loss: 45.95449217603189140391\n",
      "Iteration 35110 => Loss: 45.95433195643563806243\n",
      "Iteration 35111 => Loss: 45.95417173809678956786\n",
      "Iteration 35112 => Loss: 45.95401152101531039307\n",
      "Iteration 35113 => Loss: 45.95385130519121474890\n",
      "Iteration 35114 => Loss: 45.95369109062448131908\n",
      "Iteration 35115 => Loss: 45.95353087731509589275\n",
      "Iteration 35116 => Loss: 45.95337066526307268077\n",
      "Iteration 35117 => Loss: 45.95321045446836194515\n",
      "Iteration 35118 => Loss: 45.95305024493099921301\n",
      "Iteration 35119 => Loss: 45.95289003665093474638\n",
      "Iteration 35120 => Loss: 45.95272982962818986152\n",
      "Iteration 35121 => Loss: 45.95256962386273613674\n",
      "Iteration 35122 => Loss: 45.95240941935457357204\n",
      "Iteration 35123 => Loss: 45.95224921610368795655\n",
      "Iteration 35124 => Loss: 45.95208901411006507942\n",
      "Iteration 35125 => Loss: 45.95192881337369783523\n",
      "Iteration 35126 => Loss: 45.95176861389458622398\n",
      "Iteration 35127 => Loss: 45.95160841567269471852\n",
      "Iteration 35128 => Loss: 45.95144821870803752972\n",
      "Iteration 35129 => Loss: 45.95128802300061465758\n",
      "Iteration 35130 => Loss: 45.95112782855035504781\n",
      "Iteration 35131 => Loss: 45.95096763535734396555\n",
      "Iteration 35132 => Loss: 45.95080744342150325110\n",
      "Iteration 35133 => Loss: 45.95064725274281869360\n",
      "Iteration 35134 => Loss: 45.95048706332131160934\n",
      "Iteration 35135 => Loss: 45.95032687515698910374\n",
      "Iteration 35136 => Loss: 45.95016668824978722796\n",
      "Iteration 35137 => Loss: 45.95000650259973440370\n",
      "Iteration 35138 => Loss: 45.94984631820682352554\n",
      "Iteration 35139 => Loss: 45.94968613507101196092\n",
      "Iteration 35140 => Loss: 45.94952595319229970983\n",
      "Iteration 35141 => Loss: 45.94936577257070808855\n",
      "Iteration 35142 => Loss: 45.94920559320620867538\n",
      "Iteration 35143 => Loss: 45.94904541509875883776\n",
      "Iteration 35144 => Loss: 45.94888523824840831367\n",
      "Iteration 35145 => Loss: 45.94872506265510025969\n",
      "Iteration 35146 => Loss: 45.94856488831885599211\n",
      "Iteration 35147 => Loss: 45.94840471523963998379\n",
      "Iteration 35148 => Loss: 45.94824454341745223473\n",
      "Iteration 35149 => Loss: 45.94808437285229985036\n",
      "Iteration 35150 => Loss: 45.94792420354414019812\n",
      "Iteration 35151 => Loss: 45.94776403549298748885\n",
      "Iteration 35152 => Loss: 45.94760386869882040628\n",
      "Iteration 35153 => Loss: 45.94744370316166026669\n",
      "Iteration 35154 => Loss: 45.94728353888143601580\n",
      "Iteration 35155 => Loss: 45.94712337585819739161\n",
      "Iteration 35156 => Loss: 45.94696321409186623441\n",
      "Iteration 35157 => Loss: 45.94680305358252070391\n",
      "Iteration 35158 => Loss: 45.94664289433010395669\n",
      "Iteration 35159 => Loss: 45.94648273633458046561\n",
      "Iteration 35160 => Loss: 45.94632257959598575781\n",
      "Iteration 35161 => Loss: 45.94616242411429851700\n",
      "Iteration 35162 => Loss: 45.94600226988951163776\n",
      "Iteration 35163 => Loss: 45.94584211692157538209\n",
      "Iteration 35164 => Loss: 45.94568196521054659343\n",
      "Iteration 35165 => Loss: 45.94552181475634711205\n",
      "Iteration 35166 => Loss: 45.94536166555902667596\n",
      "Iteration 35167 => Loss: 45.94520151761852133632\n",
      "Iteration 35168 => Loss: 45.94504137093488083110\n",
      "Iteration 35169 => Loss: 45.94488122550803410604\n",
      "Iteration 35170 => Loss: 45.94472108133802379371\n",
      "Iteration 35171 => Loss: 45.94456093842480015610\n",
      "Iteration 35172 => Loss: 45.94440079676838450951\n",
      "Iteration 35173 => Loss: 45.94424065636873422136\n",
      "Iteration 35174 => Loss: 45.94408051722587060794\n",
      "Iteration 35175 => Loss: 45.94392037933975103670\n",
      "Iteration 35176 => Loss: 45.94376024271041103475\n",
      "Iteration 35177 => Loss: 45.94360010733781507497\n",
      "Iteration 35178 => Loss: 45.94343997322193473565\n",
      "Iteration 35179 => Loss: 45.94327984036279133306\n",
      "Iteration 35180 => Loss: 45.94311970876034934008\n",
      "Iteration 35181 => Loss: 45.94295957841461586213\n",
      "Iteration 35182 => Loss: 45.94279944932558379378\n",
      "Iteration 35183 => Loss: 45.94263932149323181875\n",
      "Iteration 35184 => Loss: 45.94247919491755283161\n",
      "Iteration 35185 => Loss: 45.94231906959853972694\n",
      "Iteration 35186 => Loss: 45.94215894553619250473\n",
      "Iteration 35187 => Loss: 45.94199882273046853243\n",
      "Iteration 35188 => Loss: 45.94183870118140333716\n",
      "Iteration 35189 => Loss: 45.94167858088894718094\n",
      "Iteration 35190 => Loss: 45.94151846185310716919\n",
      "Iteration 35191 => Loss: 45.94135834407388330192\n",
      "Iteration 35192 => Loss: 45.94119822755126847369\n",
      "Iteration 35193 => Loss: 45.94103811228520584109\n",
      "Iteration 35194 => Loss: 45.94087799827572382583\n",
      "Iteration 35195 => Loss: 45.94071788552281532247\n",
      "Iteration 35196 => Loss: 45.94055777402647322560\n",
      "Iteration 35197 => Loss: 45.94039766378669042979\n",
      "Iteration 35198 => Loss: 45.94023755480342430246\n",
      "Iteration 35199 => Loss: 45.94007744707667484363\n",
      "Iteration 35200 => Loss: 45.93991734060644915871\n",
      "Iteration 35201 => Loss: 45.93975723539274014229\n",
      "Iteration 35202 => Loss: 45.93959713143551226722\n",
      "Iteration 35203 => Loss: 45.93943702873479395521\n",
      "Iteration 35204 => Loss: 45.93927692729053546827\n",
      "Iteration 35205 => Loss: 45.93911682710275101726\n",
      "Iteration 35206 => Loss: 45.93895672817141928590\n",
      "Iteration 35207 => Loss: 45.93879663049655448503\n",
      "Iteration 35208 => Loss: 45.93863653407810687668\n",
      "Iteration 35209 => Loss: 45.93847643891609777711\n",
      "Iteration 35210 => Loss: 45.93831634501049876462\n",
      "Iteration 35211 => Loss: 45.93815625236131694464\n",
      "Iteration 35212 => Loss: 45.93799616096854521174\n",
      "Iteration 35213 => Loss: 45.93783607083213382793\n",
      "Iteration 35214 => Loss: 45.93767598195211121492\n",
      "Iteration 35215 => Loss: 45.93751589432847026728\n",
      "Iteration 35216 => Loss: 45.93735580796117545788\n",
      "Iteration 35217 => Loss: 45.93719572285024099756\n",
      "Iteration 35218 => Loss: 45.93703563899563846462\n",
      "Iteration 35219 => Loss: 45.93687555639737496449\n",
      "Iteration 35220 => Loss: 45.93671547505540786460\n",
      "Iteration 35221 => Loss: 45.93655539496975848124\n",
      "Iteration 35222 => Loss: 45.93639531614043391983\n",
      "Iteration 35223 => Loss: 45.93623523856737733695\n",
      "Iteration 35224 => Loss: 45.93607516225061004889\n",
      "Iteration 35225 => Loss: 45.93591508719011073936\n",
      "Iteration 35226 => Loss: 45.93575501338586519751\n",
      "Iteration 35227 => Loss: 45.93559494083786631791\n",
      "Iteration 35228 => Loss: 45.93543486954612831141\n",
      "Iteration 35229 => Loss: 45.93527479951060144003\n",
      "Iteration 35230 => Loss: 45.93511473073131412548\n",
      "Iteration 35231 => Loss: 45.93495466320821662976\n",
      "Iteration 35232 => Loss: 45.93479459694135158543\n",
      "Iteration 35233 => Loss: 45.93463453193064083280\n",
      "Iteration 35234 => Loss: 45.93447446817613410985\n",
      "Iteration 35235 => Loss: 45.93431440567781010031\n",
      "Iteration 35236 => Loss: 45.93415434443563327704\n",
      "Iteration 35237 => Loss: 45.93399428444959653461\n",
      "Iteration 35238 => Loss: 45.93383422571971408388\n",
      "Iteration 35239 => Loss: 45.93367416824598592484\n",
      "Iteration 35240 => Loss: 45.93351411202834810865\n",
      "Iteration 35241 => Loss: 45.93335405706682905702\n",
      "Iteration 35242 => Loss: 45.93319400336142166452\n",
      "Iteration 35243 => Loss: 45.93303395091209040402\n",
      "Iteration 35244 => Loss: 45.93287389971887080264\n",
      "Iteration 35245 => Loss: 45.93271384978171312241\n",
      "Iteration 35246 => Loss: 45.93255380110061025789\n",
      "Iteration 35247 => Loss: 45.93239375367558352536\n",
      "Iteration 35248 => Loss: 45.93223370750656187056\n",
      "Iteration 35249 => Loss: 45.93207366259359503147\n",
      "Iteration 35250 => Loss: 45.93191361893666169181\n",
      "Iteration 35251 => Loss: 45.93175357653574053529\n",
      "Iteration 35252 => Loss: 45.93159353539081024564\n",
      "Iteration 35253 => Loss: 45.93143349550187792829\n",
      "Iteration 35254 => Loss: 45.93127345686891516152\n",
      "Iteration 35255 => Loss: 45.93111341949195747247\n",
      "Iteration 35256 => Loss: 45.93095338337095512315\n",
      "Iteration 35257 => Loss: 45.93079334850588679728\n",
      "Iteration 35258 => Loss: 45.93063331489680223285\n",
      "Iteration 35259 => Loss: 45.93047328254363037559\n",
      "Iteration 35260 => Loss: 45.93031325144638543634\n",
      "Iteration 35261 => Loss: 45.93015322160506741511\n",
      "Iteration 35262 => Loss: 45.92999319301964078477\n",
      "Iteration 35263 => Loss: 45.92983316569010554531\n",
      "Iteration 35264 => Loss: 45.92967313961647590759\n",
      "Iteration 35265 => Loss: 45.92951311479870213361\n",
      "Iteration 35266 => Loss: 45.92935309123679132881\n",
      "Iteration 35267 => Loss: 45.92919306893075770404\n",
      "Iteration 35268 => Loss: 45.92903304788056573216\n",
      "Iteration 35269 => Loss: 45.92887302808621541317\n",
      "Iteration 35270 => Loss: 45.92871300954768543079\n",
      "Iteration 35271 => Loss: 45.92855299226496157416\n",
      "Iteration 35272 => Loss: 45.92839297623805094872\n",
      "Iteration 35273 => Loss: 45.92823296146694644904\n",
      "Iteration 35274 => Loss: 45.92807294795161965340\n",
      "Iteration 35275 => Loss: 45.92791293569207056180\n",
      "Iteration 35276 => Loss: 45.92775292468830627968\n",
      "Iteration 35277 => Loss: 45.92759291494029127989\n",
      "Iteration 35278 => Loss: 45.92743290644801135159\n",
      "Iteration 35279 => Loss: 45.92727289921147360019\n",
      "Iteration 35280 => Loss: 45.92711289323066381485\n",
      "Iteration 35281 => Loss: 45.92695288850558199556\n",
      "Iteration 35282 => Loss: 45.92679288503621393147\n",
      "Iteration 35283 => Loss: 45.92663288282253830630\n",
      "Iteration 35284 => Loss: 45.92647288186453380376\n",
      "Iteration 35285 => Loss: 45.92631288216224305643\n",
      "Iteration 35286 => Loss: 45.92615288371558079916\n",
      "Iteration 35287 => Loss: 45.92599288652461808624\n",
      "Iteration 35288 => Loss: 45.92583289058927675796\n",
      "Iteration 35289 => Loss: 45.92567289590957813061\n",
      "Iteration 35290 => Loss: 45.92551290248551509876\n",
      "Iteration 35291 => Loss: 45.92535291031708055698\n",
      "Iteration 35292 => Loss: 45.92519291940423897813\n",
      "Iteration 35293 => Loss: 45.92503292974702588936\n",
      "Iteration 35294 => Loss: 45.92487294134538444723\n",
      "Iteration 35295 => Loss: 45.92471295419931465176\n",
      "Iteration 35296 => Loss: 45.92455296830883071380\n",
      "Iteration 35297 => Loss: 45.92439298367388289535\n",
      "Iteration 35298 => Loss: 45.92423300029451382898\n",
      "Iteration 35299 => Loss: 45.92407301817068798755\n",
      "Iteration 35300 => Loss: 45.92391303730235563307\n",
      "Iteration 35301 => Loss: 45.92375305768958781982\n",
      "Iteration 35302 => Loss: 45.92359307933229928267\n",
      "Iteration 35303 => Loss: 45.92343310223054686503\n",
      "Iteration 35304 => Loss: 45.92327312638426661806\n",
      "Iteration 35305 => Loss: 45.92311315179345854176\n",
      "Iteration 35306 => Loss: 45.92295317845814395241\n",
      "Iteration 35307 => Loss: 45.92279320637826600660\n",
      "Iteration 35308 => Loss: 45.92263323555386023145\n",
      "Iteration 35309 => Loss: 45.92247326598487688898\n",
      "Iteration 35310 => Loss: 45.92231329767135861175\n",
      "Iteration 35311 => Loss: 45.92215333061325566177\n",
      "Iteration 35312 => Loss: 45.92199336481054672277\n",
      "Iteration 35313 => Loss: 45.92183340026324600558\n",
      "Iteration 35314 => Loss: 45.92167343697134640479\n",
      "Iteration 35315 => Loss: 45.92151347493482660411\n",
      "Iteration 35316 => Loss: 45.92135351415368660355\n",
      "Iteration 35317 => Loss: 45.92119355462789798139\n",
      "Iteration 35318 => Loss: 45.92103359635746073764\n",
      "Iteration 35319 => Loss: 45.92087363934237487229\n",
      "Iteration 35320 => Loss: 45.92071368358264749077\n",
      "Iteration 35321 => Loss: 45.92055372907821464423\n",
      "Iteration 35322 => Loss: 45.92039377582909764897\n",
      "Iteration 35323 => Loss: 45.92023382383529650497\n",
      "Iteration 35324 => Loss: 45.92007387309677568510\n",
      "Iteration 35325 => Loss: 45.91991392361354940022\n",
      "Iteration 35326 => Loss: 45.91975397538560343946\n",
      "Iteration 35327 => Loss: 45.91959402841289517028\n",
      "Iteration 35328 => Loss: 45.91943408269548143608\n",
      "Iteration 35329 => Loss: 45.91927413823329828801\n",
      "Iteration 35330 => Loss: 45.91911419502634572609\n",
      "Iteration 35331 => Loss: 45.91895425307462375031\n",
      "Iteration 35332 => Loss: 45.91879431237813946609\n",
      "Iteration 35333 => Loss: 45.91863437293680760831\n",
      "Iteration 35334 => Loss: 45.91847443475071344210\n",
      "Iteration 35335 => Loss: 45.91831449781977880775\n",
      "Iteration 35336 => Loss: 45.91815456214403923241\n",
      "Iteration 35337 => Loss: 45.91799462772347339978\n",
      "Iteration 35338 => Loss: 45.91783469455805288817\n",
      "Iteration 35339 => Loss: 45.91767476264777059214\n",
      "Iteration 35340 => Loss: 45.91751483199265493340\n",
      "Iteration 35341 => Loss: 45.91735490259264196311\n",
      "Iteration 35342 => Loss: 45.91719497444775299755\n",
      "Iteration 35343 => Loss: 45.91703504755795961501\n",
      "Iteration 35344 => Loss: 45.91687512192326892091\n",
      "Iteration 35345 => Loss: 45.91671519754369512611\n",
      "Iteration 35346 => Loss: 45.91655527441917428177\n",
      "Iteration 35347 => Loss: 45.91639535254972770417\n",
      "Iteration 35348 => Loss: 45.91623543193533407702\n",
      "Iteration 35349 => Loss: 45.91607551257598629491\n",
      "Iteration 35350 => Loss: 45.91591559447168435781\n",
      "Iteration 35351 => Loss: 45.91575567762241405489\n",
      "Iteration 35352 => Loss: 45.91559576202816117529\n",
      "Iteration 35353 => Loss: 45.91543584768889729730\n",
      "Iteration 35354 => Loss: 45.91527593460466505348\n",
      "Iteration 35355 => Loss: 45.91511602277539338957\n",
      "Iteration 35356 => Loss: 45.91495611220113204354\n",
      "Iteration 35357 => Loss: 45.91479620288181706655\n",
      "Iteration 35358 => Loss: 45.91463629481746266947\n",
      "Iteration 35359 => Loss: 45.91447638800807595771\n",
      "Iteration 35360 => Loss: 45.91431648245361429872\n",
      "Iteration 35361 => Loss: 45.91415657815407769249\n",
      "Iteration 35362 => Loss: 45.91399667510946613902\n",
      "Iteration 35363 => Loss: 45.91383677331977963831\n",
      "Iteration 35364 => Loss: 45.91367687278499687409\n",
      "Iteration 35365 => Loss: 45.91351697350506100292\n",
      "Iteration 35366 => Loss: 45.91335707548005728995\n",
      "Iteration 35367 => Loss: 45.91319717870990047004\n",
      "Iteration 35368 => Loss: 45.91303728319459764862\n",
      "Iteration 35369 => Loss: 45.91287738893417724739\n",
      "Iteration 35370 => Loss: 45.91271749592857531752\n",
      "Iteration 35371 => Loss: 45.91255760417781317528\n",
      "Iteration 35372 => Loss: 45.91239771368185529354\n",
      "Iteration 35373 => Loss: 45.91223782444072298858\n",
      "Iteration 35374 => Loss: 45.91207793645440915498\n",
      "Iteration 35375 => Loss: 45.91191804972286405473\n",
      "Iteration 35376 => Loss: 45.91175816424610900413\n",
      "Iteration 35377 => Loss: 45.91159828002412268688\n",
      "Iteration 35378 => Loss: 45.91143839705691220843\n",
      "Iteration 35379 => Loss: 45.91127851534444204162\n",
      "Iteration 35380 => Loss: 45.91111863488671929190\n",
      "Iteration 35381 => Loss: 45.91095875568371553754\n",
      "Iteration 35382 => Loss: 45.91079887773547341112\n",
      "Iteration 35383 => Loss: 45.91063900104191475293\n",
      "Iteration 35384 => Loss: 45.91047912560306087926\n",
      "Iteration 35385 => Loss: 45.91031925141889757924\n",
      "Iteration 35386 => Loss: 45.91015937848944616917\n",
      "Iteration 35387 => Loss: 45.90999950681464270019\n",
      "Iteration 35388 => Loss: 45.90983963639452269945\n",
      "Iteration 35389 => Loss: 45.90967976722902932352\n",
      "Iteration 35390 => Loss: 45.90951989931821231039\n",
      "Iteration 35391 => Loss: 45.90936003266201481665\n",
      "Iteration 35392 => Loss: 45.90920016726042973687\n",
      "Iteration 35393 => Loss: 45.90904030311349970361\n",
      "Iteration 35394 => Loss: 45.90888044022112524090\n",
      "Iteration 35395 => Loss: 45.90872057858337740299\n",
      "Iteration 35396 => Loss: 45.90856071820022066277\n",
      "Iteration 35397 => Loss: 45.90840085907161949308\n",
      "Iteration 35398 => Loss: 45.90824100119760231564\n",
      "Iteration 35399 => Loss: 45.90808114457813360332\n",
      "Iteration 35400 => Loss: 45.90792128921319914525\n",
      "Iteration 35401 => Loss: 45.90776143510279183602\n",
      "Iteration 35402 => Loss: 45.90760158224695430818\n",
      "Iteration 35403 => Loss: 45.90744173064560840203\n",
      "Iteration 35404 => Loss: 45.90728188029876122300\n",
      "Iteration 35405 => Loss: 45.90712203120641987653\n",
      "Iteration 35406 => Loss: 45.90696218336856304632\n",
      "Iteration 35407 => Loss: 45.90680233678518362694\n",
      "Iteration 35408 => Loss: 45.90664249145628872384\n",
      "Iteration 35409 => Loss: 45.90648264738183570444\n",
      "Iteration 35410 => Loss: 45.90632280456181035788\n",
      "Iteration 35411 => Loss: 45.90616296299626242217\n",
      "Iteration 35412 => Loss: 45.90600312268512084302\n",
      "Iteration 35413 => Loss: 45.90584328362839983129\n",
      "Iteration 35414 => Loss: 45.90568344582610649240\n",
      "Iteration 35415 => Loss: 45.90552360927818398295\n",
      "Iteration 35416 => Loss: 45.90536377398466072464\n",
      "Iteration 35417 => Loss: 45.90520393994550829575\n",
      "Iteration 35418 => Loss: 45.90504410716073380172\n",
      "Iteration 35419 => Loss: 45.90488427563031592626\n",
      "Iteration 35420 => Loss: 45.90472444535425466938\n",
      "Iteration 35421 => Loss: 45.90456461633252871479\n",
      "Iteration 35422 => Loss: 45.90440478856513095707\n",
      "Iteration 35423 => Loss: 45.90424496205205429078\n",
      "Iteration 35424 => Loss: 45.90408513679329161050\n",
      "Iteration 35425 => Loss: 45.90392531278882870538\n",
      "Iteration 35426 => Loss: 45.90376549003864425913\n",
      "Iteration 35427 => Loss: 45.90360566854276669346\n",
      "Iteration 35428 => Loss: 45.90344584830112495411\n",
      "Iteration 35429 => Loss: 45.90328602931376167362\n",
      "Iteration 35430 => Loss: 45.90312621158064132487\n",
      "Iteration 35431 => Loss: 45.90296639510176390786\n",
      "Iteration 35432 => Loss: 45.90280657987714363344\n",
      "Iteration 35433 => Loss: 45.90264676590671655276\n",
      "Iteration 35434 => Loss: 45.90248695319049687669\n",
      "Iteration 35435 => Loss: 45.90232714172849171064\n",
      "Iteration 35436 => Loss: 45.90216733152068684376\n",
      "Iteration 35437 => Loss: 45.90200752256706806520\n",
      "Iteration 35438 => Loss: 45.90184771486759274239\n",
      "Iteration 35439 => Loss: 45.90168790842228929705\n",
      "Iteration 35440 => Loss: 45.90152810323115772917\n",
      "Iteration 35441 => Loss: 45.90136829929414119533\n",
      "Iteration 35442 => Loss: 45.90120849661127522268\n",
      "Iteration 35443 => Loss: 45.90104869518252428406\n",
      "Iteration 35444 => Loss: 45.90088889500790259035\n",
      "Iteration 35445 => Loss: 45.90072909608736750897\n",
      "Iteration 35446 => Loss: 45.90056929842094746164\n",
      "Iteration 35447 => Loss: 45.90040950200859271035\n",
      "Iteration 35448 => Loss: 45.90024970685030325512\n",
      "Iteration 35449 => Loss: 45.90008991294610751766\n",
      "Iteration 35450 => Loss: 45.89993012029593444367\n",
      "Iteration 35451 => Loss: 45.89977032889980534947\n",
      "Iteration 35452 => Loss: 45.89961053875774865674\n",
      "Iteration 35453 => Loss: 45.89945074986967910036\n",
      "Iteration 35454 => Loss: 45.89929096223563931289\n",
      "Iteration 35455 => Loss: 45.89913117585560797806\n",
      "Iteration 35456 => Loss: 45.89897139072956377959\n",
      "Iteration 35457 => Loss: 45.89881160685750671746\n",
      "Iteration 35458 => Loss: 45.89865182423941547540\n",
      "Iteration 35459 => Loss: 45.89849204287531136970\n",
      "Iteration 35460 => Loss: 45.89833226276513755693\n",
      "Iteration 35461 => Loss: 45.89817248390892956422\n",
      "Iteration 35462 => Loss: 45.89801270630665186445\n",
      "Iteration 35463 => Loss: 45.89785292995830445761\n",
      "Iteration 35464 => Loss: 45.89769315486388023828\n",
      "Iteration 35465 => Loss: 45.89753338102333657389\n",
      "Iteration 35466 => Loss: 45.89737360843671609700\n",
      "Iteration 35467 => Loss: 45.89721383710395485878\n",
      "Iteration 35468 => Loss: 45.89705406702508128092\n",
      "Iteration 35469 => Loss: 45.89689429820008115257\n",
      "Iteration 35470 => Loss: 45.89673453062893315746\n",
      "Iteration 35471 => Loss: 45.89657476431165861186\n",
      "Iteration 35472 => Loss: 45.89641499924817935607\n",
      "Iteration 35473 => Loss: 45.89625523543855223352\n",
      "Iteration 35474 => Loss: 45.89609547288275592791\n",
      "Iteration 35475 => Loss: 45.89593571158074070127\n",
      "Iteration 35476 => Loss: 45.89577595153252786986\n",
      "Iteration 35477 => Loss: 45.89561619273812453912\n",
      "Iteration 35478 => Loss: 45.89545643519747386563\n",
      "Iteration 35479 => Loss: 45.89529667891059716567\n",
      "Iteration 35480 => Loss: 45.89513692387749443924\n",
      "Iteration 35481 => Loss: 45.89497717009811594835\n",
      "Iteration 35482 => Loss: 45.89481741757251143099\n",
      "Iteration 35483 => Loss: 45.89465766630059562203\n",
      "Iteration 35484 => Loss: 45.89449791628243957575\n",
      "Iteration 35485 => Loss: 45.89433816751797223787\n",
      "Iteration 35486 => Loss: 45.89417842000720781925\n",
      "Iteration 35487 => Loss: 45.89401867375013210903\n",
      "Iteration 35488 => Loss: 45.89385892874673089636\n",
      "Iteration 35489 => Loss: 45.89369918499700418124\n",
      "Iteration 35490 => Loss: 45.89353944250093775281\n",
      "Iteration 35491 => Loss: 45.89337970125853871650\n",
      "Iteration 35492 => Loss: 45.89321996126976443975\n",
      "Iteration 35493 => Loss: 45.89306022253460071170\n",
      "Iteration 35494 => Loss: 45.89290048505310437577\n",
      "Iteration 35495 => Loss: 45.89274074882517595597\n",
      "Iteration 35496 => Loss: 45.89258101385087229573\n",
      "Iteration 35497 => Loss: 45.89242128013017207877\n",
      "Iteration 35498 => Loss: 45.89226154766303267252\n",
      "Iteration 35499 => Loss: 45.89210181644945407697\n",
      "Iteration 35500 => Loss: 45.89194208648946471385\n",
      "Iteration 35501 => Loss: 45.89178235778302905601\n",
      "Iteration 35502 => Loss: 45.89162263033012578717\n",
      "Iteration 35503 => Loss: 45.89146290413073359105\n",
      "Iteration 35504 => Loss: 45.89130317918487378392\n",
      "Iteration 35505 => Loss: 45.89114345549256057666\n",
      "Iteration 35506 => Loss: 45.89098373305372291497\n",
      "Iteration 35507 => Loss: 45.89082401186837500973\n",
      "Iteration 35508 => Loss: 45.89066429193652396634\n",
      "Iteration 35509 => Loss: 45.89050457325812715226\n",
      "Iteration 35510 => Loss: 45.89034485583322009461\n",
      "Iteration 35511 => Loss: 45.89018513966175305541\n",
      "Iteration 35512 => Loss: 45.89002542474373314008\n",
      "Iteration 35513 => Loss: 45.88986571107915324319\n",
      "Iteration 35514 => Loss: 45.88970599866797783761\n",
      "Iteration 35515 => Loss: 45.88954628751023534505\n",
      "Iteration 35516 => Loss: 45.88938657760588313295\n",
      "Iteration 35517 => Loss: 45.88922686895494251758\n",
      "Iteration 35518 => Loss: 45.88906716155738507723\n",
      "Iteration 35519 => Loss: 45.88890745541316817935\n",
      "Iteration 35520 => Loss: 45.88874775052236287820\n",
      "Iteration 35521 => Loss: 45.88858804688489101409\n",
      "Iteration 35522 => Loss: 45.88842834450077390329\n",
      "Iteration 35523 => Loss: 45.88826864336999733496\n",
      "Iteration 35524 => Loss: 45.88810894349253999280\n",
      "Iteration 35525 => Loss: 45.88794924486839477140\n",
      "Iteration 35526 => Loss: 45.88778954749753324904\n",
      "Iteration 35527 => Loss: 45.88762985138000516372\n",
      "Iteration 35528 => Loss: 45.88747015651575367201\n",
      "Iteration 35529 => Loss: 45.88731046290478587935\n",
      "Iteration 35530 => Loss: 45.88715077054707336401\n",
      "Iteration 35531 => Loss: 45.88699107944263033687\n",
      "Iteration 35532 => Loss: 45.88683138959142127078\n",
      "Iteration 35533 => Loss: 45.88667170099345327117\n",
      "Iteration 35534 => Loss: 45.88651201364871212718\n",
      "Iteration 35535 => Loss: 45.88635232755719783881\n",
      "Iteration 35536 => Loss: 45.88619264271886066808\n",
      "Iteration 35537 => Loss: 45.88603295913377166926\n",
      "Iteration 35538 => Loss: 45.88587327680183847178\n",
      "Iteration 35539 => Loss: 45.88571359572308239194\n",
      "Iteration 35540 => Loss: 45.88555391589748921888\n",
      "Iteration 35541 => Loss: 45.88539423732508737430\n",
      "Iteration 35542 => Loss: 45.88523456000579869851\n",
      "Iteration 35543 => Loss: 45.88507488393967292950\n",
      "Iteration 35544 => Loss: 45.88491520912666743470\n",
      "Iteration 35545 => Loss: 45.88475553556677510869\n",
      "Iteration 35546 => Loss: 45.88459586326002437318\n",
      "Iteration 35547 => Loss: 45.88443619220632996303\n",
      "Iteration 35548 => Loss: 45.88427652240574872167\n",
      "Iteration 35549 => Loss: 45.88411685385825222738\n",
      "Iteration 35550 => Loss: 45.88395718656380495304\n",
      "Iteration 35551 => Loss: 45.88379752052244953120\n",
      "Iteration 35552 => Loss: 45.88363785573412911845\n",
      "Iteration 35553 => Loss: 45.88347819219883660935\n",
      "Iteration 35554 => Loss: 45.88331852991659332019\n",
      "Iteration 35555 => Loss: 45.88315886888736372384\n",
      "Iteration 35556 => Loss: 45.88299920911113360944\n",
      "Iteration 35557 => Loss: 45.88283955058791718784\n",
      "Iteration 35558 => Loss: 45.88267989331769314276\n",
      "Iteration 35559 => Loss: 45.88252023730045436878\n",
      "Iteration 35560 => Loss: 45.88236058253617954961\n",
      "Iteration 35561 => Loss: 45.88220092902487579067\n",
      "Iteration 35562 => Loss: 45.88204127676650045942\n",
      "Iteration 35563 => Loss: 45.88188162576110329383\n",
      "Iteration 35564 => Loss: 45.88172197600861323963\n",
      "Iteration 35565 => Loss: 45.88156232750905161311\n",
      "Iteration 35566 => Loss: 45.88140268026242551969\n",
      "Iteration 35567 => Loss: 45.88124303426867101052\n",
      "Iteration 35568 => Loss: 45.88108338952782361275\n",
      "Iteration 35569 => Loss: 45.88092374603984779924\n",
      "Iteration 35570 => Loss: 45.88076410380475778084\n",
      "Iteration 35571 => Loss: 45.88060446282255355754\n",
      "Iteration 35572 => Loss: 45.88044482309316407509\n",
      "Iteration 35573 => Loss: 45.88028518461661775518\n",
      "Iteration 35574 => Loss: 45.88012554739294301953\n",
      "Iteration 35575 => Loss: 45.87996591142204039215\n",
      "Iteration 35576 => Loss: 45.87980627670400224360\n",
      "Iteration 35577 => Loss: 45.87964664323876462504\n",
      "Iteration 35578 => Loss: 45.87948701102629200932\n",
      "Iteration 35579 => Loss: 45.87932738006661992358\n",
      "Iteration 35580 => Loss: 45.87916775035971994612\n",
      "Iteration 35581 => Loss: 45.87900812190560628778\n",
      "Iteration 35582 => Loss: 45.87884849470421499973\n",
      "Iteration 35583 => Loss: 45.87868886875558871452\n",
      "Iteration 35584 => Loss: 45.87852924405969190502\n",
      "Iteration 35585 => Loss: 45.87836962061653167666\n",
      "Iteration 35586 => Loss: 45.87820999842607250230\n",
      "Iteration 35587 => Loss: 45.87805037748833569822\n",
      "Iteration 35588 => Loss: 45.87789075780329284271\n",
      "Iteration 35589 => Loss: 45.87773113937091551406\n",
      "Iteration 35590 => Loss: 45.87757152219124634485\n",
      "Iteration 35591 => Loss: 45.87741190626422849164\n",
      "Iteration 35592 => Loss: 45.87725229158986195444\n",
      "Iteration 35593 => Loss: 45.87709267816816094410\n",
      "Iteration 35594 => Loss: 45.87693306599907572263\n",
      "Iteration 35595 => Loss: 45.87677345508263471174\n",
      "Iteration 35596 => Loss: 45.87661384541881659516\n",
      "Iteration 35597 => Loss: 45.87645423700760005659\n",
      "Iteration 35598 => Loss: 45.87629462984897088518\n",
      "Iteration 35599 => Loss: 45.87613502394293618636\n",
      "Iteration 35600 => Loss: 45.87597541928948174927\n",
      "Iteration 35601 => Loss: 45.87581581588861467935\n",
      "Iteration 35602 => Loss: 45.87565621374028523860\n",
      "Iteration 35603 => Loss: 45.87549661284448632159\n",
      "Iteration 35604 => Loss: 45.87533701320126766632\n",
      "Iteration 35605 => Loss: 45.87517741481055111308\n",
      "Iteration 35606 => Loss: 45.87501781767235797815\n",
      "Iteration 35607 => Loss: 45.87485822178668826155\n",
      "Iteration 35608 => Loss: 45.87469862715351354154\n",
      "Iteration 35609 => Loss: 45.87453903377282671272\n",
      "Iteration 35610 => Loss: 45.87437944164462066965\n",
      "Iteration 35611 => Loss: 45.87421985076888120147\n",
      "Iteration 35612 => Loss: 45.87406026114560830820\n",
      "Iteration 35613 => Loss: 45.87390067277478067354\n",
      "Iteration 35614 => Loss: 45.87374108565639829749\n",
      "Iteration 35615 => Loss: 45.87358149979043275835\n",
      "Iteration 35616 => Loss: 45.87342191517691247782\n",
      "Iteration 35617 => Loss: 45.87326233181580192877\n",
      "Iteration 35618 => Loss: 45.87310274970707979492\n",
      "Iteration 35619 => Loss: 45.87294316885075318169\n",
      "Iteration 35620 => Loss: 45.87278358924680787823\n",
      "Iteration 35621 => Loss: 45.87262401089525098996\n",
      "Iteration 35622 => Loss: 45.87246443379603277890\n",
      "Iteration 35623 => Loss: 45.87230485794918166675\n",
      "Iteration 35624 => Loss: 45.87214528335467633724\n",
      "Iteration 35625 => Loss: 45.87198571001248836865\n",
      "Iteration 35626 => Loss: 45.87182613792262486641\n",
      "Iteration 35627 => Loss: 45.87166656708507872509\n",
      "Iteration 35628 => Loss: 45.87150699749984994469\n",
      "Iteration 35629 => Loss: 45.87134742916688168179\n",
      "Iteration 35630 => Loss: 45.87118786208623077982\n",
      "Iteration 35631 => Loss: 45.87102829625784750078\n",
      "Iteration 35632 => Loss: 45.87086873168173184467\n",
      "Iteration 35633 => Loss: 45.87070916835784828436\n",
      "Iteration 35634 => Loss: 45.87054960628622524155\n",
      "Iteration 35635 => Loss: 45.87039004546683429453\n",
      "Iteration 35636 => Loss: 45.87023048589966833788\n",
      "Iteration 35637 => Loss: 45.87007092758471316074\n",
      "Iteration 35638 => Loss: 45.86991137052198297397\n",
      "Iteration 35639 => Loss: 45.86975181471143514500\n",
      "Iteration 35640 => Loss: 45.86959226015305546298\n",
      "Iteration 35641 => Loss: 45.86943270684688656047\n",
      "Iteration 35642 => Loss: 45.86927315479284317234\n",
      "Iteration 35643 => Loss: 45.86911360399099635288\n",
      "Iteration 35644 => Loss: 45.86895405444126083694\n",
      "Iteration 35645 => Loss: 45.86879450614367925709\n",
      "Iteration 35646 => Loss: 45.86863495909823740249\n",
      "Iteration 35647 => Loss: 45.86847541330489264055\n",
      "Iteration 35648 => Loss: 45.86831586876365918215\n",
      "Iteration 35649 => Loss: 45.86815632547451571099\n",
      "Iteration 35650 => Loss: 45.86799678343746933251\n",
      "Iteration 35651 => Loss: 45.86783724265251294128\n",
      "Iteration 35652 => Loss: 45.86767770311958969387\n",
      "Iteration 35653 => Loss: 45.86751816483876353914\n",
      "Iteration 35654 => Loss: 45.86735862780995631738\n",
      "Iteration 35655 => Loss: 45.86719909203319645030\n",
      "Iteration 35656 => Loss: 45.86703955750846972705\n",
      "Iteration 35657 => Loss: 45.86688002423574062050\n",
      "Iteration 35658 => Loss: 45.86672049221505176320\n",
      "Iteration 35659 => Loss: 45.86656096144634631173\n",
      "Iteration 35660 => Loss: 45.86640143192963137153\n",
      "Iteration 35661 => Loss: 45.86624190366489983717\n",
      "Iteration 35662 => Loss: 45.86608237665212328693\n",
      "Iteration 35663 => Loss: 45.86592285089130882625\n",
      "Iteration 35664 => Loss: 45.86576332638246356055\n",
      "Iteration 35665 => Loss: 45.86560380312553775184\n",
      "Iteration 35666 => Loss: 45.86544428112055271640\n",
      "Iteration 35667 => Loss: 45.86528476036748713796\n",
      "Iteration 35668 => Loss: 45.86512524086632680564\n",
      "Iteration 35669 => Loss: 45.86496572261707882490\n",
      "Iteration 35670 => Loss: 45.86480620561970766857\n",
      "Iteration 35671 => Loss: 45.86464668987421333668\n",
      "Iteration 35672 => Loss: 45.86448717538061004007\n",
      "Iteration 35673 => Loss: 45.86432766213885514617\n",
      "Iteration 35674 => Loss: 45.86416815014896286584\n",
      "Iteration 35675 => Loss: 45.86400863941090477738\n",
      "Iteration 35676 => Loss: 45.86384912992468798620\n",
      "Iteration 35677 => Loss: 45.86368962169026985976\n",
      "Iteration 35678 => Loss: 45.86353011470767881974\n",
      "Iteration 35679 => Loss: 45.86337060897688644445\n",
      "Iteration 35680 => Loss: 45.86321110449789273389\n",
      "Iteration 35681 => Loss: 45.86305160127066216091\n",
      "Iteration 35682 => Loss: 45.86289209929522314724\n",
      "Iteration 35683 => Loss: 45.86273259857155437658\n",
      "Iteration 35684 => Loss: 45.86257309909962742722\n",
      "Iteration 35685 => Loss: 45.86241360087945651003\n",
      "Iteration 35686 => Loss: 45.86225410391098478158\n",
      "Iteration 35687 => Loss: 45.86209460819426197986\n",
      "Iteration 35688 => Loss: 45.86193511372928099945\n",
      "Iteration 35689 => Loss: 45.86177562051595657522\n",
      "Iteration 35690 => Loss: 45.86161612855433133973\n",
      "Iteration 35691 => Loss: 45.86145663784441950384\n",
      "Iteration 35692 => Loss: 45.86129714838616422412\n",
      "Iteration 35693 => Loss: 45.86113766017957971144\n",
      "Iteration 35694 => Loss: 45.86097817322465886036\n",
      "Iteration 35695 => Loss: 45.86081868752135903833\n",
      "Iteration 35696 => Loss: 45.86065920306971577247\n",
      "Iteration 35697 => Loss: 45.86049971986967221937\n",
      "Iteration 35698 => Loss: 45.86034023792127811703\n",
      "Iteration 35699 => Loss: 45.86018075722445530573\n",
      "Iteration 35700 => Loss: 45.86002127777925352348\n",
      "Iteration 35701 => Loss: 45.85986179958563724313\n",
      "Iteration 35702 => Loss: 45.85970232264359225383\n",
      "Iteration 35703 => Loss: 45.85954284695309723929\n",
      "Iteration 35704 => Loss: 45.85938337251417351581\n",
      "Iteration 35705 => Loss: 45.85922389932680687252\n",
      "Iteration 35706 => Loss: 45.85906442739096888772\n",
      "Iteration 35707 => Loss: 45.85890495670666666683\n",
      "Iteration 35708 => Loss: 45.85874548727386468272\n",
      "Iteration 35709 => Loss: 45.85858601909258425167\n",
      "Iteration 35710 => Loss: 45.85842655216279695196\n",
      "Iteration 35711 => Loss: 45.85826708648448857275\n",
      "Iteration 35712 => Loss: 45.85810762205766621946\n",
      "Iteration 35713 => Loss: 45.85794815888231568124\n",
      "Iteration 35714 => Loss: 45.85778869695842274723\n",
      "Iteration 35715 => Loss: 45.85762923628597320658\n",
      "Iteration 35716 => Loss: 45.85746977686495284843\n",
      "Iteration 35717 => Loss: 45.85731031869539009449\n",
      "Iteration 35718 => Loss: 45.85715086177724941763\n",
      "Iteration 35719 => Loss: 45.85699140611048107985\n",
      "Iteration 35720 => Loss: 45.85683195169514192457\n",
      "Iteration 35721 => Loss: 45.85667249853118931924\n",
      "Iteration 35722 => Loss: 45.85651304661858773670\n",
      "Iteration 35723 => Loss: 45.85635359595738691496\n",
      "Iteration 35724 => Loss: 45.85619414654755132688\n",
      "Iteration 35725 => Loss: 45.85603469838905255074\n",
      "Iteration 35726 => Loss: 45.85587525148187637569\n",
      "Iteration 35727 => Loss: 45.85571580582604411802\n",
      "Iteration 35728 => Loss: 45.85555636142154867230\n",
      "Iteration 35729 => Loss: 45.85539691826834740596\n",
      "Iteration 35730 => Loss: 45.85523747636646874071\n",
      "Iteration 35731 => Loss: 45.85507803571586293856\n",
      "Iteration 35732 => Loss: 45.85491859631654421037\n",
      "Iteration 35733 => Loss: 45.85475915816849123985\n",
      "Iteration 35734 => Loss: 45.85459972127170402700\n",
      "Iteration 35735 => Loss: 45.85444028562618257183\n",
      "Iteration 35736 => Loss: 45.85428085123188424177\n",
      "Iteration 35737 => Loss: 45.85412141808882324767\n",
      "Iteration 35738 => Loss: 45.85396198619699958954\n",
      "Iteration 35739 => Loss: 45.85380255555636352938\n",
      "Iteration 35740 => Loss: 45.85364312616695059432\n",
      "Iteration 35741 => Loss: 45.85348369802872525725\n",
      "Iteration 35742 => Loss: 45.85332427114168751814\n",
      "Iteration 35743 => Loss: 45.85316484550580895529\n",
      "Iteration 35744 => Loss: 45.85300542112111088500\n",
      "Iteration 35745 => Loss: 45.85284599798756488553\n",
      "Iteration 35746 => Loss: 45.85268657610514964063\n",
      "Iteration 35747 => Loss: 45.85252715547387936113\n",
      "Iteration 35748 => Loss: 45.85236773609374694161\n",
      "Iteration 35749 => Loss: 45.85220831796472396036\n",
      "Iteration 35750 => Loss: 45.85204890108677489025\n",
      "Iteration 35751 => Loss: 45.85188948545996368011\n",
      "Iteration 35752 => Loss: 45.85173007108421927569\n",
      "Iteration 35753 => Loss: 45.85157065795954167697\n",
      "Iteration 35754 => Loss: 45.85141124608593798939\n",
      "Iteration 35755 => Loss: 45.85125183546338689666\n",
      "Iteration 35756 => Loss: 45.85109242609188839879\n",
      "Iteration 35757 => Loss: 45.85093301797141407405\n",
      "Iteration 35758 => Loss: 45.85077361110197813332\n",
      "Iteration 35759 => Loss: 45.85061420548357347116\n",
      "Iteration 35760 => Loss: 45.85045480111615745500\n",
      "Iteration 35761 => Loss: 45.85029539799972297942\n",
      "Iteration 35762 => Loss: 45.85013599613430557156\n",
      "Iteration 35763 => Loss: 45.84997659551984838799\n",
      "Iteration 35764 => Loss: 45.84981719615635142873\n",
      "Iteration 35765 => Loss: 45.84965779804382890461\n",
      "Iteration 35766 => Loss: 45.84949840118225239394\n",
      "Iteration 35767 => Loss: 45.84933900557160768585\n",
      "Iteration 35768 => Loss: 45.84917961121189478035\n",
      "Iteration 35769 => Loss: 45.84902021810310657202\n",
      "Iteration 35770 => Loss: 45.84886082624521463913\n",
      "Iteration 35771 => Loss: 45.84870143563821898169\n",
      "Iteration 35772 => Loss: 45.84854204628212670514\n",
      "Iteration 35773 => Loss: 45.84838265817690938775\n",
      "Iteration 35774 => Loss: 45.84822327132255281867\n",
      "Iteration 35775 => Loss: 45.84806388571907120877\n",
      "Iteration 35776 => Loss: 45.84790450136643613632\n",
      "Iteration 35777 => Loss: 45.84774511826463339048\n",
      "Iteration 35778 => Loss: 45.84758573641365586582\n",
      "Iteration 35779 => Loss: 45.84742635581350356233\n",
      "Iteration 35780 => Loss: 45.84726697646418358545\n",
      "Iteration 35781 => Loss: 45.84710759836562488090\n",
      "Iteration 35782 => Loss: 45.84694822151789850295\n",
      "Iteration 35783 => Loss: 45.84678884592092629191\n",
      "Iteration 35784 => Loss: 45.84662947157472956405\n",
      "Iteration 35785 => Loss: 45.84647009847930121396\n",
      "Iteration 35786 => Loss: 45.84631072663461281991\n",
      "Iteration 35787 => Loss: 45.84615135604068569819\n",
      "Iteration 35788 => Loss: 45.84599198669747011081\n",
      "Iteration 35789 => Loss: 45.84583261860498026863\n",
      "Iteration 35790 => Loss: 45.84567325176320906621\n",
      "Iteration 35791 => Loss: 45.84551388617213518728\n",
      "Iteration 35792 => Loss: 45.84535452183176573726\n",
      "Iteration 35793 => Loss: 45.84519515874206518902\n",
      "Iteration 35794 => Loss: 45.84503579690304775340\n",
      "Iteration 35795 => Loss: 45.84487643631468500871\n",
      "Iteration 35796 => Loss: 45.84471707697697695494\n",
      "Iteration 35797 => Loss: 45.84455771888991648666\n",
      "Iteration 35798 => Loss: 45.84439836205350360387\n",
      "Iteration 35799 => Loss: 45.84423900646768856859\n",
      "Iteration 35800 => Loss: 45.84407965213249980252\n",
      "Iteration 35801 => Loss: 45.84392029904793020023\n",
      "Iteration 35802 => Loss: 45.84376094721393712916\n",
      "Iteration 35803 => Loss: 45.84360159663052769474\n",
      "Iteration 35804 => Loss: 45.84344224729768058069\n",
      "Iteration 35805 => Loss: 45.84328289921542420871\n",
      "Iteration 35806 => Loss: 45.84312355238371594623\n",
      "Iteration 35807 => Loss: 45.84296420680254868785\n",
      "Iteration 35808 => Loss: 45.84280486247191532811\n",
      "Iteration 35809 => Loss: 45.84264551939182297247\n",
      "Iteration 35810 => Loss: 45.84248617756224319919\n",
      "Iteration 35811 => Loss: 45.84232683698315469201\n",
      "Iteration 35812 => Loss: 45.84216749765457166177\n",
      "Iteration 35813 => Loss: 45.84200815957647279220\n",
      "Iteration 35814 => Loss: 45.84184882274886518871\n",
      "Iteration 35815 => Loss: 45.84168948717169911333\n",
      "Iteration 35816 => Loss: 45.84153015284499588233\n",
      "Iteration 35817 => Loss: 45.84137081976876260114\n",
      "Iteration 35818 => Loss: 45.84121148794292821549\n",
      "Iteration 35819 => Loss: 45.84105215736756377964\n",
      "Iteration 35820 => Loss: 45.84089282804260534476\n",
      "Iteration 35821 => Loss: 45.84073349996803159456\n",
      "Iteration 35822 => Loss: 45.84057417314387805618\n",
      "Iteration 35823 => Loss: 45.84041484757010209705\n",
      "Iteration 35824 => Loss: 45.84025552324672503346\n",
      "Iteration 35825 => Loss: 45.84009620017369002198\n",
      "Iteration 35826 => Loss: 45.83993687835103258976\n",
      "Iteration 35827 => Loss: 45.83977755777872431509\n",
      "Iteration 35828 => Loss: 45.83961823845675098710\n",
      "Iteration 35829 => Loss: 45.83945892038510550037\n",
      "Iteration 35830 => Loss: 45.83929960356377364405\n",
      "Iteration 35831 => Loss: 45.83914028799275541814\n",
      "Iteration 35832 => Loss: 45.83898097367204371722\n",
      "Iteration 35833 => Loss: 45.83882166060161722498\n",
      "Iteration 35834 => Loss: 45.83866234878147594145\n",
      "Iteration 35835 => Loss: 45.83850303821160565576\n",
      "Iteration 35836 => Loss: 45.83834372889198505163\n",
      "Iteration 35837 => Loss: 45.83818442082264255077\n",
      "Iteration 35838 => Loss: 45.83802511400350709891\n",
      "Iteration 35839 => Loss: 45.83786580843461422319\n",
      "Iteration 35840 => Loss: 45.83770650411596392360\n",
      "Iteration 35841 => Loss: 45.83754720104749225129\n",
      "Iteration 35842 => Loss: 45.83738789922924894427\n",
      "Iteration 35843 => Loss: 45.83722859866120558081\n",
      "Iteration 35844 => Loss: 45.83706929934331952836\n",
      "Iteration 35845 => Loss: 45.83691000127559789235\n",
      "Iteration 35846 => Loss: 45.83675070445805488362\n",
      "Iteration 35847 => Loss: 45.83659140889066208047\n",
      "Iteration 35848 => Loss: 45.83643211457341948289\n",
      "Iteration 35849 => Loss: 45.83627282150631288005\n",
      "Iteration 35850 => Loss: 45.83611352968933516649\n",
      "Iteration 35851 => Loss: 45.83595423912245081510\n",
      "Iteration 35852 => Loss: 45.83579494980566693130\n",
      "Iteration 35853 => Loss: 45.83563566173900483136\n",
      "Iteration 35854 => Loss: 45.83547637492241477730\n",
      "Iteration 35855 => Loss: 45.83531708935588966369\n",
      "Iteration 35856 => Loss: 45.83515780503942949053\n",
      "Iteration 35857 => Loss: 45.83499852197303425783\n",
      "Iteration 35858 => Loss: 45.83483924015666843843\n",
      "Iteration 35859 => Loss: 45.83467995959036755949\n",
      "Iteration 35860 => Loss: 45.83452068027406767214\n",
      "Iteration 35861 => Loss: 45.83436140220779009269\n",
      "Iteration 35862 => Loss: 45.83420212539152771569\n",
      "Iteration 35863 => Loss: 45.83404284982523790859\n",
      "Iteration 35864 => Loss: 45.83388357550896330395\n",
      "Iteration 35865 => Loss: 45.83372430244264705834\n",
      "Iteration 35866 => Loss: 45.83356503062631048806\n",
      "Iteration 35867 => Loss: 45.83340576005990385511\n",
      "Iteration 35868 => Loss: 45.83324649074346268662\n",
      "Iteration 35869 => Loss: 45.83308722267696566632\n",
      "Iteration 35870 => Loss: 45.83292795586039858335\n",
      "Iteration 35871 => Loss: 45.83276869029373301601\n",
      "Iteration 35872 => Loss: 45.83260942597696896428\n",
      "Iteration 35873 => Loss: 45.83245016291011353360\n",
      "Iteration 35874 => Loss: 45.83229090109315961854\n",
      "Iteration 35875 => Loss: 45.83213164052606458654\n",
      "Iteration 35876 => Loss: 45.83197238120885685930\n",
      "Iteration 35877 => Loss: 45.83181312314148669884\n",
      "Iteration 35878 => Loss: 45.83165386632398252686\n",
      "Iteration 35879 => Loss: 45.83149461075629460538\n",
      "Iteration 35880 => Loss: 45.83133535643845846153\n",
      "Iteration 35881 => Loss: 45.83117610337045988445\n",
      "Iteration 35882 => Loss: 45.83101685155222071444\n",
      "Iteration 35883 => Loss: 45.83085760098380490035\n",
      "Iteration 35884 => Loss: 45.83069835166518402048\n",
      "Iteration 35885 => Loss: 45.83053910359634386396\n",
      "Iteration 35886 => Loss: 45.83037985677727021994\n",
      "Iteration 35887 => Loss: 45.83022061120796308842\n",
      "Iteration 35888 => Loss: 45.83006136688839404769\n",
      "Iteration 35889 => Loss: 45.82990212381857730861\n",
      "Iteration 35890 => Loss: 45.82974288199849866032\n",
      "Iteration 35891 => Loss: 45.82958364142811547026\n",
      "Iteration 35892 => Loss: 45.82942440210746326557\n",
      "Iteration 35893 => Loss: 45.82926516403651362452\n",
      "Iteration 35894 => Loss: 45.82910592721524523085\n",
      "Iteration 35895 => Loss: 45.82894669164365808456\n",
      "Iteration 35896 => Loss: 45.82878745732174508021\n",
      "Iteration 35897 => Loss: 45.82862822424952753408\n",
      "Iteration 35898 => Loss: 45.82846899242692018106\n",
      "Iteration 35899 => Loss: 45.82830976185395854827\n",
      "Iteration 35900 => Loss: 45.82815053253064974115\n",
      "Iteration 35901 => Loss: 45.82799130445695823255\n",
      "Iteration 35902 => Loss: 45.82783207763287691705\n",
      "Iteration 35903 => Loss: 45.82767285205839868922\n",
      "Iteration 35904 => Loss: 45.82751362773353065450\n",
      "Iteration 35905 => Loss: 45.82735440465823018030\n",
      "Iteration 35906 => Loss: 45.82719518283251147750\n",
      "Iteration 35907 => Loss: 45.82703596225635322980\n",
      "Iteration 35908 => Loss: 45.82687674292972701551\n",
      "Iteration 35909 => Loss: 45.82671752485267546717\n",
      "Iteration 35910 => Loss: 45.82655830802514884681\n",
      "Iteration 35911 => Loss: 45.82639909244716136527\n",
      "Iteration 35912 => Loss: 45.82623987811867038999\n",
      "Iteration 35913 => Loss: 45.82608066503969723726\n",
      "Iteration 35914 => Loss: 45.82592145321020637994\n",
      "Iteration 35915 => Loss: 45.82576224263022623973\n",
      "Iteration 35916 => Loss: 45.82560303329969997321\n",
      "Iteration 35917 => Loss: 45.82544382521862758040\n",
      "Iteration 35918 => Loss: 45.82528461838703037756\n",
      "Iteration 35919 => Loss: 45.82512541280488704842\n",
      "Iteration 35920 => Loss: 45.82496620847218338213\n",
      "Iteration 35921 => Loss: 45.82480700538889806239\n",
      "Iteration 35922 => Loss: 45.82464780355501687836\n",
      "Iteration 35923 => Loss: 45.82448860297056114632\n",
      "Iteration 35924 => Loss: 45.82432940363549533913\n",
      "Iteration 35925 => Loss: 45.82417020554983366765\n",
      "Iteration 35926 => Loss: 45.82401100871353349930\n",
      "Iteration 35927 => Loss: 45.82385181312658062325\n",
      "Iteration 35928 => Loss: 45.82369261878903188290\n",
      "Iteration 35929 => Loss: 45.82353342570080911855\n",
      "Iteration 35930 => Loss: 45.82337423386191233021\n",
      "Iteration 35931 => Loss: 45.82321504327236283416\n",
      "Iteration 35932 => Loss: 45.82305585393214641954\n",
      "Iteration 35933 => Loss: 45.82289666584122045379\n",
      "Iteration 35934 => Loss: 45.82273747899959204233\n",
      "Iteration 35935 => Loss: 45.82257829340725407974\n",
      "Iteration 35936 => Loss: 45.82241910906419235516\n",
      "Iteration 35937 => Loss: 45.82225992597041397403\n",
      "Iteration 35938 => Loss: 45.82210074412590472548\n",
      "Iteration 35939 => Loss: 45.82194156353061487152\n",
      "Iteration 35940 => Loss: 45.82178238418460125558\n",
      "Iteration 35941 => Loss: 45.82162320608777861253\n",
      "Iteration 35942 => Loss: 45.82146402924021799663\n",
      "Iteration 35943 => Loss: 45.82130485364183414276\n",
      "Iteration 35944 => Loss: 45.82114567929267678892\n",
      "Iteration 35945 => Loss: 45.82098650619269619710\n",
      "Iteration 35946 => Loss: 45.82082733434191368360\n",
      "Iteration 35947 => Loss: 45.82066816374029372128\n",
      "Iteration 35948 => Loss: 45.82050899438783631012\n",
      "Iteration 35949 => Loss: 45.82034982628453434472\n",
      "Iteration 35950 => Loss: 45.82019065943038071964\n",
      "Iteration 35951 => Loss: 45.82003149382533280232\n",
      "Iteration 35952 => Loss: 45.81987232946944743617\n",
      "Iteration 35953 => Loss: 45.81971316636265356692\n",
      "Iteration 35954 => Loss: 45.81955400450495830000\n",
      "Iteration 35955 => Loss: 45.81939484389636163542\n",
      "Iteration 35956 => Loss: 45.81923568453684936230\n",
      "Iteration 35957 => Loss: 45.81907652642643569152\n",
      "Iteration 35958 => Loss: 45.81891736956503535794\n",
      "Iteration 35959 => Loss: 45.81875821395273362668\n",
      "Iteration 35960 => Loss: 45.81859905958945944349\n",
      "Iteration 35961 => Loss: 45.81843990647521991377\n",
      "Iteration 35962 => Loss: 45.81828075460999372126\n",
      "Iteration 35963 => Loss: 45.81812160399380218223\n",
      "Iteration 35964 => Loss: 45.81796245462661687498\n",
      "Iteration 35965 => Loss: 45.81780330650843069407\n",
      "Iteration 35966 => Loss: 45.81764415963920811237\n",
      "Iteration 35967 => Loss: 45.81748501401898465701\n",
      "Iteration 35968 => Loss: 45.81732586964772480087\n",
      "Iteration 35969 => Loss: 45.81716672652540722765\n",
      "Iteration 35970 => Loss: 45.81700758465206746450\n",
      "Iteration 35971 => Loss: 45.81684844402762735172\n",
      "Iteration 35972 => Loss: 45.81668930465211531100\n",
      "Iteration 35973 => Loss: 45.81653016652553844779\n",
      "Iteration 35974 => Loss: 45.81637102964786834036\n",
      "Iteration 35975 => Loss: 45.81621189401909077787\n",
      "Iteration 35976 => Loss: 45.81605275963920576032\n",
      "Iteration 35977 => Loss: 45.81589362650819197142\n",
      "Iteration 35978 => Loss: 45.81573449462604230575\n",
      "Iteration 35979 => Loss: 45.81557536399278518502\n",
      "Iteration 35980 => Loss: 45.81541623460833534409\n",
      "Iteration 35981 => Loss: 45.81525710647274962639\n",
      "Iteration 35982 => Loss: 45.81509797958597829393\n",
      "Iteration 35983 => Loss: 45.81493885394804266298\n",
      "Iteration 35984 => Loss: 45.81477972955890720641\n",
      "Iteration 35985 => Loss: 45.81462060641857902965\n",
      "Iteration 35986 => Loss: 45.81446148452701550013\n",
      "Iteration 35987 => Loss: 45.81430236388425925043\n",
      "Iteration 35988 => Loss: 45.81414324449025343711\n",
      "Iteration 35989 => Loss: 45.81398412634502648189\n",
      "Iteration 35990 => Loss: 45.81382500944854996305\n",
      "Iteration 35991 => Loss: 45.81366589380080966976\n",
      "Iteration 35992 => Loss: 45.81350677940177718028\n",
      "Iteration 35993 => Loss: 45.81334766625150223263\n",
      "Iteration 35994 => Loss: 45.81318855434991377251\n",
      "Iteration 35995 => Loss: 45.81302944369704732708\n",
      "Iteration 35996 => Loss: 45.81287033429284605290\n",
      "Iteration 35997 => Loss: 45.81271122613735968798\n",
      "Iteration 35998 => Loss: 45.81255211923053138889\n",
      "Iteration 35999 => Loss: 45.81239301357235405021\n",
      "Iteration 36000 => Loss: 45.81223390916285609364\n",
      "Iteration 36001 => Loss: 45.81207480600196646492\n",
      "Iteration 36002 => Loss: 45.81191570408972069117\n",
      "Iteration 36003 => Loss: 45.81175660342611166698\n",
      "Iteration 36004 => Loss: 45.81159750401111097062\n",
      "Iteration 36005 => Loss: 45.81143840584472570754\n",
      "Iteration 36006 => Loss: 45.81127930892692745601\n",
      "Iteration 36007 => Loss: 45.81112021325770200519\n",
      "Iteration 36008 => Loss: 45.81096111883704224965\n",
      "Iteration 36009 => Loss: 45.81080202566497661110\n",
      "Iteration 36010 => Loss: 45.81064293374145535154\n",
      "Iteration 36011 => Loss: 45.81048384306646426012\n",
      "Iteration 36012 => Loss: 45.81032475364003175855\n",
      "Iteration 36013 => Loss: 45.81016566546210810884\n",
      "Iteration 36014 => Loss: 45.81000657853269331099\n",
      "Iteration 36015 => Loss: 45.80984749285178736500\n",
      "Iteration 36016 => Loss: 45.80968840841938316544\n",
      "Iteration 36017 => Loss: 45.80952932523548781774\n",
      "Iteration 36018 => Loss: 45.80937024330003737305\n",
      "Iteration 36019 => Loss: 45.80921116261306735851\n",
      "Iteration 36020 => Loss: 45.80905208317456356326\n",
      "Iteration 36021 => Loss: 45.80889300498448335475\n",
      "Iteration 36022 => Loss: 45.80873392804284804924\n",
      "Iteration 36023 => Loss: 45.80857485234965054133\n",
      "Iteration 36024 => Loss: 45.80841577790486951471\n",
      "Iteration 36025 => Loss: 45.80825670470849786398\n",
      "Iteration 36026 => Loss: 45.80809763276049295655\n",
      "Iteration 36027 => Loss: 45.80793856206089742500\n",
      "Iteration 36028 => Loss: 45.80777949260968995304\n",
      "Iteration 36029 => Loss: 45.80762042440683501354\n",
      "Iteration 36030 => Loss: 45.80746135745237523906\n",
      "Iteration 36031 => Loss: 45.80730229174623246990\n",
      "Iteration 36032 => Loss: 45.80714322728842802235\n",
      "Iteration 36033 => Loss: 45.80698416407896189639\n",
      "Iteration 36034 => Loss: 45.80682510211780567033\n",
      "Iteration 36035 => Loss: 45.80666604140497355502\n",
      "Iteration 36036 => Loss: 45.80650698194042291789\n",
      "Iteration 36037 => Loss: 45.80634792372418218065\n",
      "Iteration 36038 => Loss: 45.80618886675621581617\n",
      "Iteration 36039 => Loss: 45.80602981103650961359\n",
      "Iteration 36040 => Loss: 45.80587075656508488919\n",
      "Iteration 36041 => Loss: 45.80571170334190611584\n",
      "Iteration 36042 => Loss: 45.80555265136695908268\n",
      "Iteration 36043 => Loss: 45.80539360064022957886\n",
      "Iteration 36044 => Loss: 45.80523455116173892065\n",
      "Iteration 36045 => Loss: 45.80507550293147289722\n",
      "Iteration 36046 => Loss: 45.80491645594938887598\n",
      "Iteration 36047 => Loss: 45.80475741021550817322\n",
      "Iteration 36048 => Loss: 45.80459836572981657810\n",
      "Iteration 36049 => Loss: 45.80443932249227145803\n",
      "Iteration 36050 => Loss: 45.80428028050290123474\n",
      "Iteration 36051 => Loss: 45.80412123976169880279\n",
      "Iteration 36052 => Loss: 45.80396220026862863506\n",
      "Iteration 36053 => Loss: 45.80380316202369073153\n",
      "Iteration 36054 => Loss: 45.80364412502689219764\n",
      "Iteration 36055 => Loss: 45.80348508927819040082\n",
      "Iteration 36056 => Loss: 45.80332605477758534107\n",
      "Iteration 36057 => Loss: 45.80316702152508412382\n",
      "Iteration 36058 => Loss: 45.80300798952067253822\n",
      "Iteration 36059 => Loss: 45.80284895876432926798\n",
      "Iteration 36060 => Loss: 45.80268992925605431310\n",
      "Iteration 36061 => Loss: 45.80253090099584056816\n",
      "Iteration 36062 => Loss: 45.80237187398368092772\n",
      "Iteration 36063 => Loss: 45.80221284821953275923\n",
      "Iteration 36064 => Loss: 45.80205382370340316811\n",
      "Iteration 36065 => Loss: 45.80189480043531347064\n",
      "Iteration 36066 => Loss: 45.80173577841521392884\n",
      "Iteration 36067 => Loss: 45.80157675764314006983\n",
      "Iteration 36068 => Loss: 45.80141773811902083935\n",
      "Iteration 36069 => Loss: 45.80125871984290597538\n",
      "Iteration 36070 => Loss: 45.80109970281472442366\n",
      "Iteration 36071 => Loss: 45.80094068703449750046\n",
      "Iteration 36072 => Loss: 45.80078167250225362750\n",
      "Iteration 36073 => Loss: 45.80062265921793596135\n",
      "Iteration 36074 => Loss: 45.80046364718153739659\n",
      "Iteration 36075 => Loss: 45.80030463639306503865\n",
      "Iteration 36076 => Loss: 45.80014562685250467666\n",
      "Iteration 36077 => Loss: 45.79998661855984209978\n",
      "Iteration 36078 => Loss: 45.79982761151503467545\n",
      "Iteration 36079 => Loss: 45.79966860571813924707\n",
      "Iteration 36080 => Loss: 45.79950960116912028752\n",
      "Iteration 36081 => Loss: 45.79935059786794226966\n",
      "Iteration 36082 => Loss: 45.79919159581461940434\n",
      "Iteration 36083 => Loss: 45.79903259500913748070\n",
      "Iteration 36084 => Loss: 45.79887359545147518247\n",
      "Iteration 36085 => Loss: 45.79871459714164672050\n",
      "Iteration 36086 => Loss: 45.79855560007960946223\n",
      "Iteration 36087 => Loss: 45.79839660426539893479\n",
      "Iteration 36088 => Loss: 45.79823760969897961104\n",
      "Iteration 36089 => Loss: 45.79807861638032306928\n",
      "Iteration 36090 => Loss: 45.79791962430942930951\n",
      "Iteration 36091 => Loss: 45.79776063348631254257\n",
      "Iteration 36092 => Loss: 45.79760164391095145220\n",
      "Iteration 36093 => Loss: 45.79744265558332472210\n",
      "Iteration 36094 => Loss: 45.79728366850342524685\n",
      "Iteration 36095 => Loss: 45.79712468267126723731\n",
      "Iteration 36096 => Loss: 45.79696569808680095548\n",
      "Iteration 36097 => Loss: 45.79680671475004771764\n",
      "Iteration 36098 => Loss: 45.79664773266098620752\n",
      "Iteration 36099 => Loss: 45.79648875181960931968\n",
      "Iteration 36100 => Loss: 45.79632977222590994870\n",
      "Iteration 36101 => Loss: 45.79617079387985256744\n",
      "Iteration 36102 => Loss: 45.79601181678146559761\n",
      "Iteration 36103 => Loss: 45.79585284093071351208\n",
      "Iteration 36104 => Loss: 45.79569386632760341627\n",
      "Iteration 36105 => Loss: 45.79553489297212109932\n",
      "Iteration 36106 => Loss: 45.79537592086425945581\n",
      "Iteration 36107 => Loss: 45.79521695000397585318\n",
      "Iteration 36108 => Loss: 45.79505798039130581856\n",
      "Iteration 36109 => Loss: 45.79489901202622093024\n",
      "Iteration 36110 => Loss: 45.79474004490870697737\n",
      "Iteration 36111 => Loss: 45.79458107903877106537\n",
      "Iteration 36112 => Loss: 45.79442211441638477254\n",
      "Iteration 36113 => Loss: 45.79426315104151967716\n",
      "Iteration 36114 => Loss: 45.79410418891421841181\n",
      "Iteration 36115 => Loss: 45.79394522803443123848\n",
      "Iteration 36116 => Loss: 45.79378626840217947347\n",
      "Iteration 36117 => Loss: 45.79362731001742048420\n",
      "Iteration 36118 => Loss: 45.79346835288014005982\n",
      "Iteration 36119 => Loss: 45.79330939699037372748\n",
      "Iteration 36120 => Loss: 45.79315044234806464374\n",
      "Iteration 36121 => Loss: 45.79299148895324833575\n",
      "Iteration 36122 => Loss: 45.79283253680586796008\n",
      "Iteration 36123 => Loss: 45.79267358590595904388\n",
      "Iteration 36124 => Loss: 45.79251463625347895459\n",
      "Iteration 36125 => Loss: 45.79235568784842769219\n",
      "Iteration 36126 => Loss: 45.79219674069077683498\n",
      "Iteration 36127 => Loss: 45.79203779478054769925\n",
      "Iteration 36128 => Loss: 45.79187885011771186328\n",
      "Iteration 36129 => Loss: 45.79171990670227643250\n",
      "Iteration 36130 => Loss: 45.79156096453421298520\n",
      "Iteration 36131 => Loss: 45.79140202361352862681\n",
      "Iteration 36132 => Loss: 45.79124308394018783019\n",
      "Iteration 36133 => Loss: 45.79108414551421191163\n",
      "Iteration 36134 => Loss: 45.79092520833557244941\n",
      "Iteration 36135 => Loss: 45.79076627240424812726\n",
      "Iteration 36136 => Loss: 45.79060733772026736688\n",
      "Iteration 36137 => Loss: 45.79044840428358753570\n",
      "Iteration 36138 => Loss: 45.79028947209420863373\n",
      "Iteration 36139 => Loss: 45.79013054115213066098\n",
      "Iteration 36140 => Loss: 45.78997161145731809029\n",
      "Iteration 36141 => Loss: 45.78981268300978513253\n",
      "Iteration 36142 => Loss: 45.78965375580951757684\n",
      "Iteration 36143 => Loss: 45.78949482985650831779\n",
      "Iteration 36144 => Loss: 45.78933590515072893368\n",
      "Iteration 36145 => Loss: 45.78917698169218652993\n",
      "Iteration 36146 => Loss: 45.78901805948085979026\n",
      "Iteration 36147 => Loss: 45.78885913851674871466\n",
      "Iteration 36148 => Loss: 45.78870021879985330315\n",
      "Iteration 36149 => Loss: 45.78854130033014513401\n",
      "Iteration 36150 => Loss: 45.78838238310761710181\n",
      "Iteration 36151 => Loss: 45.78822346713226920656\n",
      "Iteration 36152 => Loss: 45.78806455240408013196\n",
      "Iteration 36153 => Loss: 45.78790563892303566718\n",
      "Iteration 36154 => Loss: 45.78774672668915712848\n",
      "Iteration 36155 => Loss: 45.78758781570238767245\n",
      "Iteration 36156 => Loss: 45.78742890596277703708\n",
      "Iteration 36157 => Loss: 45.78726999747026127352\n",
      "Iteration 36158 => Loss: 45.78711109022486169806\n",
      "Iteration 36159 => Loss: 45.78695218422654278356\n",
      "Iteration 36160 => Loss: 45.78679327947529742460\n",
      "Iteration 36161 => Loss: 45.78663437597116114830\n",
      "Iteration 36162 => Loss: 45.78647547371407000583\n",
      "Iteration 36163 => Loss: 45.78631657270405241889\n",
      "Iteration 36164 => Loss: 45.78615767294105864949\n",
      "Iteration 36165 => Loss: 45.78599877442513843562\n",
      "Iteration 36166 => Loss: 45.78583987715621361758\n",
      "Iteration 36167 => Loss: 45.78568098113431972251\n",
      "Iteration 36168 => Loss: 45.78552208635942122328\n",
      "Iteration 36169 => Loss: 45.78536319283151101445\n",
      "Iteration 36170 => Loss: 45.78520430055061751773\n",
      "Iteration 36171 => Loss: 45.78504540951668388971\n",
      "Iteration 36172 => Loss: 45.78488651972973144666\n",
      "Iteration 36173 => Loss: 45.78472763118972466145\n",
      "Iteration 36174 => Loss: 45.78456874389669195580\n",
      "Iteration 36175 => Loss: 45.78440985785056227542\n",
      "Iteration 36176 => Loss: 45.78425097305138535830\n",
      "Iteration 36177 => Loss: 45.78409208949911146647\n",
      "Iteration 36178 => Loss: 45.78393320719377612704\n",
      "Iteration 36179 => Loss: 45.78377432613530118033\n",
      "Iteration 36180 => Loss: 45.78361544632373636432\n",
      "Iteration 36181 => Loss: 45.78345656775906036273\n",
      "Iteration 36182 => Loss: 45.78329769044125185928\n",
      "Iteration 36183 => Loss: 45.78313881437030374855\n",
      "Iteration 36184 => Loss: 45.78297993954620892509\n",
      "Iteration 36185 => Loss: 45.78282106596894607264\n",
      "Iteration 36186 => Loss: 45.78266219363851519120\n",
      "Iteration 36187 => Loss: 45.78250332255490206990\n",
      "Iteration 36188 => Loss: 45.78234445271811381417\n",
      "Iteration 36189 => Loss: 45.78218558412812200231\n",
      "Iteration 36190 => Loss: 45.78202671678491952889\n",
      "Iteration 36191 => Loss: 45.78186785068850639391\n",
      "Iteration 36192 => Loss: 45.78170898583885417565\n",
      "Iteration 36193 => Loss: 45.78155012223598419041\n",
      "Iteration 36194 => Loss: 45.78139125987985380561\n",
      "Iteration 36195 => Loss: 45.78123239877044881041\n",
      "Iteration 36196 => Loss: 45.78107353890781894279\n",
      "Iteration 36197 => Loss: 45.78091468029189314848\n",
      "Iteration 36198 => Loss: 45.78075582292267142748\n",
      "Iteration 36199 => Loss: 45.78059696680015377979\n",
      "Iteration 36200 => Loss: 45.78043811192434020541\n",
      "Iteration 36201 => Loss: 45.78027925829520228262\n",
      "Iteration 36202 => Loss: 45.78012040591275422230\n",
      "Iteration 36203 => Loss: 45.77996155477696760272\n",
      "Iteration 36204 => Loss: 45.77980270488783531846\n",
      "Iteration 36205 => Loss: 45.77964385624534315866\n",
      "Iteration 36206 => Loss: 45.77948500884948401790\n",
      "Iteration 36207 => Loss: 45.77932616270026500160\n",
      "Iteration 36208 => Loss: 45.77916731779766479349\n",
      "Iteration 36209 => Loss: 45.77900847414164786642\n",
      "Iteration 36210 => Loss: 45.77884963173222843125\n",
      "Iteration 36211 => Loss: 45.77869079056940648798\n",
      "Iteration 36212 => Loss: 45.77853195065318914203\n",
      "Iteration 36213 => Loss: 45.77837311198349112829\n",
      "Iteration 36214 => Loss: 45.77821427456037639558\n",
      "Iteration 36215 => Loss: 45.77805543838380941679\n",
      "Iteration 36216 => Loss: 45.77789660345376887562\n",
      "Iteration 36217 => Loss: 45.77773776977027608837\n",
      "Iteration 36218 => Loss: 45.77757893733328131702\n",
      "Iteration 36219 => Loss: 45.77742010614279877245\n",
      "Iteration 36220 => Loss: 45.77726127619882845465\n",
      "Iteration 36221 => Loss: 45.77710244750132062563\n",
      "Iteration 36222 => Loss: 45.77694362005031081253\n",
      "Iteration 36223 => Loss: 45.77678479384577769906\n",
      "Iteration 36224 => Loss: 45.77662596888770707437\n",
      "Iteration 36225 => Loss: 45.77646714517607051675\n",
      "Iteration 36226 => Loss: 45.77630832271086802621\n",
      "Iteration 36227 => Loss: 45.77614950149210670816\n",
      "Iteration 36228 => Loss: 45.77599068151976524632\n",
      "Iteration 36229 => Loss: 45.77583186279381521899\n",
      "Iteration 36230 => Loss: 45.77567304531431346959\n",
      "Iteration 36231 => Loss: 45.77551422908116052213\n",
      "Iteration 36232 => Loss: 45.77535541409441322003\n",
      "Iteration 36233 => Loss: 45.77519660035403603615\n",
      "Iteration 36234 => Loss: 45.77503778786000054879\n",
      "Iteration 36235 => Loss: 45.77487897661232807422\n",
      "Iteration 36236 => Loss: 45.77472016661099019075\n",
      "Iteration 36237 => Loss: 45.77456135785601532007\n",
      "Iteration 36238 => Loss: 45.77440255034731819705\n",
      "Iteration 36239 => Loss: 45.77424374408496277056\n",
      "Iteration 36240 => Loss: 45.77408493906892061887\n",
      "Iteration 36241 => Loss: 45.77392613529914200399\n",
      "Iteration 36242 => Loss: 45.77376733277566245306\n",
      "Iteration 36243 => Loss: 45.77360853149846775523\n",
      "Iteration 36244 => Loss: 45.77344973146751527793\n",
      "Iteration 36245 => Loss: 45.77329093268281212659\n",
      "Iteration 36246 => Loss: 45.77313213514437251206\n",
      "Iteration 36247 => Loss: 45.77297333885216801264\n",
      "Iteration 36248 => Loss: 45.77281454380618441746\n",
      "Iteration 36249 => Loss: 45.77265575000641462111\n",
      "Iteration 36250 => Loss: 45.77249695745285862358\n",
      "Iteration 36251 => Loss: 45.77233816614548089774\n",
      "Iteration 36252 => Loss: 45.77217937608431697072\n",
      "Iteration 36253 => Loss: 45.77202058726930289367\n",
      "Iteration 36254 => Loss: 45.77186179970045998289\n",
      "Iteration 36255 => Loss: 45.77170301337776692208\n",
      "Iteration 36256 => Loss: 45.77154422830124502752\n",
      "Iteration 36257 => Loss: 45.77138544447085166667\n",
      "Iteration 36258 => Loss: 45.77122666188657262865\n",
      "Iteration 36259 => Loss: 45.77106788054841501889\n",
      "Iteration 36260 => Loss: 45.77090910045634331027\n",
      "Iteration 36261 => Loss: 45.77075032161041434620\n",
      "Iteration 36262 => Loss: 45.77059154401054996697\n",
      "Iteration 36263 => Loss: 45.77043276765675017259\n",
      "Iteration 36264 => Loss: 45.77027399254904338477\n",
      "Iteration 36265 => Loss: 45.77011521868738697094\n",
      "Iteration 36266 => Loss: 45.76995644607178093111\n",
      "Iteration 36267 => Loss: 45.76979767470221815984\n",
      "Iteration 36268 => Loss: 45.76963890457867023542\n",
      "Iteration 36269 => Loss: 45.76948013570114426329\n",
      "Iteration 36270 => Loss: 45.76932136806963313802\n",
      "Iteration 36271 => Loss: 45.76916260168412975418\n",
      "Iteration 36272 => Loss: 45.76900383654460569005\n",
      "Iteration 36273 => Loss: 45.76884507265105384022\n",
      "Iteration 36274 => Loss: 45.76868631000348841553\n",
      "Iteration 36275 => Loss: 45.76852754860190231057\n",
      "Iteration 36276 => Loss: 45.76836878844623868190\n",
      "Iteration 36277 => Loss: 45.76821002953652595124\n",
      "Iteration 36278 => Loss: 45.76805127187274280232\n",
      "Iteration 36279 => Loss: 45.76789251545488212969\n",
      "Iteration 36280 => Loss: 45.76773376028292261708\n",
      "Iteration 36281 => Loss: 45.76757500635689268620\n",
      "Iteration 36282 => Loss: 45.76741625367671417735\n",
      "Iteration 36283 => Loss: 45.76725750224245103936\n",
      "Iteration 36284 => Loss: 45.76709875205405353427\n",
      "Iteration 36285 => Loss: 45.76694000311152166205\n",
      "Iteration 36286 => Loss: 45.76678125541484121186\n",
      "Iteration 36287 => Loss: 45.76662250896398376199\n",
      "Iteration 36288 => Loss: 45.76646376375897773414\n",
      "Iteration 36289 => Loss: 45.76630501979981602290\n",
      "Iteration 36290 => Loss: 45.76614627708642757398\n",
      "Iteration 36291 => Loss: 45.76598753561886212538\n",
      "Iteration 36292 => Loss: 45.76582879539710546624\n",
      "Iteration 36293 => Loss: 45.76567005642111496400\n",
      "Iteration 36294 => Loss: 45.76551131869091193494\n",
      "Iteration 36295 => Loss: 45.76535258220648216820\n",
      "Iteration 36296 => Loss: 45.76519384696776882038\n",
      "Iteration 36297 => Loss: 45.76503511297482873488\n",
      "Iteration 36298 => Loss: 45.76487638022763348999\n",
      "Iteration 36299 => Loss: 45.76471764872614045316\n",
      "Iteration 36300 => Loss: 45.76455891847039225695\n",
      "Iteration 36301 => Loss: 45.76440018946031784708\n",
      "Iteration 36302 => Loss: 45.76424146169597406697\n",
      "Iteration 36303 => Loss: 45.76408273517729696778\n",
      "Iteration 36304 => Loss: 45.76392400990428654950\n",
      "Iteration 36305 => Loss: 45.76376528587697833927\n",
      "Iteration 36306 => Loss: 45.76360656309531549368\n",
      "Iteration 36307 => Loss: 45.76344784155928380187\n",
      "Iteration 36308 => Loss: 45.76328912126890458012\n",
      "Iteration 36309 => Loss: 45.76313040222415651215\n",
      "Iteration 36310 => Loss: 45.76297168442501117624\n",
      "Iteration 36311 => Loss: 45.76281296787147567784\n",
      "Iteration 36312 => Loss: 45.76265425256353580608\n",
      "Iteration 36313 => Loss: 45.76249553850122708809\n",
      "Iteration 36314 => Loss: 45.76233682568446425876\n",
      "Iteration 36315 => Loss: 45.76217811411326863436\n",
      "Iteration 36316 => Loss: 45.76201940378764021489\n",
      "Iteration 36317 => Loss: 45.76186069470754347321\n",
      "Iteration 36318 => Loss: 45.76170198687301393647\n",
      "Iteration 36319 => Loss: 45.76154328028400897210\n",
      "Iteration 36320 => Loss: 45.76138457494052858010\n",
      "Iteration 36321 => Loss: 45.76122587084254433876\n",
      "Iteration 36322 => Loss: 45.76106716799007045893\n",
      "Iteration 36323 => Loss: 45.76090846638307851890\n",
      "Iteration 36324 => Loss: 45.76074976602158272954\n",
      "Iteration 36325 => Loss: 45.76059106690556177455\n",
      "Iteration 36326 => Loss: 45.76043236903499433765\n",
      "Iteration 36327 => Loss: 45.76027367240988041885\n",
      "Iteration 36328 => Loss: 45.76011497703019870187\n",
      "Iteration 36329 => Loss: 45.75995628289597050298\n",
      "Iteration 36330 => Loss: 45.75979759000714608419\n",
      "Iteration 36331 => Loss: 45.75963889836373965636\n",
      "Iteration 36332 => Loss: 45.75948020796574411406\n",
      "Iteration 36333 => Loss: 45.75932151881314524644\n",
      "Iteration 36334 => Loss: 45.75916283090592173721\n",
      "Iteration 36335 => Loss: 45.75900414424408069181\n",
      "Iteration 36336 => Loss: 45.75884545882760789937\n",
      "Iteration 36337 => Loss: 45.75868677465646783276\n",
      "Iteration 36338 => Loss: 45.75852809173069601911\n",
      "Iteration 36339 => Loss: 45.75836941005024982587\n",
      "Iteration 36340 => Loss: 45.75821072961512214761\n",
      "Iteration 36341 => Loss: 45.75805205042532719517\n",
      "Iteration 36342 => Loss: 45.75789337248080812515\n",
      "Iteration 36343 => Loss: 45.75773469578161467552\n",
      "Iteration 36344 => Loss: 45.75757602032771131917\n",
      "Iteration 36345 => Loss: 45.75741734611904831809\n",
      "Iteration 36346 => Loss: 45.75725867315568962113\n",
      "Iteration 36347 => Loss: 45.75710000143755706858\n",
      "Iteration 36348 => Loss: 45.75694133096470039845\n",
      "Iteration 36349 => Loss: 45.75678266173708408360\n",
      "Iteration 36350 => Loss: 45.75662399375465838602\n",
      "Iteration 36351 => Loss: 45.75646532701747304372\n",
      "Iteration 36352 => Loss: 45.75630666152551384585\n",
      "Iteration 36353 => Loss: 45.75614799727873815982\n",
      "Iteration 36354 => Loss: 45.75598933427713177480\n",
      "Iteration 36355 => Loss: 45.75583067252072311248\n",
      "Iteration 36356 => Loss: 45.75567201200949085660\n",
      "Iteration 36357 => Loss: 45.75551335274339948000\n",
      "Iteration 36358 => Loss: 45.75535469472247029898\n",
      "Iteration 36359 => Loss: 45.75519603794668199725\n",
      "Iteration 36360 => Loss: 45.75503738241602036396\n",
      "Iteration 36361 => Loss: 45.75487872813046408282\n",
      "Iteration 36362 => Loss: 45.75472007509001315384\n",
      "Iteration 36363 => Loss: 45.75456142329470310415\n",
      "Iteration 36364 => Loss: 45.75440277274445577405\n",
      "Iteration 36365 => Loss: 45.75424412343929247982\n",
      "Iteration 36366 => Loss: 45.75408547537919901060\n",
      "Iteration 36367 => Loss: 45.75392682856418247184\n",
      "Iteration 36368 => Loss: 45.75376818299421444181\n",
      "Iteration 36369 => Loss: 45.75360953866926649880\n",
      "Iteration 36370 => Loss: 45.75345089558939548624\n",
      "Iteration 36371 => Loss: 45.75329225375449482272\n",
      "Iteration 36372 => Loss: 45.75313361316464266793\n",
      "Iteration 36373 => Loss: 45.75297497381976796760\n",
      "Iteration 36374 => Loss: 45.75281633571989914344\n",
      "Iteration 36375 => Loss: 45.75265769886501487917\n",
      "Iteration 36376 => Loss: 45.75249906325510096394\n",
      "Iteration 36377 => Loss: 45.75234042889015029232\n",
      "Iteration 36378 => Loss: 45.75218179577015575887\n",
      "Iteration 36379 => Loss: 45.75202316389511025818\n",
      "Iteration 36380 => Loss: 45.75186453326498536853\n",
      "Iteration 36381 => Loss: 45.75170590387980240621\n",
      "Iteration 36382 => Loss: 45.75154727573953294950\n",
      "Iteration 36383 => Loss: 45.75138864884416278755\n",
      "Iteration 36384 => Loss: 45.75123002319368481494\n",
      "Iteration 36385 => Loss: 45.75107139878809903166\n",
      "Iteration 36386 => Loss: 45.75091277562738412144\n",
      "Iteration 36387 => Loss: 45.75075415371153297883\n",
      "Iteration 36388 => Loss: 45.75059553304054560385\n",
      "Iteration 36389 => Loss: 45.75043691361440778564\n",
      "Iteration 36390 => Loss: 45.75027829543308399707\n",
      "Iteration 36391 => Loss: 45.75011967849661687069\n",
      "Iteration 36392 => Loss: 45.74996106280496377394\n",
      "Iteration 36393 => Loss: 45.74980244835810339055\n",
      "Iteration 36394 => Loss: 45.74964383515603572050\n",
      "Iteration 36395 => Loss: 45.74948522319877497466\n",
      "Iteration 36396 => Loss: 45.74932661248629273132\n",
      "Iteration 36397 => Loss: 45.74916800301856056876\n",
      "Iteration 36398 => Loss: 45.74900939479559269785\n",
      "Iteration 36399 => Loss: 45.74885078781737490772\n",
      "Iteration 36400 => Loss: 45.74869218208390719838\n",
      "Iteration 36401 => Loss: 45.74853357759516114811\n",
      "Iteration 36402 => Loss: 45.74837497435112254607\n",
      "Iteration 36403 => Loss: 45.74821637235181270853\n",
      "Iteration 36404 => Loss: 45.74805777159720321379\n",
      "Iteration 36405 => Loss: 45.74789917208728695641\n",
      "Iteration 36406 => Loss: 45.74774057382204262012\n",
      "Iteration 36407 => Loss: 45.74758197680145599406\n",
      "Iteration 36408 => Loss: 45.74742338102554839452\n",
      "Iteration 36409 => Loss: 45.74726478649429139978\n",
      "Iteration 36410 => Loss: 45.74710619320767079898\n",
      "Iteration 36411 => Loss: 45.74694760116568659214\n",
      "Iteration 36412 => Loss: 45.74678901036831746296\n",
      "Iteration 36413 => Loss: 45.74663042081555630602\n",
      "Iteration 36414 => Loss: 45.74647183250740312133\n",
      "Iteration 36415 => Loss: 45.74631324544384369801\n",
      "Iteration 36416 => Loss: 45.74615465962486382523\n",
      "Iteration 36417 => Loss: 45.74599607505047060840\n",
      "Iteration 36418 => Loss: 45.74583749172062852040\n",
      "Iteration 36419 => Loss: 45.74567890963533045579\n",
      "Iteration 36420 => Loss: 45.74552032879460483628\n",
      "Iteration 36421 => Loss: 45.74536174919840192388\n",
      "Iteration 36422 => Loss: 45.74520317084669329688\n",
      "Iteration 36423 => Loss: 45.74504459373953579870\n",
      "Iteration 36424 => Loss: 45.74488601787687258593\n",
      "Iteration 36425 => Loss: 45.74472744325871076398\n",
      "Iteration 36426 => Loss: 45.74456886988501480573\n",
      "Iteration 36427 => Loss: 45.74441029775580602745\n",
      "Iteration 36428 => Loss: 45.74425172687107732372\n",
      "Iteration 36429 => Loss: 45.74409315723077895655\n",
      "Iteration 36430 => Loss: 45.74393458883494645306\n",
      "Iteration 36431 => Loss: 45.74377602168353007528\n",
      "Iteration 36432 => Loss: 45.74361745577655824491\n",
      "Iteration 36433 => Loss: 45.74345889111400254023\n",
      "Iteration 36434 => Loss: 45.74330032769584164498\n",
      "Iteration 36435 => Loss: 45.74314176552210398086\n",
      "Iteration 36436 => Loss: 45.74298320459271138816\n",
      "Iteration 36437 => Loss: 45.74282464490772781573\n",
      "Iteration 36438 => Loss: 45.74266608646711063102\n",
      "Iteration 36439 => Loss: 45.74250752927083851773\n",
      "Iteration 36440 => Loss: 45.74234897331893989758\n",
      "Iteration 36441 => Loss: 45.74219041861135792715\n",
      "Iteration 36442 => Loss: 45.74203186514809971186\n",
      "Iteration 36443 => Loss: 45.74187331292915814629\n",
      "Iteration 36444 => Loss: 45.74171476195455454672\n",
      "Iteration 36445 => Loss: 45.74155621222423206973\n",
      "Iteration 36446 => Loss: 45.74139766373820492618\n",
      "Iteration 36447 => Loss: 45.74123911649645890520\n",
      "Iteration 36448 => Loss: 45.74108057049897979596\n",
      "Iteration 36449 => Loss: 45.74092202574575338758\n",
      "Iteration 36450 => Loss: 45.74076348223678678551\n",
      "Iteration 36451 => Loss: 45.74060493997205867345\n",
      "Iteration 36452 => Loss: 45.74044639895156905141\n",
      "Iteration 36453 => Loss: 45.74028785917528239224\n",
      "Iteration 36454 => Loss: 45.74012932064322001224\n",
      "Iteration 36455 => Loss: 45.73997078335537480598\n",
      "Iteration 36456 => Loss: 45.73981224731168993003\n",
      "Iteration 36457 => Loss: 45.73965371251220091153\n",
      "Iteration 36458 => Loss: 45.73949517895689353963\n",
      "Iteration 36459 => Loss: 45.73933664664576070891\n",
      "Iteration 36460 => Loss: 45.73917811557875978679\n",
      "Iteration 36461 => Loss: 45.73901958575589787870\n",
      "Iteration 36462 => Loss: 45.73886105717718919550\n",
      "Iteration 36463 => Loss: 45.73870252984256978834\n",
      "Iteration 36464 => Loss: 45.73854400375208939522\n",
      "Iteration 36465 => Loss: 45.73838547890571959442\n",
      "Iteration 36466 => Loss: 45.73822695530343906967\n",
      "Iteration 36467 => Loss: 45.73806843294525492638\n",
      "Iteration 36468 => Loss: 45.73790991183113874285\n",
      "Iteration 36469 => Loss: 45.73775139196107630823\n",
      "Iteration 36470 => Loss: 45.73759287333507472795\n",
      "Iteration 36471 => Loss: 45.73743435595311268571\n",
      "Iteration 36472 => Loss: 45.73727583981520439238\n",
      "Iteration 36473 => Loss: 45.73711732492130010996\n",
      "Iteration 36474 => Loss: 45.73695881127144247102\n",
      "Iteration 36475 => Loss: 45.73680029886555331586\n",
      "Iteration 36476 => Loss: 45.73664178770367527704\n",
      "Iteration 36477 => Loss: 45.73648327778579414371\n",
      "Iteration 36478 => Loss: 45.73632476911188859958\n",
      "Iteration 36479 => Loss: 45.73616626168195864466\n",
      "Iteration 36480 => Loss: 45.73600775549596164637\n",
      "Iteration 36481 => Loss: 45.73584925055394734272\n",
      "Iteration 36482 => Loss: 45.73569074685583757400\n",
      "Iteration 36483 => Loss: 45.73553224440166786735\n",
      "Iteration 36484 => Loss: 45.73537374319142401191\n",
      "Iteration 36485 => Loss: 45.73521524322508469140\n",
      "Iteration 36486 => Loss: 45.73505674450264990583\n",
      "Iteration 36487 => Loss: 45.73489824702409833890\n",
      "Iteration 36488 => Loss: 45.73473975078941577976\n",
      "Iteration 36489 => Loss: 45.73458125579862354471\n",
      "Iteration 36490 => Loss: 45.73442276205168610659\n",
      "Iteration 36491 => Loss: 45.73426426954858925455\n",
      "Iteration 36492 => Loss: 45.73410577828935430489\n",
      "Iteration 36493 => Loss: 45.73394728827393151960\n",
      "Iteration 36494 => Loss: 45.73378879950233510954\n",
      "Iteration 36495 => Loss: 45.73363031197455796928\n",
      "Iteration 36496 => Loss: 45.73347182569056457169\n",
      "Iteration 36497 => Loss: 45.73331334065037623304\n",
      "Iteration 36498 => Loss: 45.73315485685397874249\n",
      "Iteration 36499 => Loss: 45.73299637430132946747\n",
      "Iteration 36500 => Loss: 45.73283789299246393512\n",
      "Iteration 36501 => Loss: 45.73267941292734661829\n",
      "Iteration 36502 => Loss: 45.73252093410596330614\n",
      "Iteration 36503 => Loss: 45.73236245652832110409\n",
      "Iteration 36504 => Loss: 45.73220398019438448500\n",
      "Iteration 36505 => Loss: 45.73204550510419608145\n",
      "Iteration 36506 => Loss: 45.73188703125768483915\n",
      "Iteration 36507 => Loss: 45.73172855865490049609\n",
      "Iteration 36508 => Loss: 45.73157008729577199801\n",
      "Iteration 36509 => Loss: 45.73141161718031355576\n",
      "Iteration 36510 => Loss: 45.73125314830853227477\n",
      "Iteration 36511 => Loss: 45.73109468068042104960\n",
      "Iteration 36512 => Loss: 45.73093621429593014227\n",
      "Iteration 36513 => Loss: 45.73077774915508086906\n",
      "Iteration 36514 => Loss: 45.73061928525785191368\n",
      "Iteration 36515 => Loss: 45.73046082260425748700\n",
      "Iteration 36516 => Loss: 45.73030236119425495644\n",
      "Iteration 36517 => Loss: 45.73014390102786563830\n",
      "Iteration 36518 => Loss: 45.72998544210504690000\n",
      "Iteration 36519 => Loss: 45.72982698442581295240\n",
      "Iteration 36520 => Loss: 45.72966852799013537378\n",
      "Iteration 36521 => Loss: 45.72951007279804258587\n",
      "Iteration 36522 => Loss: 45.72935161884947063982\n",
      "Iteration 36523 => Loss: 45.72919316614444085189\n",
      "Iteration 36524 => Loss: 45.72903471468295322211\n",
      "Iteration 36525 => Loss: 45.72887626446498643418\n",
      "Iteration 36526 => Loss: 45.72871781549050496096\n",
      "Iteration 36527 => Loss: 45.72855936775953011875\n",
      "Iteration 36528 => Loss: 45.72840092127204769668\n",
      "Iteration 36529 => Loss: 45.72824247602806480018\n",
      "Iteration 36530 => Loss: 45.72808403202751748040\n",
      "Iteration 36531 => Loss: 45.72792558927045547534\n",
      "Iteration 36532 => Loss: 45.72776714775683615244\n",
      "Iteration 36533 => Loss: 45.72760870748665951169\n",
      "Iteration 36534 => Loss: 45.72745026845991134223\n",
      "Iteration 36535 => Loss: 45.72729183067658453865\n",
      "Iteration 36536 => Loss: 45.72713339413667910094\n",
      "Iteration 36537 => Loss: 45.72697495884015950196\n",
      "Iteration 36538 => Loss: 45.72681652478702574172\n",
      "Iteration 36539 => Loss: 45.72665809197729203106\n",
      "Iteration 36540 => Loss: 45.72649966041092284286\n",
      "Iteration 36541 => Loss: 45.72634123008793238796\n",
      "Iteration 36542 => Loss: 45.72618280100828513923\n",
      "Iteration 36543 => Loss: 45.72602437317197399125\n",
      "Iteration 36544 => Loss: 45.72586594657898473315\n",
      "Iteration 36545 => Loss: 45.72570752122933157580\n",
      "Iteration 36546 => Loss: 45.72554909712300030833\n",
      "Iteration 36547 => Loss: 45.72539067425996961447\n",
      "Iteration 36548 => Loss: 45.72523225264023238879\n",
      "Iteration 36549 => Loss: 45.72507383226376731500\n",
      "Iteration 36550 => Loss: 45.72491541313058149854\n",
      "Iteration 36551 => Loss: 45.72475699524067493940\n",
      "Iteration 36552 => Loss: 45.72459857859401921587\n",
      "Iteration 36553 => Loss: 45.72444016319059301168\n",
      "Iteration 36554 => Loss: 45.72428174903041764310\n",
      "Iteration 36555 => Loss: 45.72412333611346468842\n",
      "Iteration 36556 => Loss: 45.72396492443972704223\n",
      "Iteration 36557 => Loss: 45.72380651400919759908\n",
      "Iteration 36558 => Loss: 45.72364810482186214813\n",
      "Iteration 36559 => Loss: 45.72348969687769937309\n",
      "Iteration 36560 => Loss: 45.72333129017673059025\n",
      "Iteration 36561 => Loss: 45.72317288471894869417\n",
      "Iteration 36562 => Loss: 45.72301448050430394687\n",
      "Iteration 36563 => Loss: 45.72285607753279634835\n",
      "Iteration 36564 => Loss: 45.72269767580444721489\n",
      "Iteration 36565 => Loss: 45.72253927531921391392\n",
      "Iteration 36566 => Loss: 45.72238087607711065630\n",
      "Iteration 36567 => Loss: 45.72222247807811612574\n",
      "Iteration 36568 => Loss: 45.72206408132218768969\n",
      "Iteration 36569 => Loss: 45.72190568580939640242\n",
      "Iteration 36570 => Loss: 45.72174729153963568251\n",
      "Iteration 36571 => Loss: 45.72158889851299790053\n",
      "Iteration 36572 => Loss: 45.72143050672938358048\n",
      "Iteration 36573 => Loss: 45.72127211618883535493\n",
      "Iteration 36574 => Loss: 45.72111372689130348590\n",
      "Iteration 36575 => Loss: 45.72095533883683060594\n",
      "Iteration 36576 => Loss: 45.72079695202535987164\n",
      "Iteration 36577 => Loss: 45.72063856645691970471\n",
      "Iteration 36578 => Loss: 45.72048018213147457800\n",
      "Iteration 36579 => Loss: 45.72032179904901028067\n",
      "Iteration 36580 => Loss: 45.72016341720953391814\n",
      "Iteration 36581 => Loss: 45.72000503661304549041\n",
      "Iteration 36582 => Loss: 45.71984665725950947035\n",
      "Iteration 36583 => Loss: 45.71968827914890454167\n",
      "Iteration 36584 => Loss: 45.71952990228126623151\n",
      "Iteration 36585 => Loss: 45.71937152665654480188\n",
      "Iteration 36586 => Loss: 45.71921315227478288534\n",
      "Iteration 36587 => Loss: 45.71905477913590942762\n",
      "Iteration 36588 => Loss: 45.71889640723993153415\n",
      "Iteration 36589 => Loss: 45.71873803658686341578\n",
      "Iteration 36590 => Loss: 45.71857966717666954537\n",
      "Iteration 36591 => Loss: 45.71842129900933571207\n",
      "Iteration 36592 => Loss: 45.71826293208489744302\n",
      "Iteration 36593 => Loss: 45.71810456640331210565\n",
      "Iteration 36594 => Loss: 45.71794620196456548911\n",
      "Iteration 36595 => Loss: 45.71778783876865048796\n",
      "Iteration 36596 => Loss: 45.71762947681555999679\n",
      "Iteration 36597 => Loss: 45.71747111610527269931\n",
      "Iteration 36598 => Loss: 45.71731275663781701724\n",
      "Iteration 36599 => Loss: 45.71715439841315031799\n",
      "Iteration 36600 => Loss: 45.71699604143127970701\n",
      "Iteration 36601 => Loss: 45.71683768569215544630\n",
      "Iteration 36602 => Loss: 45.71667933119582727386\n",
      "Iteration 36603 => Loss: 45.71652097794225255711\n",
      "Iteration 36604 => Loss: 45.71636262593142419064\n",
      "Iteration 36605 => Loss: 45.71620427516333506901\n",
      "Iteration 36606 => Loss: 45.71604592563797098137\n",
      "Iteration 36607 => Loss: 45.71588757735531061144\n",
      "Iteration 36608 => Loss: 45.71572923031538238092\n",
      "Iteration 36609 => Loss: 45.71557088451815786811\n",
      "Iteration 36610 => Loss: 45.71541253996361575673\n",
      "Iteration 36611 => Loss: 45.71525419665173473049\n",
      "Iteration 36612 => Loss: 45.71509585458255031654\n",
      "Iteration 36613 => Loss: 45.71493751375599146058\n",
      "Iteration 36614 => Loss: 45.71477917417211500606\n",
      "Iteration 36615 => Loss: 45.71462083583086410954\n",
      "Iteration 36616 => Loss: 45.71446249873226008731\n",
      "Iteration 36617 => Loss: 45.71430416287625320138\n",
      "Iteration 36618 => Loss: 45.71414582826285766259\n",
      "Iteration 36619 => Loss: 45.71398749489208057639\n",
      "Iteration 36620 => Loss: 45.71382916276390062649\n",
      "Iteration 36621 => Loss: 45.71367083187830360202\n",
      "Iteration 36622 => Loss: 45.71351250223526108130\n",
      "Iteration 36623 => Loss: 45.71335417383478727515\n",
      "Iteration 36624 => Loss: 45.71319584667686086732\n",
      "Iteration 36625 => Loss: 45.71303752076148185779\n",
      "Iteration 36626 => Loss: 45.71287919608865735199\n",
      "Iteration 36627 => Loss: 45.71272087265834471737\n",
      "Iteration 36628 => Loss: 45.71256255047052263762\n",
      "Iteration 36629 => Loss: 45.71240422952523374533\n",
      "Iteration 36630 => Loss: 45.71224590982242830250\n",
      "Iteration 36631 => Loss: 45.71208759136211341456\n",
      "Iteration 36632 => Loss: 45.71192927414425355437\n",
      "Iteration 36633 => Loss: 45.71177095816888424906\n",
      "Iteration 36634 => Loss: 45.71161264343594154980\n",
      "Iteration 36635 => Loss: 45.71145432994546808914\n",
      "Iteration 36636 => Loss: 45.71129601769742833994\n",
      "Iteration 36637 => Loss: 45.71113770669180809136\n",
      "Iteration 36638 => Loss: 45.71097939692861444883\n",
      "Iteration 36639 => Loss: 45.71082108840781188519\n",
      "Iteration 36640 => Loss: 45.71066278112942171674\n",
      "Iteration 36641 => Loss: 45.71050447509339420549\n",
      "Iteration 36642 => Loss: 45.71034617029977198399\n",
      "Iteration 36643 => Loss: 45.71018786674850531426\n",
      "Iteration 36644 => Loss: 45.71002956443958709087\n",
      "Iteration 36645 => Loss: 45.70987126337303863011\n",
      "Iteration 36646 => Loss: 45.70971296354882440482\n",
      "Iteration 36647 => Loss: 45.70955466496693020417\n",
      "Iteration 36648 => Loss: 45.70939636762734892272\n",
      "Iteration 36649 => Loss: 45.70923807153009477133\n",
      "Iteration 36650 => Loss: 45.70907977667513932829\n",
      "Iteration 36651 => Loss: 45.70892148306245417189\n",
      "Iteration 36652 => Loss: 45.70876319069205351298\n",
      "Iteration 36653 => Loss: 45.70860489956393024613\n",
      "Iteration 36654 => Loss: 45.70844660967807016050\n",
      "Iteration 36655 => Loss: 45.70828832103445193979\n",
      "Iteration 36656 => Loss: 45.70813003363306847859\n",
      "Iteration 36657 => Loss: 45.70797174747392688232\n",
      "Iteration 36658 => Loss: 45.70781346255702715098\n",
      "Iteration 36659 => Loss: 45.70765517888229823029\n",
      "Iteration 36660 => Loss: 45.70749689644978985825\n",
      "Iteration 36661 => Loss: 45.70733861525948782401\n",
      "Iteration 36662 => Loss: 45.70718033531135660041\n",
      "Iteration 36663 => Loss: 45.70702205660539618748\n",
      "Iteration 36664 => Loss: 45.70686377914161369063\n",
      "Iteration 36665 => Loss: 45.70670550291995937187\n",
      "Iteration 36666 => Loss: 45.70654722794044744205\n",
      "Iteration 36667 => Loss: 45.70638895420309921747\n",
      "Iteration 36668 => Loss: 45.70623068170783653841\n",
      "Iteration 36669 => Loss: 45.70607241045471624830\n",
      "Iteration 36670 => Loss: 45.70591414044369571457\n",
      "Iteration 36671 => Loss: 45.70575587167477493722\n",
      "Iteration 36672 => Loss: 45.70559760414791838912\n",
      "Iteration 36673 => Loss: 45.70543933786315449197\n",
      "Iteration 36674 => Loss: 45.70528107282046192950\n",
      "Iteration 36675 => Loss: 45.70512280901981227998\n",
      "Iteration 36676 => Loss: 45.70496454646120554344\n",
      "Iteration 36677 => Loss: 45.70480628514464171985\n",
      "Iteration 36678 => Loss: 45.70464802507009949295\n",
      "Iteration 36679 => Loss: 45.70448976623757886273\n",
      "Iteration 36680 => Loss: 45.70433150864705140748\n",
      "Iteration 36681 => Loss: 45.70417325229853844348\n",
      "Iteration 36682 => Loss: 45.70401499719201154903\n",
      "Iteration 36683 => Loss: 45.70385674332745651327\n",
      "Iteration 36684 => Loss: 45.70369849070487333620\n",
      "Iteration 36685 => Loss: 45.70354023932424780696\n",
      "Iteration 36686 => Loss: 45.70338198918557282013\n",
      "Iteration 36687 => Loss: 45.70322374028883416486\n",
      "Iteration 36688 => Loss: 45.70306549263403894656\n",
      "Iteration 36689 => Loss: 45.70290724622113742726\n",
      "Iteration 36690 => Loss: 45.70274900105015802865\n",
      "Iteration 36691 => Loss: 45.70259075712108653988\n",
      "Iteration 36692 => Loss: 45.70243251443386611754\n",
      "Iteration 36693 => Loss: 45.70227427298857492133\n",
      "Iteration 36694 => Loss: 45.70211603278513479154\n",
      "Iteration 36695 => Loss: 45.70195779382354572817\n",
      "Iteration 36696 => Loss: 45.70179955610382904752\n",
      "Iteration 36697 => Loss: 45.70164131962592790615\n",
      "Iteration 36698 => Loss: 45.70148308438987072577\n",
      "Iteration 36699 => Loss: 45.70132485039562908469\n",
      "Iteration 36700 => Loss: 45.70116661764321719374\n",
      "Iteration 36701 => Loss: 45.70100838613259242038\n",
      "Iteration 36702 => Loss: 45.70085015586378318631\n",
      "Iteration 36703 => Loss: 45.70069192683673975353\n",
      "Iteration 36704 => Loss: 45.70053369905146212204\n",
      "Iteration 36705 => Loss: 45.70037547250795029186\n",
      "Iteration 36706 => Loss: 45.70021724720619005211\n",
      "Iteration 36707 => Loss: 45.70005902314618850824\n",
      "Iteration 36708 => Loss: 45.69990080032791013309\n",
      "Iteration 36709 => Loss: 45.69974257875134782125\n",
      "Iteration 36710 => Loss: 45.69958435841651578357\n",
      "Iteration 36711 => Loss: 45.69942613932337849292\n",
      "Iteration 36712 => Loss: 45.69926792147195016014\n",
      "Iteration 36713 => Loss: 45.69910970486219525810\n",
      "Iteration 36714 => Loss: 45.69895148949412799766\n",
      "Iteration 36715 => Loss: 45.69879327536771285168\n",
      "Iteration 36716 => Loss: 45.69863506248295692558\n",
      "Iteration 36717 => Loss: 45.69847685083983890308\n",
      "Iteration 36718 => Loss: 45.69831864043838010048\n",
      "Iteration 36719 => Loss: 45.69816043127853077976\n",
      "Iteration 36720 => Loss: 45.69800222336029094095\n",
      "Iteration 36721 => Loss: 45.69784401668368900573\n",
      "Iteration 36722 => Loss: 45.69768581124866102527\n",
      "Iteration 36723 => Loss: 45.69752760705522121043\n",
      "Iteration 36724 => Loss: 45.69736940410336956120\n",
      "Iteration 36725 => Loss: 45.69721120239307055044\n",
      "Iteration 36726 => Loss: 45.69705300192433838902\n",
      "Iteration 36727 => Loss: 45.69689480269717307692\n",
      "Iteration 36728 => Loss: 45.69673660471153198159\n",
      "Iteration 36729 => Loss: 45.69657840796741510303\n",
      "Iteration 36730 => Loss: 45.69642021246482244123\n",
      "Iteration 36731 => Loss: 45.69626201820374689078\n",
      "Iteration 36732 => Loss: 45.69610382518416002995\n",
      "Iteration 36733 => Loss: 45.69594563340605475332\n",
      "Iteration 36734 => Loss: 45.69578744286945237718\n",
      "Iteration 36735 => Loss: 45.69562925357431026896\n",
      "Iteration 36736 => Loss: 45.69547106552063553409\n",
      "Iteration 36737 => Loss: 45.69531287870840685628\n",
      "Iteration 36738 => Loss: 45.69515469313763844639\n",
      "Iteration 36739 => Loss: 45.69499650880828056643\n",
      "Iteration 36740 => Loss: 45.69483832572034742725\n",
      "Iteration 36741 => Loss: 45.69468014387381771257\n",
      "Iteration 36742 => Loss: 45.69452196326870563325\n",
      "Iteration 36743 => Loss: 45.69436378390499697844\n",
      "Iteration 36744 => Loss: 45.69420560578264201013\n",
      "Iteration 36745 => Loss: 45.69404742890166915004\n",
      "Iteration 36746 => Loss: 45.69388925326207129274\n",
      "Iteration 36747 => Loss: 45.69373107886383422738\n",
      "Iteration 36748 => Loss: 45.69357290570692242682\n",
      "Iteration 36749 => Loss: 45.69341473379135720734\n",
      "Iteration 36750 => Loss: 45.69325656311711725266\n",
      "Iteration 36751 => Loss: 45.69309839368418124650\n",
      "Iteration 36752 => Loss: 45.69294022549254918886\n",
      "Iteration 36753 => Loss: 45.69278205854224950144\n",
      "Iteration 36754 => Loss: 45.69262389283319691913\n",
      "Iteration 36755 => Loss: 45.69246572836542696905\n",
      "Iteration 36756 => Loss: 45.69230756513891833492\n",
      "Iteration 36757 => Loss: 45.69214940315369233303\n",
      "Iteration 36758 => Loss: 45.69199124240968501454\n",
      "Iteration 36759 => Loss: 45.69183308290691769571\n",
      "Iteration 36760 => Loss: 45.69167492464539748198\n",
      "Iteration 36761 => Loss: 45.69151676762508174079\n",
      "Iteration 36762 => Loss: 45.69135861184597047213\n",
      "Iteration 36763 => Loss: 45.69120045730806367601\n",
      "Iteration 36764 => Loss: 45.69104230401134714157\n",
      "Iteration 36765 => Loss: 45.69088415195582086881\n",
      "Iteration 36766 => Loss: 45.69072600114143511973\n",
      "Iteration 36767 => Loss: 45.69056785156823963234\n",
      "Iteration 36768 => Loss: 45.69040970323618466864\n",
      "Iteration 36769 => Loss: 45.69025155614524891234\n",
      "Iteration 36770 => Loss: 45.69009341029546789059\n",
      "Iteration 36771 => Loss: 45.68993526568679186539\n",
      "Iteration 36772 => Loss: 45.68977712231923504760\n",
      "Iteration 36773 => Loss: 45.68961898019274769922\n",
      "Iteration 36774 => Loss: 45.68946083930738666368\n",
      "Iteration 36775 => Loss: 45.68930269966311641383\n",
      "Iteration 36776 => Loss: 45.68914456125987300084\n",
      "Iteration 36777 => Loss: 45.68898642409773458439\n",
      "Iteration 36778 => Loss: 45.68882828817663011023\n",
      "Iteration 36779 => Loss: 45.68867015349655957834\n",
      "Iteration 36780 => Loss: 45.68851202005754430502\n",
      "Iteration 36781 => Loss: 45.68835388785954165769\n",
      "Iteration 36782 => Loss: 45.68819575690255874179\n",
      "Iteration 36783 => Loss: 45.68803762718655292474\n",
      "Iteration 36784 => Loss: 45.68787949871158104997\n",
      "Iteration 36785 => Loss: 45.68772137147755074693\n",
      "Iteration 36786 => Loss: 45.68756324548451885903\n",
      "Iteration 36787 => Loss: 45.68740512073244275371\n",
      "Iteration 36788 => Loss: 45.68724699722132243096\n",
      "Iteration 36789 => Loss: 45.68708887495116499622\n",
      "Iteration 36790 => Loss: 45.68693075392190650064\n",
      "Iteration 36791 => Loss: 45.68677263413361089306\n",
      "Iteration 36792 => Loss: 45.68661451558621422464\n",
      "Iteration 36793 => Loss: 45.68645639827971649538\n",
      "Iteration 36794 => Loss: 45.68629828221411770528\n",
      "Iteration 36795 => Loss: 45.68614016738943206519\n",
      "Iteration 36796 => Loss: 45.68598205380560273170\n",
      "Iteration 36797 => Loss: 45.68582394146262259937\n",
      "Iteration 36798 => Loss: 45.68566583036051298450\n",
      "Iteration 36799 => Loss: 45.68550772049926678164\n",
      "Iteration 36800 => Loss: 45.68534961187884846368\n",
      "Iteration 36801 => Loss: 45.68519150449925092516\n",
      "Iteration 36802 => Loss: 45.68503339836047416611\n",
      "Iteration 36803 => Loss: 45.68487529346251108109\n",
      "Iteration 36804 => Loss: 45.68471718980534745924\n",
      "Iteration 36805 => Loss: 45.68455908738898330057\n",
      "Iteration 36806 => Loss: 45.68440098621336176166\n",
      "Iteration 36807 => Loss: 45.68424288627853968592\n",
      "Iteration 36808 => Loss: 45.68408478758448154622\n",
      "Iteration 36809 => Loss: 45.68392669013115181542\n",
      "Iteration 36810 => Loss: 45.68376859391857891524\n",
      "Iteration 36811 => Loss: 45.68361049894673442395\n",
      "Iteration 36812 => Loss: 45.68345240521561123614\n",
      "Iteration 36813 => Loss: 45.68329431272518803553\n",
      "Iteration 36814 => Loss: 45.68313622147547903296\n",
      "Iteration 36815 => Loss: 45.68297813146645580673\n",
      "Iteration 36816 => Loss: 45.68282004269811835684\n",
      "Iteration 36817 => Loss: 45.68266195517047378871\n",
      "Iteration 36818 => Loss: 45.68250386888344394265\n",
      "Iteration 36819 => Loss: 45.68234578383709987293\n",
      "Iteration 36820 => Loss: 45.68218770003139184155\n",
      "Iteration 36821 => Loss: 45.68202961746631984852\n",
      "Iteration 36822 => Loss: 45.68187153614185547212\n",
      "Iteration 36823 => Loss: 45.68171345605804134493\n",
      "Iteration 36824 => Loss: 45.68155537721480641267\n",
      "Iteration 36825 => Loss: 45.68139729961217909704\n",
      "Iteration 36826 => Loss: 45.68123922325010966006\n",
      "Iteration 36827 => Loss: 45.68108114812864073428\n",
      "Iteration 36828 => Loss: 45.68092307424771547630\n",
      "Iteration 36829 => Loss: 45.68076500160736230782\n",
      "Iteration 36830 => Loss: 45.68060693020753859628\n",
      "Iteration 36831 => Loss: 45.68044886004826565795\n",
      "Iteration 36832 => Loss: 45.68029079112952217656\n",
      "Iteration 36833 => Loss: 45.68013272345129394125\n",
      "Iteration 36834 => Loss: 45.67997465701355253032\n",
      "Iteration 36835 => Loss: 45.67981659181634057632\n",
      "Iteration 36836 => Loss: 45.67965852785958702498\n",
      "Iteration 36837 => Loss: 45.67950046514330608716\n",
      "Iteration 36838 => Loss: 45.67934240366752618456\n",
      "Iteration 36839 => Loss: 45.67918434343218336835\n",
      "Iteration 36840 => Loss: 45.67902628443732027108\n",
      "Iteration 36841 => Loss: 45.67886822668284452220\n",
      "Iteration 36842 => Loss: 45.67871017016881296513\n",
      "Iteration 36843 => Loss: 45.67855211489521138901\n",
      "Iteration 36844 => Loss: 45.67839406086203268842\n",
      "Iteration 36845 => Loss: 45.67823600806923423079\n",
      "Iteration 36846 => Loss: 45.67807795651681601612\n",
      "Iteration 36847 => Loss: 45.67791990620479225527\n",
      "Iteration 36848 => Loss: 45.67776185713315584280\n",
      "Iteration 36849 => Loss: 45.67760380930185704074\n",
      "Iteration 36850 => Loss: 45.67744576271091716535\n",
      "Iteration 36851 => Loss: 45.67728771736030779493\n",
      "Iteration 36852 => Loss: 45.67712967325005024577\n",
      "Iteration 36853 => Loss: 45.67697163038011609615\n",
      "Iteration 36854 => Loss: 45.67681358875046271351\n",
      "Iteration 36855 => Loss: 45.67665554836111851955\n",
      "Iteration 36856 => Loss: 45.67649750921209772514\n",
      "Iteration 36857 => Loss: 45.67633947130333638142\n",
      "Iteration 36858 => Loss: 45.67618143463486291012\n",
      "Iteration 36859 => Loss: 45.67602339920662757322\n",
      "Iteration 36860 => Loss: 45.67586536501865879245\n",
      "Iteration 36861 => Loss: 45.67570733207094235695\n",
      "Iteration 36862 => Loss: 45.67554930036345695044\n",
      "Iteration 36863 => Loss: 45.67539126989618836205\n",
      "Iteration 36864 => Loss: 45.67523324066913659180\n",
      "Iteration 36865 => Loss: 45.67507521268230874512\n",
      "Iteration 36866 => Loss: 45.67491718593566218942\n",
      "Iteration 36867 => Loss: 45.67475916042918271387\n",
      "Iteration 36868 => Loss: 45.67460113616290584559\n",
      "Iteration 36869 => Loss: 45.67444311313677474118\n",
      "Iteration 36870 => Loss: 45.67428509135081071690\n",
      "Iteration 36871 => Loss: 45.67412707080499956191\n",
      "Iteration 36872 => Loss: 45.67396905149933417079\n",
      "Iteration 36873 => Loss: 45.67381103343375770010\n",
      "Iteration 36874 => Loss: 45.67365301660832699326\n",
      "Iteration 36875 => Loss: 45.67349500102300652316\n",
      "Iteration 36876 => Loss: 45.67333698667776786806\n",
      "Iteration 36877 => Loss: 45.67317897357263234426\n",
      "Iteration 36878 => Loss: 45.67302096170755731919\n",
      "Iteration 36879 => Loss: 45.67286295108255700370\n",
      "Iteration 36880 => Loss: 45.67270494169763850323\n",
      "Iteration 36881 => Loss: 45.67254693355274497435\n",
      "Iteration 36882 => Loss: 45.67238892664789773335\n",
      "Iteration 36883 => Loss: 45.67223092098307546394\n",
      "Iteration 36884 => Loss: 45.67207291655828527155\n",
      "Iteration 36885 => Loss: 45.67191491337349873447\n",
      "Iteration 36886 => Loss: 45.67175691142870874728\n",
      "Iteration 36887 => Loss: 45.67159891072390109912\n",
      "Iteration 36888 => Loss: 45.67144091125909710627\n",
      "Iteration 36889 => Loss: 45.67128291303425413616\n",
      "Iteration 36890 => Loss: 45.67112491604937218881\n",
      "Iteration 36891 => Loss: 45.67096692030445836963\n",
      "Iteration 36892 => Loss: 45.67080892579946294063\n",
      "Iteration 36893 => Loss: 45.67065093253440721810\n",
      "Iteration 36894 => Loss: 45.67049294050928409661\n",
      "Iteration 36895 => Loss: 45.67033494972403673273\n",
      "Iteration 36896 => Loss: 45.67017696017875039161\n",
      "Iteration 36897 => Loss: 45.67001897187332559724\n",
      "Iteration 36898 => Loss: 45.66986098480778366593\n",
      "Iteration 36899 => Loss: 45.66970299898211749223\n",
      "Iteration 36900 => Loss: 45.66954501439631997073\n",
      "Iteration 36901 => Loss: 45.66938703105037689056\n",
      "Iteration 36902 => Loss: 45.66922904894427404088\n",
      "Iteration 36903 => Loss: 45.66907106807803984339\n",
      "Iteration 36904 => Loss: 45.66891308845158192753\n",
      "Iteration 36905 => Loss: 45.66875511006496424216\n",
      "Iteration 36906 => Loss: 45.66859713291814415470\n",
      "Iteration 36907 => Loss: 45.66843915701112166516\n",
      "Iteration 36908 => Loss: 45.66828118234388256269\n",
      "Iteration 36909 => Loss: 45.66812320891642684728\n",
      "Iteration 36910 => Loss: 45.66796523672874030808\n",
      "Iteration 36911 => Loss: 45.66780726578081583966\n",
      "Iteration 36912 => Loss: 45.66764929607263212574\n",
      "Iteration 36913 => Loss: 45.66749132760418916632\n",
      "Iteration 36914 => Loss: 45.66733336037546564512\n",
      "Iteration 36915 => Loss: 45.66717539438646866756\n",
      "Iteration 36916 => Loss: 45.66701742963716981194\n",
      "Iteration 36917 => Loss: 45.66685946612756907825\n",
      "Iteration 36918 => Loss: 45.66670150385767357193\n",
      "Iteration 36919 => Loss: 45.66654354282746908211\n",
      "Iteration 36920 => Loss: 45.66638558303691297624\n",
      "Iteration 36921 => Loss: 45.66622762448601946517\n",
      "Iteration 36922 => Loss: 45.66606966717477433804\n",
      "Iteration 36923 => Loss: 45.66591171110315627857\n",
      "Iteration 36924 => Loss: 45.66575375627119370847\n",
      "Iteration 36925 => Loss: 45.66559580267884399518\n",
      "Iteration 36926 => Loss: 45.66543785032612134955\n",
      "Iteration 36927 => Loss: 45.66527989921296182274\n",
      "Iteration 36928 => Loss: 45.66512194933943646902\n",
      "Iteration 36929 => Loss: 45.66496400070547423411\n",
      "Iteration 36930 => Loss: 45.66480605331107511802\n",
      "Iteration 36931 => Loss: 45.66464810715624622617\n",
      "Iteration 36932 => Loss: 45.66449016224099466399\n",
      "Iteration 36933 => Loss: 45.66433221856523516635\n",
      "Iteration 36934 => Loss: 45.66417427612904589296\n",
      "Iteration 36935 => Loss: 45.66401633493237710582\n",
      "Iteration 36936 => Loss: 45.66385839497521459407\n",
      "Iteration 36937 => Loss: 45.66370045625755835772\n",
      "Iteration 36938 => Loss: 45.66354251877940129134\n",
      "Iteration 36939 => Loss: 45.66338458254072207865\n",
      "Iteration 36940 => Loss: 45.66322664754151361421\n",
      "Iteration 36941 => Loss: 45.66306871378179010890\n",
      "Iteration 36942 => Loss: 45.66291078126152314098\n",
      "Iteration 36943 => Loss: 45.66275284998068428877\n",
      "Iteration 36944 => Loss: 45.66259491993929486853\n",
      "Iteration 36945 => Loss: 45.66243699113731935313\n",
      "Iteration 36946 => Loss: 45.66227906357476484800\n",
      "Iteration 36947 => Loss: 45.66212113725163135314\n",
      "Iteration 36948 => Loss: 45.66196321216788334141\n",
      "Iteration 36949 => Loss: 45.66180528832352791824\n",
      "Iteration 36950 => Loss: 45.66164736571854376734\n",
      "Iteration 36951 => Loss: 45.66148944435291667787\n",
      "Iteration 36952 => Loss: 45.66133152422666796610\n",
      "Iteration 36953 => Loss: 45.66117360533976210490\n",
      "Iteration 36954 => Loss: 45.66101568769220619970\n",
      "Iteration 36955 => Loss: 45.66085777128397893421\n",
      "Iteration 36956 => Loss: 45.66069985611503057044\n",
      "Iteration 36957 => Loss: 45.66054194218543216266\n",
      "Iteration 36958 => Loss: 45.66038402949514107831\n",
      "Iteration 36959 => Loss: 45.66022611804410047398\n",
      "Iteration 36960 => Loss: 45.66006820783238140393\n",
      "Iteration 36961 => Loss: 45.65991029885990570847\n",
      "Iteration 36962 => Loss: 45.65975239112670891473\n",
      "Iteration 36963 => Loss: 45.65959448463274839014\n",
      "Iteration 36964 => Loss: 45.65943657937805255642\n",
      "Iteration 36965 => Loss: 45.65927867536257167558\n",
      "Iteration 36966 => Loss: 45.65912077258630574761\n",
      "Iteration 36967 => Loss: 45.65896287104926898337\n",
      "Iteration 36968 => Loss: 45.65880497075142585572\n",
      "Iteration 36969 => Loss: 45.65864707169277636467\n",
      "Iteration 36970 => Loss: 45.65848917387331340478\n",
      "Iteration 36971 => Loss: 45.65833127729302987063\n",
      "Iteration 36972 => Loss: 45.65817338195191155137\n",
      "Iteration 36973 => Loss: 45.65801548784993713070\n",
      "Iteration 36974 => Loss: 45.65785759498709950321\n",
      "Iteration 36975 => Loss: 45.65769970336342709061\n",
      "Iteration 36976 => Loss: 45.65754181297884173318\n",
      "Iteration 36977 => Loss: 45.65738392383339316893\n",
      "Iteration 36978 => Loss: 45.65722603592706718700\n",
      "Iteration 36979 => Loss: 45.65706814925978562769\n",
      "Iteration 36980 => Loss: 45.65691026383164796698\n",
      "Iteration 36981 => Loss: 45.65675237964255472889\n",
      "Iteration 36982 => Loss: 45.65659449669252722970\n",
      "Iteration 36983 => Loss: 45.65643661498157257483\n",
      "Iteration 36984 => Loss: 45.65627873450964813173\n",
      "Iteration 36985 => Loss: 45.65612085527676811125\n",
      "Iteration 36986 => Loss: 45.65596297728291830254\n",
      "Iteration 36987 => Loss: 45.65580510052808449473\n",
      "Iteration 36988 => Loss: 45.65564722501225247697\n",
      "Iteration 36989 => Loss: 45.65548935073544356555\n",
      "Iteration 36990 => Loss: 45.65533147769760091705\n",
      "Iteration 36991 => Loss: 45.65517360589874584775\n",
      "Iteration 36992 => Loss: 45.65501573533885704137\n",
      "Iteration 36993 => Loss: 45.65485786601792028705\n",
      "Iteration 36994 => Loss: 45.65469999793594979565\n",
      "Iteration 36995 => Loss: 45.65454213109292425088\n",
      "Iteration 36996 => Loss: 45.65438426548880812561\n",
      "Iteration 36997 => Loss: 45.65422640112362984155\n",
      "Iteration 36998 => Loss: 45.65406853799733966071\n",
      "Iteration 36999 => Loss: 45.65391067610999442650\n",
      "Iteration 37000 => Loss: 45.65375281546150176837\n",
      "Iteration 37001 => Loss: 45.65359495605189721346\n",
      "Iteration 37002 => Loss: 45.65343709788118076176\n",
      "Iteration 37003 => Loss: 45.65327924094930978072\n",
      "Iteration 37004 => Loss: 45.65312138525630558661\n",
      "Iteration 37005 => Loss: 45.65296353080213265230\n",
      "Iteration 37006 => Loss: 45.65280567758680518864\n",
      "Iteration 37007 => Loss: 45.65264782561030187935\n",
      "Iteration 37008 => Loss: 45.65248997487258719730\n",
      "Iteration 37009 => Loss: 45.65233212537370377504\n",
      "Iteration 37010 => Loss: 45.65217427711360187459\n",
      "Iteration 37011 => Loss: 45.65201643009229570680\n",
      "Iteration 37012 => Loss: 45.65185858430974974453\n",
      "Iteration 37013 => Loss: 45.65170073976599951493\n",
      "Iteration 37014 => Loss: 45.65154289646095975286\n",
      "Iteration 37015 => Loss: 45.65138505439470151259\n",
      "Iteration 37016 => Loss: 45.65122721356716084529\n",
      "Iteration 37017 => Loss: 45.65106937397835196180\n",
      "Iteration 37018 => Loss: 45.65091153562826065127\n",
      "Iteration 37019 => Loss: 45.65075369851686559741\n",
      "Iteration 37020 => Loss: 45.65059586264418811652\n",
      "Iteration 37021 => Loss: 45.65043802801019978688\n",
      "Iteration 37022 => Loss: 45.65028019461486508135\n",
      "Iteration 37023 => Loss: 45.65012236245821952707\n",
      "Iteration 37024 => Loss: 45.64996453154021338605\n",
      "Iteration 37025 => Loss: 45.64980670186087508000\n",
      "Iteration 37026 => Loss: 45.64964887342016197636\n",
      "Iteration 37027 => Loss: 45.64949104621808118054\n",
      "Iteration 37028 => Loss: 45.64933322025462558713\n",
      "Iteration 37029 => Loss: 45.64917539552978809070\n",
      "Iteration 37030 => Loss: 45.64901757204354737496\n",
      "Iteration 37031 => Loss: 45.64885974979586791278\n",
      "Iteration 37032 => Loss: 45.64870192878679233672\n",
      "Iteration 37033 => Loss: 45.64854410901629933051\n",
      "Iteration 37034 => Loss: 45.64838629048433915614\n",
      "Iteration 37035 => Loss: 45.64822847319095444618\n",
      "Iteration 37036 => Loss: 45.64807065713610256807\n",
      "Iteration 37037 => Loss: 45.64791284231976220553\n",
      "Iteration 37038 => Loss: 45.64775502874197599112\n",
      "Iteration 37039 => Loss: 45.64759721640270129228\n",
      "Iteration 37040 => Loss: 45.64743940530192389815\n",
      "Iteration 37041 => Loss: 45.64728159543964380873\n",
      "Iteration 37042 => Loss: 45.64712378681583260231\n",
      "Iteration 37043 => Loss: 45.64696597943049738433\n",
      "Iteration 37044 => Loss: 45.64680817328361683849\n",
      "Iteration 37045 => Loss: 45.64665036837521228108\n",
      "Iteration 37046 => Loss: 45.64649256470526239582\n",
      "Iteration 37047 => Loss: 45.64633476227371744471\n",
      "Iteration 37048 => Loss: 45.64617696108060584947\n",
      "Iteration 37049 => Loss: 45.64601916112592761010\n",
      "Iteration 37050 => Loss: 45.64586136240962588317\n",
      "Iteration 37051 => Loss: 45.64570356493173619583\n",
      "Iteration 37052 => Loss: 45.64554576869223723179\n",
      "Iteration 37053 => Loss: 45.64538797369109346391\n",
      "Iteration 37054 => Loss: 45.64523017992834041934\n",
      "Iteration 37055 => Loss: 45.64507238740394967635\n",
      "Iteration 37056 => Loss: 45.64491459611788570783\n",
      "Iteration 37057 => Loss: 45.64475680607016983004\n",
      "Iteration 37058 => Loss: 45.64459901726078783213\n",
      "Iteration 37059 => Loss: 45.64444122968969708154\n",
      "Iteration 37060 => Loss: 45.64428344335694021083\n",
      "Iteration 37061 => Loss: 45.64412565826248169287\n",
      "Iteration 37062 => Loss: 45.64396787440631442223\n",
      "Iteration 37063 => Loss: 45.64381009178840287177\n",
      "Iteration 37064 => Loss: 45.64365231040876835777\n",
      "Iteration 37065 => Loss: 45.64349453026740377481\n",
      "Iteration 37066 => Loss: 45.64333675136430201746\n",
      "Iteration 37067 => Loss: 45.64317897369941334773\n",
      "Iteration 37068 => Loss: 45.64302119727275197647\n",
      "Iteration 37069 => Loss: 45.64286342208433921996\n",
      "Iteration 37070 => Loss: 45.64270564813413244565\n",
      "Iteration 37071 => Loss: 45.64254787542212454809\n",
      "Iteration 37072 => Loss: 45.64239010394830131645\n",
      "Iteration 37073 => Loss: 45.64223233371266275071\n",
      "Iteration 37074 => Loss: 45.64207456471520174546\n",
      "Iteration 37075 => Loss: 45.64191679695589698440\n",
      "Iteration 37076 => Loss: 45.64175903043475557297\n",
      "Iteration 37077 => Loss: 45.64160126515174198403\n",
      "Iteration 37078 => Loss: 45.64144350110687042843\n",
      "Iteration 37079 => Loss: 45.64128573830013380075\n",
      "Iteration 37080 => Loss: 45.64112797673148946842\n",
      "Iteration 37081 => Loss: 45.64097021640096585315\n",
      "Iteration 37082 => Loss: 45.64081245730853453324\n",
      "Iteration 37083 => Loss: 45.64065469945418129782\n",
      "Iteration 37084 => Loss: 45.64049694283791325233\n",
      "Iteration 37085 => Loss: 45.64033918745968776420\n",
      "Iteration 37086 => Loss: 45.64018143331954746600\n",
      "Iteration 37087 => Loss: 45.64002368041742840887\n",
      "Iteration 37088 => Loss: 45.63986592875336611996\n",
      "Iteration 37089 => Loss: 45.63970817832731796670\n",
      "Iteration 37090 => Loss: 45.63955042913928394910\n",
      "Iteration 37091 => Loss: 45.63939268118928538343\n",
      "Iteration 37092 => Loss: 45.63923493447725832084\n",
      "Iteration 37093 => Loss: 45.63907718900321697220\n",
      "Iteration 37094 => Loss: 45.63891944476716133750\n",
      "Iteration 37095 => Loss: 45.63876170176907010045\n",
      "Iteration 37096 => Loss: 45.63860396000893615565\n",
      "Iteration 37097 => Loss: 45.63844621948678081935\n",
      "Iteration 37098 => Loss: 45.63828848020251882645\n",
      "Iteration 37099 => Loss: 45.63813074215622123120\n",
      "Iteration 37100 => Loss: 45.63797300534782408477\n",
      "Iteration 37101 => Loss: 45.63781526977734870343\n",
      "Iteration 37102 => Loss: 45.63765753544476666548\n",
      "Iteration 37103 => Loss: 45.63749980235009218177\n",
      "Iteration 37104 => Loss: 45.63734207049327551431\n",
      "Iteration 37105 => Loss: 45.63718433987433087395\n",
      "Iteration 37106 => Loss: 45.63702661049325826070\n",
      "Iteration 37107 => Loss: 45.63686888235004346370\n",
      "Iteration 37108 => Loss: 45.63671115544465095581\n",
      "Iteration 37109 => Loss: 45.63655342977710915875\n",
      "Iteration 37110 => Loss: 45.63639570534738965080\n",
      "Iteration 37111 => Loss: 45.63623798215547111568\n",
      "Iteration 37112 => Loss: 45.63608026020136776424\n",
      "Iteration 37113 => Loss: 45.63592253948505117478\n",
      "Iteration 37114 => Loss: 45.63576482000650003101\n",
      "Iteration 37115 => Loss: 45.63560710176576407093\n",
      "Iteration 37116 => Loss: 45.63544938476274381856\n",
      "Iteration 37117 => Loss: 45.63529166899753164444\n",
      "Iteration 37118 => Loss: 45.63513395447002807259\n",
      "Iteration 37119 => Loss: 45.63497624118027573559\n",
      "Iteration 37120 => Loss: 45.63481852912823910629\n",
      "Iteration 37121 => Loss: 45.63466081831391818469\n",
      "Iteration 37122 => Loss: 45.63450310873731297079\n",
      "Iteration 37123 => Loss: 45.63434540039838793746\n",
      "Iteration 37124 => Loss: 45.63418769329716440097\n",
      "Iteration 37125 => Loss: 45.63402998743362104506\n",
      "Iteration 37126 => Loss: 45.63387228280771523714\n",
      "Iteration 37127 => Loss: 45.63371457941949671522\n",
      "Iteration 37128 => Loss: 45.63355687726892284672\n",
      "Iteration 37129 => Loss: 45.63339917635597942080\n",
      "Iteration 37130 => Loss: 45.63324147668068775374\n",
      "Iteration 37131 => Loss: 45.63308377824296968583\n",
      "Iteration 37132 => Loss: 45.63292608104291048221\n",
      "Iteration 37133 => Loss: 45.63276838508040356146\n",
      "Iteration 37134 => Loss: 45.63261069035551997786\n",
      "Iteration 37135 => Loss: 45.63245299686820999341\n",
      "Iteration 37136 => Loss: 45.63229530461845939726\n",
      "Iteration 37137 => Loss: 45.63213761360628240027\n",
      "Iteration 37138 => Loss: 45.63197992383164347530\n",
      "Iteration 37139 => Loss: 45.63182223529456393862\n",
      "Iteration 37140 => Loss: 45.63166454799500115769\n",
      "Iteration 37141 => Loss: 45.63150686193294802706\n",
      "Iteration 37142 => Loss: 45.63134917710842586303\n",
      "Iteration 37143 => Loss: 45.63119149352140624387\n",
      "Iteration 37144 => Loss: 45.63103381117186074789\n",
      "Iteration 37145 => Loss: 45.63087613005980358594\n",
      "Iteration 37146 => Loss: 45.63071845018523475801\n",
      "Iteration 37147 => Loss: 45.63056077154812584240\n",
      "Iteration 37148 => Loss: 45.63040309414846262825\n",
      "Iteration 37149 => Loss: 45.63024541798624511557\n",
      "Iteration 37150 => Loss: 45.63008774306147330435\n",
      "Iteration 37151 => Loss: 45.62993006937411166746\n",
      "Iteration 37152 => Loss: 45.62977239692416731032\n",
      "Iteration 37153 => Loss: 45.62961472571164023293\n",
      "Iteration 37154 => Loss: 45.62945705573648780273\n",
      "Iteration 37155 => Loss: 45.62929938699873844143\n",
      "Iteration 37156 => Loss: 45.62914171949835662190\n",
      "Iteration 37157 => Loss: 45.62898405323534234412\n",
      "Iteration 37158 => Loss: 45.62882638820968139726\n",
      "Iteration 37159 => Loss: 45.62866872442136667587\n",
      "Iteration 37160 => Loss: 45.62851106187039817996\n",
      "Iteration 37161 => Loss: 45.62835340055676880411\n",
      "Iteration 37162 => Loss: 45.62819574048042170489\n",
      "Iteration 37163 => Loss: 45.62803808164139951487\n",
      "Iteration 37164 => Loss: 45.62788042403968802319\n",
      "Iteration 37165 => Loss: 45.62772276767524459729\n",
      "Iteration 37166 => Loss: 45.62756511254808344802\n",
      "Iteration 37167 => Loss: 45.62740745865819746996\n",
      "Iteration 37168 => Loss: 45.62724980600557955768\n",
      "Iteration 37169 => Loss: 45.62709215459020839489\n",
      "Iteration 37170 => Loss: 45.62693450441206977075\n",
      "Iteration 37171 => Loss: 45.62677685547115657982\n",
      "Iteration 37172 => Loss: 45.62661920776746882211\n",
      "Iteration 37173 => Loss: 45.62646156130099228676\n",
      "Iteration 37174 => Loss: 45.62630391607171986834\n",
      "Iteration 37175 => Loss: 45.62614627207964446143\n",
      "Iteration 37176 => Loss: 45.62598862932473764431\n",
      "Iteration 37177 => Loss: 45.62583098780700652242\n",
      "Iteration 37178 => Loss: 45.62567334752644399032\n",
      "Iteration 37179 => Loss: 45.62551570848303583716\n",
      "Iteration 37180 => Loss: 45.62535807067676074666\n",
      "Iteration 37181 => Loss: 45.62520043410763292968\n",
      "Iteration 37182 => Loss: 45.62504279877561685907\n",
      "Iteration 37183 => Loss: 45.62488516468071253485\n",
      "Iteration 37184 => Loss: 45.62472753182290574614\n",
      "Iteration 37185 => Loss: 45.62456990020219649296\n",
      "Iteration 37186 => Loss: 45.62441226981859898615\n",
      "Iteration 37187 => Loss: 45.62425464067206348773\n",
      "Iteration 37188 => Loss: 45.62409701276257578684\n",
      "Iteration 37189 => Loss: 45.62393938609016430519\n",
      "Iteration 37190 => Loss: 45.62378176065477930479\n",
      "Iteration 37191 => Loss: 45.62362413645643499649\n",
      "Iteration 37192 => Loss: 45.62346651349512427487\n",
      "Iteration 37193 => Loss: 45.62330889177082582364\n",
      "Iteration 37194 => Loss: 45.62315127128351832653\n",
      "Iteration 37195 => Loss: 45.62299365203324441609\n",
      "Iteration 37196 => Loss: 45.62283603401995435433\n",
      "Iteration 37197 => Loss: 45.62267841724362682498\n",
      "Iteration 37198 => Loss: 45.62252080170425472261\n",
      "Iteration 37199 => Loss: 45.62236318740185936349\n",
      "Iteration 37200 => Loss: 45.62220557433641232592\n",
      "Iteration 37201 => Loss: 45.62204796250789939904\n",
      "Iteration 37202 => Loss: 45.62189035191631347743\n",
      "Iteration 37203 => Loss: 45.62173274256164745566\n",
      "Iteration 37204 => Loss: 45.62157513444389422830\n",
      "Iteration 37205 => Loss: 45.62141752756303247907\n",
      "Iteration 37206 => Loss: 45.62125992191907641882\n",
      "Iteration 37207 => Loss: 45.62110231751199052042\n",
      "Iteration 37208 => Loss: 45.62094471434178899472\n",
      "Iteration 37209 => Loss: 45.62078711240842920915\n",
      "Iteration 37210 => Loss: 45.62062951171192537458\n",
      "Iteration 37211 => Loss: 45.62047191225228459643\n",
      "Iteration 37212 => Loss: 45.62031431402944292586\n",
      "Iteration 37213 => Loss: 45.62015671704345720627\n",
      "Iteration 37214 => Loss: 45.61999912129427059426\n",
      "Iteration 37215 => Loss: 45.61984152678189019525\n",
      "Iteration 37216 => Loss: 45.61968393350628758753\n",
      "Iteration 37217 => Loss: 45.61952634146749119282\n",
      "Iteration 37218 => Loss: 45.61936875066542995683\n",
      "Iteration 37219 => Loss: 45.61921116110017493384\n",
      "Iteration 37220 => Loss: 45.61905357277166928043\n",
      "Iteration 37221 => Loss: 45.61889598567989878575\n",
      "Iteration 37222 => Loss: 45.61873839982485634437\n",
      "Iteration 37223 => Loss: 45.61858081520654906171\n",
      "Iteration 37224 => Loss: 45.61842323182494851608\n",
      "Iteration 37225 => Loss: 45.61826564968006181289\n",
      "Iteration 37226 => Loss: 45.61810806877188184671\n",
      "Iteration 37227 => Loss: 45.61795048910038019585\n",
      "Iteration 37228 => Loss: 45.61779291066555686029\n",
      "Iteration 37229 => Loss: 45.61763533346740473462\n",
      "Iteration 37230 => Loss: 45.61747775750588829169\n",
      "Iteration 37231 => Loss: 45.61732018278103595321\n",
      "Iteration 37232 => Loss: 45.61716260929280508662\n",
      "Iteration 37233 => Loss: 45.61700503704120990278\n",
      "Iteration 37234 => Loss: 45.61684746602625040168\n",
      "Iteration 37235 => Loss: 45.61668989624788395076\n",
      "Iteration 37236 => Loss: 45.61653232770613186631\n",
      "Iteration 37237 => Loss: 45.61637476040095862118\n",
      "Iteration 37238 => Loss: 45.61621719433236421537\n",
      "Iteration 37239 => Loss: 45.61605962950035575432\n",
      "Iteration 37240 => Loss: 45.61590206590488350002\n",
      "Iteration 37241 => Loss: 45.61574450354596876878\n",
      "Iteration 37242 => Loss: 45.61558694242361156057\n",
      "Iteration 37243 => Loss: 45.61542938253776213742\n",
      "Iteration 37244 => Loss: 45.61527182388844892102\n",
      "Iteration 37245 => Loss: 45.61511426647564348968\n",
      "Iteration 37246 => Loss: 45.61495671029934584340\n",
      "Iteration 37247 => Loss: 45.61479915535953466588\n",
      "Iteration 37248 => Loss: 45.61464160165620285170\n",
      "Iteration 37249 => Loss: 45.61448404918936461172\n",
      "Iteration 37250 => Loss: 45.61432649795895599709\n",
      "Iteration 37251 => Loss: 45.61416894796503385123\n",
      "Iteration 37252 => Loss: 45.61401139920753422530\n",
      "Iteration 37253 => Loss: 45.61385385168648554099\n",
      "Iteration 37254 => Loss: 45.61369630540184516576\n",
      "Iteration 37255 => Loss: 45.61353876035362731045\n",
      "Iteration 37256 => Loss: 45.61338121654180355335\n",
      "Iteration 37257 => Loss: 45.61322367396639521075\n",
      "Iteration 37258 => Loss: 45.61306613262735965009\n",
      "Iteration 37259 => Loss: 45.61290859252471108221\n",
      "Iteration 37260 => Loss: 45.61275105365842819083\n",
      "Iteration 37261 => Loss: 45.61259351602848255425\n",
      "Iteration 37262 => Loss: 45.61243597963490259417\n",
      "Iteration 37263 => Loss: 45.61227844447765278346\n",
      "Iteration 37264 => Loss: 45.61212091055674733298\n",
      "Iteration 37265 => Loss: 45.61196337787212939929\n",
      "Iteration 37266 => Loss: 45.61180584642383450955\n",
      "Iteration 37267 => Loss: 45.61164831621183424204\n",
      "Iteration 37268 => Loss: 45.61149078723614280761\n",
      "Iteration 37269 => Loss: 45.61133325949671046828\n",
      "Iteration 37270 => Loss: 45.61117573299355854033\n",
      "Iteration 37271 => Loss: 45.61101820772664439119\n",
      "Iteration 37272 => Loss: 45.61086068369599644257\n",
      "Iteration 37273 => Loss: 45.61070316090159337818\n",
      "Iteration 37274 => Loss: 45.61054563934342809262\n",
      "Iteration 37275 => Loss: 45.61038811902145084787\n",
      "Iteration 37276 => Loss: 45.61023059993571138193\n",
      "Iteration 37277 => Loss: 45.61007308208618127310\n",
      "Iteration 37278 => Loss: 45.60991556547280367795\n",
      "Iteration 37279 => Loss: 45.60975805009565675618\n",
      "Iteration 37280 => Loss: 45.60960053595465524268\n",
      "Iteration 37281 => Loss: 45.60944302304982045371\n",
      "Iteration 37282 => Loss: 45.60928551138111686214\n",
      "Iteration 37283 => Loss: 45.60912800094859420597\n",
      "Iteration 37284 => Loss: 45.60897049175217432548\n",
      "Iteration 37285 => Loss: 45.60881298379190695869\n",
      "Iteration 37286 => Loss: 45.60865547706774236758\n",
      "Iteration 37287 => Loss: 45.60849797157967344674\n",
      "Iteration 37288 => Loss: 45.60834046732770730159\n",
      "Iteration 37289 => Loss: 45.60818296431181551043\n",
      "Iteration 37290 => Loss: 45.60802546253199807325\n",
      "Iteration 37291 => Loss: 45.60786796198826920090\n",
      "Iteration 37292 => Loss: 45.60771046268058626083\n",
      "Iteration 37293 => Loss: 45.60755296460894925303\n",
      "Iteration 37294 => Loss: 45.60739546777332975580\n",
      "Iteration 37295 => Loss: 45.60723797217375619084\n",
      "Iteration 37296 => Loss: 45.60708047781021434730\n",
      "Iteration 37297 => Loss: 45.60692298468266159261\n",
      "Iteration 37298 => Loss: 45.60676549279111213764\n",
      "Iteration 37299 => Loss: 45.60660800213552334981\n",
      "Iteration 37300 => Loss: 45.60645051271595207254\n",
      "Iteration 37301 => Loss: 45.60629302453232014614\n",
      "Iteration 37302 => Loss: 45.60613553758467020316\n",
      "Iteration 37303 => Loss: 45.60597805187295961105\n",
      "Iteration 37304 => Loss: 45.60582056739718836980\n",
      "Iteration 37305 => Loss: 45.60566308415734937398\n",
      "Iteration 37306 => Loss: 45.60550560215342130732\n",
      "Iteration 37307 => Loss: 45.60534812138541838067\n",
      "Iteration 37308 => Loss: 45.60519064185329796146\n",
      "Iteration 37309 => Loss: 45.60503316355706004970\n",
      "Iteration 37310 => Loss: 45.60487568649674727794\n",
      "Iteration 37311 => Loss: 45.60471821067228859192\n",
      "Iteration 37312 => Loss: 45.60456073608368399164\n",
      "Iteration 37313 => Loss: 45.60440326273092637166\n",
      "Iteration 37314 => Loss: 45.60424579061402994284\n",
      "Iteration 37315 => Loss: 45.60408831973294496720\n",
      "Iteration 37316 => Loss: 45.60393085008767855015\n",
      "Iteration 37317 => Loss: 45.60377338167825200799\n",
      "Iteration 37318 => Loss: 45.60361591450460849728\n",
      "Iteration 37319 => Loss: 45.60345844856677643975\n",
      "Iteration 37320 => Loss: 45.60330098386470609739\n",
      "Iteration 37321 => Loss: 45.60314352039844010278\n",
      "Iteration 37322 => Loss: 45.60298605816791450707\n",
      "Iteration 37323 => Loss: 45.60282859717315062653\n",
      "Iteration 37324 => Loss: 45.60267113741414135575\n",
      "Iteration 37325 => Loss: 45.60251367889085116758\n",
      "Iteration 37326 => Loss: 45.60235622160331558916\n",
      "Iteration 37327 => Loss: 45.60219876555147067165\n",
      "Iteration 37328 => Loss: 45.60204131073533773133\n",
      "Iteration 37329 => Loss: 45.60188385715490255734\n",
      "Iteration 37330 => Loss: 45.60172640481015804426\n",
      "Iteration 37331 => Loss: 45.60156895370108998122\n",
      "Iteration 37332 => Loss: 45.60141150382769836824\n",
      "Iteration 37333 => Loss: 45.60125405518995478360\n",
      "Iteration 37334 => Loss: 45.60109660778783791102\n",
      "Iteration 37335 => Loss: 45.60093916162139748849\n",
      "Iteration 37336 => Loss: 45.60078171669056246174\n",
      "Iteration 37337 => Loss: 45.60062427299536835790\n",
      "Iteration 37338 => Loss: 45.60046683053577254441\n",
      "Iteration 37339 => Loss: 45.60030938931176081041\n",
      "Iteration 37340 => Loss: 45.60015194932336868305\n",
      "Iteration 37341 => Loss: 45.59999451057054642433\n",
      "Iteration 37342 => Loss: 45.59983707305327271797\n",
      "Iteration 37343 => Loss: 45.59967963677158309110\n",
      "Iteration 37344 => Loss: 45.59952220172544201660\n",
      "Iteration 37345 => Loss: 45.59936476791486370530\n",
      "Iteration 37346 => Loss: 45.59920733533978420837\n",
      "Iteration 37347 => Loss: 45.59904990400023194752\n",
      "Iteration 37348 => Loss: 45.59889247389619981732\n",
      "Iteration 37349 => Loss: 45.59873504502767360691\n",
      "Iteration 37350 => Loss: 45.59857761739462489459\n",
      "Iteration 37351 => Loss: 45.59842019099708210206\n",
      "Iteration 37352 => Loss: 45.59826276583500970219\n",
      "Iteration 37353 => Loss: 45.59810534190839348412\n",
      "Iteration 37354 => Loss: 45.59794791921724055328\n",
      "Iteration 37355 => Loss: 45.59779049776152959339\n",
      "Iteration 37356 => Loss: 45.59763307754124639359\n",
      "Iteration 37357 => Loss: 45.59747565855639805932\n",
      "Iteration 37358 => Loss: 45.59731824080696327428\n",
      "Iteration 37359 => Loss: 45.59716082429293493306\n",
      "Iteration 37360 => Loss: 45.59700340901428461393\n",
      "Iteration 37361 => Loss: 45.59684599497106205490\n",
      "Iteration 37362 => Loss: 45.59668858216318199084\n",
      "Iteration 37363 => Loss: 45.59653117059066573802\n",
      "Iteration 37364 => Loss: 45.59637376025354171816\n",
      "Iteration 37365 => Loss: 45.59621635115174598241\n",
      "Iteration 37366 => Loss: 45.59605894328527853077\n",
      "Iteration 37367 => Loss: 45.59590153665413936324\n",
      "Iteration 37368 => Loss: 45.59574413125834269067\n",
      "Iteration 37369 => Loss: 45.59558672709783166965\n",
      "Iteration 37370 => Loss: 45.59542932417262051104\n",
      "Iteration 37371 => Loss: 45.59527192248272342567\n",
      "Iteration 37372 => Loss: 45.59511452202809778100\n",
      "Iteration 37373 => Loss: 45.59495712280872226074\n",
      "Iteration 37374 => Loss: 45.59479972482463239203\n",
      "Iteration 37375 => Loss: 45.59464232807577843687\n",
      "Iteration 37376 => Loss: 45.59448493256216750069\n",
      "Iteration 37377 => Loss: 45.59432753828379958350\n",
      "Iteration 37378 => Loss: 45.59417014524063915815\n",
      "Iteration 37379 => Loss: 45.59401275343269333007\n",
      "Iteration 37380 => Loss: 45.59385536285996209926\n",
      "Iteration 37381 => Loss: 45.59369797352240993860\n",
      "Iteration 37382 => Loss: 45.59354058542004395349\n",
      "Iteration 37383 => Loss: 45.59338319855284993309\n",
      "Iteration 37384 => Loss: 45.59322581292083498283\n",
      "Iteration 37385 => Loss: 45.59306842852396357557\n",
      "Iteration 37386 => Loss: 45.59291104536224281674\n",
      "Iteration 37387 => Loss: 45.59275366343563717919\n",
      "Iteration 37388 => Loss: 45.59259628274418219007\n",
      "Iteration 37389 => Loss: 45.59243890328782811139\n",
      "Iteration 37390 => Loss: 45.59228152506656783771\n",
      "Iteration 37391 => Loss: 45.59212414808041557990\n",
      "Iteration 37392 => Loss: 45.59196677232936423252\n",
      "Iteration 37393 => Loss: 45.59180939781337116301\n",
      "Iteration 37394 => Loss: 45.59165202453245768766\n",
      "Iteration 37395 => Loss: 45.59149465248658117389\n",
      "Iteration 37396 => Loss: 45.59133728167577004342\n",
      "Iteration 37397 => Loss: 45.59117991210001008540\n",
      "Iteration 37398 => Loss: 45.59102254375924445640\n",
      "Iteration 37399 => Loss: 45.59086517665352999984\n",
      "Iteration 37400 => Loss: 45.59070781078278855603\n",
      "Iteration 37401 => Loss: 45.59055044614707696837\n",
      "Iteration 37402 => Loss: 45.59039308274633128804\n",
      "Iteration 37403 => Loss: 45.59023572058058704215\n",
      "Iteration 37404 => Loss: 45.59007835964979449273\n",
      "Iteration 37405 => Loss: 45.58992099995397495604\n",
      "Iteration 37406 => Loss: 45.58976364149308579954\n",
      "Iteration 37407 => Loss: 45.58960628426716965578\n",
      "Iteration 37408 => Loss: 45.58944892827616257591\n",
      "Iteration 37409 => Loss: 45.58929157352009298165\n",
      "Iteration 37410 => Loss: 45.58913421999891824044\n",
      "Iteration 37411 => Loss: 45.58897686771264545769\n",
      "Iteration 37412 => Loss: 45.58881951666128173883\n",
      "Iteration 37413 => Loss: 45.58866216684478445131\n",
      "Iteration 37414 => Loss: 45.58850481826316780598\n",
      "Iteration 37415 => Loss: 45.58834747091641048655\n",
      "Iteration 37416 => Loss: 45.58819012480451249303\n",
      "Iteration 37417 => Loss: 45.58803277992745961456\n",
      "Iteration 37418 => Loss: 45.58787543628523764028\n",
      "Iteration 37419 => Loss: 45.58771809387783946477\n",
      "Iteration 37420 => Loss: 45.58756075270526508803\n",
      "Iteration 37421 => Loss: 45.58740341276747187749\n",
      "Iteration 37422 => Loss: 45.58724607406448825486\n",
      "Iteration 37423 => Loss: 45.58708873659629290387\n",
      "Iteration 37424 => Loss: 45.58693140036288582451\n",
      "Iteration 37425 => Loss: 45.58677406536421727878\n",
      "Iteration 37426 => Loss: 45.58661673160032989927\n",
      "Iteration 37427 => Loss: 45.58645939907118815881\n",
      "Iteration 37428 => Loss: 45.58630206777675653029\n",
      "Iteration 37429 => Loss: 45.58614473771709185712\n",
      "Iteration 37430 => Loss: 45.58598740889211597960\n",
      "Iteration 37431 => Loss: 45.58583008130185021400\n",
      "Iteration 37432 => Loss: 45.58567275494630166577\n",
      "Iteration 37433 => Loss: 45.58551542982542059690\n",
      "Iteration 37434 => Loss: 45.58535810593924963996\n",
      "Iteration 37435 => Loss: 45.58520078328771774068\n",
      "Iteration 37436 => Loss: 45.58504346187084621533\n",
      "Iteration 37437 => Loss: 45.58488614168864216936\n",
      "Iteration 37438 => Loss: 45.58472882274107007561\n",
      "Iteration 37439 => Loss: 45.58457150502812282866\n",
      "Iteration 37440 => Loss: 45.58441418854981463937\n",
      "Iteration 37441 => Loss: 45.58425687330608866432\n",
      "Iteration 37442 => Loss: 45.58409955929698753607\n",
      "Iteration 37443 => Loss: 45.58394224652246862206\n",
      "Iteration 37444 => Loss: 45.58378493498254613314\n",
      "Iteration 37445 => Loss: 45.58362762467718454218\n",
      "Iteration 37446 => Loss: 45.58347031560637674374\n",
      "Iteration 37447 => Loss: 45.58331300777013694869\n",
      "Iteration 37448 => Loss: 45.58315570116845805160\n",
      "Iteration 37449 => Loss: 45.58299839580127610361\n",
      "Iteration 37450 => Loss: 45.58284109166864084273\n",
      "Iteration 37451 => Loss: 45.58268378877050963638\n",
      "Iteration 37452 => Loss: 45.58252648710688959000\n",
      "Iteration 37453 => Loss: 45.58236918667776649272\n",
      "Iteration 37454 => Loss: 45.58221188748313323913\n",
      "Iteration 37455 => Loss: 45.58205458952296140751\n",
      "Iteration 37456 => Loss: 45.58189729279727231415\n",
      "Iteration 37457 => Loss: 45.58173999730601622105\n",
      "Iteration 37458 => Loss: 45.58158270304922154992\n",
      "Iteration 37459 => Loss: 45.58142541002687408991\n",
      "Iteration 37460 => Loss: 45.58126811823893831388\n",
      "Iteration 37461 => Loss: 45.58111082768542132726\n",
      "Iteration 37462 => Loss: 45.58095353836631602462\n",
      "Iteration 37463 => Loss: 45.58079625028160819511\n",
      "Iteration 37464 => Loss: 45.58063896343128362787\n",
      "Iteration 37465 => Loss: 45.58048167781534232290\n",
      "Iteration 37466 => Loss: 45.58032439343378428021\n",
      "Iteration 37467 => Loss: 45.58016711028655976179\n",
      "Iteration 37468 => Loss: 45.58000982837371140022\n",
      "Iteration 37469 => Loss: 45.57985254769518945750\n",
      "Iteration 37470 => Loss: 45.57969526825100103906\n",
      "Iteration 37471 => Loss: 45.57953799004113193405\n",
      "Iteration 37472 => Loss: 45.57938071306556082618\n",
      "Iteration 37473 => Loss: 45.57922343732430192631\n",
      "Iteration 37474 => Loss: 45.57906616281734102358\n",
      "Iteration 37475 => Loss: 45.57890888954465680172\n",
      "Iteration 37476 => Loss: 45.57875161750623504986\n",
      "Iteration 37477 => Loss: 45.57859434670208997886\n",
      "Iteration 37478 => Loss: 45.57843707713218606159\n",
      "Iteration 37479 => Loss: 45.57827980879654461432\n",
      "Iteration 37480 => Loss: 45.57812254169511589907\n",
      "Iteration 37481 => Loss: 45.57796527582793544298\n",
      "Iteration 37482 => Loss: 45.57780801119494640261\n",
      "Iteration 37483 => Loss: 45.57765074779617719969\n",
      "Iteration 37484 => Loss: 45.57749348563159230707\n",
      "Iteration 37485 => Loss: 45.57733622470119172476\n",
      "Iteration 37486 => Loss: 45.57717896500496834733\n",
      "Iteration 37487 => Loss: 45.57702170654291506935\n",
      "Iteration 37488 => Loss: 45.57686444931502478539\n",
      "Iteration 37489 => Loss: 45.57670719332127617918\n",
      "Iteration 37490 => Loss: 45.57654993856166214528\n",
      "Iteration 37491 => Loss: 45.57639268503616847283\n",
      "Iteration 37492 => Loss: 45.57623543274478095100\n",
      "Iteration 37493 => Loss: 45.57607818168753510690\n",
      "Iteration 37494 => Loss: 45.57592093186437409713\n",
      "Iteration 37495 => Loss: 45.57576368327529081625\n",
      "Iteration 37496 => Loss: 45.57560643592029947513\n",
      "Iteration 37497 => Loss: 45.57544918979936454662\n",
      "Iteration 37498 => Loss: 45.57529194491248603072\n",
      "Iteration 37499 => Loss: 45.57513470125967103286\n",
      "Iteration 37500 => Loss: 45.57497745884089113133\n",
      "Iteration 37501 => Loss: 45.57482021765613922071\n",
      "Iteration 37502 => Loss: 45.57466297770540819556\n",
      "Iteration 37503 => Loss: 45.57450573898869805589\n",
      "Iteration 37504 => Loss: 45.57434850150598748542\n",
      "Iteration 37505 => Loss: 45.57419126525725516785\n",
      "Iteration 37506 => Loss: 45.57403403024250820863\n",
      "Iteration 37507 => Loss: 45.57387679646171818604\n",
      "Iteration 37508 => Loss: 45.57371956391492773264\n",
      "Iteration 37509 => Loss: 45.57356233260206579416\n",
      "Iteration 37510 => Loss: 45.57340510252313947603\n",
      "Iteration 37511 => Loss: 45.57324787367818430539\n",
      "Iteration 37512 => Loss: 45.57309064606711501710\n",
      "Iteration 37513 => Loss: 45.57293341968996713831\n",
      "Iteration 37514 => Loss: 45.57277619454672645816\n",
      "Iteration 37515 => Loss: 45.57261897063738587121\n",
      "Iteration 37516 => Loss: 45.57246174796192406120\n",
      "Iteration 37517 => Loss: 45.57230452652034813354\n",
      "Iteration 37518 => Loss: 45.57214730631261545568\n",
      "Iteration 37519 => Loss: 45.57199008733876155475\n",
      "Iteration 37520 => Loss: 45.57183286959874379818\n",
      "Iteration 37521 => Loss: 45.57167565309256218598\n",
      "Iteration 37522 => Loss: 45.57151843782020250728\n",
      "Iteration 37523 => Loss: 45.57136122378166476210\n",
      "Iteration 37524 => Loss: 45.57120401097696316128\n",
      "Iteration 37525 => Loss: 45.57104679940602665056\n",
      "Iteration 37526 => Loss: 45.57088958906888365163\n",
      "Iteration 37527 => Loss: 45.57073237996550574280\n",
      "Iteration 37528 => Loss: 45.57057517209591424034\n",
      "Iteration 37529 => Loss: 45.57041796546008072255\n",
      "Iteration 37530 => Loss: 45.57026076005799808399\n",
      "Iteration 37531 => Loss: 45.57010355588964500839\n",
      "Iteration 37532 => Loss: 45.56994635295503570660\n",
      "Iteration 37533 => Loss: 45.56978915125412754605\n",
      "Iteration 37534 => Loss: 45.56963195078694894846\n",
      "Iteration 37535 => Loss: 45.56947475155345728126\n",
      "Iteration 37536 => Loss: 45.56931755355366675531\n",
      "Iteration 37537 => Loss: 45.56916035678756315974\n",
      "Iteration 37538 => Loss: 45.56900316125513228371\n",
      "Iteration 37539 => Loss: 45.56884596695634570551\n",
      "Iteration 37540 => Loss: 45.56868877389123184685\n",
      "Iteration 37541 => Loss: 45.56853158205973386430\n",
      "Iteration 37542 => Loss: 45.56837439146187307415\n",
      "Iteration 37543 => Loss: 45.56821720209766368725\n",
      "Iteration 37544 => Loss: 45.56806001396704175477\n",
      "Iteration 37545 => Loss: 45.56790282707003569840\n",
      "Iteration 37546 => Loss: 45.56774564140663130729\n",
      "Iteration 37547 => Loss: 45.56758845697679305431\n",
      "Iteration 37548 => Loss: 45.56743127378055646659\n",
      "Iteration 37549 => Loss: 45.56727409181785759529\n",
      "Iteration 37550 => Loss: 45.56711691108873907297\n",
      "Iteration 37551 => Loss: 45.56695973159312273992\n",
      "Iteration 37552 => Loss: 45.56680255333108675586\n",
      "Iteration 37553 => Loss: 45.56664537630257427736\n",
      "Iteration 37554 => Loss: 45.56648820050757109357\n",
      "Iteration 37555 => Loss: 45.56633102594606299363\n",
      "Iteration 37556 => Loss: 45.56617385261807129382\n",
      "Iteration 37557 => Loss: 45.56601668052355336158\n",
      "Iteration 37558 => Loss: 45.56585950966250919691\n",
      "Iteration 37559 => Loss: 45.56570234003494590524\n",
      "Iteration 37560 => Loss: 45.56554517164084217029\n",
      "Iteration 37561 => Loss: 45.56538800448018378120\n",
      "Iteration 37562 => Loss: 45.56523083855297784339\n",
      "Iteration 37563 => Loss: 45.56507367385917461888\n",
      "Iteration 37564 => Loss: 45.56491651039881674023\n",
      "Iteration 37565 => Loss: 45.56475934817184736403\n",
      "Iteration 37566 => Loss: 45.56460218717830912283\n",
      "Iteration 37567 => Loss: 45.56444502741813806779\n",
      "Iteration 37568 => Loss: 45.56428786889135551519\n",
      "Iteration 37569 => Loss: 45.56413071159793304332\n",
      "Iteration 37570 => Loss: 45.56397355553789196847\n",
      "Iteration 37571 => Loss: 45.56381640071118965807\n",
      "Iteration 37572 => Loss: 45.56365924711783321754\n",
      "Iteration 37573 => Loss: 45.56350209475780843604\n",
      "Iteration 37574 => Loss: 45.56334494363110820814\n",
      "Iteration 37575 => Loss: 45.56318779373773963925\n",
      "Iteration 37576 => Loss: 45.56303064507765299140\n",
      "Iteration 37577 => Loss: 45.56287349765088379172\n",
      "Iteration 37578 => Loss: 45.56271635145736809136\n",
      "Iteration 37579 => Loss: 45.56255920649714852289\n",
      "Iteration 37580 => Loss: 45.56240206277017534831\n",
      "Iteration 37581 => Loss: 45.56224492027647698933\n",
      "Iteration 37582 => Loss: 45.56208777901601791882\n",
      "Iteration 37583 => Loss: 45.56193063898879813678\n",
      "Iteration 37584 => Loss: 45.56177350019480343235\n",
      "Iteration 37585 => Loss: 45.56161636263402670011\n",
      "Iteration 37586 => Loss: 45.56145922630645372919\n",
      "Iteration 37587 => Loss: 45.56130209121207030876\n",
      "Iteration 37588 => Loss: 45.56114495735089064965\n",
      "Iteration 37589 => Loss: 45.56098782472288633016\n",
      "Iteration 37590 => Loss: 45.56083069332804313945\n",
      "Iteration 37591 => Loss: 45.56067356316636107749\n",
      "Iteration 37592 => Loss: 45.56051643423784014431\n",
      "Iteration 37593 => Loss: 45.56035930654244481275\n",
      "Iteration 37594 => Loss: 45.56020218008017508282\n",
      "Iteration 37595 => Loss: 45.56004505485104516538\n",
      "Iteration 37596 => Loss: 45.55988793085500532243\n",
      "Iteration 37597 => Loss: 45.55973080809206976483\n",
      "Iteration 37598 => Loss: 45.55957368656223138714\n",
      "Iteration 37599 => Loss: 45.55941656626549729481\n",
      "Iteration 37600 => Loss: 45.55925944720180353897\n",
      "Iteration 37601 => Loss: 45.55910232937117143592\n",
      "Iteration 37602 => Loss: 45.55894521277359388023\n",
      "Iteration 37603 => Loss: 45.55878809740907797732\n",
      "Iteration 37604 => Loss: 45.55863098327758820005\n",
      "Iteration 37605 => Loss: 45.55847387037911033758\n",
      "Iteration 37606 => Loss: 45.55831675871365149533\n",
      "Iteration 37607 => Loss: 45.55815964828118325158\n",
      "Iteration 37608 => Loss: 45.55800253908173402806\n",
      "Iteration 37609 => Loss: 45.55784543111526119219\n",
      "Iteration 37610 => Loss: 45.55768832438176474398\n",
      "Iteration 37611 => Loss: 45.55753121888123047256\n",
      "Iteration 37612 => Loss: 45.55737411461367258880\n",
      "Iteration 37613 => Loss: 45.55721701157902714385\n",
      "Iteration 37614 => Loss: 45.55705990977732966485\n",
      "Iteration 37615 => Loss: 45.55690280920855173008\n",
      "Iteration 37616 => Loss: 45.55674570987270044498\n",
      "Iteration 37617 => Loss: 45.55658861176974738783\n",
      "Iteration 37618 => Loss: 45.55643151489970676948\n",
      "Iteration 37619 => Loss: 45.55627441926255727367\n",
      "Iteration 37620 => Loss: 45.55611732485827047867\n",
      "Iteration 37621 => Loss: 45.55596023168686059535\n",
      "Iteration 37622 => Loss: 45.55580313974831341284\n",
      "Iteration 37623 => Loss: 45.55564604904260050944\n",
      "Iteration 37624 => Loss: 45.55548895956974320143\n",
      "Iteration 37625 => Loss: 45.55533187132969175082\n",
      "Iteration 37626 => Loss: 45.55517478432248879017\n",
      "Iteration 37627 => Loss: 45.55501769854807747606\n",
      "Iteration 37628 => Loss: 45.55486061400647201935\n",
      "Iteration 37629 => Loss: 45.55470353069766531462\n",
      "Iteration 37630 => Loss: 45.55454644862162894015\n",
      "Iteration 37631 => Loss: 45.55438936777838421222\n",
      "Iteration 37632 => Loss: 45.55423228816788139284\n",
      "Iteration 37633 => Loss: 45.55407520979014179829\n",
      "Iteration 37634 => Loss: 45.55391813264514411230\n",
      "Iteration 37635 => Loss: 45.55376105673287412401\n",
      "Iteration 37636 => Loss: 45.55360398205333183341\n",
      "Iteration 37637 => Loss: 45.55344690860649592423\n",
      "Iteration 37638 => Loss: 45.55328983639235929104\n",
      "Iteration 37639 => Loss: 45.55313276541093614469\n",
      "Iteration 37640 => Loss: 45.55297569566217674719\n",
      "Iteration 37641 => Loss: 45.55281862714611662568\n",
      "Iteration 37642 => Loss: 45.55266155986270604217\n",
      "Iteration 37643 => Loss: 45.55250449381195920751\n",
      "Iteration 37644 => Loss: 45.55234742899384059456\n",
      "Iteration 37645 => Loss: 45.55219036540837862503\n",
      "Iteration 37646 => Loss: 45.55203330305554487722\n",
      "Iteration 37647 => Loss: 45.55187624193531092942\n",
      "Iteration 37648 => Loss: 45.55171918204770520333\n",
      "Iteration 37649 => Loss: 45.55156212339267085554\n",
      "Iteration 37650 => Loss: 45.55140506597022920232\n",
      "Iteration 37651 => Loss: 45.55124800978039445454\n",
      "Iteration 37652 => Loss: 45.55109095482312397962\n",
      "Iteration 37653 => Loss: 45.55093390109838225044\n",
      "Iteration 37654 => Loss: 45.55077684860620479412\n",
      "Iteration 37655 => Loss: 45.55061979734657029439\n",
      "Iteration 37656 => Loss: 45.55046274731945743497\n",
      "Iteration 37657 => Loss: 45.55030569852488042670\n",
      "Iteration 37658 => Loss: 45.55014865096280374246\n",
      "Iteration 37659 => Loss: 45.54999160463321317138\n",
      "Iteration 37660 => Loss: 45.54983455953613713518\n",
      "Iteration 37661 => Loss: 45.54967751567154721215\n",
      "Iteration 37662 => Loss: 45.54952047303940076972\n",
      "Iteration 37663 => Loss: 45.54936343163975465131\n",
      "Iteration 37664 => Loss: 45.54920639147253069723\n",
      "Iteration 37665 => Loss: 45.54904935253776443460\n",
      "Iteration 37666 => Loss: 45.54889231483543454715\n",
      "Iteration 37667 => Loss: 45.54873527836550550774\n",
      "Iteration 37668 => Loss: 45.54857824312799863264\n",
      "Iteration 37669 => Loss: 45.54842120912291392187\n",
      "Iteration 37670 => Loss: 45.54826417635020874286\n",
      "Iteration 37671 => Loss: 45.54810714480989020103\n",
      "Iteration 37672 => Loss: 45.54795011450194408553\n",
      "Iteration 37673 => Loss: 45.54779308542637039636\n",
      "Iteration 37674 => Loss: 45.54763605758315492267\n",
      "Iteration 37675 => Loss: 45.54747903097226924274\n",
      "Iteration 37676 => Loss: 45.54732200559374888371\n",
      "Iteration 37677 => Loss: 45.54716498144752989674\n",
      "Iteration 37678 => Loss: 45.54700795853363359811\n",
      "Iteration 37679 => Loss: 45.54685093685205288239\n",
      "Iteration 37680 => Loss: 45.54669391640277353872\n",
      "Iteration 37681 => Loss: 45.54653689718576003997\n",
      "Iteration 37682 => Loss: 45.54637987920105501871\n",
      "Iteration 37683 => Loss: 45.54622286244858742066\n",
      "Iteration 37684 => Loss: 45.54606584692839277295\n",
      "Iteration 37685 => Loss: 45.54590883264045686474\n",
      "Iteration 37686 => Loss: 45.54575181958475837973\n",
      "Iteration 37687 => Loss: 45.54559480776128310708\n",
      "Iteration 37688 => Loss: 45.54543779717004525764\n",
      "Iteration 37689 => Loss: 45.54528078781098088257\n",
      "Iteration 37690 => Loss: 45.54512377968415393070\n",
      "Iteration 37691 => Loss: 45.54496677278948624235\n",
      "Iteration 37692 => Loss: 45.54480976712702045006\n",
      "Iteration 37693 => Loss: 45.54465276269672813214\n",
      "Iteration 37694 => Loss: 45.54449575949860218316\n",
      "Iteration 37695 => Loss: 45.54433875753262839225\n",
      "Iteration 37696 => Loss: 45.54418175679877833772\n",
      "Iteration 37697 => Loss: 45.54402475729706623042\n",
      "Iteration 37698 => Loss: 45.54386775902748496492\n",
      "Iteration 37699 => Loss: 45.54371076199002743579\n",
      "Iteration 37700 => Loss: 45.54355376618466522132\n",
      "Iteration 37701 => Loss: 45.54339677161140542694\n",
      "Iteration 37702 => Loss: 45.54323977827021963094\n",
      "Iteration 37703 => Loss: 45.54308278616112914960\n",
      "Iteration 37704 => Loss: 45.54292579528406292866\n",
      "Iteration 37705 => Loss: 45.54276880563909202237\n",
      "Iteration 37706 => Loss: 45.54261181722615958734\n",
      "Iteration 37707 => Loss: 45.54245483004526562354\n",
      "Iteration 37708 => Loss: 45.54229784409638881471\n",
      "Iteration 37709 => Loss: 45.54214085937953626626\n",
      "Iteration 37710 => Loss: 45.54198387589467245107\n",
      "Iteration 37711 => Loss: 45.54182689364182579084\n",
      "Iteration 37712 => Loss: 45.54166991262096786386\n",
      "Iteration 37713 => Loss: 45.54151293283208445928\n",
      "Iteration 37714 => Loss: 45.54135595427516847167\n",
      "Iteration 37715 => Loss: 45.54119897695021279560\n",
      "Iteration 37716 => Loss: 45.54104200085721743108\n",
      "Iteration 37717 => Loss: 45.54088502599614685096\n",
      "Iteration 37718 => Loss: 45.54072805236703658238\n",
      "Iteration 37719 => Loss: 45.54057107996980136022\n",
      "Iteration 37720 => Loss: 45.54041410880450513332\n",
      "Iteration 37721 => Loss: 45.54025713887110526912\n",
      "Iteration 37722 => Loss: 45.54010017016960176761\n",
      "Iteration 37723 => Loss: 45.53994320269995199624\n",
      "Iteration 37724 => Loss: 45.53978623646220569299\n",
      "Iteration 37725 => Loss: 45.53962927145632733072\n",
      "Iteration 37726 => Loss: 45.53947230768227427689\n",
      "Iteration 37727 => Loss: 45.53931534514007495318\n",
      "Iteration 37728 => Loss: 45.53915838382973646503\n",
      "Iteration 37729 => Loss: 45.53900142375119486360\n",
      "Iteration 37730 => Loss: 45.53884446490446435973\n",
      "Iteration 37731 => Loss: 45.53868750728954495344\n",
      "Iteration 37732 => Loss: 45.53853055090643664471\n",
      "Iteration 37733 => Loss: 45.53837359575508969556\n",
      "Iteration 37734 => Loss: 45.53821664183552542227\n",
      "Iteration 37735 => Loss: 45.53805968914773671941\n",
      "Iteration 37736 => Loss: 45.53790273769170937612\n",
      "Iteration 37737 => Loss: 45.53774578746742207613\n",
      "Iteration 37738 => Loss: 45.53758883847483929230\n",
      "Iteration 37739 => Loss: 45.53743189071401786805\n",
      "Iteration 37740 => Loss: 45.53727494418491517081\n",
      "Iteration 37741 => Loss: 45.53711799888751698973\n",
      "Iteration 37742 => Loss: 45.53696105482180200852\n",
      "Iteration 37743 => Loss: 45.53680411198777733262\n",
      "Iteration 37744 => Loss: 45.53664717038545006744\n",
      "Iteration 37745 => Loss: 45.53649023001479179129\n",
      "Iteration 37746 => Loss: 45.53633329087576697702\n",
      "Iteration 37747 => Loss: 45.53617635296841825721\n",
      "Iteration 37748 => Loss: 45.53601941629271010470\n",
      "Iteration 37749 => Loss: 45.53586248084862120322\n",
      "Iteration 37750 => Loss: 45.53570554663617997448\n",
      "Iteration 37751 => Loss: 45.53554861365530825879\n",
      "Iteration 37752 => Loss: 45.53539168190606289954\n",
      "Iteration 37753 => Loss: 45.53523475138839415877\n",
      "Iteration 37754 => Loss: 45.53507782210231624731\n",
      "Iteration 37755 => Loss: 45.53492089404782205975\n",
      "Iteration 37756 => Loss: 45.53476396722488317437\n",
      "Iteration 37757 => Loss: 45.53460704163347827489\n",
      "Iteration 37758 => Loss: 45.53445011727364999388\n",
      "Iteration 37759 => Loss: 45.53429319414534148791\n",
      "Iteration 37760 => Loss: 45.53413627224855986242\n",
      "Iteration 37761 => Loss: 45.53397935158328380112\n",
      "Iteration 37762 => Loss: 45.53382243214950619858\n",
      "Iteration 37763 => Loss: 45.53366551394726258195\n",
      "Iteration 37764 => Loss: 45.53350859697645347524\n",
      "Iteration 37765 => Loss: 45.53335168123715703814\n",
      "Iteration 37766 => Loss: 45.53319476672931642725\n",
      "Iteration 37767 => Loss: 45.53303785345293164255\n",
      "Iteration 37768 => Loss: 45.53288094140799557863\n",
      "Iteration 37769 => Loss: 45.53272403059448691920\n",
      "Iteration 37770 => Loss: 45.53256712101241987511\n",
      "Iteration 37771 => Loss: 45.53241021266175891924\n",
      "Iteration 37772 => Loss: 45.53225330554253247328\n",
      "Iteration 37773 => Loss: 45.53209639965469079925\n",
      "Iteration 37774 => Loss: 45.53193949499821968629\n",
      "Iteration 37775 => Loss: 45.53178259157314045069\n",
      "Iteration 37776 => Loss: 45.53162568937942467073\n",
      "Iteration 37777 => Loss: 45.53146878841708655727\n",
      "Iteration 37778 => Loss: 45.53131188868609058318\n",
      "Iteration 37779 => Loss: 45.53115499018642253759\n",
      "Iteration 37780 => Loss: 45.53099809291810373679\n",
      "Iteration 37781 => Loss: 45.53084119688111286450\n",
      "Iteration 37782 => Loss: 45.53068430207541439358\n",
      "Iteration 37783 => Loss: 45.53052740850102964032\n",
      "Iteration 37784 => Loss: 45.53037051615793018300\n",
      "Iteration 37785 => Loss: 45.53021362504611602162\n",
      "Iteration 37786 => Loss: 45.53005673516556583991\n",
      "Iteration 37787 => Loss: 45.52989984651630095414\n",
      "Iteration 37788 => Loss: 45.52974295909828583717\n",
      "Iteration 37789 => Loss: 45.52958607291148496188\n",
      "Iteration 37790 => Loss: 45.52942918795593385539\n",
      "Iteration 37791 => Loss: 45.52927230423162541229\n",
      "Iteration 37792 => Loss: 45.52911542173852410542\n",
      "Iteration 37793 => Loss: 45.52895854047661572395\n",
      "Iteration 37794 => Loss: 45.52880166044592868957\n",
      "Iteration 37795 => Loss: 45.52864478164639905344\n",
      "Iteration 37796 => Loss: 45.52848790407805523728\n",
      "Iteration 37797 => Loss: 45.52833102774088303022\n",
      "Iteration 37798 => Loss: 45.52817415263485401056\n",
      "Iteration 37799 => Loss: 45.52801727875999660000\n",
      "Iteration 37800 => Loss: 45.52786040611626816599\n",
      "Iteration 37801 => Loss: 45.52770353470366160309\n",
      "Iteration 37802 => Loss: 45.52754666452217691130\n",
      "Iteration 37803 => Loss: 45.52738979557179987978\n",
      "Iteration 37804 => Loss: 45.52723292785251629766\n",
      "Iteration 37805 => Loss: 45.52707606136434037580\n",
      "Iteration 37806 => Loss: 45.52691919610723658707\n",
      "Iteration 37807 => Loss: 45.52676233208121914231\n",
      "Iteration 37808 => Loss: 45.52660546928621698726\n",
      "Iteration 37809 => Loss: 45.52644860772229407075\n",
      "Iteration 37810 => Loss: 45.52629174738940065481\n",
      "Iteration 37811 => Loss: 45.52613488828756516114\n",
      "Iteration 37812 => Loss: 45.52597803041672364088\n",
      "Iteration 37813 => Loss: 45.52582117377690451576\n",
      "Iteration 37814 => Loss: 45.52566431836808646949\n",
      "Iteration 37815 => Loss: 45.52550746419026950207\n",
      "Iteration 37816 => Loss: 45.52535061124342519179\n",
      "Iteration 37817 => Loss: 45.52519375952756774950\n",
      "Iteration 37818 => Loss: 45.52503690904266875350\n",
      "Iteration 37819 => Loss: 45.52488005978872109836\n",
      "Iteration 37820 => Loss: 45.52472321176571767865\n",
      "Iteration 37821 => Loss: 45.52456636497364428351\n",
      "Iteration 37822 => Loss: 45.52440951941250091295\n",
      "Iteration 37823 => Loss: 45.52425267508229467239\n",
      "Iteration 37824 => Loss: 45.52409583198297582385\n",
      "Iteration 37825 => Loss: 45.52393899011453015646\n",
      "Iteration 37826 => Loss: 45.52378214947698609194\n",
      "Iteration 37827 => Loss: 45.52362531007032941943\n",
      "Iteration 37828 => Loss: 45.52346847189453882265\n",
      "Iteration 37829 => Loss: 45.52331163494962140703\n",
      "Iteration 37830 => Loss: 45.52315479923553454000\n",
      "Iteration 37831 => Loss: 45.52299796475228532699\n",
      "Iteration 37832 => Loss: 45.52284113149985245173\n",
      "Iteration 37833 => Loss: 45.52268429947825723048\n",
      "Iteration 37834 => Loss: 45.52252746868745703068\n",
      "Iteration 37835 => Loss: 45.52237063912748027406\n",
      "Iteration 37836 => Loss: 45.52221381079827722260\n",
      "Iteration 37837 => Loss: 45.52205698369984787632\n",
      "Iteration 37838 => Loss: 45.52190015783220644607\n",
      "Iteration 37839 => Loss: 45.52174333319532451014\n",
      "Iteration 37840 => Loss: 45.52158650978917364682\n",
      "Iteration 37841 => Loss: 45.52142968761378227782\n",
      "Iteration 37842 => Loss: 45.52127286666912198143\n",
      "Iteration 37843 => Loss: 45.52111604695517854680\n",
      "Iteration 37844 => Loss: 45.52095922847194486849\n",
      "Iteration 37845 => Loss: 45.52080241121942805194\n",
      "Iteration 37846 => Loss: 45.52064559519759257000\n",
      "Iteration 37847 => Loss: 45.52048878040644552812\n",
      "Iteration 37848 => Loss: 45.52033196684599403170\n",
      "Iteration 37849 => Loss: 45.52017515451615992106\n",
      "Iteration 37850 => Loss: 45.52001834341702846132\n",
      "Iteration 37851 => Loss: 45.51986153354850017649\n",
      "Iteration 37852 => Loss: 45.51970472491065322629\n",
      "Iteration 37853 => Loss: 45.51954791750338102929\n",
      "Iteration 37854 => Loss: 45.51939111132676885063\n",
      "Iteration 37855 => Loss: 45.51923430638074563603\n",
      "Iteration 37856 => Loss: 45.51907750266531138550\n",
      "Iteration 37857 => Loss: 45.51892070018046609903\n",
      "Iteration 37858 => Loss: 45.51876389892620977662\n",
      "Iteration 37859 => Loss: 45.51860709890251399656\n",
      "Iteration 37860 => Loss: 45.51845030010937875886\n",
      "Iteration 37861 => Loss: 45.51829350254678274723\n",
      "Iteration 37862 => Loss: 45.51813670621473306710\n",
      "Iteration 37863 => Loss: 45.51797991111322261304\n",
      "Iteration 37864 => Loss: 45.51782311724222296334\n",
      "Iteration 37865 => Loss: 45.51766632460172701258\n",
      "Iteration 37866 => Loss: 45.51750953319174186618\n",
      "Iteration 37867 => Loss: 45.51735274301226041871\n",
      "Iteration 37868 => Loss: 45.51719595406322582676\n",
      "Iteration 37869 => Loss: 45.51703916634468782831\n",
      "Iteration 37870 => Loss: 45.51688237985659668539\n",
      "Iteration 37871 => Loss: 45.51672559459896660883\n",
      "Iteration 37872 => Loss: 45.51656881057177628236\n",
      "Iteration 37873 => Loss: 45.51641202777503991683\n",
      "Iteration 37874 => Loss: 45.51625524620869356340\n",
      "Iteration 37875 => Loss: 45.51609846587277985464\n",
      "Iteration 37876 => Loss: 45.51594168676725615796\n",
      "Iteration 37877 => Loss: 45.51578490889214378967\n",
      "Iteration 37878 => Loss: 45.51562813224739301177\n",
      "Iteration 37879 => Loss: 45.51547135683303935139\n",
      "Iteration 37880 => Loss: 45.51531458264903307054\n",
      "Iteration 37881 => Loss: 45.51515780969540259093\n",
      "Iteration 37882 => Loss: 45.51500103797210528001\n",
      "Iteration 37883 => Loss: 45.51484426747914113776\n",
      "Iteration 37884 => Loss: 45.51468749821651016418\n",
      "Iteration 37885 => Loss: 45.51453073018421235929\n",
      "Iteration 37886 => Loss: 45.51437396338219798508\n",
      "Iteration 37887 => Loss: 45.51421719781047414699\n",
      "Iteration 37888 => Loss: 45.51406043346904084501\n",
      "Iteration 37889 => Loss: 45.51390367035789097372\n",
      "Iteration 37890 => Loss: 45.51374690847703163854\n",
      "Iteration 37891 => Loss: 45.51359014782640599606\n",
      "Iteration 37892 => Loss: 45.51343338840604246798\n",
      "Iteration 37893 => Loss: 45.51327663021591973802\n",
      "Iteration 37894 => Loss: 45.51311987325600227905\n",
      "Iteration 37895 => Loss: 45.51296311752634693448\n",
      "Iteration 37896 => Loss: 45.51280636302687554462\n",
      "Iteration 37897 => Loss: 45.51264960975759521489\n",
      "Iteration 37898 => Loss: 45.51249285771853436700\n",
      "Iteration 37899 => Loss: 45.51233610690965747381\n",
      "Iteration 37900 => Loss: 45.51217935733090769190\n",
      "Iteration 37901 => Loss: 45.51202260898235607556\n",
      "Iteration 37902 => Loss: 45.51186586186394578135\n",
      "Iteration 37903 => Loss: 45.51170911597569102014\n",
      "Iteration 37904 => Loss: 45.51155237131755626478\n",
      "Iteration 37905 => Loss: 45.51139562788955572614\n",
      "Iteration 37906 => Loss: 45.51123888569166808793\n",
      "Iteration 37907 => Loss: 45.51108214472387913929\n",
      "Iteration 37908 => Loss: 45.51092540498618888023\n",
      "Iteration 37909 => Loss: 45.51076866647859731074\n",
      "Iteration 37910 => Loss: 45.51061192920104758741\n",
      "Iteration 37911 => Loss: 45.51045519315357523737\n",
      "Iteration 37912 => Loss: 45.51029845833617315520\n",
      "Iteration 37913 => Loss: 45.51014172474880581376\n",
      "Iteration 37914 => Loss: 45.50998499239148031847\n",
      "Iteration 37915 => Loss: 45.50982826126418956392\n",
      "Iteration 37916 => Loss: 45.50967153136690512838\n",
      "Iteration 37917 => Loss: 45.50951480269961990643\n",
      "Iteration 37918 => Loss: 45.50935807526235521436\n",
      "Iteration 37919 => Loss: 45.50920134905508263046\n",
      "Iteration 37920 => Loss: 45.50904462407775952215\n",
      "Iteration 37921 => Loss: 45.50888790033044273287\n",
      "Iteration 37922 => Loss: 45.50873117781306120833\n",
      "Iteration 37923 => Loss: 45.50857445652562205396\n",
      "Iteration 37924 => Loss: 45.50841773646813237519\n",
      "Iteration 37925 => Loss: 45.50826101764057796117\n",
      "Iteration 37926 => Loss: 45.50810430004293749562\n",
      "Iteration 37927 => Loss: 45.50794758367521808395\n",
      "Iteration 37928 => Loss: 45.50779086853740551533\n",
      "Iteration 37929 => Loss: 45.50763415462947136803\n",
      "Iteration 37930 => Loss: 45.50747744195142985291\n",
      "Iteration 37931 => Loss: 45.50732073050325254826\n",
      "Iteration 37932 => Loss: 45.50716402028496077037\n",
      "Iteration 37933 => Loss: 45.50700731129648346496\n",
      "Iteration 37934 => Loss: 45.50685060353786326459\n",
      "Iteration 37935 => Loss: 45.50669389700908595842\n",
      "Iteration 37936 => Loss: 45.50653719171013023015\n",
      "Iteration 37937 => Loss: 45.50638048764100318522\n",
      "Iteration 37938 => Loss: 45.50622378480165508563\n",
      "Iteration 37939 => Loss: 45.50606708319211435310\n",
      "Iteration 37940 => Loss: 45.50591038281236677676\n",
      "Iteration 37941 => Loss: 45.50575368366239104034\n",
      "Iteration 37942 => Loss: 45.50559698574218714384\n",
      "Iteration 37943 => Loss: 45.50544028905174087640\n",
      "Iteration 37944 => Loss: 45.50528359359100960546\n",
      "Iteration 37945 => Loss: 45.50512689936005727986\n",
      "Iteration 37946 => Loss: 45.50497020635881284534\n",
      "Iteration 37947 => Loss: 45.50481351458729051274\n",
      "Iteration 37948 => Loss: 45.50465682404548317663\n",
      "Iteration 37949 => Loss: 45.50450013473337662617\n",
      "Iteration 37950 => Loss: 45.50434344665094243965\n",
      "Iteration 37951 => Loss: 45.50418675979820193334\n",
      "Iteration 37952 => Loss: 45.50403007417511958010\n",
      "Iteration 37953 => Loss: 45.50387338978170248538\n",
      "Iteration 37954 => Loss: 45.50371670661794354373\n",
      "Iteration 37955 => Loss: 45.50356002468382854431\n",
      "Iteration 37956 => Loss: 45.50340334397933617083\n",
      "Iteration 37957 => Loss: 45.50324666450445931787\n",
      "Iteration 37958 => Loss: 45.50308998625921219627\n",
      "Iteration 37959 => Loss: 45.50293330924355217348\n",
      "Iteration 37960 => Loss: 45.50277663345749346036\n",
      "Iteration 37961 => Loss: 45.50261995890101474060\n",
      "Iteration 37962 => Loss: 45.50246328557410180338\n",
      "Iteration 37963 => Loss: 45.50230661347677596495\n",
      "Iteration 37964 => Loss: 45.50214994260898748735\n",
      "Iteration 37965 => Loss: 45.50199327297075768683\n",
      "Iteration 37966 => Loss: 45.50183660456204393085\n",
      "Iteration 37967 => Loss: 45.50167993738286753569\n",
      "Iteration 37968 => Loss: 45.50152327143319297420\n",
      "Iteration 37969 => Loss: 45.50136660671305577353\n",
      "Iteration 37970 => Loss: 45.50120994322238487939\n",
      "Iteration 37971 => Loss: 45.50105328096120160808\n",
      "Iteration 37972 => Loss: 45.50089661992949885416\n",
      "Iteration 37973 => Loss: 45.50073996012726951221\n",
      "Iteration 37974 => Loss: 45.50058330155449937138\n",
      "Iteration 37975 => Loss: 45.50042664421118843165\n",
      "Iteration 37976 => Loss: 45.50026998809729406048\n",
      "Iteration 37977 => Loss: 45.50011333321284467957\n",
      "Iteration 37978 => Loss: 45.49995667955780476177\n",
      "Iteration 37979 => Loss: 45.49980002713217430710\n",
      "Iteration 37980 => Loss: 45.49964337593595331555\n",
      "Iteration 37981 => Loss: 45.49948672596911336541\n",
      "Iteration 37982 => Loss: 45.49933007723164735125\n",
      "Iteration 37983 => Loss: 45.49917342972357658937\n",
      "Iteration 37984 => Loss: 45.49901678344484423633\n",
      "Iteration 37985 => Loss: 45.49886013839548581927\n",
      "Iteration 37986 => Loss: 45.49870349457543738936\n",
      "Iteration 37987 => Loss: 45.49854685198474157914\n",
      "Iteration 37988 => Loss: 45.49839021062336286150\n",
      "Iteration 37989 => Loss: 45.49823357049130123642\n",
      "Iteration 37990 => Loss: 45.49807693158853538762\n",
      "Iteration 37991 => Loss: 45.49792029391508663139\n",
      "Iteration 37992 => Loss: 45.49776365747091233516\n",
      "Iteration 37993 => Loss: 45.49760702225600539350\n",
      "Iteration 37994 => Loss: 45.49745038827035159557\n",
      "Iteration 37995 => Loss: 45.49729375551397936306\n",
      "Iteration 37996 => Loss: 45.49713712398682474713\n",
      "Iteration 37997 => Loss: 45.49698049368893748579\n",
      "Iteration 37998 => Loss: 45.49682386462025363016\n",
      "Iteration 37999 => Loss: 45.49666723678078739113\n",
      "Iteration 38000 => Loss: 45.49651061017053876867\n",
      "Iteration 38001 => Loss: 45.49635398478947934109\n",
      "Iteration 38002 => Loss: 45.49619736063760200295\n",
      "Iteration 38003 => Loss: 45.49604073771492096512\n",
      "Iteration 38004 => Loss: 45.49588411602139359502\n",
      "Iteration 38005 => Loss: 45.49572749555703410351\n",
      "Iteration 38006 => Loss: 45.49557087632182117432\n",
      "Iteration 38007 => Loss: 45.49541425831574059657\n",
      "Iteration 38008 => Loss: 45.49525764153880658114\n",
      "Iteration 38009 => Loss: 45.49510102599098360088\n",
      "Iteration 38010 => Loss: 45.49494441167226455036\n",
      "Iteration 38011 => Loss: 45.49478779858265653502\n",
      "Iteration 38012 => Loss: 45.49463118672213113314\n",
      "Iteration 38013 => Loss: 45.49447457609068834472\n",
      "Iteration 38014 => Loss: 45.49431796668832106434\n",
      "Iteration 38015 => Loss: 45.49416135851500797571\n",
      "Iteration 38016 => Loss: 45.49400475157075618426\n",
      "Iteration 38017 => Loss: 45.49384814585555147914\n",
      "Iteration 38018 => Loss: 45.49369154136937964950\n",
      "Iteration 38019 => Loss: 45.49353493811223358989\n",
      "Iteration 38020 => Loss: 45.49337833608407777319\n",
      "Iteration 38021 => Loss: 45.49322173528496193740\n",
      "Iteration 38022 => Loss: 45.49306513571481502822\n",
      "Iteration 38023 => Loss: 45.49290853737365125653\n",
      "Iteration 38024 => Loss: 45.49275194026147062232\n",
      "Iteration 38025 => Loss: 45.49259534437827312559\n",
      "Iteration 38026 => Loss: 45.49243874972400192291\n",
      "Iteration 38027 => Loss: 45.49228215629869254144\n",
      "Iteration 38028 => Loss: 45.49212556410233787574\n",
      "Iteration 38029 => Loss: 45.49196897313487397696\n",
      "Iteration 38030 => Loss: 45.49181238339635768853\n",
      "Iteration 38031 => Loss: 45.49165579488672506159\n",
      "Iteration 38032 => Loss: 45.49149920760599741243\n",
      "Iteration 38033 => Loss: 45.49134262155417474105\n",
      "Iteration 38034 => Loss: 45.49118603673122152031\n",
      "Iteration 38035 => Loss: 45.49102945313713064479\n",
      "Iteration 38036 => Loss: 45.49087287077191632534\n",
      "Iteration 38037 => Loss: 45.49071628963553592939\n",
      "Iteration 38038 => Loss: 45.49055970972800366781\n",
      "Iteration 38039 => Loss: 45.49040313104930532973\n",
      "Iteration 38040 => Loss: 45.49024655359940538801\n",
      "Iteration 38041 => Loss: 45.49008997737833936981\n",
      "Iteration 38042 => Loss: 45.48993340238607174797\n",
      "Iteration 38043 => Loss: 45.48977682862260252250\n",
      "Iteration 38044 => Loss: 45.48962025608791037712\n",
      "Iteration 38045 => Loss: 45.48946368478198820640\n",
      "Iteration 38046 => Loss: 45.48930711470484311576\n",
      "Iteration 38047 => Loss: 45.48915054585643957807\n",
      "Iteration 38048 => Loss: 45.48899397823675627706\n",
      "Iteration 38049 => Loss: 45.48883741184583584527\n",
      "Iteration 38050 => Loss: 45.48868084668364275558\n",
      "Iteration 38051 => Loss: 45.48852428275014858627\n",
      "Iteration 38052 => Loss: 45.48836772004538175906\n",
      "Iteration 38053 => Loss: 45.48821115856929964139\n",
      "Iteration 38054 => Loss: 45.48805459832188091696\n",
      "Iteration 38055 => Loss: 45.48789803930316111291\n",
      "Iteration 38056 => Loss: 45.48774148151312601840\n",
      "Iteration 38057 => Loss: 45.48758492495171879000\n",
      "Iteration 38058 => Loss: 45.48742836961896784942\n",
      "Iteration 38059 => Loss: 45.48727181551486609123\n",
      "Iteration 38060 => Loss: 45.48711526263937798831\n",
      "Iteration 38061 => Loss: 45.48695871099251775149\n",
      "Iteration 38062 => Loss: 45.48680216057426406451\n",
      "Iteration 38063 => Loss: 45.48664561138460982193\n",
      "Iteration 38064 => Loss: 45.48648906342354081289\n",
      "Iteration 38065 => Loss: 45.48633251669104993198\n",
      "Iteration 38066 => Loss: 45.48617597118714428461\n",
      "Iteration 38067 => Loss: 45.48601942691177413280\n",
      "Iteration 38068 => Loss: 45.48586288386498921454\n",
      "Iteration 38069 => Loss: 45.48570634204671847556\n",
      "Iteration 38070 => Loss: 45.48554980145699033756\n",
      "Iteration 38071 => Loss: 45.48539326209579058968\n",
      "Iteration 38072 => Loss: 45.48523672396308370480\n",
      "Iteration 38073 => Loss: 45.48508018705889810462\n",
      "Iteration 38074 => Loss: 45.48492365138320536744\n",
      "Iteration 38075 => Loss: 45.48476711693598417696\n",
      "Iteration 38076 => Loss: 45.48461058371724874405\n",
      "Iteration 38077 => Loss: 45.48445405172696354157\n",
      "Iteration 38078 => Loss: 45.48429752096514988580\n",
      "Iteration 38079 => Loss: 45.48414099143176514417\n",
      "Iteration 38080 => Loss: 45.48398446312683063297\n",
      "Iteration 38081 => Loss: 45.48382793605032503592\n",
      "Iteration 38082 => Loss: 45.48367141020222703673\n",
      "Iteration 38083 => Loss: 45.48351488558253663541\n",
      "Iteration 38084 => Loss: 45.48335836219124672652\n",
      "Iteration 38085 => Loss: 45.48320184002832888837\n",
      "Iteration 38086 => Loss: 45.48304531909381154264\n",
      "Iteration 38087 => Loss: 45.48288879938763784594\n",
      "Iteration 38088 => Loss: 45.48273228090982911453\n",
      "Iteration 38089 => Loss: 45.48257576366038534843\n",
      "Iteration 38090 => Loss: 45.48241924763924970421\n",
      "Iteration 38091 => Loss: 45.48226273284646481443\n",
      "Iteration 38092 => Loss: 45.48210621928200936281\n",
      "Iteration 38093 => Loss: 45.48194970694585492765\n",
      "Iteration 38094 => Loss: 45.48179319583800861437\n",
      "Iteration 38095 => Loss: 45.48163668595843489584\n",
      "Iteration 38096 => Loss: 45.48148017730715508833\n",
      "Iteration 38097 => Loss: 45.48132366988414787556\n",
      "Iteration 38098 => Loss: 45.48116716368939904669\n",
      "Iteration 38099 => Loss: 45.48101065872290149628\n",
      "Iteration 38100 => Loss: 45.48085415498466232975\n",
      "Iteration 38101 => Loss: 45.48069765247463891455\n",
      "Iteration 38102 => Loss: 45.48054115119284546154\n",
      "Iteration 38103 => Loss: 45.48038465113923223271\n",
      "Iteration 38104 => Loss: 45.48022815231386317691\n",
      "Iteration 38105 => Loss: 45.48007165471667434531\n",
      "Iteration 38106 => Loss: 45.47991515834767284332\n",
      "Iteration 38107 => Loss: 45.47975866320686577637\n",
      "Iteration 38108 => Loss: 45.47960216929418919563\n",
      "Iteration 38109 => Loss: 45.47944567660970704992\n",
      "Iteration 38110 => Loss: 45.47928918515334828498\n",
      "Iteration 38111 => Loss: 45.47913269492509868996\n",
      "Iteration 38112 => Loss: 45.47897620592501510828\n",
      "Iteration 38113 => Loss: 45.47881971815304069651\n",
      "Iteration 38114 => Loss: 45.47866323160918966551\n",
      "Iteration 38115 => Loss: 45.47850674629340517185\n",
      "Iteration 38116 => Loss: 45.47835026220572984812\n",
      "Iteration 38117 => Loss: 45.47819377934612816716\n",
      "Iteration 38118 => Loss: 45.47803729771459302356\n",
      "Iteration 38119 => Loss: 45.47788081731112441730\n",
      "Iteration 38120 => Loss: 45.47772433813568682126\n",
      "Iteration 38121 => Loss: 45.47756786018832286800\n",
      "Iteration 38122 => Loss: 45.47741138346896150324\n",
      "Iteration 38123 => Loss: 45.47725490797762404327\n",
      "Iteration 38124 => Loss: 45.47709843371433180437\n",
      "Iteration 38125 => Loss: 45.47694196067899241598\n",
      "Iteration 38126 => Loss: 45.47678548887168403780\n",
      "Iteration 38127 => Loss: 45.47662901829232140472\n",
      "Iteration 38128 => Loss: 45.47647254894096136013\n",
      "Iteration 38129 => Loss: 45.47631608081752574435\n",
      "Iteration 38130 => Loss: 45.47615961392209271708\n",
      "Iteration 38131 => Loss: 45.47600314825457701318\n",
      "Iteration 38132 => Loss: 45.47584668381499994894\n",
      "Iteration 38133 => Loss: 45.47569022060334020807\n",
      "Iteration 38134 => Loss: 45.47553375861959779058\n",
      "Iteration 38135 => Loss: 45.47537729786377980190\n",
      "Iteration 38136 => Loss: 45.47522083833584360946\n",
      "Iteration 38137 => Loss: 45.47506438003579631868\n",
      "Iteration 38138 => Loss: 45.47490792296362371872\n",
      "Iteration 38139 => Loss: 45.47475146711932580956\n",
      "Iteration 38140 => Loss: 45.47459501250286706409\n",
      "Iteration 38141 => Loss: 45.47443855911427590399\n",
      "Iteration 38142 => Loss: 45.47428210695352390758\n",
      "Iteration 38143 => Loss: 45.47412565602057554770\n",
      "Iteration 38144 => Loss: 45.47396920631546635150\n",
      "Iteration 38145 => Loss: 45.47381275783816079183\n",
      "Iteration 38146 => Loss: 45.47365631058863755243\n",
      "Iteration 38147 => Loss: 45.47349986456693216041\n",
      "Iteration 38148 => Loss: 45.47334341977300198323\n",
      "Iteration 38149 => Loss: 45.47318697620683991545\n",
      "Iteration 38150 => Loss: 45.47303053386843174621\n",
      "Iteration 38151 => Loss: 45.47287409275777037010\n",
      "Iteration 38152 => Loss: 45.47271765287485578710\n",
      "Iteration 38153 => Loss: 45.47256121421965247009\n",
      "Iteration 38154 => Loss: 45.47240477679220305163\n",
      "Iteration 38155 => Loss: 45.47224834059247200457\n",
      "Iteration 38156 => Loss: 45.47209190562042380179\n",
      "Iteration 38157 => Loss: 45.47193547187606554871\n",
      "Iteration 38158 => Loss: 45.47177903935940435076\n",
      "Iteration 38159 => Loss: 45.47162260807041889166\n",
      "Iteration 38160 => Loss: 45.47146617800909496054\n",
      "Iteration 38161 => Loss: 45.47130974917543255742\n",
      "Iteration 38162 => Loss: 45.47115332156940326058\n",
      "Iteration 38163 => Loss: 45.47099689519100707003\n",
      "Iteration 38164 => Loss: 45.47084047004022266947\n",
      "Iteration 38165 => Loss: 45.47068404611707848062\n",
      "Iteration 38166 => Loss: 45.47052762342154608177\n",
      "Iteration 38167 => Loss: 45.47037120195360415664\n",
      "Iteration 38168 => Loss: 45.47021478171325981066\n",
      "Iteration 38169 => Loss: 45.47005836270047751668\n",
      "Iteration 38170 => Loss: 45.46990194491525727472\n",
      "Iteration 38171 => Loss: 45.46974552835759197933\n",
      "Iteration 38172 => Loss: 45.46958911302750294681\n",
      "Iteration 38173 => Loss: 45.46943269892492622830\n",
      "Iteration 38174 => Loss: 45.46927628604989024552\n",
      "Iteration 38175 => Loss: 45.46911987440236657676\n",
      "Iteration 38176 => Loss: 45.46896346398237653830\n",
      "Iteration 38177 => Loss: 45.46880705478986328671\n",
      "Iteration 38178 => Loss: 45.46865064682485524372\n",
      "Iteration 38179 => Loss: 45.46849424008731688218\n",
      "Iteration 38180 => Loss: 45.46833783457725530752\n",
      "Iteration 38181 => Loss: 45.46818143029466341432\n",
      "Iteration 38182 => Loss: 45.46802502723951278085\n",
      "Iteration 38183 => Loss: 45.46786862541181051256\n",
      "Iteration 38184 => Loss: 45.46771222481154239858\n",
      "Iteration 38185 => Loss: 45.46755582543869422807\n",
      "Iteration 38186 => Loss: 45.46739942729325889559\n",
      "Iteration 38187 => Loss: 45.46724303037524350657\n",
      "Iteration 38188 => Loss: 45.46708663468459832302\n",
      "Iteration 38189 => Loss: 45.46693024022135176665\n",
      "Iteration 38190 => Loss: 45.46677384698548252118\n",
      "Iteration 38191 => Loss: 45.46661745497697637575\n",
      "Iteration 38192 => Loss: 45.46646106419583333036\n",
      "Iteration 38193 => Loss: 45.46630467464202496330\n",
      "Iteration 38194 => Loss: 45.46614828631556548544\n",
      "Iteration 38195 => Loss: 45.46599189921642647505\n",
      "Iteration 38196 => Loss: 45.46583551334460082671\n",
      "Iteration 38197 => Loss: 45.46567912870008143500\n",
      "Iteration 38198 => Loss: 45.46552274528288251076\n",
      "Iteration 38199 => Loss: 45.46536636309294010516\n",
      "Iteration 38200 => Loss: 45.46520998213030395618\n",
      "Iteration 38201 => Loss: 45.46505360239491722041\n",
      "Iteration 38202 => Loss: 45.46489722388680121412\n",
      "Iteration 38203 => Loss: 45.46474084660594883189\n",
      "Iteration 38204 => Loss: 45.46458447055232454659\n",
      "Iteration 38205 => Loss: 45.46442809572592835821\n",
      "Iteration 38206 => Loss: 45.46427172212675316132\n",
      "Iteration 38207 => Loss: 45.46411534975479185050\n",
      "Iteration 38208 => Loss: 45.46395897861003021490\n",
      "Iteration 38209 => Loss: 45.46380260869247535993\n",
      "Iteration 38210 => Loss: 45.46364624000208465304\n",
      "Iteration 38211 => Loss: 45.46348987253886519966\n",
      "Iteration 38212 => Loss: 45.46333350630280989435\n",
      "Iteration 38213 => Loss: 45.46317714129391873712\n",
      "Iteration 38214 => Loss: 45.46302077751218462254\n",
      "Iteration 38215 => Loss: 45.46286441495757202347\n",
      "Iteration 38216 => Loss: 45.46270805363007383448\n",
      "Iteration 38217 => Loss: 45.46255169352969716101\n",
      "Iteration 38218 => Loss: 45.46239533465644200305\n",
      "Iteration 38219 => Loss: 45.46223897701025862261\n",
      "Iteration 38220 => Loss: 45.46208262059116833598\n",
      "Iteration 38221 => Loss: 45.46192626539917114314\n",
      "Iteration 38222 => Loss: 45.46176991143423151698\n",
      "Iteration 38223 => Loss: 45.46161355869635656290\n",
      "Iteration 38224 => Loss: 45.46145720718550364836\n",
      "Iteration 38225 => Loss: 45.46130085690172251134\n",
      "Iteration 38226 => Loss: 45.46114450784494920299\n",
      "Iteration 38227 => Loss: 45.46098816001519793417\n",
      "Iteration 38228 => Loss: 45.46083181341246870488\n",
      "Iteration 38229 => Loss: 45.46067546803672598799\n",
      "Iteration 38230 => Loss: 45.46051912388797688891\n",
      "Iteration 38231 => Loss: 45.46036278096620719680\n",
      "Iteration 38232 => Loss: 45.46020643927141691165\n",
      "Iteration 38233 => Loss: 45.46005009880356340091\n",
      "Iteration 38234 => Loss: 45.45989375956267508627\n",
      "Iteration 38235 => Loss: 45.45973742154873065147\n",
      "Iteration 38236 => Loss: 45.45958108476172299106\n",
      "Iteration 38237 => Loss: 45.45942474920164499963\n",
      "Iteration 38238 => Loss: 45.45926841486847536089\n",
      "Iteration 38239 => Loss: 45.45911208176219986399\n",
      "Iteration 38240 => Loss: 45.45895574988283271978\n",
      "Iteration 38241 => Loss: 45.45879941923031708484\n",
      "Iteration 38242 => Loss: 45.45864308980471690802\n",
      "Iteration 38243 => Loss: 45.45848676160596113505\n",
      "Iteration 38244 => Loss: 45.45833043463405687135\n",
      "Iteration 38245 => Loss: 45.45817410888901122235\n",
      "Iteration 38246 => Loss: 45.45801778437080997719\n",
      "Iteration 38247 => Loss: 45.45786146107940339789\n",
      "Iteration 38248 => Loss: 45.45770513901484122243\n",
      "Iteration 38249 => Loss: 45.45754881817707371283\n",
      "Iteration 38250 => Loss: 45.45739249856612218537\n",
      "Iteration 38251 => Loss: 45.45723618018193690204\n",
      "Iteration 38252 => Loss: 45.45707986302453207372\n",
      "Iteration 38253 => Loss: 45.45692354709390059497\n",
      "Iteration 38254 => Loss: 45.45676723239002825494\n",
      "Iteration 38255 => Loss: 45.45661091891290794820\n",
      "Iteration 38256 => Loss: 45.45645460666253967474\n",
      "Iteration 38257 => Loss: 45.45629829563888790744\n",
      "Iteration 38258 => Loss: 45.45614198584195264630\n",
      "Iteration 38259 => Loss: 45.45598567727172678588\n",
      "Iteration 38260 => Loss: 45.45582936992821743161\n",
      "Iteration 38261 => Loss: 45.45567306381138905635\n",
      "Iteration 38262 => Loss: 45.45551675892124166012\n",
      "Iteration 38263 => Loss: 45.45536045525776813747\n",
      "Iteration 38264 => Loss: 45.45520415282096848841\n",
      "Iteration 38265 => Loss: 45.45504785161081429123\n",
      "Iteration 38266 => Loss: 45.45489155162730554594\n",
      "Iteration 38267 => Loss: 45.45473525287043514709\n",
      "Iteration 38268 => Loss: 45.45457895534015335670\n",
      "Iteration 38269 => Loss: 45.45442265903654543990\n",
      "Iteration 38270 => Loss: 45.45426636395949060443\n",
      "Iteration 38271 => Loss: 45.45411007010905990455\n",
      "Iteration 38272 => Loss: 45.45395377748520360228\n",
      "Iteration 38273 => Loss: 45.45379748608794301390\n",
      "Iteration 38274 => Loss: 45.45364119591722129599\n",
      "Iteration 38275 => Loss: 45.45348490697305976482\n",
      "Iteration 38276 => Loss: 45.45332861925545842041\n",
      "Iteration 38277 => Loss: 45.45317233276439594647\n",
      "Iteration 38278 => Loss: 45.45301604749986523757\n",
      "Iteration 38279 => Loss: 45.45285976346182366115\n",
      "Iteration 38280 => Loss: 45.45270348065032095519\n",
      "Iteration 38281 => Loss: 45.45254719906532159257\n",
      "Iteration 38282 => Loss: 45.45239091870678294072\n",
      "Iteration 38283 => Loss: 45.45223463957474052677\n",
      "Iteration 38284 => Loss: 45.45207836166918013987\n",
      "Iteration 38285 => Loss: 45.45192208499008046374\n",
      "Iteration 38286 => Loss: 45.45176580953740597124\n",
      "Iteration 38287 => Loss: 45.45160953531118508408\n",
      "Iteration 38288 => Loss: 45.45145326231141069684\n",
      "Iteration 38289 => Loss: 45.45129699053803307152\n",
      "Iteration 38290 => Loss: 45.45114071999108773525\n",
      "Iteration 38291 => Loss: 45.45098445067054626634\n",
      "Iteration 38292 => Loss: 45.45082818257638734849\n",
      "Iteration 38293 => Loss: 45.45067191570861098171\n",
      "Iteration 38294 => Loss: 45.45051565006721006057\n",
      "Iteration 38295 => Loss: 45.45035938565217037421\n",
      "Iteration 38296 => Loss: 45.45020312246351323893\n",
      "Iteration 38297 => Loss: 45.45004686050117470586\n",
      "Iteration 38298 => Loss: 45.44989059976516898587\n",
      "Iteration 38299 => Loss: 45.44973434025551028981\n",
      "Iteration 38300 => Loss: 45.44957808197214177426\n",
      "Iteration 38301 => Loss: 45.44942182491509186093\n",
      "Iteration 38302 => Loss: 45.44926556908433923354\n",
      "Iteration 38303 => Loss: 45.44910931447987678666\n",
      "Iteration 38304 => Loss: 45.44895306110169030944\n",
      "Iteration 38305 => Loss: 45.44879680894978690731\n",
      "Iteration 38306 => Loss: 45.44864055802413105312\n",
      "Iteration 38307 => Loss: 45.44848430832470853602\n",
      "Iteration 38308 => Loss: 45.44832805985153356687\n",
      "Iteration 38309 => Loss: 45.44817181260459193481\n",
      "Iteration 38310 => Loss: 45.44801556658388363985\n",
      "Iteration 38311 => Loss: 45.44785932178938026027\n",
      "Iteration 38312 => Loss: 45.44770307822108179607\n",
      "Iteration 38313 => Loss: 45.44754683587894561470\n",
      "Iteration 38314 => Loss: 45.44739059476301434870\n",
      "Iteration 38315 => Loss: 45.44723435487325957638\n",
      "Iteration 38316 => Loss: 45.44707811620963866517\n",
      "Iteration 38317 => Loss: 45.44692187877220135306\n",
      "Iteration 38318 => Loss: 45.44676564256089790206\n",
      "Iteration 38319 => Loss: 45.44660940757573541759\n",
      "Iteration 38320 => Loss: 45.44645317381667837253\n",
      "Iteration 38321 => Loss: 45.44629694128374097772\n",
      "Iteration 38322 => Loss: 45.44614070997691612774\n",
      "Iteration 38323 => Loss: 45.44598447989617540088\n",
      "Iteration 38324 => Loss: 45.44582825104152590256\n",
      "Iteration 38325 => Loss: 45.44567202341294631651\n",
      "Iteration 38326 => Loss: 45.44551579701045085358\n",
      "Iteration 38327 => Loss: 45.44535957183401109205\n",
      "Iteration 38328 => Loss: 45.44520334788359150480\n",
      "Iteration 38329 => Loss: 45.44504712515923472438\n",
      "Iteration 38330 => Loss: 45.44489090366090522366\n",
      "Iteration 38331 => Loss: 45.44473468338857458093\n",
      "Iteration 38332 => Loss: 45.44457846434227832333\n",
      "Iteration 38333 => Loss: 45.44442224652196671286\n",
      "Iteration 38334 => Loss: 45.44426602992763264410\n",
      "Iteration 38335 => Loss: 45.44410981455930453876\n",
      "Iteration 38336 => Loss: 45.44395360041690423714\n",
      "Iteration 38337 => Loss: 45.44379738750050989893\n",
      "Iteration 38338 => Loss: 45.44364117581005046986\n",
      "Iteration 38339 => Loss: 45.44348496534552594994\n",
      "Iteration 38340 => Loss: 45.44332875610692212831\n",
      "Iteration 38341 => Loss: 45.44317254809426032125\n",
      "Iteration 38342 => Loss: 45.44301634130751921248\n",
      "Iteration 38343 => Loss: 45.44286013574666327486\n",
      "Iteration 38344 => Loss: 45.44270393141169250839\n",
      "Iteration 38345 => Loss: 45.44254772830262822936\n",
      "Iteration 38346 => Loss: 45.44239152641941359434\n",
      "Iteration 38347 => Loss: 45.44223532576209123590\n",
      "Iteration 38348 => Loss: 45.44207912633060431062\n",
      "Iteration 38349 => Loss: 45.44192292812494571308\n",
      "Iteration 38350 => Loss: 45.44176673114515097041\n",
      "Iteration 38351 => Loss: 45.44161053539117745004\n",
      "Iteration 38352 => Loss: 45.44145434086301804655\n",
      "Iteration 38353 => Loss: 45.44129814756066565451\n",
      "Iteration 38354 => Loss: 45.44114195548409185221\n",
      "Iteration 38355 => Loss: 45.44098576463331795594\n",
      "Iteration 38356 => Loss: 45.44082957500833686026\n",
      "Iteration 38357 => Loss: 45.44067338660908461634\n",
      "Iteration 38358 => Loss: 45.44051719943563938386\n",
      "Iteration 38359 => Loss: 45.44036101348792300314\n",
      "Iteration 38360 => Loss: 45.44020482876592836874\n",
      "Iteration 38361 => Loss: 45.44004864526969100780\n",
      "Iteration 38362 => Loss: 45.43989246299915407690\n",
      "Iteration 38363 => Loss: 45.43973628195433889232\n",
      "Iteration 38364 => Loss: 45.43958010213521703236\n",
      "Iteration 38365 => Loss: 45.43942392354178139158\n",
      "Iteration 38366 => Loss: 45.43926774617403196999\n",
      "Iteration 38367 => Loss: 45.43911157003195455673\n",
      "Iteration 38368 => Loss: 45.43895539511554915180\n",
      "Iteration 38369 => Loss: 45.43879922142478022806\n",
      "Iteration 38370 => Loss: 45.43864304895965489095\n",
      "Iteration 38371 => Loss: 45.43848687772018024589\n",
      "Iteration 38372 => Loss: 45.43833070770631366031\n",
      "Iteration 38373 => Loss: 45.43817453891806934507\n",
      "Iteration 38374 => Loss: 45.43801837135543308932\n",
      "Iteration 38375 => Loss: 45.43786220501837647134\n",
      "Iteration 38376 => Loss: 45.43770603990692080743\n",
      "Iteration 38377 => Loss: 45.43754987602102346500\n",
      "Iteration 38378 => Loss: 45.43739371336071286578\n",
      "Iteration 38379 => Loss: 45.43723755192595348262\n",
      "Iteration 38380 => Loss: 45.43708139171673110468\n",
      "Iteration 38381 => Loss: 45.43692523273303152109\n",
      "Iteration 38382 => Loss: 45.43676907497489736443\n",
      "Iteration 38383 => Loss: 45.43661291844225047498\n",
      "Iteration 38384 => Loss: 45.43645676313513348532\n",
      "Iteration 38385 => Loss: 45.43630060905349665745\n",
      "Iteration 38386 => Loss: 45.43614445619735420223\n",
      "Iteration 38387 => Loss: 45.43598830456670611966\n",
      "Iteration 38388 => Loss: 45.43583215416151688260\n",
      "Iteration 38389 => Loss: 45.43567600498177228019\n",
      "Iteration 38390 => Loss: 45.43551985702750073415\n",
      "Iteration 38391 => Loss: 45.43536371029865961191\n",
      "Iteration 38392 => Loss: 45.43520756479524180804\n",
      "Iteration 38393 => Loss: 45.43505142051727574426\n",
      "Iteration 38394 => Loss: 45.43489527746469036629\n",
      "Iteration 38395 => Loss: 45.43473913563751409583\n",
      "Iteration 38396 => Loss: 45.43458299503574693290\n",
      "Iteration 38397 => Loss: 45.43442685565934624492\n",
      "Iteration 38398 => Loss: 45.43427071750833334818\n",
      "Iteration 38399 => Loss: 45.43411458058266561011\n",
      "Iteration 38400 => Loss: 45.43395844488237145242\n",
      "Iteration 38401 => Loss: 45.43380231040740113713\n",
      "Iteration 38402 => Loss: 45.43364617715777598050\n",
      "Iteration 38403 => Loss: 45.43349004513347466627\n",
      "Iteration 38404 => Loss: 45.43333391433449008900\n",
      "Iteration 38405 => Loss: 45.43317778476080803784\n",
      "Iteration 38406 => Loss: 45.43302165641244982908\n",
      "Iteration 38407 => Loss: 45.43286552928933730300\n",
      "Iteration 38408 => Loss: 45.43270940339153440846\n",
      "Iteration 38409 => Loss: 45.43255327871897009118\n",
      "Iteration 38410 => Loss: 45.43239715527169408915\n",
      "Iteration 38411 => Loss: 45.43224103304966376982\n",
      "Iteration 38412 => Loss: 45.43208491205285071146\n",
      "Iteration 38413 => Loss: 45.43192879228126912494\n",
      "Iteration 38414 => Loss: 45.43177267373493322111\n",
      "Iteration 38415 => Loss: 45.43161655641378615655\n",
      "Iteration 38416 => Loss: 45.43146044031784214212\n",
      "Iteration 38417 => Loss: 45.43130432544709407239\n",
      "Iteration 38418 => Loss: 45.43114821180152063107\n",
      "Iteration 38419 => Loss: 45.43099209938112892360\n",
      "Iteration 38420 => Loss: 45.43083598818589763368\n",
      "Iteration 38421 => Loss: 45.43067987821579123420\n",
      "Iteration 38422 => Loss: 45.43052376947086656855\n",
      "Iteration 38423 => Loss: 45.43036766195105968791\n",
      "Iteration 38424 => Loss: 45.43021155565639190854\n",
      "Iteration 38425 => Loss: 45.43005545058678507075\n",
      "Iteration 38426 => Loss: 45.42989934674233154510\n",
      "Iteration 38427 => Loss: 45.42974324412296027731\n",
      "Iteration 38428 => Loss: 45.42958714272868547823\n",
      "Iteration 38429 => Loss: 45.42943104255947162073\n",
      "Iteration 38430 => Loss: 45.42927494361533291567\n",
      "Iteration 38431 => Loss: 45.42911884589624804676\n",
      "Iteration 38432 => Loss: 45.42896274940221701399\n",
      "Iteration 38433 => Loss: 45.42880665413320429025\n",
      "Iteration 38434 => Loss: 45.42865056008922408637\n",
      "Iteration 38435 => Loss: 45.42849446727026929693\n",
      "Iteration 38436 => Loss: 45.42833837567631150023\n",
      "Iteration 38437 => Loss: 45.42818228530735780168\n",
      "Iteration 38438 => Loss: 45.42802619616338688502\n",
      "Iteration 38439 => Loss: 45.42787010824440585566\n",
      "Iteration 38440 => Loss: 45.42771402155038629189\n",
      "Iteration 38441 => Loss: 45.42755793608134951000\n",
      "Iteration 38442 => Loss: 45.42740185183723866658\n",
      "Iteration 38443 => Loss: 45.42724576881806086703\n",
      "Iteration 38444 => Loss: 45.42708968702385163851\n",
      "Iteration 38445 => Loss: 45.42693360645452571589\n",
      "Iteration 38446 => Loss: 45.42677752711013994258\n",
      "Iteration 38447 => Loss: 45.42662144899065168602\n",
      "Iteration 38448 => Loss: 45.42646537209605384078\n",
      "Iteration 38449 => Loss: 45.42630929642633219601\n",
      "Iteration 38450 => Loss: 45.42615322198147964627\n",
      "Iteration 38451 => Loss: 45.42599714876151040244\n",
      "Iteration 38452 => Loss: 45.42584107676636762108\n",
      "Iteration 38453 => Loss: 45.42568500599609393475\n",
      "Iteration 38454 => Loss: 45.42552893645065381634\n",
      "Iteration 38455 => Loss: 45.42537286813001884411\n",
      "Iteration 38456 => Loss: 45.42521680103421743979\n",
      "Iteration 38457 => Loss: 45.42506073516322828709\n",
      "Iteration 38458 => Loss: 45.42490467051701585888\n",
      "Iteration 38459 => Loss: 45.42474860709560857686\n",
      "Iteration 38460 => Loss: 45.42459254489897091389\n",
      "Iteration 38461 => Loss: 45.42443648392709576456\n",
      "Iteration 38462 => Loss: 45.42428042417998312885\n",
      "Iteration 38463 => Loss: 45.42412436565763300678\n",
      "Iteration 38464 => Loss: 45.42396830835999566034\n",
      "Iteration 38465 => Loss: 45.42381225228711372210\n",
      "Iteration 38466 => Loss: 45.42365619743893745408\n",
      "Iteration 38467 => Loss: 45.42350014381546685627\n",
      "Iteration 38468 => Loss: 45.42334409141669482324\n",
      "Iteration 38469 => Loss: 45.42318804024263556585\n",
      "Iteration 38470 => Loss: 45.42303199029324645153\n",
      "Iteration 38471 => Loss: 45.42287594156852748029\n",
      "Iteration 38472 => Loss: 45.42271989406847154669\n",
      "Iteration 38473 => Loss: 45.42256384779306443988\n",
      "Iteration 38474 => Loss: 45.42240780274230615987\n",
      "Iteration 38475 => Loss: 45.42225175891616828494\n",
      "Iteration 38476 => Loss: 45.42209571631465081509\n",
      "Iteration 38477 => Loss: 45.42193967493778217204\n",
      "Iteration 38478 => Loss: 45.42178363478549840693\n",
      "Iteration 38479 => Loss: 45.42162759585780662519\n",
      "Iteration 38480 => Loss: 45.42147155815468551054\n",
      "Iteration 38481 => Loss: 45.42131552167616348470\n",
      "Iteration 38482 => Loss: 45.42115948642220502052\n",
      "Iteration 38483 => Loss: 45.42100345239279590714\n",
      "Iteration 38484 => Loss: 45.42084741958792903915\n",
      "Iteration 38485 => Loss: 45.42069138800759731112\n",
      "Iteration 38486 => Loss: 45.42053535765182203932\n",
      "Iteration 38487 => Loss: 45.42037932852055348576\n",
      "Iteration 38488 => Loss: 45.42022330061377743959\n",
      "Iteration 38489 => Loss: 45.42006727393150811167\n",
      "Iteration 38490 => Loss: 45.41991124847372418571\n",
      "Iteration 38491 => Loss: 45.41975522424041855629\n",
      "Iteration 38492 => Loss: 45.41959920123158411798\n",
      "Iteration 38493 => Loss: 45.41944317944720665992\n",
      "Iteration 38494 => Loss: 45.41928715888728618211\n",
      "Iteration 38495 => Loss: 45.41913113955181557913\n",
      "Iteration 38496 => Loss: 45.41897512144075221840\n",
      "Iteration 38497 => Loss: 45.41881910455413873251\n",
      "Iteration 38498 => Loss: 45.41866308889193248888\n",
      "Iteration 38499 => Loss: 45.41850707445412638208\n",
      "Iteration 38500 => Loss: 45.41835106124069909583\n",
      "Iteration 38501 => Loss: 45.41819504925165773557\n",
      "Iteration 38502 => Loss: 45.41803903848700230128\n",
      "Iteration 38503 => Loss: 45.41788302894671147669\n",
      "Iteration 38504 => Loss: 45.41772702063075684009\n",
      "Iteration 38505 => Loss: 45.41757101353917391862\n",
      "Iteration 38506 => Loss: 45.41741500767192007970\n",
      "Iteration 38507 => Loss: 45.41725900302896690164\n",
      "Iteration 38508 => Loss: 45.41710299961035701699\n",
      "Iteration 38509 => Loss: 45.41694699741605489862\n",
      "Iteration 38510 => Loss: 45.41679099644602501940\n",
      "Iteration 38511 => Loss: 45.41663499670028159017\n",
      "Iteration 38512 => Loss: 45.41647899817883882179\n",
      "Iteration 38513 => Loss: 45.41632300088165408170\n",
      "Iteration 38514 => Loss: 45.41616700480873447532\n",
      "Iteration 38515 => Loss: 45.41601100996005868637\n",
      "Iteration 38516 => Loss: 45.41585501633562671486\n",
      "Iteration 38517 => Loss: 45.41569902393543145536\n",
      "Iteration 38518 => Loss: 45.41554303275944448615\n",
      "Iteration 38519 => Loss: 45.41538704280765159638\n",
      "Iteration 38520 => Loss: 45.41523105408008120776\n",
      "Iteration 38521 => Loss: 45.41507506657669779315\n",
      "Iteration 38522 => Loss: 45.41491908029750845799\n",
      "Iteration 38523 => Loss: 45.41476309524248478056\n",
      "Iteration 38524 => Loss: 45.41460711141161965543\n",
      "Iteration 38525 => Loss: 45.41445112880490597718\n",
      "Iteration 38526 => Loss: 45.41429514742232242952\n",
      "Iteration 38527 => Loss: 45.41413916726389032874\n",
      "Iteration 38528 => Loss: 45.41398318832958835856\n",
      "Iteration 38529 => Loss: 45.41382721061938809726\n",
      "Iteration 38530 => Loss: 45.41367123413329665027\n",
      "Iteration 38531 => Loss: 45.41351525887128559589\n",
      "Iteration 38532 => Loss: 45.41335928483338335582\n",
      "Iteration 38533 => Loss: 45.41320331201954729750\n",
      "Iteration 38534 => Loss: 45.41304734042976321007\n",
      "Iteration 38535 => Loss: 45.41289137006405951524\n",
      "Iteration 38536 => Loss: 45.41273540092237936960\n",
      "Iteration 38537 => Loss: 45.41257943300475830029\n",
      "Iteration 38538 => Loss: 45.41242346631116078015\n",
      "Iteration 38539 => Loss: 45.41226750084158680920\n",
      "Iteration 38540 => Loss: 45.41211153659600796573\n",
      "Iteration 38541 => Loss: 45.41195557357444556601\n",
      "Iteration 38542 => Loss: 45.41179961177684987206\n",
      "Iteration 38543 => Loss: 45.41164365120323509473\n",
      "Iteration 38544 => Loss: 45.41148769185360833944\n",
      "Iteration 38545 => Loss: 45.41133173372792697364\n",
      "Iteration 38546 => Loss: 45.41117577682622652446\n",
      "Iteration 38547 => Loss: 45.41101982114843593763\n",
      "Iteration 38548 => Loss: 45.41086386669458363485\n",
      "Iteration 38549 => Loss: 45.41070791346465540528\n",
      "Iteration 38550 => Loss: 45.41055196145865124890\n",
      "Iteration 38551 => Loss: 45.41039601067652853317\n",
      "Iteration 38552 => Loss: 45.41024006111831567978\n",
      "Iteration 38553 => Loss: 45.41008411278397005617\n",
      "Iteration 38554 => Loss: 45.40992816567353429491\n",
      "Iteration 38555 => Loss: 45.40977221978692313087\n",
      "Iteration 38556 => Loss: 45.40961627512418630204\n",
      "Iteration 38557 => Loss: 45.40946033168528828128\n",
      "Iteration 38558 => Loss: 45.40930438947024327945\n",
      "Iteration 38559 => Loss: 45.40914844847900155855\n",
      "Iteration 38560 => Loss: 45.40899250871161996201\n",
      "Iteration 38561 => Loss: 45.40883657016799901385\n",
      "Iteration 38562 => Loss: 45.40868063284817424119\n",
      "Iteration 38563 => Loss: 45.40852469675215274947\n",
      "Iteration 38564 => Loss: 45.40836876187990611697\n",
      "Iteration 38565 => Loss: 45.40821282823142723828\n",
      "Iteration 38566 => Loss: 45.40805689580671611338\n",
      "Iteration 38567 => Loss: 45.40790096460574432058\n",
      "Iteration 38568 => Loss: 45.40774503462853317615\n",
      "Iteration 38569 => Loss: 45.40758910587503294209\n",
      "Iteration 38570 => Loss: 45.40743317834525782928\n",
      "Iteration 38571 => Loss: 45.40727725203918652142\n",
      "Iteration 38572 => Loss: 45.40712132695682612393\n",
      "Iteration 38573 => Loss: 45.40696540309816953140\n",
      "Iteration 38574 => Loss: 45.40680948046315990041\n",
      "Iteration 38575 => Loss: 45.40665355905184696894\n",
      "Iteration 38576 => Loss: 45.40649763886419520986\n",
      "Iteration 38577 => Loss: 45.40634171990019041232\n",
      "Iteration 38578 => Loss: 45.40618580215983968174\n",
      "Iteration 38579 => Loss: 45.40602988564311459641\n",
      "Iteration 38580 => Loss: 45.40587397035002936718\n",
      "Iteration 38581 => Loss: 45.40571805628054136150\n",
      "Iteration 38582 => Loss: 45.40556214343465768479\n",
      "Iteration 38583 => Loss: 45.40540623181239254791\n",
      "Iteration 38584 => Loss: 45.40525032141368910743\n",
      "Iteration 38585 => Loss: 45.40509441223856157421\n",
      "Iteration 38586 => Loss: 45.40493850428702415911\n",
      "Iteration 38587 => Loss: 45.40478259755901291328\n",
      "Iteration 38588 => Loss: 45.40462669205458468014\n",
      "Iteration 38589 => Loss: 45.40447078777367551083\n",
      "Iteration 38590 => Loss: 45.40431488471628540537\n",
      "Iteration 38591 => Loss: 45.40415898288242857461\n",
      "Iteration 38592 => Loss: 45.40400308227206238598\n",
      "Iteration 38593 => Loss: 45.40384718288521526119\n",
      "Iteration 38594 => Loss: 45.40369128472185877854\n",
      "Iteration 38595 => Loss: 45.40353538778197162173\n",
      "Iteration 38596 => Loss: 45.40337949206557510706\n",
      "Iteration 38597 => Loss: 45.40322359757262660196\n",
      "Iteration 38598 => Loss: 45.40306770430311900100\n",
      "Iteration 38599 => Loss: 45.40291181225707362046\n",
      "Iteration 38600 => Loss: 45.40275592143444072235\n",
      "Iteration 38601 => Loss: 45.40260003183524162296\n",
      "Iteration 38602 => Loss: 45.40244414345946921685\n",
      "Iteration 38603 => Loss: 45.40228825630708087147\n",
      "Iteration 38604 => Loss: 45.40213237037809790309\n",
      "Iteration 38605 => Loss: 45.40197648567248478457\n",
      "Iteration 38606 => Loss: 45.40182060219025572678\n",
      "Iteration 38607 => Loss: 45.40166471993140362429\n",
      "Iteration 38608 => Loss: 45.40150883889587873909\n",
      "Iteration 38609 => Loss: 45.40135295908372370377\n",
      "Iteration 38610 => Loss: 45.40119708049491009660\n",
      "Iteration 38611 => Loss: 45.40104120312940949589\n",
      "Iteration 38612 => Loss: 45.40088532698722900705\n",
      "Iteration 38613 => Loss: 45.40072945206835441923\n",
      "Iteration 38614 => Loss: 45.40057357837279283785\n",
      "Iteration 38615 => Loss: 45.40041770590049452494\n",
      "Iteration 38616 => Loss: 45.40026183465150211305\n",
      "Iteration 38617 => Loss: 45.40010596462576586418\n",
      "Iteration 38618 => Loss: 45.39995009582328577835\n",
      "Iteration 38619 => Loss: 45.39979422824404764469\n",
      "Iteration 38620 => Loss: 45.39963836188804435778\n",
      "Iteration 38621 => Loss: 45.39948249675529723390\n",
      "Iteration 38622 => Loss: 45.39932663284576364049\n",
      "Iteration 38623 => Loss: 45.39917077015945068297\n",
      "Iteration 38624 => Loss: 45.39901490869633704506\n",
      "Iteration 38625 => Loss: 45.39885904845640141048\n",
      "Iteration 38626 => Loss: 45.39870318943964377922\n",
      "Iteration 38627 => Loss: 45.39854733164607125673\n",
      "Iteration 38628 => Loss: 45.39839147507566252671\n",
      "Iteration 38629 => Loss: 45.39823561972841758916\n",
      "Iteration 38630 => Loss: 45.39807976560432223323\n",
      "Iteration 38631 => Loss: 45.39792391270333382636\n",
      "Iteration 38632 => Loss: 45.39776806102547368482\n",
      "Iteration 38633 => Loss: 45.39761221057075601948\n",
      "Iteration 38634 => Loss: 45.39745636133911688148\n",
      "Iteration 38635 => Loss: 45.39730051333059179797\n",
      "Iteration 38636 => Loss: 45.39714466654515945265\n",
      "Iteration 38637 => Loss: 45.39698882098279142383\n",
      "Iteration 38638 => Loss: 45.39683297664348060607\n",
      "Iteration 38639 => Loss: 45.39667713352724831566\n",
      "Iteration 38640 => Loss: 45.39652129163405902545\n",
      "Iteration 38641 => Loss: 45.39636545096389852461\n",
      "Iteration 38642 => Loss: 45.39620961151677391854\n",
      "Iteration 38643 => Loss: 45.39605377329267099640\n",
      "Iteration 38644 => Loss: 45.39589793629157554733\n",
      "Iteration 38645 => Loss: 45.39574210051348046591\n",
      "Iteration 38646 => Loss: 45.39558626595838575213\n",
      "Iteration 38647 => Loss: 45.39543043262625587886\n",
      "Iteration 38648 => Loss: 45.39527460051710505695\n",
      "Iteration 38649 => Loss: 45.39511876963091907555\n",
      "Iteration 38650 => Loss: 45.39496293996768372381\n",
      "Iteration 38651 => Loss: 45.39480711152740610714\n",
      "Iteration 38652 => Loss: 45.39465128431005780385\n",
      "Iteration 38653 => Loss: 45.39449545831561039222\n",
      "Iteration 38654 => Loss: 45.39433963354408518853\n",
      "Iteration 38655 => Loss: 45.39418380999548929822\n",
      "Iteration 38656 => Loss: 45.39402798766976587785\n",
      "Iteration 38657 => Loss: 45.39387216656692203287\n",
      "Iteration 38658 => Loss: 45.39371634668698618498\n",
      "Iteration 38659 => Loss: 45.39356052802986596362\n",
      "Iteration 38660 => Loss: 45.39340471059563242306\n",
      "Iteration 38661 => Loss: 45.39324889438424293076\n",
      "Iteration 38662 => Loss: 45.39309307939569748669\n",
      "Iteration 38663 => Loss: 45.39293726562996056373\n",
      "Iteration 38664 => Loss: 45.39278145308706058358\n",
      "Iteration 38665 => Loss: 45.39262564176696912455\n",
      "Iteration 38666 => Loss: 45.39246983166966487033\n",
      "Iteration 38667 => Loss: 45.39231402279516203180\n",
      "Iteration 38668 => Loss: 45.39215821514342508181\n",
      "Iteration 38669 => Loss: 45.39200240871448954749\n",
      "Iteration 38670 => Loss: 45.39184660350827726916\n",
      "Iteration 38671 => Loss: 45.39169079952482377394\n",
      "Iteration 38672 => Loss: 45.39153499676412195640\n",
      "Iteration 38673 => Loss: 45.39137919522614339485\n",
      "Iteration 38674 => Loss: 45.39122339491091651098\n",
      "Iteration 38675 => Loss: 45.39106759581836314510\n",
      "Iteration 38676 => Loss: 45.39091179794852592977\n",
      "Iteration 38677 => Loss: 45.39075600130138354871\n",
      "Iteration 38678 => Loss: 45.39060020587691468563\n",
      "Iteration 38679 => Loss: 45.39044441167514065683\n",
      "Iteration 38680 => Loss: 45.39028861869602593515\n",
      "Iteration 38681 => Loss: 45.39013282693955630975\n",
      "Iteration 38682 => Loss: 45.38997703640573888606\n",
      "Iteration 38683 => Loss: 45.38982124709455945322\n",
      "Iteration 38684 => Loss: 45.38966545900599669494\n",
      "Iteration 38685 => Loss: 45.38950967214006482209\n",
      "Iteration 38686 => Loss: 45.38935388649671409667\n",
      "Iteration 38687 => Loss: 45.38919810207600846752\n",
      "Iteration 38688 => Loss: 45.38904231887784845867\n",
      "Iteration 38689 => Loss: 45.38888653690228380810\n",
      "Iteration 38690 => Loss: 45.38873075614927898869\n",
      "Iteration 38691 => Loss: 45.38857497661882689499\n",
      "Iteration 38692 => Loss: 45.38841919831096305415\n",
      "Iteration 38693 => Loss: 45.38826342122560220105\n",
      "Iteration 38694 => Loss: 45.38810764536276565195\n",
      "Iteration 38695 => Loss: 45.38795187072246761772\n",
      "Iteration 38696 => Loss: 45.38779609730469388751\n",
      "Iteration 38697 => Loss: 45.38764032510939472331\n",
      "Iteration 38698 => Loss: 45.38748455413659854685\n",
      "Iteration 38699 => Loss: 45.38732878438628404183\n",
      "Iteration 38700 => Loss: 45.38717301585845831369\n",
      "Iteration 38701 => Loss: 45.38701724855306451900\n",
      "Iteration 38702 => Loss: 45.38686148247014529034\n",
      "Iteration 38703 => Loss: 45.38670571760965799513\n",
      "Iteration 38704 => Loss: 45.38654995397160973880\n",
      "Iteration 38705 => Loss: 45.38639419155600762679\n",
      "Iteration 38706 => Loss: 45.38623843036279481566\n",
      "Iteration 38707 => Loss: 45.38608267039199972714\n",
      "Iteration 38708 => Loss: 45.38592691164360104494\n",
      "Iteration 38709 => Loss: 45.38577115411757034735\n",
      "Iteration 38710 => Loss: 45.38561539781395026694\n",
      "Iteration 38711 => Loss: 45.38545964273265553857\n",
      "Iteration 38712 => Loss: 45.38530388887374300566\n",
      "Iteration 38713 => Loss: 45.38514813623717714108\n",
      "Iteration 38714 => Loss: 45.38499238482295083941\n",
      "Iteration 38715 => Loss: 45.38483663463104988978\n",
      "Iteration 38716 => Loss: 45.38468088566146718676\n",
      "Iteration 38717 => Loss: 45.38452513791420983580\n",
      "Iteration 38718 => Loss: 45.38436939138924230974\n",
      "Iteration 38719 => Loss: 45.38421364608655750317\n",
      "Iteration 38720 => Loss: 45.38405790200614831065\n",
      "Iteration 38721 => Loss: 45.38390215914802894304\n",
      "Iteration 38722 => Loss: 45.38374641751216387320\n",
      "Iteration 38723 => Loss: 45.38359067709854599570\n",
      "Iteration 38724 => Loss: 45.38343493790717531056\n",
      "Iteration 38725 => Loss: 45.38327919993803050147\n",
      "Iteration 38726 => Loss: 45.38312346319112577930\n",
      "Iteration 38727 => Loss: 45.38296772766641851149\n",
      "Iteration 38728 => Loss: 45.38281199336391580346\n",
      "Iteration 38729 => Loss: 45.38265626028361054978\n",
      "Iteration 38730 => Loss: 45.38250052842550985588\n",
      "Iteration 38731 => Loss: 45.38234479778955687834\n",
      "Iteration 38732 => Loss: 45.38218906837579424973\n",
      "Iteration 38733 => Loss: 45.38203334018415802120\n",
      "Iteration 38734 => Loss: 45.38187761321469082532\n",
      "Iteration 38735 => Loss: 45.38172188746737134579\n",
      "Iteration 38736 => Loss: 45.38156616294214273921\n",
      "Iteration 38737 => Loss: 45.38141043963905474357\n",
      "Iteration 38738 => Loss: 45.38125471755807183172\n",
      "Iteration 38739 => Loss: 45.38109899669919400367\n",
      "Iteration 38740 => Loss: 45.38094327706239994313\n",
      "Iteration 38741 => Loss: 45.38078755864766833383\n",
      "Iteration 38742 => Loss: 45.38063184145504180833\n",
      "Iteration 38743 => Loss: 45.38047612548444931235\n",
      "Iteration 38744 => Loss: 45.38032041073590505675\n",
      "Iteration 38745 => Loss: 45.38016469720943035782\n",
      "Iteration 38746 => Loss: 45.38000898490496837212\n",
      "Iteration 38747 => Loss: 45.37985327382251199424\n",
      "Iteration 38748 => Loss: 45.37969756396211096217\n",
      "Iteration 38749 => Loss: 45.37954185532366579992\n",
      "Iteration 38750 => Loss: 45.37938614790723335091\n",
      "Iteration 38751 => Loss: 45.37923044171278519343\n",
      "Iteration 38752 => Loss: 45.37907473674032843292\n",
      "Iteration 38753 => Loss: 45.37891903298981333137\n",
      "Iteration 38754 => Loss: 45.37876333046126120507\n",
      "Iteration 38755 => Loss: 45.37860762915465073775\n",
      "Iteration 38756 => Loss: 45.37845192906997482396\n",
      "Iteration 38757 => Loss: 45.37829623020721925286\n",
      "Iteration 38758 => Loss: 45.37814053256639823530\n",
      "Iteration 38759 => Loss: 45.37798483614746203330\n",
      "Iteration 38760 => Loss: 45.37782914095044617397\n",
      "Iteration 38761 => Loss: 45.37767344697529381392\n",
      "Iteration 38762 => Loss: 45.37751775422204048027\n",
      "Iteration 38763 => Loss: 45.37736206269064354046\n",
      "Iteration 38764 => Loss: 45.37720637238112431078\n",
      "Iteration 38765 => Loss: 45.37705068329343305322\n",
      "Iteration 38766 => Loss: 45.37689499542757687323\n",
      "Iteration 38767 => Loss: 45.37673930878357708707\n",
      "Iteration 38768 => Loss: 45.37658362336139106219\n",
      "Iteration 38769 => Loss: 45.37642793916099037688\n",
      "Iteration 38770 => Loss: 45.37627225618241766369\n",
      "Iteration 38771 => Loss: 45.37611657442562318465\n",
      "Iteration 38772 => Loss: 45.37596089389060693975\n",
      "Iteration 38773 => Loss: 45.37580521457737603441\n",
      "Iteration 38774 => Loss: 45.37564953648591625779\n",
      "Iteration 38775 => Loss: 45.37549385961619918817\n",
      "Iteration 38776 => Loss: 45.37533818396821061469\n",
      "Iteration 38777 => Loss: 45.37518250954198606451\n",
      "Iteration 38778 => Loss: 45.37502683633746158876\n",
      "Iteration 38779 => Loss: 45.37487116435464429287\n",
      "Iteration 38780 => Loss: 45.37471549359356970399\n",
      "Iteration 38781 => Loss: 45.37455982405415966241\n",
      "Iteration 38782 => Loss: 45.37440415573644969527\n",
      "Iteration 38783 => Loss: 45.37424848864041848628\n",
      "Iteration 38784 => Loss: 45.37409282276605182460\n",
      "Iteration 38785 => Loss: 45.37393715811334971022\n",
      "Iteration 38786 => Loss: 45.37378149468226951058\n",
      "Iteration 38787 => Loss: 45.37362583247286096366\n",
      "Iteration 38788 => Loss: 45.37347017148506722606\n",
      "Iteration 38789 => Loss: 45.37331451171888119234\n",
      "Iteration 38790 => Loss: 45.37315885317431707335\n",
      "Iteration 38791 => Loss: 45.37300319585134644740\n",
      "Iteration 38792 => Loss: 45.37284753974996931447\n",
      "Iteration 38793 => Loss: 45.37269188487016435829\n",
      "Iteration 38794 => Loss: 45.37253623121194578971\n",
      "Iteration 38795 => Loss: 45.37238057877527097617\n",
      "Iteration 38796 => Loss: 45.37222492756018255022\n",
      "Iteration 38797 => Loss: 45.37206927756660945761\n",
      "Iteration 38798 => Loss: 45.37191362879457301460\n",
      "Iteration 38799 => Loss: 45.37175798124406611578\n",
      "Iteration 38800 => Loss: 45.37160233491506744485\n",
      "Iteration 38801 => Loss: 45.37144668980757700183\n",
      "Iteration 38802 => Loss: 45.37129104592157347042\n",
      "Iteration 38803 => Loss: 45.37113540325705685063\n",
      "Iteration 38804 => Loss: 45.37097976181399872075\n",
      "Iteration 38805 => Loss: 45.37082412159246302963\n",
      "Iteration 38806 => Loss: 45.37066848259233609042\n",
      "Iteration 38807 => Loss: 45.37051284481366053569\n",
      "Iteration 38808 => Loss: 45.37035720825641504916\n",
      "Iteration 38809 => Loss: 45.37020157292061384169\n",
      "Iteration 38810 => Loss: 45.37004593880624270241\n",
      "Iteration 38811 => Loss: 45.36989030591325899877\n",
      "Iteration 38812 => Loss: 45.36973467424166983619\n",
      "Iteration 38813 => Loss: 45.36957904379148942553\n",
      "Iteration 38814 => Loss: 45.36942341456268223965\n",
      "Iteration 38815 => Loss: 45.36926778655523406769\n",
      "Iteration 38816 => Loss: 45.36911215976915912051\n",
      "Iteration 38817 => Loss: 45.36895653420442897641\n",
      "Iteration 38818 => Loss: 45.36880090986103652995\n",
      "Iteration 38819 => Loss: 45.36864528673897467570\n",
      "Iteration 38820 => Loss: 45.36848966483823630824\n",
      "Iteration 38821 => Loss: 45.36833404415882142757\n",
      "Iteration 38822 => Loss: 45.36817842470070161198\n",
      "Iteration 38823 => Loss: 45.36802280646386975604\n",
      "Iteration 38824 => Loss: 45.36786718944832585976\n",
      "Iteration 38825 => Loss: 45.36771157365404860684\n",
      "Iteration 38826 => Loss: 45.36755595908105220815\n",
      "Iteration 38827 => Loss: 45.36740034572930824197\n",
      "Iteration 38828 => Loss: 45.36724473359880249745\n",
      "Iteration 38829 => Loss: 45.36708912268952786917\n",
      "Iteration 38830 => Loss: 45.36693351300149146255\n",
      "Iteration 38831 => Loss: 45.36677790453465775045\n",
      "Iteration 38832 => Loss: 45.36662229728905515458\n",
      "Iteration 38833 => Loss: 45.36646669126461972610\n",
      "Iteration 38834 => Loss: 45.36631108646140830842\n",
      "Iteration 38835 => Loss: 45.36615548287934984728\n",
      "Iteration 38836 => Loss: 45.36599988051845855352\n",
      "Iteration 38837 => Loss: 45.36584427937874153258\n",
      "Iteration 38838 => Loss: 45.36568867946014194104\n",
      "Iteration 38839 => Loss: 45.36553308076271662230\n",
      "Iteration 38840 => Loss: 45.36537748328640873297\n",
      "Iteration 38841 => Loss: 45.36522188703122537845\n",
      "Iteration 38842 => Loss: 45.36506629199713813705\n",
      "Iteration 38843 => Loss: 45.36491069818417543047\n",
      "Iteration 38844 => Loss: 45.36475510559230173158\n",
      "Iteration 38845 => Loss: 45.36459951422149572409\n",
      "Iteration 38846 => Loss: 45.36444392407177872428\n",
      "Iteration 38847 => Loss: 45.36428833514310809960\n",
      "Iteration 38848 => Loss: 45.36413274743549806090\n",
      "Iteration 38849 => Loss: 45.36397716094893439731\n",
      "Iteration 38850 => Loss: 45.36382157568339579257\n",
      "Iteration 38851 => Loss: 45.36366599163889645752\n",
      "Iteration 38852 => Loss: 45.36351040881541507588\n",
      "Iteration 38853 => Loss: 45.36335482721291612052\n",
      "Iteration 38854 => Loss: 45.36319924683143511857\n",
      "Iteration 38855 => Loss: 45.36304366767092233204\n",
      "Iteration 38856 => Loss: 45.36288808973140618264\n",
      "Iteration 38857 => Loss: 45.36273251301285114323\n",
      "Iteration 38858 => Loss: 45.36257693751527142467\n",
      "Iteration 38859 => Loss: 45.36242136323859597269\n",
      "Iteration 38860 => Loss: 45.36226579018289584155\n",
      "Iteration 38861 => Loss: 45.36211021834811418785\n",
      "Iteration 38862 => Loss: 45.36195464773425101157\n",
      "Iteration 38863 => Loss: 45.36179907834129920730\n",
      "Iteration 38864 => Loss: 45.36164351016923745874\n",
      "Iteration 38865 => Loss: 45.36148794321808708219\n",
      "Iteration 38866 => Loss: 45.36133237748779833964\n",
      "Iteration 38867 => Loss: 45.36117681297839965282\n",
      "Iteration 38868 => Loss: 45.36102124968984838915\n",
      "Iteration 38869 => Loss: 45.36086568762215875950\n",
      "Iteration 38870 => Loss: 45.36071012677530234214\n",
      "Iteration 38871 => Loss: 45.36055456714928624251\n",
      "Iteration 38872 => Loss: 45.36039900874408914433\n",
      "Iteration 38873 => Loss: 45.36024345155970394217\n",
      "Iteration 38874 => Loss: 45.36008789559614484688\n",
      "Iteration 38875 => Loss: 45.35993234085335501504\n",
      "Iteration 38876 => Loss: 45.35977678733136997380\n",
      "Iteration 38877 => Loss: 45.35962123503014709058\n",
      "Iteration 38878 => Loss: 45.35946568394970057625\n",
      "Iteration 38879 => Loss: 45.35931013408999490366\n",
      "Iteration 38880 => Loss: 45.35915458545105138910\n",
      "Iteration 38881 => Loss: 45.35899903803283450543\n",
      "Iteration 38882 => Loss: 45.35884349183533714722\n",
      "Iteration 38883 => Loss: 45.35868794685858063076\n",
      "Iteration 38884 => Loss: 45.35853240310252232348\n",
      "Iteration 38885 => Loss: 45.35837686056716933081\n",
      "Iteration 38886 => Loss: 45.35822131925251454732\n",
      "Iteration 38887 => Loss: 45.35806577915851534044\n",
      "Iteration 38888 => Loss: 45.35791024028520013189\n",
      "Iteration 38889 => Loss: 45.35775470263254760539\n",
      "Iteration 38890 => Loss: 45.35759916620053644465\n",
      "Iteration 38891 => Loss: 45.35744363098917375510\n",
      "Iteration 38892 => Loss: 45.35728809699843822045\n",
      "Iteration 38893 => Loss: 45.35713256422831562986\n",
      "Iteration 38894 => Loss: 45.35697703267884861589\n",
      "Iteration 38895 => Loss: 45.35682150234995191340\n",
      "Iteration 38896 => Loss: 45.35666597324165394411\n",
      "Iteration 38897 => Loss: 45.35651044535394760260\n",
      "Iteration 38898 => Loss: 45.35635491868679025629\n",
      "Iteration 38899 => Loss: 45.35619939324021743232\n",
      "Iteration 38900 => Loss: 45.35604386901419360356\n",
      "Iteration 38901 => Loss: 45.35588834600872587544\n",
      "Iteration 38902 => Loss: 45.35573282422379293166\n",
      "Iteration 38903 => Loss: 45.35557730365937345596\n",
      "Iteration 38904 => Loss: 45.35542178431548876461\n",
      "Iteration 38905 => Loss: 45.35526626619211043590\n",
      "Iteration 38906 => Loss: 45.35511074928922425897\n",
      "Iteration 38907 => Loss: 45.35495523360682312841\n",
      "Iteration 38908 => Loss: 45.35479971914490704421\n",
      "Iteration 38909 => Loss: 45.35464420590345469009\n",
      "Iteration 38910 => Loss: 45.35448869388246606604\n",
      "Iteration 38911 => Loss: 45.35433318308191985579\n",
      "Iteration 38912 => Loss: 45.35417767350182316477\n",
      "Iteration 38913 => Loss: 45.35402216514214046583\n",
      "Iteration 38914 => Loss: 45.35386665800290018069\n",
      "Iteration 38915 => Loss: 45.35371115208405257135\n",
      "Iteration 38916 => Loss: 45.35355564738564027039\n",
      "Iteration 38917 => Loss: 45.35340014390759222351\n",
      "Iteration 38918 => Loss: 45.35324464164992974702\n",
      "Iteration 38919 => Loss: 45.35308914061264573547\n",
      "Iteration 38920 => Loss: 45.35293364079573308345\n",
      "Iteration 38921 => Loss: 45.35277814219916336924\n",
      "Iteration 38922 => Loss: 45.35262264482294369827\n",
      "Iteration 38923 => Loss: 45.35246714866704564884\n",
      "Iteration 38924 => Loss: 45.35231165373150474807\n",
      "Iteration 38925 => Loss: 45.35215616001624994169\n",
      "Iteration 38926 => Loss: 45.35200066752131675685\n",
      "Iteration 38927 => Loss: 45.35184517624667677183\n",
      "Iteration 38928 => Loss: 45.35168968619231577577\n",
      "Iteration 38929 => Loss: 45.35153419735825508496\n",
      "Iteration 38930 => Loss: 45.35137870974445206684\n",
      "Iteration 38931 => Loss: 45.35122322335089961598\n",
      "Iteration 38932 => Loss: 45.35106773817760483780\n",
      "Iteration 38933 => Loss: 45.35091225422452509974\n",
      "Iteration 38934 => Loss: 45.35075677149169592894\n",
      "Iteration 38935 => Loss: 45.35060128997909600912\n",
      "Iteration 38936 => Loss: 45.35044580968668270771\n",
      "Iteration 38937 => Loss: 45.35029033061449155184\n",
      "Iteration 38938 => Loss: 45.35013485276247990896\n",
      "Iteration 38939 => Loss: 45.34997937613065488449\n",
      "Iteration 38940 => Loss: 45.34982390071902358386\n",
      "Iteration 38941 => Loss: 45.34966842652750784737\n",
      "Iteration 38942 => Loss: 45.34951295355618583471\n",
      "Iteration 38943 => Loss: 45.34935748180499359705\n",
      "Iteration 38944 => Loss: 45.34920201127392402896\n",
      "Iteration 38945 => Loss: 45.34904654196301265756\n",
      "Iteration 38946 => Loss: 45.34889107387218132317\n",
      "Iteration 38947 => Loss: 45.34873560700147265834\n",
      "Iteration 38948 => Loss: 45.34858014135085113594\n",
      "Iteration 38949 => Loss: 45.34842467692031675597\n",
      "Iteration 38950 => Loss: 45.34826921370986241300\n",
      "Iteration 38951 => Loss: 45.34811375171948100160\n",
      "Iteration 38952 => Loss: 45.34795829094913699464\n",
      "Iteration 38953 => Loss: 45.34780283139886591925\n",
      "Iteration 38954 => Loss: 45.34764737306862514288\n",
      "Iteration 38955 => Loss: 45.34749191595841466551\n",
      "Iteration 38956 => Loss: 45.34733646006821317087\n",
      "Iteration 38957 => Loss: 45.34718100539802776439\n",
      "Iteration 38958 => Loss: 45.34702555194783002435\n",
      "Iteration 38959 => Loss: 45.34687009971764837246\n",
      "Iteration 38960 => Loss: 45.34671464870742596531\n",
      "Iteration 38961 => Loss: 45.34655919891719122461\n",
      "Iteration 38962 => Loss: 45.34640375034689441236\n",
      "Iteration 38963 => Loss: 45.34624830299657105570\n",
      "Iteration 38964 => Loss: 45.34609285686617852207\n",
      "Iteration 38965 => Loss: 45.34593741195573812774\n",
      "Iteration 38966 => Loss: 45.34578196826521434559\n",
      "Iteration 38967 => Loss: 45.34562652579459296476\n",
      "Iteration 38968 => Loss: 45.34547108454387398524\n",
      "Iteration 38969 => Loss: 45.34531564451305030161\n",
      "Iteration 38970 => Loss: 45.34516020570212901930\n",
      "Iteration 38971 => Loss: 45.34500476811107461117\n",
      "Iteration 38972 => Loss: 45.34484933173987997179\n",
      "Iteration 38973 => Loss: 45.34469389658852378489\n",
      "Iteration 38974 => Loss: 45.34453846265706289387\n",
      "Iteration 38975 => Loss: 45.34438302994540492818\n",
      "Iteration 38976 => Loss: 45.34422759845357830955\n",
      "Iteration 38977 => Loss: 45.34407216818157593252\n",
      "Iteration 38978 => Loss: 45.34391673912939069169\n",
      "Iteration 38979 => Loss: 45.34376131129700127076\n",
      "Iteration 38980 => Loss: 45.34360588468437924803\n",
      "Iteration 38981 => Loss: 45.34345045929156725606\n",
      "Iteration 38982 => Loss: 45.34329503511849424058\n",
      "Iteration 38983 => Loss: 45.34313961216518862329\n",
      "Iteration 38984 => Loss: 45.34298419043165040421\n",
      "Iteration 38985 => Loss: 45.34282876991783695075\n",
      "Iteration 38986 => Loss: 45.34267335062377668464\n",
      "Iteration 38987 => Loss: 45.34251793254944828959\n",
      "Iteration 38988 => Loss: 45.34236251569479492218\n",
      "Iteration 38989 => Loss: 45.34220710005985921498\n",
      "Iteration 38990 => Loss: 45.34205168564460564085\n",
      "Iteration 38991 => Loss: 45.34189627244906972692\n",
      "Iteration 38992 => Loss: 45.34174086047319462978\n",
      "Iteration 38993 => Loss: 45.34158544971695903314\n",
      "Iteration 38994 => Loss: 45.34143004018040556957\n",
      "Iteration 38995 => Loss: 45.34127463186351292279\n",
      "Iteration 38996 => Loss: 45.34111922476621714395\n",
      "Iteration 38997 => Loss: 45.34096381888856086562\n",
      "Iteration 38998 => Loss: 45.34080841423052277150\n",
      "Iteration 38999 => Loss: 45.34065301079210996704\n",
      "Iteration 39000 => Loss: 45.34049760857328692509\n",
      "Iteration 39001 => Loss: 45.34034220757403943480\n",
      "Iteration 39002 => Loss: 45.34018680779437460160\n",
      "Iteration 39003 => Loss: 45.34003140923429242548\n",
      "Iteration 39004 => Loss: 45.33987601189375737931\n",
      "Iteration 39005 => Loss: 45.33972061577277656852\n",
      "Iteration 39006 => Loss: 45.33956522087132157139\n",
      "Iteration 39007 => Loss: 45.33940982718941370422\n",
      "Iteration 39008 => Loss: 45.33925443472703165071\n",
      "Iteration 39009 => Loss: 45.33909904348416120001\n",
      "Iteration 39010 => Loss: 45.33894365346078814127\n",
      "Iteration 39011 => Loss: 45.33878826465689826364\n",
      "Iteration 39012 => Loss: 45.33863287707250577796\n",
      "Iteration 39013 => Loss: 45.33847749070756805168\n",
      "Iteration 39014 => Loss: 45.33832210556211350649\n",
      "Iteration 39015 => Loss: 45.33816672163609950985\n",
      "Iteration 39016 => Loss: 45.33801133892954027260\n",
      "Iteration 39017 => Loss: 45.33785595744242158389\n",
      "Iteration 39018 => Loss: 45.33770057717470081116\n",
      "Iteration 39019 => Loss: 45.33754519812642769239\n",
      "Iteration 39020 => Loss: 45.33738982029755959502\n",
      "Iteration 39021 => Loss: 45.33723444368806809734\n",
      "Iteration 39022 => Loss: 45.33707906829798162107\n",
      "Iteration 39023 => Loss: 45.33692369412725042821\n",
      "Iteration 39024 => Loss: 45.33676832117589583504\n",
      "Iteration 39025 => Loss: 45.33661294944391073614\n",
      "Iteration 39026 => Loss: 45.33645757893127381521\n",
      "Iteration 39027 => Loss: 45.33630220963799217770\n",
      "Iteration 39028 => Loss: 45.33614684156401608561\n",
      "Iteration 39029 => Loss: 45.33599147470937396065\n",
      "Iteration 39030 => Loss: 45.33583610907403738111\n",
      "Iteration 39031 => Loss: 45.33568074465798503070\n",
      "Iteration 39032 => Loss: 45.33552538146123822571\n",
      "Iteration 39033 => Loss: 45.33537001948378275529\n",
      "Iteration 39034 => Loss: 45.33521465872557598686\n",
      "Iteration 39035 => Loss: 45.33505929918666055300\n",
      "Iteration 39036 => Loss: 45.33490394086697961029\n",
      "Iteration 39037 => Loss: 45.33474858376655447501\n",
      "Iteration 39038 => Loss: 45.33459322788536383086\n",
      "Iteration 39039 => Loss: 45.33443787322337925616\n",
      "Iteration 39040 => Loss: 45.33428251978063627803\n",
      "Iteration 39041 => Loss: 45.33412716755708515848\n",
      "Iteration 39042 => Loss: 45.33397181655272589751\n",
      "Iteration 39043 => Loss: 45.33381646676755138969\n",
      "Iteration 39044 => Loss: 45.33366111820156163503\n",
      "Iteration 39045 => Loss: 45.33350577085474242267\n",
      "Iteration 39046 => Loss: 45.33335042472708664718\n",
      "Iteration 39047 => Loss: 45.33319507981857299228\n",
      "Iteration 39048 => Loss: 45.33303973612917303626\n",
      "Iteration 39049 => Loss: 45.33288439365891520083\n",
      "Iteration 39050 => Loss: 45.33272905240779238056\n",
      "Iteration 39051 => Loss: 45.33257371237578325918\n",
      "Iteration 39052 => Loss: 45.33241837356284520411\n",
      "Iteration 39053 => Loss: 45.33226303596903505877\n",
      "Iteration 39054 => Loss: 45.33210769959426755804\n",
      "Iteration 39055 => Loss: 45.33195236443859954534\n",
      "Iteration 39056 => Loss: 45.33179703050198128267\n",
      "Iteration 39057 => Loss: 45.33164169778441987546\n",
      "Iteration 39058 => Loss: 45.33148636628590111286\n",
      "Iteration 39059 => Loss: 45.33133103600641788944\n",
      "Iteration 39060 => Loss: 45.33117570694597731062\n",
      "Iteration 39061 => Loss: 45.33102037910450121672\n",
      "Iteration 39062 => Loss: 45.33086505248206066199\n",
      "Iteration 39063 => Loss: 45.33070972707862722473\n",
      "Iteration 39064 => Loss: 45.33055440289415827237\n",
      "Iteration 39065 => Loss: 45.33039907992868933206\n",
      "Iteration 39066 => Loss: 45.33024375818215645495\n",
      "Iteration 39067 => Loss: 45.33008843765458806274\n",
      "Iteration 39068 => Loss: 45.32993311834598415544\n",
      "Iteration 39069 => Loss: 45.32977780025630210048\n",
      "Iteration 39070 => Loss: 45.32962248338555610871\n",
      "Iteration 39071 => Loss: 45.32946716773372486387\n",
      "Iteration 39072 => Loss: 45.32931185330081547136\n",
      "Iteration 39073 => Loss: 45.32915654008677819320\n",
      "Iteration 39074 => Loss: 45.32900122809164145110\n",
      "Iteration 39075 => Loss: 45.32884591731539103421\n",
      "Iteration 39076 => Loss: 45.32869060775800562624\n",
      "Iteration 39077 => Loss: 45.32853529941949233262\n",
      "Iteration 39078 => Loss: 45.32837999229980141536\n",
      "Iteration 39079 => Loss: 45.32822468639901813958\n",
      "Iteration 39080 => Loss: 45.32806938171699329132\n",
      "Iteration 39081 => Loss: 45.32791407825384055741\n",
      "Iteration 39082 => Loss: 45.32775877600947467272\n",
      "Iteration 39083 => Loss: 45.32760347498393116439\n",
      "Iteration 39084 => Loss: 45.32744817517716029442\n",
      "Iteration 39085 => Loss: 45.32729287658919048454\n",
      "Iteration 39086 => Loss: 45.32713757921999331302\n",
      "Iteration 39087 => Loss: 45.32698228306956167444\n",
      "Iteration 39088 => Loss: 45.32682698813786714709\n",
      "Iteration 39089 => Loss: 45.32667169442493815268\n",
      "Iteration 39090 => Loss: 45.32651640193075337493\n",
      "Iteration 39091 => Loss: 45.32636111065529860298\n",
      "Iteration 39092 => Loss: 45.32620582059855252055\n",
      "Iteration 39093 => Loss: 45.32605053176049381136\n",
      "Iteration 39094 => Loss: 45.32589524414114379169\n",
      "Iteration 39095 => Loss: 45.32573995774050246155\n",
      "Iteration 39096 => Loss: 45.32558467255853429378\n",
      "Iteration 39097 => Loss: 45.32542938859523218298\n",
      "Iteration 39098 => Loss: 45.32527410585058902370\n",
      "Iteration 39099 => Loss: 45.32511882432457639425\n",
      "Iteration 39100 => Loss: 45.32496354401724403260\n",
      "Iteration 39101 => Loss: 45.32480826492852798992\n",
      "Iteration 39102 => Loss: 45.32465298705841405535\n",
      "Iteration 39103 => Loss: 45.32449771040693775603\n",
      "Iteration 39104 => Loss: 45.32434243497404935397\n",
      "Iteration 39105 => Loss: 45.32418716075977727087\n",
      "Iteration 39106 => Loss: 45.32403188776405755789\n",
      "Iteration 39107 => Loss: 45.32387661598693284759\n",
      "Iteration 39108 => Loss: 45.32372134542836050741\n",
      "Iteration 39109 => Loss: 45.32356607608835474821\n",
      "Iteration 39110 => Loss: 45.32341080796689425370\n",
      "Iteration 39111 => Loss: 45.32325554106396481302\n",
      "Iteration 39112 => Loss: 45.32310027537954510990\n",
      "Iteration 39113 => Loss: 45.32294501091368488233\n",
      "Iteration 39114 => Loss: 45.32278974766628465431\n",
      "Iteration 39115 => Loss: 45.32263448563740126929\n",
      "Iteration 39116 => Loss: 45.32247922482701341096\n",
      "Iteration 39117 => Loss: 45.32232396523507844677\n",
      "Iteration 39118 => Loss: 45.32216870686165322013\n",
      "Iteration 39119 => Loss: 45.32201344970666667678\n",
      "Iteration 39120 => Loss: 45.32185819377014723841\n",
      "Iteration 39121 => Loss: 45.32170293905205227247\n",
      "Iteration 39122 => Loss: 45.32154768555237467353\n",
      "Iteration 39123 => Loss: 45.32139243327112865245\n",
      "Iteration 39124 => Loss: 45.32123718220831420922\n",
      "Iteration 39125 => Loss: 45.32108193236386739500\n",
      "Iteration 39126 => Loss: 45.32092668373784505320\n",
      "Iteration 39127 => Loss: 45.32077143633019744584\n",
      "Iteration 39128 => Loss: 45.32061619014090325663\n",
      "Iteration 39129 => Loss: 45.32046094516999801272\n",
      "Iteration 39130 => Loss: 45.32030570141741776524\n",
      "Iteration 39131 => Loss: 45.32015045888321225220\n",
      "Iteration 39132 => Loss: 45.31999521756733884104\n",
      "Iteration 39133 => Loss: 45.31983997746976911003\n",
      "Iteration 39134 => Loss: 45.31968473859053858632\n",
      "Iteration 39135 => Loss: 45.31952950092959753192\n",
      "Iteration 39136 => Loss: 45.31937426448698147396\n",
      "Iteration 39137 => Loss: 45.31921902926261935818\n",
      "Iteration 39138 => Loss: 45.31906379525655381713\n",
      "Iteration 39139 => Loss: 45.31890856246874221824\n",
      "Iteration 39140 => Loss: 45.31875333089921298324\n",
      "Iteration 39141 => Loss: 45.31859810054792347955\n",
      "Iteration 39142 => Loss: 45.31844287141485239090\n",
      "Iteration 39143 => Loss: 45.31828764350002103356\n",
      "Iteration 39144 => Loss: 45.31813241680340098583\n",
      "Iteration 39145 => Loss: 45.31797719132502777484\n",
      "Iteration 39146 => Loss: 45.31782196706483745174\n",
      "Iteration 39147 => Loss: 45.31766674402283712197\n",
      "Iteration 39148 => Loss: 45.31751152219901968010\n",
      "Iteration 39149 => Loss: 45.31735630159336380984\n",
      "Iteration 39150 => Loss: 45.31720108220588372205\n",
      "Iteration 39151 => Loss: 45.31704586403655810045\n",
      "Iteration 39152 => Loss: 45.31689064708538694504\n",
      "Iteration 39153 => Loss: 45.31673543135233472867\n",
      "Iteration 39154 => Loss: 45.31658021683739434593\n",
      "Iteration 39155 => Loss: 45.31642500354058711309\n",
      "Iteration 39156 => Loss: 45.31626979146188460845\n",
      "Iteration 39157 => Loss: 45.31611458060127972658\n",
      "Iteration 39158 => Loss: 45.31595937095875825662\n",
      "Iteration 39159 => Loss: 45.31580416253432019857\n",
      "Iteration 39160 => Loss: 45.31564895532793713073\n",
      "Iteration 39161 => Loss: 45.31549374933961615852\n",
      "Iteration 39162 => Loss: 45.31533854456935017652\n",
      "Iteration 39163 => Loss: 45.31518334101712497386\n",
      "Iteration 39164 => Loss: 45.31502813868291923427\n",
      "Iteration 39165 => Loss: 45.31487293756672585232\n",
      "Iteration 39166 => Loss: 45.31471773766857324972\n",
      "Iteration 39167 => Loss: 45.31456253898839037220\n",
      "Iteration 39168 => Loss: 45.31440734152621985231\n",
      "Iteration 39169 => Loss: 45.31425214528201195208\n",
      "Iteration 39170 => Loss: 45.31409695025578088234\n",
      "Iteration 39171 => Loss: 45.31394175644752664311\n",
      "Iteration 39172 => Loss: 45.31378656385721370725\n",
      "Iteration 39173 => Loss: 45.31363137248483496933\n",
      "Iteration 39174 => Loss: 45.31347618233041174562\n",
      "Iteration 39175 => Loss: 45.31332099339389429815\n",
      "Iteration 39176 => Loss: 45.31316580567531104862\n",
      "Iteration 39177 => Loss: 45.31301061917461936446\n",
      "Iteration 39178 => Loss: 45.31285543389181924567\n",
      "Iteration 39179 => Loss: 45.31270024982691069226\n",
      "Iteration 39180 => Loss: 45.31254506697987238795\n",
      "Iteration 39181 => Loss: 45.31238988535069722730\n",
      "Iteration 39182 => Loss: 45.31223470493939942116\n",
      "Iteration 39183 => Loss: 45.31207952574591502071\n",
      "Iteration 39184 => Loss: 45.31192434777029376392\n",
      "Iteration 39185 => Loss: 45.31176917101252143993\n",
      "Iteration 39186 => Loss: 45.31161399547254120534\n",
      "Iteration 39187 => Loss: 45.31145882115037437643\n",
      "Iteration 39188 => Loss: 45.31130364804602805862\n",
      "Iteration 39189 => Loss: 45.31114847615941698677\n",
      "Iteration 39190 => Loss: 45.31099330549064774232\n",
      "Iteration 39191 => Loss: 45.31083813603959953298\n",
      "Iteration 39192 => Loss: 45.31068296780634341303\n",
      "Iteration 39193 => Loss: 45.31052780079083674991\n",
      "Iteration 39194 => Loss: 45.31037263499307243819\n",
      "Iteration 39195 => Loss: 45.31021747041304337245\n",
      "Iteration 39196 => Loss: 45.31006230705074244725\n",
      "Iteration 39197 => Loss: 45.30990714490614124088\n",
      "Iteration 39198 => Loss: 45.30975198397921843707\n",
      "Iteration 39199 => Loss: 45.30959682427003798466\n",
      "Iteration 39200 => Loss: 45.30944166577852172395\n",
      "Iteration 39201 => Loss: 45.30928650850468386579\n",
      "Iteration 39202 => Loss: 45.30913135244851019934\n",
      "Iteration 39203 => Loss: 45.30897619761000072458\n",
      "Iteration 39204 => Loss: 45.30882104398914123067\n",
      "Iteration 39205 => Loss: 45.30866589158591750675\n",
      "Iteration 39206 => Loss: 45.30851074040030113110\n",
      "Iteration 39207 => Loss: 45.30835559043232052545\n",
      "Iteration 39208 => Loss: 45.30820044168194726808\n",
      "Iteration 39209 => Loss: 45.30804529414916004271\n",
      "Iteration 39210 => Loss: 45.30789014783397306019\n",
      "Iteration 39211 => Loss: 45.30773500273637210967\n",
      "Iteration 39212 => Loss: 45.30757985885633587486\n",
      "Iteration 39213 => Loss: 45.30742471619386435577\n",
      "Iteration 39214 => Loss: 45.30726957474894334155\n",
      "Iteration 39215 => Loss: 45.30711443452156572675\n",
      "Iteration 39216 => Loss: 45.30695929551170308969\n",
      "Iteration 39217 => Loss: 45.30680415771937674663\n",
      "Iteration 39218 => Loss: 45.30664902114457248672\n",
      "Iteration 39219 => Loss: 45.30649388578726188825\n",
      "Iteration 39220 => Loss: 45.30633875164745205666\n",
      "Iteration 39221 => Loss: 45.30618361872510035937\n",
      "Iteration 39222 => Loss: 45.30602848702024942895\n",
      "Iteration 39223 => Loss: 45.30587335653287084369\n",
      "Iteration 39224 => Loss: 45.30571822726293618189\n",
      "Iteration 39225 => Loss: 45.30556309921045254896\n",
      "Iteration 39226 => Loss: 45.30540797237539152320\n",
      "Iteration 39227 => Loss: 45.30525284675776731547\n",
      "Iteration 39228 => Loss: 45.30509772235756571490\n",
      "Iteration 39229 => Loss: 45.30494259917477251065\n",
      "Iteration 39230 => Loss: 45.30478747720937349186\n",
      "Iteration 39231 => Loss: 45.30463235646135444767\n",
      "Iteration 39232 => Loss: 45.30447723693071537809\n",
      "Iteration 39233 => Loss: 45.30432211861746338855\n",
      "Iteration 39234 => Loss: 45.30416700152154874104\n",
      "Iteration 39235 => Loss: 45.30401188564300696271\n",
      "Iteration 39236 => Loss: 45.30385677098181673728\n",
      "Iteration 39237 => Loss: 45.30370165753791411589\n",
      "Iteration 39238 => Loss: 45.30354654531136304740\n",
      "Iteration 39239 => Loss: 45.30339143430213511010\n",
      "Iteration 39240 => Loss: 45.30323632451018056599\n",
      "Iteration 39241 => Loss: 45.30308121593554915307\n",
      "Iteration 39242 => Loss: 45.30292610857818402792\n",
      "Iteration 39243 => Loss: 45.30277100243809229596\n",
      "Iteration 39244 => Loss: 45.30261589751526685177\n",
      "Iteration 39245 => Loss: 45.30246079380969348449\n",
      "Iteration 39246 => Loss: 45.30230569132138640498\n",
      "Iteration 39247 => Loss: 45.30215059005029587524\n",
      "Iteration 39248 => Loss: 45.30199548999643610614\n",
      "Iteration 39249 => Loss: 45.30184039115978578138\n",
      "Iteration 39250 => Loss: 45.30168529354034490098\n",
      "Iteration 39251 => Loss: 45.30153019713812767577\n",
      "Iteration 39252 => Loss: 45.30137510195306305150\n",
      "Iteration 39253 => Loss: 45.30122000798520076614\n",
      "Iteration 39254 => Loss: 45.30106491523450529257\n",
      "Iteration 39255 => Loss: 45.30090982370095531451\n",
      "Iteration 39256 => Loss: 45.30075473338457214822\n",
      "Iteration 39257 => Loss: 45.30059964428533447744\n",
      "Iteration 39258 => Loss: 45.30044455640319966960\n",
      "Iteration 39259 => Loss: 45.30028946973821746269\n",
      "Iteration 39260 => Loss: 45.30013438429031680243\n",
      "Iteration 39261 => Loss: 45.29997930005952611054\n",
      "Iteration 39262 => Loss: 45.29982421704584538702\n",
      "Iteration 39263 => Loss: 45.29966913524923910472\n",
      "Iteration 39264 => Loss: 45.29951405466970015823\n",
      "Iteration 39265 => Loss: 45.29935897530724275839\n",
      "Iteration 39266 => Loss: 45.29920389716183137807\n",
      "Iteration 39267 => Loss: 45.29904882023346601727\n",
      "Iteration 39268 => Loss: 45.29889374452211825428\n",
      "Iteration 39269 => Loss: 45.29873867002782361624\n",
      "Iteration 39270 => Loss: 45.29858359675052525972\n",
      "Iteration 39271 => Loss: 45.29842852469024450102\n",
      "Iteration 39272 => Loss: 45.29827345384695291841\n",
      "Iteration 39273 => Loss: 45.29811838422065761733\n",
      "Iteration 39274 => Loss: 45.29796331581133728150\n",
      "Iteration 39275 => Loss: 45.29780824861898480549\n",
      "Iteration 39276 => Loss: 45.29765318264361440015\n",
      "Iteration 39277 => Loss: 45.29749811788514790578\n",
      "Iteration 39278 => Loss: 45.29734305434364216580\n",
      "Iteration 39279 => Loss: 45.29718799201906165308\n",
      "Iteration 39280 => Loss: 45.29703293091142768390\n",
      "Iteration 39281 => Loss: 45.29687787102068341483\n",
      "Iteration 39282 => Loss: 45.29672281234685016216\n",
      "Iteration 39283 => Loss: 45.29656775488990660961\n",
      "Iteration 39284 => Loss: 45.29641269864983854632\n",
      "Iteration 39285 => Loss: 45.29625764362664597229\n",
      "Iteration 39286 => Loss: 45.29610258982032888753\n",
      "Iteration 39287 => Loss: 45.29594753723085176489\n",
      "Iteration 39288 => Loss: 45.29579248585822170980\n",
      "Iteration 39289 => Loss: 45.29563743570242451142\n",
      "Iteration 39290 => Loss: 45.29548238676347438059\n",
      "Iteration 39291 => Loss: 45.29532733904130736846\n",
      "Iteration 39292 => Loss: 45.29517229253597321303\n",
      "Iteration 39293 => Loss: 45.29501724724741507089\n",
      "Iteration 39294 => Loss: 45.29486220317565425830\n",
      "Iteration 39295 => Loss: 45.29470716032068366985\n",
      "Iteration 39296 => Loss: 45.29455211868245356754\n",
      "Iteration 39297 => Loss: 45.29439707826100658394\n",
      "Iteration 39298 => Loss: 45.29424203905629298106\n",
      "Iteration 39299 => Loss: 45.29408700106833407517\n",
      "Iteration 39300 => Loss: 45.29393196429710144457\n",
      "Iteration 39301 => Loss: 45.29377692874256666755\n",
      "Iteration 39302 => Loss: 45.29362189440476527125\n",
      "Iteration 39303 => Loss: 45.29346686128366883395\n",
      "Iteration 39304 => Loss: 45.29331182937925603937\n",
      "Iteration 39305 => Loss: 45.29315679869151978210\n",
      "Iteration 39306 => Loss: 45.29300176922046716754\n",
      "Iteration 39307 => Loss: 45.29284674096606977400\n",
      "Iteration 39308 => Loss: 45.29269171392832049605\n",
      "Iteration 39309 => Loss: 45.29253668810721933369\n",
      "Iteration 39310 => Loss: 45.29238166350276628691\n",
      "Iteration 39311 => Loss: 45.29222664011491872316\n",
      "Iteration 39312 => Loss: 45.29207161794369795871\n",
      "Iteration 39313 => Loss: 45.29191659698909688814\n",
      "Iteration 39314 => Loss: 45.29176157725105866803\n",
      "Iteration 39315 => Loss: 45.29160655872961882551\n",
      "Iteration 39316 => Loss: 45.29145154142476314973\n",
      "Iteration 39317 => Loss: 45.29129652533647032442\n",
      "Iteration 39318 => Loss: 45.29114151046475456042\n",
      "Iteration 39319 => Loss: 45.29098649680955901431\n",
      "Iteration 39320 => Loss: 45.29083148437092631866\n",
      "Iteration 39321 => Loss: 45.29067647314882094634\n",
      "Iteration 39322 => Loss: 45.29052146314321447562\n",
      "Iteration 39323 => Loss: 45.29036645435412822280\n",
      "Iteration 39324 => Loss: 45.29021144678156929331\n",
      "Iteration 39325 => Loss: 45.29005644042546663286\n",
      "Iteration 39326 => Loss: 45.28990143528585576860\n",
      "Iteration 39327 => Loss: 45.28974643136272248967\n",
      "Iteration 39328 => Loss: 45.28959142865603837436\n",
      "Iteration 39329 => Loss: 45.28943642716581052809\n",
      "Iteration 39330 => Loss: 45.28928142689204605631\n",
      "Iteration 39331 => Loss: 45.28912642783468811558\n",
      "Iteration 39332 => Loss: 45.28897142999377223305\n",
      "Iteration 39333 => Loss: 45.28881643336926288157\n",
      "Iteration 39334 => Loss: 45.28866143796116006115\n",
      "Iteration 39335 => Loss: 45.28850644376945666636\n",
      "Iteration 39336 => Loss: 45.28835145079414559177\n",
      "Iteration 39337 => Loss: 45.28819645903519131025\n",
      "Iteration 39338 => Loss: 45.28804146849262934893\n",
      "Iteration 39339 => Loss: 45.28788647916640996982\n",
      "Iteration 39340 => Loss: 45.28773149105652606750\n",
      "Iteration 39341 => Loss: 45.28757650416300606366\n",
      "Iteration 39342 => Loss: 45.28742151848582153661\n",
      "Iteration 39343 => Loss: 45.28726653402492985379\n",
      "Iteration 39344 => Loss: 45.28711155078035943689\n",
      "Iteration 39345 => Loss: 45.28695656875208186420\n",
      "Iteration 39346 => Loss: 45.28680158794010424117\n",
      "Iteration 39347 => Loss: 45.28664660834439814607\n",
      "Iteration 39348 => Loss: 45.28649162996497068434\n",
      "Iteration 39349 => Loss: 45.28633665280182185597\n",
      "Iteration 39350 => Loss: 45.28618167685490192298\n",
      "Iteration 39351 => Loss: 45.28602670212423220164\n",
      "Iteration 39352 => Loss: 45.28587172860980558653\n",
      "Iteration 39353 => Loss: 45.28571675631157233965\n",
      "Iteration 39354 => Loss: 45.28556178522958219901\n",
      "Iteration 39355 => Loss: 45.28540681536379963745\n",
      "Iteration 39356 => Loss: 45.28525184671418912785\n",
      "Iteration 39357 => Loss: 45.28509687928079330277\n",
      "Iteration 39358 => Loss: 45.28494191306354821336\n",
      "Iteration 39359 => Loss: 45.28478694806247517590\n",
      "Iteration 39360 => Loss: 45.28463198427757419040\n",
      "Iteration 39361 => Loss: 45.28447702170880972972\n",
      "Iteration 39362 => Loss: 45.28432206035618889928\n",
      "Iteration 39363 => Loss: 45.28416710021967617195\n",
      "Iteration 39364 => Loss: 45.28401214129929996943\n",
      "Iteration 39365 => Loss: 45.28385718359503187003\n",
      "Iteration 39366 => Loss: 45.28370222710687187373\n",
      "Iteration 39367 => Loss: 45.28354727183479155883\n",
      "Iteration 39368 => Loss: 45.28339231777877671448\n",
      "Iteration 39369 => Loss: 45.28323736493884865695\n",
      "Iteration 39370 => Loss: 45.28308241331499317539\n",
      "Iteration 39371 => Loss: 45.28292746290716763724\n",
      "Iteration 39372 => Loss: 45.28277251371542178049\n",
      "Iteration 39373 => Loss: 45.28261756573967034001\n",
      "Iteration 39374 => Loss: 45.28246261897997015922\n",
      "Iteration 39375 => Loss: 45.28230767343627150012\n",
      "Iteration 39376 => Loss: 45.28215272910856725730\n",
      "Iteration 39377 => Loss: 45.28199778599687164160\n",
      "Iteration 39378 => Loss: 45.28184284410114912589\n",
      "Iteration 39379 => Loss: 45.28168790342141392102\n",
      "Iteration 39380 => Loss: 45.28153296395763760529\n",
      "Iteration 39381 => Loss: 45.28137802570983438954\n",
      "Iteration 39382 => Loss: 45.28122308867796164122\n",
      "Iteration 39383 => Loss: 45.28106815286202646575\n",
      "Iteration 39384 => Loss: 45.28091321826201465228\n",
      "Iteration 39385 => Loss: 45.28075828487793330623\n",
      "Iteration 39386 => Loss: 45.28060335270974690047\n",
      "Iteration 39387 => Loss: 45.28044842175748385671\n",
      "Iteration 39388 => Loss: 45.28029349202109443695\n",
      "Iteration 39389 => Loss: 45.28013856350059285205\n",
      "Iteration 39390 => Loss: 45.27998363619596489116\n",
      "Iteration 39391 => Loss: 45.27982871010718213256\n",
      "Iteration 39392 => Loss: 45.27967378523428010340\n",
      "Iteration 39393 => Loss: 45.27951886157717353854\n",
      "Iteration 39394 => Loss: 45.27936393913593349225\n",
      "Iteration 39395 => Loss: 45.27920901791051022656\n",
      "Iteration 39396 => Loss: 45.27905409790090374145\n",
      "Iteration 39397 => Loss: 45.27889917910709272064\n",
      "Iteration 39398 => Loss: 45.27874426152908426957\n",
      "Iteration 39399 => Loss: 45.27858934516684286109\n",
      "Iteration 39400 => Loss: 45.27843443002041112777\n",
      "Iteration 39401 => Loss: 45.27827951608971801534\n",
      "Iteration 39402 => Loss: 45.27812460337481326178\n",
      "Iteration 39403 => Loss: 45.27796969187561870740\n",
      "Iteration 39404 => Loss: 45.27781478159217698476\n",
      "Iteration 39405 => Loss: 45.27765987252445967215\n",
      "Iteration 39406 => Loss: 45.27750496467245966414\n",
      "Iteration 39407 => Loss: 45.27735005803615564446\n",
      "Iteration 39408 => Loss: 45.27719515261556892938\n",
      "Iteration 39409 => Loss: 45.27704024841068530804\n",
      "Iteration 39410 => Loss: 45.27688534542145504247\n",
      "Iteration 39411 => Loss: 45.27673044364790655436\n",
      "Iteration 39412 => Loss: 45.27657554309001852744\n",
      "Iteration 39413 => Loss: 45.27642064374776964542\n",
      "Iteration 39414 => Loss: 45.27626574562118122458\n",
      "Iteration 39415 => Loss: 45.27611084871023194864\n",
      "Iteration 39416 => Loss: 45.27595595301487207962\n",
      "Iteration 39417 => Loss: 45.27580105853515135550\n",
      "Iteration 39418 => Loss: 45.27564616527104135457\n",
      "Iteration 39419 => Loss: 45.27549127322249233885\n",
      "Iteration 39420 => Loss: 45.27533638238953983546\n",
      "Iteration 39421 => Loss: 45.27518149277218384441\n",
      "Iteration 39422 => Loss: 45.27502660437037462771\n",
      "Iteration 39423 => Loss: 45.27487171718412639621\n",
      "Iteration 39424 => Loss: 45.27471683121342493905\n",
      "Iteration 39425 => Loss: 45.27456194645824893996\n",
      "Iteration 39426 => Loss: 45.27440706291861971522\n",
      "Iteration 39427 => Loss: 45.27425218059450173769\n",
      "Iteration 39428 => Loss: 45.27409729948588079651\n",
      "Iteration 39429 => Loss: 45.27394241959278531340\n",
      "Iteration 39430 => Loss: 45.27378754091514423408\n",
      "Iteration 39431 => Loss: 45.27363266345300019111\n",
      "Iteration 39432 => Loss: 45.27347778720635318450\n",
      "Iteration 39433 => Loss: 45.27332291217511794912\n",
      "Iteration 39434 => Loss: 45.27316803835935843381\n",
      "Iteration 39435 => Loss: 45.27301316575903911144\n",
      "Iteration 39436 => Loss: 45.27285829437413866572\n",
      "Iteration 39437 => Loss: 45.27270342420469262379\n",
      "Iteration 39438 => Loss: 45.27254855525063703681\n",
      "Iteration 39439 => Loss: 45.27239368751198611562\n",
      "Iteration 39440 => Loss: 45.27223882098871854396\n",
      "Iteration 39441 => Loss: 45.27208395568084853267\n",
      "Iteration 39442 => Loss: 45.27192909158834766004\n",
      "Iteration 39443 => Loss: 45.27177422871121592607\n",
      "Iteration 39444 => Loss: 45.27161936704943911991\n",
      "Iteration 39445 => Loss: 45.27146450660301013613\n",
      "Iteration 39446 => Loss: 45.27130964737192897474\n",
      "Iteration 39447 => Loss: 45.27115478935616010858\n",
      "Iteration 39448 => Loss: 45.27099993255569643225\n",
      "Iteration 39449 => Loss: 45.27084507697057347286\n",
      "Iteration 39450 => Loss: 45.27069022260072017616\n",
      "Iteration 39451 => Loss: 45.27053536944617206927\n",
      "Iteration 39452 => Loss: 45.27038051750689362507\n",
      "Iteration 39453 => Loss: 45.27022566678288484354\n",
      "Iteration 39454 => Loss: 45.27007081727415993555\n",
      "Iteration 39455 => Loss: 45.26991596898066916310\n",
      "Iteration 39456 => Loss: 45.26976112190241963162\n",
      "Iteration 39457 => Loss: 45.26960627603939713026\n",
      "Iteration 39458 => Loss: 45.26945143139159455359\n",
      "Iteration 39459 => Loss: 45.26929658795900479618\n",
      "Iteration 39460 => Loss: 45.26914174574162785802\n",
      "Iteration 39461 => Loss: 45.26898690473944242285\n",
      "Iteration 39462 => Loss: 45.26883206495242006895\n",
      "Iteration 39463 => Loss: 45.26867722638059632345\n",
      "Iteration 39464 => Loss: 45.26852238902394276465\n",
      "Iteration 39465 => Loss: 45.26836755288241675999\n",
      "Iteration 39466 => Loss: 45.26821271795606094202\n",
      "Iteration 39467 => Loss: 45.26805788424483267818\n",
      "Iteration 39468 => Loss: 45.26790305174874617933\n",
      "Iteration 39469 => Loss: 45.26774822046775170747\n",
      "Iteration 39470 => Loss: 45.26759339040189189518\n",
      "Iteration 39471 => Loss: 45.26743856155109568817\n",
      "Iteration 39472 => Loss: 45.26728373391542703530\n",
      "Iteration 39473 => Loss: 45.26712890749479356600\n",
      "Iteration 39474 => Loss: 45.26697408228927343998\n",
      "Iteration 39475 => Loss: 45.26681925829878849754\n",
      "Iteration 39476 => Loss: 45.26666443552334584410\n",
      "Iteration 39477 => Loss: 45.26650961396296679595\n",
      "Iteration 39478 => Loss: 45.26635479361761582595\n",
      "Iteration 39479 => Loss: 45.26619997448726451239\n",
      "Iteration 39480 => Loss: 45.26604515657196259326\n",
      "Iteration 39481 => Loss: 45.26589033987162480344\n",
      "Iteration 39482 => Loss: 45.26573552438631509176\n",
      "Iteration 39483 => Loss: 45.26558071011595529853\n",
      "Iteration 39484 => Loss: 45.26542589706060226717\n",
      "Iteration 39485 => Loss: 45.26527108522019204884\n",
      "Iteration 39486 => Loss: 45.26511627459473885438\n",
      "Iteration 39487 => Loss: 45.26496146518424268379\n",
      "Iteration 39488 => Loss: 45.26480665698868222080\n",
      "Iteration 39489 => Loss: 45.26465185000801483284\n",
      "Iteration 39490 => Loss: 45.26449704424231157418\n",
      "Iteration 39491 => Loss: 45.26434223969149428513\n",
      "Iteration 39492 => Loss: 45.26418743635559138738\n",
      "Iteration 39493 => Loss: 45.26403263423455314296\n",
      "Iteration 39494 => Loss: 45.26387783332840086814\n",
      "Iteration 39495 => Loss: 45.26372303363712035207\n",
      "Iteration 39496 => Loss: 45.26356823516069027846\n",
      "Iteration 39497 => Loss: 45.26341343789911064732\n",
      "Iteration 39498 => Loss: 45.26325864185238856408\n",
      "Iteration 39499 => Loss: 45.26310384702048850158\n",
      "Iteration 39500 => Loss: 45.26294905340341756528\n",
      "Iteration 39501 => Loss: 45.26279426100116154430\n",
      "Iteration 39502 => Loss: 45.26263946981369912237\n",
      "Iteration 39503 => Loss: 45.26248467984102319406\n",
      "Iteration 39504 => Loss: 45.26232989108314797022\n",
      "Iteration 39505 => Loss: 45.26217510354002371287\n",
      "Iteration 39506 => Loss: 45.26202031721168594913\n",
      "Iteration 39507 => Loss: 45.26186553209808494103\n",
      "Iteration 39508 => Loss: 45.26171074819924911026\n",
      "Iteration 39509 => Loss: 45.26155596551512161341\n",
      "Iteration 39510 => Loss: 45.26140118404573797761\n",
      "Iteration 39511 => Loss: 45.26124640379108399202\n",
      "Iteration 39512 => Loss: 45.26109162475111702406\n",
      "Iteration 39513 => Loss: 45.26093684692585839002\n",
      "Iteration 39514 => Loss: 45.26078207031526545734\n",
      "Iteration 39515 => Loss: 45.26062729491937375315\n",
      "Iteration 39516 => Loss: 45.26047252073815485574\n",
      "Iteration 39517 => Loss: 45.26031774777157323797\n",
      "Iteration 39518 => Loss: 45.26016297601965732156\n",
      "Iteration 39519 => Loss: 45.26000820548239289565\n",
      "Iteration 39520 => Loss: 45.25985343615975153853\n",
      "Iteration 39521 => Loss: 45.25969866805171903934\n",
      "Iteration 39522 => Loss: 45.25954390115830960895\n",
      "Iteration 39523 => Loss: 45.25938913547950193106\n",
      "Iteration 39524 => Loss: 45.25923437101529600568\n",
      "Iteration 39525 => Loss: 45.25907960776565630567\n",
      "Iteration 39526 => Loss: 45.25892484573059704189\n",
      "Iteration 39527 => Loss: 45.25877008491009689806\n",
      "Iteration 39528 => Loss: 45.25861532530413455788\n",
      "Iteration 39529 => Loss: 45.25846056691275975936\n",
      "Iteration 39530 => Loss: 45.25830580973588723737\n",
      "Iteration 39531 => Loss: 45.25815105377355962446\n",
      "Iteration 39532 => Loss: 45.25799629902574849893\n",
      "Iteration 39533 => Loss: 45.25784154549243254451\n",
      "Iteration 39534 => Loss: 45.25768679317363307746\n",
      "Iteration 39535 => Loss: 45.25753204206930035980\n",
      "Iteration 39536 => Loss: 45.25737729217944860238\n",
      "Iteration 39537 => Loss: 45.25722254350407780521\n",
      "Iteration 39538 => Loss: 45.25706779604316665200\n",
      "Iteration 39539 => Loss: 45.25691304979669382647\n",
      "Iteration 39540 => Loss: 45.25675830476466643404\n",
      "Iteration 39541 => Loss: 45.25660356094707026386\n",
      "Iteration 39542 => Loss: 45.25644881834389821051\n",
      "Iteration 39543 => Loss: 45.25629407695513606313\n",
      "Iteration 39544 => Loss: 45.25613933678076961087\n",
      "Iteration 39545 => Loss: 45.25598459782080595915\n",
      "Iteration 39546 => Loss: 45.25582986007522379168\n",
      "Iteration 39547 => Loss: 45.25567512354400889762\n",
      "Iteration 39548 => Loss: 45.25552038822715417155\n",
      "Iteration 39549 => Loss: 45.25536565412467382430\n",
      "Iteration 39550 => Loss: 45.25521092123653943418\n",
      "Iteration 39551 => Loss: 45.25505618956273679032\n",
      "Iteration 39552 => Loss: 45.25490145910322326017\n",
      "Iteration 39553 => Loss: 45.25474672985806279257\n",
      "Iteration 39554 => Loss: 45.25459200182719854411\n",
      "Iteration 39555 => Loss: 45.25443727501064472563\n",
      "Iteration 39556 => Loss: 45.25428254940835870457\n",
      "Iteration 39557 => Loss: 45.25412782502036890264\n",
      "Iteration 39558 => Loss: 45.25397310184662558186\n",
      "Iteration 39559 => Loss: 45.25381837988715716392\n",
      "Iteration 39560 => Loss: 45.25366365914194943798\n",
      "Iteration 39561 => Loss: 45.25350893961096687690\n",
      "Iteration 39562 => Loss: 45.25335422129421658610\n",
      "Iteration 39563 => Loss: 45.25319950419167724931\n",
      "Iteration 39564 => Loss: 45.25304478830336307738\n",
      "Iteration 39565 => Loss: 45.25289007362923854316\n",
      "Iteration 39566 => Loss: 45.25273536016932496295\n",
      "Iteration 39567 => Loss: 45.25258064792358680961\n",
      "Iteration 39568 => Loss: 45.25242593689203118856\n",
      "Iteration 39569 => Loss: 45.25227122707462257267\n",
      "Iteration 39570 => Loss: 45.25211651847138227822\n",
      "Iteration 39571 => Loss: 45.25196181108227477807\n",
      "Iteration 39572 => Loss: 45.25180710490730007223\n",
      "Iteration 39573 => Loss: 45.25165239994647237154\n",
      "Iteration 39574 => Loss: 45.25149769619974904344\n",
      "Iteration 39575 => Loss: 45.25134299366712298252\n",
      "Iteration 39576 => Loss: 45.25118829234858708332\n",
      "Iteration 39577 => Loss: 45.25103359224417687301\n",
      "Iteration 39578 => Loss: 45.25087889335382129730\n",
      "Iteration 39579 => Loss: 45.25072419567752746161\n",
      "Iteration 39580 => Loss: 45.25056949921531668224\n",
      "Iteration 39581 => Loss: 45.25041480396713922119\n",
      "Iteration 39582 => Loss: 45.25026010993300218388\n",
      "Iteration 39583 => Loss: 45.25010541711288425404\n",
      "Iteration 39584 => Loss: 45.24995072550680674794\n",
      "Iteration 39585 => Loss: 45.24979603511474834932\n",
      "Iteration 39586 => Loss: 45.24964134593668063644\n",
      "Iteration 39587 => Loss: 45.24948665797261071475\n",
      "Iteration 39588 => Loss: 45.24933197122249595168\n",
      "Iteration 39589 => Loss: 45.24917728568637187436\n",
      "Iteration 39590 => Loss: 45.24902260136421716652\n",
      "Iteration 39591 => Loss: 45.24886791825601761730\n",
      "Iteration 39592 => Loss: 45.24871323636175191041\n",
      "Iteration 39593 => Loss: 45.24855855568142715128\n",
      "Iteration 39594 => Loss: 45.24840387621504333993\n",
      "Iteration 39595 => Loss: 45.24824919796256494919\n",
      "Iteration 39596 => Loss: 45.24809452092399197909\n",
      "Iteration 39597 => Loss: 45.24793984509929600790\n",
      "Iteration 39598 => Loss: 45.24778517048851256277\n",
      "Iteration 39599 => Loss: 45.24763049709159901113\n",
      "Iteration 39600 => Loss: 45.24747582490854824755\n",
      "Iteration 39601 => Loss: 45.24732115393938158832\n",
      "Iteration 39602 => Loss: 45.24716648418403508458\n",
      "Iteration 39603 => Loss: 45.24701181564255847434\n",
      "Iteration 39604 => Loss: 45.24685714831488070331\n",
      "Iteration 39605 => Loss: 45.24670248220105861492\n",
      "Iteration 39606 => Loss: 45.24654781730102115489\n",
      "Iteration 39607 => Loss: 45.24639315361478253408\n",
      "Iteration 39608 => Loss: 45.24623849114235696334\n",
      "Iteration 39609 => Loss: 45.24608382988370181010\n",
      "Iteration 39610 => Loss: 45.24592916983881707438\n",
      "Iteration 39611 => Loss: 45.24577451100770275616\n",
      "Iteration 39612 => Loss: 45.24561985339034464459\n",
      "Iteration 39613 => Loss: 45.24546519698672852883\n",
      "Iteration 39614 => Loss: 45.24531054179685440886\n",
      "Iteration 39615 => Loss: 45.24515588782069386298\n",
      "Iteration 39616 => Loss: 45.24500123505824689119\n",
      "Iteration 39617 => Loss: 45.24484658350951349348\n",
      "Iteration 39618 => Loss: 45.24469193317447945901\n",
      "Iteration 39619 => Loss: 45.24453728405314478778\n",
      "Iteration 39620 => Loss: 45.24438263614545974178\n",
      "Iteration 39621 => Loss: 45.24422798945145984817\n",
      "Iteration 39622 => Loss: 45.24407334397110957980\n",
      "Iteration 39623 => Loss: 45.24391869970443735838\n",
      "Iteration 39624 => Loss: 45.24376405665137923506\n",
      "Iteration 39625 => Loss: 45.24360941481194942071\n",
      "Iteration 39626 => Loss: 45.24345477418616212617\n",
      "Iteration 39627 => Loss: 45.24330013477396050803\n",
      "Iteration 39628 => Loss: 45.24314549657538719885\n",
      "Iteration 39629 => Loss: 45.24299085959037114435\n",
      "Iteration 39630 => Loss: 45.24283622381897629339\n",
      "Iteration 39631 => Loss: 45.24268158926113869711\n",
      "Iteration 39632 => Loss: 45.24252695591685835552\n",
      "Iteration 39633 => Loss: 45.24237232378614947947\n",
      "Iteration 39634 => Loss: 45.24221769286896233098\n",
      "Iteration 39635 => Loss: 45.24206306316531822631\n",
      "Iteration 39636 => Loss: 45.24190843467522427090\n",
      "Iteration 39637 => Loss: 45.24175380739862362134\n",
      "Iteration 39638 => Loss: 45.24159918133553048847\n",
      "Iteration 39639 => Loss: 45.24144455648593776687\n",
      "Iteration 39640 => Loss: 45.24128993284981703482\n",
      "Iteration 39641 => Loss: 45.24113531042719671404\n",
      "Iteration 39642 => Loss: 45.24098068921803417197\n",
      "Iteration 39643 => Loss: 45.24082606922233651403\n",
      "Iteration 39644 => Loss: 45.24067145044008952937\n",
      "Iteration 39645 => Loss: 45.24051683287128611255\n",
      "Iteration 39646 => Loss: 45.24036221651589784187\n",
      "Iteration 39647 => Loss: 45.24020760137393892819\n",
      "Iteration 39648 => Loss: 45.24005298744538094979\n",
      "Iteration 39649 => Loss: 45.23989837473025232839\n",
      "Iteration 39650 => Loss: 45.23974376322848911514\n",
      "Iteration 39651 => Loss: 45.23958915294011262631\n",
      "Iteration 39652 => Loss: 45.23943454386512286192\n",
      "Iteration 39653 => Loss: 45.23927993600348429482\n",
      "Iteration 39654 => Loss: 45.23912532935521113586\n",
      "Iteration 39655 => Loss: 45.23897072392027496335\n",
      "Iteration 39656 => Loss: 45.23881611969867577727\n",
      "Iteration 39657 => Loss: 45.23866151669040647221\n",
      "Iteration 39658 => Loss: 45.23850691489545283730\n",
      "Iteration 39659 => Loss: 45.23835231431380066169\n",
      "Iteration 39660 => Loss: 45.23819771494543573453\n",
      "Iteration 39661 => Loss: 45.23804311679038647753\n",
      "Iteration 39662 => Loss: 45.23788851984859604727\n",
      "Iteration 39663 => Loss: 45.23773392412008576002\n",
      "Iteration 39664 => Loss: 45.23757932960481298323\n",
      "Iteration 39665 => Loss: 45.23742473630279903318\n",
      "Iteration 39666 => Loss: 45.23727014421403680444\n",
      "Iteration 39667 => Loss: 45.23711555333849787530\n",
      "Iteration 39668 => Loss: 45.23696096367618224576\n",
      "Iteration 39669 => Loss: 45.23680637522708281040\n",
      "Iteration 39670 => Loss: 45.23665178799117114750\n",
      "Iteration 39671 => Loss: 45.23649720196846146791\n",
      "Iteration 39672 => Loss: 45.23634261715893245537\n",
      "Iteration 39673 => Loss: 45.23618803356257700443\n",
      "Iteration 39674 => Loss: 45.23603345117938800968\n",
      "Iteration 39675 => Loss: 45.23587887000935836568\n",
      "Iteration 39676 => Loss: 45.23572429005246675615\n",
      "Iteration 39677 => Loss: 45.23556971130869897024\n",
      "Iteration 39678 => Loss: 45.23541513377806211338\n",
      "Iteration 39679 => Loss: 45.23526055746055618556\n",
      "Iteration 39680 => Loss: 45.23510598235614565965\n",
      "Iteration 39681 => Loss: 45.23495140846482343022\n",
      "Iteration 39682 => Loss: 45.23479683578662502441\n",
      "Iteration 39683 => Loss: 45.23464226432148649337\n",
      "Iteration 39684 => Loss: 45.23448769406938652082\n",
      "Iteration 39685 => Loss: 45.23433312503036773933\n",
      "Iteration 39686 => Loss: 45.23417855720439462175\n",
      "Iteration 39687 => Loss: 45.23402399059147427351\n",
      "Iteration 39688 => Loss: 45.23386942519159248377\n",
      "Iteration 39689 => Loss: 45.23371486100471372538\n",
      "Iteration 39690 => Loss: 45.23356029803083799834\n",
      "Iteration 39691 => Loss: 45.23340573626998661894\n",
      "Iteration 39692 => Loss: 45.23325117572210274375\n",
      "Iteration 39693 => Loss: 45.23309661638721479449\n",
      "Iteration 39694 => Loss: 45.23294205826532987658\n",
      "Iteration 39695 => Loss: 45.23278750135637693575\n",
      "Iteration 39696 => Loss: 45.23263294566037728828\n",
      "Iteration 39697 => Loss: 45.23247839117731672332\n",
      "Iteration 39698 => Loss: 45.23232383790720945171\n",
      "Iteration 39699 => Loss: 45.23216928585003415719\n",
      "Iteration 39700 => Loss: 45.23201473500576241804\n",
      "Iteration 39701 => Loss: 45.23186018537438712883\n",
      "Iteration 39702 => Loss: 45.23170563695592960585\n",
      "Iteration 39703 => Loss: 45.23155108975034721652\n",
      "Iteration 39704 => Loss: 45.23139654375763996086\n",
      "Iteration 39705 => Loss: 45.23124199897782204971\n",
      "Iteration 39706 => Loss: 45.23108745541085085051\n",
      "Iteration 39707 => Loss: 45.23093291305671215241\n",
      "Iteration 39708 => Loss: 45.23077837191543437712\n",
      "Iteration 39709 => Loss: 45.23062383198698910292\n",
      "Iteration 39710 => Loss: 45.23046929327135501353\n",
      "Iteration 39711 => Loss: 45.23031475576854631981\n",
      "Iteration 39712 => Loss: 45.23016021947850617835\n",
      "Iteration 39713 => Loss: 45.23000568440129143255\n",
      "Iteration 39714 => Loss: 45.22985115053685234443\n",
      "Iteration 39715 => Loss: 45.22969661788519601942\n",
      "Iteration 39716 => Loss: 45.22954208644628693037\n",
      "Iteration 39717 => Loss: 45.22938755622013928814\n",
      "Iteration 39718 => Loss: 45.22923302720672467103\n",
      "Iteration 39719 => Loss: 45.22907849940606439532\n",
      "Iteration 39720 => Loss: 45.22892397281813003929\n",
      "Iteration 39721 => Loss: 45.22876944744289318123\n",
      "Iteration 39722 => Loss: 45.22861492328036803201\n",
      "Iteration 39723 => Loss: 45.22846040033055459162\n",
      "Iteration 39724 => Loss: 45.22830587859342443835\n",
      "Iteration 39725 => Loss: 45.22815135806895625592\n",
      "Iteration 39726 => Loss: 45.22799683875717136061\n",
      "Iteration 39727 => Loss: 45.22784232065804843614\n",
      "Iteration 39728 => Loss: 45.22768780377157327166\n",
      "Iteration 39729 => Loss: 45.22753328809774586716\n",
      "Iteration 39730 => Loss: 45.22737877363653780094\n",
      "Iteration 39731 => Loss: 45.22722426038795617842\n",
      "Iteration 39732 => Loss: 45.22706974835197968332\n",
      "Iteration 39733 => Loss: 45.22691523752861542107\n",
      "Iteration 39734 => Loss: 45.22676072791783496996\n",
      "Iteration 39735 => Loss: 45.22660621951963122456\n",
      "Iteration 39736 => Loss: 45.22645171233401839572\n",
      "Iteration 39737 => Loss: 45.22629720636096095632\n",
      "Iteration 39738 => Loss: 45.22614270160046601177\n",
      "Iteration 39739 => Loss: 45.22598819805251224579\n",
      "Iteration 39740 => Loss: 45.22583369571709965840\n",
      "Iteration 39741 => Loss: 45.22567919459420693329\n",
      "Iteration 39742 => Loss: 45.22552469468383407047\n",
      "Iteration 39743 => Loss: 45.22537019598594554282\n",
      "Iteration 39744 => Loss: 45.22521569850059819373\n",
      "Iteration 39745 => Loss: 45.22506120222769965267\n",
      "Iteration 39746 => Loss: 45.22490670716729965761\n",
      "Iteration 39747 => Loss: 45.22475221331936978686\n",
      "Iteration 39748 => Loss: 45.22459772068386740784\n",
      "Iteration 39749 => Loss: 45.22444322926085646941\n",
      "Iteration 39750 => Loss: 45.22428873905027302271\n",
      "Iteration 39751 => Loss: 45.22413425005210996233\n",
      "Iteration 39752 => Loss: 45.22397976226637439368\n",
      "Iteration 39753 => Loss: 45.22382527569305210591\n",
      "Iteration 39754 => Loss: 45.22367079033213599359\n",
      "Iteration 39755 => Loss: 45.22351630618361895131\n",
      "Iteration 39756 => Loss: 45.22336182324746545191\n",
      "Iteration 39757 => Loss: 45.22320734152369681169\n",
      "Iteration 39758 => Loss: 45.22305286101229171436\n",
      "Iteration 39759 => Loss: 45.22289838171325726535\n",
      "Iteration 39760 => Loss: 45.22274390362655793751\n",
      "Iteration 39761 => Loss: 45.22258942675217241458\n",
      "Iteration 39762 => Loss: 45.22243495109012201283\n",
      "Iteration 39763 => Loss: 45.22228047664040673226\n",
      "Iteration 39764 => Loss: 45.22212600340298394030\n",
      "Iteration 39765 => Loss: 45.22197153137787495325\n",
      "Iteration 39766 => Loss: 45.22181706056504424396\n",
      "Iteration 39767 => Loss: 45.22166259096449891786\n",
      "Iteration 39768 => Loss: 45.22150812257621055323\n",
      "Iteration 39769 => Loss: 45.22135365540019336095\n",
      "Iteration 39770 => Loss: 45.22119918943642602471\n",
      "Iteration 39771 => Loss: 45.22104472468486591197\n",
      "Iteration 39772 => Loss: 45.22089026114557697156\n",
      "Iteration 39773 => Loss: 45.22073579881849525464\n",
      "Iteration 39774 => Loss: 45.22058133770362786663\n",
      "Iteration 39775 => Loss: 45.22042687780098191297\n",
      "Iteration 39776 => Loss: 45.22027241911050055023\n",
      "Iteration 39777 => Loss: 45.22011796163220509470\n",
      "Iteration 39778 => Loss: 45.21996350536608844095\n",
      "Iteration 39779 => Loss: 45.21980905031215058898\n",
      "Iteration 39780 => Loss: 45.21965459647035601165\n",
      "Iteration 39781 => Loss: 45.21950014384071181439\n",
      "Iteration 39782 => Loss: 45.21934569242319668092\n",
      "Iteration 39783 => Loss: 45.21919124221780350581\n",
      "Iteration 39784 => Loss: 45.21903679322453939449\n",
      "Iteration 39785 => Loss: 45.21888234544337592524\n",
      "Iteration 39786 => Loss: 45.21872789887431309808\n",
      "Iteration 39787 => Loss: 45.21857345351732959671\n",
      "Iteration 39788 => Loss: 45.21841900937244673742\n",
      "Iteration 39789 => Loss: 45.21826456643962899307\n",
      "Iteration 39790 => Loss: 45.21811012471886215280\n",
      "Iteration 39791 => Loss: 45.21795568421013911120\n",
      "Iteration 39792 => Loss: 45.21780124491347407911\n",
      "Iteration 39793 => Loss: 45.21764680682881731855\n",
      "Iteration 39794 => Loss: 45.21749236995620435664\n",
      "Iteration 39795 => Loss: 45.21733793429559966626\n",
      "Iteration 39796 => Loss: 45.21718349984699614197\n",
      "Iteration 39797 => Loss: 45.21702906661037246749\n",
      "Iteration 39798 => Loss: 45.21687463458574995911\n",
      "Iteration 39799 => Loss: 45.21672020377310730055\n",
      "Iteration 39800 => Loss: 45.21656577417240896466\n",
      "Iteration 39801 => Loss: 45.21641134578365495145\n",
      "Iteration 39802 => Loss: 45.21625691860689499890\n",
      "Iteration 39803 => Loss: 45.21610249264202963104\n",
      "Iteration 39804 => Loss: 45.21594806788910148043\n",
      "Iteration 39805 => Loss: 45.21579364434810344164\n",
      "Iteration 39806 => Loss: 45.21563922201901419839\n",
      "Iteration 39807 => Loss: 45.21548480090179822355\n",
      "Iteration 39808 => Loss: 45.21533038099649104424\n",
      "Iteration 39809 => Loss: 45.21517596230303581706\n",
      "Iteration 39810 => Loss: 45.21502154482149649084\n",
      "Iteration 39811 => Loss: 45.21486712855178780046\n",
      "Iteration 39812 => Loss: 45.21471271349391685135\n",
      "Iteration 39813 => Loss: 45.21455829964792627607\n",
      "Iteration 39814 => Loss: 45.21440388701374502034\n",
      "Iteration 39815 => Loss: 45.21424947559139440045\n",
      "Iteration 39816 => Loss: 45.21409506538085310012\n",
      "Iteration 39817 => Loss: 45.21394065638209269764\n",
      "Iteration 39818 => Loss: 45.21378624859515582557\n",
      "Iteration 39819 => Loss: 45.21363184201999274592\n",
      "Iteration 39820 => Loss: 45.21347743665660345869\n",
      "Iteration 39821 => Loss: 45.21332303250497375302\n",
      "Iteration 39822 => Loss: 45.21316862956511073435\n",
      "Iteration 39823 => Loss: 45.21301422783698598096\n",
      "Iteration 39824 => Loss: 45.21285982732060659828\n",
      "Iteration 39825 => Loss: 45.21270542801592995374\n",
      "Iteration 39826 => Loss: 45.21255102992300578535\n",
      "Iteration 39827 => Loss: 45.21239663304178435510\n",
      "Iteration 39828 => Loss: 45.21224223737223013586\n",
      "Iteration 39829 => Loss: 45.21208784291440707648\n",
      "Iteration 39830 => Loss: 45.21193344966821570097\n",
      "Iteration 39831 => Loss: 45.21177905763373416903\n",
      "Iteration 39832 => Loss: 45.21162466681090563725\n",
      "Iteration 39833 => Loss: 45.21147027719971589477\n",
      "Iteration 39834 => Loss: 45.21131588880016494159\n",
      "Iteration 39835 => Loss: 45.21116150161225277770\n",
      "Iteration 39836 => Loss: 45.21100711563597940312\n",
      "Iteration 39837 => Loss: 45.21085273087132350156\n",
      "Iteration 39838 => Loss: 45.21069834731822822960\n",
      "Iteration 39839 => Loss: 45.21054396497676464151\n",
      "Iteration 39840 => Loss: 45.21038958384684036673\n",
      "Iteration 39841 => Loss: 45.21023520392853356498\n",
      "Iteration 39842 => Loss: 45.21008082522179449825\n",
      "Iteration 39843 => Loss: 45.20992644772660895569\n",
      "Iteration 39844 => Loss: 45.20977207144294851560\n",
      "Iteration 39845 => Loss: 45.20961769637084159967\n",
      "Iteration 39846 => Loss: 45.20946332251024557536\n",
      "Iteration 39847 => Loss: 45.20930894986116754808\n",
      "Iteration 39848 => Loss: 45.20915457842361462326\n",
      "Iteration 39849 => Loss: 45.20900020819756548462\n",
      "Iteration 39850 => Loss: 45.20884583918298460503\n",
      "Iteration 39851 => Loss: 45.20869147137990751162\n",
      "Iteration 39852 => Loss: 45.20853710478828446639\n",
      "Iteration 39853 => Loss: 45.20838273940811546936\n",
      "Iteration 39854 => Loss: 45.20822837523940762594\n",
      "Iteration 39855 => Loss: 45.20807401228216093614\n",
      "Iteration 39856 => Loss: 45.20791965053631855653\n",
      "Iteration 39857 => Loss: 45.20776529000190180341\n",
      "Iteration 39858 => Loss: 45.20761093067891067676\n",
      "Iteration 39859 => Loss: 45.20745657256731675488\n",
      "Iteration 39860 => Loss: 45.20730221566710582692\n",
      "Iteration 39861 => Loss: 45.20714785997830631459\n",
      "Iteration 39862 => Loss: 45.20699350550086847988\n",
      "Iteration 39863 => Loss: 45.20683915223479232282\n",
      "Iteration 39864 => Loss: 45.20668480018007073795\n",
      "Iteration 39865 => Loss: 45.20653044933670372529\n",
      "Iteration 39866 => Loss: 45.20637609970466996856\n",
      "Iteration 39867 => Loss: 45.20622175128395525689\n",
      "Iteration 39868 => Loss: 45.20606740407458090658\n",
      "Iteration 39869 => Loss: 45.20591305807648296877\n",
      "Iteration 39870 => Loss: 45.20575871328973249774\n",
      "Iteration 39871 => Loss: 45.20560436971422291208\n",
      "Iteration 39872 => Loss: 45.20545002735001816063\n",
      "Iteration 39873 => Loss: 45.20529568619708982169\n",
      "Iteration 39874 => Loss: 45.20514134625540947354\n",
      "Iteration 39875 => Loss: 45.20498700752498422162\n",
      "Iteration 39876 => Loss: 45.20483267000579274963\n",
      "Iteration 39877 => Loss: 45.20467833369784926845\n",
      "Iteration 39878 => Loss: 45.20452399860113246177\n",
      "Iteration 39879 => Loss: 45.20436966471560680247\n",
      "Iteration 39880 => Loss: 45.20421533204128650141\n",
      "Iteration 39881 => Loss: 45.20406100057818576943\n",
      "Iteration 39882 => Loss: 45.20390667032625486854\n",
      "Iteration 39883 => Loss: 45.20375234128549379875\n",
      "Iteration 39884 => Loss: 45.20359801345590256005\n",
      "Iteration 39885 => Loss: 45.20344368683748115245\n",
      "Iteration 39886 => Loss: 45.20328936143020115423\n",
      "Iteration 39887 => Loss: 45.20313503723405545998\n",
      "Iteration 39888 => Loss: 45.20298071424902985882\n",
      "Iteration 39889 => Loss: 45.20282639247513856162\n",
      "Iteration 39890 => Loss: 45.20267207191233893582\n",
      "Iteration 39891 => Loss: 45.20251775256065940312\n",
      "Iteration 39892 => Loss: 45.20236343442005022553\n",
      "Iteration 39893 => Loss: 45.20220911749053982476\n",
      "Iteration 39894 => Loss: 45.20205480177207846282\n",
      "Iteration 39895 => Loss: 45.20190048726468745599\n",
      "Iteration 39896 => Loss: 45.20174617396837390970\n",
      "Iteration 39897 => Loss: 45.20159186188308098053\n",
      "Iteration 39898 => Loss: 45.20143755100881577391\n",
      "Iteration 39899 => Loss: 45.20128324134558539527\n",
      "Iteration 39900 => Loss: 45.20112893289335431746\n",
      "Iteration 39901 => Loss: 45.20097462565215096220\n",
      "Iteration 39902 => Loss: 45.20082031962192559149\n",
      "Iteration 39903 => Loss: 45.20066601480267820534\n",
      "Iteration 39904 => Loss: 45.20051171119443012003\n",
      "Iteration 39905 => Loss: 45.20035740879711738671\n",
      "Iteration 39906 => Loss: 45.20020310761079684880\n",
      "Iteration 39907 => Loss: 45.20004880763541166289\n",
      "Iteration 39908 => Loss: 45.19989450887096182896\n",
      "Iteration 39909 => Loss: 45.19974021131743313617\n",
      "Iteration 39910 => Loss: 45.19958591497483268995\n",
      "Iteration 39911 => Loss: 45.19943161984314627944\n",
      "Iteration 39912 => Loss: 45.19927732592234548292\n",
      "Iteration 39913 => Loss: 45.19912303321244451126\n",
      "Iteration 39914 => Loss: 45.19896874171342204818\n",
      "Iteration 39915 => Loss: 45.19881445142527809367\n",
      "Iteration 39916 => Loss: 45.19866016234798422602\n",
      "Iteration 39917 => Loss: 45.19850587448154044523\n",
      "Iteration 39918 => Loss: 45.19835158782595385674\n",
      "Iteration 39919 => Loss: 45.19819730238120314425\n",
      "Iteration 39920 => Loss: 45.19804301814727409692\n",
      "Iteration 39921 => Loss: 45.19788873512413118760\n",
      "Iteration 39922 => Loss: 45.19773445331183125973\n",
      "Iteration 39923 => Loss: 45.19758017271029615358\n",
      "Iteration 39924 => Loss: 45.19742589331958271259\n",
      "Iteration 39925 => Loss: 45.19727161513961988248\n",
      "Iteration 39926 => Loss: 45.19711733817041476868\n",
      "Iteration 39927 => Loss: 45.19696306241199579290\n",
      "Iteration 39928 => Loss: 45.19680878786432032257\n",
      "Iteration 39929 => Loss: 45.19665451452735283056\n",
      "Iteration 39930 => Loss: 45.19650024240114305485\n",
      "Iteration 39931 => Loss: 45.19634597148565546831\n",
      "Iteration 39932 => Loss: 45.19619170178086164924\n",
      "Iteration 39933 => Loss: 45.19603743328676870306\n",
      "Iteration 39934 => Loss: 45.19588316600337662976\n",
      "Iteration 39935 => Loss: 45.19572889993066411307\n",
      "Iteration 39936 => Loss: 45.19557463506862404756\n",
      "Iteration 39937 => Loss: 45.19542037141724222238\n",
      "Iteration 39938 => Loss: 45.19526610897650442666\n",
      "Iteration 39939 => Loss: 45.19511184774644618756\n",
      "Iteration 39940 => Loss: 45.19495758772698934536\n",
      "Iteration 39941 => Loss: 45.19480332891814811092\n",
      "Iteration 39942 => Loss: 45.19464907131995090595\n",
      "Iteration 39943 => Loss: 45.19449481493234088703\n",
      "Iteration 39944 => Loss: 45.19434055975533226501\n",
      "Iteration 39945 => Loss: 45.19418630578891793448\n",
      "Iteration 39946 => Loss: 45.19403205303306947371\n",
      "Iteration 39947 => Loss: 45.19387780148779398814\n",
      "Iteration 39948 => Loss: 45.19372355115308437234\n",
      "Iteration 39949 => Loss: 45.19356930202890509918\n",
      "Iteration 39950 => Loss: 45.19341505411527748493\n",
      "Iteration 39951 => Loss: 45.19326080741216600245\n",
      "Iteration 39952 => Loss: 45.19310656191958486261\n",
      "Iteration 39953 => Loss: 45.19295231763752695997\n",
      "Iteration 39954 => Loss: 45.19279807456594966197\n",
      "Iteration 39955 => Loss: 45.19264383270486717947\n",
      "Iteration 39956 => Loss: 45.19248959205427240704\n",
      "Iteration 39957 => Loss: 45.19233535261413692297\n",
      "Iteration 39958 => Loss: 45.19218111438448914896\n",
      "Iteration 39959 => Loss: 45.19202687736527934703\n",
      "Iteration 39960 => Loss: 45.19187264155651462261\n",
      "Iteration 39961 => Loss: 45.19171840695817365940\n",
      "Iteration 39962 => Loss: 45.19156417357026356285\n",
      "Iteration 39963 => Loss: 45.19140994139279143837\n",
      "Iteration 39964 => Loss: 45.19125571042569333713\n",
      "Iteration 39965 => Loss: 45.19110148066900478625\n",
      "Iteration 39966 => Loss: 45.19094725212272578574\n",
      "Iteration 39967 => Loss: 45.19079302478677817589\n",
      "Iteration 39968 => Loss: 45.19063879866122590556\n",
      "Iteration 39969 => Loss: 45.19048457374604765846\n",
      "Iteration 39970 => Loss: 45.19033035004120790745\n",
      "Iteration 39971 => Loss: 45.19017612754669244168\n",
      "Iteration 39972 => Loss: 45.19002190626250126115\n",
      "Iteration 39973 => Loss: 45.18986768618865568214\n",
      "Iteration 39974 => Loss: 45.18971346732510596667\n",
      "Iteration 39975 => Loss: 45.18955924967187343100\n",
      "Iteration 39976 => Loss: 45.18940503322890833715\n",
      "Iteration 39977 => Loss: 45.18925081799623910683\n",
      "Iteration 39978 => Loss: 45.18909660397384442376\n",
      "Iteration 39979 => Loss: 45.18894239116171718251\n",
      "Iteration 39980 => Loss: 45.18878817955983606680\n",
      "Iteration 39981 => Loss: 45.18863396916818686577\n",
      "Iteration 39982 => Loss: 45.18847975998679089571\n",
      "Iteration 39983 => Loss: 45.18832555201561973490\n",
      "Iteration 39984 => Loss: 45.18817134525468759421\n",
      "Iteration 39985 => Loss: 45.18801713970390920849\n",
      "Iteration 39986 => Loss: 45.18786293536336273746\n",
      "Iteration 39987 => Loss: 45.18770873223299133770\n",
      "Iteration 39988 => Loss: 45.18755453031280211462\n",
      "Iteration 39989 => Loss: 45.18740032960278085739\n",
      "Iteration 39990 => Loss: 45.18724613010292756599\n",
      "Iteration 39991 => Loss: 45.18709193181321381871\n",
      "Iteration 39992 => Loss: 45.18693773473363251014\n",
      "Iteration 39993 => Loss: 45.18678353886419785113\n",
      "Iteration 39994 => Loss: 45.18662934420488141996\n",
      "Iteration 39995 => Loss: 45.18647515075567611120\n",
      "Iteration 39996 => Loss: 45.18632095851657481944\n",
      "Iteration 39997 => Loss: 45.18616676748755622839\n",
      "Iteration 39998 => Loss: 45.18601257766860612719\n",
      "Iteration 39999 => Loss: 45.18585838905975293756\n",
      "Iteration 40000 => Loss: 45.18570420166097534320\n",
      "Iteration 40001 => Loss: 45.18555001547223071157\n",
      "Iteration 40002 => Loss: 45.18539583049354035893\n",
      "Iteration 40003 => Loss: 45.18524164672488296901\n",
      "Iteration 40004 => Loss: 45.18508746416625854181\n",
      "Iteration 40005 => Loss: 45.18493328281763865562\n",
      "Iteration 40006 => Loss: 45.18477910267902331043\n",
      "Iteration 40007 => Loss: 45.18462492375041961168\n",
      "Iteration 40008 => Loss: 45.18447074603179203223\n",
      "Iteration 40009 => Loss: 45.18431656952314057207\n",
      "Iteration 40010 => Loss: 45.18416239422447233665\n",
      "Iteration 40011 => Loss: 45.18400822013575890423\n",
      "Iteration 40012 => Loss: 45.18385404725698606399\n",
      "Iteration 40013 => Loss: 45.18369987558818223761\n",
      "Iteration 40014 => Loss: 45.18354570512926926540\n",
      "Iteration 40015 => Loss: 45.18339153588030399078\n",
      "Iteration 40016 => Loss: 45.18323736784125088661\n",
      "Iteration 40017 => Loss: 45.18308320101208863662\n",
      "Iteration 40018 => Loss: 45.18292903539281724079\n",
      "Iteration 40019 => Loss: 45.18277487098345801542\n",
      "Iteration 40020 => Loss: 45.18262070778394701165\n",
      "Iteration 40021 => Loss: 45.18246654579428422949\n",
      "Iteration 40022 => Loss: 45.18231238501452651235\n",
      "Iteration 40023 => Loss: 45.18215822544456727883\n",
      "Iteration 40024 => Loss: 45.18200406708447758319\n",
      "Iteration 40025 => Loss: 45.18184990993418637117\n",
      "Iteration 40026 => Loss: 45.18169575399372916991\n",
      "Iteration 40027 => Loss: 45.18154159926308466311\n",
      "Iteration 40028 => Loss: 45.18138744574222442907\n",
      "Iteration 40029 => Loss: 45.18123329343115557322\n",
      "Iteration 40030 => Loss: 45.18107914232987099012\n",
      "Iteration 40031 => Loss: 45.18092499243836357437\n",
      "Iteration 40032 => Loss: 45.18077084375660490423\n",
      "Iteration 40033 => Loss: 45.18061669628459497972\n",
      "Iteration 40034 => Loss: 45.18046255002232669540\n",
      "Iteration 40035 => Loss: 45.18030840496980005128\n",
      "Iteration 40036 => Loss: 45.18015426112698662564\n",
      "Iteration 40037 => Loss: 45.18000011849389352392\n",
      "Iteration 40038 => Loss: 45.17984597707048521897\n",
      "Iteration 40039 => Loss: 45.17969183685680434337\n",
      "Iteration 40040 => Loss: 45.17953769785277273741\n",
      "Iteration 40041 => Loss: 45.17938356005843303365\n",
      "Iteration 40042 => Loss: 45.17922942347374970495\n",
      "Iteration 40043 => Loss: 45.17907528809872275133\n",
      "Iteration 40044 => Loss: 45.17892115393336638363\n",
      "Iteration 40045 => Loss: 45.17876702097764507471\n",
      "Iteration 40046 => Loss: 45.17861288923150908658\n",
      "Iteration 40047 => Loss: 45.17845875869503657896\n",
      "Iteration 40048 => Loss: 45.17830462936814228669\n",
      "Iteration 40049 => Loss: 45.17815050125086173693\n",
      "Iteration 40050 => Loss: 45.17799637434315940254\n",
      "Iteration 40051 => Loss: 45.17784224864504949437\n",
      "Iteration 40052 => Loss: 45.17768812415650359071\n",
      "Iteration 40053 => Loss: 45.17753400087751458614\n",
      "Iteration 40054 => Loss: 45.17737987880808248065\n",
      "Iteration 40055 => Loss: 45.17722575794818595796\n",
      "Iteration 40056 => Loss: 45.17707163829782501807\n",
      "Iteration 40057 => Loss: 45.17691751985699966099\n",
      "Iteration 40058 => Loss: 45.17676340262568857042\n",
      "Iteration 40059 => Loss: 45.17660928660385621924\n",
      "Iteration 40060 => Loss: 45.17645517179153813458\n",
      "Iteration 40061 => Loss: 45.17630105818869168388\n",
      "Iteration 40062 => Loss: 45.17614694579530976171\n",
      "Iteration 40063 => Loss: 45.17599283461142789520\n",
      "Iteration 40064 => Loss: 45.17583872463697503008\n",
      "Iteration 40065 => Loss: 45.17568461587200090435\n",
      "Iteration 40066 => Loss: 45.17553050831642735830\n",
      "Iteration 40067 => Loss: 45.17537640197030412992\n",
      "Iteration 40068 => Loss: 45.17522229683360279751\n",
      "Iteration 40069 => Loss: 45.17506819290629493935\n",
      "Iteration 40070 => Loss: 45.17491409018838766087\n",
      "Iteration 40071 => Loss: 45.17475998867986675123\n",
      "Iteration 40072 => Loss: 45.17460588838073931583\n",
      "Iteration 40073 => Loss: 45.17445178929099114384\n",
      "Iteration 40074 => Loss: 45.17429769141058670812\n",
      "Iteration 40075 => Loss: 45.17414359473953311408\n",
      "Iteration 40076 => Loss: 45.17398949927784457259\n",
      "Iteration 40077 => Loss: 45.17383540502547134565\n",
      "Iteration 40078 => Loss: 45.17368131198242764412\n",
      "Iteration 40079 => Loss: 45.17352722014867794087\n",
      "Iteration 40080 => Loss: 45.17337312952425776302\n",
      "Iteration 40081 => Loss: 45.17321904010911026717\n",
      "Iteration 40082 => Loss: 45.17306495190326387501\n",
      "Iteration 40083 => Loss: 45.17291086490669727027\n",
      "Iteration 40084 => Loss: 45.17275677911939624209\n",
      "Iteration 40085 => Loss: 45.17260269454133947420\n",
      "Iteration 40086 => Loss: 45.17244861117252696658\n",
      "Iteration 40087 => Loss: 45.17229452901297293010\n",
      "Iteration 40088 => Loss: 45.17214044806264183762\n",
      "Iteration 40089 => Loss: 45.17198636832152658371\n",
      "Iteration 40090 => Loss: 45.17183228978961295752\n",
      "Iteration 40091 => Loss: 45.17167821246692938075\n",
      "Iteration 40092 => Loss: 45.17152413635341190457\n",
      "Iteration 40093 => Loss: 45.17137006144906763438\n",
      "Iteration 40094 => Loss: 45.17121598775391078107\n",
      "Iteration 40095 => Loss: 45.17106191526791292290\n",
      "Iteration 40096 => Loss: 45.17090784399106695446\n",
      "Iteration 40097 => Loss: 45.17075377392336577032\n",
      "Iteration 40098 => Loss: 45.17059970506480226504\n",
      "Iteration 40099 => Loss: 45.17044563741535512236\n",
      "Iteration 40100 => Loss: 45.17029157097501723683\n",
      "Iteration 40101 => Loss: 45.17013750574379571390\n",
      "Iteration 40102 => Loss: 45.16998344172165502641\n",
      "Iteration 40103 => Loss: 45.16982937890861649066\n",
      "Iteration 40104 => Loss: 45.16967531730464457951\n",
      "Iteration 40105 => Loss: 45.16952125690975350381\n",
      "Iteration 40106 => Loss: 45.16936719772392905270\n",
      "Iteration 40107 => Loss: 45.16921313974712859363\n",
      "Iteration 40108 => Loss: 45.16905908297937344287\n",
      "Iteration 40109 => Loss: 45.16890502742065649500\n",
      "Iteration 40110 => Loss: 45.16875097307094932830\n",
      "Iteration 40111 => Loss: 45.16859691993024483736\n",
      "Iteration 40112 => Loss: 45.16844286799855012760\n",
      "Iteration 40113 => Loss: 45.16828881727584388273\n",
      "Iteration 40114 => Loss: 45.16813476776213320818\n",
      "Iteration 40115 => Loss: 45.16798071945738968225\n",
      "Iteration 40116 => Loss: 45.16782667236159198865\n",
      "Iteration 40117 => Loss: 45.16767262647477565451\n",
      "Iteration 40118 => Loss: 45.16751858179687673100\n",
      "Iteration 40119 => Loss: 45.16736453832793785068\n",
      "Iteration 40120 => Loss: 45.16721049606789506470\n",
      "Iteration 40121 => Loss: 45.16705645501679100562\n",
      "Iteration 40122 => Loss: 45.16690241517458304088\n",
      "Iteration 40123 => Loss: 45.16674837654128538134\n",
      "Iteration 40124 => Loss: 45.16659433911686960528\n",
      "Iteration 40125 => Loss: 45.16644030290131439642\n",
      "Iteration 40126 => Loss: 45.16628626789464107105\n",
      "Iteration 40127 => Loss: 45.16613223409682120746\n",
      "Iteration 40128 => Loss: 45.16597820150786191107\n",
      "Iteration 40129 => Loss: 45.16582417012771344389\n",
      "Iteration 40130 => Loss: 45.16567013995643264934\n",
      "Iteration 40131 => Loss: 45.16551611099394847315\n",
      "Iteration 40132 => Loss: 45.16536208324028223160\n",
      "Iteration 40133 => Loss: 45.16520805669541260841\n",
      "Iteration 40134 => Loss: 45.16505403135935381442\n",
      "Iteration 40135 => Loss: 45.16490000723204900623\n",
      "Iteration 40136 => Loss: 45.16474598431354081640\n",
      "Iteration 40137 => Loss: 45.16459196260377950694\n",
      "Iteration 40138 => Loss: 45.16443794210277928869\n",
      "Iteration 40139 => Loss: 45.16428392281052595081\n",
      "Iteration 40140 => Loss: 45.16412990472701238787\n",
      "Iteration 40141 => Loss: 45.16397588785222438901\n",
      "Iteration 40142 => Loss: 45.16382187218614063795\n",
      "Iteration 40143 => Loss: 45.16366785772876113469\n",
      "Iteration 40144 => Loss: 45.16351384448010009010\n",
      "Iteration 40145 => Loss: 45.16335983244010776616\n",
      "Iteration 40146 => Loss: 45.16320582160880547917\n",
      "Iteration 40147 => Loss: 45.16305181198617191285\n",
      "Iteration 40148 => Loss: 45.16289780357218575091\n",
      "Iteration 40149 => Loss: 45.16274379636686830963\n",
      "Iteration 40150 => Loss: 45.16258979037018406189\n",
      "Iteration 40151 => Loss: 45.16243578558212590224\n",
      "Iteration 40152 => Loss: 45.16228178200267961984\n",
      "Iteration 40153 => Loss: 45.16212777963185942554\n",
      "Iteration 40154 => Loss: 45.16197377846962979220\n",
      "Iteration 40155 => Loss: 45.16181977851603335239\n",
      "Iteration 40156 => Loss: 45.16166577977097063012\n",
      "Iteration 40157 => Loss: 45.16151178223449846882\n",
      "Iteration 40158 => Loss: 45.16135778590659555221\n",
      "Iteration 40159 => Loss: 45.16120379078723345856\n",
      "Iteration 40160 => Loss: 45.16104979687644771502\n",
      "Iteration 40161 => Loss: 45.16089580417416726732\n",
      "Iteration 40162 => Loss: 45.16074181268042053716\n",
      "Iteration 40163 => Loss: 45.16058782239520041912\n",
      "Iteration 40164 => Loss: 45.16043383331846428064\n",
      "Iteration 40165 => Loss: 45.16027984545026185970\n",
      "Iteration 40166 => Loss: 45.16012585879054341831\n",
      "Iteration 40167 => Loss: 45.15997187333928764019\n",
      "Iteration 40168 => Loss: 45.15981788909650873620\n",
      "Iteration 40169 => Loss: 45.15966390606219249548\n",
      "Iteration 40170 => Loss: 45.15950992423632470718\n",
      "Iteration 40171 => Loss: 45.15935594361888405501\n",
      "Iteration 40172 => Loss: 45.15920196420987764441\n",
      "Iteration 40173 => Loss: 45.15904798600931968622\n",
      "Iteration 40174 => Loss: 45.15889400901715333703\n",
      "Iteration 40175 => Loss: 45.15874003323338570226\n",
      "Iteration 40176 => Loss: 45.15858605865801678192\n",
      "Iteration 40177 => Loss: 45.15843208529102525972\n",
      "Iteration 40178 => Loss: 45.15827811313243245195\n",
      "Iteration 40179 => Loss: 45.15812414218220283146\n",
      "Iteration 40180 => Loss: 45.15797017244032218741\n",
      "Iteration 40181 => Loss: 45.15781620390676920351\n",
      "Iteration 40182 => Loss: 45.15766223658157940690\n",
      "Iteration 40183 => Loss: 45.15750827046470305959\n",
      "Iteration 40184 => Loss: 45.15735430555614016157\n",
      "Iteration 40185 => Loss: 45.15720034185589071285\n",
      "Iteration 40186 => Loss: 45.15704637936394760800\n",
      "Iteration 40187 => Loss: 45.15689241808028242531\n",
      "Iteration 40188 => Loss: 45.15673845800489516478\n",
      "Iteration 40189 => Loss: 45.15658449913779293183\n",
      "Iteration 40190 => Loss: 45.15643054147894730477\n",
      "Iteration 40191 => Loss: 45.15627658502835828358\n",
      "Iteration 40192 => Loss: 45.15612262978599744656\n",
      "Iteration 40193 => Loss: 45.15596867575187900457\n",
      "Iteration 40194 => Loss: 45.15581472292598164131\n",
      "Iteration 40195 => Loss: 45.15566077130829114594\n",
      "Iteration 40196 => Loss: 45.15550682089881462389\n",
      "Iteration 40197 => Loss: 45.15535287169752365344\n",
      "Iteration 40198 => Loss: 45.15519892370443244545\n",
      "Iteration 40199 => Loss: 45.15504497691949126192\n",
      "Iteration 40200 => Loss: 45.15489103134274273543\n",
      "Iteration 40201 => Loss: 45.15473708697414423341\n",
      "Iteration 40202 => Loss: 45.15458314381368865043\n",
      "Iteration 40203 => Loss: 45.15442920186136888105\n",
      "Iteration 40204 => Loss: 45.15427526111719203072\n",
      "Iteration 40205 => Loss: 45.15412132158110836144\n",
      "Iteration 40206 => Loss: 45.15396738325316761120\n",
      "Iteration 40207 => Loss: 45.15381344613329872573\n",
      "Iteration 40208 => Loss: 45.15365951022153012673\n",
      "Iteration 40209 => Loss: 45.15350557551784049792\n",
      "Iteration 40210 => Loss: 45.15335164202220852303\n",
      "Iteration 40211 => Loss: 45.15319770973466262376\n",
      "Iteration 40212 => Loss: 45.15304377865516727297\n",
      "Iteration 40213 => Loss: 45.15288984878372957610\n",
      "Iteration 40214 => Loss: 45.15273592012028558429\n",
      "Iteration 40215 => Loss: 45.15258199266487082468\n",
      "Iteration 40216 => Loss: 45.15242806641749240271\n",
      "Iteration 40217 => Loss: 45.15227414137811479122\n",
      "Iteration 40218 => Loss: 45.15212021754670956852\n",
      "Iteration 40219 => Loss: 45.15196629492331226174\n",
      "Iteration 40220 => Loss: 45.15181237350788734375\n",
      "Iteration 40221 => Loss: 45.15165845330043481454\n",
      "Iteration 40222 => Loss: 45.15150453430094046325\n",
      "Iteration 40223 => Loss: 45.15135061650939007905\n",
      "Iteration 40224 => Loss: 45.15119669992578366191\n",
      "Iteration 40225 => Loss: 45.15104278455009279014\n",
      "Iteration 40226 => Loss: 45.15088887038234588545\n",
      "Iteration 40227 => Loss: 45.15073495742247899898\n",
      "Iteration 40228 => Loss: 45.15058104567051344702\n",
      "Iteration 40229 => Loss: 45.15042713512644922957\n",
      "Iteration 40230 => Loss: 45.15027322579029345206\n",
      "Iteration 40231 => Loss: 45.15011931766196084936\n",
      "Iteration 40232 => Loss: 45.14996541074152958117\n",
      "Iteration 40233 => Loss: 45.14981150502893569865\n",
      "Iteration 40234 => Loss: 45.14965760052419341264\n",
      "Iteration 40235 => Loss: 45.14950369722726719601\n",
      "Iteration 40236 => Loss: 45.14934979513818547048\n",
      "Iteration 40237 => Loss: 45.14919589425691270890\n",
      "Iteration 40238 => Loss: 45.14904199458345601670\n",
      "Iteration 40239 => Loss: 45.14888809611778697217\n",
      "Iteration 40240 => Loss: 45.14873419885990557532\n",
      "Iteration 40241 => Loss: 45.14858030280980472071\n",
      "Iteration 40242 => Loss: 45.14842640796745598664\n",
      "Iteration 40243 => Loss: 45.14827251433290200566\n",
      "Iteration 40244 => Loss: 45.14811862190605751266\n",
      "Iteration 40245 => Loss: 45.14796473068697224562\n",
      "Iteration 40246 => Loss: 45.14781084067560357198\n",
      "Iteration 40247 => Loss: 45.14765695187198701888\n",
      "Iteration 40248 => Loss: 45.14750306427605153203\n",
      "Iteration 40249 => Loss: 45.14734917788781842773\n",
      "Iteration 40250 => Loss: 45.14719529270728060055\n",
      "Iteration 40251 => Loss: 45.14704140873443805049\n",
      "Iteration 40252 => Loss: 45.14688752596925525040\n",
      "Iteration 40253 => Loss: 45.14673364441174641115\n",
      "Iteration 40254 => Loss: 45.14657976406189732188\n",
      "Iteration 40255 => Loss: 45.14642588491967245545\n",
      "Iteration 40256 => Loss: 45.14627200698510023358\n",
      "Iteration 40257 => Loss: 45.14611813025815223455\n",
      "Iteration 40258 => Loss: 45.14596425473881424750\n",
      "Iteration 40259 => Loss: 45.14581038042707916702\n",
      "Iteration 40260 => Loss: 45.14565650732294699310\n",
      "Iteration 40261 => Loss: 45.14550263542641062031\n",
      "Iteration 40262 => Loss: 45.14534876473744162695\n",
      "Iteration 40263 => Loss: 45.14519489525605422386\n",
      "Iteration 40264 => Loss: 45.14504102698219867307\n",
      "Iteration 40265 => Loss: 45.14488715991593181798\n",
      "Iteration 40266 => Loss: 45.14473329405717549889\n",
      "Iteration 40267 => Loss: 45.14457942940596524295\n",
      "Iteration 40268 => Loss: 45.14442556596226552301\n",
      "Iteration 40269 => Loss: 45.14427170372608344451\n",
      "Iteration 40270 => Loss: 45.14411784269739769115\n",
      "Iteration 40271 => Loss: 45.14396398287623668466\n",
      "Iteration 40272 => Loss: 45.14381012426252226533\n",
      "Iteration 40273 => Loss: 45.14365626685631838200\n",
      "Iteration 40274 => Loss: 45.14350241065754687497\n",
      "Iteration 40275 => Loss: 45.14334855566622906053\n",
      "Iteration 40276 => Loss: 45.14319470188235783326\n",
      "Iteration 40277 => Loss: 45.14304084930594029856\n",
      "Iteration 40278 => Loss: 45.14288699793694803475\n",
      "Iteration 40279 => Loss: 45.14273314777538814724\n",
      "Iteration 40280 => Loss: 45.14257929882120379261\n",
      "Iteration 40281 => Loss: 45.14242545107440918173\n",
      "Iteration 40282 => Loss: 45.14227160453504694715\n",
      "Iteration 40283 => Loss: 45.14211775920303892917\n",
      "Iteration 40284 => Loss: 45.14196391507839933865\n",
      "Iteration 40285 => Loss: 45.14181007216112817559\n",
      "Iteration 40286 => Loss: 45.14165623045120412371\n",
      "Iteration 40287 => Loss: 45.14150238994860586672\n",
      "Iteration 40288 => Loss: 45.14134855065336893176\n",
      "Iteration 40289 => Loss: 45.14119471256544358084\n",
      "Iteration 40290 => Loss: 45.14104087568482270854\n",
      "Iteration 40291 => Loss: 45.14088704001151342027\n",
      "Iteration 40292 => Loss: 45.14073320554550861061\n",
      "Iteration 40293 => Loss: 45.14057937228678696329\n",
      "Iteration 40294 => Loss: 45.14042554023532005658\n",
      "Iteration 40295 => Loss: 45.14027170939113631221\n",
      "Iteration 40296 => Loss: 45.14011787975419309760\n",
      "Iteration 40297 => Loss: 45.13996405132451172904\n",
      "Iteration 40298 => Loss: 45.13981022410207089024\n",
      "Iteration 40299 => Loss: 45.13965639808684215950\n",
      "Iteration 40300 => Loss: 45.13950257327885395853\n",
      "Iteration 40301 => Loss: 45.13934874967804944390\n",
      "Iteration 40302 => Loss: 45.13919492728445703733\n",
      "Iteration 40303 => Loss: 45.13904110609805542254\n",
      "Iteration 40304 => Loss: 45.13888728611883038866\n",
      "Iteration 40305 => Loss: 45.13873346734678904113\n",
      "Iteration 40306 => Loss: 45.13857964978187453653\n",
      "Iteration 40307 => Loss: 45.13842583342415082370\n",
      "Iteration 40308 => Loss: 45.13827201827356105923\n",
      "Iteration 40309 => Loss: 45.13811820433009813769\n",
      "Iteration 40310 => Loss: 45.13796439159374784822\n",
      "Iteration 40311 => Loss: 45.13781058006452440168\n",
      "Iteration 40312 => Loss: 45.13765676974242779806\n",
      "Iteration 40313 => Loss: 45.13750296062737987768\n",
      "Iteration 40314 => Loss: 45.13734915271945169479\n",
      "Iteration 40315 => Loss: 45.13719534601859351142\n",
      "Iteration 40316 => Loss: 45.13704154052479111670\n",
      "Iteration 40317 => Loss: 45.13688773623805872148\n",
      "Iteration 40318 => Loss: 45.13673393315836790407\n",
      "Iteration 40319 => Loss: 45.13658013128571866446\n",
      "Iteration 40320 => Loss: 45.13642633062008968636\n",
      "Iteration 40321 => Loss: 45.13627253116148807521\n",
      "Iteration 40322 => Loss: 45.13611873290988540930\n",
      "Iteration 40323 => Loss: 45.13596493586530300490\n",
      "Iteration 40324 => Loss: 45.13581114002769112403\n",
      "Iteration 40325 => Loss: 45.13565734539709239925\n",
      "Iteration 40326 => Loss: 45.13550355197342867086\n",
      "Iteration 40327 => Loss: 45.13534975975674967685\n",
      "Iteration 40328 => Loss: 45.13519596874701278466\n",
      "Iteration 40329 => Loss: 45.13504217894421799429\n",
      "Iteration 40330 => Loss: 45.13488839034836530573\n",
      "Iteration 40331 => Loss: 45.13473460295944050813\n",
      "Iteration 40332 => Loss: 45.13458081677743649607\n",
      "Iteration 40333 => Loss: 45.13442703180233905869\n",
      "Iteration 40334 => Loss: 45.13427324803411266885\n",
      "Iteration 40335 => Loss: 45.13411946547277864283\n",
      "Iteration 40336 => Loss: 45.13396568411835119150\n",
      "Iteration 40337 => Loss: 45.13381190397075926057\n",
      "Iteration 40338 => Loss: 45.13365812503003837719\n",
      "Iteration 40339 => Loss: 45.13350434729617433049\n",
      "Iteration 40340 => Loss: 45.13335057076914580421\n",
      "Iteration 40341 => Loss: 45.13319679544893858747\n",
      "Iteration 40342 => Loss: 45.13304302133554557486\n",
      "Iteration 40343 => Loss: 45.13288924842896676637\n",
      "Iteration 40344 => Loss: 45.13273547672920926743\n",
      "Iteration 40345 => Loss: 45.13258170623623755091\n",
      "Iteration 40346 => Loss: 45.13242793695005161680\n",
      "Iteration 40347 => Loss: 45.13227416887064435969\n",
      "Iteration 40348 => Loss: 45.13212040199798025242\n",
      "Iteration 40349 => Loss: 45.13196663633207350586\n",
      "Iteration 40350 => Loss: 45.13181287187290280372\n",
      "Iteration 40351 => Loss: 45.13165910862048946228\n",
      "Iteration 40352 => Loss: 45.13150534657479795442\n",
      "Iteration 40353 => Loss: 45.13135158573581406927\n",
      "Iteration 40354 => Loss: 45.13119782610354491226\n",
      "Iteration 40355 => Loss: 45.13104406767796206168\n",
      "Iteration 40356 => Loss: 45.13089031045907972839\n",
      "Iteration 40357 => Loss: 45.13073655444688370153\n",
      "Iteration 40358 => Loss: 45.13058279964133134854\n",
      "Iteration 40359 => Loss: 45.13042904604245819655\n",
      "Iteration 40360 => Loss: 45.13027529365022161301\n",
      "Iteration 40361 => Loss: 45.13012154246464291418\n",
      "Iteration 40362 => Loss: 45.12996779248567236209\n",
      "Iteration 40363 => Loss: 45.12981404371333837844\n",
      "Iteration 40364 => Loss: 45.12966029614761964694\n",
      "Iteration 40365 => Loss: 45.12950654978848774590\n",
      "Iteration 40366 => Loss: 45.12935280463596399159\n",
      "Iteration 40367 => Loss: 45.12919906069003417315\n",
      "Iteration 40368 => Loss: 45.12904531795064855260\n",
      "Iteration 40369 => Loss: 45.12889157641784976249\n",
      "Iteration 40370 => Loss: 45.12873783609160227570\n",
      "Iteration 40371 => Loss: 45.12858409697189898679\n",
      "Iteration 40372 => Loss: 45.12843035905873279034\n",
      "Iteration 40373 => Loss: 45.12827662235208947550\n",
      "Iteration 40374 => Loss: 45.12812288685195483140\n",
      "Iteration 40375 => Loss: 45.12796915255835017433\n",
      "Iteration 40376 => Loss: 45.12781541947123287173\n",
      "Iteration 40377 => Loss: 45.12766168759060292359\n",
      "Iteration 40378 => Loss: 45.12750795691647454078\n",
      "Iteration 40379 => Loss: 45.12735422744877666901\n",
      "Iteration 40380 => Loss: 45.12720049918758746799\n",
      "Iteration 40381 => Loss: 45.12704677213280035630\n",
      "Iteration 40382 => Loss: 45.12689304628448638823\n",
      "Iteration 40383 => Loss: 45.12673932164259582578\n",
      "Iteration 40384 => Loss: 45.12658559820713577437\n",
      "Iteration 40385 => Loss: 45.12643187597808491773\n",
      "Iteration 40386 => Loss: 45.12627815495542904500\n",
      "Iteration 40387 => Loss: 45.12612443513916815618\n",
      "Iteration 40388 => Loss: 45.12597071652930225127\n",
      "Iteration 40389 => Loss: 45.12581699912579580314\n",
      "Iteration 40390 => Loss: 45.12566328292867723349\n",
      "Iteration 40391 => Loss: 45.12550956793791812061\n",
      "Iteration 40392 => Loss: 45.12535585415349714822\n",
      "Iteration 40393 => Loss: 45.12520214157539300004\n",
      "Iteration 40394 => Loss: 45.12504843020364120321\n",
      "Iteration 40395 => Loss: 45.12489472003820623058\n",
      "Iteration 40396 => Loss: 45.12474101107905966046\n",
      "Iteration 40397 => Loss: 45.12458730332625123083\n",
      "Iteration 40398 => Loss: 45.12443359677969567656\n",
      "Iteration 40399 => Loss: 45.12427989143944984107\n",
      "Iteration 40400 => Loss: 45.12412618730544267009\n",
      "Iteration 40401 => Loss: 45.12397248437773811247\n",
      "Iteration 40402 => Loss: 45.12381878265625090307\n",
      "Iteration 40403 => Loss: 45.12366508214100946361\n",
      "Iteration 40404 => Loss: 45.12351138283202089951\n",
      "Iteration 40405 => Loss: 45.12335768472923547279\n",
      "Iteration 40406 => Loss: 45.12320398783269581600\n",
      "Iteration 40407 => Loss: 45.12305029214235219115\n",
      "Iteration 40408 => Loss: 45.12289659765816907111\n",
      "Iteration 40409 => Loss: 45.12274290438021751015\n",
      "Iteration 40410 => Loss: 45.12258921230841934857\n",
      "Iteration 40411 => Loss: 45.12243552144277458638\n",
      "Iteration 40412 => Loss: 45.12228183178331164527\n",
      "Iteration 40413 => Loss: 45.12212814332999499811\n",
      "Iteration 40414 => Loss: 45.12197445608281043405\n",
      "Iteration 40415 => Loss: 45.12182077004175795309\n",
      "Iteration 40416 => Loss: 45.12166708520682334438\n",
      "Iteration 40417 => Loss: 45.12151340157799239705\n",
      "Iteration 40418 => Loss: 45.12135971915529353282\n",
      "Iteration 40419 => Loss: 45.12120603793866280284\n",
      "Iteration 40420 => Loss: 45.12105235792810731255\n",
      "Iteration 40421 => Loss: 45.12089867912363416735\n",
      "Iteration 40422 => Loss: 45.12074500152522205099\n",
      "Iteration 40423 => Loss: 45.12059132513284964716\n",
      "Iteration 40424 => Loss: 45.12043764994654537759\n",
      "Iteration 40425 => Loss: 45.12028397596625239885\n",
      "Iteration 40426 => Loss: 45.12013030319200623808\n",
      "Iteration 40427 => Loss: 45.11997663162377136814\n",
      "Iteration 40428 => Loss: 45.11982296126154778904\n",
      "Iteration 40429 => Loss: 45.11966929210529997363\n",
      "Iteration 40430 => Loss: 45.11951562415504213277\n",
      "Iteration 40431 => Loss: 45.11936195741077426646\n",
      "Iteration 40432 => Loss: 45.11920829187247505843\n",
      "Iteration 40433 => Loss: 45.11905462754015161408\n",
      "Iteration 40434 => Loss: 45.11890096441375419545\n",
      "Iteration 40435 => Loss: 45.11874730249330411880\n",
      "Iteration 40436 => Loss: 45.11859364177878006785\n",
      "Iteration 40437 => Loss: 45.11843998227019625347\n",
      "Iteration 40438 => Loss: 45.11828632396749583222\n",
      "Iteration 40439 => Loss: 45.11813266687069301497\n",
      "Iteration 40440 => Loss: 45.11797901097980201257\n",
      "Iteration 40441 => Loss: 45.11782535629480150874\n",
      "Iteration 40442 => Loss: 45.11767170281565597634\n",
      "Iteration 40443 => Loss: 45.11751805054238673165\n",
      "Iteration 40444 => Loss: 45.11736439947496535297\n",
      "Iteration 40445 => Loss: 45.11721074961339894571\n",
      "Iteration 40446 => Loss: 45.11705710095765908818\n",
      "Iteration 40447 => Loss: 45.11690345350775288580\n",
      "Iteration 40448 => Loss: 45.11674980726365902228\n",
      "Iteration 40449 => Loss: 45.11659616222537749763\n",
      "Iteration 40450 => Loss: 45.11644251839289410100\n",
      "Iteration 40451 => Loss: 45.11628887576619462152\n",
      "Iteration 40452 => Loss: 45.11613523434527905920\n",
      "Iteration 40453 => Loss: 45.11598159413011899233\n",
      "Iteration 40454 => Loss: 45.11582795512074994804\n",
      "Iteration 40455 => Loss: 45.11567431731709376663\n",
      "Iteration 40456 => Loss: 45.11552068071922150239\n",
      "Iteration 40457 => Loss: 45.11536704532704078474\n",
      "Iteration 40458 => Loss: 45.11521341114058714084\n",
      "Iteration 40459 => Loss: 45.11505977815986057067\n",
      "Iteration 40460 => Loss: 45.11490614638483975796\n",
      "Iteration 40461 => Loss: 45.11475251581551759728\n",
      "Iteration 40462 => Loss: 45.11459888645187277234\n",
      "Iteration 40463 => Loss: 45.11444525829389107230\n",
      "Iteration 40464 => Loss: 45.11429163134157960258\n",
      "Iteration 40465 => Loss: 45.11413800559493125775\n",
      "Iteration 40466 => Loss: 45.11398438105393893238\n",
      "Iteration 40467 => Loss: 45.11383075771857420477\n",
      "Iteration 40468 => Loss: 45.11367713558884418035\n",
      "Iteration 40469 => Loss: 45.11352351466472754282\n",
      "Iteration 40470 => Loss: 45.11336989494619587049\n",
      "Iteration 40471 => Loss: 45.11321627643330600677\n",
      "Iteration 40472 => Loss: 45.11306265912596558110\n",
      "Iteration 40473 => Loss: 45.11290904302424564776\n",
      "Iteration 40474 => Loss: 45.11275542812806094162\n",
      "Iteration 40475 => Loss: 45.11260181443746830610\n",
      "Iteration 40476 => Loss: 45.11244820195240379235\n",
      "Iteration 40477 => Loss: 45.11229459067289582208\n",
      "Iteration 40478 => Loss: 45.11214098059891597359\n",
      "Iteration 40479 => Loss: 45.11198737173047135229\n",
      "Iteration 40480 => Loss: 45.11183376406751222021\n",
      "Iteration 40481 => Loss: 45.11168015761007410447\n",
      "Iteration 40482 => Loss: 45.11152655235814989965\n",
      "Iteration 40483 => Loss: 45.11137294831168986775\n",
      "Iteration 40484 => Loss: 45.11121934547070821964\n",
      "Iteration 40485 => Loss: 45.11106574383518363902\n",
      "Iteration 40486 => Loss: 45.11091214340513033676\n",
      "Iteration 40487 => Loss: 45.11075854418051989114\n",
      "Iteration 40488 => Loss: 45.11060494616135940760\n",
      "Iteration 40489 => Loss: 45.11045134934761335899\n",
      "Iteration 40490 => Loss: 45.11029775373930306159\n",
      "Iteration 40491 => Loss: 45.11014415933639298828\n",
      "Iteration 40492 => Loss: 45.10999056613889024447\n",
      "Iteration 40493 => Loss: 45.10983697414675930304\n",
      "Iteration 40494 => Loss: 45.10968338336003569111\n",
      "Iteration 40495 => Loss: 45.10952979377868388156\n",
      "Iteration 40496 => Loss: 45.10937620540268255809\n",
      "Iteration 40497 => Loss: 45.10922261823203882614\n",
      "Iteration 40498 => Loss: 45.10906903226673847485\n",
      "Iteration 40499 => Loss: 45.10891544750678150422\n",
      "Iteration 40500 => Loss: 45.10876186395213238711\n",
      "Iteration 40501 => Loss: 45.10860828160279822896\n",
      "Iteration 40502 => Loss: 45.10845470045877902976\n",
      "Iteration 40503 => Loss: 45.10830112052006768408\n",
      "Iteration 40504 => Loss: 45.10814754178662155937\n",
      "Iteration 40505 => Loss: 45.10799396425844776104\n",
      "Iteration 40506 => Loss: 45.10784038793556760538\n",
      "Iteration 40507 => Loss: 45.10768681281793845983\n",
      "Iteration 40508 => Loss: 45.10753323890554611353\n",
      "Iteration 40509 => Loss: 45.10737966619841898819\n",
      "Iteration 40510 => Loss: 45.10722609469650734582\n",
      "Iteration 40511 => Loss: 45.10707252439981118641\n",
      "Iteration 40512 => Loss: 45.10691895530833050998\n",
      "Iteration 40513 => Loss: 45.10676538742205821109\n",
      "Iteration 40514 => Loss: 45.10661182074096586803\n",
      "Iteration 40515 => Loss: 45.10645825526507479708\n",
      "Iteration 40516 => Loss: 45.10630469099434947111\n",
      "Iteration 40517 => Loss: 45.10615112792878278469\n",
      "Iteration 40518 => Loss: 45.10599756606837473782\n",
      "Iteration 40519 => Loss: 45.10584400541312533051\n",
      "Iteration 40520 => Loss: 45.10569044596298482475\n",
      "Iteration 40521 => Loss: 45.10553688771798874768\n",
      "Iteration 40522 => Loss: 45.10538333067810867760\n",
      "Iteration 40523 => Loss: 45.10522977484333040366\n",
      "Iteration 40524 => Loss: 45.10507622021366813669\n",
      "Iteration 40525 => Loss: 45.10492266678906503330\n",
      "Iteration 40526 => Loss: 45.10476911456954951518\n",
      "Iteration 40527 => Loss: 45.10461556355511447691\n",
      "Iteration 40528 => Loss: 45.10446201374574570764\n",
      "Iteration 40529 => Loss: 45.10430846514141478565\n",
      "Iteration 40530 => Loss: 45.10415491774211460552\n",
      "Iteration 40531 => Loss: 45.10400137154786648352\n",
      "Iteration 40532 => Loss: 45.10384782655862068168\n",
      "Iteration 40533 => Loss: 45.10369428277442693798\n",
      "Iteration 40534 => Loss: 45.10354074019520709271\n",
      "Iteration 40535 => Loss: 45.10338719882098246217\n",
      "Iteration 40536 => Loss: 45.10323365865175304634\n",
      "Iteration 40537 => Loss: 45.10308011968749042353\n",
      "Iteration 40538 => Loss: 45.10292658192817327745\n",
      "Iteration 40539 => Loss: 45.10277304537384424066\n",
      "Iteration 40540 => Loss: 45.10261951002445357517\n",
      "Iteration 40541 => Loss: 45.10246597587998707013\n",
      "Iteration 40542 => Loss: 45.10231244294046604182\n",
      "Iteration 40543 => Loss: 45.10215891120586206853\n",
      "Iteration 40544 => Loss: 45.10200538067616804483\n",
      "Iteration 40545 => Loss: 45.10185185135134844359\n",
      "Iteration 40546 => Loss: 45.10169832323144589736\n",
      "Iteration 40547 => Loss: 45.10154479631641066817\n",
      "Iteration 40548 => Loss: 45.10139127060624986143\n",
      "Iteration 40549 => Loss: 45.10123774610095637172\n",
      "Iteration 40550 => Loss: 45.10108422280051598818\n",
      "Iteration 40551 => Loss: 45.10093070070490739454\n",
      "Iteration 40552 => Loss: 45.10077717981413059078\n",
      "Iteration 40553 => Loss: 45.10062366012819268235\n",
      "Iteration 40554 => Loss: 45.10047014164705814210\n",
      "Iteration 40555 => Loss: 45.10031662437071986460\n",
      "Iteration 40556 => Loss: 45.10016310829918495529\n",
      "Iteration 40557 => Loss: 45.10000959343244630873\n",
      "Iteration 40558 => Loss: 45.09985607977048260864\n",
      "Iteration 40559 => Loss: 45.09970256731327253874\n",
      "Iteration 40560 => Loss: 45.09954905606083741532\n",
      "Iteration 40561 => Loss: 45.09939554601313460580\n",
      "Iteration 40562 => Loss: 45.09924203717019253190\n",
      "Iteration 40563 => Loss: 45.09908852953196145563\n",
      "Iteration 40564 => Loss: 45.09893502309844848241\n",
      "Iteration 40565 => Loss: 45.09878151786964650682\n",
      "Iteration 40566 => Loss: 45.09862801384556973971\n",
      "Iteration 40567 => Loss: 45.09847451102614712681\n",
      "Iteration 40568 => Loss: 45.09832100941143551154\n",
      "Iteration 40569 => Loss: 45.09816750900139226133\n",
      "Iteration 40570 => Loss: 45.09801400979600316532\n",
      "Iteration 40571 => Loss: 45.09786051179526111810\n",
      "Iteration 40572 => Loss: 45.09770701499917322508\n",
      "Iteration 40573 => Loss: 45.09755351940772527541\n",
      "Iteration 40574 => Loss: 45.09740002502090305825\n",
      "Iteration 40575 => Loss: 45.09724653183867104644\n",
      "Iteration 40576 => Loss: 45.09709303986107897799\n",
      "Iteration 40577 => Loss: 45.09693954908807000947\n",
      "Iteration 40578 => Loss: 45.09678605951965124632\n",
      "Iteration 40579 => Loss: 45.09663257115580847767\n",
      "Iteration 40580 => Loss: 45.09647908399654170353\n",
      "Iteration 40581 => Loss: 45.09632559804179408047\n",
      "Iteration 40582 => Loss: 45.09617211329162955735\n",
      "Iteration 40583 => Loss: 45.09601862974601260703\n",
      "Iteration 40584 => Loss: 45.09586514740491480779\n",
      "Iteration 40585 => Loss: 45.09571166626834326507\n",
      "Iteration 40586 => Loss: 45.09555818633629087344\n",
      "Iteration 40587 => Loss: 45.09540470760872210576\n",
      "Iteration 40588 => Loss: 45.09525123008565117289\n",
      "Iteration 40589 => Loss: 45.09509775376707096939\n",
      "Iteration 40590 => Loss: 45.09494427865298149527\n",
      "Iteration 40591 => Loss: 45.09479080474331880168\n",
      "Iteration 40592 => Loss: 45.09463733203812552119\n",
      "Iteration 40593 => Loss: 45.09448386053738033752\n",
      "Iteration 40594 => Loss: 45.09433039024106903980\n",
      "Iteration 40595 => Loss: 45.09417692114919873347\n",
      "Iteration 40596 => Loss: 45.09402345326174099682\n",
      "Iteration 40597 => Loss: 45.09386998657867451357\n",
      "Iteration 40598 => Loss: 45.09371652110000638913\n",
      "Iteration 40599 => Loss: 45.09356305682574372895\n",
      "Iteration 40600 => Loss: 45.09340959375585811131\n",
      "Iteration 40601 => Loss: 45.09325613189032821992\n",
      "Iteration 40602 => Loss: 45.09310267122918247651\n",
      "Iteration 40603 => Loss: 45.09294921177236403764\n",
      "Iteration 40604 => Loss: 45.09279575351992264132\n",
      "Iteration 40605 => Loss: 45.09264229647178012783\n",
      "Iteration 40606 => Loss: 45.09248884062797912975\n",
      "Iteration 40607 => Loss: 45.09233538598848411993\n",
      "Iteration 40608 => Loss: 45.09218193255328088753\n",
      "Iteration 40609 => Loss: 45.09202848032238364340\n",
      "Iteration 40610 => Loss: 45.09187502929577107125\n",
      "Iteration 40611 => Loss: 45.09172157947342896023\n",
      "Iteration 40612 => Loss: 45.09156813085535020491\n",
      "Iteration 40613 => Loss: 45.09141468344154901615\n",
      "Iteration 40614 => Loss: 45.09126123723198986681\n",
      "Iteration 40615 => Loss: 45.09110779222665144061\n",
      "Iteration 40616 => Loss: 45.09095434842554794841\n",
      "Iteration 40617 => Loss: 45.09080090582866517934\n",
      "Iteration 40618 => Loss: 45.09064746443598892256\n",
      "Iteration 40619 => Loss: 45.09049402424751207263\n",
      "Iteration 40620 => Loss: 45.09034058526322752414\n",
      "Iteration 40621 => Loss: 45.09018714748313527707\n",
      "Iteration 40622 => Loss: 45.09003371090720690972\n",
      "Iteration 40623 => Loss: 45.08988027553542821124\n",
      "Iteration 40624 => Loss: 45.08972684136780628705\n",
      "Iteration 40625 => Loss: 45.08957340840434824258\n",
      "Iteration 40626 => Loss: 45.08941997664499723442\n",
      "Iteration 40627 => Loss: 45.08926654608979589511\n",
      "Iteration 40628 => Loss: 45.08911311673869448668\n",
      "Iteration 40629 => Loss: 45.08895968859168590370\n",
      "Iteration 40630 => Loss: 45.08880626164881277873\n",
      "Iteration 40631 => Loss: 45.08865283590999695207\n",
      "Iteration 40632 => Loss: 45.08849941137525263457\n",
      "Iteration 40633 => Loss: 45.08834598804460114252\n",
      "Iteration 40634 => Loss: 45.08819256591799984335\n",
      "Iteration 40635 => Loss: 45.08803914499543452621\n",
      "Iteration 40636 => Loss: 45.08788572527689808567\n",
      "Iteration 40637 => Loss: 45.08773230676242604886\n",
      "Iteration 40638 => Loss: 45.08757888945195446695\n",
      "Iteration 40639 => Loss: 45.08742547334549755078\n",
      "Iteration 40640 => Loss: 45.08727205844302687865\n",
      "Iteration 40641 => Loss: 45.08711864474457087226\n",
      "Iteration 40642 => Loss: 45.08696523225008689906\n",
      "Iteration 40643 => Loss: 45.08681182095957495903\n",
      "Iteration 40644 => Loss: 45.08665841087302084134\n",
      "Iteration 40645 => Loss: 45.08650500199046007310\n",
      "Iteration 40646 => Loss: 45.08635159431180028378\n",
      "Iteration 40647 => Loss: 45.08619818783709121135\n",
      "Iteration 40648 => Loss: 45.08604478256631153954\n",
      "Iteration 40649 => Loss: 45.08589137849943284664\n",
      "Iteration 40650 => Loss: 45.08573797563646223807\n",
      "Iteration 40651 => Loss: 45.08558457397741392469\n",
      "Iteration 40652 => Loss: 45.08543117352223106309\n",
      "Iteration 40653 => Loss: 45.08527777427093496954\n",
      "Iteration 40654 => Loss: 45.08512437622351143318\n",
      "Iteration 40655 => Loss: 45.08497097937993913774\n",
      "Iteration 40656 => Loss: 45.08481758374022518865\n",
      "Iteration 40657 => Loss: 45.08466418930434116419\n",
      "Iteration 40658 => Loss: 45.08451079607229416979\n",
      "Iteration 40659 => Loss: 45.08435740404406288917\n",
      "Iteration 40660 => Loss: 45.08420401321966153318\n",
      "Iteration 40661 => Loss: 45.08405062359906168012\n",
      "Iteration 40662 => Loss: 45.08389723518224911913\n",
      "Iteration 40663 => Loss: 45.08374384796921674479\n",
      "Iteration 40664 => Loss: 45.08359046195995745165\n",
      "Iteration 40665 => Loss: 45.08343707715447123974\n",
      "Iteration 40666 => Loss: 45.08328369355272968733\n",
      "Iteration 40667 => Loss: 45.08313031115474700528\n",
      "Iteration 40668 => Loss: 45.08297692996049477188\n",
      "Iteration 40669 => Loss: 45.08282354996998009256\n",
      "Iteration 40670 => Loss: 45.08267017118316744018\n",
      "Iteration 40671 => Loss: 45.08251679360006392017\n",
      "Iteration 40672 => Loss: 45.08236341722067663795\n",
      "Iteration 40673 => Loss: 45.08221004204494875012\n",
      "Iteration 40674 => Loss: 45.08205666807293710008\n",
      "Iteration 40675 => Loss: 45.08190329530457063356\n",
      "Iteration 40676 => Loss: 45.08174992373988487770\n",
      "Iteration 40677 => Loss: 45.08159655337883719994\n",
      "Iteration 40678 => Loss: 45.08144318422144891656\n",
      "Iteration 40679 => Loss: 45.08128981626767739499\n",
      "Iteration 40680 => Loss: 45.08113644951752974066\n",
      "Iteration 40681 => Loss: 45.08098308397099884814\n",
      "Iteration 40682 => Loss: 45.08082971962808471744\n",
      "Iteration 40683 => Loss: 45.08067635648875182142\n",
      "Iteration 40684 => Loss: 45.08052299455301437092\n",
      "Iteration 40685 => Loss: 45.08036963382085104968\n",
      "Iteration 40686 => Loss: 45.08021627429222633054\n",
      "Iteration 40687 => Loss: 45.08006291596720416237\n",
      "Iteration 40688 => Loss: 45.07990955884570638545\n",
      "Iteration 40689 => Loss: 45.07975620292775431608\n",
      "Iteration 40690 => Loss: 45.07960284821331953253\n",
      "Iteration 40691 => Loss: 45.07944949470241624567\n",
      "Iteration 40692 => Loss: 45.07929614239500892836\n",
      "Iteration 40693 => Loss: 45.07914279129112600231\n",
      "Iteration 40694 => Loss: 45.07898944139072483495\n",
      "Iteration 40695 => Loss: 45.07883609269379121542\n",
      "Iteration 40696 => Loss: 45.07868274520035356545\n",
      "Iteration 40697 => Loss: 45.07852939891036925246\n",
      "Iteration 40698 => Loss: 45.07837605382382406560\n",
      "Iteration 40699 => Loss: 45.07822270994073221573\n",
      "Iteration 40700 => Loss: 45.07806936726108659741\n",
      "Iteration 40701 => Loss: 45.07791602578485168351\n",
      "Iteration 40702 => Loss: 45.07776268551204168489\n",
      "Iteration 40703 => Loss: 45.07760934644262817983\n",
      "Iteration 40704 => Loss: 45.07745600857660406291\n",
      "Iteration 40705 => Loss: 45.07730267191401196669\n",
      "Iteration 40706 => Loss: 45.07714933645474530977\n",
      "Iteration 40707 => Loss: 45.07699600219887514641\n",
      "Iteration 40708 => Loss: 45.07684266914636594947\n",
      "Iteration 40709 => Loss: 45.07668933729717508641\n",
      "Iteration 40710 => Loss: 45.07653600665136650605\n",
      "Iteration 40711 => Loss: 45.07638267720885494327\n",
      "Iteration 40712 => Loss: 45.07622934896969013607\n",
      "Iteration 40713 => Loss: 45.07607602193382945188\n",
      "Iteration 40714 => Loss: 45.07592269610126578527\n",
      "Iteration 40715 => Loss: 45.07576937147202045253\n",
      "Iteration 40716 => Loss: 45.07561604804602239938\n",
      "Iteration 40717 => Loss: 45.07546272582330004752\n",
      "Iteration 40718 => Loss: 45.07530940480386760782\n",
      "Iteration 40719 => Loss: 45.07515608498766113144\n",
      "Iteration 40720 => Loss: 45.07500276637472325092\n",
      "Iteration 40721 => Loss: 45.07484944896503264999\n",
      "Iteration 40722 => Loss: 45.07469613275853248524\n",
      "Iteration 40723 => Loss: 45.07454281775527249465\n",
      "Iteration 40724 => Loss: 45.07438950395522425652\n",
      "Iteration 40725 => Loss: 45.07423619135838066541\n",
      "Iteration 40726 => Loss: 45.07408287996469198333\n",
      "Iteration 40727 => Loss: 45.07392956977422215914\n",
      "Iteration 40728 => Loss: 45.07377626078690013856\n",
      "Iteration 40729 => Loss: 45.07362295300275434329\n",
      "Iteration 40730 => Loss: 45.07346964642172792992\n",
      "Iteration 40731 => Loss: 45.07331634104387063644\n",
      "Iteration 40732 => Loss: 45.07316303686913272486\n",
      "Iteration 40733 => Loss: 45.07300973389753551146\n",
      "Iteration 40734 => Loss: 45.07285643212905057453\n",
      "Iteration 40735 => Loss: 45.07270313156366370322\n",
      "Iteration 40736 => Loss: 45.07254983220136779209\n",
      "Iteration 40737 => Loss: 45.07239653404216284116\n",
      "Iteration 40738 => Loss: 45.07224323708602753413\n",
      "Iteration 40739 => Loss: 45.07208994133295476558\n",
      "Iteration 40740 => Loss: 45.07193664678294453552\n",
      "Iteration 40741 => Loss: 45.07178335343598263307\n",
      "Iteration 40742 => Loss: 45.07163006129206195283\n",
      "Iteration 40743 => Loss: 45.07147677035115407307\n",
      "Iteration 40744 => Loss: 45.07132348061329452094\n",
      "Iteration 40745 => Loss: 45.07117019207844066386\n",
      "Iteration 40746 => Loss: 45.07101690474654276386\n",
      "Iteration 40747 => Loss: 45.07086361861767898063\n",
      "Iteration 40748 => Loss: 45.07071033369178536532\n",
      "Iteration 40749 => Loss: 45.07055704996886902336\n",
      "Iteration 40750 => Loss: 45.07040376744890153304\n",
      "Iteration 40751 => Loss: 45.07025048613189710522\n",
      "Iteration 40752 => Loss: 45.07009720601784863447\n",
      "Iteration 40753 => Loss: 45.06994392710670638280\n",
      "Iteration 40754 => Loss: 45.06979064939850587734\n",
      "Iteration 40755 => Loss: 45.06963737289321869639\n",
      "Iteration 40756 => Loss: 45.06948409759084483994\n",
      "Iteration 40757 => Loss: 45.06933082349135588629\n",
      "Iteration 40758 => Loss: 45.06917755059474473001\n",
      "Iteration 40759 => Loss: 45.06902427890103268737\n",
      "Iteration 40760 => Loss: 45.06887100841018423125\n",
      "Iteration 40761 => Loss: 45.06871773912218515079\n",
      "Iteration 40762 => Loss: 45.06856447103703544599\n",
      "Iteration 40763 => Loss: 45.06841120415474222227\n",
      "Iteration 40764 => Loss: 45.06825793847526284708\n",
      "Iteration 40765 => Loss: 45.06810467399861863669\n",
      "Iteration 40766 => Loss: 45.06795141072477406397\n",
      "Iteration 40767 => Loss: 45.06779814865373623434\n",
      "Iteration 40768 => Loss: 45.06764488778549093695\n",
      "Iteration 40769 => Loss: 45.06749162812001685552\n",
      "Iteration 40770 => Loss: 45.06733836965732109547\n",
      "Iteration 40771 => Loss: 45.06718511239741786767\n",
      "Iteration 40772 => Loss: 45.06703185634024322326\n",
      "Iteration 40773 => Loss: 45.06687860148581847852\n",
      "Iteration 40774 => Loss: 45.06672534783410100090\n",
      "Iteration 40775 => Loss: 45.06657209538517605552\n",
      "Iteration 40776 => Loss: 45.06641884413892995553\n",
      "Iteration 40777 => Loss: 45.06626559409536980638\n",
      "Iteration 40778 => Loss: 45.06611234525453113520\n",
      "Iteration 40779 => Loss: 45.06595909761638552027\n",
      "Iteration 40780 => Loss: 45.06580585118089743446\n",
      "Iteration 40781 => Loss: 45.06565260594811661576\n",
      "Iteration 40782 => Loss: 45.06549936191798622076\n",
      "Iteration 40783 => Loss: 45.06534611909047782774\n",
      "Iteration 40784 => Loss: 45.06519287746562696384\n",
      "Iteration 40785 => Loss: 45.06503963704340520735\n",
      "Iteration 40786 => Loss: 45.06488639782381255827\n",
      "Iteration 40787 => Loss: 45.06473315980683480575\n",
      "Iteration 40788 => Loss: 45.06457992299247194978\n",
      "Iteration 40789 => Loss: 45.06442668738068846324\n",
      "Iteration 40790 => Loss: 45.06427345297148434611\n",
      "Iteration 40791 => Loss: 45.06412021976487380925\n",
      "Iteration 40792 => Loss: 45.06396698776082843096\n",
      "Iteration 40793 => Loss: 45.06381375695931268410\n",
      "Iteration 40794 => Loss: 45.06366052736036920123\n",
      "Iteration 40795 => Loss: 45.06350729896394113894\n",
      "Iteration 40796 => Loss: 45.06335407177007823520\n",
      "Iteration 40797 => Loss: 45.06320084577870233034\n",
      "Iteration 40798 => Loss: 45.06304762098983474061\n",
      "Iteration 40799 => Loss: 45.06289439740348967689\n",
      "Iteration 40800 => Loss: 45.06274117501962450660\n",
      "Iteration 40801 => Loss: 45.06258795383823212433\n",
      "Iteration 40802 => Loss: 45.06243473385932674091\n",
      "Iteration 40803 => Loss: 45.06228151508286572380\n",
      "Iteration 40804 => Loss: 45.06212829750887749469\n",
      "Iteration 40805 => Loss: 45.06197508113732652646\n",
      "Iteration 40806 => Loss: 45.06182186596821281910\n",
      "Iteration 40807 => Loss: 45.06166865200150795090\n",
      "Iteration 40808 => Loss: 45.06151543923723323815\n",
      "Iteration 40809 => Loss: 45.06136222767536025913\n",
      "Iteration 40810 => Loss: 45.06120901731588190842\n",
      "Iteration 40811 => Loss: 45.06105580815878397516\n",
      "Iteration 40812 => Loss: 45.06090260020408067021\n",
      "Iteration 40813 => Loss: 45.06074939345172225558\n",
      "Iteration 40814 => Loss: 45.06059618790173715297\n",
      "Iteration 40815 => Loss: 45.06044298355410404611\n",
      "Iteration 40816 => Loss: 45.06028978040879451328\n",
      "Iteration 40817 => Loss: 45.06013657846582987077\n",
      "Iteration 40818 => Loss: 45.05998337772519590771\n",
      "Iteration 40819 => Loss: 45.05983017818684999156\n",
      "Iteration 40820 => Loss: 45.05967697985080633316\n",
      "Iteration 40821 => Loss: 45.05952378271706493251\n",
      "Iteration 40822 => Loss: 45.05937058678560447333\n",
      "Iteration 40823 => Loss: 45.05921739205641785020\n",
      "Iteration 40824 => Loss: 45.05906419852951216853\n",
      "Iteration 40825 => Loss: 45.05891100620483769035\n",
      "Iteration 40826 => Loss: 45.05875781508240152107\n",
      "Iteration 40827 => Loss: 45.05860462516222497698\n",
      "Iteration 40828 => Loss: 45.05845143644428674179\n",
      "Iteration 40829 => Loss: 45.05829824892854418295\n",
      "Iteration 40830 => Loss: 45.05814506261499019502\n",
      "Iteration 40831 => Loss: 45.05799187750366741056\n",
      "Iteration 40832 => Loss: 45.05783869359449766989\n",
      "Iteration 40833 => Loss: 45.05768551088754492184\n",
      "Iteration 40834 => Loss: 45.05753232938275232300\n",
      "Iteration 40835 => Loss: 45.05737914908009855708\n",
      "Iteration 40836 => Loss: 45.05722596997962625665\n",
      "Iteration 40837 => Loss: 45.05707279208127147285\n",
      "Iteration 40838 => Loss: 45.05691961538506262741\n",
      "Iteration 40839 => Loss: 45.05676643989097840404\n",
      "Iteration 40840 => Loss: 45.05661326559899748645\n",
      "Iteration 40841 => Loss: 45.05646009250910566379\n",
      "Iteration 40842 => Loss: 45.05630692062134556863\n",
      "Iteration 40843 => Loss: 45.05615374993563904127\n",
      "Iteration 40844 => Loss: 45.05600058045202871426\n",
      "Iteration 40845 => Loss: 45.05584741217047195505\n",
      "Iteration 40846 => Loss: 45.05569424509097586906\n",
      "Iteration 40847 => Loss: 45.05554107921351203458\n",
      "Iteration 40848 => Loss: 45.05538791453811597876\n",
      "Iteration 40849 => Loss: 45.05523475106473796359\n",
      "Iteration 40850 => Loss: 45.05508158879336377822\n",
      "Iteration 40851 => Loss: 45.05492842772401473894\n",
      "Iteration 40852 => Loss: 45.05477526785665531861\n",
      "Iteration 40853 => Loss: 45.05462210919129262265\n",
      "Iteration 40854 => Loss: 45.05446895172789822936\n",
      "Iteration 40855 => Loss: 45.05431579546650056045\n",
      "Iteration 40856 => Loss: 45.05416264040704987792\n",
      "Iteration 40857 => Loss: 45.05400948654955328720\n",
      "Iteration 40858 => Loss: 45.05385633389400368287\n",
      "Iteration 40859 => Loss: 45.05370318244037264321\n",
      "Iteration 40860 => Loss: 45.05355003218868858994\n",
      "Iteration 40861 => Loss: 45.05339688313890178506\n",
      "Iteration 40862 => Loss: 45.05324373529101933400\n",
      "Iteration 40863 => Loss: 45.05309058864506255304\n",
      "Iteration 40864 => Loss: 45.05293744320096038791\n",
      "Iteration 40865 => Loss: 45.05278429895874836575\n",
      "Iteration 40866 => Loss: 45.05263115591840517027\n",
      "Iteration 40867 => Loss: 45.05247801407990237976\n",
      "Iteration 40868 => Loss: 45.05232487344327552137\n",
      "Iteration 40869 => Loss: 45.05217173400847485709\n",
      "Iteration 40870 => Loss: 45.05201859577551459779\n",
      "Iteration 40871 => Loss: 45.05186545874435211090\n",
      "Iteration 40872 => Loss: 45.05171232291504423983\n",
      "Iteration 40873 => Loss: 45.05155918828749150862\n",
      "Iteration 40874 => Loss: 45.05140605486174365524\n",
      "Iteration 40875 => Loss: 45.05125292263779357427\n",
      "Iteration 40876 => Loss: 45.05109979161561994943\n",
      "Iteration 40877 => Loss: 45.05094666179518725357\n",
      "Iteration 40878 => Loss: 45.05079353317652390842\n",
      "Iteration 40879 => Loss: 45.05064040575960859769\n",
      "Iteration 40880 => Loss: 45.05048727954442000510\n",
      "Iteration 40881 => Loss: 45.05033415453095813064\n",
      "Iteration 40882 => Loss: 45.05018103071921586888\n",
      "Iteration 40883 => Loss: 45.05002790810918611442\n",
      "Iteration 40884 => Loss: 45.04987478670084755095\n",
      "Iteration 40885 => Loss: 45.04972166649419307305\n",
      "Iteration 40886 => Loss: 45.04956854748923689158\n",
      "Iteration 40887 => Loss: 45.04941542968595058483\n",
      "Iteration 40888 => Loss: 45.04926231308431283651\n",
      "Iteration 40889 => Loss: 45.04910919768431654120\n",
      "Iteration 40890 => Loss: 45.04895608348597590975\n",
      "Iteration 40891 => Loss: 45.04880297048926252046\n",
      "Iteration 40892 => Loss: 45.04864985869416216246\n",
      "Iteration 40893 => Loss: 45.04849674810069615205\n",
      "Iteration 40894 => Loss: 45.04834363870882896208\n",
      "Iteration 40895 => Loss: 45.04819053051853927627\n",
      "Iteration 40896 => Loss: 45.04803742352984130548\n",
      "Iteration 40897 => Loss: 45.04788431774272794428\n",
      "Iteration 40898 => Loss: 45.04773121315718498181\n",
      "Iteration 40899 => Loss: 45.04757810977319110179\n",
      "Iteration 40900 => Loss: 45.04742500759074630423\n",
      "Iteration 40901 => Loss: 45.04727190660983637827\n",
      "Iteration 40902 => Loss: 45.04711880683046842933\n",
      "Iteration 40903 => Loss: 45.04696570825260693027\n",
      "Iteration 40904 => Loss: 45.04681261087624477568\n",
      "Iteration 40905 => Loss: 45.04665951470138196555\n",
      "Iteration 40906 => Loss: 45.04650641972802560531\n",
      "Iteration 40907 => Loss: 45.04635332595614016782\n",
      "Iteration 40908 => Loss: 45.04620023338572565308\n",
      "Iteration 40909 => Loss: 45.04604714201679627195\n",
      "Iteration 40910 => Loss: 45.04589405184928807557\n",
      "Iteration 40911 => Loss: 45.04574096288326501281\n",
      "Iteration 40912 => Loss: 45.04558787511863471309\n",
      "Iteration 40913 => Loss: 45.04543478855545401984\n",
      "Iteration 40914 => Loss: 45.04528170319367319507\n",
      "Iteration 40915 => Loss: 45.04512861903327802793\n",
      "Iteration 40916 => Loss: 45.04497553607433246725\n",
      "Iteration 40917 => Loss: 45.04482245431672993163\n",
      "Iteration 40918 => Loss: 45.04466937376054147535\n",
      "Iteration 40919 => Loss: 45.04451629440568893870\n",
      "Iteration 40920 => Loss: 45.04436321625223627052\n",
      "Iteration 40921 => Loss: 45.04421013930006978399\n",
      "Iteration 40922 => Loss: 45.04405706354929606050\n",
      "Iteration 40923 => Loss: 45.04390398899982272951\n",
      "Iteration 40924 => Loss: 45.04375091565168531815\n",
      "Iteration 40925 => Loss: 45.04359784350485540472\n",
      "Iteration 40926 => Loss: 45.04344477255932588378\n",
      "Iteration 40927 => Loss: 45.04329170281509675533\n",
      "Iteration 40928 => Loss: 45.04313863427214670310\n",
      "Iteration 40929 => Loss: 45.04298556693045441079\n",
      "Iteration 40930 => Loss: 45.04283250079005540556\n",
      "Iteration 40931 => Loss: 45.04267943585088573855\n",
      "Iteration 40932 => Loss: 45.04252637211299514775\n",
      "Iteration 40933 => Loss: 45.04237330957630547346\n",
      "Iteration 40934 => Loss: 45.04222024824085224282\n",
      "Iteration 40935 => Loss: 45.04206718810662835040\n",
      "Iteration 40936 => Loss: 45.04191412917359826906\n",
      "Iteration 40937 => Loss: 45.04176107144176910424\n",
      "Iteration 40938 => Loss: 45.04160801491114085593\n",
      "Iteration 40939 => Loss: 45.04145495958169220785\n",
      "Iteration 40940 => Loss: 45.04130190545340184372\n",
      "Iteration 40941 => Loss: 45.04114885252626976353\n",
      "Iteration 40942 => Loss: 45.04099580080029596729\n",
      "Iteration 40943 => Loss: 45.04084275027546624415\n",
      "Iteration 40944 => Loss: 45.04068970095175927781\n",
      "Iteration 40945 => Loss: 45.04053665282916796286\n",
      "Iteration 40946 => Loss: 45.04038360590769940472\n",
      "Iteration 40947 => Loss: 45.04023056018736781425\n",
      "Iteration 40948 => Loss: 45.04007751566808792631\n",
      "Iteration 40949 => Loss: 45.03992447234990947891\n",
      "Iteration 40950 => Loss: 45.03977143023280405032\n",
      "Iteration 40951 => Loss: 45.03961838931677164055\n",
      "Iteration 40952 => Loss: 45.03946534960177672247\n",
      "Iteration 40953 => Loss: 45.03931231108786192863\n",
      "Iteration 40954 => Loss: 45.03915927377494199391\n",
      "Iteration 40955 => Loss: 45.03900623766309507801\n",
      "Iteration 40956 => Loss: 45.03885320275224302122\n",
      "Iteration 40957 => Loss: 45.03870016904241424527\n",
      "Iteration 40958 => Loss: 45.03854713653358032843\n",
      "Iteration 40959 => Loss: 45.03839410522571995443\n",
      "Iteration 40960 => Loss: 45.03824107511885443955\n",
      "Iteration 40961 => Loss: 45.03808804621298378379\n",
      "Iteration 40962 => Loss: 45.03793501850804403830\n",
      "Iteration 40963 => Loss: 45.03778199200407783565\n",
      "Iteration 40964 => Loss: 45.03762896670103543784\n",
      "Iteration 40965 => Loss: 45.03747594259893816115\n",
      "Iteration 40966 => Loss: 45.03732291969777179474\n",
      "Iteration 40967 => Loss: 45.03716989799752212775\n",
      "Iteration 40968 => Loss: 45.03701687749816784390\n",
      "Iteration 40969 => Loss: 45.03686385819972315403\n",
      "Iteration 40970 => Loss: 45.03671084010213832016\n",
      "Iteration 40971 => Loss: 45.03655782320546308028\n",
      "Iteration 40972 => Loss: 45.03640480750964769641\n",
      "Iteration 40973 => Loss: 45.03625179301468506310\n",
      "Iteration 40974 => Loss: 45.03609877972058228579\n",
      "Iteration 40975 => Loss: 45.03594576762730383734\n",
      "Iteration 40976 => Loss: 45.03579275673486392861\n",
      "Iteration 40977 => Loss: 45.03563974704325545417\n",
      "Iteration 40978 => Loss: 45.03548673855243578146\n",
      "Iteration 40979 => Loss: 45.03533373126244043760\n",
      "Iteration 40980 => Loss: 45.03518072517324100090\n",
      "Iteration 40981 => Loss: 45.03502772028480194422\n",
      "Iteration 40982 => Loss: 45.03487471659714458383\n",
      "Iteration 40983 => Loss: 45.03472171411025470888\n",
      "Iteration 40984 => Loss: 45.03456871282412521396\n",
      "Iteration 40985 => Loss: 45.03441571273874188819\n",
      "Iteration 40986 => Loss: 45.03426271385411183701\n",
      "Iteration 40987 => Loss: 45.03410971617019242785\n",
      "Iteration 40988 => Loss: 45.03395671968698366072\n",
      "Iteration 40989 => Loss: 45.03380372440447132476\n",
      "Iteration 40990 => Loss: 45.03365073032269094711\n",
      "Iteration 40991 => Loss: 45.03349773744158568434\n",
      "Iteration 40992 => Loss: 45.03334474576114843103\n",
      "Iteration 40993 => Loss: 45.03319175528140050346\n",
      "Iteration 40994 => Loss: 45.03303876600228505822\n",
      "Iteration 40995 => Loss: 45.03288577792385183329\n",
      "Iteration 40996 => Loss: 45.03273279104603687983\n",
      "Iteration 40997 => Loss: 45.03257980536887572498\n",
      "Iteration 40998 => Loss: 45.03242682089234705245\n",
      "Iteration 40999 => Loss: 45.03227383761642954596\n",
      "Iteration 41000 => Loss: 45.03212085554109478380\n",
      "Iteration 41001 => Loss: 45.03196787466634987140\n",
      "Iteration 41002 => Loss: 45.03181489499220901962\n",
      "Iteration 41003 => Loss: 45.03166191651864380674\n",
      "Iteration 41004 => Loss: 45.03150893924562581105\n",
      "Iteration 41005 => Loss: 45.03135596317318345427\n",
      "Iteration 41006 => Loss: 45.03120298830130252554\n",
      "Iteration 41007 => Loss: 45.03105001462994749772\n",
      "Iteration 41008 => Loss: 45.03089704215911837082\n",
      "Iteration 41009 => Loss: 45.03074407088879382854\n",
      "Iteration 41010 => Loss: 45.03059110081902360889\n",
      "Iteration 41011 => Loss: 45.03043813194971534131\n",
      "Iteration 41012 => Loss: 45.03028516428092586921\n",
      "Iteration 41013 => Loss: 45.03013219781259124375\n",
      "Iteration 41014 => Loss: 45.02997923254474699206\n",
      "Iteration 41015 => Loss: 45.02982626847735048159\n",
      "Iteration 41016 => Loss: 45.02967330561040881776\n",
      "Iteration 41017 => Loss: 45.02952034394392200056\n",
      "Iteration 41018 => Loss: 45.02936738347789003001\n",
      "Iteration 41019 => Loss: 45.02921442421227027353\n",
      "Iteration 41020 => Loss: 45.02906146614703430942\n",
      "Iteration 41021 => Loss: 45.02890850928224608651\n",
      "Iteration 41022 => Loss: 45.02875555361784165598\n",
      "Iteration 41023 => Loss: 45.02860259915382812324\n",
      "Iteration 41024 => Loss: 45.02844964589016996115\n",
      "Iteration 41025 => Loss: 45.02829669382690269686\n",
      "Iteration 41026 => Loss: 45.02814374296399080322\n",
      "Iteration 41027 => Loss: 45.02799079330144138567\n",
      "Iteration 41028 => Loss: 45.02783784483922602249\n",
      "Iteration 41029 => Loss: 45.02768489757731629197\n",
      "Iteration 41030 => Loss: 45.02753195151575482669\n",
      "Iteration 41031 => Loss: 45.02737900665451320492\n",
      "Iteration 41032 => Loss: 45.02722606299355589954\n",
      "Iteration 41033 => Loss: 45.02707312053289001597\n",
      "Iteration 41034 => Loss: 45.02692017927252976506\n",
      "Iteration 41035 => Loss: 45.02676723921243961968\n",
      "Iteration 41036 => Loss: 45.02661430035261247440\n",
      "Iteration 41037 => Loss: 45.02646136269302701294\n",
      "Iteration 41038 => Loss: 45.02630842623370455158\n",
      "Iteration 41039 => Loss: 45.02615549097460956318\n",
      "Iteration 41040 => Loss: 45.02600255691574204775\n",
      "Iteration 41041 => Loss: 45.02584962405710911071\n",
      "Iteration 41042 => Loss: 45.02569669239865390864\n",
      "Iteration 41043 => Loss: 45.02554376194043328496\n",
      "Iteration 41044 => Loss: 45.02539083268237618540\n",
      "Iteration 41045 => Loss: 45.02523790462451103167\n",
      "Iteration 41046 => Loss: 45.02508497776680940206\n",
      "Iteration 41047 => Loss: 45.02493205210929971827\n",
      "Iteration 41048 => Loss: 45.02477912765190382061\n",
      "Iteration 41049 => Loss: 45.02462620439467144706\n",
      "Iteration 41050 => Loss: 45.02447328233756707050\n",
      "Iteration 41051 => Loss: 45.02432036148058358549\n",
      "Iteration 41052 => Loss: 45.02416744182372099203\n",
      "Iteration 41053 => Loss: 45.02401452336695797385\n",
      "Iteration 41054 => Loss: 45.02386160611030163636\n",
      "Iteration 41055 => Loss: 45.02370869005373776872\n",
      "Iteration 41056 => Loss: 45.02355577519723794921\n",
      "Iteration 41057 => Loss: 45.02340286154080217784\n",
      "Iteration 41058 => Loss: 45.02324994908443045460\n",
      "Iteration 41059 => Loss: 45.02309703782809435779\n",
      "Iteration 41060 => Loss: 45.02294412777182230911\n",
      "Iteration 41061 => Loss: 45.02279121891557167601\n",
      "Iteration 41062 => Loss: 45.02263831125932114219\n",
      "Iteration 41063 => Loss: 45.02248540480310623479\n",
      "Iteration 41064 => Loss: 45.02233249954687011041\n",
      "Iteration 41065 => Loss: 45.02217959549066250702\n",
      "Iteration 41066 => Loss: 45.02202669263441947578\n",
      "Iteration 41067 => Loss: 45.02187379097813391127\n",
      "Iteration 41068 => Loss: 45.02172089052184134061\n",
      "Iteration 41069 => Loss: 45.02156799126547781498\n",
      "Iteration 41070 => Loss: 45.02141509320907175606\n",
      "Iteration 41071 => Loss: 45.02126219635261605845\n",
      "Iteration 41072 => Loss: 45.02110930069605387871\n",
      "Iteration 41073 => Loss: 45.02095640623942074399\n",
      "Iteration 41074 => Loss: 45.02080351298271665428\n",
      "Iteration 41075 => Loss: 45.02065062092588476617\n",
      "Iteration 41076 => Loss: 45.02049773006894639593\n",
      "Iteration 41077 => Loss: 45.02034484041188733272\n",
      "Iteration 41078 => Loss: 45.02019195195472889282\n",
      "Iteration 41079 => Loss: 45.02003906469740712737\n",
      "Iteration 41080 => Loss: 45.01988617863991493095\n",
      "Iteration 41081 => Loss: 45.01973329378228783071\n",
      "Iteration 41082 => Loss: 45.01958041012449029949\n",
      "Iteration 41083 => Loss: 45.01942752766652233731\n",
      "Iteration 41084 => Loss: 45.01927464640834131160\n",
      "Iteration 41085 => Loss: 45.01912176634999696034\n",
      "Iteration 41086 => Loss: 45.01896888749143244013\n",
      "Iteration 41087 => Loss: 45.01881600983264775095\n",
      "Iteration 41088 => Loss: 45.01866313337365710368\n",
      "Iteration 41089 => Loss: 45.01851025811441786573\n",
      "Iteration 41090 => Loss: 45.01835738405493714254\n",
      "Iteration 41091 => Loss: 45.01820451119521493411\n",
      "Iteration 41092 => Loss: 45.01805163953520150244\n",
      "Iteration 41093 => Loss: 45.01789876907495369096\n",
      "Iteration 41094 => Loss: 45.01774589981440044539\n",
      "Iteration 41095 => Loss: 45.01759303175354887117\n",
      "Iteration 41096 => Loss: 45.01744016489242738999\n",
      "Iteration 41097 => Loss: 45.01728729923097915844\n",
      "Iteration 41098 => Loss: 45.01713443476922549280\n",
      "Iteration 41099 => Loss: 45.01698157150714507679\n",
      "Iteration 41100 => Loss: 45.01682870944472369956\n",
      "Iteration 41101 => Loss: 45.01667584858194004482\n",
      "Iteration 41102 => Loss: 45.01652298891880832343\n",
      "Iteration 41103 => Loss: 45.01637013045531432454\n",
      "Iteration 41104 => Loss: 45.01621727319142962642\n",
      "Iteration 41105 => Loss: 45.01606441712718265080\n",
      "Iteration 41106 => Loss: 45.01591156226253076511\n",
      "Iteration 41107 => Loss: 45.01575870859748818020\n",
      "Iteration 41108 => Loss: 45.01560585613202647437\n",
      "Iteration 41109 => Loss: 45.01545300486613143676\n",
      "Iteration 41110 => Loss: 45.01530015479983859450\n",
      "Iteration 41111 => Loss: 45.01514730593306268247\n",
      "Iteration 41112 => Loss: 45.01499445826586054409\n",
      "Iteration 41113 => Loss: 45.01484161179819665222\n",
      "Iteration 41114 => Loss: 45.01468876653004969057\n",
      "Iteration 41115 => Loss: 45.01453592246144097544\n",
      "Iteration 41116 => Loss: 45.01438307959234208511\n",
      "Iteration 41117 => Loss: 45.01423023792273880872\n",
      "Iteration 41118 => Loss: 45.01407739745264535713\n",
      "Iteration 41119 => Loss: 45.01392455818201199236\n",
      "Iteration 41120 => Loss: 45.01377172011086003067\n",
      "Iteration 41121 => Loss: 45.01361888323919657751\n",
      "Iteration 41122 => Loss: 45.01346604756695057858\n",
      "Iteration 41123 => Loss: 45.01331321309416466647\n",
      "Iteration 41124 => Loss: 45.01316037982083884117\n",
      "Iteration 41125 => Loss: 45.01300754774690915383\n",
      "Iteration 41126 => Loss: 45.01285471687243244787\n",
      "Iteration 41127 => Loss: 45.01270188719733056359\n",
      "Iteration 41128 => Loss: 45.01254905872163902814\n",
      "Iteration 41129 => Loss: 45.01239623144533652521\n",
      "Iteration 41130 => Loss: 45.01224340536841594940\n",
      "Iteration 41131 => Loss: 45.01209058049087019526\n",
      "Iteration 41132 => Loss: 45.01193775681269215738\n",
      "Iteration 41133 => Loss: 45.01178493433384630862\n",
      "Iteration 41134 => Loss: 45.01163211305436107068\n",
      "Iteration 41135 => Loss: 45.01147929297420091643\n",
      "Iteration 41136 => Loss: 45.01132647409335874045\n",
      "Iteration 41137 => Loss: 45.01117365641182743730\n",
      "Iteration 41138 => Loss: 45.01102083992962832326\n",
      "Iteration 41139 => Loss: 45.01086802464671876578\n",
      "Iteration 41140 => Loss: 45.01071521056306323771\n",
      "Iteration 41141 => Loss: 45.01056239767873279334\n",
      "Iteration 41142 => Loss: 45.01040958599363506210\n",
      "Iteration 41143 => Loss: 45.01025677550779846570\n",
      "Iteration 41144 => Loss: 45.01010396622121589871\n",
      "Iteration 41145 => Loss: 45.00995115813388025572\n",
      "Iteration 41146 => Loss: 45.00979835124576311500\n",
      "Iteration 41147 => Loss: 45.00964554555687158199\n",
      "Iteration 41148 => Loss: 45.00949274106718434041\n",
      "Iteration 41149 => Loss: 45.00933993777671560110\n",
      "Iteration 41150 => Loss: 45.00918713568540852066\n",
      "Iteration 41151 => Loss: 45.00903433479331994249\n",
      "Iteration 41152 => Loss: 45.00888153510037170690\n",
      "Iteration 41153 => Loss: 45.00872873660660644646\n",
      "Iteration 41154 => Loss: 45.00857593931200995030\n",
      "Iteration 41155 => Loss: 45.00842314321653958586\n",
      "Iteration 41156 => Loss: 45.00827034832018824773\n",
      "Iteration 41157 => Loss: 45.00811755462298435759\n",
      "Iteration 41158 => Loss: 45.00796476212489238833\n",
      "Iteration 41159 => Loss: 45.00781197082591233993\n",
      "Iteration 41160 => Loss: 45.00765918072602289612\n",
      "Iteration 41161 => Loss: 45.00750639182523826776\n",
      "Iteration 41162 => Loss: 45.00735360412351582227\n",
      "Iteration 41163 => Loss: 45.00720081762088398136\n",
      "Iteration 41164 => Loss: 45.00704803231727879620\n",
      "Iteration 41165 => Loss: 45.00689524821275000477\n",
      "Iteration 41166 => Loss: 45.00674246530725497450\n",
      "Iteration 41167 => Loss: 45.00658968360080081084\n",
      "Iteration 41168 => Loss: 45.00643690309335909205\n",
      "Iteration 41169 => Loss: 45.00628412378493692358\n",
      "Iteration 41170 => Loss: 45.00613134567551298915\n",
      "Iteration 41171 => Loss: 45.00597856876509439417\n",
      "Iteration 41172 => Loss: 45.00582579305364561151\n",
      "Iteration 41173 => Loss: 45.00567301854118795745\n",
      "Iteration 41174 => Loss: 45.00552024522769301029\n",
      "Iteration 41175 => Loss: 45.00536747311314655917\n",
      "Iteration 41176 => Loss: 45.00521470219755570952\n",
      "Iteration 41177 => Loss: 45.00506193248089203962\n",
      "Iteration 41178 => Loss: 45.00490916396316976034\n",
      "Iteration 41179 => Loss: 45.00475639664435334453\n",
      "Iteration 41180 => Loss: 45.00460363052444989762\n",
      "Iteration 41181 => Loss: 45.00445086560344520876\n",
      "Iteration 41182 => Loss: 45.00429810188135348881\n",
      "Iteration 41183 => Loss: 45.00414533935813210519\n",
      "Iteration 41184 => Loss: 45.00399257803378105791\n",
      "Iteration 41185 => Loss: 45.00383981790827903069\n",
      "Iteration 41186 => Loss: 45.00368705898164023438\n",
      "Iteration 41187 => Loss: 45.00353430125384335270\n",
      "Iteration 41188 => Loss: 45.00338154472488128022\n",
      "Iteration 41189 => Loss: 45.00322878939474691151\n",
      "Iteration 41190 => Loss: 45.00307603526344024658\n",
      "Iteration 41191 => Loss: 45.00292328233093286372\n",
      "Iteration 41192 => Loss: 45.00277053059721055206\n",
      "Iteration 41193 => Loss: 45.00261778006228752247\n",
      "Iteration 41194 => Loss: 45.00246503072615666952\n",
      "Iteration 41195 => Loss: 45.00231228258876114978\n",
      "Iteration 41196 => Loss: 45.00215953565014359583\n",
      "Iteration 41197 => Loss: 45.00200678991027558595\n",
      "Iteration 41198 => Loss: 45.00185404536915001472\n",
      "Iteration 41199 => Loss: 45.00170130202673846043\n",
      "Iteration 41200 => Loss: 45.00154855988308355563\n",
      "Iteration 41201 => Loss: 45.00139581893810714064\n",
      "Iteration 41202 => Loss: 45.00124307919185184801\n",
      "Iteration 41203 => Loss: 45.00109034064428215061\n",
      "Iteration 41204 => Loss: 45.00093760329539094300\n",
      "Iteration 41205 => Loss: 45.00078486714517111977\n",
      "Iteration 41206 => Loss: 45.00063213219362978634\n",
      "Iteration 41207 => Loss: 45.00047939844073141558\n",
      "Iteration 41208 => Loss: 45.00032666588650442918\n",
      "Iteration 41209 => Loss: 45.00017393453090619460\n",
      "Iteration 41210 => Loss: 45.00002120437391539554\n",
      "Iteration 41211 => Loss: 44.99986847541555334828\n",
      "Iteration 41212 => Loss: 44.99971574765581294741\n",
      "Iteration 41213 => Loss: 44.99956302109465866579\n",
      "Iteration 41214 => Loss: 44.99941029573209760883\n",
      "Iteration 41215 => Loss: 44.99925757156810846027\n",
      "Iteration 41216 => Loss: 44.99910484860269832552\n",
      "Iteration 41217 => Loss: 44.99895212683586009916\n",
      "Iteration 41218 => Loss: 44.99879940626755825406\n",
      "Iteration 41219 => Loss: 44.99864668689780700106\n",
      "Iteration 41220 => Loss: 44.99849396872658502389\n",
      "Iteration 41221 => Loss: 44.99834125175388521711\n",
      "Iteration 41222 => Loss: 44.99818853597971468616\n",
      "Iteration 41223 => Loss: 44.99803582140405922019\n",
      "Iteration 41224 => Loss: 44.99788310802687618661\n",
      "Iteration 41225 => Loss: 44.99773039584816558545\n",
      "Iteration 41226 => Loss: 44.99757768486794873297\n",
      "Iteration 41227 => Loss: 44.99742497508619720747\n",
      "Iteration 41228 => Loss: 44.99727226650292521981\n",
      "Iteration 41229 => Loss: 44.99711955911806882114\n",
      "Iteration 41230 => Loss: 44.99696685293168485487\n",
      "Iteration 41231 => Loss: 44.99681414794371647758\n",
      "Iteration 41232 => Loss: 44.99666144415416368929\n",
      "Iteration 41233 => Loss: 44.99650874156301227913\n",
      "Iteration 41234 => Loss: 44.99635604017029066881\n",
      "Iteration 41235 => Loss: 44.99620333997594201492\n",
      "Iteration 41236 => Loss: 44.99605064097998763373\n",
      "Iteration 41237 => Loss: 44.99589794318238489268\n",
      "Iteration 41238 => Loss: 44.99574524658317642434\n",
      "Iteration 41239 => Loss: 44.99559255118229827985\n",
      "Iteration 41240 => Loss: 44.99543985697978598637\n",
      "Iteration 41241 => Loss: 44.99528716397558980589\n",
      "Iteration 41242 => Loss: 44.99513447216973105469\n",
      "Iteration 41243 => Loss: 44.99498178156219552193\n",
      "Iteration 41244 => Loss: 44.99482909215297610217\n",
      "Iteration 41245 => Loss: 44.99467640394202305743\n",
      "Iteration 41246 => Loss: 44.99452371692937191483\n",
      "Iteration 41247 => Loss: 44.99437103111501556896\n",
      "Iteration 41248 => Loss: 44.99421834649891138724\n",
      "Iteration 41249 => Loss: 44.99406566308107358054\n",
      "Iteration 41250 => Loss: 44.99391298086148083257\n",
      "Iteration 41251 => Loss: 44.99376029984014735419\n",
      "Iteration 41252 => Loss: 44.99360762001704472368\n",
      "Iteration 41253 => Loss: 44.99345494139215162477\n",
      "Iteration 41254 => Loss: 44.99330226396547516288\n",
      "Iteration 41255 => Loss: 44.99314958773701533801\n",
      "Iteration 41256 => Loss: 44.99299691270671530674\n",
      "Iteration 41257 => Loss: 44.99284423887466033420\n",
      "Iteration 41258 => Loss: 44.99269156624072962813\n",
      "Iteration 41259 => Loss: 44.99253889480499424280\n",
      "Iteration 41260 => Loss: 44.99238622456739733479\n",
      "Iteration 41261 => Loss: 44.99223355552796732582\n",
      "Iteration 41262 => Loss: 44.99208088768667579416\n",
      "Iteration 41263 => Loss: 44.99192822104349431811\n",
      "Iteration 41264 => Loss: 44.99177555559843000310\n",
      "Iteration 41265 => Loss: 44.99162289135147574370\n",
      "Iteration 41266 => Loss: 44.99147022830265996163\n",
      "Iteration 41267 => Loss: 44.99131756645191870803\n",
      "Iteration 41268 => Loss: 44.99116490579923066662\n",
      "Iteration 41269 => Loss: 44.99101224634463846996\n",
      "Iteration 41270 => Loss: 44.99085958808809948550\n",
      "Iteration 41271 => Loss: 44.99070693102962792409\n",
      "Iteration 41272 => Loss: 44.99055427516919536401\n",
      "Iteration 41273 => Loss: 44.99040162050680180528\n",
      "Iteration 41274 => Loss: 44.99024896704242593160\n",
      "Iteration 41275 => Loss: 44.99009631477606774297\n",
      "Iteration 41276 => Loss: 44.98994366370771302854\n",
      "Iteration 41277 => Loss: 44.98979101383736178832\n",
      "Iteration 41278 => Loss: 44.98963836516501402230\n",
      "Iteration 41279 => Loss: 44.98948571769062709791\n",
      "Iteration 41280 => Loss: 44.98933307141421522601\n",
      "Iteration 41281 => Loss: 44.98918042633574998490\n",
      "Iteration 41282 => Loss: 44.98902778245525269085\n",
      "Iteration 41283 => Loss: 44.98887513977268071130\n",
      "Iteration 41284 => Loss: 44.98872249828805536254\n",
      "Iteration 41285 => Loss: 44.98856985800134111741\n",
      "Iteration 41286 => Loss: 44.98841721891253087051\n",
      "Iteration 41287 => Loss: 44.98826458102166725439\n",
      "Iteration 41288 => Loss: 44.98811194432867210935\n",
      "Iteration 41289 => Loss: 44.98795930883355964625\n",
      "Iteration 41290 => Loss: 44.98780667453630144337\n",
      "Iteration 41291 => Loss: 44.98765404143693302785\n",
      "Iteration 41292 => Loss: 44.98750140953541887257\n",
      "Iteration 41293 => Loss: 44.98734877883174476665\n",
      "Iteration 41294 => Loss: 44.98719614932591071010\n",
      "Iteration 41295 => Loss: 44.98704352101791670293\n",
      "Iteration 41296 => Loss: 44.98689089390772721799\n",
      "Iteration 41297 => Loss: 44.98673826799537067700\n",
      "Iteration 41298 => Loss: 44.98658564328078313110\n",
      "Iteration 41299 => Loss: 44.98643301976399300202\n",
      "Iteration 41300 => Loss: 44.98628039744498607888\n",
      "Iteration 41301 => Loss: 44.98612777632376236170\n",
      "Iteration 41302 => Loss: 44.98597515640030763961\n",
      "Iteration 41303 => Loss: 44.98582253767457928006\n",
      "Iteration 41304 => Loss: 44.98566992014661281019\n",
      "Iteration 41305 => Loss: 44.98551730381637270284\n",
      "Iteration 41306 => Loss: 44.98536468868386606346\n",
      "Iteration 41307 => Loss: 44.98521207474906447032\n",
      "Iteration 41308 => Loss: 44.98505946201197502887\n",
      "Iteration 41309 => Loss: 44.98490685047257642282\n",
      "Iteration 41310 => Loss: 44.98475424013088286301\n",
      "Iteration 41311 => Loss: 44.98460163098684461147\n",
      "Iteration 41312 => Loss: 44.98444902304049008990\n",
      "Iteration 41313 => Loss: 44.98429641629178377116\n",
      "Iteration 41314 => Loss: 44.98414381074073986611\n",
      "Iteration 41315 => Loss: 44.98399120638732284760\n",
      "Iteration 41316 => Loss: 44.98383860323153271565\n",
      "Iteration 41317 => Loss: 44.98368600127339078654\n",
      "Iteration 41318 => Loss: 44.98353340051284732226\n",
      "Iteration 41319 => Loss: 44.98338080094990232283\n",
      "Iteration 41320 => Loss: 44.98322820258454868281\n",
      "Iteration 41321 => Loss: 44.98307560541677219135\n",
      "Iteration 41322 => Loss: 44.98292300944658705930\n",
      "Iteration 41323 => Loss: 44.98277041467396486496\n",
      "Iteration 41324 => Loss: 44.98261782109889850290\n",
      "Iteration 41325 => Loss: 44.98246522872137376226\n",
      "Iteration 41326 => Loss: 44.98231263754136932675\n",
      "Iteration 41327 => Loss: 44.98216004755892072353\n",
      "Iteration 41328 => Loss: 44.98200745877397821459\n",
      "Iteration 41329 => Loss: 44.98185487118654179994\n",
      "Iteration 41330 => Loss: 44.98170228479660437415\n",
      "Iteration 41331 => Loss: 44.98154969960417304264\n",
      "Iteration 41332 => Loss: 44.98139711560921938371\n",
      "Iteration 41333 => Loss: 44.98124453281171497565\n",
      "Iteration 41334 => Loss: 44.98109195121168824016\n",
      "Iteration 41335 => Loss: 44.98093937080910365012\n",
      "Iteration 41336 => Loss: 44.98078679160397541636\n",
      "Iteration 41337 => Loss: 44.98063421359626090634\n",
      "Iteration 41338 => Loss: 44.98048163678599564719\n",
      "Iteration 41339 => Loss: 44.98032906117312990091\n",
      "Iteration 41340 => Loss: 44.98017648675767077293\n",
      "Iteration 41341 => Loss: 44.98002391353961826326\n",
      "Iteration 41342 => Loss: 44.97987134151894395018\n",
      "Iteration 41343 => Loss: 44.97971877069563362284\n",
      "Iteration 41344 => Loss: 44.97956620106970149209\n",
      "Iteration 41345 => Loss: 44.97941363264114045251\n",
      "Iteration 41346 => Loss: 44.97926106540992208238\n",
      "Iteration 41347 => Loss: 44.97910849937603927629\n",
      "Iteration 41348 => Loss: 44.97895593453948492879\n",
      "Iteration 41349 => Loss: 44.97880337090025903990\n",
      "Iteration 41350 => Loss: 44.97865080845833318790\n",
      "Iteration 41351 => Loss: 44.97849824721371447822\n",
      "Iteration 41352 => Loss: 44.97834568716639580543\n",
      "Iteration 41353 => Loss: 44.97819312831632743155\n",
      "Iteration 41354 => Loss: 44.97804057066358041084\n",
      "Iteration 41355 => Loss: 44.97788801420808368903\n",
      "Iteration 41356 => Loss: 44.97773545894981594984\n",
      "Iteration 41357 => Loss: 44.97758290488881982583\n",
      "Iteration 41358 => Loss: 44.97743035202505268444\n",
      "Iteration 41359 => Loss: 44.97727780035850031481\n",
      "Iteration 41360 => Loss: 44.97712524988919824409\n",
      "Iteration 41361 => Loss: 44.97697270061707541799\n",
      "Iteration 41362 => Loss: 44.97682015254215315281\n",
      "Iteration 41363 => Loss: 44.97666760566443855396\n",
      "Iteration 41364 => Loss: 44.97651505998387477803\n",
      "Iteration 41365 => Loss: 44.97636251550049735215\n",
      "Iteration 41366 => Loss: 44.97620997221429206547\n",
      "Iteration 41367 => Loss: 44.97605743012523049629\n",
      "Iteration 41368 => Loss: 44.97590488923331264459\n",
      "Iteration 41369 => Loss: 44.97575234953852429953\n",
      "Iteration 41370 => Loss: 44.97559981104085125025\n",
      "Iteration 41371 => Loss: 44.97544727374030060219\n",
      "Iteration 41372 => Loss: 44.97529473763684393361\n",
      "Iteration 41373 => Loss: 44.97514220273050256083\n",
      "Iteration 41374 => Loss: 44.97498966902123385125\n",
      "Iteration 41375 => Loss: 44.97483713650905201575\n",
      "Iteration 41376 => Loss: 44.97468460519392863262\n",
      "Iteration 41377 => Loss: 44.97453207507585659641\n",
      "Iteration 41378 => Loss: 44.97437954615486432886\n",
      "Iteration 41379 => Loss: 44.97422701843088077567\n",
      "Iteration 41380 => Loss: 44.97407449190393435856\n",
      "Iteration 41381 => Loss: 44.97392196657399665582\n",
      "Iteration 41382 => Loss: 44.97376944244108187831\n",
      "Iteration 41383 => Loss: 44.97361691950517581517\n",
      "Iteration 41384 => Loss: 44.97346439776623583384\n",
      "Iteration 41385 => Loss: 44.97331187722430456688\n",
      "Iteration 41386 => Loss: 44.97315935787934648715\n",
      "Iteration 41387 => Loss: 44.97300683973132606752\n",
      "Iteration 41388 => Loss: 44.97285432278029304598\n",
      "Iteration 41389 => Loss: 44.97270180702618347368\n",
      "Iteration 41390 => Loss: 44.97254929246901156148\n",
      "Iteration 41391 => Loss: 44.97239677910877730938\n",
      "Iteration 41392 => Loss: 44.97224426694545229566\n",
      "Iteration 41393 => Loss: 44.97209175597903652033\n",
      "Iteration 41394 => Loss: 44.97193924620950866711\n",
      "Iteration 41395 => Loss: 44.97178673763687584142\n",
      "Iteration 41396 => Loss: 44.97163423026113093783\n",
      "Iteration 41397 => Loss: 44.97148172408223842922\n",
      "Iteration 41398 => Loss: 44.97132921910021252643\n",
      "Iteration 41399 => Loss: 44.97117671531506744032\n",
      "Iteration 41400 => Loss: 44.97102421272671790575\n",
      "Iteration 41401 => Loss: 44.97087171133522076616\n",
      "Iteration 41402 => Loss: 44.97071921114055470525\n",
      "Iteration 41403 => Loss: 44.97056671214269840675\n",
      "Iteration 41404 => Loss: 44.97041421434163055437\n",
      "Iteration 41405 => Loss: 44.97026171773737956983\n",
      "Iteration 41406 => Loss: 44.97010922232990282055\n",
      "Iteration 41407 => Loss: 44.96995672811918609568\n",
      "Iteration 41408 => Loss: 44.96980423510525071151\n",
      "Iteration 41409 => Loss: 44.96965174328808956261\n",
      "Iteration 41410 => Loss: 44.96949925266765291099\n",
      "Iteration 41411 => Loss: 44.96934676324396207292\n",
      "Iteration 41412 => Loss: 44.96919427501701704841\n",
      "Iteration 41413 => Loss: 44.96904178798674678319\n",
      "Iteration 41414 => Loss: 44.96888930215323654238\n",
      "Iteration 41415 => Loss: 44.96873681751640106086\n",
      "Iteration 41416 => Loss: 44.96858433407625454947\n",
      "Iteration 41417 => Loss: 44.96843185183279700823\n",
      "Iteration 41418 => Loss: 44.96827937078601422627\n",
      "Iteration 41419 => Loss: 44.96812689093588488731\n",
      "Iteration 41420 => Loss: 44.96797441228242320221\n",
      "Iteration 41421 => Loss: 44.96782193482561496012\n",
      "Iteration 41422 => Loss: 44.96766945856541752846\n",
      "Iteration 41423 => Loss: 44.96751698350185932895\n",
      "Iteration 41424 => Loss: 44.96736450963489772903\n",
      "Iteration 41425 => Loss: 44.96721203696456825583\n",
      "Iteration 41426 => Loss: 44.96705956549082827678\n",
      "Iteration 41427 => Loss: 44.96690709521366358103\n",
      "Iteration 41428 => Loss: 44.96675462613307416859\n",
      "Iteration 41429 => Loss: 44.96660215824908135573\n",
      "Iteration 41430 => Loss: 44.96644969156164250990\n",
      "Iteration 41431 => Loss: 44.96629722607075763108\n",
      "Iteration 41432 => Loss: 44.96614476177638408672\n",
      "Iteration 41433 => Loss: 44.96599229867857872023\n",
      "Iteration 41434 => Loss: 44.96583983677727047734\n",
      "Iteration 41435 => Loss: 44.96568737607247356891\n",
      "Iteration 41436 => Loss: 44.96553491656419510036\n",
      "Iteration 41437 => Loss: 44.96538245825239954456\n",
      "Iteration 41438 => Loss: 44.96523000113710111236\n",
      "Iteration 41439 => Loss: 44.96507754521827848748\n",
      "Iteration 41440 => Loss: 44.96492509049590324821\n",
      "Iteration 41441 => Loss: 44.96477263696999671083\n",
      "Iteration 41442 => Loss: 44.96462018464053755906\n",
      "Iteration 41443 => Loss: 44.96446773350752579290\n",
      "Iteration 41444 => Loss: 44.96431528357092588521\n",
      "Iteration 41445 => Loss: 44.96416283483075204686\n",
      "Iteration 41446 => Loss: 44.96401038728698296154\n",
      "Iteration 41447 => Loss: 44.96385794093962573470\n",
      "Iteration 41448 => Loss: 44.96370549578863773377\n",
      "Iteration 41449 => Loss: 44.96355305183406869673\n",
      "Iteration 41450 => Loss: 44.96340060907584046390\n",
      "Iteration 41451 => Loss: 44.96324816751398145698\n",
      "Iteration 41452 => Loss: 44.96309572714847035968\n",
      "Iteration 41453 => Loss: 44.96294328797932848829\n",
      "Iteration 41454 => Loss: 44.96279085000647057768\n",
      "Iteration 41455 => Loss: 44.96263841322999610384\n",
      "Iteration 41456 => Loss: 44.96248597764981269620\n",
      "Iteration 41457 => Loss: 44.96233354326594167105\n",
      "Iteration 41458 => Loss: 44.96218111007834750126\n",
      "Iteration 41459 => Loss: 44.96202867808707992481\n",
      "Iteration 41460 => Loss: 44.96187624729203946572\n",
      "Iteration 41461 => Loss: 44.96172381769330428369\n",
      "Iteration 41462 => Loss: 44.96157138929081042988\n",
      "Iteration 41463 => Loss: 44.96141896208458632600\n",
      "Iteration 41464 => Loss: 44.96126653607456802320\n",
      "Iteration 41465 => Loss: 44.96111411126081236489\n",
      "Iteration 41466 => Loss: 44.96096168764326250766\n",
      "Iteration 41467 => Loss: 44.96080926522195397865\n",
      "Iteration 41468 => Loss: 44.96065684399680861816\n",
      "Iteration 41469 => Loss: 44.96050442396789748045\n",
      "Iteration 41470 => Loss: 44.96035200513514240583\n",
      "Iteration 41471 => Loss: 44.96019958749857181601\n",
      "Iteration 41472 => Loss: 44.96004717105813597300\n",
      "Iteration 41473 => Loss: 44.95989475581389882564\n",
      "Iteration 41474 => Loss: 44.95974234176579642508\n",
      "Iteration 41475 => Loss: 44.95958992891382877133\n",
      "Iteration 41476 => Loss: 44.95943751725798875896\n",
      "Iteration 41477 => Loss: 44.95928510679824796625\n",
      "Iteration 41478 => Loss: 44.95913269753464902578\n",
      "Iteration 41479 => Loss: 44.95898028946714219956\n",
      "Iteration 41480 => Loss: 44.95882788259572038214\n",
      "Iteration 41481 => Loss: 44.95867547692039778440\n",
      "Iteration 41482 => Loss: 44.95852307244111045748\n",
      "Iteration 41483 => Loss: 44.95837066915790813937\n",
      "Iteration 41484 => Loss: 44.95821826707074819751\n",
      "Iteration 41485 => Loss: 44.95806586617965905361\n",
      "Iteration 41486 => Loss: 44.95791346648456965340\n",
      "Iteration 41487 => Loss: 44.95776106798552262944\n",
      "Iteration 41488 => Loss: 44.95760867068247534917\n",
      "Iteration 41489 => Loss: 44.95745627457545623429\n",
      "Iteration 41490 => Loss: 44.95730387966441554681\n",
      "Iteration 41491 => Loss: 44.95715148594937460302\n",
      "Iteration 41492 => Loss: 44.95699909343029787578\n",
      "Iteration 41493 => Loss: 44.95684670210720668138\n",
      "Iteration 41494 => Loss: 44.95669431198007970352\n",
      "Iteration 41495 => Loss: 44.95654192304888141507\n",
      "Iteration 41496 => Loss: 44.95638953531363313232\n",
      "Iteration 41497 => Loss: 44.95623714877430643355\n",
      "Iteration 41498 => Loss: 44.95608476343089421334\n",
      "Iteration 41499 => Loss: 44.95593237928342489340\n",
      "Iteration 41500 => Loss: 44.95577999633184163031\n",
      "Iteration 41501 => Loss: 44.95562761457615152949\n",
      "Iteration 41502 => Loss: 44.95547523401634748552\n",
      "Iteration 41503 => Loss: 44.95532285465240107669\n",
      "Iteration 41504 => Loss: 44.95517047648433361928\n",
      "Iteration 41505 => Loss: 44.95501809951212379701\n",
      "Iteration 41506 => Loss: 44.95486572373576450445\n",
      "Iteration 41507 => Loss: 44.95471334915525574161\n",
      "Iteration 41508 => Loss: 44.95456097577054777048\n",
      "Iteration 41509 => Loss: 44.95440860358165480193\n",
      "Iteration 41510 => Loss: 44.95425623258859815223\n",
      "Iteration 41511 => Loss: 44.95410386279132097798\n",
      "Iteration 41512 => Loss: 44.95395149418983749001\n",
      "Iteration 41513 => Loss: 44.95379912678414768834\n",
      "Iteration 41514 => Loss: 44.95364676057420894040\n",
      "Iteration 41515 => Loss: 44.95349439556004966789\n",
      "Iteration 41516 => Loss: 44.95334203174164144912\n",
      "Iteration 41517 => Loss: 44.95318966911895586236\n",
      "Iteration 41518 => Loss: 44.95303730769202843476\n",
      "Iteration 41519 => Loss: 44.95288494746080942832\n",
      "Iteration 41520 => Loss: 44.95273258842531305390\n",
      "Iteration 41521 => Loss: 44.95258023058551799522\n",
      "Iteration 41522 => Loss: 44.95242787394141714685\n",
      "Iteration 41523 => Loss: 44.95227551849301050879\n",
      "Iteration 41524 => Loss: 44.95212316424027676476\n",
      "Iteration 41525 => Loss: 44.95197081118320880933\n",
      "Iteration 41526 => Loss: 44.95181845932182085335\n",
      "Iteration 41527 => Loss: 44.95166610865605605341\n",
      "Iteration 41528 => Loss: 44.95151375918592862035\n",
      "Iteration 41529 => Loss: 44.95136141091145276505\n",
      "Iteration 41530 => Loss: 44.95120906383258585493\n",
      "Iteration 41531 => Loss: 44.95105671794933499541\n",
      "Iteration 41532 => Loss: 44.95090437326167887022\n",
      "Iteration 41533 => Loss: 44.95075202976962458479\n",
      "Iteration 41534 => Loss: 44.95059968747316503368\n",
      "Iteration 41535 => Loss: 44.95044734637225758433\n",
      "Iteration 41536 => Loss: 44.95029500646691644761\n",
      "Iteration 41537 => Loss: 44.95014266775714162350\n",
      "Iteration 41538 => Loss: 44.94999033024291179572\n",
      "Iteration 41539 => Loss: 44.94983799392422696428\n",
      "Iteration 41540 => Loss: 44.94968565880105160204\n",
      "Iteration 41541 => Loss: 44.94953332487341413071\n",
      "Iteration 41542 => Loss: 44.94938099214125060143\n",
      "Iteration 41543 => Loss: 44.94922866060461075222\n",
      "Iteration 41544 => Loss: 44.94907633026346616134\n",
      "Iteration 41545 => Loss: 44.94892400111779551253\n",
      "Iteration 41546 => Loss: 44.94877167316760591120\n",
      "Iteration 41547 => Loss: 44.94861934641284761938\n",
      "Iteration 41548 => Loss: 44.94846702085358458589\n",
      "Iteration 41549 => Loss: 44.94831469648972444020\n",
      "Iteration 41550 => Loss: 44.94816237332129560400\n",
      "Iteration 41551 => Loss: 44.94801005134833360444\n",
      "Iteration 41552 => Loss: 44.94785773057074607095\n",
      "Iteration 41553 => Loss: 44.94770541098860405782\n",
      "Iteration 41554 => Loss: 44.94755309260182940534\n",
      "Iteration 41555 => Loss: 44.94740077541044342979\n",
      "Iteration 41556 => Loss: 44.94724845941442481490\n",
      "Iteration 41557 => Loss: 44.94709614461379487693\n",
      "Iteration 41558 => Loss: 44.94694383100852519419\n",
      "Iteration 41559 => Loss: 44.94679151859858023954\n",
      "Iteration 41560 => Loss: 44.94663920738398843469\n",
      "Iteration 41561 => Loss: 44.94648689736473556877\n",
      "Iteration 41562 => Loss: 44.94633458854079322009\n",
      "Iteration 41563 => Loss: 44.94618228091216138864\n",
      "Iteration 41564 => Loss: 44.94602997447884007443\n",
      "Iteration 41565 => Loss: 44.94587766924080085573\n",
      "Iteration 41566 => Loss: 44.94572536519807215427\n",
      "Iteration 41567 => Loss: 44.94557306235060423205\n",
      "Iteration 41568 => Loss: 44.94542076069839708907\n",
      "Iteration 41569 => Loss: 44.94526846024143651448\n",
      "Iteration 41570 => Loss: 44.94511616097972250827\n",
      "Iteration 41571 => Loss: 44.94496386291324085960\n",
      "Iteration 41572 => Loss: 44.94481156604201288474\n",
      "Iteration 41573 => Loss: 44.94465927036598174027\n",
      "Iteration 41574 => Loss: 44.94450697588515453162\n",
      "Iteration 41575 => Loss: 44.94435468259954546966\n",
      "Iteration 41576 => Loss: 44.94420239050910481637\n",
      "Iteration 41577 => Loss: 44.94405009961385388806\n",
      "Iteration 41578 => Loss: 44.94389780991377136843\n",
      "Iteration 41579 => Loss: 44.94374552140888567919\n",
      "Iteration 41580 => Loss: 44.94359323409911155522\n",
      "Iteration 41581 => Loss: 44.94344094798448452366\n",
      "Iteration 41582 => Loss: 44.94328866306499747907\n",
      "Iteration 41583 => Loss: 44.94313637934062910517\n",
      "Iteration 41584 => Loss: 44.94298409681138650740\n",
      "Iteration 41585 => Loss: 44.94283181547723415861\n",
      "Iteration 41586 => Loss: 44.94267953533819337508\n",
      "Iteration 41587 => Loss: 44.94252725639422152426\n",
      "Iteration 41588 => Loss: 44.94237497864533281700\n",
      "Iteration 41589 => Loss: 44.94222270209151304243\n",
      "Iteration 41590 => Loss: 44.94207042673276930600\n",
      "Iteration 41591 => Loss: 44.94191815256905186970\n",
      "Iteration 41592 => Loss: 44.94176587960038915526\n",
      "Iteration 41593 => Loss: 44.94161360782673853009\n",
      "Iteration 41594 => Loss: 44.94146133724812841592\n",
      "Iteration 41595 => Loss: 44.94130906786451618018\n",
      "Iteration 41596 => Loss: 44.94115679967590892829\n",
      "Iteration 41597 => Loss: 44.94100453268229244941\n",
      "Iteration 41598 => Loss: 44.94085226688368095438\n",
      "Iteration 41599 => Loss: 44.94070000228000338893\n",
      "Iteration 41600 => Loss: 44.94054773887131659649\n",
      "Iteration 41601 => Loss: 44.94039547665759926076\n",
      "Iteration 41602 => Loss: 44.94024321563878032748\n",
      "Iteration 41603 => Loss: 44.94009095581493795635\n",
      "Iteration 41604 => Loss: 44.93993869718601530394\n",
      "Iteration 41605 => Loss: 44.93978643975201237026\n",
      "Iteration 41606 => Loss: 44.93963418351290783903\n",
      "Iteration 41607 => Loss: 44.93948192846870881567\n",
      "Iteration 41608 => Loss: 44.93932967461940108933\n",
      "Iteration 41609 => Loss: 44.93917742196496334373\n",
      "Iteration 41610 => Loss: 44.93902517050539557886\n",
      "Iteration 41611 => Loss: 44.93887292024069779472\n",
      "Iteration 41612 => Loss: 44.93872067117086288590\n",
      "Iteration 41613 => Loss: 44.93856842329584821982\n",
      "Iteration 41614 => Loss: 44.93841617661568932363\n",
      "Iteration 41615 => Loss: 44.93826393113032935389\n",
      "Iteration 41616 => Loss: 44.93811168683980383776\n",
      "Iteration 41617 => Loss: 44.93795944374407724808\n",
      "Iteration 41618 => Loss: 44.93780720184313537402\n",
      "Iteration 41619 => Loss: 44.93765496113699953185\n",
      "Iteration 41620 => Loss: 44.93750272162561998357\n",
      "Iteration 41621 => Loss: 44.93735048330902515090\n",
      "Iteration 41622 => Loss: 44.93719824618719371756\n",
      "Iteration 41623 => Loss: 44.93704601026009726183\n",
      "Iteration 41624 => Loss: 44.93689377552773578373\n",
      "Iteration 41625 => Loss: 44.93674154199010217781\n",
      "Iteration 41626 => Loss: 44.93658930964721065493\n",
      "Iteration 41627 => Loss: 44.93643707849903279339\n",
      "Iteration 41628 => Loss: 44.93628484854552596062\n",
      "Iteration 41629 => Loss: 44.93613261978672568375\n",
      "Iteration 41630 => Loss: 44.93598039222261064651\n",
      "Iteration 41631 => Loss: 44.93582816585318084890\n",
      "Iteration 41632 => Loss: 44.93567594067840786920\n",
      "Iteration 41633 => Loss: 44.93552371669828460199\n",
      "Iteration 41634 => Loss: 44.93537149391281104727\n",
      "Iteration 41635 => Loss: 44.93521927232198009960\n",
      "Iteration 41636 => Loss: 44.93506705192576333729\n",
      "Iteration 41637 => Loss: 44.93491483272416786576\n",
      "Iteration 41638 => Loss: 44.93476261471718657958\n",
      "Iteration 41639 => Loss: 44.93461039790479105704\n",
      "Iteration 41640 => Loss: 44.93445818228698840358\n",
      "Iteration 41641 => Loss: 44.93430596786379283003\n",
      "Iteration 41642 => Loss: 44.93415375463513328214\n",
      "Iteration 41643 => Loss: 44.93400154260105239246\n",
      "Iteration 41644 => Loss: 44.93384933176152173928\n",
      "Iteration 41645 => Loss: 44.93369712211652000633\n",
      "Iteration 41646 => Loss: 44.93354491366608272074\n",
      "Iteration 41647 => Loss: 44.93339270641013882823\n",
      "Iteration 41648 => Loss: 44.93324050034872385595\n",
      "Iteration 41649 => Loss: 44.93308829548180938218\n",
      "Iteration 41650 => Loss: 44.93293609180938119607\n",
      "Iteration 41651 => Loss: 44.93278388933148193018\n",
      "Iteration 41652 => Loss: 44.93263168804801921397\n",
      "Iteration 41653 => Loss: 44.93247948795902146912\n",
      "Iteration 41654 => Loss: 44.93232728906450290651\n",
      "Iteration 41655 => Loss: 44.93217509136442089357\n",
      "Iteration 41656 => Loss: 44.93202289485876832487\n",
      "Iteration 41657 => Loss: 44.93187069954755941126\n",
      "Iteration 41658 => Loss: 44.93171850543076573103\n",
      "Iteration 41659 => Loss: 44.93156631250840149505\n",
      "Iteration 41660 => Loss: 44.93141412078042407074\n",
      "Iteration 41661 => Loss: 44.93126193024684766897\n",
      "Iteration 41662 => Loss: 44.93110974090764386801\n",
      "Iteration 41663 => Loss: 44.93095755276281266788\n",
      "Iteration 41664 => Loss: 44.93080536581236827942\n",
      "Iteration 41665 => Loss: 44.93065318005626096465\n",
      "Iteration 41666 => Loss: 44.93050099549449782899\n",
      "Iteration 41667 => Loss: 44.93034881212706466158\n",
      "Iteration 41668 => Loss: 44.93019662995397567329\n",
      "Iteration 41669 => Loss: 44.93004444897518823154\n",
      "Iteration 41670 => Loss: 44.92989226919073075805\n",
      "Iteration 41671 => Loss: 44.92974009060054640941\n",
      "Iteration 41672 => Loss: 44.92958791320467781816\n",
      "Iteration 41673 => Loss: 44.92943573700308235175\n",
      "Iteration 41674 => Loss: 44.92928356199573869389\n",
      "Iteration 41675 => Loss: 44.92913138818266816088\n",
      "Iteration 41676 => Loss: 44.92897921556384943642\n",
      "Iteration 41677 => Loss: 44.92882704413928962595\n",
      "Iteration 41678 => Loss: 44.92867487390894609689\n",
      "Iteration 41679 => Loss: 44.92852270487283306011\n",
      "Iteration 41680 => Loss: 44.92837053703092919932\n",
      "Iteration 41681 => Loss: 44.92821837038323451452\n",
      "Iteration 41682 => Loss: 44.92806620492971347858\n",
      "Iteration 41683 => Loss: 44.92791404067040872405\n",
      "Iteration 41684 => Loss: 44.92776187760527051296\n",
      "Iteration 41685 => Loss: 44.92760971573429884529\n",
      "Iteration 41686 => Loss: 44.92745755505749372105\n",
      "Iteration 41687 => Loss: 44.92730539557482671853\n",
      "Iteration 41688 => Loss: 44.92715323728631204858\n",
      "Iteration 41689 => Loss: 44.92700108019191418407\n",
      "Iteration 41690 => Loss: 44.92684892429164023042\n",
      "Iteration 41691 => Loss: 44.92669676958547597678\n",
      "Iteration 41692 => Loss: 44.92654461607342852858\n",
      "Iteration 41693 => Loss: 44.92639246375546946410\n",
      "Iteration 41694 => Loss: 44.92624031263157036165\n",
      "Iteration 41695 => Loss: 44.92608816270176674834\n",
      "Iteration 41696 => Loss: 44.92593601396603730791\n",
      "Iteration 41697 => Loss: 44.92578386642432519693\n",
      "Iteration 41698 => Loss: 44.92563172007668015340\n",
      "Iteration 41699 => Loss: 44.92547957492308796645\n",
      "Iteration 41700 => Loss: 44.92532743096349889811\n",
      "Iteration 41701 => Loss: 44.92517528819792715922\n",
      "Iteration 41702 => Loss: 44.92502314662640827692\n",
      "Iteration 41703 => Loss: 44.92487100624884988065\n",
      "Iteration 41704 => Loss: 44.92471886706527328670\n",
      "Iteration 41705 => Loss: 44.92456672907567849506\n",
      "Iteration 41706 => Loss: 44.92441459228008682203\n",
      "Iteration 41707 => Loss: 44.92426245667840589704\n",
      "Iteration 41708 => Loss: 44.92411032227072809064\n",
      "Iteration 41709 => Loss: 44.92395818905696103229\n",
      "Iteration 41710 => Loss: 44.92380605703714735455\n",
      "Iteration 41711 => Loss: 44.92365392621126574113\n",
      "Iteration 41712 => Loss: 44.92350179657927355947\n",
      "Iteration 41713 => Loss: 44.92334966814118502043\n",
      "Iteration 41714 => Loss: 44.92319754089700722943\n",
      "Iteration 41715 => Loss: 44.92304541484671176477\n",
      "Iteration 41716 => Loss: 44.92289328999029152101\n",
      "Iteration 41717 => Loss: 44.92274116632772518187\n",
      "Iteration 41718 => Loss: 44.92258904385905537993\n",
      "Iteration 41719 => Loss: 44.92243692258420395547\n",
      "Iteration 41720 => Loss: 44.92228480250318511935\n",
      "Iteration 41721 => Loss: 44.92213268361601308243\n",
      "Iteration 41722 => Loss: 44.92198056592267363385\n",
      "Iteration 41723 => Loss: 44.92182844942312414105\n",
      "Iteration 41724 => Loss: 44.92167633411740013116\n",
      "Iteration 41725 => Loss: 44.92152422000543765535\n",
      "Iteration 41726 => Loss: 44.92137210708728645159\n",
      "Iteration 41727 => Loss: 44.92121999536290388733\n",
      "Iteration 41728 => Loss: 44.92106788483227575171\n",
      "Iteration 41729 => Loss: 44.92091577549540915015\n",
      "Iteration 41730 => Loss: 44.92076366735227566096\n",
      "Iteration 41731 => Loss: 44.92061156040290370584\n",
      "Iteration 41732 => Loss: 44.92045945464725065222\n",
      "Iteration 41733 => Loss: 44.92030735008529518382\n",
      "Iteration 41734 => Loss: 44.92015524671707282778\n",
      "Iteration 41735 => Loss: 44.92000314454254095153\n",
      "Iteration 41736 => Loss: 44.91985104356168534423\n",
      "Iteration 41737 => Loss: 44.91969894377454153300\n",
      "Iteration 41738 => Loss: 44.91954684518104556901\n",
      "Iteration 41739 => Loss: 44.91939474778121166310\n",
      "Iteration 41740 => Loss: 44.91924265157502560442\n",
      "Iteration 41741 => Loss: 44.91909055656251581468\n",
      "Iteration 41742 => Loss: 44.91893846274361123960\n",
      "Iteration 41743 => Loss: 44.91878637011834030091\n",
      "Iteration 41744 => Loss: 44.91863427868669589316\n",
      "Iteration 41745 => Loss: 44.91848218844862117294\n",
      "Iteration 41746 => Loss: 44.91833009940416587824\n",
      "Iteration 41747 => Loss: 44.91817801155328027107\n",
      "Iteration 41748 => Loss: 44.91802592489599277314\n",
      "Iteration 41749 => Loss: 44.91787383943226075189\n",
      "Iteration 41750 => Loss: 44.91772175516209841817\n",
      "Iteration 41751 => Loss: 44.91756967208547735027\n",
      "Iteration 41752 => Loss: 44.91741759020241175904\n",
      "Iteration 41753 => Loss: 44.91726550951285190649\n",
      "Iteration 41754 => Loss: 44.91711343001683331977\n",
      "Iteration 41755 => Loss: 44.91696135171430626087\n",
      "Iteration 41756 => Loss: 44.91680927460531336237\n",
      "Iteration 41757 => Loss: 44.91665719868979067542\n",
      "Iteration 41758 => Loss: 44.91650512396773820001\n",
      "Iteration 41759 => Loss: 44.91635305043919856871\n",
      "Iteration 41760 => Loss: 44.91620097810409362182\n",
      "Iteration 41761 => Loss: 44.91604890696245178106\n",
      "Iteration 41762 => Loss: 44.91589683701426594098\n",
      "Iteration 41763 => Loss: 44.91574476825948636360\n",
      "Iteration 41764 => Loss: 44.91559270069817699778\n",
      "Iteration 41765 => Loss: 44.91544063433028100008\n",
      "Iteration 41766 => Loss: 44.91528856915576284337\n",
      "Iteration 41767 => Loss: 44.91513650517466516021\n",
      "Iteration 41768 => Loss: 44.91498444238694531805\n",
      "Iteration 41769 => Loss: 44.91483238079263173859\n",
      "Iteration 41770 => Loss: 44.91468032039165336755\n",
      "Iteration 41771 => Loss: 44.91452826118405994293\n",
      "Iteration 41772 => Loss: 44.91437620316980883217\n",
      "Iteration 41773 => Loss: 44.91422414634890003526\n",
      "Iteration 41774 => Loss: 44.91407209072134776306\n",
      "Iteration 41775 => Loss: 44.91392003628709517216\n",
      "Iteration 41776 => Loss: 44.91376798304615647339\n",
      "Iteration 41777 => Loss: 44.91361593099853166677\n",
      "Iteration 41778 => Loss: 44.91346388014422075230\n",
      "Iteration 41779 => Loss: 44.91331183048315978112\n",
      "Iteration 41780 => Loss: 44.91315978201541270209\n",
      "Iteration 41781 => Loss: 44.91300773474091556636\n",
      "Iteration 41782 => Loss: 44.91285568865968969021\n",
      "Iteration 41783 => Loss: 44.91270364377170665193\n",
      "Iteration 41784 => Loss: 44.91255160007695224067\n",
      "Iteration 41785 => Loss: 44.91239955757544777271\n",
      "Iteration 41786 => Loss: 44.91224751626715772090\n",
      "Iteration 41787 => Loss: 44.91209547615206787441\n",
      "Iteration 41788 => Loss: 44.91194343723020665493\n",
      "Iteration 41789 => Loss: 44.91179139950151721905\n",
      "Iteration 41790 => Loss: 44.91163936296601377762\n",
      "Iteration 41791 => Loss: 44.91148732762367501437\n",
      "Iteration 41792 => Loss: 44.91133529347453645642\n",
      "Iteration 41793 => Loss: 44.91118326051851994407\n",
      "Iteration 41794 => Loss: 44.91103122875566810990\n",
      "Iteration 41795 => Loss: 44.91087919818595253219\n",
      "Iteration 41796 => Loss: 44.91072716880935900008\n",
      "Iteration 41797 => Loss: 44.91057514062588751358\n",
      "Iteration 41798 => Loss: 44.91042311363550965098\n",
      "Iteration 41799 => Loss: 44.91027108783826804483\n",
      "Iteration 41800 => Loss: 44.91011906323408453545\n",
      "Iteration 41801 => Loss: 44.90996703982298754454\n",
      "Iteration 41802 => Loss: 44.90981501760496286124\n",
      "Iteration 41803 => Loss: 44.90966299658001048556\n",
      "Iteration 41804 => Loss: 44.90951097674810910121\n",
      "Iteration 41805 => Loss: 44.90935895810923739191\n",
      "Iteration 41806 => Loss: 44.90920694066341667394\n",
      "Iteration 41807 => Loss: 44.90905492441060431474\n",
      "Iteration 41808 => Loss: 44.90890290935081452517\n",
      "Iteration 41809 => Loss: 44.90875089548404019979\n",
      "Iteration 41810 => Loss: 44.90859888281026002232\n",
      "Iteration 41811 => Loss: 44.90844687132946688735\n",
      "Iteration 41812 => Loss: 44.90829486104164658400\n",
      "Iteration 41813 => Loss: 44.90814285194679911228\n",
      "Iteration 41814 => Loss: 44.90799084404491026135\n",
      "Iteration 41815 => Loss: 44.90783883733595871490\n",
      "Iteration 41816 => Loss: 44.90768683181995868381\n",
      "Iteration 41817 => Loss: 44.90753482749688174636\n",
      "Iteration 41818 => Loss: 44.90738282436674211340\n",
      "Iteration 41819 => Loss: 44.90723082242951136323\n",
      "Iteration 41820 => Loss: 44.90707882168517528498\n",
      "Iteration 41821 => Loss: 44.90692682213376230038\n",
      "Iteration 41822 => Loss: 44.90677482377519424972\n",
      "Iteration 41823 => Loss: 44.90662282660952797642\n",
      "Iteration 41824 => Loss: 44.90647083063670663705\n",
      "Iteration 41825 => Loss: 44.90631883585675154791\n",
      "Iteration 41826 => Loss: 44.90616684226963428728\n",
      "Iteration 41827 => Loss: 44.90601484987536906601\n",
      "Iteration 41828 => Loss: 44.90586285867393456783\n",
      "Iteration 41829 => Loss: 44.90571086866530237103\n",
      "Iteration 41830 => Loss: 44.90555887984948668645\n",
      "Iteration 41831 => Loss: 44.90540689222648040868\n",
      "Iteration 41832 => Loss: 44.90525490579625511600\n",
      "Iteration 41833 => Loss: 44.90510292055881080842\n",
      "Iteration 41834 => Loss: 44.90495093651413327507\n",
      "Iteration 41835 => Loss: 44.90479895366224383224\n",
      "Iteration 41836 => Loss: 44.90464697200307853109\n",
      "Iteration 41837 => Loss: 44.90449499153668710960\n",
      "Iteration 41838 => Loss: 44.90434301226301272436\n",
      "Iteration 41839 => Loss: 44.90419103418204826994\n",
      "Iteration 41840 => Loss: 44.90403905729380795719\n",
      "Iteration 41841 => Loss: 44.90388708159829178612\n",
      "Iteration 41842 => Loss: 44.90373510709547133501\n",
      "Iteration 41843 => Loss: 44.90358313378532528759\n",
      "Iteration 41844 => Loss: 44.90343116166786785470\n",
      "Iteration 41845 => Loss: 44.90327919074307061464\n",
      "Iteration 41846 => Loss: 44.90312722101094067284\n",
      "Iteration 41847 => Loss: 44.90297525247144960758\n",
      "Iteration 41848 => Loss: 44.90282328512461873515\n",
      "Iteration 41849 => Loss: 44.90267131897041252842\n",
      "Iteration 41850 => Loss: 44.90251935400880967109\n",
      "Iteration 41851 => Loss: 44.90236739023983147945\n",
      "Iteration 41852 => Loss: 44.90221542766347084807\n",
      "Iteration 41853 => Loss: 44.90206346627967803897\n",
      "Iteration 41854 => Loss: 44.90191150608848857928\n",
      "Iteration 41855 => Loss: 44.90175954708988115271\n",
      "Iteration 41856 => Loss: 44.90160758928382733757\n",
      "Iteration 41857 => Loss: 44.90145563267032713384\n",
      "Iteration 41858 => Loss: 44.90130367724937343610\n",
      "Iteration 41859 => Loss: 44.90115172302097334978\n",
      "Iteration 41860 => Loss: 44.90099976998509845316\n",
      "Iteration 41861 => Loss: 44.90084781814174164083\n",
      "Iteration 41862 => Loss: 44.90069586749088870192\n",
      "Iteration 41863 => Loss: 44.90054391803254674187\n",
      "Iteration 41864 => Loss: 44.90039196976670154982\n",
      "Iteration 41865 => Loss: 44.90024002269330338777\n",
      "Iteration 41866 => Loss: 44.90008807681240199372\n",
      "Iteration 41867 => Loss: 44.89993613212395473511\n",
      "Iteration 41868 => Loss: 44.89978418862799713906\n",
      "Iteration 41869 => Loss: 44.89963224632443683504\n",
      "Iteration 41870 => Loss: 44.89948030521333777187\n",
      "Iteration 41871 => Loss: 44.89932836529466442244\n",
      "Iteration 41872 => Loss: 44.89917642656838836501\n",
      "Iteration 41873 => Loss: 44.89902448903454512674\n",
      "Iteration 41874 => Loss: 44.89887255269307786421\n",
      "Iteration 41875 => Loss: 44.89872061754400789368\n",
      "Iteration 41876 => Loss: 44.89856868358731389890\n",
      "Iteration 41877 => Loss: 44.89841675082298877442\n",
      "Iteration 41878 => Loss: 44.89826481925103252024\n",
      "Iteration 41879 => Loss: 44.89811288887140960924\n",
      "Iteration 41880 => Loss: 44.89796095968415556854\n",
      "Iteration 41881 => Loss: 44.89780903168920644930\n",
      "Iteration 41882 => Loss: 44.89765710488659067323\n",
      "Iteration 41883 => Loss: 44.89750517927630113491\n",
      "Iteration 41884 => Loss: 44.89735325485830941261\n",
      "Iteration 41885 => Loss: 44.89720133163260129550\n",
      "Iteration 41886 => Loss: 44.89704940959917678356\n",
      "Iteration 41887 => Loss: 44.89689748875804298223\n",
      "Iteration 41888 => Loss: 44.89674556910918568065\n",
      "Iteration 41889 => Loss: 44.89659365065256224625\n",
      "Iteration 41890 => Loss: 44.89644173338820110075\n",
      "Iteration 41891 => Loss: 44.89628981731606671701\n",
      "Iteration 41892 => Loss: 44.89613790243615198960\n",
      "Iteration 41893 => Loss: 44.89598598874847823481\n",
      "Iteration 41894 => Loss: 44.89583407625301703092\n",
      "Iteration 41895 => Loss: 44.89568216494973995623\n",
      "Iteration 41896 => Loss: 44.89553025483867543244\n",
      "Iteration 41897 => Loss: 44.89537834591978082699\n",
      "Iteration 41898 => Loss: 44.89522643819305613988\n",
      "Iteration 41899 => Loss: 44.89507453165851558197\n",
      "Iteration 41900 => Loss: 44.89492262631610941526\n",
      "Iteration 41901 => Loss: 44.89477072216585185060\n",
      "Iteration 41902 => Loss: 44.89461881920772867716\n",
      "Iteration 41903 => Loss: 44.89446691744173278948\n",
      "Iteration 41904 => Loss: 44.89431501686785708216\n",
      "Iteration 41905 => Loss: 44.89416311748609444976\n",
      "Iteration 41906 => Loss: 44.89401121929640936514\n",
      "Iteration 41907 => Loss: 44.89385932229882314459\n",
      "Iteration 41908 => Loss: 44.89370742649333578811\n",
      "Iteration 41909 => Loss: 44.89355553187991176856\n",
      "Iteration 41910 => Loss: 44.89340363845852976965\n",
      "Iteration 41911 => Loss: 44.89325174622920400225\n",
      "Iteration 41912 => Loss: 44.89309985519193446635\n",
      "Iteration 41913 => Loss: 44.89294796534669274024\n",
      "Iteration 41914 => Loss: 44.89279607669346461307\n",
      "Iteration 41915 => Loss: 44.89264418923225719027\n",
      "Iteration 41916 => Loss: 44.89249230296304915555\n",
      "Iteration 41917 => Loss: 44.89234041788584761434\n",
      "Iteration 41918 => Loss: 44.89218853400063835579\n",
      "Iteration 41919 => Loss: 44.89203665130738585276\n",
      "Iteration 41920 => Loss: 44.89188476980611142153\n",
      "Iteration 41921 => Loss: 44.89173288949678664039\n",
      "Iteration 41922 => Loss: 44.89158101037942572020\n",
      "Iteration 41923 => Loss: 44.89142913245397892297\n",
      "Iteration 41924 => Loss: 44.89127725572048888125\n",
      "Iteration 41925 => Loss: 44.89112538017890585706\n",
      "Iteration 41926 => Loss: 44.89097350582924406126\n",
      "Iteration 41927 => Loss: 44.89082163267148928298\n",
      "Iteration 41928 => Loss: 44.89066976070559888967\n",
      "Iteration 41929 => Loss: 44.89051788993161551389\n",
      "Iteration 41930 => Loss: 44.89036602034949652307\n",
      "Iteration 41931 => Loss: 44.89021415195923481178\n",
      "Iteration 41932 => Loss: 44.89006228476083748546\n",
      "Iteration 41933 => Loss: 44.88991041875428322783\n",
      "Iteration 41934 => Loss: 44.88975855393957914430\n",
      "Iteration 41935 => Loss: 44.88960669031668970774\n",
      "Iteration 41936 => Loss: 44.88945482788561491816\n",
      "Iteration 41937 => Loss: 44.88930296664634767012\n",
      "Iteration 41938 => Loss: 44.88915110659888796363\n",
      "Iteration 41939 => Loss: 44.88899924774321448240\n",
      "Iteration 41940 => Loss: 44.88884739007933433186\n",
      "Iteration 41941 => Loss: 44.88869553360719066859\n",
      "Iteration 41942 => Loss: 44.88854367832683323059\n",
      "Iteration 41943 => Loss: 44.88839182423824780699\n",
      "Iteration 41944 => Loss: 44.88823997134135623810\n",
      "Iteration 41945 => Loss: 44.88808811963622957819\n",
      "Iteration 41946 => Loss: 44.88793626912281808927\n",
      "Iteration 41947 => Loss: 44.88778441980112887677\n",
      "Iteration 41948 => Loss: 44.88763257167114062440\n",
      "Iteration 41949 => Loss: 44.88748072473284622674\n",
      "Iteration 41950 => Loss: 44.88732887898625278922\n",
      "Iteration 41951 => Loss: 44.88717703443133189012\n",
      "Iteration 41952 => Loss: 44.88702519106806221316\n",
      "Iteration 41953 => Loss: 44.88687334889645796920\n",
      "Iteration 41954 => Loss: 44.88672150791649784196\n",
      "Iteration 41955 => Loss: 44.88656966812820314772\n",
      "Iteration 41956 => Loss: 44.88641782953151704305\n",
      "Iteration 41957 => Loss: 44.88626599212644663339\n",
      "Iteration 41958 => Loss: 44.88611415591302034045\n",
      "Iteration 41959 => Loss: 44.88596232089116000452\n",
      "Iteration 41960 => Loss: 44.88581048706090825817\n",
      "Iteration 41961 => Loss: 44.88565865442225089055\n",
      "Iteration 41962 => Loss: 44.88550682297515237451\n",
      "Iteration 41963 => Loss: 44.88535499271962692092\n",
      "Iteration 41964 => Loss: 44.88520316365565321348\n",
      "Iteration 41965 => Loss: 44.88505133578322414678\n",
      "Iteration 41966 => Loss: 44.88489950910233261538\n",
      "Iteration 41967 => Loss: 44.88474768361297861929\n",
      "Iteration 41968 => Loss: 44.88459585931514084223\n",
      "Iteration 41969 => Loss: 44.88444403620880507333\n",
      "Iteration 41970 => Loss: 44.88429221429397841803\n",
      "Iteration 41971 => Loss: 44.88414039357061824376\n",
      "Iteration 41972 => Loss: 44.88398857403875297223\n",
      "Iteration 41973 => Loss: 44.88383675569836839259\n",
      "Iteration 41974 => Loss: 44.88368493854945029398\n",
      "Iteration 41975 => Loss: 44.88353312259196314926\n",
      "Iteration 41976 => Loss: 44.88338130782595669643\n",
      "Iteration 41977 => Loss: 44.88322949425134567036\n",
      "Iteration 41978 => Loss: 44.88307768186816559819\n",
      "Iteration 41979 => Loss: 44.88292587067640226905\n",
      "Iteration 41980 => Loss: 44.88277406067606989382\n",
      "Iteration 41981 => Loss: 44.88262225186711873448\n",
      "Iteration 41982 => Loss: 44.88247044424954168562\n",
      "Iteration 41983 => Loss: 44.88231863782336716895\n",
      "Iteration 41984 => Loss: 44.88216683258855965732\n",
      "Iteration 41985 => Loss: 44.88201502854508362361\n",
      "Iteration 41986 => Loss: 44.88186322569296038409\n",
      "Iteration 41987 => Loss: 44.88171142403220414963\n",
      "Iteration 41988 => Loss: 44.88155962356276518221\n",
      "Iteration 41989 => Loss: 44.88140782428465058729\n",
      "Iteration 41990 => Loss: 44.88125602619784615399\n",
      "Iteration 41991 => Loss: 44.88110422930235188232\n",
      "Iteration 41992 => Loss: 44.88095243359815356143\n",
      "Iteration 41993 => Loss: 44.88080063908522276961\n",
      "Iteration 41994 => Loss: 44.88064884576358082313\n",
      "Iteration 41995 => Loss: 44.88049705363321351115\n",
      "Iteration 41996 => Loss: 44.88034526269409241195\n",
      "Iteration 41997 => Loss: 44.88019347294621042010\n",
      "Iteration 41998 => Loss: 44.88004168438957464105\n",
      "Iteration 41999 => Loss: 44.87988989702416375849\n",
      "Iteration 42000 => Loss: 44.87973811084997066700\n",
      "Iteration 42001 => Loss: 44.87958632586700247202\n",
      "Iteration 42002 => Loss: 44.87943454207520943555\n",
      "Iteration 42003 => Loss: 44.87928275947462708473\n",
      "Iteration 42004 => Loss: 44.87913097806522699784\n",
      "Iteration 42005 => Loss: 44.87897919784698785861\n",
      "Iteration 42006 => Loss: 44.87882741881991677246\n",
      "Iteration 42007 => Loss: 44.87867564098400663397\n",
      "Iteration 42008 => Loss: 44.87852386433922902143\n",
      "Iteration 42009 => Loss: 44.87837208888561235653\n",
      "Iteration 42010 => Loss: 44.87822031462307847960\n",
      "Iteration 42011 => Loss: 44.87806854155169133946\n",
      "Iteration 42012 => Loss: 44.87791676967139409271\n",
      "Iteration 42013 => Loss: 44.87776499898220805562\n",
      "Iteration 42014 => Loss: 44.87761322948411191192\n",
      "Iteration 42015 => Loss: 44.87746146117709855616\n",
      "Iteration 42016 => Loss: 44.87730969406112535580\n",
      "Iteration 42017 => Loss: 44.87715792813624204882\n",
      "Iteration 42018 => Loss: 44.87700616340241310809\n",
      "Iteration 42019 => Loss: 44.87685439985961721732\n",
      "Iteration 42020 => Loss: 44.87670263750784016565\n",
      "Iteration 42021 => Loss: 44.87655087634708905853\n",
      "Iteration 42022 => Loss: 44.87639911637736389594\n",
      "Iteration 42023 => Loss: 44.87624735759864336160\n",
      "Iteration 42024 => Loss: 44.87609560001089903380\n",
      "Iteration 42025 => Loss: 44.87594384361416643969\n",
      "Iteration 42026 => Loss: 44.87579208840839584127\n",
      "Iteration 42027 => Loss: 44.87564033439358723854\n",
      "Iteration 42028 => Loss: 44.87548858156974063149\n",
      "Iteration 42029 => Loss: 44.87533682993686312557\n",
      "Iteration 42030 => Loss: 44.87518507949489077191\n",
      "Iteration 42031 => Loss: 44.87503333024385199224\n",
      "Iteration 42032 => Loss: 44.87488158218375389197\n",
      "Iteration 42033 => Loss: 44.87472983531457515483\n",
      "Iteration 42034 => Loss: 44.87457808963625893739\n",
      "Iteration 42035 => Loss: 44.87442634514885497765\n",
      "Iteration 42036 => Loss: 44.87427460185232774847\n",
      "Iteration 42037 => Loss: 44.87412285974669146071\n",
      "Iteration 42038 => Loss: 44.87397111883189637638\n",
      "Iteration 42039 => Loss: 44.87381937910797091718\n",
      "Iteration 42040 => Loss: 44.87366764057487955597\n",
      "Iteration 42041 => Loss: 44.87351590323262939819\n",
      "Iteration 42042 => Loss: 44.87336416708121333841\n",
      "Iteration 42043 => Loss: 44.87321243212061716576\n",
      "Iteration 42044 => Loss: 44.87306069835080535313\n",
      "Iteration 42045 => Loss: 44.87290896577182763849\n",
      "Iteration 42046 => Loss: 44.87275723438360586215\n",
      "Iteration 42047 => Loss: 44.87260550418618265667\n",
      "Iteration 42048 => Loss: 44.87245377517951538948\n",
      "Iteration 42049 => Loss: 44.87230204736362537687\n",
      "Iteration 42050 => Loss: 44.87215032073849130256\n",
      "Iteration 42051 => Loss: 44.87199859530407763941\n",
      "Iteration 42052 => Loss: 44.87184687106040570370\n",
      "Iteration 42053 => Loss: 44.87169514800746839001\n",
      "Iteration 42054 => Loss: 44.87154342614524438204\n",
      "Iteration 42055 => Loss: 44.87139170547371236353\n",
      "Iteration 42056 => Loss: 44.87123998599289365075\n",
      "Iteration 42057 => Loss: 44.87108826770273140028\n",
      "Iteration 42058 => Loss: 44.87093655060327535011\n",
      "Iteration 42059 => Loss: 44.87078483469448286769\n",
      "Iteration 42060 => Loss: 44.87063311997633974215\n",
      "Iteration 42061 => Loss: 44.87048140644884597350\n",
      "Iteration 42062 => Loss: 44.87032969411200866716\n",
      "Iteration 42063 => Loss: 44.87017798296577808514\n",
      "Iteration 42064 => Loss: 44.87002627301017554373\n",
      "Iteration 42065 => Loss: 44.86987456424518683207\n",
      "Iteration 42066 => Loss: 44.86972285667080484473\n",
      "Iteration 42067 => Loss: 44.86957115028700826542\n",
      "Iteration 42068 => Loss: 44.86941944509380419959\n",
      "Iteration 42069 => Loss: 44.86926774109117133094\n",
      "Iteration 42070 => Loss: 44.86911603827911676490\n",
      "Iteration 42071 => Loss: 44.86896433665759076348\n",
      "Iteration 42072 => Loss: 44.86881263622662885382\n",
      "Iteration 42073 => Loss: 44.86866093698618129793\n",
      "Iteration 42074 => Loss: 44.86850923893629072836\n",
      "Iteration 42075 => Loss: 44.86835754207691451256\n",
      "Iteration 42076 => Loss: 44.86820584640803133425\n",
      "Iteration 42077 => Loss: 44.86805415192965540427\n",
      "Iteration 42078 => Loss: 44.86790245864177961721\n",
      "Iteration 42079 => Loss: 44.86775076654437555135\n",
      "Iteration 42080 => Loss: 44.86759907563744320669\n",
      "Iteration 42081 => Loss: 44.86744738592097547780\n",
      "Iteration 42082 => Loss: 44.86729569739495104841\n",
      "Iteration 42083 => Loss: 44.86714401005937702394\n",
      "Iteration 42084 => Loss: 44.86699232391423208810\n",
      "Iteration 42085 => Loss: 44.86684063895952334633\n",
      "Iteration 42086 => Loss: 44.86668895519520816606\n",
      "Iteration 42087 => Loss: 44.86653727262132207443\n",
      "Iteration 42088 => Loss: 44.86638559123784375515\n",
      "Iteration 42089 => Loss: 44.86623391104472347024\n",
      "Iteration 42090 => Loss: 44.86608223204198964140\n",
      "Iteration 42091 => Loss: 44.86593055422964226864\n",
      "Iteration 42092 => Loss: 44.86577887760763871938\n",
      "Iteration 42093 => Loss: 44.86562720217597899364\n",
      "Iteration 42094 => Loss: 44.86547552793466309140\n",
      "Iteration 42095 => Loss: 44.86532385488368390725\n",
      "Iteration 42096 => Loss: 44.86517218302302723032\n",
      "Iteration 42097 => Loss: 44.86502051235268595519\n",
      "Iteration 42098 => Loss: 44.86486884287263876558\n",
      "Iteration 42099 => Loss: 44.86471717458289276692\n",
      "Iteration 42100 => Loss: 44.86456550748342664292\n",
      "Iteration 42101 => Loss: 44.86441384157426170987\n",
      "Iteration 42102 => Loss: 44.86426217685533401891\n",
      "Iteration 42103 => Loss: 44.86411051332666488634\n",
      "Iteration 42104 => Loss: 44.86395885098823299586\n",
      "Iteration 42105 => Loss: 44.86380718984005966377\n",
      "Iteration 42106 => Loss: 44.86365552988211646834\n",
      "Iteration 42107 => Loss: 44.86350387111438209331\n",
      "Iteration 42108 => Loss: 44.86335221353687074952\n",
      "Iteration 42109 => Loss: 44.86320055714954690984\n",
      "Iteration 42110 => Loss: 44.86304890195241057427\n",
      "Iteration 42111 => Loss: 44.86289724794547595366\n",
      "Iteration 42112 => Loss: 44.86274559512869331002\n",
      "Iteration 42113 => Loss: 44.86259394350208395963\n",
      "Iteration 42114 => Loss: 44.86244229306561948079\n",
      "Iteration 42115 => Loss: 44.86229064381930697891\n",
      "Iteration 42116 => Loss: 44.86213899576313224316\n",
      "Iteration 42117 => Loss: 44.86198734889708816809\n",
      "Iteration 42118 => Loss: 44.86183570322115343743\n",
      "Iteration 42119 => Loss: 44.86168405873531384032\n",
      "Iteration 42120 => Loss: 44.86153241543959779847\n",
      "Iteration 42121 => Loss: 44.86138077333394136303\n",
      "Iteration 42122 => Loss: 44.86122913241838006115\n",
      "Iteration 42123 => Loss: 44.86107749269290678740\n",
      "Iteration 42124 => Loss: 44.86092585415747180377\n",
      "Iteration 42125 => Loss: 44.86077421681208932114\n",
      "Iteration 42126 => Loss: 44.86062258065675223406\n",
      "Iteration 42127 => Loss: 44.86047094569145343712\n",
      "Iteration 42128 => Loss: 44.86031931191617871946\n",
      "Iteration 42129 => Loss: 44.86016767933089965936\n",
      "Iteration 42130 => Loss: 44.86001604793564467855\n",
      "Iteration 42131 => Loss: 44.85986441773036403902\n",
      "Iteration 42132 => Loss: 44.85971278871508616248\n",
      "Iteration 42133 => Loss: 44.85956116088978973266\n",
      "Iteration 42134 => Loss: 44.85940953425444632785\n",
      "Iteration 42135 => Loss: 44.85925790880907726432\n",
      "Iteration 42136 => Loss: 44.85910628455362569866\n",
      "Iteration 42137 => Loss: 44.85895466148813426344\n",
      "Iteration 42138 => Loss: 44.85880303961256032608\n",
      "Iteration 42139 => Loss: 44.85865141892691809744\n",
      "Iteration 42140 => Loss: 44.85849979943119336667\n",
      "Iteration 42141 => Loss: 44.85834818112536481749\n",
      "Iteration 42142 => Loss: 44.85819656400943244989\n",
      "Iteration 42143 => Loss: 44.85804494808338205303\n",
      "Iteration 42144 => Loss: 44.85789333334719941604\n",
      "Iteration 42145 => Loss: 44.85774171980087032807\n",
      "Iteration 42146 => Loss: 44.85759010744441610541\n",
      "Iteration 42147 => Loss: 44.85743849627780832634\n",
      "Iteration 42148 => Loss: 44.85728688630100435830\n",
      "Iteration 42149 => Loss: 44.85713527751408236099\n",
      "Iteration 42150 => Loss: 44.85698366991694285844\n",
      "Iteration 42151 => Loss: 44.85683206350961427233\n",
      "Iteration 42152 => Loss: 44.85668045829208949726\n",
      "Iteration 42153 => Loss: 44.85652885426434011151\n",
      "Iteration 42154 => Loss: 44.85637725142638743137\n",
      "Iteration 42155 => Loss: 44.85622564977820303511\n",
      "Iteration 42156 => Loss: 44.85607404931977981732\n",
      "Iteration 42157 => Loss: 44.85592245005110356715\n",
      "Iteration 42158 => Loss: 44.85577085197219560087\n",
      "Iteration 42159 => Loss: 44.85561925508298486420\n",
      "Iteration 42160 => Loss: 44.85546765938352109515\n",
      "Iteration 42161 => Loss: 44.85531606487376876657\n",
      "Iteration 42162 => Loss: 44.85516447155371366762\n",
      "Iteration 42163 => Loss: 44.85501287942335579828\n",
      "Iteration 42164 => Loss: 44.85486128848269515856\n",
      "Iteration 42165 => Loss: 44.85470969873171043218\n",
      "Iteration 42166 => Loss: 44.85455811017038740829\n",
      "Iteration 42167 => Loss: 44.85440652279872608688\n",
      "Iteration 42168 => Loss: 44.85425493661672646795\n",
      "Iteration 42169 => Loss: 44.85410335162434591894\n",
      "Iteration 42170 => Loss: 44.85395176782161286155\n",
      "Iteration 42171 => Loss: 44.85380018520849887409\n",
      "Iteration 42172 => Loss: 44.85364860378498264026\n",
      "Iteration 42173 => Loss: 44.85349702355107126550\n",
      "Iteration 42174 => Loss: 44.85334544450677896066\n",
      "Iteration 42175 => Loss: 44.85319386665205598774\n",
      "Iteration 42176 => Loss: 44.85304228998691655761\n",
      "Iteration 42177 => Loss: 44.85289071451131803769\n",
      "Iteration 42178 => Loss: 44.85273914022529595513\n",
      "Iteration 42179 => Loss: 44.85258756712882188822\n",
      "Iteration 42180 => Loss: 44.85243599522186030981\n",
      "Iteration 42181 => Loss: 44.85228442450446806333\n",
      "Iteration 42182 => Loss: 44.85213285497656698908\n",
      "Iteration 42183 => Loss: 44.85198128663817129791\n",
      "Iteration 42184 => Loss: 44.85182971948929520067\n",
      "Iteration 42185 => Loss: 44.85167815352991027567\n",
      "Iteration 42186 => Loss: 44.85152658876000941746\n",
      "Iteration 42187 => Loss: 44.85137502517953578263\n",
      "Iteration 42188 => Loss: 44.85122346278856753088\n",
      "Iteration 42189 => Loss: 44.85107190158704071337\n",
      "Iteration 42190 => Loss: 44.85092034157497664637\n",
      "Iteration 42191 => Loss: 44.85076878275232559190\n",
      "Iteration 42192 => Loss: 44.85061722511910886624\n",
      "Iteration 42193 => Loss: 44.85046566867529094225\n",
      "Iteration 42194 => Loss: 44.85031411342090734706\n",
      "Iteration 42195 => Loss: 44.85016255935591544812\n",
      "Iteration 42196 => Loss: 44.85001100648028682372\n",
      "Iteration 42197 => Loss: 44.84985945479407121184\n",
      "Iteration 42198 => Loss: 44.84970790429721176906\n",
      "Iteration 42199 => Loss: 44.84955635498970138997\n",
      "Iteration 42200 => Loss: 44.84940480687155428541\n",
      "Iteration 42201 => Loss: 44.84925325994275624453\n",
      "Iteration 42202 => Loss: 44.84910171420328595104\n",
      "Iteration 42203 => Loss: 44.84895016965313629953\n",
      "Iteration 42204 => Loss: 44.84879862629227886828\n",
      "Iteration 42205 => Loss: 44.84864708412075628985\n",
      "Iteration 42206 => Loss: 44.84849554313849750997\n",
      "Iteration 42207 => Loss: 44.84834400334556647749\n",
      "Iteration 42208 => Loss: 44.84819246474189213814\n",
      "Iteration 42209 => Loss: 44.84804092732747449190\n",
      "Iteration 42210 => Loss: 44.84788939110231353879\n",
      "Iteration 42211 => Loss: 44.84773785606643059509\n",
      "Iteration 42212 => Loss: 44.84758632221976171195\n",
      "Iteration 42213 => Loss: 44.84743478956232110022\n",
      "Iteration 42214 => Loss: 44.84728325809410875991\n",
      "Iteration 42215 => Loss: 44.84713172781510337472\n",
      "Iteration 42216 => Loss: 44.84698019872529073382\n",
      "Iteration 42217 => Loss: 44.84682867082468504805\n",
      "Iteration 42218 => Loss: 44.84667714411325789570\n",
      "Iteration 42219 => Loss: 44.84652561859098796049\n",
      "Iteration 42220 => Loss: 44.84637409425789655870\n",
      "Iteration 42221 => Loss: 44.84622257111399079577\n",
      "Iteration 42222 => Loss: 44.84607104915919251198\n",
      "Iteration 42223 => Loss: 44.84591952839353723448\n",
      "Iteration 42224 => Loss: 44.84576800881700364698\n",
      "Iteration 42225 => Loss: 44.84561649042959885492\n",
      "Iteration 42226 => Loss: 44.84546497323130154200\n",
      "Iteration 42227 => Loss: 44.84531345722210460281\n",
      "Iteration 42228 => Loss: 44.84516194240198672105\n",
      "Iteration 42229 => Loss: 44.84501042877096921302\n",
      "Iteration 42230 => Loss: 44.84485891632900234072\n",
      "Iteration 42231 => Loss: 44.84470740507609320957\n",
      "Iteration 42232 => Loss: 44.84455589501225603044\n",
      "Iteration 42233 => Loss: 44.84440438613744817076\n",
      "Iteration 42234 => Loss: 44.84425287845168384138\n",
      "Iteration 42235 => Loss: 44.84410137195494172602\n",
      "Iteration 42236 => Loss: 44.84394986664721471925\n",
      "Iteration 42237 => Loss: 44.84379836252847439937\n",
      "Iteration 42238 => Loss: 44.84364685959875629351\n",
      "Iteration 42239 => Loss: 44.84349535785801066368\n",
      "Iteration 42240 => Loss: 44.84334385730624461530\n",
      "Iteration 42241 => Loss: 44.84319235794344393753\n",
      "Iteration 42242 => Loss: 44.84304085976962284121\n",
      "Iteration 42243 => Loss: 44.84288936278472448294\n",
      "Iteration 42244 => Loss: 44.84273786698879149526\n",
      "Iteration 42245 => Loss: 44.84258637238178124562\n",
      "Iteration 42246 => Loss: 44.84243487896368662859\n",
      "Iteration 42247 => Loss: 44.84228338673448632790\n",
      "Iteration 42248 => Loss: 44.84213189569423008152\n",
      "Iteration 42249 => Loss: 44.84198040584283972976\n",
      "Iteration 42250 => Loss: 44.84182891718033658890\n",
      "Iteration 42251 => Loss: 44.84167742970671355351\n",
      "Iteration 42252 => Loss: 44.84152594342194930732\n",
      "Iteration 42253 => Loss: 44.84137445832604385032\n",
      "Iteration 42254 => Loss: 44.84122297441900428794\n",
      "Iteration 42255 => Loss: 44.84107149170078088218\n",
      "Iteration 42256 => Loss: 44.84092001017139494934\n",
      "Iteration 42257 => Loss: 44.84076852983082517312\n",
      "Iteration 42258 => Loss: 44.84061705067906444810\n",
      "Iteration 42259 => Loss: 44.84046557271610566886\n",
      "Iteration 42260 => Loss: 44.84031409594192041368\n",
      "Iteration 42261 => Loss: 44.84016262035653710427\n",
      "Iteration 42262 => Loss: 44.84001114595992731893\n",
      "Iteration 42263 => Loss: 44.83985967275207684679\n",
      "Iteration 42264 => Loss: 44.83970820073298568786\n",
      "Iteration 42265 => Loss: 44.83955672990262542044\n",
      "Iteration 42266 => Loss: 44.83940526026101025536\n",
      "Iteration 42267 => Loss: 44.83925379180811177093\n",
      "Iteration 42268 => Loss: 44.83910232454394417800\n",
      "Iteration 42269 => Loss: 44.83895085846846484401\n",
      "Iteration 42270 => Loss: 44.83879939358170219066\n",
      "Iteration 42271 => Loss: 44.83864792988360647996\n",
      "Iteration 42272 => Loss: 44.83849646737418481734\n",
      "Iteration 42273 => Loss: 44.83834500605347272995\n",
      "Iteration 42274 => Loss: 44.83819354592140626892\n",
      "Iteration 42275 => Loss: 44.83804208697796411798\n",
      "Iteration 42276 => Loss: 44.83789062922319601512\n",
      "Iteration 42277 => Loss: 44.83773917265705932778\n",
      "Iteration 42278 => Loss: 44.83758771727953984509\n",
      "Iteration 42279 => Loss: 44.83743626309060914537\n",
      "Iteration 42280 => Loss: 44.83728481009030275573\n",
      "Iteration 42281 => Loss: 44.83713335827858514904\n",
      "Iteration 42282 => Loss: 44.83698190765547764158\n",
      "Iteration 42283 => Loss: 44.83683045822093760080\n",
      "Iteration 42284 => Loss: 44.83667900997495081583\n",
      "Iteration 42285 => Loss: 44.83652756291752439211\n",
      "Iteration 42286 => Loss: 44.83637611704865832962\n",
      "Iteration 42287 => Loss: 44.83622467236830999582\n",
      "Iteration 42288 => Loss: 44.83607322887649360155\n",
      "Iteration 42289 => Loss: 44.83592178657323046309\n",
      "Iteration 42290 => Loss: 44.83577034545843531532\n",
      "Iteration 42291 => Loss: 44.83561890553215789623\n",
      "Iteration 42292 => Loss: 44.83546746679439110039\n",
      "Iteration 42293 => Loss: 44.83531602924509229524\n",
      "Iteration 42294 => Loss: 44.83516459288426858620\n",
      "Iteration 42295 => Loss: 44.83501315771191286785\n",
      "Iteration 42296 => Loss: 44.83486172372801092934\n",
      "Iteration 42297 => Loss: 44.83471029093254855979\n",
      "Iteration 42298 => Loss: 44.83455885932551865380\n",
      "Iteration 42299 => Loss: 44.83440742890693542222\n",
      "Iteration 42300 => Loss: 44.83425599967675623247\n",
      "Iteration 42301 => Loss: 44.83410457163499529543\n",
      "Iteration 42302 => Loss: 44.83395314478163840022\n",
      "Iteration 42303 => Loss: 44.83380171911665001971\n",
      "Iteration 42304 => Loss: 44.83365029464004436477\n",
      "Iteration 42305 => Loss: 44.83349887135182854081\n",
      "Iteration 42306 => Loss: 44.83334744925197412613\n",
      "Iteration 42307 => Loss: 44.83319602834045269901\n",
      "Iteration 42308 => Loss: 44.83304460861728557575\n",
      "Iteration 42309 => Loss: 44.83289319008245144005\n",
      "Iteration 42310 => Loss: 44.83274177273593608106\n",
      "Iteration 42311 => Loss: 44.83259035657774660422\n",
      "Iteration 42312 => Loss: 44.83243894160786879866\n",
      "Iteration 42313 => Loss: 44.83228752782626003182\n",
      "Iteration 42314 => Loss: 44.83213611523296293626\n",
      "Iteration 42315 => Loss: 44.83198470382794909028\n",
      "Iteration 42316 => Loss: 44.83183329361119007217\n",
      "Iteration 42317 => Loss: 44.83168188458268588192\n",
      "Iteration 42318 => Loss: 44.83153047674244362497\n",
      "Iteration 42319 => Loss: 44.83137907009042777418\n",
      "Iteration 42320 => Loss: 44.83122766462665964582\n",
      "Iteration 42321 => Loss: 44.83107626035109660734\n",
      "Iteration 42322 => Loss: 44.83092485726375997501\n",
      "Iteration 42323 => Loss: 44.83077345536462843256\n",
      "Iteration 42324 => Loss: 44.83062205465368776913\n",
      "Iteration 42325 => Loss: 44.83047065513090956301\n",
      "Iteration 42326 => Loss: 44.83031925679633644677\n",
      "Iteration 42327 => Loss: 44.83016785964992578783\n",
      "Iteration 42328 => Loss: 44.83001646369167758621\n",
      "Iteration 42329 => Loss: 44.82986506892154920934\n",
      "Iteration 42330 => Loss: 44.82971367533959750062\n",
      "Iteration 42331 => Loss: 44.82956228294573719495\n",
      "Iteration 42332 => Loss: 44.82941089174000381945\n",
      "Iteration 42333 => Loss: 44.82925950172239026870\n",
      "Iteration 42334 => Loss: 44.82910811289286812098\n",
      "Iteration 42335 => Loss: 44.82895672525145158716\n",
      "Iteration 42336 => Loss: 44.82880533879810514009\n",
      "Iteration 42337 => Loss: 44.82865395353285720148\n",
      "Iteration 42338 => Loss: 44.82850256945565803335\n",
      "Iteration 42339 => Loss: 44.82835118656649342483\n",
      "Iteration 42340 => Loss: 44.82819980486538469222\n",
      "Iteration 42341 => Loss: 44.82804842435231762465\n",
      "Iteration 42342 => Loss: 44.82789704502728511670\n",
      "Iteration 42343 => Loss: 44.82774566689025164123\n",
      "Iteration 42344 => Loss: 44.82759428994123140910\n",
      "Iteration 42345 => Loss: 44.82744291418020310402\n",
      "Iteration 42346 => Loss: 44.82729153960718804228\n",
      "Iteration 42347 => Loss: 44.82714016622212938046\n",
      "Iteration 42348 => Loss: 44.82698879402504843483\n",
      "Iteration 42349 => Loss: 44.82683742301593099455\n",
      "Iteration 42350 => Loss: 44.82668605319475574333\n",
      "Iteration 42351 => Loss: 44.82653468456154399746\n",
      "Iteration 42352 => Loss: 44.82638331711626022980\n",
      "Iteration 42353 => Loss: 44.82623195085888312406\n",
      "Iteration 42354 => Loss: 44.82608058578941978567\n",
      "Iteration 42355 => Loss: 44.82592922190787732006\n",
      "Iteration 42356 => Loss: 44.82577785921422020010\n",
      "Iteration 42357 => Loss: 44.82562649770845553121\n",
      "Iteration 42358 => Loss: 44.82547513739055489168\n",
      "Iteration 42359 => Loss: 44.82532377826053959780\n",
      "Iteration 42360 => Loss: 44.82517242031837412242\n",
      "Iteration 42361 => Loss: 44.82502106356406557097\n",
      "Iteration 42362 => Loss: 44.82486970799759262718\n",
      "Iteration 42363 => Loss: 44.82471835361894108019\n",
      "Iteration 42364 => Loss: 44.82456700042811803542\n",
      "Iteration 42365 => Loss: 44.82441564842510217659\n",
      "Iteration 42366 => Loss: 44.82426429760990771456\n",
      "Iteration 42367 => Loss: 44.82411294798249201676\n",
      "Iteration 42368 => Loss: 44.82396159954284797777\n",
      "Iteration 42369 => Loss: 44.82381025229098270302\n",
      "Iteration 42370 => Loss: 44.82365890622691040335\n",
      "Iteration 42371 => Loss: 44.82350756135056002449\n",
      "Iteration 42372 => Loss: 44.82335621766198130445\n",
      "Iteration 42373 => Loss: 44.82320487516113161064\n",
      "Iteration 42374 => Loss: 44.82305353384798252137\n",
      "Iteration 42375 => Loss: 44.82290219372259798547\n",
      "Iteration 42376 => Loss: 44.82275085478489984325\n",
      "Iteration 42377 => Loss: 44.82259951703490941100\n",
      "Iteration 42378 => Loss: 44.82244818047259826699\n",
      "Iteration 42379 => Loss: 44.82229684509796641123\n",
      "Iteration 42380 => Loss: 44.82214551091102805458\n",
      "Iteration 42381 => Loss: 44.82199417791174056447\n",
      "Iteration 42382 => Loss: 44.82184284610010394090\n",
      "Iteration 42383 => Loss: 44.82169151547611818387\n",
      "Iteration 42384 => Loss: 44.82154018603974776624\n",
      "Iteration 42385 => Loss: 44.82138885779100689888\n",
      "Iteration 42386 => Loss: 44.82123753072990268720\n",
      "Iteration 42387 => Loss: 44.82108620485639960407\n",
      "Iteration 42388 => Loss: 44.82093488017049054406\n",
      "Iteration 42389 => Loss: 44.82078355667216129632\n",
      "Iteration 42390 => Loss: 44.82063223436141186085\n",
      "Iteration 42391 => Loss: 44.82048091323823513221\n",
      "Iteration 42392 => Loss: 44.82032959330263821585\n",
      "Iteration 42393 => Loss: 44.82017827455457137376\n",
      "Iteration 42394 => Loss: 44.82002695699405592222\n",
      "Iteration 42395 => Loss: 44.81987564062105633411\n",
      "Iteration 42396 => Loss: 44.81972432543559392570\n",
      "Iteration 42397 => Loss: 44.81957301143761895901\n",
      "Iteration 42398 => Loss: 44.81942169862718827744\n",
      "Iteration 42399 => Loss: 44.81927038700422372131\n",
      "Iteration 42400 => Loss: 44.81911907656876081774\n",
      "Iteration 42401 => Loss: 44.81896776732077114502\n",
      "Iteration 42402 => Loss: 44.81881645926024759774\n",
      "Iteration 42403 => Loss: 44.81866515238716885960\n",
      "Iteration 42404 => Loss: 44.81851384670156335233\n",
      "Iteration 42405 => Loss: 44.81836254220338844334\n",
      "Iteration 42406 => Loss: 44.81821123889262992179\n",
      "Iteration 42407 => Loss: 44.81805993676930910397\n",
      "Iteration 42408 => Loss: 44.81790863583337625187\n",
      "Iteration 42409 => Loss: 44.81775733608486689263\n",
      "Iteration 42410 => Loss: 44.81760603752373839370\n",
      "Iteration 42411 => Loss: 44.81745474014999786050\n",
      "Iteration 42412 => Loss: 44.81730344396363108217\n",
      "Iteration 42413 => Loss: 44.81715214896463095329\n",
      "Iteration 42414 => Loss: 44.81700085515297615757\n",
      "Iteration 42415 => Loss: 44.81684956252869511673\n",
      "Iteration 42416 => Loss: 44.81669827109171677648\n",
      "Iteration 42417 => Loss: 44.81654698084205534769\n",
      "Iteration 42418 => Loss: 44.81639569177974635750\n",
      "Iteration 42419 => Loss: 44.81624440390474006790\n",
      "Iteration 42420 => Loss: 44.81609311721702226805\n",
      "Iteration 42421 => Loss: 44.81594183171661427423\n",
      "Iteration 42422 => Loss: 44.81579054740347345387\n",
      "Iteration 42423 => Loss: 44.81563926427759980697\n",
      "Iteration 42424 => Loss: 44.81548798233897912269\n",
      "Iteration 42425 => Loss: 44.81533670158762561186\n",
      "Iteration 42426 => Loss: 44.81518542202352506365\n",
      "Iteration 42427 => Loss: 44.81503414364663484548\n",
      "Iteration 42428 => Loss: 44.81488286645697627364\n",
      "Iteration 42429 => Loss: 44.81473159045455645355\n",
      "Iteration 42430 => Loss: 44.81458031563931854180\n",
      "Iteration 42431 => Loss: 44.81442904201128385466\n",
      "Iteration 42432 => Loss: 44.81427776957041686501\n",
      "Iteration 42433 => Loss: 44.81412649831676020540\n",
      "Iteration 42434 => Loss: 44.81397522825025703241\n",
      "Iteration 42435 => Loss: 44.81382395937092155691\n",
      "Iteration 42436 => Loss: 44.81367269167873246261\n",
      "Iteration 42437 => Loss: 44.81352142517368974950\n",
      "Iteration 42438 => Loss: 44.81337015985577210131\n",
      "Iteration 42439 => Loss: 44.81321889572497241261\n",
      "Iteration 42440 => Loss: 44.81306763278128357797\n",
      "Iteration 42441 => Loss: 44.81291637102471270282\n",
      "Iteration 42442 => Loss: 44.81276511045521715459\n",
      "Iteration 42443 => Loss: 44.81261385107281824958\n",
      "Iteration 42444 => Loss: 44.81246259287749467148\n",
      "Iteration 42445 => Loss: 44.81231133586923220946\n",
      "Iteration 42446 => Loss: 44.81216008004803086351\n",
      "Iteration 42447 => Loss: 44.81200882541388352820\n",
      "Iteration 42448 => Loss: 44.81185757196675467640\n",
      "Iteration 42449 => Loss: 44.81170631970666562438\n",
      "Iteration 42450 => Loss: 44.81155506863360926673\n",
      "Iteration 42451 => Loss: 44.81140381874755007630\n",
      "Iteration 42452 => Loss: 44.81125257004850936937\n",
      "Iteration 42453 => Loss: 44.81110132253644451339\n",
      "Iteration 42454 => Loss: 44.81095007621136971920\n",
      "Iteration 42455 => Loss: 44.81079883107324235425\n",
      "Iteration 42456 => Loss: 44.81064758712209084024\n",
      "Iteration 42457 => Loss: 44.81049634435790807174\n",
      "Iteration 42458 => Loss: 44.81034510278066562705\n",
      "Iteration 42459 => Loss: 44.81019386239034929531\n",
      "Iteration 42460 => Loss: 44.81004262318696618195\n",
      "Iteration 42461 => Loss: 44.80989138517050918153\n",
      "Iteration 42462 => Loss: 44.80974014834095697779\n",
      "Iteration 42463 => Loss: 44.80958891269830246529\n",
      "Iteration 42464 => Loss: 44.80943767824252432774\n",
      "Iteration 42465 => Loss: 44.80928644497365098687\n",
      "Iteration 42466 => Loss: 44.80913521289163270467\n",
      "Iteration 42467 => Loss: 44.80898398199647658657\n",
      "Iteration 42468 => Loss: 44.80883275228816842173\n",
      "Iteration 42469 => Loss: 44.80868152376671531556\n",
      "Iteration 42470 => Loss: 44.80853029643208174093\n",
      "Iteration 42471 => Loss: 44.80837907028428190870\n",
      "Iteration 42472 => Loss: 44.80822784532328739715\n",
      "Iteration 42473 => Loss: 44.80807662154909820629\n",
      "Iteration 42474 => Loss: 44.80792539896172144154\n",
      "Iteration 42475 => Loss: 44.80777417756111447034\n",
      "Iteration 42476 => Loss: 44.80762295734729150354\n",
      "Iteration 42477 => Loss: 44.80747173832023833029\n",
      "Iteration 42478 => Loss: 44.80732052047995495059\n",
      "Iteration 42479 => Loss: 44.80716930382639873187\n",
      "Iteration 42480 => Loss: 44.80701808835959099042\n",
      "Iteration 42481 => Loss: 44.80686687407952462081\n",
      "Iteration 42482 => Loss: 44.80671566098617120133\n",
      "Iteration 42483 => Loss: 44.80656444907953073198\n",
      "Iteration 42484 => Loss: 44.80641323835960321276\n",
      "Iteration 42485 => Loss: 44.80626202882634601110\n",
      "Iteration 42486 => Loss: 44.80611082047978754872\n",
      "Iteration 42487 => Loss: 44.80595961331990650933\n",
      "Iteration 42488 => Loss: 44.80580840734668868208\n",
      "Iteration 42489 => Loss: 44.80565720256011275069\n",
      "Iteration 42490 => Loss: 44.80550599896021424229\n",
      "Iteration 42491 => Loss: 44.80535479654693631346\n",
      "Iteration 42492 => Loss: 44.80520359532030028049\n",
      "Iteration 42493 => Loss: 44.80505239528025640539\n",
      "Iteration 42494 => Loss: 44.80490119642684021528\n",
      "Iteration 42495 => Loss: 44.80474999876003039390\n",
      "Iteration 42496 => Loss: 44.80459880227979851952\n",
      "Iteration 42497 => Loss: 44.80444760698616590844\n",
      "Iteration 42498 => Loss: 44.80429641287908992808\n",
      "Iteration 42499 => Loss: 44.80414521995857057846\n",
      "Iteration 42500 => Loss: 44.80399402822461496498\n",
      "Iteration 42501 => Loss: 44.80384283767721598224\n",
      "Iteration 42502 => Loss: 44.80369164831635231394\n",
      "Iteration 42503 => Loss: 44.80354046014198843295\n",
      "Iteration 42504 => Loss: 44.80338927315415986641\n",
      "Iteration 42505 => Loss: 44.80323808735283108717\n",
      "Iteration 42506 => Loss: 44.80308690273801630610\n",
      "Iteration 42507 => Loss: 44.80293571930967289063\n",
      "Iteration 42508 => Loss: 44.80278453706783636790\n",
      "Iteration 42509 => Loss: 44.80263335601241436734\n",
      "Iteration 42510 => Loss: 44.80248217614351347038\n",
      "Iteration 42511 => Loss: 44.80233099746103420102\n",
      "Iteration 42512 => Loss: 44.80217981996499077013\n",
      "Iteration 42513 => Loss: 44.80202864365541870484\n",
      "Iteration 42514 => Loss: 44.80187746853222563459\n",
      "Iteration 42515 => Loss: 44.80172629459546129738\n",
      "Iteration 42516 => Loss: 44.80157512184512569320\n",
      "Iteration 42517 => Loss: 44.80142395028114776778\n",
      "Iteration 42518 => Loss: 44.80127277990357725912\n",
      "Iteration 42519 => Loss: 44.80112161071237864007\n",
      "Iteration 42520 => Loss: 44.80097044270755191064\n",
      "Iteration 42521 => Loss: 44.80081927588909707083\n",
      "Iteration 42522 => Loss: 44.80066811025696438264\n",
      "Iteration 42523 => Loss: 44.80051694581118937322\n",
      "Iteration 42524 => Loss: 44.80036578255174362084\n",
      "Iteration 42525 => Loss: 44.80021462047860580924\n",
      "Iteration 42526 => Loss: 44.80006345959179014926\n",
      "Iteration 42527 => Loss: 44.79991229989127532463\n",
      "Iteration 42528 => Loss: 44.79976114137706133533\n",
      "Iteration 42529 => Loss: 44.79960998404911265425\n",
      "Iteration 42530 => Loss: 44.79945882790745059765\n",
      "Iteration 42531 => Loss: 44.79930767295206806011\n",
      "Iteration 42532 => Loss: 44.79915651918292240907\n",
      "Iteration 42533 => Loss: 44.79900536660002785538\n",
      "Iteration 42534 => Loss: 44.79885421520336308276\n",
      "Iteration 42535 => Loss: 44.79870306499293519664\n",
      "Iteration 42536 => Loss: 44.79855191596872998616\n",
      "Iteration 42537 => Loss: 44.79840076813074034590\n",
      "Iteration 42538 => Loss: 44.79824962147893785414\n",
      "Iteration 42539 => Loss: 44.79809847601332961631\n",
      "Iteration 42540 => Loss: 44.79794733173390852699\n",
      "Iteration 42541 => Loss: 44.79779618864065326989\n",
      "Iteration 42542 => Loss: 44.79764504673356384501\n",
      "Iteration 42543 => Loss: 44.79749390601261893607\n",
      "Iteration 42544 => Loss: 44.79734276647782564851\n",
      "Iteration 42545 => Loss: 44.79719162812916266603\n",
      "Iteration 42546 => Loss: 44.79704049096662998863\n",
      "Iteration 42547 => Loss: 44.79688935499023472175\n",
      "Iteration 42548 => Loss: 44.79673822019992002197\n",
      "Iteration 42549 => Loss: 44.79658708659568588928\n",
      "Iteration 42550 => Loss: 44.79643595417758206167\n",
      "Iteration 42551 => Loss: 44.79628482294553037946\n",
      "Iteration 42552 => Loss: 44.79613369289956636976\n",
      "Iteration 42553 => Loss: 44.79598256403966161088\n",
      "Iteration 42554 => Loss: 44.79583143636579478652\n",
      "Iteration 42555 => Loss: 44.79568030987797300213\n",
      "Iteration 42556 => Loss: 44.79552918457618915227\n",
      "Iteration 42557 => Loss: 44.79537806046042902608\n",
      "Iteration 42558 => Loss: 44.79522693753067841271\n",
      "Iteration 42559 => Loss: 44.79507581578693731217\n",
      "Iteration 42560 => Loss: 44.79492469522919151359\n",
      "Iteration 42561 => Loss: 44.79477357585742680612\n",
      "Iteration 42562 => Loss: 44.79462245767164318977\n",
      "Iteration 42563 => Loss: 44.79447134067181224282\n",
      "Iteration 42564 => Loss: 44.79432022485795528155\n",
      "Iteration 42565 => Loss: 44.79416911023006520054\n",
      "Iteration 42566 => Loss: 44.79401799678809226180\n",
      "Iteration 42567 => Loss: 44.79386688453205067617\n",
      "Iteration 42568 => Loss: 44.79371577346191912739\n",
      "Iteration 42569 => Loss: 44.79356466357771893172\n",
      "Iteration 42570 => Loss: 44.79341355487941456204\n",
      "Iteration 42571 => Loss: 44.79326244736699891291\n",
      "Iteration 42572 => Loss: 44.79311134104047908977\n",
      "Iteration 42573 => Loss: 44.79296023589982667090\n",
      "Iteration 42574 => Loss: 44.79280913194503455088\n",
      "Iteration 42575 => Loss: 44.79265802917610272971\n",
      "Iteration 42576 => Loss: 44.79250692759300989110\n",
      "Iteration 42577 => Loss: 44.79235582719576314048\n",
      "Iteration 42578 => Loss: 44.79220472798434116157\n",
      "Iteration 42579 => Loss: 44.79205362995873684895\n",
      "Iteration 42580 => Loss: 44.79190253311895020261\n",
      "Iteration 42581 => Loss: 44.79175143746495280084\n",
      "Iteration 42582 => Loss: 44.79160034299675885450\n",
      "Iteration 42583 => Loss: 44.79144924971433283645\n",
      "Iteration 42584 => Loss: 44.79129815761767474669\n",
      "Iteration 42585 => Loss: 44.79114706670678458522\n",
      "Iteration 42586 => Loss: 44.79099597698165524662\n",
      "Iteration 42587 => Loss: 44.79084488844227962545\n",
      "Iteration 42588 => Loss: 44.79069380108861508916\n",
      "Iteration 42589 => Loss: 44.79054271492068295402\n",
      "Iteration 42590 => Loss: 44.79039162993849743089\n",
      "Iteration 42591 => Loss: 44.79024054614198746549\n",
      "Iteration 42592 => Loss: 44.79008946353117437411\n",
      "Iteration 42593 => Loss: 44.78993838210605105132\n",
      "Iteration 42594 => Loss: 44.78978730186661749713\n",
      "Iteration 42595 => Loss: 44.78963622281284528981\n",
      "Iteration 42596 => Loss: 44.78948514494474153480\n",
      "Iteration 42597 => Loss: 44.78933406826228491582\n",
      "Iteration 42598 => Loss: 44.78918299276547543286\n",
      "Iteration 42599 => Loss: 44.78903191845429176965\n",
      "Iteration 42600 => Loss: 44.78888084532873392618\n",
      "Iteration 42601 => Loss: 44.78872977338876637532\n",
      "Iteration 42602 => Loss: 44.78857870263442464420\n",
      "Iteration 42603 => Loss: 44.78842763306569452197\n",
      "Iteration 42604 => Loss: 44.78827656468252627064\n",
      "Iteration 42605 => Loss: 44.78812549748494831192\n",
      "Iteration 42606 => Loss: 44.78797443147293222410\n",
      "Iteration 42607 => Loss: 44.78782336664646379631\n",
      "Iteration 42608 => Loss: 44.78767230300556434486\n",
      "Iteration 42609 => Loss: 44.78752124055019834259\n",
      "Iteration 42610 => Loss: 44.78737017928035157865\n",
      "Iteration 42611 => Loss: 44.78721911919603115848\n",
      "Iteration 42612 => Loss: 44.78706806029721576579\n",
      "Iteration 42613 => Loss: 44.78691700258391961142\n",
      "Iteration 42614 => Loss: 44.78676594605609295741\n",
      "Iteration 42615 => Loss: 44.78661489071377843629\n",
      "Iteration 42616 => Loss: 44.78646383655692631010\n",
      "Iteration 42617 => Loss: 44.78631278358552236796\n",
      "Iteration 42618 => Loss: 44.78616173179960213702\n",
      "Iteration 42619 => Loss: 44.78601068119910877385\n",
      "Iteration 42620 => Loss: 44.78585963178406359475\n",
      "Iteration 42621 => Loss: 44.78570858355443107257\n",
      "Iteration 42622 => Loss: 44.78555753651024673445\n",
      "Iteration 42623 => Loss: 44.78540649065145373697\n",
      "Iteration 42624 => Loss: 44.78525544597805208014\n",
      "Iteration 42625 => Loss: 44.78510440249004176394\n",
      "Iteration 42626 => Loss: 44.78495336018744410467\n",
      "Iteration 42627 => Loss: 44.78480231907018094262\n",
      "Iteration 42628 => Loss: 44.78465127913828780493\n",
      "Iteration 42629 => Loss: 44.78450024039175758617\n",
      "Iteration 42630 => Loss: 44.78434920283056186463\n",
      "Iteration 42631 => Loss: 44.78419816645470774574\n",
      "Iteration 42632 => Loss: 44.78404713126417391322\n",
      "Iteration 42633 => Loss: 44.78389609725898168335\n",
      "Iteration 42634 => Loss: 44.78374506443906000186\n",
      "Iteration 42635 => Loss: 44.78359403280444439588\n",
      "Iteration 42636 => Loss: 44.78344300235514197084\n",
      "Iteration 42637 => Loss: 44.78329197309107456704\n",
      "Iteration 42638 => Loss: 44.78314094501231323875\n",
      "Iteration 42639 => Loss: 44.78298991811881535341\n",
      "Iteration 42640 => Loss: 44.78283889241054538388\n",
      "Iteration 42641 => Loss: 44.78268786788751754102\n",
      "Iteration 42642 => Loss: 44.78253684454974603568\n",
      "Iteration 42643 => Loss: 44.78238582239716691902\n",
      "Iteration 42644 => Loss: 44.78223480142982992902\n",
      "Iteration 42645 => Loss: 44.78208378164768532770\n",
      "Iteration 42646 => Loss: 44.78193276305073311505\n",
      "Iteration 42647 => Loss: 44.78178174563895908022\n",
      "Iteration 42648 => Loss: 44.78163072941239164493\n",
      "Iteration 42649 => Loss: 44.78147971437097396574\n",
      "Iteration 42650 => Loss: 44.78132870051470604267\n",
      "Iteration 42651 => Loss: 44.78117768784358787570\n",
      "Iteration 42652 => Loss: 44.78102667635761946485\n",
      "Iteration 42653 => Loss: 44.78087566605677949383\n",
      "Iteration 42654 => Loss: 44.78072465694106085721\n",
      "Iteration 42655 => Loss: 44.78057364901045644956\n",
      "Iteration 42656 => Loss: 44.78042264226494495460\n",
      "Iteration 42657 => Loss: 44.78027163670453347777\n",
      "Iteration 42658 => Loss: 44.78012063232919359734\n",
      "Iteration 42659 => Loss: 44.77996962913893952418\n",
      "Iteration 42660 => Loss: 44.77981862713375704743\n",
      "Iteration 42661 => Loss: 44.77966762631361774538\n",
      "Iteration 42662 => Loss: 44.77951662667852161803\n",
      "Iteration 42663 => Loss: 44.77936562822847577081\n",
      "Iteration 42664 => Loss: 44.77921463096345178201\n",
      "Iteration 42665 => Loss: 44.77906363488344965162\n",
      "Iteration 42666 => Loss: 44.77891263998844806338\n",
      "Iteration 42667 => Loss: 44.77876164627846122812\n",
      "Iteration 42668 => Loss: 44.77861065375343940786\n",
      "Iteration 42669 => Loss: 44.77845966241342523517\n",
      "Iteration 42670 => Loss: 44.77830867225837607748\n",
      "Iteration 42671 => Loss: 44.77815768328827772393\n",
      "Iteration 42672 => Loss: 44.77800669550313017453\n",
      "Iteration 42673 => Loss: 44.77785570890295474555\n",
      "Iteration 42674 => Loss: 44.77770472348769459359\n",
      "Iteration 42675 => Loss: 44.77755373925736392948\n",
      "Iteration 42676 => Loss: 44.77740275621196275324\n",
      "Iteration 42677 => Loss: 44.77725177435144843230\n",
      "Iteration 42678 => Loss: 44.77710079367584938836\n",
      "Iteration 42679 => Loss: 44.77694981418511588345\n",
      "Iteration 42680 => Loss: 44.77679883587926212840\n",
      "Iteration 42681 => Loss: 44.77664785875829522865\n",
      "Iteration 42682 => Loss: 44.77649688282219386792\n",
      "Iteration 42683 => Loss: 44.77634590807092962450\n",
      "Iteration 42684 => Loss: 44.77619493450450960381\n",
      "Iteration 42685 => Loss: 44.77604396212292670043\n",
      "Iteration 42686 => Loss: 44.77589299092614538722\n",
      "Iteration 42687 => Loss: 44.77574202091420829674\n",
      "Iteration 42688 => Loss: 44.77559105208707279644\n",
      "Iteration 42689 => Loss: 44.77544008444471757002\n",
      "Iteration 42690 => Loss: 44.77528911798714261749\n",
      "Iteration 42691 => Loss: 44.77513815271436214971\n",
      "Iteration 42692 => Loss: 44.77498718862635485038\n",
      "Iteration 42693 => Loss: 44.77483622572308519239\n",
      "Iteration 42694 => Loss: 44.77468526400457449199\n",
      "Iteration 42695 => Loss: 44.77453430347079432750\n",
      "Iteration 42696 => Loss: 44.77438334412175890975\n",
      "Iteration 42697 => Loss: 44.77423238595743981705\n",
      "Iteration 42698 => Loss: 44.77408142897784415482\n",
      "Iteration 42699 => Loss: 44.77393047318292929049\n",
      "Iteration 42700 => Loss: 44.77377951857272364578\n",
      "Iteration 42701 => Loss: 44.77362856514716327183\n",
      "Iteration 42702 => Loss: 44.77347761290632632836\n",
      "Iteration 42703 => Loss: 44.77332666185013465565\n",
      "Iteration 42704 => Loss: 44.77317571197858825371\n",
      "Iteration 42705 => Loss: 44.77302476329172264968\n",
      "Iteration 42706 => Loss: 44.77287381578945968386\n",
      "Iteration 42707 => Loss: 44.77272286947184909423\n",
      "Iteration 42708 => Loss: 44.77257192433883403737\n",
      "Iteration 42709 => Loss: 44.77242098039043582958\n",
      "Iteration 42710 => Loss: 44.77227003762664025999\n",
      "Iteration 42711 => Loss: 44.77211909604745443403\n",
      "Iteration 42712 => Loss: 44.77196815565282861371\n",
      "Iteration 42713 => Loss: 44.77181721644279122074\n",
      "Iteration 42714 => Loss: 44.77166627841730672799\n",
      "Iteration 42715 => Loss: 44.77151534157636092459\n",
      "Iteration 42716 => Loss: 44.77136440591998223226\n",
      "Iteration 42717 => Loss: 44.77121347144812091301\n",
      "Iteration 42718 => Loss: 44.77106253816079828312\n",
      "Iteration 42719 => Loss: 44.77091160605797881544\n",
      "Iteration 42720 => Loss: 44.77076067513968382627\n",
      "Iteration 42721 => Loss: 44.77060974540587778847\n",
      "Iteration 42722 => Loss: 44.77045881685657491289\n",
      "Iteration 42723 => Loss: 44.77030788949171835611\n",
      "Iteration 42724 => Loss: 44.77015696331134364527\n",
      "Iteration 42725 => Loss: 44.77000603831544367495\n",
      "Iteration 42726 => Loss: 44.76985511450398291800\n",
      "Iteration 42727 => Loss: 44.76970419187696847985\n",
      "Iteration 42728 => Loss: 44.76955327043438614965\n",
      "Iteration 42729 => Loss: 44.76940235017622882197\n",
      "Iteration 42730 => Loss: 44.76925143110248939138\n",
      "Iteration 42731 => Loss: 44.76910051321316075246\n",
      "Iteration 42732 => Loss: 44.76894959650821448349\n",
      "Iteration 42733 => Loss: 44.76879868098765768991\n",
      "Iteration 42734 => Loss: 44.76864776665149037171\n",
      "Iteration 42735 => Loss: 44.76849685349965568548\n",
      "Iteration 42736 => Loss: 44.76834594153221047463\n",
      "Iteration 42737 => Loss: 44.76819503074911210661\n",
      "Iteration 42738 => Loss: 44.76804412115034637054\n",
      "Iteration 42739 => Loss: 44.76789321273592037187\n",
      "Iteration 42740 => Loss: 44.76774230550581279431\n",
      "Iteration 42741 => Loss: 44.76759139946000942700\n",
      "Iteration 42742 => Loss: 44.76744049459850316453\n",
      "Iteration 42743 => Loss: 44.76728959092130111230\n",
      "Iteration 42744 => Loss: 44.76713868842837484863\n",
      "Iteration 42745 => Loss: 44.76698778711974568978\n",
      "Iteration 42746 => Loss: 44.76683688699535679234\n",
      "Iteration 42747 => Loss: 44.76668598805525078888\n",
      "Iteration 42748 => Loss: 44.76653509029938504682\n",
      "Iteration 42749 => Loss: 44.76638419372773824989\n",
      "Iteration 42750 => Loss: 44.76623329834032460894\n",
      "Iteration 42751 => Loss: 44.76608240413712991312\n",
      "Iteration 42752 => Loss: 44.76593151111814705700\n",
      "Iteration 42753 => Loss: 44.76578061928335472430\n",
      "Iteration 42754 => Loss: 44.76562972863278844216\n",
      "Iteration 42755 => Loss: 44.76547883916635584001\n",
      "Iteration 42756 => Loss: 44.76532795088413507756\n",
      "Iteration 42757 => Loss: 44.76517706378606220596\n",
      "Iteration 42758 => Loss: 44.76502617787215143608\n",
      "Iteration 42759 => Loss: 44.76487529314236724076\n",
      "Iteration 42760 => Loss: 44.76472440959674514716\n",
      "Iteration 42761 => Loss: 44.76457352723523541727\n",
      "Iteration 42762 => Loss: 44.76442264605782384024\n",
      "Iteration 42763 => Loss: 44.76427176606453173235\n",
      "Iteration 42764 => Loss: 44.76412088725533777733\n",
      "Iteration 42765 => Loss: 44.76397000963027039688\n",
      "Iteration 42766 => Loss: 44.76381913318923011502\n",
      "Iteration 42767 => Loss: 44.76366825793228798602\n",
      "Iteration 42768 => Loss: 44.76351738385939427189\n",
      "Iteration 42769 => Loss: 44.76336651097055607806\n",
      "Iteration 42770 => Loss: 44.76321563926574498282\n",
      "Iteration 42771 => Loss: 44.76306476874500361873\n",
      "Iteration 42772 => Loss: 44.76291389940825382610\n",
      "Iteration 42773 => Loss: 44.76276303125553113205\n",
      "Iteration 42774 => Loss: 44.76261216428681422030\n",
      "Iteration 42775 => Loss: 44.76246129850210309087\n",
      "Iteration 42776 => Loss: 44.76231043390136932203\n",
      "Iteration 42777 => Loss: 44.76215957048459870293\n",
      "Iteration 42778 => Loss: 44.76200870825180544443\n",
      "Iteration 42779 => Loss: 44.76185784720297533568\n",
      "Iteration 42780 => Loss: 44.76170698733812258752\n",
      "Iteration 42781 => Loss: 44.76155612865716193483\n",
      "Iteration 42782 => Loss: 44.76140527116015022102\n",
      "Iteration 42783 => Loss: 44.76125441484708034068\n",
      "Iteration 42784 => Loss: 44.76110355971789545038\n",
      "Iteration 42785 => Loss: 44.76095270577262397182\n",
      "Iteration 42786 => Loss: 44.76080185301123037789\n",
      "Iteration 42787 => Loss: 44.76065100143375019570\n",
      "Iteration 42788 => Loss: 44.76050015104011947642\n",
      "Iteration 42789 => Loss: 44.76034930183038085261\n",
      "Iteration 42790 => Loss: 44.76019845380447037542\n",
      "Iteration 42791 => Loss: 44.76004760696242357199\n",
      "Iteration 42792 => Loss: 44.75989676130421202060\n",
      "Iteration 42793 => Loss: 44.75974591682982861585\n",
      "Iteration 42794 => Loss: 44.75959507353928046314\n",
      "Iteration 42795 => Loss: 44.75944423143250361363\n",
      "Iteration 42796 => Loss: 44.75929339050956912160\n",
      "Iteration 42797 => Loss: 44.75914255077039882735\n",
      "Iteration 42798 => Loss: 44.75899171221503536344\n",
      "Iteration 42799 => Loss: 44.75884087484343609731\n",
      "Iteration 42800 => Loss: 44.75869003865557971267\n",
      "Iteration 42801 => Loss: 44.75853920365150173666\n",
      "Iteration 42802 => Loss: 44.75838836983115953672\n",
      "Iteration 42803 => Loss: 44.75823753719455311284\n",
      "Iteration 42804 => Loss: 44.75808670574168246503\n",
      "Iteration 42805 => Loss: 44.75793587547252627701\n",
      "Iteration 42806 => Loss: 44.75778504638706323249\n",
      "Iteration 42807 => Loss: 44.75763421848531464775\n",
      "Iteration 42808 => Loss: 44.75748339176723789024\n",
      "Iteration 42809 => Loss: 44.75733256623284006537\n",
      "Iteration 42810 => Loss: 44.75718174188212827858\n",
      "Iteration 42811 => Loss: 44.75703091871509542443\n",
      "Iteration 42812 => Loss: 44.75688009673169176494\n",
      "Iteration 42813 => Loss: 44.75672927593192440554\n",
      "Iteration 42814 => Loss: 44.75657845631580045165\n",
      "Iteration 42815 => Loss: 44.75642763788329858698\n",
      "Iteration 42816 => Loss: 44.75627682063441881155\n",
      "Iteration 42817 => Loss: 44.75612600456913980906\n",
      "Iteration 42818 => Loss: 44.75597518968745447410\n",
      "Iteration 42819 => Loss: 44.75582437598937701750\n",
      "Iteration 42820 => Loss: 44.75567356347485059587\n",
      "Iteration 42821 => Loss: 44.75552275214390363089\n",
      "Iteration 42822 => Loss: 44.75537194199652191173\n",
      "Iteration 42823 => Loss: 44.75522113303268412210\n",
      "Iteration 42824 => Loss: 44.75507032525238315657\n",
      "Iteration 42825 => Loss: 44.75491951865561901514\n",
      "Iteration 42826 => Loss: 44.75476871324237038152\n",
      "Iteration 42827 => Loss: 44.75461790901265146658\n",
      "Iteration 42828 => Loss: 44.75446710596640542690\n",
      "Iteration 42829 => Loss: 44.75431630410368200046\n",
      "Iteration 42830 => Loss: 44.75416550342442434385\n",
      "Iteration 42831 => Loss: 44.75401470392866798420\n",
      "Iteration 42832 => Loss: 44.75386390561634897267\n",
      "Iteration 42833 => Loss: 44.75371310848749573097\n",
      "Iteration 42834 => Loss: 44.75356231254212246995\n",
      "Iteration 42835 => Loss: 44.75341151778012971363\n",
      "Iteration 42836 => Loss: 44.75326072420161693799\n",
      "Iteration 42837 => Loss: 44.75310993180649887790\n",
      "Iteration 42838 => Loss: 44.75295914059479684965\n",
      "Iteration 42839 => Loss: 44.75280835056650374781\n",
      "Iteration 42840 => Loss: 44.75265756172159115067\n",
      "Iteration 42841 => Loss: 44.75250677406005905823\n",
      "Iteration 42842 => Loss: 44.75235598758191457591\n",
      "Iteration 42843 => Loss: 44.75220520228712217659\n",
      "Iteration 42844 => Loss: 44.75205441817569607110\n",
      "Iteration 42845 => Loss: 44.75190363524760073233\n",
      "Iteration 42846 => Loss: 44.75175285350284326569\n",
      "Iteration 42847 => Loss: 44.75160207294143788204\n",
      "Iteration 42848 => Loss: 44.75145129356332773796\n",
      "Iteration 42849 => Loss: 44.75130051536853414973\n",
      "Iteration 42850 => Loss: 44.75114973835703580107\n",
      "Iteration 42851 => Loss: 44.75099896252883269199\n",
      "Iteration 42852 => Loss: 44.75084818788389640076\n",
      "Iteration 42853 => Loss: 44.75069741442223403283\n",
      "Iteration 42854 => Loss: 44.75054664214385269361\n",
      "Iteration 42855 => Loss: 44.75039587104869553968\n",
      "Iteration 42856 => Loss: 44.75024510113680520362\n",
      "Iteration 42857 => Loss: 44.75009433240816036914\n",
      "Iteration 42858 => Loss: 44.74994356486271129825\n",
      "Iteration 42859 => Loss: 44.74979279850050772893\n",
      "Iteration 42860 => Loss: 44.74964203332147860692\n",
      "Iteration 42861 => Loss: 44.74949126932566656478\n",
      "Iteration 42862 => Loss: 44.74934050651304318080\n",
      "Iteration 42863 => Loss: 44.74918974488358713870\n",
      "Iteration 42864 => Loss: 44.74903898443730554391\n",
      "Iteration 42865 => Loss: 44.74888822517419129099\n",
      "Iteration 42866 => Loss: 44.74873746709421595824\n",
      "Iteration 42867 => Loss: 44.74858671019737954566\n",
      "Iteration 42868 => Loss: 44.74843595448368915868\n",
      "Iteration 42869 => Loss: 44.74828519995311637558\n",
      "Iteration 42870 => Loss: 44.74813444660564698552\n",
      "Iteration 42871 => Loss: 44.74798369444130230477\n",
      "Iteration 42872 => Loss: 44.74783294346003970077\n",
      "Iteration 42873 => Loss: 44.74768219366187338437\n",
      "Iteration 42874 => Loss: 44.74753144504676782844\n",
      "Iteration 42875 => Loss: 44.74738069761473013841\n",
      "Iteration 42876 => Loss: 44.74722995136576031427\n",
      "Iteration 42877 => Loss: 44.74707920629982282890\n",
      "Iteration 42878 => Loss: 44.74692846241696031484\n",
      "Iteration 42879 => Loss: 44.74677771971707329612\n",
      "Iteration 42880 => Loss: 44.74662697820026124873\n",
      "Iteration 42881 => Loss: 44.74647623786642469668\n",
      "Iteration 42882 => Loss: 44.74632549871561337795\n",
      "Iteration 42883 => Loss: 44.74617476074778466000\n",
      "Iteration 42884 => Loss: 44.74602402396293143738\n",
      "Iteration 42885 => Loss: 44.74587328836106081553\n",
      "Iteration 42886 => Loss: 44.74572255394215858360\n",
      "Iteration 42887 => Loss: 44.74557182070621053072\n",
      "Iteration 42888 => Loss: 44.74542108865320244604\n",
      "Iteration 42889 => Loss: 44.74527035778314143499\n",
      "Iteration 42890 => Loss: 44.74511962809599907587\n",
      "Iteration 42891 => Loss: 44.74496889959178247409\n",
      "Iteration 42892 => Loss: 44.74481817227047741881\n",
      "Iteration 42893 => Loss: 44.74466744613206969916\n",
      "Iteration 42894 => Loss: 44.74451672117656642058\n",
      "Iteration 42895 => Loss: 44.74436599740391073965\n",
      "Iteration 42896 => Loss: 44.74421527481415949978\n",
      "Iteration 42897 => Loss: 44.74406455340722743586\n",
      "Iteration 42898 => Loss: 44.74391383318319270757\n",
      "Iteration 42899 => Loss: 44.74376311414199847150\n",
      "Iteration 42900 => Loss: 44.74361239628360920051\n",
      "Iteration 42901 => Loss: 44.74346167960808173802\n",
      "Iteration 42902 => Loss: 44.74331096411535213520\n",
      "Iteration 42903 => Loss: 44.74316024980542749745\n",
      "Iteration 42904 => Loss: 44.74300953667831493021\n",
      "Iteration 42905 => Loss: 44.74285882473398601178\n",
      "Iteration 42906 => Loss: 44.74270811397241232044\n",
      "Iteration 42907 => Loss: 44.74255740439362938332\n",
      "Iteration 42908 => Loss: 44.74240669599761588415\n",
      "Iteration 42909 => Loss: 44.74225598878435050665\n",
      "Iteration 42910 => Loss: 44.74210528275381903995\n",
      "Iteration 42911 => Loss: 44.74195457790602148407\n",
      "Iteration 42912 => Loss: 44.74180387424095073357\n",
      "Iteration 42913 => Loss: 44.74165317175859968302\n",
      "Iteration 42914 => Loss: 44.74150247045893280529\n",
      "Iteration 42915 => Loss: 44.74135177034199273294\n",
      "Iteration 42916 => Loss: 44.74120107140771551713\n",
      "Iteration 42917 => Loss: 44.74105037365611536870\n",
      "Iteration 42918 => Loss: 44.74089967708719228767\n",
      "Iteration 42919 => Loss: 44.74074898170093206318\n",
      "Iteration 42920 => Loss: 44.74059828749730627351\n",
      "Iteration 42921 => Loss: 44.74044759447635044580\n",
      "Iteration 42922 => Loss: 44.74029690263800063121\n",
      "Iteration 42923 => Loss: 44.74014621198226393517\n",
      "Iteration 42924 => Loss: 44.73999552250915456852\n",
      "Iteration 42925 => Loss: 44.73984483421863700414\n",
      "Iteration 42926 => Loss: 44.73969414711071834745\n",
      "Iteration 42927 => Loss: 44.73954346118538438759\n",
      "Iteration 42928 => Loss: 44.73939277644265644085\n",
      "Iteration 42929 => Loss: 44.73924209288245634752\n",
      "Iteration 42930 => Loss: 44.73909141050482674018\n",
      "Iteration 42931 => Loss: 44.73894072930973919711\n",
      "Iteration 42932 => Loss: 44.73879004929719371830\n",
      "Iteration 42933 => Loss: 44.73863937046716898749\n",
      "Iteration 42934 => Loss: 44.73848869281967921552\n",
      "Iteration 42935 => Loss: 44.73833801635468176983\n",
      "Iteration 42936 => Loss: 44.73818734107219086127\n",
      "Iteration 42937 => Loss: 44.73803666697220648985\n",
      "Iteration 42938 => Loss: 44.73788599405470023385\n",
      "Iteration 42939 => Loss: 44.73773532231964367156\n",
      "Iteration 42940 => Loss: 44.73758465176705811928\n",
      "Iteration 42941 => Loss: 44.73743398239694357699\n",
      "Iteration 42942 => Loss: 44.73728331420926451756\n",
      "Iteration 42943 => Loss: 44.73713264720402804642\n",
      "Iteration 42944 => Loss: 44.73698198138121995271\n",
      "Iteration 42945 => Loss: 44.73683131674081892015\n",
      "Iteration 42946 => Loss: 44.73668065328283205417\n",
      "Iteration 42947 => Loss: 44.73652999100724514392\n",
      "Iteration 42948 => Loss: 44.73637932991404397853\n",
      "Iteration 42949 => Loss: 44.73622867000322855802\n",
      "Iteration 42950 => Loss: 44.73607801127477756609\n",
      "Iteration 42951 => Loss: 44.73592735372866258103\n",
      "Iteration 42952 => Loss: 44.73577669736496176256\n",
      "Iteration 42953 => Loss: 44.73562604218356142383\n",
      "Iteration 42954 => Loss: 44.73547538818450419740\n",
      "Iteration 42955 => Loss: 44.73532473536776166156\n",
      "Iteration 42956 => Loss: 44.73517408373334802718\n",
      "Iteration 42957 => Loss: 44.73502343328122776711\n",
      "Iteration 42958 => Loss: 44.73487278401142930306\n",
      "Iteration 42959 => Loss: 44.73472213592391000248\n",
      "Iteration 42960 => Loss: 44.73457148901863433821\n",
      "Iteration 42961 => Loss: 44.73442084329566625911\n",
      "Iteration 42962 => Loss: 44.73427019875494181633\n",
      "Iteration 42963 => Loss: 44.73411955539648943159\n",
      "Iteration 42964 => Loss: 44.73396891322025226145\n",
      "Iteration 42965 => Loss: 44.73381827222625872764\n",
      "Iteration 42966 => Loss: 44.73366763241448040844\n",
      "Iteration 42967 => Loss: 44.73351699378493151471\n",
      "Iteration 42968 => Loss: 44.73336635633756941388\n",
      "Iteration 42969 => Loss: 44.73321572007241542224\n",
      "Iteration 42970 => Loss: 44.73306508498942690721\n",
      "Iteration 42971 => Loss: 44.73291445108863229052\n",
      "Iteration 42972 => Loss: 44.73276381837001736130\n",
      "Iteration 42973 => Loss: 44.73261318683352527614\n",
      "Iteration 42974 => Loss: 44.73246255647919866760\n",
      "Iteration 42975 => Loss: 44.73231192730699490312\n",
      "Iteration 42976 => Loss: 44.73216129931694240440\n",
      "Iteration 42977 => Loss: 44.73201067250900564432\n",
      "Iteration 42978 => Loss: 44.73186004688319172828\n",
      "Iteration 42979 => Loss: 44.73170942243945091832\n",
      "Iteration 42980 => Loss: 44.73155879917784005784\n",
      "Iteration 42981 => Loss: 44.73140817709828809257\n",
      "Iteration 42982 => Loss: 44.73125755620080212793\n",
      "Iteration 42983 => Loss: 44.73110693648538926936\n",
      "Iteration 42984 => Loss: 44.73095631795204241143\n",
      "Iteration 42985 => Loss: 44.73080570060071892158\n",
      "Iteration 42986 => Loss: 44.73065508443146143236\n",
      "Iteration 42987 => Loss: 44.73050446944420599493\n",
      "Iteration 42988 => Loss: 44.73035385563899524186\n",
      "Iteration 42989 => Loss: 44.73020324301578654058\n",
      "Iteration 42990 => Loss: 44.73005263157456568024\n",
      "Iteration 42991 => Loss: 44.72990202131533976626\n",
      "Iteration 42992 => Loss: 44.72975141223810169322\n",
      "Iteration 42993 => Loss: 44.72960080434283014483\n",
      "Iteration 42994 => Loss: 44.72945019762950380482\n",
      "Iteration 42995 => Loss: 44.72929959209817951660\n",
      "Iteration 42996 => Loss: 44.72914898774877912047\n",
      "Iteration 42997 => Loss: 44.72899838458128130014\n",
      "Iteration 42998 => Loss: 44.72884778259574289905\n",
      "Iteration 42999 => Loss: 44.72869718179209996833\n",
      "Iteration 43000 => Loss: 44.72854658217037382428\n",
      "Iteration 43001 => Loss: 44.72839598373055025604\n",
      "Iteration 43002 => Loss: 44.72824538647260084190\n",
      "Iteration 43003 => Loss: 44.72809479039654689814\n",
      "Iteration 43004 => Loss: 44.72794419550234579219\n",
      "Iteration 43005 => Loss: 44.72779360179002594577\n",
      "Iteration 43006 => Loss: 44.72764300925954472632\n",
      "Iteration 43007 => Loss: 44.72749241791091634468\n",
      "Iteration 43008 => Loss: 44.72734182774411237915\n",
      "Iteration 43009 => Loss: 44.72719123875913282973\n",
      "Iteration 43010 => Loss: 44.72704065095596348556\n",
      "Iteration 43011 => Loss: 44.72689006433461145207\n",
      "Iteration 43012 => Loss: 44.72673947889504120212\n",
      "Iteration 43013 => Loss: 44.72658889463725984115\n",
      "Iteration 43014 => Loss: 44.72643831156127447457\n",
      "Iteration 43015 => Loss: 44.72628772966703536440\n",
      "Iteration 43016 => Loss: 44.72613714895457093235\n",
      "Iteration 43017 => Loss: 44.72598656942384565127\n",
      "Iteration 43018 => Loss: 44.72583599107485241575\n",
      "Iteration 43019 => Loss: 44.72568541390761254206\n",
      "Iteration 43020 => Loss: 44.72553483792208339764\n",
      "Iteration 43021 => Loss: 44.72538426311827208792\n",
      "Iteration 43022 => Loss: 44.72523368949612887491\n",
      "Iteration 43023 => Loss: 44.72508311705571770744\n",
      "Iteration 43024 => Loss: 44.72493254579698174211\n",
      "Iteration 43025 => Loss: 44.72478197571992808435\n",
      "Iteration 43026 => Loss: 44.72463140682452120700\n",
      "Iteration 43027 => Loss: 44.72448083911078953179\n",
      "Iteration 43028 => Loss: 44.72433027257869042614\n",
      "Iteration 43029 => Loss: 44.72417970722825941721\n",
      "Iteration 43030 => Loss: 44.72402914305941834527\n",
      "Iteration 43031 => Loss: 44.72387858007221694834\n",
      "Iteration 43032 => Loss: 44.72372801826663391012\n",
      "Iteration 43033 => Loss: 44.72357745764264080890\n",
      "Iteration 43034 => Loss: 44.72342689820021632841\n",
      "Iteration 43035 => Loss: 44.72327633993941731205\n",
      "Iteration 43036 => Loss: 44.72312578286017981100\n",
      "Iteration 43037 => Loss: 44.72297522696248250895\n",
      "Iteration 43038 => Loss: 44.72282467224636093306\n",
      "Iteration 43039 => Loss: 44.72267411871177955618\n",
      "Iteration 43040 => Loss: 44.72252356635873837831\n",
      "Iteration 43041 => Loss: 44.72237301518720187232\n",
      "Iteration 43042 => Loss: 44.72222246519721977620\n",
      "Iteration 43043 => Loss: 44.72207191638873524653\n",
      "Iteration 43044 => Loss: 44.72192136876172696702\n",
      "Iteration 43045 => Loss: 44.72177082231623046482\n",
      "Iteration 43046 => Loss: 44.72162027705221731821\n",
      "Iteration 43047 => Loss: 44.72146973296965910549\n",
      "Iteration 43048 => Loss: 44.72131919006858424837\n",
      "Iteration 43049 => Loss: 44.72116864834894300884\n",
      "Iteration 43050 => Loss: 44.72101810781074249235\n",
      "Iteration 43051 => Loss: 44.72086756845398980431\n",
      "Iteration 43052 => Loss: 44.72071703027866362845\n",
      "Iteration 43053 => Loss: 44.72056649328473554306\n",
      "Iteration 43054 => Loss: 44.72041595747222686441\n",
      "Iteration 43055 => Loss: 44.72026542284111627623\n",
      "Iteration 43056 => Loss: 44.72011488939138956766\n",
      "Iteration 43057 => Loss: 44.71996435712304673871\n",
      "Iteration 43058 => Loss: 44.71981382603607357851\n",
      "Iteration 43059 => Loss: 44.71966329613043455993\n",
      "Iteration 43060 => Loss: 44.71951276740617942096\n",
      "Iteration 43061 => Loss: 44.71936223986325842361\n",
      "Iteration 43062 => Loss: 44.71921171350165735703\n",
      "Iteration 43063 => Loss: 44.71906118832139043207\n",
      "Iteration 43064 => Loss: 44.71891066432242212159\n",
      "Iteration 43065 => Loss: 44.71876014150478084730\n",
      "Iteration 43066 => Loss: 44.71860961986841687121\n",
      "Iteration 43067 => Loss: 44.71845909941334440418\n",
      "Iteration 43068 => Loss: 44.71830858013954923535\n",
      "Iteration 43069 => Loss: 44.71815806204702425930\n",
      "Iteration 43070 => Loss: 44.71800754513576237059\n",
      "Iteration 43071 => Loss: 44.71785702940573514752\n",
      "Iteration 43072 => Loss: 44.71770651485695680094\n",
      "Iteration 43073 => Loss: 44.71755600148941312000\n",
      "Iteration 43074 => Loss: 44.71740548930306857756\n",
      "Iteration 43075 => Loss: 44.71725497829795870075\n",
      "Iteration 43076 => Loss: 44.71710446847404796245\n",
      "Iteration 43077 => Loss: 44.71695395983133636264\n",
      "Iteration 43078 => Loss: 44.71680345236978126877\n",
      "Iteration 43079 => Loss: 44.71665294608942531340\n",
      "Iteration 43080 => Loss: 44.71650244099021875854\n",
      "Iteration 43081 => Loss: 44.71635193707217581505\n",
      "Iteration 43082 => Loss: 44.71620143433528937749\n",
      "Iteration 43083 => Loss: 44.71605093277952391873\n",
      "Iteration 43084 => Loss: 44.71590043240489364962\n",
      "Iteration 43085 => Loss: 44.71574993321137014846\n",
      "Iteration 43086 => Loss: 44.71559943519898183695\n",
      "Iteration 43087 => Loss: 44.71544893836766476625\n",
      "Iteration 43088 => Loss: 44.71529844271746156892\n",
      "Iteration 43089 => Loss: 44.71514794824833671782\n",
      "Iteration 43090 => Loss: 44.71499745496028310754\n",
      "Iteration 43091 => Loss: 44.71484696285329363263\n",
      "Iteration 43092 => Loss: 44.71469647192735408225\n",
      "Iteration 43093 => Loss: 44.71454598218247156183\n",
      "Iteration 43094 => Loss: 44.71439549361860343879\n",
      "Iteration 43095 => Loss: 44.71424500623577813485\n",
      "Iteration 43096 => Loss: 44.71409452003395301745\n",
      "Iteration 43097 => Loss: 44.71394403501314229743\n",
      "Iteration 43098 => Loss: 44.71379355117335308023\n",
      "Iteration 43099 => Loss: 44.71364306851453562786\n",
      "Iteration 43100 => Loss: 44.71349258703668994031\n",
      "Iteration 43101 => Loss: 44.71334210673982312301\n",
      "Iteration 43102 => Loss: 44.71319162762392096511\n",
      "Iteration 43103 => Loss: 44.71304114968896215032\n",
      "Iteration 43104 => Loss: 44.71289067293496799493\n",
      "Iteration 43105 => Loss: 44.71274019736188876095\n",
      "Iteration 43106 => Loss: 44.71258972296973155380\n",
      "Iteration 43107 => Loss: 44.71243924975847505721\n",
      "Iteration 43108 => Loss: 44.71228877772814769287\n",
      "Iteration 43109 => Loss: 44.71213830687871393366\n",
      "Iteration 43110 => Loss: 44.71198783721018799042\n",
      "Iteration 43111 => Loss: 44.71183736872249880889\n",
      "Iteration 43112 => Loss: 44.71168690141570323249\n",
      "Iteration 43113 => Loss: 44.71153643528975152321\n",
      "Iteration 43114 => Loss: 44.71138597034466499736\n",
      "Iteration 43115 => Loss: 44.71123550658041523320\n",
      "Iteration 43116 => Loss: 44.71108504399700223075\n",
      "Iteration 43117 => Loss: 44.71093458259439756830\n",
      "Iteration 43118 => Loss: 44.71078412237261545670\n",
      "Iteration 43119 => Loss: 44.71063366333162747424\n",
      "Iteration 43120 => Loss: 44.71048320547144783177\n",
      "Iteration 43121 => Loss: 44.71033274879204100216\n",
      "Iteration 43122 => Loss: 44.71018229329342830169\n",
      "Iteration 43123 => Loss: 44.71003183897555999238\n",
      "Iteration 43124 => Loss: 44.70988138583847870677\n",
      "Iteration 43125 => Loss: 44.70973093388212049604\n",
      "Iteration 43126 => Loss: 44.70958048310651378188\n",
      "Iteration 43127 => Loss: 44.70943003351162303716\n",
      "Iteration 43128 => Loss: 44.70927958509745536730\n",
      "Iteration 43129 => Loss: 44.70912913786401077232\n",
      "Iteration 43130 => Loss: 44.70897869181127504135\n",
      "Iteration 43131 => Loss: 44.70882824693921975268\n",
      "Iteration 43132 => Loss: 44.70867780324783780088\n",
      "Iteration 43133 => Loss: 44.70852736073712918596\n",
      "Iteration 43134 => Loss: 44.70837691940710101335\n",
      "Iteration 43135 => Loss: 44.70822647925772486133\n",
      "Iteration 43136 => Loss: 44.70807604028900072990\n",
      "Iteration 43137 => Loss: 44.70792560250090019736\n",
      "Iteration 43138 => Loss: 44.70777516589345168541\n",
      "Iteration 43139 => Loss: 44.70762473046658413978\n",
      "Iteration 43140 => Loss: 44.70747429622035440389\n",
      "Iteration 43141 => Loss: 44.70732386315471984517\n",
      "Iteration 43142 => Loss: 44.70717343126967335820\n",
      "Iteration 43143 => Loss: 44.70702300056519362670\n",
      "Iteration 43144 => Loss: 44.70687257104130196694\n",
      "Iteration 43145 => Loss: 44.70672214269795574637\n",
      "Iteration 43146 => Loss: 44.70657171553519049212\n",
      "Iteration 43147 => Loss: 44.70642128955297778248\n",
      "Iteration 43148 => Loss: 44.70627086475127498488\n",
      "Iteration 43149 => Loss: 44.70612044113008920476\n",
      "Iteration 43150 => Loss: 44.70597001868945596925\n",
      "Iteration 43151 => Loss: 44.70581959742929711865\n",
      "Iteration 43152 => Loss: 44.70566917734964818010\n",
      "Iteration 43153 => Loss: 44.70551875845048783731\n",
      "Iteration 43154 => Loss: 44.70536834073180898486\n",
      "Iteration 43155 => Loss: 44.70521792419359741189\n",
      "Iteration 43156 => Loss: 44.70506750883584601297\n",
      "Iteration 43157 => Loss: 44.70491709465854768268\n",
      "Iteration 43158 => Loss: 44.70476668166169531560\n",
      "Iteration 43159 => Loss: 44.70461626984526049000\n",
      "Iteration 43160 => Loss: 44.70446585920927162761\n",
      "Iteration 43161 => Loss: 44.70431544975370030670\n",
      "Iteration 43162 => Loss: 44.70416504147851810558\n",
      "Iteration 43163 => Loss: 44.70401463438373212966\n",
      "Iteration 43164 => Loss: 44.70386422846933527353\n",
      "Iteration 43165 => Loss: 44.70371382373532753718\n",
      "Iteration 43166 => Loss: 44.70356342018167339347\n",
      "Iteration 43167 => Loss: 44.70341301780838705326\n",
      "Iteration 43168 => Loss: 44.70326261661544720027\n",
      "Iteration 43169 => Loss: 44.70311221660284672907\n",
      "Iteration 43170 => Loss: 44.70296181777056432338\n",
      "Iteration 43171 => Loss: 44.70281142011863551033\n",
      "Iteration 43172 => Loss: 44.70266102364701055194\n",
      "Iteration 43173 => Loss: 44.70251062835565392106\n",
      "Iteration 43174 => Loss: 44.70236023424462956655\n",
      "Iteration 43175 => Loss: 44.70220984131389485583\n",
      "Iteration 43176 => Loss: 44.70205944956342847263\n",
      "Iteration 43177 => Loss: 44.70190905899320910066\n",
      "Iteration 43178 => Loss: 44.70175866960325095079\n",
      "Iteration 43179 => Loss: 44.70160828139354691757\n",
      "Iteration 43180 => Loss: 44.70145789436411121187\n",
      "Iteration 43181 => Loss: 44.70130750851485146313\n",
      "Iteration 43182 => Loss: 44.70115712384586004191\n",
      "Iteration 43183 => Loss: 44.70100674035705878850\n",
      "Iteration 43184 => Loss: 44.70085635804844770291\n",
      "Iteration 43185 => Loss: 44.70070597692003389056\n",
      "Iteration 43186 => Loss: 44.70055559697181024603\n",
      "Iteration 43187 => Loss: 44.70040521820375545303\n",
      "Iteration 43188 => Loss: 44.70025484061589082785\n",
      "Iteration 43189 => Loss: 44.70010446420814531621\n",
      "Iteration 43190 => Loss: 44.69995408898055444524\n",
      "Iteration 43191 => Loss: 44.69980371493311821496\n",
      "Iteration 43192 => Loss: 44.69965334206579399279\n",
      "Iteration 43193 => Loss: 44.69950297037857467330\n",
      "Iteration 43194 => Loss: 44.69935259987150288907\n",
      "Iteration 43195 => Loss: 44.69920223054450758582\n",
      "Iteration 43196 => Loss: 44.69905186239758876354\n",
      "Iteration 43197 => Loss: 44.69890149543079616024\n",
      "Iteration 43198 => Loss: 44.69875112964402319449\n",
      "Iteration 43199 => Loss: 44.69860076503734092057\n",
      "Iteration 43200 => Loss: 44.69845040161070670592\n",
      "Iteration 43201 => Loss: 44.69830003936412765597\n",
      "Iteration 43202 => Loss: 44.69814967829756113815\n",
      "Iteration 43203 => Loss: 44.69799931841104978503\n",
      "Iteration 43204 => Loss: 44.69784895970453675318\n",
      "Iteration 43205 => Loss: 44.69769860217801493718\n",
      "Iteration 43206 => Loss: 44.69754824583150565331\n",
      "Iteration 43207 => Loss: 44.69739789066500179615\n",
      "Iteration 43208 => Loss: 44.69724753667845362770\n",
      "Iteration 43209 => Loss: 44.69709718387189667510\n",
      "Iteration 43210 => Loss: 44.69694683224528830578\n",
      "Iteration 43211 => Loss: 44.69679648179862851975\n",
      "Iteration 43212 => Loss: 44.69664613253191731701\n",
      "Iteration 43213 => Loss: 44.69649578444514048670\n",
      "Iteration 43214 => Loss: 44.69634543753826960710\n",
      "Iteration 43215 => Loss: 44.69619509181134020537\n",
      "Iteration 43216 => Loss: 44.69604474726431675435\n",
      "Iteration 43217 => Loss: 44.69589440389715662150\n",
      "Iteration 43218 => Loss: 44.69574406170990243936\n",
      "Iteration 43219 => Loss: 44.69559372070252578624\n",
      "Iteration 43220 => Loss: 44.69544338087503376755\n",
      "Iteration 43221 => Loss: 44.69529304222738375074\n",
      "Iteration 43222 => Loss: 44.69514270475956863038\n",
      "Iteration 43223 => Loss: 44.69499236847163103903\n",
      "Iteration 43224 => Loss: 44.69484203336349281699\n",
      "Iteration 43225 => Loss: 44.69469169943518949140\n",
      "Iteration 43226 => Loss: 44.69454136668668553511\n",
      "Iteration 43227 => Loss: 44.69439103511801647528\n",
      "Iteration 43228 => Loss: 44.69424070472910415219\n",
      "Iteration 43229 => Loss: 44.69409037552000540927\n",
      "Iteration 43230 => Loss: 44.69394004749066340310\n",
      "Iteration 43231 => Loss: 44.69378972064109944995\n",
      "Iteration 43232 => Loss: 44.69363939497127802269\n",
      "Iteration 43233 => Loss: 44.69348907048122043761\n",
      "Iteration 43234 => Loss: 44.69333874717091248385\n",
      "Iteration 43235 => Loss: 44.69318842504031152885\n",
      "Iteration 43236 => Loss: 44.69303810408943178345\n",
      "Iteration 43237 => Loss: 44.69288778431827324766\n",
      "Iteration 43238 => Loss: 44.69273746572680749978\n",
      "Iteration 43239 => Loss: 44.69258714831504164522\n",
      "Iteration 43240 => Loss: 44.69243683208296857856\n",
      "Iteration 43241 => Loss: 44.69228651703053856181\n",
      "Iteration 43242 => Loss: 44.69213620315780843839\n",
      "Iteration 43243 => Loss: 44.69198589046469294317\n",
      "Iteration 43244 => Loss: 44.69183557895127023585\n",
      "Iteration 43245 => Loss: 44.69168526861745505130\n",
      "Iteration 43246 => Loss: 44.69153495946327581123\n",
      "Iteration 43247 => Loss: 44.69138465148871119936\n",
      "Iteration 43248 => Loss: 44.69123434469375411027\n",
      "Iteration 43249 => Loss: 44.69108403907838322766\n",
      "Iteration 43250 => Loss: 44.69093373464264118411\n",
      "Iteration 43251 => Loss: 44.69078343138646403077\n",
      "Iteration 43252 => Loss: 44.69063312930984466220\n",
      "Iteration 43253 => Loss: 44.69048282841279018385\n",
      "Iteration 43254 => Loss: 44.69033252869530770113\n",
      "Iteration 43255 => Loss: 44.69018223015734747605\n",
      "Iteration 43256 => Loss: 44.69003193279892371947\n",
      "Iteration 43257 => Loss: 44.68988163662005064225\n",
      "Iteration 43258 => Loss: 44.68973134162067140096\n",
      "Iteration 43259 => Loss: 44.68958104780082152274\n",
      "Iteration 43260 => Loss: 44.68943075516044416418\n",
      "Iteration 43261 => Loss: 44.68928046369956774697\n",
      "Iteration 43262 => Loss: 44.68913017341815674399\n",
      "Iteration 43263 => Loss: 44.68897988431622536609\n",
      "Iteration 43264 => Loss: 44.68882959639376650784\n",
      "Iteration 43265 => Loss: 44.68867930965075174754\n",
      "Iteration 43266 => Loss: 44.68852902408718108518\n",
      "Iteration 43267 => Loss: 44.68837873970304030991\n",
      "Iteration 43268 => Loss: 44.68822845649832942172\n",
      "Iteration 43269 => Loss: 44.68807817447301999891\n",
      "Iteration 43270 => Loss: 44.68792789362711914691\n",
      "Iteration 43271 => Loss: 44.68777761396061976029\n",
      "Iteration 43272 => Loss: 44.68762733547350762819\n",
      "Iteration 43273 => Loss: 44.68747705816576853977\n",
      "Iteration 43274 => Loss: 44.68732678203741670586\n",
      "Iteration 43275 => Loss: 44.68717650708838817764\n",
      "Iteration 43276 => Loss: 44.68702623331872558765\n",
      "Iteration 43277 => Loss: 44.68687596072841472505\n",
      "Iteration 43278 => Loss: 44.68672568931744137899\n",
      "Iteration 43279 => Loss: 44.68657541908577002232\n",
      "Iteration 43280 => Loss: 44.68642515003341486590\n",
      "Iteration 43281 => Loss: 44.68627488216037590973\n",
      "Iteration 43282 => Loss: 44.68612461546662473211\n",
      "Iteration 43283 => Loss: 44.68597434995214712217\n",
      "Iteration 43284 => Loss: 44.68582408561695018534\n",
      "Iteration 43285 => Loss: 44.68567382246103392163\n",
      "Iteration 43286 => Loss: 44.68552356048435569846\n",
      "Iteration 43287 => Loss: 44.68537329968694393756\n",
      "Iteration 43288 => Loss: 44.68522304006875600635\n",
      "Iteration 43289 => Loss: 44.68507278162978479941\n",
      "Iteration 43290 => Loss: 44.68492252437006584387\n",
      "Iteration 43291 => Loss: 44.68477226828954229632\n",
      "Iteration 43292 => Loss: 44.68462201338822836760\n",
      "Iteration 43293 => Loss: 44.68447175966611695230\n",
      "Iteration 43294 => Loss: 44.68432150712316541785\n",
      "Iteration 43295 => Loss: 44.68417125575938797510\n",
      "Iteration 43296 => Loss: 44.68402100557477751863\n",
      "Iteration 43297 => Loss: 44.68387075656934115386\n",
      "Iteration 43298 => Loss: 44.68372050874303624823\n",
      "Iteration 43299 => Loss: 44.68357026209586280174\n",
      "Iteration 43300 => Loss: 44.68342001662784213067\n",
      "Iteration 43301 => Loss: 44.68326977233891028618\n",
      "Iteration 43302 => Loss: 44.68311952922910279540\n",
      "Iteration 43303 => Loss: 44.68296928729839123662\n",
      "Iteration 43304 => Loss: 44.68281904654677560984\n",
      "Iteration 43305 => Loss: 44.68266880697424170421\n",
      "Iteration 43306 => Loss: 44.68251856858076109802\n",
      "Iteration 43307 => Loss: 44.68236833136636221298\n",
      "Iteration 43308 => Loss: 44.68221809533100952194\n",
      "Iteration 43309 => Loss: 44.68206786047471013035\n",
      "Iteration 43310 => Loss: 44.68191762679745693276\n",
      "Iteration 43311 => Loss: 44.68176739429920019120\n",
      "Iteration 43312 => Loss: 44.68161716297997543279\n",
      "Iteration 43313 => Loss: 44.68146693283974002497\n",
      "Iteration 43314 => Loss: 44.68131670387852949489\n",
      "Iteration 43315 => Loss: 44.68116647609630120996\n",
      "Iteration 43316 => Loss: 44.68101624949305517021\n",
      "Iteration 43317 => Loss: 44.68086602406877005933\n",
      "Iteration 43318 => Loss: 44.68071579982346008819\n",
      "Iteration 43319 => Loss: 44.68056557675707551880\n",
      "Iteration 43320 => Loss: 44.68041535486965898372\n",
      "Iteration 43321 => Loss: 44.68026513416115363952\n",
      "Iteration 43322 => Loss: 44.68011491463158790793\n",
      "Iteration 43323 => Loss: 44.67996469628095468352\n",
      "Iteration 43324 => Loss: 44.67981447910919001743\n",
      "Iteration 43325 => Loss: 44.67966426311635785851\n",
      "Iteration 43326 => Loss: 44.67951404830237294163\n",
      "Iteration 43327 => Loss: 44.67936383466729921565\n",
      "Iteration 43328 => Loss: 44.67921362221107273172\n",
      "Iteration 43329 => Loss: 44.67906341093372901696\n",
      "Iteration 43330 => Loss: 44.67891320083521122797\n",
      "Iteration 43331 => Loss: 44.67876299191556199730\n",
      "Iteration 43332 => Loss: 44.67861278417471027069\n",
      "Iteration 43333 => Loss: 44.67846257761269868070\n",
      "Iteration 43334 => Loss: 44.67831237222951301646\n",
      "Iteration 43335 => Loss: 44.67816216802509643458\n",
      "Iteration 43336 => Loss: 44.67801196499949867302\n",
      "Iteration 43337 => Loss: 44.67786176315268420467\n",
      "Iteration 43338 => Loss: 44.67771156248465302951\n",
      "Iteration 43339 => Loss: 44.67756136299536962042\n",
      "Iteration 43340 => Loss: 44.67741116468486239910\n",
      "Iteration 43341 => Loss: 44.67726096755311715469\n",
      "Iteration 43342 => Loss: 44.67711077160006993836\n",
      "Iteration 43343 => Loss: 44.67696057682577048809\n",
      "Iteration 43344 => Loss: 44.67681038323020459302\n",
      "Iteration 43345 => Loss: 44.67666019081334383145\n",
      "Iteration 43346 => Loss: 44.67650999957516688710\n",
      "Iteration 43347 => Loss: 44.67635980951569507624\n",
      "Iteration 43348 => Loss: 44.67620962063491418803\n",
      "Iteration 43349 => Loss: 44.67605943293280290618\n",
      "Iteration 43350 => Loss: 44.67590924640935412526\n",
      "Iteration 43351 => Loss: 44.67575906106456073985\n",
      "Iteration 43352 => Loss: 44.67560887689842274995\n",
      "Iteration 43353 => Loss: 44.67545869391091883926\n",
      "Iteration 43354 => Loss: 44.67530851210204900781\n",
      "Iteration 43355 => Loss: 44.67515833147177772844\n",
      "Iteration 43356 => Loss: 44.67500815202012631744\n",
      "Iteration 43357 => Loss: 44.67485797374708766938\n",
      "Iteration 43358 => Loss: 44.67470779665261915170\n",
      "Iteration 43359 => Loss: 44.67455762073676339696\n",
      "Iteration 43360 => Loss: 44.67440744599944935089\n",
      "Iteration 43361 => Loss: 44.67425727244070543520\n",
      "Iteration 43362 => Loss: 44.67410710006051743903\n",
      "Iteration 43363 => Loss: 44.67395692885889246782\n",
      "Iteration 43364 => Loss: 44.67380675883578788898\n",
      "Iteration 43365 => Loss: 44.67365658999118949168\n",
      "Iteration 43366 => Loss: 44.67350642232513280305\n",
      "Iteration 43367 => Loss: 44.67335625583758940138\n",
      "Iteration 43368 => Loss: 44.67320609052853086496\n",
      "Iteration 43369 => Loss: 44.67305592639796429921\n",
      "Iteration 43370 => Loss: 44.67290576344586838786\n",
      "Iteration 43371 => Loss: 44.67275560167225734176\n",
      "Iteration 43372 => Loss: 44.67260544107712405548\n",
      "Iteration 43373 => Loss: 44.67245528166040458018\n",
      "Iteration 43374 => Loss: 44.67230512342214865384\n",
      "Iteration 43375 => Loss: 44.67215496636232074934\n",
      "Iteration 43376 => Loss: 44.67200481048092797209\n",
      "Iteration 43377 => Loss: 44.67185465577794900582\n",
      "Iteration 43378 => Loss: 44.67170450225337674510\n",
      "Iteration 43379 => Loss: 44.67155434990719697907\n",
      "Iteration 43380 => Loss: 44.67140419873939549689\n",
      "Iteration 43381 => Loss: 44.67125404874997940396\n",
      "Iteration 43382 => Loss: 44.67110389993894870031\n",
      "Iteration 43383 => Loss: 44.67095375230625364793\n",
      "Iteration 43384 => Loss: 44.67080360585192977396\n",
      "Iteration 43385 => Loss: 44.67065346057592734041\n",
      "Iteration 43386 => Loss: 44.67050331647826766357\n",
      "Iteration 43387 => Loss: 44.67035317355893653257\n",
      "Iteration 43388 => Loss: 44.67020303181790552571\n",
      "Iteration 43389 => Loss: 44.67005289125519595927\n",
      "Iteration 43390 => Loss: 44.66990275187077941155\n",
      "Iteration 43391 => Loss: 44.66975261366462035539\n",
      "Iteration 43392 => Loss: 44.66960247663676142338\n",
      "Iteration 43393 => Loss: 44.66945234078718129922\n",
      "Iteration 43394 => Loss: 44.66930220611583735035\n",
      "Iteration 43395 => Loss: 44.66915207262275089306\n",
      "Iteration 43396 => Loss: 44.66900194030789350563\n",
      "Iteration 43397 => Loss: 44.66885180917130071521\n",
      "Iteration 43398 => Loss: 44.66870167921288725665\n",
      "Iteration 43399 => Loss: 44.66855155043271707882\n",
      "Iteration 43400 => Loss: 44.66840142283074044371\n",
      "Iteration 43401 => Loss: 44.66825129640695024591\n",
      "Iteration 43402 => Loss: 44.66810117116134648541\n",
      "Iteration 43403 => Loss: 44.66795104709392916220\n",
      "Iteration 43404 => Loss: 44.66780092420466274916\n",
      "Iteration 43405 => Loss: 44.66765080249356145714\n",
      "Iteration 43406 => Loss: 44.66750068196060396986\n",
      "Iteration 43407 => Loss: 44.66735056260577607645\n",
      "Iteration 43408 => Loss: 44.66720044442909198779\n",
      "Iteration 43409 => Loss: 44.66705032743051617672\n",
      "Iteration 43410 => Loss: 44.66690021161004864325\n",
      "Iteration 43411 => Loss: 44.66675009696769649281\n",
      "Iteration 43412 => Loss: 44.66659998350341709283\n",
      "Iteration 43413 => Loss: 44.66644987121723175960\n",
      "Iteration 43414 => Loss: 44.66629976010912628226\n",
      "Iteration 43415 => Loss: 44.66614965017907934453\n",
      "Iteration 43416 => Loss: 44.66599954142707673554\n",
      "Iteration 43417 => Loss: 44.66584943385314687703\n",
      "Iteration 43418 => Loss: 44.66569932745722582013\n",
      "Iteration 43419 => Loss: 44.66554922223933488112\n",
      "Iteration 43420 => Loss: 44.66539911819947406002\n",
      "Iteration 43421 => Loss: 44.66524901533762204053\n",
      "Iteration 43422 => Loss: 44.66509891365376461181\n",
      "Iteration 43423 => Loss: 44.66494881314788756299\n",
      "Iteration 43424 => Loss: 44.66479871381998378865\n",
      "Iteration 43425 => Loss: 44.66464861567008171050\n",
      "Iteration 43426 => Loss: 44.66449851869813159055\n",
      "Iteration 43427 => Loss: 44.66434842290413342880\n",
      "Iteration 43428 => Loss: 44.66419832828807301439\n",
      "Iteration 43429 => Loss: 44.66404823484994324190\n",
      "Iteration 43430 => Loss: 44.66389814258975121675\n",
      "Iteration 43431 => Loss: 44.66374805150746851723\n",
      "Iteration 43432 => Loss: 44.66359796160310935420\n",
      "Iteration 43433 => Loss: 44.66344787287663820052\n",
      "Iteration 43434 => Loss: 44.66329778532804795077\n",
      "Iteration 43435 => Loss: 44.66314769895733149951\n",
      "Iteration 43436 => Loss: 44.66299761376449595218\n",
      "Iteration 43437 => Loss: 44.66284752974951999249\n",
      "Iteration 43438 => Loss: 44.66269744691239651502\n",
      "Iteration 43439 => Loss: 44.66254736525310420348\n",
      "Iteration 43440 => Loss: 44.66239728477166437415\n",
      "Iteration 43441 => Loss: 44.66224720546802018362\n",
      "Iteration 43442 => Loss: 44.66209712734220005359\n",
      "Iteration 43443 => Loss: 44.66194705039421819492\n",
      "Iteration 43444 => Loss: 44.66179697462399644792\n",
      "Iteration 43445 => Loss: 44.66164690003154902342\n",
      "Iteration 43446 => Loss: 44.66149682661691144858\n",
      "Iteration 43447 => Loss: 44.66134675438004819625\n",
      "Iteration 43448 => Loss: 44.66119668332093795016\n",
      "Iteration 43449 => Loss: 44.66104661343953807773\n",
      "Iteration 43450 => Loss: 44.66089654473591252781\n",
      "Iteration 43451 => Loss: 44.66074647721003287870\n",
      "Iteration 43452 => Loss: 44.66059641086184228698\n",
      "Iteration 43453 => Loss: 44.66044634569138338520\n",
      "Iteration 43454 => Loss: 44.66029628169863485709\n",
      "Iteration 43455 => Loss: 44.66014621888356117552\n",
      "Iteration 43456 => Loss: 44.65999615724618365675\n",
      "Iteration 43457 => Loss: 44.65984609678647387909\n",
      "Iteration 43458 => Loss: 44.65969603750443894796\n",
      "Iteration 43459 => Loss: 44.65954597940005044165\n",
      "Iteration 43460 => Loss: 44.65939592247330836017\n",
      "Iteration 43461 => Loss: 44.65924586672422691436\n",
      "Iteration 43462 => Loss: 44.65909581215275636623\n",
      "Iteration 43463 => Loss: 44.65894575875892513750\n",
      "Iteration 43464 => Loss: 44.65879570654268349017\n",
      "Iteration 43465 => Loss: 44.65864565550404563510\n",
      "Iteration 43466 => Loss: 44.65849560564300446686\n",
      "Iteration 43467 => Loss: 44.65834555695954577459\n",
      "Iteration 43468 => Loss: 44.65819550945365534744\n",
      "Iteration 43469 => Loss: 44.65804546312536871255\n",
      "Iteration 43470 => Loss: 44.65789541797459349937\n",
      "Iteration 43471 => Loss: 44.65774537400137234044\n",
      "Iteration 43472 => Loss: 44.65759533120570523579\n",
      "Iteration 43473 => Loss: 44.65744528958757086912\n",
      "Iteration 43474 => Loss: 44.65729524914694081872\n",
      "Iteration 43475 => Loss: 44.65714520988380797917\n",
      "Iteration 43476 => Loss: 44.65699517179817945589\n",
      "Iteration 43477 => Loss: 44.65684513489006235432\n",
      "Iteration 43478 => Loss: 44.65669509915939272560\n",
      "Iteration 43479 => Loss: 44.65654506460624872943\n",
      "Iteration 43480 => Loss: 44.65639503123052378442\n",
      "Iteration 43481 => Loss: 44.65624499903226762854\n",
      "Iteration 43482 => Loss: 44.65609496801145184008\n",
      "Iteration 43483 => Loss: 44.65594493816806931363\n",
      "Iteration 43484 => Loss: 44.65579490950211294376\n",
      "Iteration 43485 => Loss: 44.65564488201358273045\n",
      "Iteration 43486 => Loss: 44.65549485570247156829\n",
      "Iteration 43487 => Loss: 44.65534483056873682472\n",
      "Iteration 43488 => Loss: 44.65519480661240692143\n",
      "Iteration 43489 => Loss: 44.65504478383343922587\n",
      "Iteration 43490 => Loss: 44.65489476223185505432\n",
      "Iteration 43491 => Loss: 44.65474474180761887965\n",
      "Iteration 43492 => Loss: 44.65459472256076622898\n",
      "Iteration 43493 => Loss: 44.65444470449121894262\n",
      "Iteration 43494 => Loss: 44.65429468759901965313\n",
      "Iteration 43495 => Loss: 44.65414467188416125509\n",
      "Iteration 43496 => Loss: 44.65399465734660111593\n",
      "Iteration 43497 => Loss: 44.65384464398634634108\n",
      "Iteration 43498 => Loss: 44.65369463180338982511\n",
      "Iteration 43499 => Loss: 44.65354462079772446259\n",
      "Iteration 43500 => Loss: 44.65339461096933604267\n",
      "Iteration 43501 => Loss: 44.65324460231822456535\n",
      "Iteration 43502 => Loss: 44.65309459484436871435\n",
      "Iteration 43503 => Loss: 44.65294458854776138423\n",
      "Iteration 43504 => Loss: 44.65279458342840257501\n",
      "Iteration 43505 => Loss: 44.65264457948627097039\n",
      "Iteration 43506 => Loss: 44.65249457672136657038\n",
      "Iteration 43507 => Loss: 44.65234457513364674242\n",
      "Iteration 43508 => Loss: 44.65219457472317543534\n",
      "Iteration 43509 => Loss: 44.65204457548986738402\n",
      "Iteration 43510 => Loss: 44.65189457743376522103\n",
      "Iteration 43511 => Loss: 44.65174458055481920837\n",
      "Iteration 43512 => Loss: 44.65159458485304355690\n",
      "Iteration 43513 => Loss: 44.65144459032845247748\n",
      "Iteration 43514 => Loss: 44.65129459698098912668\n",
      "Iteration 43515 => Loss: 44.65114460481066771536\n",
      "Iteration 43516 => Loss: 44.65099461381749534894\n",
      "Iteration 43517 => Loss: 44.65084462400141518401\n",
      "Iteration 43518 => Loss: 44.65069463536245564228\n",
      "Iteration 43519 => Loss: 44.65054464790060961832\n",
      "Iteration 43520 => Loss: 44.65039466161585579584\n",
      "Iteration 43521 => Loss: 44.65024467650819417486\n",
      "Iteration 43522 => Loss: 44.65009469257758212279\n",
      "Iteration 43523 => Loss: 44.64994470982406227222\n",
      "Iteration 43524 => Loss: 44.64979472824757777971\n",
      "Iteration 43525 => Loss: 44.64964474784812864527\n",
      "Iteration 43526 => Loss: 44.64949476862576460690\n",
      "Iteration 43527 => Loss: 44.64934479058040039945\n",
      "Iteration 43528 => Loss: 44.64919481371205733922\n",
      "Iteration 43529 => Loss: 44.64904483802073542620\n",
      "Iteration 43530 => Loss: 44.64889486350639913326\n",
      "Iteration 43531 => Loss: 44.64874489016906267125\n",
      "Iteration 43532 => Loss: 44.64859491800869761846\n",
      "Iteration 43533 => Loss: 44.64844494702532529118\n",
      "Iteration 43534 => Loss: 44.64829497721891016226\n",
      "Iteration 43535 => Loss: 44.64814500858943091544\n",
      "Iteration 43536 => Loss: 44.64799504113695149954\n",
      "Iteration 43537 => Loss: 44.64784507486135822774\n",
      "Iteration 43538 => Loss: 44.64769510976270794345\n",
      "Iteration 43539 => Loss: 44.64754514584097222496\n",
      "Iteration 43540 => Loss: 44.64739518309615817770\n",
      "Iteration 43541 => Loss: 44.64724522152824448540\n",
      "Iteration 43542 => Loss: 44.64709526113719562090\n",
      "Iteration 43543 => Loss: 44.64694530192303290050\n",
      "Iteration 43544 => Loss: 44.64679534388574921877\n",
      "Iteration 43545 => Loss: 44.64664538702535168113\n",
      "Iteration 43546 => Loss: 44.64649543134176923331\n",
      "Iteration 43547 => Loss: 44.64634547683507292959\n",
      "Iteration 43548 => Loss: 44.64619552350518461026\n",
      "Iteration 43549 => Loss: 44.64604557135212559160\n",
      "Iteration 43550 => Loss: 44.64589562037586745191\n",
      "Iteration 43551 => Loss: 44.64574567057643861290\n",
      "Iteration 43552 => Loss: 44.64559572195381065285\n",
      "Iteration 43553 => Loss: 44.64544577450795515006\n",
      "Iteration 43554 => Loss: 44.64529582823888631538\n",
      "Iteration 43555 => Loss: 44.64514588314658283252\n",
      "Iteration 43556 => Loss: 44.64499593923105891236\n",
      "Iteration 43557 => Loss: 44.64484599649227902773\n",
      "Iteration 43558 => Loss: 44.64469605493022896781\n",
      "Iteration 43559 => Loss: 44.64454611454491583800\n",
      "Iteration 43560 => Loss: 44.64439617533632542745\n",
      "Iteration 43561 => Loss: 44.64424623730446484160\n",
      "Iteration 43562 => Loss: 44.64409630044931276416\n",
      "Iteration 43563 => Loss: 44.64394636477084077342\n",
      "Iteration 43564 => Loss: 44.64379643026907018566\n",
      "Iteration 43565 => Loss: 44.64364649694395126289\n",
      "Iteration 43566 => Loss: 44.64349656479552663768\n",
      "Iteration 43567 => Loss: 44.64334663382374657203\n",
      "Iteration 43568 => Loss: 44.64319670402862527681\n",
      "Iteration 43569 => Loss: 44.64304677541014854114\n",
      "Iteration 43570 => Loss: 44.64289684796829504876\n",
      "Iteration 43571 => Loss: 44.64274692170307190509\n",
      "Iteration 43572 => Loss: 44.64259699661445779384\n",
      "Iteration 43573 => Loss: 44.64244707270245271502\n",
      "Iteration 43574 => Loss: 44.64229714996702824692\n",
      "Iteration 43575 => Loss: 44.64214722840821991667\n",
      "Iteration 43576 => Loss: 44.64199730802594956458\n",
      "Iteration 43577 => Loss: 44.64184738882026692863\n",
      "Iteration 43578 => Loss: 44.64169747079114358712\n",
      "Iteration 43579 => Loss: 44.64154755393856532919\n",
      "Iteration 43580 => Loss: 44.64139763826252504941\n",
      "Iteration 43581 => Loss: 44.64124772376302274779\n",
      "Iteration 43582 => Loss: 44.64109781044003710804\n",
      "Iteration 43583 => Loss: 44.64094789829357523558\n",
      "Iteration 43584 => Loss: 44.64079798732358028701\n",
      "Iteration 43585 => Loss: 44.64064807753010200031\n",
      "Iteration 43586 => Loss: 44.64049816891311905920\n",
      "Iteration 43587 => Loss: 44.64034826147259593654\n",
      "Iteration 43588 => Loss: 44.64019835520853263233\n",
      "Iteration 43589 => Loss: 44.64004845012095046286\n",
      "Iteration 43590 => Loss: 44.63989854620978547928\n",
      "Iteration 43591 => Loss: 44.63974864347506610329\n",
      "Iteration 43592 => Loss: 44.63959874191678522948\n",
      "Iteration 43593 => Loss: 44.63944884153493575241\n",
      "Iteration 43594 => Loss: 44.63929894232946082866\n",
      "Iteration 43595 => Loss: 44.63914904430041730166\n",
      "Iteration 43596 => Loss: 44.63899914744775543340\n",
      "Iteration 43597 => Loss: 44.63884925177148232933\n",
      "Iteration 43598 => Loss: 44.63869935727156956773\n",
      "Iteration 43599 => Loss: 44.63854946394803846488\n",
      "Iteration 43600 => Loss: 44.63839957180084638821\n",
      "Iteration 43601 => Loss: 44.63824968083000754859\n",
      "Iteration 43602 => Loss: 44.63809979103551484059\n",
      "Iteration 43603 => Loss: 44.63794990241733984249\n",
      "Iteration 43604 => Loss: 44.63780001497546834344\n",
      "Iteration 43605 => Loss: 44.63765012870992165972\n",
      "Iteration 43606 => Loss: 44.63750024362067136963\n",
      "Iteration 43607 => Loss: 44.63735035970772457858\n",
      "Iteration 43608 => Loss: 44.63720047697101733775\n",
      "Iteration 43609 => Loss: 44.63705059541062070139\n",
      "Iteration 43610 => Loss: 44.63690071502648493151\n",
      "Iteration 43611 => Loss: 44.63675083581858871185\n",
      "Iteration 43612 => Loss: 44.63660095778694625324\n",
      "Iteration 43613 => Loss: 44.63645108093152913398\n",
      "Iteration 43614 => Loss: 44.63630120525233735407\n",
      "Iteration 43615 => Loss: 44.63615133074937091351\n",
      "Iteration 43616 => Loss: 44.63600145742260139059\n",
      "Iteration 43617 => Loss: 44.63585158527203589074\n",
      "Iteration 43618 => Loss: 44.63570171429766020310\n",
      "Iteration 43619 => Loss: 44.63555184449947432768\n",
      "Iteration 43620 => Loss: 44.63540197587741431562\n",
      "Iteration 43621 => Loss: 44.63525210843157964291\n",
      "Iteration 43622 => Loss: 44.63510224216186372814\n",
      "Iteration 43623 => Loss: 44.63495237706827367674\n",
      "Iteration 43624 => Loss: 44.63480251315084501584\n",
      "Iteration 43625 => Loss: 44.63465265040952800746\n",
      "Iteration 43626 => Loss: 44.63450278884434396787\n",
      "Iteration 43627 => Loss: 44.63435292845523605365\n",
      "Iteration 43628 => Loss: 44.63420306924225400280\n",
      "Iteration 43629 => Loss: 44.63405321120533386647\n",
      "Iteration 43630 => Loss: 44.63390335434450406638\n",
      "Iteration 43631 => Loss: 44.63375349865974328623\n",
      "Iteration 43632 => Loss: 44.63360364415104442060\n",
      "Iteration 43633 => Loss: 44.63345379081837904778\n",
      "Iteration 43634 => Loss: 44.63330393866176848405\n",
      "Iteration 43635 => Loss: 44.63315408768121272942\n",
      "Iteration 43636 => Loss: 44.63300423787664072961\n",
      "Iteration 43637 => Loss: 44.63285438924810222261\n",
      "Iteration 43638 => Loss: 44.63270454179554036500\n",
      "Iteration 43639 => Loss: 44.63255469551902621106\n",
      "Iteration 43640 => Loss: 44.63240485041845317937\n",
      "Iteration 43641 => Loss: 44.63225500649386390251\n",
      "Iteration 43642 => Loss: 44.63210516374525127503\n",
      "Iteration 43643 => Loss: 44.63195532217260108609\n",
      "Iteration 43644 => Loss: 44.63180548177587780856\n",
      "Iteration 43645 => Loss: 44.63165564255512407499\n",
      "Iteration 43646 => Loss: 44.63150580451029014739\n",
      "Iteration 43647 => Loss: 44.63135596764135470949\n",
      "Iteration 43648 => Loss: 44.63120613194836039384\n",
      "Iteration 43649 => Loss: 44.63105629743125746245\n",
      "Iteration 43650 => Loss: 44.63090646409004591533\n",
      "Iteration 43651 => Loss: 44.63075663192471864704\n",
      "Iteration 43652 => Loss: 44.63060680093526144674\n",
      "Iteration 43653 => Loss: 44.63045697112168852527\n",
      "Iteration 43654 => Loss: 44.63030714248395014465\n",
      "Iteration 43655 => Loss: 44.63015731502207472658\n",
      "Iteration 43656 => Loss: 44.63000748873602674394\n",
      "Iteration 43657 => Loss: 44.62985766362580619671\n",
      "Iteration 43658 => Loss: 44.62970783969140597947\n",
      "Iteration 43659 => Loss: 44.62955801693281898679\n",
      "Iteration 43660 => Loss: 44.62940819535004521867\n",
      "Iteration 43661 => Loss: 44.62925837494305625341\n",
      "Iteration 43662 => Loss: 44.62910855571185209101\n",
      "Iteration 43663 => Loss: 44.62895873765641141517\n",
      "Iteration 43664 => Loss: 44.62880892077672001506\n",
      "Iteration 43665 => Loss: 44.62865910507281341779\n",
      "Iteration 43666 => Loss: 44.62850929054464188539\n",
      "Iteration 43667 => Loss: 44.62835947719219831242\n",
      "Iteration 43668 => Loss: 44.62820966501550401517\n",
      "Iteration 43669 => Loss: 44.62805985401452346650\n",
      "Iteration 43670 => Loss: 44.62791004418922824470\n",
      "Iteration 43671 => Loss: 44.62776023553966098234\n",
      "Iteration 43672 => Loss: 44.62761042806578615227\n",
      "Iteration 43673 => Loss: 44.62746062176755401651\n",
      "Iteration 43674 => Loss: 44.62731081664502141848\n",
      "Iteration 43675 => Loss: 44.62716101269815993646\n",
      "Iteration 43676 => Loss: 44.62701120992692693790\n",
      "Iteration 43677 => Loss: 44.62686140833135794992\n",
      "Iteration 43678 => Loss: 44.62671160791140323454\n",
      "Iteration 43679 => Loss: 44.62656180866708410804\n",
      "Iteration 43680 => Loss: 44.62641201059838635956\n",
      "Iteration 43681 => Loss: 44.62626221370530998911\n",
      "Iteration 43682 => Loss: 44.62611241798781946954\n",
      "Iteration 43683 => Loss: 44.62596262344590059001\n",
      "Iteration 43684 => Loss: 44.62581283007958887765\n",
      "Iteration 43685 => Loss: 44.62566303788882748904\n",
      "Iteration 43686 => Loss: 44.62551324687363063504\n",
      "Iteration 43687 => Loss: 44.62536345703398410478\n",
      "Iteration 43688 => Loss: 44.62521366836989500371\n",
      "Iteration 43689 => Loss: 44.62506388088132069925\n",
      "Iteration 43690 => Loss: 44.62491409456828961311\n",
      "Iteration 43691 => Loss: 44.62476430943075911273\n",
      "Iteration 43692 => Loss: 44.62461452546873630354\n",
      "Iteration 43693 => Loss: 44.62446474268220697468\n",
      "Iteration 43694 => Loss: 44.62431496107118533700\n",
      "Iteration 43695 => Loss: 44.62416518063562165253\n",
      "Iteration 43696 => Loss: 44.62401540137553723753\n",
      "Iteration 43697 => Loss: 44.62386562329091788115\n",
      "Iteration 43698 => Loss: 44.62371584638172805626\n",
      "Iteration 43699 => Loss: 44.62356607064798197371\n",
      "Iteration 43700 => Loss: 44.62341629608968673892\n",
      "Iteration 43701 => Loss: 44.62326652270680682477\n",
      "Iteration 43702 => Loss: 44.62311675049933512582\n",
      "Iteration 43703 => Loss: 44.62296697946727164208\n",
      "Iteration 43704 => Loss: 44.62281720961058795183\n",
      "Iteration 43705 => Loss: 44.62266744092933379306\n",
      "Iteration 43706 => Loss: 44.62251767342340968980\n",
      "Iteration 43707 => Loss: 44.62236790709287959089\n",
      "Iteration 43708 => Loss: 44.62221814193770086376\n",
      "Iteration 43709 => Loss: 44.62206837795785219214\n",
      "Iteration 43710 => Loss: 44.62191861515336910315\n",
      "Iteration 43711 => Loss: 44.62176885352421606967\n",
      "Iteration 43712 => Loss: 44.62161909307037177541\n",
      "Iteration 43713 => Loss: 44.62146933379184332580\n",
      "Iteration 43714 => Loss: 44.62131957568863072083\n",
      "Iteration 43715 => Loss: 44.62116981876068422253\n",
      "Iteration 43716 => Loss: 44.62102006300803225258\n",
      "Iteration 43717 => Loss: 44.62087030843068191643\n",
      "Iteration 43718 => Loss: 44.62072055502856215981\n",
      "Iteration 43719 => Loss: 44.62057080280170850983\n",
      "Iteration 43720 => Loss: 44.62042105175011386109\n",
      "Iteration 43721 => Loss: 44.62027130187375689729\n",
      "Iteration 43722 => Loss: 44.62012155317261630216\n",
      "Iteration 43723 => Loss: 44.61997180564670628655\n",
      "Iteration 43724 => Loss: 44.61982205929601974503\n",
      "Iteration 43725 => Loss: 44.61967231412049272876\n",
      "Iteration 43726 => Loss: 44.61952257012018208115\n",
      "Iteration 43727 => Loss: 44.61937282729506648593\n",
      "Iteration 43728 => Loss: 44.61922308564511041595\n",
      "Iteration 43729 => Loss: 44.61907334517030676579\n",
      "Iteration 43730 => Loss: 44.61892360587069106259\n",
      "Iteration 43731 => Loss: 44.61877386774620646293\n",
      "Iteration 43732 => Loss: 44.61862413079684586137\n",
      "Iteration 43733 => Loss: 44.61847439502263767963\n",
      "Iteration 43734 => Loss: 44.61832466042354639058\n",
      "Iteration 43735 => Loss: 44.61817492699955067792\n",
      "Iteration 43736 => Loss: 44.61802519475065764709\n",
      "Iteration 43737 => Loss: 44.61787546367683177095\n",
      "Iteration 43738 => Loss: 44.61772573377811568207\n",
      "Iteration 43739 => Loss: 44.61757600505448095873\n",
      "Iteration 43740 => Loss: 44.61742627750589207380\n",
      "Iteration 43741 => Loss: 44.61727655113235613271\n",
      "Iteration 43742 => Loss: 44.61712682593387313545\n",
      "Iteration 43743 => Loss: 44.61697710191042176575\n",
      "Iteration 43744 => Loss: 44.61682737906199491817\n",
      "Iteration 43745 => Loss: 44.61667765738857127644\n",
      "Iteration 43746 => Loss: 44.61652793689017926226\n",
      "Iteration 43747 => Loss: 44.61637821756679045393\n",
      "Iteration 43748 => Loss: 44.61622849941836932430\n",
      "Iteration 43749 => Loss: 44.61607878244493718967\n",
      "Iteration 43750 => Loss: 44.61592906664647273374\n",
      "Iteration 43751 => Loss: 44.61577935202296885109\n",
      "Iteration 43752 => Loss: 44.61562963857442554172\n",
      "Iteration 43753 => Loss: 44.61547992630082859478\n",
      "Iteration 43754 => Loss: 44.61533021520215669398\n",
      "Iteration 43755 => Loss: 44.61518050527839562847\n",
      "Iteration 43756 => Loss: 44.61503079652956671453\n",
      "Iteration 43757 => Loss: 44.61488108895566284673\n",
      "Iteration 43758 => Loss: 44.61473138255663428708\n",
      "Iteration 43759 => Loss: 44.61458167733249524645\n",
      "Iteration 43760 => Loss: 44.61443197328322440853\n",
      "Iteration 43761 => Loss: 44.61428227040885019505\n",
      "Iteration 43762 => Loss: 44.61413256870930865716\n",
      "Iteration 43763 => Loss: 44.61398286818463532200\n",
      "Iteration 43764 => Loss: 44.61383316883479466242\n",
      "Iteration 43765 => Loss: 44.61368347065979378385\n",
      "Iteration 43766 => Loss: 44.61353377365960426459\n",
      "Iteration 43767 => Loss: 44.61338407783423321007\n",
      "Iteration 43768 => Loss: 44.61323438318365930400\n",
      "Iteration 43769 => Loss: 44.61308468970791807351\n",
      "Iteration 43770 => Loss: 44.61293499740693846434\n",
      "Iteration 43771 => Loss: 44.61278530628073468733\n",
      "Iteration 43772 => Loss: 44.61263561632929963707\n",
      "Iteration 43773 => Loss: 44.61248592755261910270\n",
      "Iteration 43774 => Loss: 44.61233623995069308421\n",
      "Iteration 43775 => Loss: 44.61218655352351447618\n",
      "Iteration 43776 => Loss: 44.61203686827104064605\n",
      "Iteration 43777 => Loss: 44.61188718419331422638\n",
      "Iteration 43778 => Loss: 44.61173750129032100631\n",
      "Iteration 43779 => Loss: 44.61158781956198993157\n",
      "Iteration 43780 => Loss: 44.61143813900837074016\n",
      "Iteration 43781 => Loss: 44.61128845962942790493\n",
      "Iteration 43782 => Loss: 44.61113878142517563674\n",
      "Iteration 43783 => Loss: 44.61098910439557130303\n",
      "Iteration 43784 => Loss: 44.61083942854063622008\n",
      "Iteration 43785 => Loss: 44.61068975386034907160\n",
      "Iteration 43786 => Loss: 44.61054008035470985760\n",
      "Iteration 43787 => Loss: 44.61039040802367594551\n",
      "Iteration 43788 => Loss: 44.61024073686728286248\n",
      "Iteration 43789 => Loss: 44.61009106688550218678\n",
      "Iteration 43790 => Loss: 44.60994139807831260214\n",
      "Iteration 43791 => Loss: 44.60979173044570700313\n",
      "Iteration 43792 => Loss: 44.60964206398772091688\n",
      "Iteration 43793 => Loss: 44.60949239870426197285\n",
      "Iteration 43794 => Loss: 44.60934273459540833073\n",
      "Iteration 43795 => Loss: 44.60919307166110314711\n",
      "Iteration 43796 => Loss: 44.60904340990133221112\n",
      "Iteration 43797 => Loss: 44.60889374931608841734\n",
      "Iteration 43798 => Loss: 44.60874408990539308206\n",
      "Iteration 43799 => Loss: 44.60859443166922488899\n",
      "Iteration 43800 => Loss: 44.60844477460754831100\n",
      "Iteration 43801 => Loss: 44.60829511872038466436\n",
      "Iteration 43802 => Loss: 44.60814546400769131651\n",
      "Iteration 43803 => Loss: 44.60799581046950379459\n",
      "Iteration 43804 => Loss: 44.60784615810577236061\n",
      "Iteration 43805 => Loss: 44.60769650691651833085\n",
      "Iteration 43806 => Loss: 44.60754685690171328361\n",
      "Iteration 43807 => Loss: 44.60739720806135011344\n",
      "Iteration 43808 => Loss: 44.60724756039542882036\n",
      "Iteration 43809 => Loss: 44.60709791390392808808\n",
      "Iteration 43810 => Loss: 44.60694826858685502202\n",
      "Iteration 43811 => Loss: 44.60679862444418830592\n",
      "Iteration 43812 => Loss: 44.60664898147591372890\n",
      "Iteration 43813 => Loss: 44.60649933968203839640\n",
      "Iteration 43814 => Loss: 44.60634969906254099214\n",
      "Iteration 43815 => Loss: 44.60620005961740730527\n",
      "Iteration 43816 => Loss: 44.60605042134663733577\n",
      "Iteration 43817 => Loss: 44.60590078425023818909\n",
      "Iteration 43818 => Loss: 44.60575114832816723265\n",
      "Iteration 43819 => Loss: 44.60560151358044578274\n",
      "Iteration 43820 => Loss: 44.60545188000702410136\n",
      "Iteration 43821 => Loss: 44.60530224760793061023\n",
      "Iteration 43822 => Loss: 44.60515261638315109849\n",
      "Iteration 43823 => Loss: 44.60500298633266424986\n",
      "Iteration 43824 => Loss: 44.60485335745646295891\n",
      "Iteration 43825 => Loss: 44.60470372975453301478\n",
      "Iteration 43826 => Loss: 44.60455410322690283920\n",
      "Iteration 43827 => Loss: 44.60440447787350848330\n",
      "Iteration 43828 => Loss: 44.60425485369436415795\n",
      "Iteration 43829 => Loss: 44.60410523068946986314\n",
      "Iteration 43830 => Loss: 44.60395560885883980973\n",
      "Iteration 43831 => Loss: 44.60380598820240294344\n",
      "Iteration 43832 => Loss: 44.60365636872018058057\n",
      "Iteration 43833 => Loss: 44.60350675041215851024\n",
      "Iteration 43834 => Loss: 44.60335713327833673247\n",
      "Iteration 43835 => Loss: 44.60320751731870814183\n",
      "Iteration 43836 => Loss: 44.60305790253327273831\n",
      "Iteration 43837 => Loss: 44.60290828892198788935\n",
      "Iteration 43838 => Loss: 44.60275867648485359496\n",
      "Iteration 43839 => Loss: 44.60260906522188406598\n",
      "Iteration 43840 => Loss: 44.60245945513305088070\n",
      "Iteration 43841 => Loss: 44.60230984621836114457\n",
      "Iteration 43842 => Loss: 44.60216023847779354128\n",
      "Iteration 43843 => Loss: 44.60201063191134096542\n",
      "Iteration 43844 => Loss: 44.60186102651896078441\n",
      "Iteration 43845 => Loss: 44.60171142230071694712\n",
      "Iteration 43846 => Loss: 44.60156181925651708298\n",
      "Iteration 43847 => Loss: 44.60141221738641803540\n",
      "Iteration 43848 => Loss: 44.60126261669039848812\n",
      "Iteration 43849 => Loss: 44.60111301716844423026\n",
      "Iteration 43850 => Loss: 44.60096341882050552385\n",
      "Iteration 43851 => Loss: 44.60081382164661079059\n",
      "Iteration 43852 => Loss: 44.60066422564676003049\n",
      "Iteration 43853 => Loss: 44.60051463082091771639\n",
      "Iteration 43854 => Loss: 44.60036503716909805917\n",
      "Iteration 43855 => Loss: 44.60021544469128684796\n",
      "Iteration 43856 => Loss: 44.60006585338745566105\n",
      "Iteration 43857 => Loss: 44.59991626325762581473\n",
      "Iteration 43858 => Loss: 44.59976667430176178186\n",
      "Iteration 43859 => Loss: 44.59961708651988487873\n",
      "Iteration 43860 => Loss: 44.59946749991192405105\n",
      "Iteration 43861 => Loss: 44.59931791447795745853\n",
      "Iteration 43862 => Loss: 44.59916833021787851976\n",
      "Iteration 43863 => Loss: 44.59901874713177249987\n",
      "Iteration 43864 => Loss: 44.59886916521956123916\n",
      "Iteration 43865 => Loss: 44.59871958448125894847\n",
      "Iteration 43866 => Loss: 44.59857000491686562782\n",
      "Iteration 43867 => Loss: 44.59842042652638838263\n",
      "Iteration 43868 => Loss: 44.59827084930976326405\n",
      "Iteration 43869 => Loss: 44.59812127326701158836\n",
      "Iteration 43870 => Loss: 44.59797169839814756642\n",
      "Iteration 43871 => Loss: 44.59782212470313567110\n",
      "Iteration 43872 => Loss: 44.59767255218195458610\n",
      "Iteration 43873 => Loss: 44.59752298083461141687\n",
      "Iteration 43874 => Loss: 44.59737341066110616339\n",
      "Iteration 43875 => Loss: 44.59722384166141750939\n",
      "Iteration 43876 => Loss: 44.59707427383554545486\n",
      "Iteration 43877 => Loss: 44.59692470718346157810\n",
      "Iteration 43878 => Loss: 44.59677514170516587910\n",
      "Iteration 43879 => Loss: 44.59662557740066546330\n",
      "Iteration 43880 => Loss: 44.59647601426993190898\n",
      "Iteration 43881 => Loss: 44.59632645231296521615\n",
      "Iteration 43882 => Loss: 44.59617689152975117395\n",
      "Iteration 43883 => Loss: 44.59602733192026846609\n",
      "Iteration 43884 => Loss: 44.59587777348453840887\n",
      "Iteration 43885 => Loss: 44.59572821622253968599\n",
      "Iteration 43886 => Loss: 44.59557866013422966489\n",
      "Iteration 43887 => Loss: 44.59542910521967939985\n",
      "Iteration 43888 => Loss: 44.59527955147878230946\n",
      "Iteration 43889 => Loss: 44.59512999891160234256\n",
      "Iteration 43890 => Loss: 44.59498044751808976116\n",
      "Iteration 43891 => Loss: 44.59483089729824456526\n",
      "Iteration 43892 => Loss: 44.59468134825206675487\n",
      "Iteration 43893 => Loss: 44.59453180037954922454\n",
      "Iteration 43894 => Loss: 44.59438225368064223630\n",
      "Iteration 43895 => Loss: 44.59423270815541684442\n",
      "Iteration 43896 => Loss: 44.59408316380377357291\n",
      "Iteration 43897 => Loss: 44.59393362062576215976\n",
      "Iteration 43898 => Loss: 44.59378407862138260498\n",
      "Iteration 43899 => Loss: 44.59363453779057806514\n",
      "Iteration 43900 => Loss: 44.59348499813337696196\n",
      "Iteration 43901 => Loss: 44.59333545964972955744\n",
      "Iteration 43902 => Loss: 44.59318592233967137872\n",
      "Iteration 43903 => Loss: 44.59303638620317400409\n",
      "Iteration 43904 => Loss: 44.59288685124021611728\n",
      "Iteration 43905 => Loss: 44.59273731745082613998\n",
      "Iteration 43906 => Loss: 44.59258778483492591249\n",
      "Iteration 43907 => Loss: 44.59243825339257938367\n",
      "Iteration 43908 => Loss: 44.59228872312375102638\n",
      "Iteration 43909 => Loss: 44.59213919402842662976\n",
      "Iteration 43910 => Loss: 44.59198966610658487753\n",
      "Iteration 43911 => Loss: 44.59184013935825419139\n",
      "Iteration 43912 => Loss: 44.59169061378337062251\n",
      "Iteration 43913 => Loss: 44.59154108938197680345\n",
      "Iteration 43914 => Loss: 44.59139156615404431250\n",
      "Iteration 43915 => Loss: 44.59124204409953762251\n",
      "Iteration 43916 => Loss: 44.59109252321850647149\n",
      "Iteration 43917 => Loss: 44.59094300351087980516\n",
      "Iteration 43918 => Loss: 44.59079348497669315066\n",
      "Iteration 43919 => Loss: 44.59064396761591098084\n",
      "Iteration 43920 => Loss: 44.59049445142854750657\n",
      "Iteration 43921 => Loss: 44.59034493641454588442\n",
      "Iteration 43922 => Loss: 44.59019542257398427409\n",
      "Iteration 43923 => Loss: 44.59004590990674898876\n",
      "Iteration 43924 => Loss: 44.58989639841289687183\n",
      "Iteration 43925 => Loss: 44.58974688809241371246\n",
      "Iteration 43926 => Loss: 44.58959737894527108892\n",
      "Iteration 43927 => Loss: 44.58944787097145479038\n",
      "Iteration 43928 => Loss: 44.58929836417098613310\n",
      "Iteration 43929 => Loss: 44.58914885854384380082\n",
      "Iteration 43930 => Loss: 44.58899935408999226638\n",
      "Iteration 43931 => Loss: 44.58884985080948126779\n",
      "Iteration 43932 => Loss: 44.58870034870222553991\n",
      "Iteration 43933 => Loss: 44.58855084776826771531\n",
      "Iteration 43934 => Loss: 44.58840134800758647771\n",
      "Iteration 43935 => Loss: 44.58825184942018893253\n",
      "Iteration 43936 => Loss: 44.58810235200602534178\n",
      "Iteration 43937 => Loss: 44.58795285576510991632\n",
      "Iteration 43938 => Loss: 44.58780336069743555072\n",
      "Iteration 43939 => Loss: 44.58765386680300935041\n",
      "Iteration 43940 => Loss: 44.58750437408176736653\n",
      "Iteration 43941 => Loss: 44.58735488253376644252\n",
      "Iteration 43942 => Loss: 44.58720539215895684038\n",
      "Iteration 43943 => Loss: 44.58705590295734566553\n",
      "Iteration 43944 => Loss: 44.58690641492890449626\n",
      "Iteration 43945 => Loss: 44.58675692807365464887\n",
      "Iteration 43946 => Loss: 44.58660744239156059621\n",
      "Iteration 43947 => Loss: 44.58645795788262233827\n",
      "Iteration 43948 => Loss: 44.58630847454683987507\n",
      "Iteration 43949 => Loss: 44.58615899238417057404\n",
      "Iteration 43950 => Loss: 44.58600951139465706774\n",
      "Iteration 43951 => Loss: 44.58586003157824961818\n",
      "Iteration 43952 => Loss: 44.58571055293494822536\n",
      "Iteration 43953 => Loss: 44.58556107546475288927\n",
      "Iteration 43954 => Loss: 44.58541159916764229365\n",
      "Iteration 43955 => Loss: 44.58526212404363064934\n",
      "Iteration 43956 => Loss: 44.58511265009267532378\n",
      "Iteration 43957 => Loss: 44.58496317731477631696\n",
      "Iteration 43958 => Loss: 44.58481370570996915603\n",
      "Iteration 43959 => Loss: 44.58466423527816147043\n",
      "Iteration 43960 => Loss: 44.58451476601942431444\n",
      "Iteration 43961 => Loss: 44.58436529793369373920\n",
      "Iteration 43962 => Loss: 44.58421583102099106100\n",
      "Iteration 43963 => Loss: 44.58406636528128075270\n",
      "Iteration 43964 => Loss: 44.58391690071457702516\n",
      "Iteration 43965 => Loss: 44.58376743732087987837\n",
      "Iteration 43966 => Loss: 44.58361797510014667978\n",
      "Iteration 43967 => Loss: 44.58346851405238453481\n",
      "Iteration 43968 => Loss: 44.58331905417760765431\n",
      "Iteration 43969 => Loss: 44.58316959547575919487\n",
      "Iteration 43970 => Loss: 44.58302013794686047277\n",
      "Iteration 43971 => Loss: 44.58287068159089727715\n",
      "Iteration 43972 => Loss: 44.58272122640786250258\n",
      "Iteration 43973 => Loss: 44.58257177239774904365\n",
      "Iteration 43974 => Loss: 44.58242231956053558406\n",
      "Iteration 43975 => Loss: 44.58227286789622212382\n",
      "Iteration 43976 => Loss: 44.58212341740480155750\n",
      "Iteration 43977 => Loss: 44.58197396808623835796\n",
      "Iteration 43978 => Loss: 44.58182451994058936862\n",
      "Iteration 43979 => Loss: 44.58167507296776221892\n",
      "Iteration 43980 => Loss: 44.58152562716780664687\n",
      "Iteration 43981 => Loss: 44.58137618254067291446\n",
      "Iteration 43982 => Loss: 44.58122673908639654883\n",
      "Iteration 43983 => Loss: 44.58107729680493491742\n",
      "Iteration 43984 => Loss: 44.58092785569628091480\n",
      "Iteration 43985 => Loss: 44.58077841576045585725\n",
      "Iteration 43986 => Loss: 44.58062897699741000679\n",
      "Iteration 43987 => Loss: 44.58047953940714336341\n",
      "Iteration 43988 => Loss: 44.58033010298966303253\n",
      "Iteration 43989 => Loss: 44.58018066774495480331\n",
      "Iteration 43990 => Loss: 44.58003123367301157032\n",
      "Iteration 43991 => Loss: 44.57988180077380491184\n",
      "Iteration 43992 => Loss: 44.57973236904734903874\n",
      "Iteration 43993 => Loss: 44.57958293849363684558\n",
      "Iteration 43994 => Loss: 44.57943350911263991065\n",
      "Iteration 43995 => Loss: 44.57928408090432270683\n",
      "Iteration 43996 => Loss: 44.57913465386876339380\n",
      "Iteration 43997 => Loss: 44.57898522800586960102\n",
      "Iteration 43998 => Loss: 44.57883580331567685562\n",
      "Iteration 43999 => Loss: 44.57868637979814252503\n",
      "Iteration 44000 => Loss: 44.57853695745328792555\n",
      "Iteration 44001 => Loss: 44.57838753628109174088\n",
      "Iteration 44002 => Loss: 44.57823811628153976017\n",
      "Iteration 44003 => Loss: 44.57808869745462487799\n",
      "Iteration 44004 => Loss: 44.57793927980034709435\n",
      "Iteration 44005 => Loss: 44.57778986331870640925\n",
      "Iteration 44006 => Loss: 44.57764044800966019011\n",
      "Iteration 44007 => Loss: 44.57749103387323685865\n",
      "Iteration 44008 => Loss: 44.57734162090937246603\n",
      "Iteration 44009 => Loss: 44.57719220911812385566\n",
      "Iteration 44010 => Loss: 44.57704279849943418412\n",
      "Iteration 44011 => Loss: 44.57689338905332476770\n",
      "Iteration 44012 => Loss: 44.57674398077976007926\n",
      "Iteration 44013 => Loss: 44.57659457367875432965\n",
      "Iteration 44014 => Loss: 44.57644516775029330802\n",
      "Iteration 44015 => Loss: 44.57629576299434148723\n",
      "Iteration 44016 => Loss: 44.57614635941092018356\n",
      "Iteration 44017 => Loss: 44.57599695700001518617\n",
      "Iteration 44018 => Loss: 44.57584755576160517876\n",
      "Iteration 44019 => Loss: 44.57569815569569016134\n",
      "Iteration 44020 => Loss: 44.57554875680225592305\n",
      "Iteration 44021 => Loss: 44.57539935908129535846\n",
      "Iteration 44022 => Loss: 44.57524996253281557301\n",
      "Iteration 44023 => Loss: 44.57510056715677393413\n",
      "Iteration 44024 => Loss: 44.57495117295319175810\n",
      "Iteration 44025 => Loss: 44.57480177992204062321\n",
      "Iteration 44026 => Loss: 44.57465238806332763488\n",
      "Iteration 44027 => Loss: 44.57450299737700305513\n",
      "Iteration 44028 => Loss: 44.57435360786313083281\n",
      "Iteration 44029 => Loss: 44.57420421952162570278\n",
      "Iteration 44030 => Loss: 44.57405483235253029761\n",
      "Iteration 44031 => Loss: 44.57390544635581619559\n",
      "Iteration 44032 => Loss: 44.57375606153148339672\n",
      "Iteration 44033 => Loss: 44.57360667787949637386\n",
      "Iteration 44034 => Loss: 44.57345729539987644330\n",
      "Iteration 44035 => Loss: 44.57330791409260228875\n",
      "Iteration 44036 => Loss: 44.57315853395765969935\n",
      "Iteration 44037 => Loss: 44.57300915499506288597\n",
      "Iteration 44038 => Loss: 44.57285977720474789976\n",
      "Iteration 44039 => Loss: 44.57271040058676447870\n",
      "Iteration 44040 => Loss: 44.57256102514107709567\n",
      "Iteration 44041 => Loss: 44.57241165086769285608\n",
      "Iteration 44042 => Loss: 44.57226227776658333823\n",
      "Iteration 44043 => Loss: 44.57211290583773433127\n",
      "Iteration 44044 => Loss: 44.57196353508115294062\n",
      "Iteration 44045 => Loss: 44.57181416549682495543\n",
      "Iteration 44046 => Loss: 44.57166479708474327026\n",
      "Iteration 44047 => Loss: 44.57151542984489367427\n",
      "Iteration 44048 => Loss: 44.57136606377728327288\n",
      "Iteration 44049 => Loss: 44.57121669888188364439\n",
      "Iteration 44050 => Loss: 44.57106733515869478879\n",
      "Iteration 44051 => Loss: 44.57091797260768828437\n",
      "Iteration 44052 => Loss: 44.57076861122889255284\n",
      "Iteration 44053 => Loss: 44.57061925102225785622\n",
      "Iteration 44054 => Loss: 44.57046989198779840535\n",
      "Iteration 44055 => Loss: 44.57032053412551420024\n",
      "Iteration 44056 => Loss: 44.57017117743538392460\n",
      "Iteration 44057 => Loss: 44.57002182191737915673\n",
      "Iteration 44058 => Loss: 44.56987246757149989662\n",
      "Iteration 44059 => Loss: 44.56972311439778167141\n",
      "Iteration 44060 => Loss: 44.56957376239615342683\n",
      "Iteration 44061 => Loss: 44.56942441156663647917\n",
      "Iteration 44062 => Loss: 44.56927506190921661755\n",
      "Iteration 44063 => Loss: 44.56912571342388673656\n",
      "Iteration 44064 => Loss: 44.56897636611065394163\n",
      "Iteration 44065 => Loss: 44.56882701996948270562\n",
      "Iteration 44066 => Loss: 44.56867767500035171224\n",
      "Iteration 44067 => Loss: 44.56852833120328227778\n",
      "Iteration 44068 => Loss: 44.56837898857825308596\n",
      "Iteration 44069 => Loss: 44.56822964712527834763\n",
      "Iteration 44070 => Loss: 44.56808030684429411394\n",
      "Iteration 44071 => Loss: 44.56793096773534301747\n",
      "Iteration 44072 => Loss: 44.56778162979839663649\n",
      "Iteration 44073 => Loss: 44.56763229303344076015\n",
      "Iteration 44074 => Loss: 44.56748295744047538847\n",
      "Iteration 44075 => Loss: 44.56733362301947209971\n",
      "Iteration 44076 => Loss: 44.56718428977047352646\n",
      "Iteration 44077 => Loss: 44.56703495769341571986\n",
      "Iteration 44078 => Loss: 44.56688562678830578534\n",
      "Iteration 44079 => Loss: 44.56673629705513661747\n",
      "Iteration 44080 => Loss: 44.56658696849390111083\n",
      "Iteration 44081 => Loss: 44.56643764110459926542\n",
      "Iteration 44082 => Loss: 44.56628831488718844867\n",
      "Iteration 44083 => Loss: 44.56613898984167576600\n",
      "Iteration 44084 => Loss: 44.56598966596808963914\n",
      "Iteration 44085 => Loss: 44.56584034326637322465\n",
      "Iteration 44086 => Loss: 44.56569102173653362797\n",
      "Iteration 44087 => Loss: 44.56554170137854953282\n",
      "Iteration 44088 => Loss: 44.56539238219244936090\n",
      "Iteration 44089 => Loss: 44.56524306417817626880\n",
      "Iteration 44090 => Loss: 44.56509374733577288907\n",
      "Iteration 44091 => Loss: 44.56494443166517527288\n",
      "Iteration 44092 => Loss: 44.56479511716641184194\n",
      "Iteration 44093 => Loss: 44.56464580383943996367\n",
      "Iteration 44094 => Loss: 44.56449649168428095436\n",
      "Iteration 44095 => Loss: 44.56434718070092060316\n",
      "Iteration 44096 => Loss: 44.56419787088934469921\n",
      "Iteration 44097 => Loss: 44.56404856224953903165\n",
      "Iteration 44098 => Loss: 44.56389925478150360050\n",
      "Iteration 44099 => Loss: 44.56374994848525261659\n",
      "Iteration 44100 => Loss: 44.56360064336070081481\n",
      "Iteration 44101 => Loss: 44.56345133940791214400\n",
      "Iteration 44102 => Loss: 44.56330203662684397159\n",
      "Iteration 44103 => Loss: 44.56315273501751050844\n",
      "Iteration 44104 => Loss: 44.56300343457988333284\n",
      "Iteration 44105 => Loss: 44.56285413531395533937\n",
      "Iteration 44106 => Loss: 44.56270483721971231716\n",
      "Iteration 44107 => Loss: 44.56255554029717558251\n",
      "Iteration 44108 => Loss: 44.56240624454628829199\n",
      "Iteration 44109 => Loss: 44.56225694996706465645\n",
      "Iteration 44110 => Loss: 44.56210765655953309761\n",
      "Iteration 44111 => Loss: 44.56195836432360835033\n",
      "Iteration 44112 => Loss: 44.56180907325933304719\n",
      "Iteration 44113 => Loss: 44.56165978336670008275\n",
      "Iteration 44114 => Loss: 44.56151049464565971903\n",
      "Iteration 44115 => Loss: 44.56136120709625458858\n",
      "Iteration 44116 => Loss: 44.56121192071844205884\n",
      "Iteration 44117 => Loss: 44.56106263551222212982\n",
      "Iteration 44118 => Loss: 44.56091335147759480151\n",
      "Iteration 44119 => Loss: 44.56076406861451033592\n",
      "Iteration 44120 => Loss: 44.56061478692302557647\n",
      "Iteration 44121 => Loss: 44.56046550640308367974\n",
      "Iteration 44122 => Loss: 44.56031622705467754031\n",
      "Iteration 44123 => Loss: 44.56016694887780005274\n",
      "Iteration 44124 => Loss: 44.56001767187245832247\n",
      "Iteration 44125 => Loss: 44.55986839603865234949\n",
      "Iteration 44126 => Loss: 44.55971912137633239581\n",
      "Iteration 44127 => Loss: 44.55956984788552688315\n",
      "Iteration 44128 => Loss: 44.55942057556621449521\n",
      "Iteration 44129 => Loss: 44.55927130441835970487\n",
      "Iteration 44130 => Loss: 44.55912203444199093383\n",
      "Iteration 44131 => Loss: 44.55897276563710107666\n",
      "Iteration 44132 => Loss: 44.55882349800364750081\n",
      "Iteration 44133 => Loss: 44.55867423154164441712\n",
      "Iteration 44134 => Loss: 44.55852496625107050932\n",
      "Iteration 44135 => Loss: 44.55837570213191156654\n",
      "Iteration 44136 => Loss: 44.55822643918418890507\n",
      "Iteration 44137 => Loss: 44.55807717740785989236\n",
      "Iteration 44138 => Loss: 44.55792791680296716095\n",
      "Iteration 44139 => Loss: 44.55777865736941834029\n",
      "Iteration 44140 => Loss: 44.55762939910728448467\n",
      "Iteration 44141 => Loss: 44.55748014201649453980\n",
      "Iteration 44142 => Loss: 44.55733088609705561112\n",
      "Iteration 44143 => Loss: 44.55718163134898901490\n",
      "Iteration 44144 => Loss: 44.55703237777227343486\n",
      "Iteration 44145 => Loss: 44.55688312536689466015\n",
      "Iteration 44146 => Loss: 44.55673387413281716363\n",
      "Iteration 44147 => Loss: 44.55658462407007647244\n",
      "Iteration 44148 => Loss: 44.55643537517864416486\n",
      "Iteration 44149 => Loss: 44.55628612745848471377\n",
      "Iteration 44150 => Loss: 44.55613688090964075172\n",
      "Iteration 44151 => Loss: 44.55598763553206964616\n",
      "Iteration 44152 => Loss: 44.55583839132575718622\n",
      "Iteration 44153 => Loss: 44.55568914829071047734\n",
      "Iteration 44154 => Loss: 44.55553990642691530866\n",
      "Iteration 44155 => Loss: 44.55539066573435036389\n",
      "Iteration 44156 => Loss: 44.55524142621305117018\n",
      "Iteration 44157 => Loss: 44.55509218786293246239\n",
      "Iteration 44158 => Loss: 44.55494295068407240024\n",
      "Iteration 44159 => Loss: 44.55479371467639282400\n",
      "Iteration 44160 => Loss: 44.55464447983990083912\n",
      "Iteration 44161 => Loss: 44.55449524617461065645\n",
      "Iteration 44162 => Loss: 44.55434601368050095971\n",
      "Iteration 44163 => Loss: 44.55419678235755043261\n",
      "Iteration 44164 => Loss: 44.55404755220577328600\n",
      "Iteration 44165 => Loss: 44.55389832322513399276\n",
      "Iteration 44166 => Loss: 44.55374909541563965831\n",
      "Iteration 44167 => Loss: 44.55359986877729028265\n",
      "Iteration 44168 => Loss: 44.55345064331004323321\n",
      "Iteration 44169 => Loss: 44.55330141901391272086\n",
      "Iteration 44170 => Loss: 44.55315219588889874558\n",
      "Iteration 44171 => Loss: 44.55300297393496578024\n",
      "Iteration 44172 => Loss: 44.55285375315214224656\n",
      "Iteration 44173 => Loss: 44.55270453354036419569\n",
      "Iteration 44174 => Loss: 44.55255531509966715475\n",
      "Iteration 44175 => Loss: 44.55240609783004401834\n",
      "Iteration 44176 => Loss: 44.55225688173143794302\n",
      "Iteration 44177 => Loss: 44.55210766680389866679\n",
      "Iteration 44178 => Loss: 44.55195845304738355708\n",
      "Iteration 44179 => Loss: 44.55180924046189971932\n",
      "Iteration 44180 => Loss: 44.55166002904739741552\n",
      "Iteration 44181 => Loss: 44.55151081880394059453\n",
      "Iteration 44182 => Loss: 44.55136160973143688580\n",
      "Iteration 44183 => Loss: 44.55121240182995734358\n",
      "Iteration 44184 => Loss: 44.55106319509942380819\n",
      "Iteration 44185 => Loss: 44.55091398953986470133\n",
      "Iteration 44186 => Loss: 44.55076478515127291757\n",
      "Iteration 44187 => Loss: 44.55061558193360582436\n",
      "Iteration 44188 => Loss: 44.55046637988689894883\n",
      "Iteration 44189 => Loss: 44.55031717901110965840\n",
      "Iteration 44190 => Loss: 44.55016797930623795310\n",
      "Iteration 44191 => Loss: 44.55001878077230514918\n",
      "Iteration 44192 => Loss: 44.54986958340925440325\n",
      "Iteration 44193 => Loss: 44.54972038721709282072\n",
      "Iteration 44194 => Loss: 44.54957119219580619074\n",
      "Iteration 44195 => Loss: 44.54942199834541582959\n",
      "Iteration 44196 => Loss: 44.54927280566590752642\n",
      "Iteration 44197 => Loss: 44.54912361415722443780\n",
      "Iteration 44198 => Loss: 44.54897442381938077460\n",
      "Iteration 44199 => Loss: 44.54882523465239074767\n",
      "Iteration 44200 => Loss: 44.54867604665623304072\n",
      "Iteration 44201 => Loss: 44.54852685983088633748\n",
      "Iteration 44202 => Loss: 44.54837767417635774336\n",
      "Iteration 44203 => Loss: 44.54822848969263304753\n",
      "Iteration 44204 => Loss: 44.54807930637969093368\n",
      "Iteration 44205 => Loss: 44.54793012423753140183\n",
      "Iteration 44206 => Loss: 44.54778094326615445198\n",
      "Iteration 44207 => Loss: 44.54763176346552455698\n",
      "Iteration 44208 => Loss: 44.54748258483566303312\n",
      "Iteration 44209 => Loss: 44.54733340737655566954\n",
      "Iteration 44210 => Loss: 44.54718423108818114997\n",
      "Iteration 44211 => Loss: 44.54703505597051815812\n",
      "Iteration 44212 => Loss: 44.54688588202358090484\n",
      "Iteration 44213 => Loss: 44.54673670924737649557\n",
      "Iteration 44214 => Loss: 44.54658753764183387602\n",
      "Iteration 44215 => Loss: 44.54643836720700988963\n",
      "Iteration 44216 => Loss: 44.54628919794284769296\n",
      "Iteration 44217 => Loss: 44.54614002984937570773\n",
      "Iteration 44218 => Loss: 44.54599086292655130137\n",
      "Iteration 44219 => Loss: 44.54584169717438868474\n",
      "Iteration 44220 => Loss: 44.54569253259287364699\n",
      "Iteration 44221 => Loss: 44.54554336918199908268\n",
      "Iteration 44222 => Loss: 44.54539420694174367554\n",
      "Iteration 44223 => Loss: 44.54524504587212163642\n",
      "Iteration 44224 => Loss: 44.54509588597307612190\n",
      "Iteration 44225 => Loss: 44.54494672724463555369\n",
      "Iteration 44226 => Loss: 44.54479756968679993179\n",
      "Iteration 44227 => Loss: 44.54464841329952662363\n",
      "Iteration 44228 => Loss: 44.54449925808285115636\n",
      "Iteration 44229 => Loss: 44.54435010403673089741\n",
      "Iteration 44230 => Loss: 44.54420095116115163592\n",
      "Iteration 44231 => Loss: 44.54405179945612758274\n",
      "Iteration 44232 => Loss: 44.54390264892163031618\n",
      "Iteration 44233 => Loss: 44.54375349955766694166\n",
      "Iteration 44234 => Loss: 44.54360435136420903746\n",
      "Iteration 44235 => Loss: 44.54345520434126370901\n",
      "Iteration 44236 => Loss: 44.54330605848881674547\n",
      "Iteration 44237 => Loss: 44.54315691380686104139\n",
      "Iteration 44238 => Loss: 44.54300777029538238594\n",
      "Iteration 44239 => Loss: 44.54285862795435946282\n",
      "Iteration 44240 => Loss: 44.54270948678382069374\n",
      "Iteration 44241 => Loss: 44.54256034678373765701\n",
      "Iteration 44242 => Loss: 44.54241120795408193089\n",
      "Iteration 44243 => Loss: 44.54226207029486062083\n",
      "Iteration 44244 => Loss: 44.54211293380605951597\n",
      "Iteration 44245 => Loss: 44.54196379848769282717\n",
      "Iteration 44246 => Loss: 44.54181466433971081642\n",
      "Iteration 44247 => Loss: 44.54166553136214190545\n",
      "Iteration 44248 => Loss: 44.54151639955495767254\n",
      "Iteration 44249 => Loss: 44.54136726891814390683\n",
      "Iteration 44250 => Loss: 44.54121813945169350291\n",
      "Iteration 44251 => Loss: 44.54106901115561356619\n",
      "Iteration 44252 => Loss: 44.54091988402989699125\n",
      "Iteration 44253 => Loss: 44.54077075807450825096\n",
      "Iteration 44254 => Loss: 44.54062163328944023988\n",
      "Iteration 44255 => Loss: 44.54047250967471427430\n",
      "Iteration 44256 => Loss: 44.54032338723030903793\n",
      "Iteration 44257 => Loss: 44.54017426595619610907\n",
      "Iteration 44258 => Loss: 44.54002514585237548772\n",
      "Iteration 44259 => Loss: 44.53987602691884717387\n",
      "Iteration 44260 => Loss: 44.53972690915558985125\n",
      "Iteration 44261 => Loss: 44.53957779256261062528\n",
      "Iteration 44262 => Loss: 44.53942867713989528511\n",
      "Iteration 44263 => Loss: 44.53927956288741540902\n",
      "Iteration 44264 => Loss: 44.53913044980517810245\n",
      "Iteration 44265 => Loss: 44.53898133789316915454\n",
      "Iteration 44266 => Loss: 44.53883222715138856529\n",
      "Iteration 44267 => Loss: 44.53868311757984344013\n",
      "Iteration 44268 => Loss: 44.53853400917846983020\n",
      "Iteration 44269 => Loss: 44.53838490194730326266\n",
      "Iteration 44270 => Loss: 44.53823579588631531578\n",
      "Iteration 44271 => Loss: 44.53808669099552020043\n",
      "Iteration 44272 => Loss: 44.53793758727488949489\n",
      "Iteration 44273 => Loss: 44.53778848472440188289\n",
      "Iteration 44274 => Loss: 44.53763938334407157527\n",
      "Iteration 44275 => Loss: 44.53749028313388436118\n",
      "Iteration 44276 => Loss: 44.53734118409383313519\n",
      "Iteration 44277 => Loss: 44.53719208622388947560\n",
      "Iteration 44278 => Loss: 44.53704298952406759327\n",
      "Iteration 44279 => Loss: 44.53689389399433196104\n",
      "Iteration 44280 => Loss: 44.53674479963470389521\n",
      "Iteration 44281 => Loss: 44.53659570644516918492\n",
      "Iteration 44282 => Loss: 44.53644661442569230303\n",
      "Iteration 44283 => Loss: 44.53629752357630167126\n",
      "Iteration 44284 => Loss: 44.53614843389694755160\n",
      "Iteration 44285 => Loss: 44.53599934538764415493\n",
      "Iteration 44286 => Loss: 44.53585025804839858665\n",
      "Iteration 44287 => Loss: 44.53570117187916821422\n",
      "Iteration 44288 => Loss: 44.53555208687994593220\n",
      "Iteration 44289 => Loss: 44.53540300305076016230\n",
      "Iteration 44290 => Loss: 44.53525392039154695567\n",
      "Iteration 44291 => Loss: 44.53510483890235605031\n",
      "Iteration 44292 => Loss: 44.53495575858313060280\n",
      "Iteration 44293 => Loss: 44.53480667943389903485\n",
      "Iteration 44294 => Loss: 44.53465760145460450303\n",
      "Iteration 44295 => Loss: 44.53450852464528253449\n",
      "Iteration 44296 => Loss: 44.53435944900591891837\n",
      "Iteration 44297 => Loss: 44.53421037453646391668\n",
      "Iteration 44298 => Loss: 44.53406130123695305656\n",
      "Iteration 44299 => Loss: 44.53391222910735791629\n",
      "Iteration 44300 => Loss: 44.53376315814769981216\n",
      "Iteration 44301 => Loss: 44.53361408835792190075\n",
      "Iteration 44302 => Loss: 44.53346501973801707663\n",
      "Iteration 44303 => Loss: 44.53331595228801376152\n",
      "Iteration 44304 => Loss: 44.53316688600789063912\n",
      "Iteration 44305 => Loss: 44.53301782089761928773\n",
      "Iteration 44306 => Loss: 44.53286875695719970736\n",
      "Iteration 44307 => Loss: 44.53271969418663900342\n",
      "Iteration 44308 => Loss: 44.53257063258592296506\n",
      "Iteration 44309 => Loss: 44.53242157215501606515\n",
      "Iteration 44310 => Loss: 44.53227251289392540912\n",
      "Iteration 44311 => Loss: 44.53212345480265099695\n",
      "Iteration 44312 => Loss: 44.53197439788118572324\n",
      "Iteration 44313 => Loss: 44.53182534212949406083\n",
      "Iteration 44314 => Loss: 44.53167628754759732601\n",
      "Iteration 44315 => Loss: 44.53152723413546709708\n",
      "Iteration 44316 => Loss: 44.53137818189311047945\n",
      "Iteration 44317 => Loss: 44.53122913082049194600\n",
      "Iteration 44318 => Loss: 44.53108008091763281300\n",
      "Iteration 44319 => Loss: 44.53093103218448334246\n",
      "Iteration 44320 => Loss: 44.53078198462110037781\n",
      "Iteration 44321 => Loss: 44.53063293822739154848\n",
      "Iteration 44322 => Loss: 44.53048389300342080332\n",
      "Iteration 44323 => Loss: 44.53033484894915261521\n",
      "Iteration 44324 => Loss: 44.53018580606455856241\n",
      "Iteration 44325 => Loss: 44.53003676434965996123\n",
      "Iteration 44326 => Loss: 44.52988772380441417909\n",
      "Iteration 44327 => Loss: 44.52973868442883542684\n",
      "Iteration 44328 => Loss: 44.52958964622290949364\n",
      "Iteration 44329 => Loss: 44.52944060918662927406\n",
      "Iteration 44330 => Loss: 44.52929157332000187353\n",
      "Iteration 44331 => Loss: 44.52914253862298465947\n",
      "Iteration 44332 => Loss: 44.52899350509558473732\n",
      "Iteration 44333 => Loss: 44.52884447273779500165\n",
      "Iteration 44334 => Loss: 44.52869544154957992532\n",
      "Iteration 44335 => Loss: 44.52854641153098924633\n",
      "Iteration 44336 => Loss: 44.52839738268195191040\n",
      "Iteration 44337 => Loss: 44.52824835500249633924\n",
      "Iteration 44338 => Loss: 44.52809932849259411114\n",
      "Iteration 44339 => Loss: 44.52795030315225943696\n",
      "Iteration 44340 => Loss: 44.52780127898145678955\n",
      "Iteration 44341 => Loss: 44.52765225598018616893\n",
      "Iteration 44342 => Loss: 44.52750323414844757508\n",
      "Iteration 44343 => Loss: 44.52735421348623390259\n",
      "Iteration 44344 => Loss: 44.52720519399350962431\n",
      "Iteration 44345 => Loss: 44.52705617567028184567\n",
      "Iteration 44346 => Loss: 44.52690715851655767210\n",
      "Iteration 44347 => Loss: 44.52675814253228736561\n",
      "Iteration 44348 => Loss: 44.52660912771751355876\n",
      "Iteration 44349 => Loss: 44.52646011407218651357\n",
      "Iteration 44350 => Loss: 44.52631110159629201917\n",
      "Iteration 44351 => Loss: 44.52616209028987981355\n",
      "Iteration 44352 => Loss: 44.52601308015287173703\n",
      "Iteration 44353 => Loss: 44.52586407118530331672\n",
      "Iteration 44354 => Loss: 44.52571506338714613094\n",
      "Iteration 44355 => Loss: 44.52556605675839307423\n",
      "Iteration 44356 => Loss: 44.52541705129902993576\n",
      "Iteration 44357 => Loss: 44.52526804700904250467\n",
      "Iteration 44358 => Loss: 44.52511904388845920266\n",
      "Iteration 44359 => Loss: 44.52497004193724450261\n",
      "Iteration 44360 => Loss: 44.52482104115535577193\n",
      "Iteration 44361 => Loss: 44.52467204154286406492\n",
      "Iteration 44362 => Loss: 44.52452304309966990559\n",
      "Iteration 44363 => Loss: 44.52437404582582303192\n",
      "Iteration 44364 => Loss: 44.52422504972131633849\n",
      "Iteration 44365 => Loss: 44.52407605478610719274\n",
      "Iteration 44366 => Loss: 44.52392706102020270009\n",
      "Iteration 44367 => Loss: 44.52377806842360286055\n",
      "Iteration 44368 => Loss: 44.52362907699627214697\n",
      "Iteration 44369 => Loss: 44.52348008673823187564\n",
      "Iteration 44370 => Loss: 44.52333109764945362485\n",
      "Iteration 44371 => Loss: 44.52318210972993739460\n",
      "Iteration 44372 => Loss: 44.52303312297966897404\n",
      "Iteration 44373 => Loss: 44.52288413739863415231\n",
      "Iteration 44374 => Loss: 44.52273515298683292940\n",
      "Iteration 44375 => Loss: 44.52258616974427951618\n",
      "Iteration 44376 => Loss: 44.52243718767089575294\n",
      "Iteration 44377 => Loss: 44.52228820676673137768\n",
      "Iteration 44378 => Loss: 44.52213922703177217954\n",
      "Iteration 44379 => Loss: 44.52199024846598973681\n",
      "Iteration 44380 => Loss: 44.52184127106939115492\n",
      "Iteration 44381 => Loss: 44.52169229484195511759\n",
      "Iteration 44382 => Loss: 44.52154331978368873024\n",
      "Iteration 44383 => Loss: 44.52139434589453514945\n",
      "Iteration 44384 => Loss: 44.52124537317455121865\n",
      "Iteration 44385 => Loss: 44.52109640162370851613\n",
      "Iteration 44386 => Loss: 44.52094743124196440931\n",
      "Iteration 44387 => Loss: 44.52079846202931179278\n",
      "Iteration 44388 => Loss: 44.52064949398578619366\n",
      "Iteration 44389 => Loss: 44.52050052711135919026\n",
      "Iteration 44390 => Loss: 44.52035156140600946628\n",
      "Iteration 44391 => Loss: 44.52020259686973702173\n",
      "Iteration 44392 => Loss: 44.52005363350252764576\n",
      "Iteration 44393 => Loss: 44.51990467130438133836\n",
      "Iteration 44394 => Loss: 44.51975571027526257240\n",
      "Iteration 44395 => Loss: 44.51960675041521398043\n",
      "Iteration 44396 => Loss: 44.51945779172417871905\n",
      "Iteration 44397 => Loss: 44.51930883420214257740\n",
      "Iteration 44398 => Loss: 44.51915987784913397718\n",
      "Iteration 44399 => Loss: 44.51901092266513160212\n",
      "Iteration 44400 => Loss: 44.51886196865012124135\n",
      "Iteration 44401 => Loss: 44.51871301580409578946\n",
      "Iteration 44402 => Loss: 44.51856406412704103559\n",
      "Iteration 44403 => Loss: 44.51841511361894276888\n",
      "Iteration 44404 => Loss: 44.51826616427981520019\n",
      "Iteration 44405 => Loss: 44.51811721610962280238\n",
      "Iteration 44406 => Loss: 44.51796826910837978630\n",
      "Iteration 44407 => Loss: 44.51781932327605062483\n",
      "Iteration 44408 => Loss: 44.51767037861267084509\n",
      "Iteration 44409 => Loss: 44.51752143511814807653\n",
      "Iteration 44410 => Loss: 44.51737249279256047885\n",
      "Iteration 44411 => Loss: 44.51722355163585120863\n",
      "Iteration 44412 => Loss: 44.51707461164804158216\n",
      "Iteration 44413 => Loss: 44.51692567282908186144\n",
      "Iteration 44414 => Loss: 44.51677673517901467903\n",
      "Iteration 44415 => Loss: 44.51662779869778319153\n",
      "Iteration 44416 => Loss: 44.51647886338541582063\n",
      "Iteration 44417 => Loss: 44.51632992924186993378\n",
      "Iteration 44418 => Loss: 44.51618099626715263639\n",
      "Iteration 44419 => Loss: 44.51603206446124971762\n",
      "Iteration 44420 => Loss: 44.51588313382414696662\n",
      "Iteration 44421 => Loss: 44.51573420435586569965\n",
      "Iteration 44422 => Loss: 44.51558527605636328417\n",
      "Iteration 44423 => Loss: 44.51543634892564682559\n",
      "Iteration 44424 => Loss: 44.51528742296370921849\n",
      "Iteration 44425 => Loss: 44.51513849817051493574\n",
      "Iteration 44426 => Loss: 44.51498957454609950446\n",
      "Iteration 44427 => Loss: 44.51484065209041318667\n",
      "Iteration 44428 => Loss: 44.51469173080345598237\n",
      "Iteration 44429 => Loss: 44.51454281068523499698\n",
      "Iteration 44430 => Loss: 44.51439389173572180880\n",
      "Iteration 44431 => Loss: 44.51424497395493062868\n",
      "Iteration 44432 => Loss: 44.51409605734285435119\n",
      "Iteration 44433 => Loss: 44.51394714189943613292\n",
      "Iteration 44434 => Loss: 44.51379822762470439557\n",
      "Iteration 44435 => Loss: 44.51364931451865913914\n",
      "Iteration 44436 => Loss: 44.51350040258125773107\n",
      "Iteration 44437 => Loss: 44.51335149181251438222\n",
      "Iteration 44438 => Loss: 44.51320258221240067087\n",
      "Iteration 44439 => Loss: 44.51305367378093791331\n",
      "Iteration 44440 => Loss: 44.51290476651810479325\n",
      "Iteration 44441 => Loss: 44.51275586042388709984\n",
      "Iteration 44442 => Loss: 44.51260695549828483308\n",
      "Iteration 44443 => Loss: 44.51245805174126957127\n",
      "Iteration 44444 => Loss: 44.51230914915284131439\n",
      "Iteration 44445 => Loss: 44.51216024773299295703\n",
      "Iteration 44446 => Loss: 44.51201134748171028832\n",
      "Iteration 44447 => Loss: 44.51186244839900751913\n",
      "Iteration 44448 => Loss: 44.51171355048483491146\n",
      "Iteration 44449 => Loss: 44.51156465373919957074\n",
      "Iteration 44450 => Loss: 44.51141575816214412953\n",
      "Iteration 44451 => Loss: 44.51126686375356911185\n",
      "Iteration 44452 => Loss: 44.51111797051352425569\n",
      "Iteration 44453 => Loss: 44.51096907844197403392\n",
      "Iteration 44454 => Loss: 44.51082018753893976282\n",
      "Iteration 44455 => Loss: 44.51067129780437880981\n",
      "Iteration 44456 => Loss: 44.51052240923831959662\n",
      "Iteration 44457 => Loss: 44.51037352184071238526\n",
      "Iteration 44458 => Loss: 44.51022463561155717571\n",
      "Iteration 44459 => Loss: 44.51007575055086817883\n",
      "Iteration 44460 => Loss: 44.50992686665860986750\n",
      "Iteration 44461 => Loss: 44.50977798393478224170\n",
      "Iteration 44462 => Loss: 44.50962910237939240687\n",
      "Iteration 44463 => Loss: 44.50948022199241904673\n",
      "Iteration 44464 => Loss: 44.50933134277384084498\n",
      "Iteration 44465 => Loss: 44.50918246472365780164\n",
      "Iteration 44466 => Loss: 44.50903358784186991670\n",
      "Iteration 44467 => Loss: 44.50888471212844876845\n",
      "Iteration 44468 => Loss: 44.50873583758340146233\n",
      "Iteration 44469 => Loss: 44.50858696420671378746\n",
      "Iteration 44470 => Loss: 44.50843809199836442758\n",
      "Iteration 44471 => Loss: 44.50828922095839601525\n",
      "Iteration 44472 => Loss: 44.50814035108673749619\n",
      "Iteration 44473 => Loss: 44.50799148238337465955\n",
      "Iteration 44474 => Loss: 44.50784261484837145417\n",
      "Iteration 44475 => Loss: 44.50769374848162840408\n",
      "Iteration 44476 => Loss: 44.50754488328320235269\n",
      "Iteration 44477 => Loss: 44.50739601925306487828\n",
      "Iteration 44478 => Loss: 44.50724715639121598088\n",
      "Iteration 44479 => Loss: 44.50709829469761302789\n",
      "Iteration 44480 => Loss: 44.50694943417227733562\n",
      "Iteration 44481 => Loss: 44.50680057481518758777\n",
      "Iteration 44482 => Loss: 44.50665171662632957350\n",
      "Iteration 44483 => Loss: 44.50650285960573171451\n",
      "Iteration 44484 => Loss: 44.50635400375334427281\n",
      "Iteration 44485 => Loss: 44.50620514906915303754\n",
      "Iteration 44486 => Loss: 44.50605629555318643042\n",
      "Iteration 44487 => Loss: 44.50590744320539471346\n",
      "Iteration 44488 => Loss: 44.50575859202579920293\n",
      "Iteration 44489 => Loss: 44.50560974201437147713\n",
      "Iteration 44490 => Loss: 44.50546089317113995776\n",
      "Iteration 44491 => Loss: 44.50531204549603359055\n",
      "Iteration 44492 => Loss: 44.50516319898908790265\n",
      "Iteration 44493 => Loss: 44.50501435365026026147\n",
      "Iteration 44494 => Loss: 44.50486550947962882674\n",
      "Iteration 44495 => Loss: 44.50471666647705148989\n",
      "Iteration 44496 => Loss: 44.50456782464261351606\n",
      "Iteration 44497 => Loss: 44.50441898397627937811\n",
      "Iteration 44498 => Loss: 44.50427014447803486519\n",
      "Iteration 44499 => Loss: 44.50412130614786576643\n",
      "Iteration 44500 => Loss: 44.50397246898577208185\n",
      "Iteration 44501 => Loss: 44.50382363299176091687\n",
      "Iteration 44502 => Loss: 44.50367479816578963892\n",
      "Iteration 44503 => Loss: 44.50352596450788666971\n",
      "Iteration 44504 => Loss: 44.50337713201799516582\n",
      "Iteration 44505 => Loss: 44.50322830069615065440\n",
      "Iteration 44506 => Loss: 44.50307947054232471373\n",
      "Iteration 44507 => Loss: 44.50293064155650313296\n",
      "Iteration 44508 => Loss: 44.50278181373869301751\n",
      "Iteration 44509 => Loss: 44.50263298708886594568\n",
      "Iteration 44510 => Loss: 44.50248416160704323374\n",
      "Iteration 44511 => Loss: 44.50233533729316803829\n",
      "Iteration 44512 => Loss: 44.50218651414728299187\n",
      "Iteration 44513 => Loss: 44.50203769216933835651\n",
      "Iteration 44514 => Loss: 44.50188887135934834305\n",
      "Iteration 44515 => Loss: 44.50174005171729163521\n",
      "Iteration 44516 => Loss: 44.50159123324315402215\n",
      "Iteration 44517 => Loss: 44.50144241593695682013\n",
      "Iteration 44518 => Loss: 44.50129359979866450203\n",
      "Iteration 44519 => Loss: 44.50114478482825575156\n",
      "Iteration 44520 => Loss: 44.50099597102574477958\n",
      "Iteration 44521 => Loss: 44.50084715839113158609\n",
      "Iteration 44522 => Loss: 44.50069834692438774937\n",
      "Iteration 44523 => Loss: 44.50054953662549905857\n",
      "Iteration 44524 => Loss: 44.50040072749447261913\n",
      "Iteration 44525 => Loss: 44.50025191953128711475\n",
      "Iteration 44526 => Loss: 44.50010311273594965087\n",
      "Iteration 44527 => Loss: 44.49995430710843891120\n",
      "Iteration 44528 => Loss: 44.49980550264872647404\n",
      "Iteration 44529 => Loss: 44.49965669935684076108\n",
      "Iteration 44530 => Loss: 44.49950789723275335064\n",
      "Iteration 44531 => Loss: 44.49935909627645713726\n",
      "Iteration 44532 => Loss: 44.49921029648795922640\n",
      "Iteration 44533 => Loss: 44.49906149786721698547\n",
      "Iteration 44534 => Loss: 44.49891270041423751991\n",
      "Iteration 44535 => Loss: 44.49876390412899951343\n",
      "Iteration 44536 => Loss: 44.49861510901152428232\n",
      "Iteration 44537 => Loss: 44.49846631506178340487\n",
      "Iteration 44538 => Loss: 44.49831752227976977565\n",
      "Iteration 44539 => Loss: 44.49816873066547628923\n",
      "Iteration 44540 => Loss: 44.49801994021889584019\n",
      "Iteration 44541 => Loss: 44.49787115093999290139\n",
      "Iteration 44542 => Loss: 44.49772236282879589453\n",
      "Iteration 44543 => Loss: 44.49757357588529060877\n",
      "Iteration 44544 => Loss: 44.49742479010944151696\n",
      "Iteration 44545 => Loss: 44.49727600550126282997\n",
      "Iteration 44546 => Loss: 44.49712722206073323150\n",
      "Iteration 44547 => Loss: 44.49697843978784561614\n",
      "Iteration 44548 => Loss: 44.49682965868259998388\n",
      "Iteration 44549 => Loss: 44.49668087874498212386\n",
      "Iteration 44550 => Loss: 44.49653209997496361439\n",
      "Iteration 44551 => Loss: 44.49638332237257998258\n",
      "Iteration 44552 => Loss: 44.49623454593776727961\n",
      "Iteration 44553 => Loss: 44.49608577067056813803\n",
      "Iteration 44554 => Loss: 44.49593699657094703070\n",
      "Iteration 44555 => Loss: 44.49578822363889685221\n",
      "Iteration 44556 => Loss: 44.49563945187440339168\n",
      "Iteration 44557 => Loss: 44.49549068127745243828\n",
      "Iteration 44558 => Loss: 44.49534191184805109742\n",
      "Iteration 44559 => Loss: 44.49519314358619936911\n",
      "Iteration 44560 => Loss: 44.49504437649186172621\n",
      "Iteration 44561 => Loss: 44.49489561056502395786\n",
      "Iteration 44562 => Loss: 44.49474684580572159120\n",
      "Iteration 44563 => Loss: 44.49459808221391199368\n",
      "Iteration 44564 => Loss: 44.49444931978958805985\n",
      "Iteration 44565 => Loss: 44.49430055853273557886\n",
      "Iteration 44566 => Loss: 44.49415179844334744530\n",
      "Iteration 44567 => Loss: 44.49400303952143787001\n",
      "Iteration 44568 => Loss: 44.49385428176697132585\n",
      "Iteration 44569 => Loss: 44.49370552517994070740\n",
      "Iteration 44570 => Loss: 44.49355676976037443637\n",
      "Iteration 44571 => Loss: 44.49340801550819435306\n",
      "Iteration 44572 => Loss: 44.49325926242345730088\n",
      "Iteration 44573 => Loss: 44.49311051050613485813\n",
      "Iteration 44574 => Loss: 44.49296175975617728682\n",
      "Iteration 44575 => Loss: 44.49281301017362011407\n",
      "Iteration 44576 => Loss: 44.49266426175847044533\n",
      "Iteration 44577 => Loss: 44.49251551451063591003\n",
      "Iteration 44578 => Loss: 44.49236676843020177330\n",
      "Iteration 44579 => Loss: 44.49221802351710408630\n",
      "Iteration 44580 => Loss: 44.49206927977134995444\n",
      "Iteration 44581 => Loss: 44.49192053719293937775\n",
      "Iteration 44582 => Loss: 44.49177179578184393449\n",
      "Iteration 44583 => Loss: 44.49162305553805651925\n",
      "Iteration 44584 => Loss: 44.49147431646157713203\n",
      "Iteration 44585 => Loss: 44.49132557855241998368\n",
      "Iteration 44586 => Loss: 44.49117684181052112535\n",
      "Iteration 44587 => Loss: 44.49102810623590897876\n",
      "Iteration 44588 => Loss: 44.49087937182855512219\n",
      "Iteration 44589 => Loss: 44.49073063858848087193\n",
      "Iteration 44590 => Loss: 44.49058190651566491169\n",
      "Iteration 44591 => Loss: 44.49043317561003618721\n",
      "Iteration 44592 => Loss: 44.49028444587170127988\n",
      "Iteration 44593 => Loss: 44.49013571730055360831\n",
      "Iteration 44594 => Loss: 44.48998698989663580505\n",
      "Iteration 44595 => Loss: 44.48983826365991944840\n",
      "Iteration 44596 => Loss: 44.48968953859039743293\n",
      "Iteration 44597 => Loss: 44.48954081468806975863\n",
      "Iteration 44598 => Loss: 44.48939209195290089838\n",
      "Iteration 44599 => Loss: 44.48924337038491927387\n",
      "Iteration 44600 => Loss: 44.48909464998407514713\n",
      "Iteration 44601 => Loss: 44.48894593075040404528\n",
      "Iteration 44602 => Loss: 44.48879721268386333577\n",
      "Iteration 44603 => Loss: 44.48864849578445301859\n",
      "Iteration 44604 => Loss: 44.48849978005216598831\n",
      "Iteration 44605 => Loss: 44.48835106548700224494\n",
      "Iteration 44606 => Loss: 44.48820235208892626133\n",
      "Iteration 44607 => Loss: 44.48805363985797356463\n",
      "Iteration 44608 => Loss: 44.48790492879406599513\n",
      "Iteration 44609 => Loss: 44.48775621889724618541\n",
      "Iteration 44610 => Loss: 44.48760751016751413545\n",
      "Iteration 44611 => Loss: 44.48745880260483431812\n",
      "Iteration 44612 => Loss: 44.48731009620919962799\n",
      "Iteration 44613 => Loss: 44.48716139098059585422\n",
      "Iteration 44614 => Loss: 44.48701268691903720764\n",
      "Iteration 44615 => Loss: 44.48686398402448105571\n",
      "Iteration 44616 => Loss: 44.48671528229694871470\n",
      "Iteration 44617 => Loss: 44.48656658173641886833\n",
      "Iteration 44618 => Loss: 44.48641788234287730575\n",
      "Iteration 44619 => Loss: 44.48626918411634534323\n",
      "Iteration 44620 => Loss: 44.48612048705677324278\n",
      "Iteration 44621 => Loss: 44.48597179116414679356\n",
      "Iteration 44622 => Loss: 44.48582309643849441727\n",
      "Iteration 44623 => Loss: 44.48567440287981611391\n",
      "Iteration 44624 => Loss: 44.48552571048805504006\n",
      "Iteration 44625 => Loss: 44.48537701926320409029\n",
      "Iteration 44626 => Loss: 44.48522832920530589718\n",
      "Iteration 44627 => Loss: 44.48507964031431072272\n",
      "Iteration 44628 => Loss: 44.48493095259019725063\n",
      "Iteration 44629 => Loss: 44.48478226603300100805\n",
      "Iteration 44630 => Loss: 44.48463358064268646785\n",
      "Iteration 44631 => Loss: 44.48448489641924652460\n",
      "Iteration 44632 => Loss: 44.48433621336267407287\n",
      "Iteration 44633 => Loss: 44.48418753147294069095\n",
      "Iteration 44634 => Loss: 44.48403885075007480054\n",
      "Iteration 44635 => Loss: 44.48389017119404087452\n",
      "Iteration 44636 => Loss: 44.48374149280482470203\n",
      "Iteration 44637 => Loss: 44.48359281558244759935\n",
      "Iteration 44638 => Loss: 44.48344413952686693392\n",
      "Iteration 44639 => Loss: 44.48329546463810402201\n",
      "Iteration 44640 => Loss: 44.48314679091612333650\n",
      "Iteration 44641 => Loss: 44.48299811836091777195\n",
      "Iteration 44642 => Loss: 44.48284944697249443379\n",
      "Iteration 44643 => Loss: 44.48270077675084621660\n",
      "Iteration 44644 => Loss: 44.48255210769594469866\n",
      "Iteration 44645 => Loss: 44.48240343980778277455\n",
      "Iteration 44646 => Loss: 44.48225477308637465512\n",
      "Iteration 44647 => Loss: 44.48210610753169191867\n",
      "Iteration 44648 => Loss: 44.48195744314371324890\n",
      "Iteration 44649 => Loss: 44.48180877992245285668\n",
      "Iteration 44650 => Loss: 44.48166011786791074201\n",
      "Iteration 44651 => Loss: 44.48151145698003716689\n",
      "Iteration 44652 => Loss: 44.48136279725887476388\n",
      "Iteration 44653 => Loss: 44.48121413870434537330\n",
      "Iteration 44654 => Loss: 44.48106548131651294398\n",
      "Iteration 44655 => Loss: 44.48091682509532063250\n",
      "Iteration 44656 => Loss: 44.48076817004077554429\n",
      "Iteration 44657 => Loss: 44.48061951615287057393\n",
      "Iteration 44658 => Loss: 44.48047086343158440513\n",
      "Iteration 44659 => Loss: 44.48032221187693835418\n",
      "Iteration 44660 => Loss: 44.48017356148889689393\n",
      "Iteration 44661 => Loss: 44.48002491226743160269\n",
      "Iteration 44662 => Loss: 44.47987626421258511300\n",
      "Iteration 44663 => Loss: 44.47972761732430058146\n",
      "Iteration 44664 => Loss: 44.47957897160259932434\n",
      "Iteration 44665 => Loss: 44.47943032704746713080\n",
      "Iteration 44666 => Loss: 44.47928168365888268454\n",
      "Iteration 44667 => Loss: 44.47913304143686019643\n",
      "Iteration 44668 => Loss: 44.47898440038134282304\n",
      "Iteration 44669 => Loss: 44.47883576049236609151\n",
      "Iteration 44670 => Loss: 44.47868712176991579099\n",
      "Iteration 44671 => Loss: 44.47853848421398481605\n",
      "Iteration 44672 => Loss: 44.47838984782452342870\n",
      "Iteration 44673 => Loss: 44.47824121260156715607\n",
      "Iteration 44674 => Loss: 44.47809257854508757646\n",
      "Iteration 44675 => Loss: 44.47794394565507758443\n",
      "Iteration 44676 => Loss: 44.47779531393154428542\n",
      "Iteration 44677 => Loss: 44.47764668337447346858\n",
      "Iteration 44678 => Loss: 44.47749805398380118504\n",
      "Iteration 44679 => Loss: 44.47734942575960559452\n",
      "Iteration 44680 => Loss: 44.47720079870182274817\n",
      "Iteration 44681 => Loss: 44.47705217281046685684\n",
      "Iteration 44682 => Loss: 44.47690354808552370969\n",
      "Iteration 44683 => Loss: 44.47675492452694356871\n",
      "Iteration 44684 => Loss: 44.47660630213478327732\n",
      "Iteration 44685 => Loss: 44.47645768090899309755\n",
      "Iteration 44686 => Loss: 44.47630906084958724023\n",
      "Iteration 44687 => Loss: 44.47616044195653728366\n",
      "Iteration 44688 => Loss: 44.47601182422985743870\n",
      "Iteration 44689 => Loss: 44.47586320766949086192\n",
      "Iteration 44690 => Loss: 44.47571459227547308046\n",
      "Iteration 44691 => Loss: 44.47556597804779698890\n",
      "Iteration 44692 => Loss: 44.47541736498639863839\n",
      "Iteration 44693 => Loss: 44.47526875309133487235\n",
      "Iteration 44694 => Loss: 44.47512014236256305821\n",
      "Iteration 44695 => Loss: 44.47497153280007609055\n",
      "Iteration 44696 => Loss: 44.47482292440388107480\n",
      "Iteration 44697 => Loss: 44.47467431717395669466\n",
      "Iteration 44698 => Loss: 44.47452571111029584472\n",
      "Iteration 44699 => Loss: 44.47437710621287010326\n",
      "Iteration 44700 => Loss: 44.47422850248169368115\n",
      "Iteration 44701 => Loss: 44.47407989991675236752\n",
      "Iteration 44702 => Loss: 44.47393129851805326780\n",
      "Iteration 44703 => Loss: 44.47378269828553953857\n",
      "Iteration 44704 => Loss: 44.47363409921925381241\n",
      "Iteration 44705 => Loss: 44.47348550131915345673\n",
      "Iteration 44706 => Loss: 44.47333690458523847155\n",
      "Iteration 44707 => Loss: 44.47318830901751596230\n",
      "Iteration 44708 => Loss: 44.47303971461597882353\n",
      "Iteration 44709 => Loss: 44.47289112138058442270\n",
      "Iteration 44710 => Loss: 44.47274252931131854893\n",
      "Iteration 44711 => Loss: 44.47259393840824515109\n",
      "Iteration 44712 => Loss: 44.47244534867127896405\n",
      "Iteration 44713 => Loss: 44.47229676010043419865\n",
      "Iteration 44714 => Loss: 44.47214817269569664404\n",
      "Iteration 44715 => Loss: 44.47199958645708761651\n",
      "Iteration 44716 => Loss: 44.47185100138455737806\n",
      "Iteration 44717 => Loss: 44.47170241747812013955\n",
      "Iteration 44718 => Loss: 44.47155383473778300640\n",
      "Iteration 44719 => Loss: 44.47140525316348202978\n",
      "Iteration 44720 => Loss: 44.47125667275527405309\n",
      "Iteration 44721 => Loss: 44.47110809351309512749\n",
      "Iteration 44722 => Loss: 44.47095951543694525299\n",
      "Iteration 44723 => Loss: 44.47081093852685285128\n",
      "Iteration 44724 => Loss: 44.47066236278277528982\n",
      "Iteration 44725 => Loss: 44.47051378820471256859\n",
      "Iteration 44726 => Loss: 44.47036521479265047674\n",
      "Iteration 44727 => Loss: 44.47021664254658190885\n",
      "Iteration 44728 => Loss: 44.47006807146652107576\n",
      "Iteration 44729 => Loss: 44.46991950155241823950\n",
      "Iteration 44730 => Loss: 44.46977093280430182176\n",
      "Iteration 44731 => Loss: 44.46962236522214340084\n",
      "Iteration 44732 => Loss: 44.46947379880591455503\n",
      "Iteration 44733 => Loss: 44.46932523355563660061\n",
      "Iteration 44734 => Loss: 44.46917666947130953758\n",
      "Iteration 44735 => Loss: 44.46902810655287652253\n",
      "Iteration 44736 => Loss: 44.46887954480038018801\n",
      "Iteration 44737 => Loss: 44.46873098421377079603\n",
      "Iteration 44738 => Loss: 44.46858242479306966288\n",
      "Iteration 44739 => Loss: 44.46843386653825547228\n",
      "Iteration 44740 => Loss: 44.46828530944931401336\n",
      "Iteration 44741 => Loss: 44.46813675352623107528\n",
      "Iteration 44742 => Loss: 44.46798819876902797432\n",
      "Iteration 44743 => Loss: 44.46783964517765497249\n",
      "Iteration 44744 => Loss: 44.46769109275214049148\n",
      "Iteration 44745 => Loss: 44.46754254149244189875\n",
      "Iteration 44746 => Loss: 44.46739399139857340515\n",
      "Iteration 44747 => Loss: 44.46724544247051369439\n",
      "Iteration 44748 => Loss: 44.46709689470826987190\n",
      "Iteration 44749 => Loss: 44.46694834811181351597\n",
      "Iteration 44750 => Loss: 44.46679980268115883746\n",
      "Iteration 44751 => Loss: 44.46665125841624188752\n",
      "Iteration 44752 => Loss: 44.46650271531713372042\n",
      "Iteration 44753 => Loss: 44.46635417338375617646\n",
      "Iteration 44754 => Loss: 44.46620563261614478279\n",
      "Iteration 44755 => Loss: 44.46605709301424269597\n",
      "Iteration 44756 => Loss: 44.46590855457811386486\n",
      "Iteration 44757 => Loss: 44.46576001730770144604\n",
      "Iteration 44758 => Loss: 44.46561148120297701780\n",
      "Iteration 44759 => Loss: 44.46546294626397610728\n",
      "Iteration 44760 => Loss: 44.46531441249064897647\n",
      "Iteration 44761 => Loss: 44.46516587988300273082\n",
      "Iteration 44762 => Loss: 44.46501734844106579203\n",
      "Iteration 44763 => Loss: 44.46486881816477421125\n",
      "Iteration 44764 => Loss: 44.46472028905414930477\n",
      "Iteration 44765 => Loss: 44.46457176110916265088\n",
      "Iteration 44766 => Loss: 44.46442323432982846043\n",
      "Iteration 44767 => Loss: 44.46427470871613252257\n",
      "Iteration 44768 => Loss: 44.46412618426802509930\n",
      "Iteration 44769 => Loss: 44.46397766098554171776\n",
      "Iteration 44770 => Loss: 44.46382913886865395625\n",
      "Iteration 44771 => Loss: 44.46368061791739734190\n",
      "Iteration 44772 => Loss: 44.46353209813170082043\n",
      "Iteration 44773 => Loss: 44.46338357951159281356\n",
      "Iteration 44774 => Loss: 44.46323506205702358329\n",
      "Iteration 44775 => Loss: 44.46308654576801444591\n",
      "Iteration 44776 => Loss: 44.46293803064457961227\n",
      "Iteration 44777 => Loss: 44.46278951668666934438\n",
      "Iteration 44778 => Loss: 44.46264100389429074767\n",
      "Iteration 44779 => Loss: 44.46249249226742961127\n",
      "Iteration 44780 => Loss: 44.46234398180607172435\n",
      "Iteration 44781 => Loss: 44.46219547251023129775\n",
      "Iteration 44782 => Loss: 44.46204696437986569890\n",
      "Iteration 44783 => Loss: 44.46189845741501045495\n",
      "Iteration 44784 => Loss: 44.46174995161561582790\n",
      "Iteration 44785 => Loss: 44.46160144698168181776\n",
      "Iteration 44786 => Loss: 44.46145294351320131909\n",
      "Iteration 44787 => Loss: 44.46130444121018143733\n",
      "Iteration 44788 => Loss: 44.46115594007259375076\n",
      "Iteration 44789 => Loss: 44.46100744010043825938\n",
      "Iteration 44790 => Loss: 44.46085894129370075234\n",
      "Iteration 44791 => Loss: 44.46071044365237412421\n",
      "Iteration 44792 => Loss: 44.46056194717645126957\n",
      "Iteration 44793 => Loss: 44.46041345186591087213\n",
      "Iteration 44794 => Loss: 44.46026495772076714275\n",
      "Iteration 44795 => Loss: 44.46011646474099876514\n",
      "Iteration 44796 => Loss: 44.45996797292658442302\n",
      "Iteration 44797 => Loss: 44.45981948227753832725\n",
      "Iteration 44798 => Loss: 44.45967099279382495070\n",
      "Iteration 44799 => Loss: 44.45952250447545850420\n",
      "Iteration 44800 => Loss: 44.45937401732241767149\n",
      "Iteration 44801 => Loss: 44.45922553133470245257\n",
      "Iteration 44802 => Loss: 44.45907704651229153114\n",
      "Iteration 44803 => Loss: 44.45892856285518490722\n",
      "Iteration 44804 => Loss: 44.45878008036333994824\n",
      "Iteration 44805 => Loss: 44.45863159903682770846\n",
      "Iteration 44806 => Loss: 44.45848311887555581734\n",
      "Iteration 44807 => Loss: 44.45833463987955980201\n",
      "Iteration 44808 => Loss: 44.45818616204881124077\n",
      "Iteration 44809 => Loss: 44.45803768538332434446\n",
      "Iteration 44810 => Loss: 44.45788920988307069138\n",
      "Iteration 44811 => Loss: 44.45774073554802896524\n",
      "Iteration 44812 => Loss: 44.45759226237820627148\n",
      "Iteration 44813 => Loss: 44.45744379037360971552\n",
      "Iteration 44814 => Loss: 44.45729531953421798107\n",
      "Iteration 44815 => Loss: 44.45714684986000264644\n",
      "Iteration 44816 => Loss: 44.45699838135098502789\n",
      "Iteration 44817 => Loss: 44.45684991400712249288\n",
      "Iteration 44818 => Loss: 44.45670144782843635767\n",
      "Iteration 44819 => Loss: 44.45655298281489109513\n",
      "Iteration 44820 => Loss: 44.45640451896650802155\n",
      "Iteration 44821 => Loss: 44.45625605628322318807\n",
      "Iteration 44822 => Loss: 44.45610759476512185984\n",
      "Iteration 44823 => Loss: 44.45595913441210456085\n",
      "Iteration 44824 => Loss: 44.45581067522420681826\n",
      "Iteration 44825 => Loss: 44.45566221720139310492\n",
      "Iteration 44826 => Loss: 44.45551376034370605339\n",
      "Iteration 44827 => Loss: 44.45536530465107460941\n",
      "Iteration 44828 => Loss: 44.45521685012352008926\n",
      "Iteration 44829 => Loss: 44.45506839676102117664\n",
      "Iteration 44830 => Loss: 44.45491994456357076615\n",
      "Iteration 44831 => Loss: 44.45477149353119017405\n",
      "Iteration 44832 => Loss: 44.45462304366381545151\n",
      "Iteration 44833 => Loss: 44.45447459496148212565\n",
      "Iteration 44834 => Loss: 44.45432614742417598563\n",
      "Iteration 44835 => Loss: 44.45417770105188282059\n",
      "Iteration 44836 => Loss: 44.45402925584457420882\n",
      "Iteration 44837 => Loss: 44.45388081180226436118\n",
      "Iteration 44838 => Loss: 44.45373236892492485595\n",
      "Iteration 44839 => Loss: 44.45358392721256990399\n",
      "Iteration 44840 => Loss: 44.45343548666515687273\n",
      "Iteration 44841 => Loss: 44.45328704728271418389\n",
      "Iteration 44842 => Loss: 44.45313860906521341576\n",
      "Iteration 44843 => Loss: 44.45299017201265456833\n",
      "Iteration 44844 => Loss: 44.45284173612502343076\n",
      "Iteration 44845 => Loss: 44.45269330140228447590\n",
      "Iteration 44846 => Loss: 44.45254486784447323089\n",
      "Iteration 44847 => Loss: 44.45239643545155416859\n",
      "Iteration 44848 => Loss: 44.45224800422352728901\n",
      "Iteration 44849 => Loss: 44.45209957416039259215\n",
      "Iteration 44850 => Loss: 44.45195114526210034001\n",
      "Iteration 44851 => Loss: 44.45180271752869316515\n",
      "Iteration 44852 => Loss: 44.45165429096014264587\n",
      "Iteration 44853 => Loss: 44.45150586555641325504\n",
      "Iteration 44854 => Loss: 44.45135744131754762520\n",
      "Iteration 44855 => Loss: 44.45120901824347470210\n",
      "Iteration 44856 => Loss: 44.45106059633425132915\n",
      "Iteration 44857 => Loss: 44.45091217558980645208\n",
      "Iteration 44858 => Loss: 44.45076375601018270345\n",
      "Iteration 44859 => Loss: 44.45061533759533745069\n",
      "Iteration 44860 => Loss: 44.45046692034527069382\n",
      "Iteration 44861 => Loss: 44.45031850425997532739\n",
      "Iteration 44862 => Loss: 44.45017008933944424598\n",
      "Iteration 44863 => Loss: 44.45002167558367744959\n",
      "Iteration 44864 => Loss: 44.44987326299261809481\n",
      "Iteration 44865 => Loss: 44.44972485156633723591\n",
      "Iteration 44866 => Loss: 44.44957644130474250233\n",
      "Iteration 44867 => Loss: 44.44942803220787652663\n",
      "Iteration 44868 => Loss: 44.44927962427573930881\n",
      "Iteration 44869 => Loss: 44.44913121750828821632\n",
      "Iteration 44870 => Loss: 44.44898281190550903830\n",
      "Iteration 44871 => Loss: 44.44883440746741598559\n",
      "Iteration 44872 => Loss: 44.44868600419401616364\n",
      "Iteration 44873 => Loss: 44.44853760208525272901\n",
      "Iteration 44874 => Loss: 44.44838920114113278714\n",
      "Iteration 44875 => Loss: 44.44824080136168475974\n",
      "Iteration 44876 => Loss: 44.44809240274684469796\n",
      "Iteration 44877 => Loss: 44.44794400529663391808\n",
      "Iteration 44878 => Loss: 44.44779560901105242010\n",
      "Iteration 44879 => Loss: 44.44764721389006467689\n",
      "Iteration 44880 => Loss: 44.44749881993367068844\n",
      "Iteration 44881 => Loss: 44.44735042714188466562\n",
      "Iteration 44882 => Loss: 44.44720203551465687042\n",
      "Iteration 44883 => Loss: 44.44705364505202282999\n",
      "Iteration 44884 => Loss: 44.44690525575391859547\n",
      "Iteration 44885 => Loss: 44.44675686762037969402\n",
      "Iteration 44886 => Loss: 44.44660848065138480933\n",
      "Iteration 44887 => Loss: 44.44646009484693394143\n",
      "Iteration 44888 => Loss: 44.44631171020699866858\n",
      "Iteration 44889 => Loss: 44.44616332673157188538\n",
      "Iteration 44890 => Loss: 44.44601494442063938095\n",
      "Iteration 44891 => Loss: 44.44586656327421536616\n",
      "Iteration 44892 => Loss: 44.44571818329230694644\n",
      "Iteration 44893 => Loss: 44.44556980447483596208\n",
      "Iteration 44894 => Loss: 44.44542142682183794022\n",
      "Iteration 44895 => Loss: 44.44527305033331998629\n",
      "Iteration 44896 => Loss: 44.44512467500923946773\n",
      "Iteration 44897 => Loss: 44.44497630084960348995\n",
      "Iteration 44898 => Loss: 44.44482792785440494754\n",
      "Iteration 44899 => Loss: 44.44467955602364384049\n",
      "Iteration 44900 => Loss: 44.44453118535726332539\n",
      "Iteration 44901 => Loss: 44.44438281585531314022\n",
      "Iteration 44902 => Loss: 44.44423444751775775785\n",
      "Iteration 44903 => Loss: 44.44408608034458296743\n",
      "Iteration 44904 => Loss: 44.44393771433578876895\n",
      "Iteration 44905 => Loss: 44.44378934949134674071\n",
      "Iteration 44906 => Loss: 44.44364098581127109355\n",
      "Iteration 44907 => Loss: 44.44349262329555472206\n",
      "Iteration 44908 => Loss: 44.44334426194419762624\n",
      "Iteration 44909 => Loss: 44.44319590175712875180\n",
      "Iteration 44910 => Loss: 44.44304754273442625845\n",
      "Iteration 44911 => Loss: 44.44289918487600488106\n",
      "Iteration 44912 => Loss: 44.44275082818190014677\n",
      "Iteration 44913 => Loss: 44.44260247265210495016\n",
      "Iteration 44914 => Loss: 44.44245411828656955322\n",
      "Iteration 44915 => Loss: 44.44230576508532948310\n",
      "Iteration 44916 => Loss: 44.44215741304834210723\n",
      "Iteration 44917 => Loss: 44.44200906217562874190\n",
      "Iteration 44918 => Loss: 44.44186071246716096539\n",
      "Iteration 44919 => Loss: 44.44171236392294588313\n",
      "Iteration 44920 => Loss: 44.44156401654292665171\n",
      "Iteration 44921 => Loss: 44.44141567032716721997\n",
      "Iteration 44922 => Loss: 44.44126732527560363906\n",
      "Iteration 44923 => Loss: 44.44111898138825011983\n",
      "Iteration 44924 => Loss: 44.44097063866508534602\n",
      "Iteration 44925 => Loss: 44.44082229710611642304\n",
      "Iteration 44926 => Loss: 44.44067395671130782375\n",
      "Iteration 44927 => Loss: 44.44052561748068086445\n",
      "Iteration 44928 => Loss: 44.44037727941420001798\n",
      "Iteration 44929 => Loss: 44.44022894251189370607\n",
      "Iteration 44930 => Loss: 44.44008060677369797986\n",
      "Iteration 44931 => Loss: 44.43993227219964836650\n",
      "Iteration 44932 => Loss: 44.43978393878971644426\n",
      "Iteration 44933 => Loss: 44.43963560654390221316\n",
      "Iteration 44934 => Loss: 44.43948727546218435691\n",
      "Iteration 44935 => Loss: 44.43933894554456287551\n",
      "Iteration 44936 => Loss: 44.43919061679102355811\n",
      "Iteration 44937 => Loss: 44.43904228920157351013\n",
      "Iteration 44938 => Loss: 44.43889396277619141529\n",
      "Iteration 44939 => Loss: 44.43874563751484885188\n",
      "Iteration 44940 => Loss: 44.43859731341755292533\n",
      "Iteration 44941 => Loss: 44.43844899048432495192\n",
      "Iteration 44942 => Loss: 44.43830066871510808824\n",
      "Iteration 44943 => Loss: 44.43815234810992365055\n",
      "Iteration 44944 => Loss: 44.43800402866875032259\n",
      "Iteration 44945 => Loss: 44.43785571039155968265\n",
      "Iteration 44946 => Loss: 44.43770739327836594157\n",
      "Iteration 44947 => Loss: 44.43755907732917620478\n",
      "Iteration 44948 => Loss: 44.43741076254398336687\n",
      "Iteration 44949 => Loss: 44.43726244892270216269\n",
      "Iteration 44950 => Loss: 44.43711413646539654110\n",
      "Iteration 44951 => Loss: 44.43696582517204518581\n",
      "Iteration 44952 => Loss: 44.43681751504264099140\n",
      "Iteration 44953 => Loss: 44.43666920607716264158\n",
      "Iteration 44954 => Loss: 44.43652089827559592550\n",
      "Iteration 44955 => Loss: 44.43637259163795505401\n",
      "Iteration 44956 => Loss: 44.43622428616421871084\n",
      "Iteration 44957 => Loss: 44.43607598185435847427\n",
      "Iteration 44958 => Loss: 44.43592767870840276601\n",
      "Iteration 44959 => Loss: 44.43577937672630184807\n",
      "Iteration 44960 => Loss: 44.43563107590807703673\n",
      "Iteration 44961 => Loss: 44.43548277625371412114\n",
      "Iteration 44962 => Loss: 44.43533447776317757416\n",
      "Iteration 44963 => Loss: 44.43518618043651002836\n",
      "Iteration 44964 => Loss: 44.43503788427364042946\n",
      "Iteration 44965 => Loss: 44.43488958927461851545\n",
      "Iteration 44966 => Loss: 44.43474129543938744291\n",
      "Iteration 44967 => Loss: 44.43459300276797563356\n",
      "Iteration 44968 => Loss: 44.43444471126036177111\n",
      "Iteration 44969 => Loss: 44.43429642091651743385\n",
      "Iteration 44970 => Loss: 44.43414813173644262179\n",
      "Iteration 44971 => Loss: 44.43399984372015154577\n",
      "Iteration 44972 => Loss: 44.43385155686759446780\n",
      "Iteration 44973 => Loss: 44.43370327117882112589\n",
      "Iteration 44974 => Loss: 44.43355498665376046574\n",
      "Iteration 44975 => Loss: 44.43340670329242669823\n",
      "Iteration 44976 => Loss: 44.43325842109479850706\n",
      "Iteration 44977 => Loss: 44.43311014006091852480\n",
      "Iteration 44978 => Loss: 44.43296186019071569717\n",
      "Iteration 44979 => Loss: 44.43281358148419712961\n",
      "Iteration 44980 => Loss: 44.43266530394139834925\n",
      "Iteration 44981 => Loss: 44.43251702756224830182\n",
      "Iteration 44982 => Loss: 44.43236875234678251445\n",
      "Iteration 44983 => Loss: 44.43222047829494414373\n",
      "Iteration 44984 => Loss: 44.43207220540675450593\n",
      "Iteration 44985 => Loss: 44.43192393368221360106\n",
      "Iteration 44986 => Loss: 44.43177566312132142912\n",
      "Iteration 44987 => Loss: 44.43162739372403535754\n",
      "Iteration 44988 => Loss: 44.43147912549033407004\n",
      "Iteration 44989 => Loss: 44.43133085842026019918\n",
      "Iteration 44990 => Loss: 44.43118259251376400698\n",
      "Iteration 44991 => Loss: 44.43103432777086680971\n",
      "Iteration 44992 => Loss: 44.43088606419152597482\n",
      "Iteration 44993 => Loss: 44.43073780177576281858\n",
      "Iteration 44994 => Loss: 44.43058954052355602471\n",
      "Iteration 44995 => Loss: 44.43044128043489138236\n",
      "Iteration 44996 => Loss: 44.43029302150976178609\n",
      "Iteration 44997 => Loss: 44.43014476374816723592\n",
      "Iteration 44998 => Loss: 44.42999650715007931012\n",
      "Iteration 44999 => Loss: 44.42984825171551932499\n",
      "Iteration 45000 => Loss: 44.42969999744444464795\n",
      "Iteration 45001 => Loss: 44.42955174433688370073\n",
      "Iteration 45002 => Loss: 44.42940349239277963989\n",
      "Iteration 45003 => Loss: 44.42925524161215378172\n",
      "Iteration 45004 => Loss: 44.42910699199500612622\n",
      "Iteration 45005 => Loss: 44.42895874354129404082\n",
      "Iteration 45006 => Loss: 44.42881049625103173639\n",
      "Iteration 45007 => Loss: 44.42866225012422631835\n",
      "Iteration 45008 => Loss: 44.42851400516082094327\n",
      "Iteration 45009 => Loss: 44.42836576136085113831\n",
      "Iteration 45010 => Loss: 44.42821751872430269259\n",
      "Iteration 45011 => Loss: 44.42806927725114007899\n",
      "Iteration 45012 => Loss: 44.42792103694136329750\n",
      "Iteration 45013 => Loss: 44.42777279779497945356\n",
      "Iteration 45014 => Loss: 44.42762455981196723087\n",
      "Iteration 45015 => Loss: 44.42747632299232662945\n",
      "Iteration 45016 => Loss: 44.42732808733600791129\n",
      "Iteration 45017 => Loss: 44.42717985284304660354\n",
      "Iteration 45018 => Loss: 44.42703161951344981162\n",
      "Iteration 45019 => Loss: 44.42688338734714648126\n",
      "Iteration 45020 => Loss: 44.42673515634418635045\n",
      "Iteration 45021 => Loss: 44.42658692650453389206\n",
      "Iteration 45022 => Loss: 44.42643869782817489522\n",
      "Iteration 45023 => Loss: 44.42629047031508093824\n",
      "Iteration 45024 => Loss: 44.42614224396531596994\n",
      "Iteration 45025 => Loss: 44.42599401877878051437\n",
      "Iteration 45026 => Loss: 44.42584579475553852035\n",
      "Iteration 45027 => Loss: 44.42569757189554735533\n",
      "Iteration 45028 => Loss: 44.42554935019879280844\n",
      "Iteration 45029 => Loss: 44.42540112966528198513\n",
      "Iteration 45030 => Loss: 44.42525291029499356910\n",
      "Iteration 45031 => Loss: 44.42510469208792756035\n",
      "Iteration 45032 => Loss: 44.42495647504404843176\n",
      "Iteration 45033 => Loss: 44.42480825916340592130\n",
      "Iteration 45034 => Loss: 44.42466004444591476386\n",
      "Iteration 45035 => Loss: 44.42451183089161759199\n",
      "Iteration 45036 => Loss: 44.42436361850052151112\n",
      "Iteration 45037 => Loss: 44.42421540727256257242\n",
      "Iteration 45038 => Loss: 44.42406719720774788129\n",
      "Iteration 45039 => Loss: 44.42391898830608454318\n",
      "Iteration 45040 => Loss: 44.42377078056755124180\n",
      "Iteration 45041 => Loss: 44.42362257399216929343\n",
      "Iteration 45042 => Loss: 44.42347436857989606551\n",
      "Iteration 45043 => Loss: 44.42332616433071734718\n",
      "Iteration 45044 => Loss: 44.42317796124464024388\n",
      "Iteration 45045 => Loss: 44.42302975932167186102\n",
      "Iteration 45046 => Loss: 44.42288155856178377690\n",
      "Iteration 45047 => Loss: 44.42273335896494046438\n",
      "Iteration 45048 => Loss: 44.42258516053119876688\n",
      "Iteration 45049 => Loss: 44.42243696326047341927\n",
      "Iteration 45050 => Loss: 44.42228876715280705412\n",
      "Iteration 45051 => Loss: 44.42214057220817124971\n",
      "Iteration 45052 => Loss: 44.42199237842655890063\n",
      "Iteration 45053 => Loss: 44.42184418580797000686\n",
      "Iteration 45054 => Loss: 44.42169599435239746299\n",
      "Iteration 45055 => Loss: 44.42154780405981995273\n",
      "Iteration 45056 => Loss: 44.42139961493020905436\n",
      "Iteration 45057 => Loss: 44.42125142696361450589\n",
      "Iteration 45058 => Loss: 44.42110324015996525304\n",
      "Iteration 45059 => Loss: 44.42095505451926840124\n",
      "Iteration 45060 => Loss: 44.42080687004157368847\n",
      "Iteration 45061 => Loss: 44.42065868672676742790\n",
      "Iteration 45062 => Loss: 44.42051050457492777923\n",
      "Iteration 45063 => Loss: 44.42036232358600500447\n",
      "Iteration 45064 => Loss: 44.42021414376000620905\n",
      "Iteration 45065 => Loss: 44.42006596509690297125\n",
      "Iteration 45066 => Loss: 44.41991778759669529109\n",
      "Iteration 45067 => Loss: 44.41976961125939737940\n",
      "Iteration 45068 => Loss: 44.41962143608498081448\n",
      "Iteration 45069 => Loss: 44.41947326207342428006\n",
      "Iteration 45070 => Loss: 44.41932508922469224899\n",
      "Iteration 45071 => Loss: 44.41917691753886998640\n",
      "Iteration 45072 => Loss: 44.41902874701585801631\n",
      "Iteration 45073 => Loss: 44.41888057765569186586\n",
      "Iteration 45074 => Loss: 44.41873240945836442961\n",
      "Iteration 45075 => Loss: 44.41858424242384728586\n",
      "Iteration 45076 => Loss: 44.41843607655212622376\n",
      "Iteration 45077 => Loss: 44.41828791184319413787\n",
      "Iteration 45078 => Loss: 44.41813974829706523906\n",
      "Iteration 45079 => Loss: 44.41799158591372531646\n",
      "Iteration 45080 => Loss: 44.41784342469314594837\n",
      "Iteration 45081 => Loss: 44.41769526463531292393\n",
      "Iteration 45082 => Loss: 44.41754710574025466485\n",
      "Iteration 45083 => Loss: 44.41739894800792853857\n",
      "Iteration 45084 => Loss: 44.41725079143834165052\n",
      "Iteration 45085 => Loss: 44.41710263603148689526\n",
      "Iteration 45086 => Loss: 44.41695448178732874567\n",
      "Iteration 45087 => Loss: 44.41680632870588141259\n",
      "Iteration 45088 => Loss: 44.41665817678713068517\n",
      "Iteration 45089 => Loss: 44.41651002603109787970\n",
      "Iteration 45090 => Loss: 44.41636187643771904732\n",
      "Iteration 45091 => Loss: 44.41621372800701550432\n",
      "Iteration 45092 => Loss: 44.41606558073895882899\n",
      "Iteration 45093 => Loss: 44.41591743463357744304\n",
      "Iteration 45094 => Loss: 44.41576928969081450305\n",
      "Iteration 45095 => Loss: 44.41562114591070553615\n",
      "Iteration 45096 => Loss: 44.41547300329322212065\n",
      "Iteration 45097 => Loss: 44.41532486183832872939\n",
      "Iteration 45098 => Loss: 44.41517672154606799495\n",
      "Iteration 45099 => Loss: 44.41502858241639017933\n",
      "Iteration 45100 => Loss: 44.41488044444930238797\n",
      "Iteration 45101 => Loss: 44.41473230764480462085\n",
      "Iteration 45102 => Loss: 44.41458417200286845627\n",
      "Iteration 45103 => Loss: 44.41443603752349389424\n",
      "Iteration 45104 => Loss: 44.41428790420667382932\n",
      "Iteration 45105 => Loss: 44.41413977205237273438\n",
      "Iteration 45106 => Loss: 44.41399164106062613655\n",
      "Iteration 45107 => Loss: 44.41384351123141271955\n",
      "Iteration 45108 => Loss: 44.41369538256471116711\n",
      "Iteration 45109 => Loss: 44.41354725506050726835\n",
      "Iteration 45110 => Loss: 44.41339912871878681244\n",
      "Iteration 45111 => Loss: 44.41325100353959243193\n",
      "Iteration 45112 => Loss: 44.41310287952283175628\n",
      "Iteration 45113 => Loss: 44.41295475666855452346\n",
      "Iteration 45114 => Loss: 44.41280663497675362805\n",
      "Iteration 45115 => Loss: 44.41265851444739354292\n",
      "Iteration 45116 => Loss: 44.41251039508047426807\n",
      "Iteration 45117 => Loss: 44.41236227687599580349\n",
      "Iteration 45118 => Loss: 44.41221415983393683291\n",
      "Iteration 45119 => Loss: 44.41206604395429025089\n",
      "Iteration 45120 => Loss: 44.41191792923705605745\n",
      "Iteration 45121 => Loss: 44.41176981568221293628\n",
      "Iteration 45122 => Loss: 44.41162170328976088740\n",
      "Iteration 45123 => Loss: 44.41147359205968569995\n",
      "Iteration 45124 => Loss: 44.41132548199197316308\n",
      "Iteration 45125 => Loss: 44.41117737308660906592\n",
      "Iteration 45126 => Loss: 44.41102926534361472477\n",
      "Iteration 45127 => Loss: 44.41088115876297592877\n",
      "Iteration 45128 => Loss: 44.41073305334465715077\n",
      "Iteration 45129 => Loss: 44.41058494908865839079\n",
      "Iteration 45130 => Loss: 44.41043684599495833254\n",
      "Iteration 45131 => Loss: 44.41028874406358539773\n",
      "Iteration 45132 => Loss: 44.41014064329450405921\n",
      "Iteration 45133 => Loss: 44.40999254368772142243\n",
      "Iteration 45134 => Loss: 44.40984444524318774938\n",
      "Iteration 45135 => Loss: 44.40969634796093856721\n",
      "Iteration 45136 => Loss: 44.40954825184095255963\n",
      "Iteration 45137 => Loss: 44.40940015688320130494\n",
      "Iteration 45138 => Loss: 44.40925206308769901398\n",
      "Iteration 45139 => Loss: 44.40910397045443858133\n",
      "Iteration 45140 => Loss: 44.40895587898341290156\n",
      "Iteration 45141 => Loss: 44.40880778867457223669\n",
      "Iteration 45142 => Loss: 44.40865969952795211384\n",
      "Iteration 45143 => Loss: 44.40851161154350990046\n",
      "Iteration 45144 => Loss: 44.40836352472128822910\n",
      "Iteration 45145 => Loss: 44.40821543906122315093\n",
      "Iteration 45146 => Loss: 44.40806735456331466594\n",
      "Iteration 45147 => Loss: 44.40791927122758409041\n",
      "Iteration 45148 => Loss: 44.40777118905399589721\n",
      "Iteration 45149 => Loss: 44.40762310804254298091\n",
      "Iteration 45150 => Loss: 44.40747502819323244694\n",
      "Iteration 45151 => Loss: 44.40732694950605008444\n",
      "Iteration 45152 => Loss: 44.40717887198097457713\n",
      "Iteration 45153 => Loss: 44.40703079561801303043\n",
      "Iteration 45154 => Loss: 44.40688272041713702265\n",
      "Iteration 45155 => Loss: 44.40673464637833944835\n",
      "Iteration 45156 => Loss: 44.40658657350163451838\n",
      "Iteration 45157 => Loss: 44.40643850178697960018\n",
      "Iteration 45158 => Loss: 44.40629043123439601004\n",
      "Iteration 45159 => Loss: 44.40614236184386953710\n",
      "Iteration 45160 => Loss: 44.40599429361537175964\n",
      "Iteration 45161 => Loss: 44.40584622654892399396\n",
      "Iteration 45162 => Loss: 44.40569816064447650206\n",
      "Iteration 45163 => Loss: 44.40555009590205770564\n",
      "Iteration 45164 => Loss: 44.40540203232162497216\n",
      "Iteration 45165 => Loss: 44.40525396990320672330\n",
      "Iteration 45166 => Loss: 44.40510590864675322109\n",
      "Iteration 45167 => Loss: 44.40495784855229288723\n",
      "Iteration 45168 => Loss: 44.40480978961979019459\n",
      "Iteration 45169 => Loss: 44.40466173184926645945\n",
      "Iteration 45170 => Loss: 44.40451367524066483838\n",
      "Iteration 45171 => Loss: 44.40436561979402085854\n",
      "Iteration 45172 => Loss: 44.40421756550930609819\n",
      "Iteration 45173 => Loss: 44.40406951238649924107\n",
      "Iteration 45174 => Loss: 44.40392146042563581432\n",
      "Iteration 45175 => Loss: 44.40377340962665186908\n",
      "Iteration 45176 => Loss: 44.40362535998956872163\n",
      "Iteration 45177 => Loss: 44.40347731151437926655\n",
      "Iteration 45178 => Loss: 44.40332926420105508214\n",
      "Iteration 45179 => Loss: 44.40318121804959616838\n",
      "Iteration 45180 => Loss: 44.40303317306001673614\n",
      "Iteration 45181 => Loss: 44.40288512923226704743\n",
      "Iteration 45182 => Loss: 44.40273708656636131309\n",
      "Iteration 45183 => Loss: 44.40258904506229953313\n",
      "Iteration 45184 => Loss: 44.40244100472004618041\n",
      "Iteration 45185 => Loss: 44.40229296553959414950\n",
      "Iteration 45186 => Loss: 44.40214492752095765127\n",
      "Iteration 45187 => Loss: 44.40199689066412247485\n",
      "Iteration 45188 => Loss: 44.40184885496906730395\n",
      "Iteration 45189 => Loss: 44.40170082043579213860\n",
      "Iteration 45190 => Loss: 44.40155278706427566249\n",
      "Iteration 45191 => Loss: 44.40140475485453208648\n",
      "Iteration 45192 => Loss: 44.40125672380651167259\n",
      "Iteration 45193 => Loss: 44.40110869392026415881\n",
      "Iteration 45194 => Loss: 44.40096066519571849085\n",
      "Iteration 45195 => Loss: 44.40081263763291730129\n",
      "Iteration 45196 => Loss: 44.40066461123182506299\n",
      "Iteration 45197 => Loss: 44.40051658599241335423\n",
      "Iteration 45198 => Loss: 44.40036856191471770217\n",
      "Iteration 45199 => Loss: 44.40022053899870968507\n",
      "Iteration 45200 => Loss: 44.40007251724434667040\n",
      "Iteration 45201 => Loss: 44.39992449665169971240\n",
      "Iteration 45202 => Loss: 44.39977647722066222968\n",
      "Iteration 45203 => Loss: 44.39962845895130527651\n",
      "Iteration 45204 => Loss: 44.39948044184357200947\n",
      "Iteration 45205 => Loss: 44.39933242589746953399\n",
      "Iteration 45206 => Loss: 44.39918441111300495550\n",
      "Iteration 45207 => Loss: 44.39903639749013564142\n",
      "Iteration 45208 => Loss: 44.39888838502887580262\n",
      "Iteration 45209 => Loss: 44.39874037372922543909\n",
      "Iteration 45210 => Loss: 44.39859236359112770742\n",
      "Iteration 45211 => Loss: 44.39844435461462524017\n",
      "Iteration 45212 => Loss: 44.39829634679968961564\n",
      "Iteration 45213 => Loss: 44.39814834014630662296\n",
      "Iteration 45214 => Loss: 44.39800033465448336756\n",
      "Iteration 45215 => Loss: 44.39785233032418432231\n",
      "Iteration 45216 => Loss: 44.39770432715541659263\n",
      "Iteration 45217 => Loss: 44.39755632514817307310\n",
      "Iteration 45218 => Loss: 44.39740832430243955287\n",
      "Iteration 45219 => Loss: 44.39726032461820892649\n",
      "Iteration 45220 => Loss: 44.39711232609547408856\n",
      "Iteration 45221 => Loss: 44.39696432873422793364\n",
      "Iteration 45222 => Loss: 44.39681633253444204001\n",
      "Iteration 45223 => Loss: 44.39666833749614482940\n",
      "Iteration 45224 => Loss: 44.39652034361930788009\n",
      "Iteration 45225 => Loss: 44.39637235090388855951\n",
      "Iteration 45226 => Loss: 44.39622435934992950024\n",
      "Iteration 45227 => Loss: 44.39607636895739517513\n",
      "Iteration 45228 => Loss: 44.39592837972629268961\n",
      "Iteration 45229 => Loss: 44.39578039165657230569\n",
      "Iteration 45230 => Loss: 44.39563240474829086679\n",
      "Iteration 45231 => Loss: 44.39548441900137731864\n",
      "Iteration 45232 => Loss: 44.39533643441587429379\n",
      "Iteration 45233 => Loss: 44.39518845099171784341\n",
      "Iteration 45234 => Loss: 44.39504046872894349463\n",
      "Iteration 45235 => Loss: 44.39489248762752993116\n",
      "Iteration 45236 => Loss: 44.39474450768742741502\n",
      "Iteration 45237 => Loss: 44.39459652890871410591\n",
      "Iteration 45238 => Loss: 44.39444855129130473870\n",
      "Iteration 45239 => Loss: 44.39430057483522062967\n",
      "Iteration 45240 => Loss: 44.39415259954044756796\n",
      "Iteration 45241 => Loss: 44.39400462540695713187\n",
      "Iteration 45242 => Loss: 44.39385665243478484854\n",
      "Iteration 45243 => Loss: 44.39370868062389519082\n",
      "Iteration 45244 => Loss: 44.39356070997427394786\n",
      "Iteration 45245 => Loss: 44.39341274048592822510\n",
      "Iteration 45246 => Loss: 44.39326477215884381167\n",
      "Iteration 45247 => Loss: 44.39311680499297807501\n",
      "Iteration 45248 => Loss: 44.39296883898836654225\n",
      "Iteration 45249 => Loss: 44.39282087414498789713\n",
      "Iteration 45250 => Loss: 44.39267291046283503420\n",
      "Iteration 45251 => Loss: 44.39252494794188663718\n",
      "Iteration 45252 => Loss: 44.39237698658213560066\n",
      "Iteration 45253 => Loss: 44.39222902638358903005\n",
      "Iteration 45254 => Loss: 44.39208106734621139822\n",
      "Iteration 45255 => Loss: 44.39193310947000981059\n",
      "Iteration 45256 => Loss: 44.39178515275498426718\n",
      "Iteration 45257 => Loss: 44.39163719720112055711\n",
      "Iteration 45258 => Loss: 44.39148924280837604783\n",
      "Iteration 45259 => Loss: 44.39134128957678626648\n",
      "Iteration 45260 => Loss: 44.39119333750633700220\n",
      "Iteration 45261 => Loss: 44.39104538659699272785\n",
      "Iteration 45262 => Loss: 44.39089743684876765428\n",
      "Iteration 45263 => Loss: 44.39074948826164757065\n",
      "Iteration 45264 => Loss: 44.39060154083560405525\n",
      "Iteration 45265 => Loss: 44.39045359457065842435\n",
      "Iteration 45266 => Loss: 44.39030564946678225624\n",
      "Iteration 45267 => Loss: 44.39015770552398265636\n",
      "Iteration 45268 => Loss: 44.39000976274220278128\n",
      "Iteration 45269 => Loss: 44.38986182112151368528\n",
      "Iteration 45270 => Loss: 44.38971388066183720866\n",
      "Iteration 45271 => Loss: 44.38956594136321598398\n",
      "Iteration 45272 => Loss: 44.38941800322558606240\n",
      "Iteration 45273 => Loss: 44.38927006624898297105\n",
      "Iteration 45274 => Loss: 44.38912213043337828822\n",
      "Iteration 45275 => Loss: 44.38897419577875069763\n",
      "Iteration 45276 => Loss: 44.38882626228512862099\n",
      "Iteration 45277 => Loss: 44.38867832995246942573\n",
      "Iteration 45278 => Loss: 44.38853039878078021729\n",
      "Iteration 45279 => Loss: 44.38838246877003967938\n",
      "Iteration 45280 => Loss: 44.38823453992024781201\n",
      "Iteration 45281 => Loss: 44.38808661223140461516\n",
      "Iteration 45282 => Loss: 44.38793868570348166713\n",
      "Iteration 45283 => Loss: 44.38779076033648607336\n",
      "Iteration 45284 => Loss: 44.38764283613038230669\n",
      "Iteration 45285 => Loss: 44.38749491308519168342\n",
      "Iteration 45286 => Loss: 44.38734699120088578184\n",
      "Iteration 45287 => Loss: 44.38719907047747881279\n",
      "Iteration 45288 => Loss: 44.38705115091493524915\n",
      "Iteration 45289 => Loss: 44.38690323251326219633\n",
      "Iteration 45290 => Loss: 44.38675531527244544350\n",
      "Iteration 45291 => Loss: 44.38660739919247077978\n",
      "Iteration 45292 => Loss: 44.38645948427332399433\n",
      "Iteration 45293 => Loss: 44.38631157051501219257\n",
      "Iteration 45294 => Loss: 44.38616365791752826908\n",
      "Iteration 45295 => Loss: 44.38601574648085090757\n",
      "Iteration 45296 => Loss: 44.38586783620498010805\n",
      "Iteration 45297 => Loss: 44.38571992708989455423\n",
      "Iteration 45298 => Loss: 44.38557201913560845696\n",
      "Iteration 45299 => Loss: 44.38542411234206497284\n",
      "Iteration 45300 => Loss: 44.38527620670928541813\n",
      "Iteration 45301 => Loss: 44.38512830223729110912\n",
      "Iteration 45302 => Loss: 44.38498039892604651868\n",
      "Iteration 45303 => Loss: 44.38483249677550190881\n",
      "Iteration 45304 => Loss: 44.38468459578570701751\n",
      "Iteration 45305 => Loss: 44.38453669595664763392\n",
      "Iteration 45306 => Loss: 44.38438879728825270377\n",
      "Iteration 45307 => Loss: 44.38424089978060749218\n",
      "Iteration 45308 => Loss: 44.38409300343362673402\n",
      "Iteration 45309 => Loss: 44.38394510824733174559\n",
      "Iteration 45310 => Loss: 44.38379721422171542144\n",
      "Iteration 45311 => Loss: 44.38364932135675644531\n",
      "Iteration 45312 => Loss: 44.38350142965245481719\n",
      "Iteration 45313 => Loss: 44.38335353910881053707\n",
      "Iteration 45314 => Loss: 44.38320564972580939411\n",
      "Iteration 45315 => Loss: 44.38305776150340875574\n",
      "Iteration 45316 => Loss: 44.38290987444164414910\n",
      "Iteration 45317 => Loss: 44.38276198854047294162\n",
      "Iteration 45318 => Loss: 44.38261410379993776587\n",
      "Iteration 45319 => Loss: 44.38246622021996756757\n",
      "Iteration 45320 => Loss: 44.38231833780058366301\n",
      "Iteration 45321 => Loss: 44.38217045654177894676\n",
      "Iteration 45322 => Loss: 44.38202257644352499710\n",
      "Iteration 45323 => Loss: 44.38187469750585734118\n",
      "Iteration 45324 => Loss: 44.38172681972870492473\n",
      "Iteration 45325 => Loss: 44.38157894311209616944\n",
      "Iteration 45326 => Loss: 44.38143106765601686448\n",
      "Iteration 45327 => Loss: 44.38128319336044569354\n",
      "Iteration 45328 => Loss: 44.38113532022541818378\n",
      "Iteration 45329 => Loss: 44.38098744825085617549\n",
      "Iteration 45330 => Loss: 44.38083957743679519581\n",
      "Iteration 45331 => Loss: 44.38069170778322103388\n",
      "Iteration 45332 => Loss: 44.38054383929012658427\n",
      "Iteration 45333 => Loss: 44.38039597195749763614\n",
      "Iteration 45334 => Loss: 44.38024810578529866234\n",
      "Iteration 45335 => Loss: 44.38010024077355808458\n",
      "Iteration 45336 => Loss: 44.37995237692227590287\n",
      "Iteration 45337 => Loss: 44.37980451423140948464\n",
      "Iteration 45338 => Loss: 44.37965665270094461903\n",
      "Iteration 45339 => Loss: 44.37950879233090972775\n",
      "Iteration 45340 => Loss: 44.37936093312125507282\n",
      "Iteration 45341 => Loss: 44.37921307507200197051\n",
      "Iteration 45342 => Loss: 44.37906521818313620997\n",
      "Iteration 45343 => Loss: 44.37891736245463647492\n",
      "Iteration 45344 => Loss: 44.37876950788650276536\n",
      "Iteration 45345 => Loss: 44.37862165447872087043\n",
      "Iteration 45346 => Loss: 44.37847380223130500099\n",
      "Iteration 45347 => Loss: 44.37832595114420541904\n",
      "Iteration 45348 => Loss: 44.37817810121743633545\n",
      "Iteration 45349 => Loss: 44.37803025245099064477\n",
      "Iteration 45350 => Loss: 44.37788240484483281989\n",
      "Iteration 45351 => Loss: 44.37773455839899838793\n",
      "Iteration 45352 => Loss: 44.37758671311344471633\n",
      "Iteration 45353 => Loss: 44.37743886898817180509\n",
      "Iteration 45354 => Loss: 44.37729102602316544335\n",
      "Iteration 45355 => Loss: 44.37714318421845405283\n",
      "Iteration 45356 => Loss: 44.37699534357397368467\n",
      "Iteration 45357 => Loss: 44.37684750408974565516\n",
      "Iteration 45358 => Loss: 44.37669966576575575345\n",
      "Iteration 45359 => Loss: 44.37655182860198266326\n",
      "Iteration 45360 => Loss: 44.37640399259841217372\n",
      "Iteration 45361 => Loss: 44.37625615775509402283\n",
      "Iteration 45362 => Loss: 44.37610832407195005089\n",
      "Iteration 45363 => Loss: 44.37596049154900867961\n",
      "Iteration 45364 => Loss: 44.37581266018624859271\n",
      "Iteration 45365 => Loss: 44.37566482998364847390\n",
      "Iteration 45366 => Loss: 44.37551700094120832318\n",
      "Iteration 45367 => Loss: 44.37536917305894235142\n",
      "Iteration 45368 => Loss: 44.37522134633681503146\n",
      "Iteration 45369 => Loss: 44.37507352077481215247\n",
      "Iteration 45370 => Loss: 44.37492569637294792528\n",
      "Iteration 45371 => Loss: 44.37477787313120103363\n",
      "Iteration 45372 => Loss: 44.37463005104955726665\n",
      "Iteration 45373 => Loss: 44.37448223012802372978\n",
      "Iteration 45374 => Loss: 44.37433441036658621215\n",
      "Iteration 45375 => Loss: 44.37418659176521629206\n",
      "Iteration 45376 => Loss: 44.37403877432389975866\n",
      "Iteration 45377 => Loss: 44.37389095804268634993\n",
      "Iteration 45378 => Loss: 44.37374314292151922245\n",
      "Iteration 45379 => Loss: 44.37359532896037705996\n",
      "Iteration 45380 => Loss: 44.37344751615928117872\n",
      "Iteration 45381 => Loss: 44.37329970451821026245\n",
      "Iteration 45382 => Loss: 44.37315189403716431116\n",
      "Iteration 45383 => Loss: 44.37300408471612911399\n",
      "Iteration 45384 => Loss: 44.37285627655508335465\n",
      "Iteration 45385 => Loss: 44.37270846955403413858\n",
      "Iteration 45386 => Loss: 44.37256066371293883321\n",
      "Iteration 45387 => Loss: 44.37241285903187559825\n",
      "Iteration 45388 => Loss: 44.37226505551073785227\n",
      "Iteration 45389 => Loss: 44.37211725314953980615\n",
      "Iteration 45390 => Loss: 44.37196945194833119785\n",
      "Iteration 45391 => Loss: 44.37182165190701965685\n",
      "Iteration 45392 => Loss: 44.37167385302564781568\n",
      "Iteration 45393 => Loss: 44.37152605530421567437\n",
      "Iteration 45394 => Loss: 44.37137825874265928405\n",
      "Iteration 45395 => Loss: 44.37123046334100706645\n",
      "Iteration 45396 => Loss: 44.37108266909925902155\n",
      "Iteration 45397 => Loss: 44.37093487601738672765\n",
      "Iteration 45398 => Loss: 44.37078708409539018476\n",
      "Iteration 45399 => Loss: 44.37063929333324097115\n",
      "Iteration 45400 => Loss: 44.37049150373095329769\n",
      "Iteration 45401 => Loss: 44.37034371528852716438\n",
      "Iteration 45402 => Loss: 44.37019592800592704407\n",
      "Iteration 45403 => Loss: 44.37004814188314583134\n",
      "Iteration 45404 => Loss: 44.36990035692019063163\n",
      "Iteration 45405 => Loss: 44.36975257311703302321\n",
      "Iteration 45406 => Loss: 44.36960479047370142780\n",
      "Iteration 45407 => Loss: 44.36945700899013900198\n",
      "Iteration 45408 => Loss: 44.36930922866635285118\n",
      "Iteration 45409 => Loss: 44.36916144950235008082\n",
      "Iteration 45410 => Loss: 44.36901367149810937462\n",
      "Iteration 45411 => Loss: 44.36886589465362362716\n",
      "Iteration 45412 => Loss: 44.36871811896886441673\n",
      "Iteration 45413 => Loss: 44.36857034444386727046\n",
      "Iteration 45414 => Loss: 44.36842257107858245035\n",
      "Iteration 45415 => Loss: 44.36827479887302416728\n",
      "Iteration 45416 => Loss: 44.36812702782716399952\n",
      "Iteration 45417 => Loss: 44.36797925794100905250\n",
      "Iteration 45418 => Loss: 44.36783148921455932623\n",
      "Iteration 45419 => Loss: 44.36768372164775087185\n",
      "Iteration 45420 => Loss: 44.36753595524064763822\n",
      "Iteration 45421 => Loss: 44.36738818999321409819\n",
      "Iteration 45422 => Loss: 44.36724042590540761921\n",
      "Iteration 45423 => Loss: 44.36709266297724951755\n",
      "Iteration 45424 => Loss: 44.36694490120873268779\n",
      "Iteration 45425 => Loss: 44.36679714059985002450\n",
      "Iteration 45426 => Loss: 44.36664938115058021140\n",
      "Iteration 45427 => Loss: 44.36650162286091614305\n",
      "Iteration 45428 => Loss: 44.36635386573085781947\n",
      "Iteration 45429 => Loss: 44.36620610976037681894\n",
      "Iteration 45430 => Loss: 44.36605835494948024689\n",
      "Iteration 45431 => Loss: 44.36591060129818231417\n",
      "Iteration 45432 => Loss: 44.36576284880642617736\n",
      "Iteration 45433 => Loss: 44.36561509747420473104\n",
      "Iteration 45434 => Loss: 44.36546734730154639692\n",
      "Iteration 45435 => Loss: 44.36531959828842275328\n",
      "Iteration 45436 => Loss: 44.36517185043482669471\n",
      "Iteration 45437 => Loss: 44.36502410374074401034\n",
      "Iteration 45438 => Loss: 44.36487635820618180560\n",
      "Iteration 45439 => Loss: 44.36472861383109744793\n",
      "Iteration 45440 => Loss: 44.36458087061552646446\n",
      "Iteration 45441 => Loss: 44.36443312855943332806\n",
      "Iteration 45442 => Loss: 44.36428538766278251160\n",
      "Iteration 45443 => Loss: 44.36413764792563796391\n",
      "Iteration 45444 => Loss: 44.36398990934791441987\n",
      "Iteration 45445 => Loss: 44.36384217192964030119\n",
      "Iteration 45446 => Loss: 44.36369443567080139701\n",
      "Iteration 45447 => Loss: 44.36354670057140481276\n",
      "Iteration 45448 => Loss: 44.36339896663140791588\n",
      "Iteration 45449 => Loss: 44.36325123385084623351\n",
      "Iteration 45450 => Loss: 44.36310350222966292222\n",
      "Iteration 45451 => Loss: 44.36295577176786508744\n",
      "Iteration 45452 => Loss: 44.36280804246545983460\n",
      "Iteration 45453 => Loss: 44.36266031432241163657\n",
      "Iteration 45454 => Loss: 44.36251258733873470419\n",
      "Iteration 45455 => Loss: 44.36236486151442903747\n",
      "Iteration 45456 => Loss: 44.36221713684943779299\n",
      "Iteration 45457 => Loss: 44.36206941334378939246\n",
      "Iteration 45458 => Loss: 44.36192169099748383587\n",
      "Iteration 45459 => Loss: 44.36177396981047138524\n",
      "Iteration 45460 => Loss: 44.36162624978279467314\n",
      "Iteration 45461 => Loss: 44.36147853091438975071\n",
      "Iteration 45462 => Loss: 44.36133081320528503966\n",
      "Iteration 45463 => Loss: 44.36118309665547343457\n",
      "Iteration 45464 => Loss: 44.36103538126492651372\n",
      "Iteration 45465 => Loss: 44.36088766703363717170\n",
      "Iteration 45466 => Loss: 44.36073995396160540849\n",
      "Iteration 45467 => Loss: 44.36059224204881701326\n",
      "Iteration 45468 => Loss: 44.36044453129525066970\n",
      "Iteration 45469 => Loss: 44.36029682170093479954\n",
      "Iteration 45470 => Loss: 44.36014911326581966478\n",
      "Iteration 45471 => Loss: 44.36000140598992658170\n",
      "Iteration 45472 => Loss: 44.35985369987321291774\n",
      "Iteration 45473 => Loss: 44.35970599491568577832\n",
      "Iteration 45474 => Loss: 44.35955829111736647974\n",
      "Iteration 45475 => Loss: 44.35941058847822660027\n",
      "Iteration 45476 => Loss: 44.35926288699819508565\n",
      "Iteration 45477 => Loss: 44.35911518667735720101\n",
      "Iteration 45478 => Loss: 44.35896748751565610291\n",
      "Iteration 45479 => Loss: 44.35881978951310600223\n",
      "Iteration 45480 => Loss: 44.35867209266965716097\n",
      "Iteration 45481 => Loss: 44.35852439698533800083\n",
      "Iteration 45482 => Loss: 44.35837670246012010011\n",
      "Iteration 45483 => Loss: 44.35822900909400345881\n",
      "Iteration 45484 => Loss: 44.35808131688697386608\n",
      "Iteration 45485 => Loss: 44.35793362583903132190\n",
      "Iteration 45486 => Loss: 44.35778593595015451001\n",
      "Iteration 45487 => Loss: 44.35763824722034343040\n",
      "Iteration 45488 => Loss: 44.35749055964959097764\n",
      "Iteration 45489 => Loss: 44.35734287323786873003\n",
      "Iteration 45490 => Loss: 44.35719518798518379299\n",
      "Iteration 45491 => Loss: 44.35704750389153616652\n",
      "Iteration 45492 => Loss: 44.35689982095690453434\n",
      "Iteration 45493 => Loss: 44.35675213918126758017\n",
      "Iteration 45494 => Loss: 44.35660445856464662029\n",
      "Iteration 45495 => Loss: 44.35645677910702033842\n",
      "Iteration 45496 => Loss: 44.35630910080835320741\n",
      "Iteration 45497 => Loss: 44.35616142366866654356\n",
      "Iteration 45498 => Loss: 44.35601374768793192516\n",
      "Iteration 45499 => Loss: 44.35586607286616356305\n",
      "Iteration 45500 => Loss: 44.35571839920334014096\n",
      "Iteration 45501 => Loss: 44.35557072669944744803\n",
      "Iteration 45502 => Loss: 44.35542305535448548426\n",
      "Iteration 45503 => Loss: 44.35527538516844003880\n",
      "Iteration 45504 => Loss: 44.35512771614128979536\n",
      "Iteration 45505 => Loss: 44.35498004827304896480\n",
      "Iteration 45506 => Loss: 44.35483238156369623084\n",
      "Iteration 45507 => Loss: 44.35468471601322448805\n",
      "Iteration 45508 => Loss: 44.35453705162162663100\n",
      "Iteration 45509 => Loss: 44.35438938838888134342\n",
      "Iteration 45510 => Loss: 44.35424172631499573072\n",
      "Iteration 45511 => Loss: 44.35409406539994137120\n",
      "Iteration 45512 => Loss: 44.35394640564375379199\n",
      "Iteration 45513 => Loss: 44.35379874704639036054\n",
      "Iteration 45514 => Loss: 44.35365108960779423342\n",
      "Iteration 45515 => Loss: 44.35350343332805778118\n",
      "Iteration 45516 => Loss: 44.35335577820708152785\n",
      "Iteration 45517 => Loss: 44.35320812424491521142\n",
      "Iteration 45518 => Loss: 44.35306047144153751560\n",
      "Iteration 45519 => Loss: 44.35291281979692712412\n",
      "Iteration 45520 => Loss: 44.35276516931106272068\n",
      "Iteration 45521 => Loss: 44.35261751998396562158\n",
      "Iteration 45522 => Loss: 44.35246987181561451052\n",
      "Iteration 45523 => Loss: 44.35232222480599517667\n",
      "Iteration 45524 => Loss: 44.35217457895511472543\n",
      "Iteration 45525 => Loss: 44.35202693426290920797\n",
      "Iteration 45526 => Loss: 44.35187929072946388942\n",
      "Iteration 45527 => Loss: 44.35173164835468639922\n",
      "Iteration 45528 => Loss: 44.35158400713861226450\n",
      "Iteration 45529 => Loss: 44.35143636708119174727\n",
      "Iteration 45530 => Loss: 44.35128872818247458554\n",
      "Iteration 45531 => Loss: 44.35114109044241814672\n",
      "Iteration 45532 => Loss: 44.35099345386099400912\n",
      "Iteration 45533 => Loss: 44.35084581843822348901\n",
      "Iteration 45534 => Loss: 44.35069818417408527012\n",
      "Iteration 45535 => Loss: 44.35055055106858645786\n",
      "Iteration 45536 => Loss: 44.35040291912169152511\n",
      "Iteration 45537 => Loss: 44.35025528833340757728\n",
      "Iteration 45538 => Loss: 44.35010765870370619268\n",
      "Iteration 45539 => Loss: 44.34996003023260868758\n",
      "Iteration 45540 => Loss: 44.34981240292009374571\n",
      "Iteration 45541 => Loss: 44.34966477676615426162\n",
      "Iteration 45542 => Loss: 44.34951715177077602448\n",
      "Iteration 45543 => Loss: 44.34936952793394482342\n",
      "Iteration 45544 => Loss: 44.34922190525563223673\n",
      "Iteration 45545 => Loss: 44.34907428373589510784\n",
      "Iteration 45546 => Loss: 44.34892666337468369875\n",
      "Iteration 45547 => Loss: 44.34877904417199090403\n",
      "Iteration 45548 => Loss: 44.34863142612778830198\n",
      "Iteration 45549 => Loss: 44.34848380924207589260\n",
      "Iteration 45550 => Loss: 44.34833619351485367588\n",
      "Iteration 45551 => Loss: 44.34818857894612875725\n",
      "Iteration 45552 => Loss: 44.34804096553587982044\n",
      "Iteration 45553 => Loss: 44.34789335328407133829\n",
      "Iteration 45554 => Loss: 44.34774574219073173253\n",
      "Iteration 45555 => Loss: 44.34759813225583968688\n",
      "Iteration 45556 => Loss: 44.34745052347935256876\n",
      "Iteration 45557 => Loss: 44.34730291586132722159\n",
      "Iteration 45558 => Loss: 44.34715530940171390739\n",
      "Iteration 45559 => Loss: 44.34700770410049841530\n",
      "Iteration 45560 => Loss: 44.34686009995768074532\n",
      "Iteration 45561 => Loss: 44.34671249697323958117\n",
      "Iteration 45562 => Loss: 44.34656489514721044998\n",
      "Iteration 45563 => Loss: 44.34641729447954361376\n",
      "Iteration 45564 => Loss: 44.34626969497021065081\n",
      "Iteration 45565 => Loss: 44.34612209661925419368\n",
      "Iteration 45566 => Loss: 44.34597449942663871525\n",
      "Iteration 45567 => Loss: 44.34582690339237132093\n",
      "Iteration 45568 => Loss: 44.34567930851641648360\n",
      "Iteration 45569 => Loss: 44.34553171479877420325\n",
      "Iteration 45570 => Loss: 44.34538412223945158530\n",
      "Iteration 45571 => Loss: 44.34523653083841310263\n",
      "Iteration 45572 => Loss: 44.34508894059566586066\n",
      "Iteration 45573 => Loss: 44.34494135151120985938\n",
      "Iteration 45574 => Loss: 44.34479376358501667710\n",
      "Iteration 45575 => Loss: 44.34464617681709341923\n",
      "Iteration 45576 => Loss: 44.34449859120741876950\n",
      "Iteration 45577 => Loss: 44.34435100675597851705\n",
      "Iteration 45578 => Loss: 44.34420342346279397816\n",
      "Iteration 45579 => Loss: 44.34405584132782252027\n",
      "Iteration 45580 => Loss: 44.34390826035107124881\n",
      "Iteration 45581 => Loss: 44.34376068053252595291\n",
      "Iteration 45582 => Loss: 44.34361310187216531631\n",
      "Iteration 45583 => Loss: 44.34346552437003197156\n",
      "Iteration 45584 => Loss: 44.34331794802605486439\n",
      "Iteration 45585 => Loss: 44.34317037284024110022\n",
      "Iteration 45586 => Loss: 44.34302279881260488992\n",
      "Iteration 45587 => Loss: 44.34287522594311781177\n",
      "Iteration 45588 => Loss: 44.34272765423176565491\n",
      "Iteration 45589 => Loss: 44.34258008367856263021\n",
      "Iteration 45590 => Loss: 44.34243251428348031595\n",
      "Iteration 45591 => Loss: 44.34228494604651871214\n",
      "Iteration 45592 => Loss: 44.34213737896764939705\n",
      "Iteration 45593 => Loss: 44.34198981304688658156\n",
      "Iteration 45594 => Loss: 44.34184224828420894937\n",
      "Iteration 45595 => Loss: 44.34169468467962360592\n",
      "Iteration 45596 => Loss: 44.34154712223310923491\n",
      "Iteration 45597 => Loss: 44.34139956094465162550\n",
      "Iteration 45598 => Loss: 44.34125200081425077769\n",
      "Iteration 45599 => Loss: 44.34110444184188537520\n",
      "Iteration 45600 => Loss: 44.34095688402756252344\n",
      "Iteration 45601 => Loss: 44.34080932737126801158\n",
      "Iteration 45602 => Loss: 44.34066177187298052331\n",
      "Iteration 45603 => Loss: 44.34051421753270005865\n",
      "Iteration 45604 => Loss: 44.34036666435043372303\n",
      "Iteration 45605 => Loss: 44.34021911232613888387\n",
      "Iteration 45606 => Loss: 44.34007156145982264661\n",
      "Iteration 45607 => Loss: 44.33992401175149922210\n",
      "Iteration 45608 => Loss: 44.33977646320114018863\n",
      "Iteration 45609 => Loss: 44.33962891580870291364\n",
      "Iteration 45610 => Loss: 44.33948136957425845139\n",
      "Iteration 45611 => Loss: 44.33933382449770022049\n",
      "Iteration 45612 => Loss: 44.33918628057909216977\n",
      "Iteration 45613 => Loss: 44.33903873781839166668\n",
      "Iteration 45614 => Loss: 44.33889119621559160578\n",
      "Iteration 45615 => Loss: 44.33874365577071330335\n",
      "Iteration 45616 => Loss: 44.33859611648370702142\n",
      "Iteration 45617 => Loss: 44.33844857835460118167\n",
      "Iteration 45618 => Loss: 44.33830104138335315156\n",
      "Iteration 45619 => Loss: 44.33815350556996293108\n",
      "Iteration 45620 => Loss: 44.33800597091441630937\n",
      "Iteration 45621 => Loss: 44.33785843741673460272\n",
      "Iteration 45622 => Loss: 44.33771090507688228399\n",
      "Iteration 45623 => Loss: 44.33756337389485224776\n",
      "Iteration 45624 => Loss: 44.33741584387067291573\n",
      "Iteration 45625 => Loss: 44.33726831500423770649\n",
      "Iteration 45626 => Loss: 44.33712078729562477974\n",
      "Iteration 45627 => Loss: 44.33697326074481992464\n",
      "Iteration 45628 => Loss: 44.33682573535179471946\n",
      "Iteration 45629 => Loss: 44.33667821111654205879\n",
      "Iteration 45630 => Loss: 44.33653068803904773176\n",
      "Iteration 45631 => Loss: 44.33638316611929042210\n",
      "Iteration 45632 => Loss: 44.33623564535729855152\n",
      "Iteration 45633 => Loss: 44.33608812575302948744\n",
      "Iteration 45634 => Loss: 44.33594060730647612445\n",
      "Iteration 45635 => Loss: 44.33579309001766688425\n",
      "Iteration 45636 => Loss: 44.33564557388655202885\n",
      "Iteration 45637 => Loss: 44.33549805891311734740\n",
      "Iteration 45638 => Loss: 44.33535054509739126161\n",
      "Iteration 45639 => Loss: 44.33520303243933824433\n",
      "Iteration 45640 => Loss: 44.33505552093897250643\n",
      "Iteration 45641 => Loss: 44.33490801059627983705\n",
      "Iteration 45642 => Loss: 44.33476050141121049819\n",
      "Iteration 45643 => Loss: 44.33461299338378580615\n",
      "Iteration 45644 => Loss: 44.33446548651400576091\n",
      "Iteration 45645 => Loss: 44.33431798080186325706\n",
      "Iteration 45646 => Loss: 44.33417047624731566202\n",
      "Iteration 45647 => Loss: 44.33402297285039850294\n",
      "Iteration 45648 => Loss: 44.33387547061107625268\n",
      "Iteration 45649 => Loss: 44.33372796952931338410\n",
      "Iteration 45650 => Loss: 44.33358046960516674062\n",
      "Iteration 45651 => Loss: 44.33343297083858658425\n",
      "Iteration 45652 => Loss: 44.33328547322956580956\n",
      "Iteration 45653 => Loss: 44.33313797677809020570\n",
      "Iteration 45654 => Loss: 44.33299048148417398352\n",
      "Iteration 45655 => Loss: 44.33284298734776029960\n",
      "Iteration 45656 => Loss: 44.33269549436890599736\n",
      "Iteration 45657 => Loss: 44.33254800254755423339\n",
      "Iteration 45658 => Loss: 44.33240051188371211310\n",
      "Iteration 45659 => Loss: 44.33225302237738674194\n",
      "Iteration 45660 => Loss: 44.33210553402852838190\n",
      "Iteration 45661 => Loss: 44.33195804683714413841\n",
      "Iteration 45662 => Loss: 44.33181056080326243318\n",
      "Iteration 45663 => Loss: 44.33166307592681221195\n",
      "Iteration 45664 => Loss: 44.33151559220782900184\n",
      "Iteration 45665 => Loss: 44.33136810964629148657\n",
      "Iteration 45666 => Loss: 44.33122062824218545529\n",
      "Iteration 45667 => Loss: 44.33107314799551801343\n",
      "Iteration 45668 => Loss: 44.33092566890624652842\n",
      "Iteration 45669 => Loss: 44.33077819097441363283\n",
      "Iteration 45670 => Loss: 44.33063071419995537781\n",
      "Iteration 45671 => Loss: 44.33048323858290018507\n",
      "Iteration 45672 => Loss: 44.33033576412320542204\n",
      "Iteration 45673 => Loss: 44.33018829082089951044\n",
      "Iteration 45674 => Loss: 44.33004081867595402855\n",
      "Iteration 45675 => Loss: 44.32989334768835476552\n",
      "Iteration 45676 => Loss: 44.32974587785810882679\n",
      "Iteration 45677 => Loss: 44.32959840918519489605\n",
      "Iteration 45678 => Loss: 44.32945094166962007876\n",
      "Iteration 45679 => Loss: 44.32930347531134174233\n",
      "Iteration 45680 => Loss: 44.32915601011039541390\n",
      "Iteration 45681 => Loss: 44.32900854606671003921\n",
      "Iteration 45682 => Loss: 44.32886108318034246167\n",
      "Iteration 45683 => Loss: 44.32871362145125004872\n",
      "Iteration 45684 => Loss: 44.32856616087945411664\n",
      "Iteration 45685 => Loss: 44.32841870146488361115\n",
      "Iteration 45686 => Loss: 44.32827124320758116482\n",
      "Iteration 45687 => Loss: 44.32812378610752546138\n",
      "Iteration 45688 => Loss: 44.32797633016469518452\n",
      "Iteration 45689 => Loss: 44.32782887537911165055\n",
      "Iteration 45690 => Loss: 44.32768142175071801603\n",
      "Iteration 45691 => Loss: 44.32753396927954980811\n",
      "Iteration 45692 => Loss: 44.32738651796557860507\n",
      "Iteration 45693 => Loss: 44.32723906780881861778\n",
      "Iteration 45694 => Loss: 44.32709161880921300281\n",
      "Iteration 45695 => Loss: 44.32694417096677597101\n",
      "Iteration 45696 => Loss: 44.32679672428151462782\n",
      "Iteration 45697 => Loss: 44.32664927875338634067\n",
      "Iteration 45698 => Loss: 44.32650183438243374212\n",
      "Iteration 45699 => Loss: 44.32635439116859998876\n",
      "Iteration 45700 => Loss: 44.32620694911189218601\n",
      "Iteration 45701 => Loss: 44.32605950821231033387\n",
      "Iteration 45702 => Loss: 44.32591206846984732692\n",
      "Iteration 45703 => Loss: 44.32576462988446053259\n",
      "Iteration 45704 => Loss: 44.32561719245617126717\n",
      "Iteration 45705 => Loss: 44.32546975618495821436\n",
      "Iteration 45706 => Loss: 44.32532232107080716332\n",
      "Iteration 45707 => Loss: 44.32517488711374653576\n",
      "Iteration 45708 => Loss: 44.32502745431372659368\n",
      "Iteration 45709 => Loss: 44.32488002267075444252\n",
      "Iteration 45710 => Loss: 44.32473259218482297683\n",
      "Iteration 45711 => Loss: 44.32458516285589666950\n",
      "Iteration 45712 => Loss: 44.32443773468401815308\n",
      "Iteration 45713 => Loss: 44.32429030766912347872\n",
      "Iteration 45714 => Loss: 44.32414288181124817356\n",
      "Iteration 45715 => Loss: 44.32399545711034249962\n",
      "Iteration 45716 => Loss: 44.32384803356642777317\n",
      "Iteration 45717 => Loss: 44.32370061117948267793\n",
      "Iteration 45718 => Loss: 44.32355318994952142475\n",
      "Iteration 45719 => Loss: 44.32340576987649427565\n",
      "Iteration 45720 => Loss: 44.32325835096041544148\n",
      "Iteration 45721 => Loss: 44.32311093320126360595\n",
      "Iteration 45722 => Loss: 44.32296351659905297993\n",
      "Iteration 45723 => Loss: 44.32281610115374803627\n",
      "Iteration 45724 => Loss: 44.32266868686536298583\n",
      "Iteration 45725 => Loss: 44.32252127373386230147\n",
      "Iteration 45726 => Loss: 44.32237386175926019405\n",
      "Iteration 45727 => Loss: 44.32222645094154245271\n",
      "Iteration 45728 => Loss: 44.32207904128070197203\n",
      "Iteration 45729 => Loss: 44.32193163277671743572\n",
      "Iteration 45730 => Loss: 44.32178422542958173835\n",
      "Iteration 45731 => Loss: 44.32163681923930198536\n",
      "Iteration 45732 => Loss: 44.32148941420584975504\n",
      "Iteration 45733 => Loss: 44.32134201032922504737\n",
      "Iteration 45734 => Loss: 44.32119460760942786237\n",
      "Iteration 45735 => Loss: 44.32104720604643688375\n",
      "Iteration 45736 => Loss: 44.32089980564023790066\n",
      "Iteration 45737 => Loss: 44.32075240639083091310\n",
      "Iteration 45738 => Loss: 44.32060500829820881563\n",
      "Iteration 45739 => Loss: 44.32045761136236450284\n",
      "Iteration 45740 => Loss: 44.32031021558326955301\n",
      "Iteration 45741 => Loss: 44.32016282096093817700\n",
      "Iteration 45742 => Loss: 44.32001542749534905852\n",
      "Iteration 45743 => Loss: 44.31986803518648088129\n",
      "Iteration 45744 => Loss: 44.31972064403437627789\n",
      "Iteration 45745 => Loss: 44.31957325403897129945\n",
      "Iteration 45746 => Loss: 44.31942586520027305141\n",
      "Iteration 45747 => Loss: 44.31927847751827442835\n",
      "Iteration 45748 => Loss: 44.31913109099296121940\n",
      "Iteration 45749 => Loss: 44.31898370562434052999\n",
      "Iteration 45750 => Loss: 44.31883632141239104385\n",
      "Iteration 45751 => Loss: 44.31868893835709855011\n",
      "Iteration 45752 => Loss: 44.31854155645846304878\n",
      "Iteration 45753 => Loss: 44.31839417571647743443\n",
      "Iteration 45754 => Loss: 44.31824679613112749621\n",
      "Iteration 45755 => Loss: 44.31809941770239902326\n",
      "Iteration 45756 => Loss: 44.31795204043028491014\n",
      "Iteration 45757 => Loss: 44.31780466431478515688\n",
      "Iteration 45758 => Loss: 44.31765728935589265802\n",
      "Iteration 45759 => Loss: 44.31750991555358609730\n",
      "Iteration 45760 => Loss: 44.31736254290784415844\n",
      "Iteration 45761 => Loss: 44.31721517141868815770\n",
      "Iteration 45762 => Loss: 44.31706780108611098967\n",
      "Iteration 45763 => Loss: 44.31692043191007712721\n",
      "Iteration 45764 => Loss: 44.31677306389059367575\n",
      "Iteration 45765 => Loss: 44.31662569702763931900\n",
      "Iteration 45766 => Loss: 44.31647833132121405697\n",
      "Iteration 45767 => Loss: 44.31633096677130367880\n",
      "Iteration 45768 => Loss: 44.31618360337792239534\n",
      "Iteration 45769 => Loss: 44.31603624114102046860\n",
      "Iteration 45770 => Loss: 44.31588888006061210945\n",
      "Iteration 45771 => Loss: 44.31574152013667600158\n",
      "Iteration 45772 => Loss: 44.31559416136922635587\n",
      "Iteration 45773 => Loss: 44.31544680375824185603\n",
      "Iteration 45774 => Loss: 44.31529944730370829120\n",
      "Iteration 45775 => Loss: 44.31515209200563987224\n",
      "Iteration 45776 => Loss: 44.31500473786397975573\n",
      "Iteration 45777 => Loss: 44.31485738487876346881\n",
      "Iteration 45778 => Loss: 44.31471003304995548433\n",
      "Iteration 45779 => Loss: 44.31456268237754869688\n",
      "Iteration 45780 => Loss: 44.31441533286155731730\n",
      "Iteration 45781 => Loss: 44.31426798450194581847\n",
      "Iteration 45782 => Loss: 44.31412063729871420037\n",
      "Iteration 45783 => Loss: 44.31397329125189799015\n",
      "Iteration 45784 => Loss: 44.31382594636140481725\n",
      "Iteration 45785 => Loss: 44.31367860262727731424\n",
      "Iteration 45786 => Loss: 44.31353126004949416483\n",
      "Iteration 45787 => Loss: 44.31338391862803405274\n",
      "Iteration 45788 => Loss: 44.31323657836290408341\n",
      "Iteration 45789 => Loss: 44.31308923925411136224\n",
      "Iteration 45790 => Loss: 44.31294190130163457297\n",
      "Iteration 45791 => Loss: 44.31279456450543818846\n",
      "Iteration 45792 => Loss: 44.31264722886552931413\n",
      "Iteration 45793 => Loss: 44.31249989438191505542\n",
      "Iteration 45794 => Loss: 44.31235256105455988518\n",
      "Iteration 45795 => Loss: 44.31220522888349222512\n",
      "Iteration 45796 => Loss: 44.31205789786868365354\n",
      "Iteration 45797 => Loss: 44.31191056801009864330\n",
      "Iteration 45798 => Loss: 44.31176323930775140525\n",
      "Iteration 45799 => Loss: 44.31161591176164904482\n",
      "Iteration 45800 => Loss: 44.31146858537174182402\n",
      "Iteration 45801 => Loss: 44.31132126013806526998\n",
      "Iteration 45802 => Loss: 44.31117393606056964472\n",
      "Iteration 45803 => Loss: 44.31102661313929047537\n",
      "Iteration 45804 => Loss: 44.31087929137416381309\n",
      "Iteration 45805 => Loss: 44.31073197076523939586\n",
      "Iteration 45806 => Loss: 44.31058465131247459112\n",
      "Iteration 45807 => Loss: 44.31043733301584808260\n",
      "Iteration 45808 => Loss: 44.31029001587535987028\n",
      "Iteration 45809 => Loss: 44.31014269989105258674\n",
      "Iteration 45810 => Loss: 44.30999538506284096684\n",
      "Iteration 45811 => Loss: 44.30984807139076053772\n",
      "Iteration 45812 => Loss: 44.30970075887476866683\n",
      "Iteration 45813 => Loss: 44.30955344751490088129\n",
      "Iteration 45814 => Loss: 44.30940613731112165397\n",
      "Iteration 45815 => Loss: 44.30925882826343809029\n",
      "Iteration 45816 => Loss: 44.30911152037179334684\n",
      "Iteration 45817 => Loss: 44.30896421363623716161\n",
      "Iteration 45818 => Loss: 44.30881690805672690203\n",
      "Iteration 45819 => Loss: 44.30866960363325546268\n",
      "Iteration 45820 => Loss: 44.30852230036582994899\n",
      "Iteration 45821 => Loss: 44.30837499825445746637\n",
      "Iteration 45822 => Loss: 44.30822769729906696057\n",
      "Iteration 45823 => Loss: 44.30808039749970816956\n",
      "Iteration 45824 => Loss: 44.30793309885635267165\n",
      "Iteration 45825 => Loss: 44.30778580136896493968\n",
      "Iteration 45826 => Loss: 44.30763850503758050081\n",
      "Iteration 45827 => Loss: 44.30749120986217093332\n",
      "Iteration 45828 => Loss: 44.30734391584271492093\n",
      "Iteration 45829 => Loss: 44.30719662297921956906\n",
      "Iteration 45830 => Loss: 44.30704933127167066687\n",
      "Iteration 45831 => Loss: 44.30690204072003979263\n",
      "Iteration 45832 => Loss: 44.30675475132437668435\n",
      "Iteration 45833 => Loss: 44.30660746308461028775\n",
      "Iteration 45834 => Loss: 44.30646017600074060283\n",
      "Iteration 45835 => Loss: 44.30631289007281736758\n",
      "Iteration 45836 => Loss: 44.30616560530073400059\n",
      "Iteration 45837 => Loss: 44.30601832168454734528\n",
      "Iteration 45838 => Loss: 44.30587103922426450708\n",
      "Iteration 45839 => Loss: 44.30572375791982864257\n",
      "Iteration 45840 => Loss: 44.30557647777124685717\n",
      "Iteration 45841 => Loss: 44.30542919877851915089\n",
      "Iteration 45842 => Loss: 44.30528192094160999659\n",
      "Iteration 45843 => Loss: 44.30513464426054781597\n",
      "Iteration 45844 => Loss: 44.30498736873529708191\n",
      "Iteration 45845 => Loss: 44.30484009436586489983\n",
      "Iteration 45846 => Loss: 44.30469282115222995344\n",
      "Iteration 45847 => Loss: 44.30454554909437803190\n",
      "Iteration 45848 => Loss: 44.30439827819231624062\n",
      "Iteration 45849 => Loss: 44.30425100844605168504\n",
      "Iteration 45850 => Loss: 44.30410373985551331089\n",
      "Iteration 45851 => Loss: 44.30395647242072953986\n",
      "Iteration 45852 => Loss: 44.30380920614172879368\n",
      "Iteration 45853 => Loss: 44.30366194101844001807\n",
      "Iteration 45854 => Loss: 44.30351467705089874016\n",
      "Iteration 45855 => Loss: 44.30336741423906943282\n",
      "Iteration 45856 => Loss: 44.30322015258295209605\n",
      "Iteration 45857 => Loss: 44.30307289208253251900\n",
      "Iteration 45858 => Loss: 44.30292563273780359623\n",
      "Iteration 45859 => Loss: 44.30277837454875822232\n",
      "Iteration 45860 => Loss: 44.30263111751538929184\n",
      "Iteration 45861 => Loss: 44.30248386163767548851\n",
      "Iteration 45862 => Loss: 44.30233660691563812861\n",
      "Iteration 45863 => Loss: 44.30218935334923457958\n",
      "Iteration 45864 => Loss: 44.30204210093848615770\n",
      "Iteration 45865 => Loss: 44.30189484968335733583\n",
      "Iteration 45866 => Loss: 44.30174759958382679770\n",
      "Iteration 45867 => Loss: 44.30160035063993717586\n",
      "Iteration 45868 => Loss: 44.30145310285163162689\n",
      "Iteration 45869 => Loss: 44.30130585621893857251\n",
      "Iteration 45870 => Loss: 44.30115861074182959101\n",
      "Iteration 45871 => Loss: 44.30101136642026204981\n",
      "Iteration 45872 => Loss: 44.30086412325429989778\n",
      "Iteration 45873 => Loss: 44.30071688124386497520\n",
      "Iteration 45874 => Loss: 44.30056964038899991465\n",
      "Iteration 45875 => Loss: 44.30042240068964076727\n",
      "Iteration 45876 => Loss: 44.30027516214582306020\n",
      "Iteration 45877 => Loss: 44.30012792475753968802\n",
      "Iteration 45878 => Loss: 44.29998068852476222901\n",
      "Iteration 45879 => Loss: 44.29983345344748357775\n",
      "Iteration 45880 => Loss: 44.29968621952571083966\n",
      "Iteration 45881 => Loss: 44.29953898675942269847\n",
      "Iteration 45882 => Loss: 44.29939175514859073246\n",
      "Iteration 45883 => Loss: 44.29924452469322204706\n",
      "Iteration 45884 => Loss: 44.29909729539333085313\n",
      "Iteration 45885 => Loss: 44.29895006724887451810\n",
      "Iteration 45886 => Loss: 44.29880284025986725283\n",
      "Iteration 45887 => Loss: 44.29865561442627353017\n",
      "Iteration 45888 => Loss: 44.29850838974810756099\n",
      "Iteration 45889 => Loss: 44.29836116622536934528\n",
      "Iteration 45890 => Loss: 44.29821394385802335592\n",
      "Iteration 45891 => Loss: 44.29806672264606248746\n",
      "Iteration 45892 => Loss: 44.29791950258947963448\n",
      "Iteration 45893 => Loss: 44.29777228368828190241\n",
      "Iteration 45894 => Loss: 44.29762506594244797498\n",
      "Iteration 45895 => Loss: 44.29747784935199206302\n",
      "Iteration 45896 => Loss: 44.29733063391685732313\n",
      "Iteration 45897 => Loss: 44.29718341963708638787\n",
      "Iteration 45898 => Loss: 44.29703620651262241381\n",
      "Iteration 45899 => Loss: 44.29688899454347961182\n",
      "Iteration 45900 => Loss: 44.29674178372964377104\n",
      "Iteration 45901 => Loss: 44.29659457407112910232\n",
      "Iteration 45902 => Loss: 44.29644736556790718396\n",
      "Iteration 45903 => Loss: 44.29630015821994959424\n",
      "Iteration 45904 => Loss: 44.29615295202729186030\n",
      "Iteration 45905 => Loss: 44.29600574698989845501\n",
      "Iteration 45906 => Loss: 44.29585854310774806208\n",
      "Iteration 45907 => Loss: 44.29571134038086199780\n",
      "Iteration 45908 => Loss: 44.29556413880918341874\n",
      "Iteration 45909 => Loss: 44.29541693839276206290\n",
      "Iteration 45910 => Loss: 44.29526973913156950857\n",
      "Iteration 45911 => Loss: 44.29512254102557022861\n",
      "Iteration 45912 => Loss: 44.29497534407477132845\n",
      "Iteration 45913 => Loss: 44.29482814827917280809\n",
      "Iteration 45914 => Loss: 44.29468095363876756210\n",
      "Iteration 45915 => Loss: 44.29453376015353427420\n",
      "Iteration 45916 => Loss: 44.29438656782347294438\n",
      "Iteration 45917 => Loss: 44.29423937664856225638\n",
      "Iteration 45918 => Loss: 44.29409218662880221018\n",
      "Iteration 45919 => Loss: 44.29394499776417148951\n",
      "Iteration 45920 => Loss: 44.29379781005467719979\n",
      "Iteration 45921 => Loss: 44.29365062350033355187\n",
      "Iteration 45922 => Loss: 44.29350343810106949149\n",
      "Iteration 45923 => Loss: 44.29335625385690633493\n",
      "Iteration 45924 => Loss: 44.29320907076783697676\n",
      "Iteration 45925 => Loss: 44.29306188883386852240\n",
      "Iteration 45926 => Loss: 44.29291470805495833929\n",
      "Iteration 45927 => Loss: 44.29276752843112774372\n",
      "Iteration 45928 => Loss: 44.29262034996236252482\n",
      "Iteration 45929 => Loss: 44.29247317264862715547\n",
      "Iteration 45930 => Loss: 44.29232599648995005737\n",
      "Iteration 45931 => Loss: 44.29217882148628859795\n",
      "Iteration 45932 => Loss: 44.29203164763764988265\n",
      "Iteration 45933 => Loss: 44.29188447494404101690\n",
      "Iteration 45934 => Loss: 44.29173730340541226269\n",
      "Iteration 45935 => Loss: 44.29159013302179914717\n",
      "Iteration 45936 => Loss: 44.29144296379315193235\n",
      "Iteration 45937 => Loss: 44.29129579571949193451\n",
      "Iteration 45938 => Loss: 44.29114862880080494278\n",
      "Iteration 45939 => Loss: 44.29100146303706253548\n",
      "Iteration 45940 => Loss: 44.29085429842827181801\n",
      "Iteration 45941 => Loss: 44.29070713497443279039\n",
      "Iteration 45942 => Loss: 44.29055997267552413632\n",
      "Iteration 45943 => Loss: 44.29041281153152453953\n",
      "Iteration 45944 => Loss: 44.29026565154243400002\n",
      "Iteration 45945 => Loss: 44.29011849270825962321\n",
      "Iteration 45946 => Loss: 44.28997133502898009283\n",
      "Iteration 45947 => Loss: 44.28982417850457409259\n",
      "Iteration 45948 => Loss: 44.28967702313504872791\n",
      "Iteration 45949 => Loss: 44.28952986892041110423\n",
      "Iteration 45950 => Loss: 44.28938271586061858898\n",
      "Iteration 45951 => Loss: 44.28923556395565697130\n",
      "Iteration 45952 => Loss: 44.28908841320556177834\n",
      "Iteration 45953 => Loss: 44.28894126361029037753\n",
      "Iteration 45954 => Loss: 44.28879411516982855801\n",
      "Iteration 45955 => Loss: 44.28864696788420474149\n",
      "Iteration 45956 => Loss: 44.28849982175336208456\n",
      "Iteration 45957 => Loss: 44.28835267677733611436\n",
      "Iteration 45958 => Loss: 44.28820553295606998745\n",
      "Iteration 45959 => Loss: 44.28805839028959923098\n",
      "Iteration 45960 => Loss: 44.28791124877791673953\n",
      "Iteration 45961 => Loss: 44.28776410842095145881\n",
      "Iteration 45962 => Loss: 44.28761696921874602140\n",
      "Iteration 45963 => Loss: 44.28746983117130753271\n",
      "Iteration 45964 => Loss: 44.28732269427856493849\n",
      "Iteration 45965 => Loss: 44.28717555854055376585\n",
      "Iteration 45966 => Loss: 44.28702842395727401481\n",
      "Iteration 45967 => Loss: 44.28688129052869015823\n",
      "Iteration 45968 => Loss: 44.28673415825479509067\n",
      "Iteration 45969 => Loss: 44.28658702713559591757\n",
      "Iteration 45970 => Loss: 44.28643989717107132265\n",
      "Iteration 45971 => Loss: 44.28629276836119998961\n",
      "Iteration 45972 => Loss: 44.28614564070601034018\n",
      "Iteration 45973 => Loss: 44.28599851420546684722\n",
      "Iteration 45974 => Loss: 44.28585138885954819443\n",
      "Iteration 45975 => Loss: 44.28570426466827569811\n",
      "Iteration 45976 => Loss: 44.28555714163162804198\n",
      "Iteration 45977 => Loss: 44.28541001974958390974\n",
      "Iteration 45978 => Loss: 44.28526289902215040684\n",
      "Iteration 45979 => Loss: 44.28511577944932042783\n",
      "Iteration 45980 => Loss: 44.28496866103105844559\n",
      "Iteration 45981 => Loss: 44.28482154376737867096\n",
      "Iteration 45982 => Loss: 44.28467442765828110396\n",
      "Iteration 45983 => Loss: 44.28452731270374442829\n",
      "Iteration 45984 => Loss: 44.28438019890373311682\n",
      "Iteration 45985 => Loss: 44.28423308625826848584\n",
      "Iteration 45986 => Loss: 44.28408597476735053533\n",
      "Iteration 45987 => Loss: 44.28393886443095084360\n",
      "Iteration 45988 => Loss: 44.28379175524907651607\n",
      "Iteration 45989 => Loss: 44.28364464722169202560\n",
      "Iteration 45990 => Loss: 44.28349754034879737219\n",
      "Iteration 45991 => Loss: 44.28335043463040676670\n",
      "Iteration 45992 => Loss: 44.28320333006648468199\n",
      "Iteration 45993 => Loss: 44.28305622665705243435\n",
      "Iteration 45994 => Loss: 44.28290912440204607492\n",
      "Iteration 45995 => Loss: 44.28276202330149402542\n",
      "Iteration 45996 => Loss: 44.28261492335541049670\n",
      "Iteration 45997 => Loss: 44.28246782456375996162\n",
      "Iteration 45998 => Loss: 44.28232072692649978762\n",
      "Iteration 45999 => Loss: 44.28217363044367260727\n",
      "Iteration 46000 => Loss: 44.28202653511525710428\n",
      "Iteration 46001 => Loss: 44.28187944094123906780\n",
      "Iteration 46002 => Loss: 44.28173234792159718154\n",
      "Iteration 46003 => Loss: 44.28158525605633855093\n",
      "Iteration 46004 => Loss: 44.28143816534543475427\n",
      "Iteration 46005 => Loss: 44.28129107578890000241\n",
      "Iteration 46006 => Loss: 44.28114398738672718991\n",
      "Iteration 46007 => Loss: 44.28099690013889500051\n",
      "Iteration 46008 => Loss: 44.28084981404539632877\n",
      "Iteration 46009 => Loss: 44.28070272910621696383\n",
      "Iteration 46010 => Loss: 44.28055564532134269484\n",
      "Iteration 46011 => Loss: 44.28040856269078062724\n",
      "Iteration 46012 => Loss: 44.28026148121453076101\n",
      "Iteration 46013 => Loss: 44.28011440089254335817\n",
      "Iteration 46014 => Loss: 44.27996732172485394585\n",
      "Iteration 46015 => Loss: 44.27982024371141989150\n",
      "Iteration 46016 => Loss: 44.27967316685224119510\n",
      "Iteration 46017 => Loss: 44.27952609114733206752\n",
      "Iteration 46018 => Loss: 44.27937901659667119247\n",
      "Iteration 46019 => Loss: 44.27923194320022304282\n",
      "Iteration 46020 => Loss: 44.27908487095801604028\n",
      "Iteration 46021 => Loss: 44.27893779987001465770\n",
      "Iteration 46022 => Loss: 44.27879072993621889509\n",
      "Iteration 46023 => Loss: 44.27864366115662875245\n",
      "Iteration 46024 => Loss: 44.27849659353121580807\n",
      "Iteration 46025 => Loss: 44.27834952705998006195\n",
      "Iteration 46026 => Loss: 44.27820246174292151409\n",
      "Iteration 46027 => Loss: 44.27805539758002595363\n",
      "Iteration 46028 => Loss: 44.27790833457127206430\n",
      "Iteration 46029 => Loss: 44.27776127271668826779\n",
      "Iteration 46030 => Loss: 44.27761421201619640442\n",
      "Iteration 46031 => Loss: 44.27746715246986752845\n",
      "Iteration 46032 => Loss: 44.27732009407761637476\n",
      "Iteration 46033 => Loss: 44.27717303683949978677\n",
      "Iteration 46034 => Loss: 44.27702598075546092105\n",
      "Iteration 46035 => Loss: 44.27687892582552109388\n",
      "Iteration 46036 => Loss: 44.27673187204965898900\n",
      "Iteration 46037 => Loss: 44.27658481942789592267\n",
      "Iteration 46038 => Loss: 44.27643776796015373520\n",
      "Iteration 46039 => Loss: 44.27629071764648216458\n",
      "Iteration 46040 => Loss: 44.27614366848685989453\n",
      "Iteration 46041 => Loss: 44.27599662048124429248\n",
      "Iteration 46042 => Loss: 44.27584957362967799099\n",
      "Iteration 46043 => Loss: 44.27570252793211835751\n",
      "Iteration 46044 => Loss: 44.27555548338855828661\n",
      "Iteration 46045 => Loss: 44.27540843999901909456\n",
      "Iteration 46046 => Loss: 44.27526139776344393795\n",
      "Iteration 46047 => Loss: 44.27511435668187544934\n",
      "Iteration 46048 => Loss: 44.27496731675424257446\n",
      "Iteration 46049 => Loss: 44.27482027798059505130\n",
      "Iteration 46050 => Loss: 44.27467324036090445816\n",
      "Iteration 46051 => Loss: 44.27452620389514237331\n",
      "Iteration 46052 => Loss: 44.27437916858333011305\n",
      "Iteration 46053 => Loss: 44.27423213442542504481\n",
      "Iteration 46054 => Loss: 44.27408510142144137944\n",
      "Iteration 46055 => Loss: 44.27393806957136490610\n",
      "Iteration 46056 => Loss: 44.27379103887520273020\n",
      "Iteration 46057 => Loss: 44.27364400933293353546\n",
      "Iteration 46058 => Loss: 44.27349698094452179475\n",
      "Iteration 46059 => Loss: 44.27334995370998882436\n",
      "Iteration 46060 => Loss: 44.27320292762931330799\n",
      "Iteration 46061 => Loss: 44.27305590270249524565\n",
      "Iteration 46062 => Loss: 44.27290887892952042648\n",
      "Iteration 46063 => Loss: 44.27276185631038174506\n",
      "Iteration 46064 => Loss: 44.27261483484505788510\n",
      "Iteration 46065 => Loss: 44.27246781453356305747\n",
      "Iteration 46066 => Loss: 44.27232079537587594587\n",
      "Iteration 46067 => Loss: 44.27217377737196812859\n",
      "Iteration 46068 => Loss: 44.27202676052188223821\n",
      "Iteration 46069 => Loss: 44.27187974482556143130\n",
      "Iteration 46070 => Loss: 44.27173273028300570786\n",
      "Iteration 46071 => Loss: 44.27158571689421506790\n",
      "Iteration 46072 => Loss: 44.27143870465917530055\n",
      "Iteration 46073 => Loss: 44.27129169357789351125\n",
      "Iteration 46074 => Loss: 44.27114468365034127828\n",
      "Iteration 46075 => Loss: 44.27099767487649728537\n",
      "Iteration 46076 => Loss: 44.27085066725639705965\n",
      "Iteration 46077 => Loss: 44.27070366079000507398\n",
      "Iteration 46078 => Loss: 44.27055665547729290665\n",
      "Iteration 46079 => Loss: 44.27040965131827476853\n",
      "Iteration 46080 => Loss: 44.27026264831294355417\n",
      "Iteration 46081 => Loss: 44.27011564646129215816\n",
      "Iteration 46082 => Loss: 44.26996864576329215879\n",
      "Iteration 46083 => Loss: 44.26982164621895066148\n",
      "Iteration 46084 => Loss: 44.26967464782823924452\n",
      "Iteration 46085 => Loss: 44.26952765059117211877\n",
      "Iteration 46086 => Loss: 44.26938065450774928422\n",
      "Iteration 46087 => Loss: 44.26923365957791389746\n",
      "Iteration 46088 => Loss: 44.26908666580169438021\n",
      "Iteration 46089 => Loss: 44.26893967317909073245\n",
      "Iteration 46090 => Loss: 44.26879268171007453248\n",
      "Iteration 46091 => Loss: 44.26864569139463156944\n",
      "Iteration 46092 => Loss: 44.26849870223275473791\n",
      "Iteration 46093 => Loss: 44.26835171422445114331\n",
      "Iteration 46094 => Loss: 44.26820472736971368022\n",
      "Iteration 46095 => Loss: 44.26805774166849971607\n",
      "Iteration 46096 => Loss: 44.26791075712083056715\n",
      "Iteration 46097 => Loss: 44.26776377372669202259\n",
      "Iteration 46098 => Loss: 44.26761679148606276613\n",
      "Iteration 46099 => Loss: 44.26746981039894990317\n",
      "Iteration 46100 => Loss: 44.26732283046532501203\n",
      "Iteration 46101 => Loss: 44.26717585168518098726\n",
      "Iteration 46102 => Loss: 44.26702887405856046144\n",
      "Iteration 46103 => Loss: 44.26688189758539238028\n",
      "Iteration 46104 => Loss: 44.26673492226567674379\n",
      "Iteration 46105 => Loss: 44.26658794809940644654\n",
      "Iteration 46106 => Loss: 44.26644097508660280482\n",
      "Iteration 46107 => Loss: 44.26629400322724450234\n",
      "Iteration 46108 => Loss: 44.26614703252129601196\n",
      "Iteration 46109 => Loss: 44.26600006296877154455\n",
      "Iteration 46110 => Loss: 44.26585309456964267838\n",
      "Iteration 46111 => Loss: 44.26570612732395204603\n",
      "Iteration 46112 => Loss: 44.26555916123161438236\n",
      "Iteration 46113 => Loss: 44.26541219629265810909\n",
      "Iteration 46114 => Loss: 44.26526523250710454249\n",
      "Iteration 46115 => Loss: 44.26511826987488973373\n",
      "Iteration 46116 => Loss: 44.26497130839604210450\n",
      "Iteration 46117 => Loss: 44.26482434807054033854\n",
      "Iteration 46118 => Loss: 44.26467738889837733041\n",
      "Iteration 46119 => Loss: 44.26453043087953176382\n",
      "Iteration 46120 => Loss: 44.26438347401399653336\n",
      "Iteration 46121 => Loss: 44.26423651830179295530\n",
      "Iteration 46122 => Loss: 44.26408956374288550251\n",
      "Iteration 46123 => Loss: 44.26394261033728128041\n",
      "Iteration 46124 => Loss: 44.26379565808492344559\n",
      "Iteration 46125 => Loss: 44.26364870698586884146\n",
      "Iteration 46126 => Loss: 44.26350175704007483546\n",
      "Iteration 46127 => Loss: 44.26335480824751300588\n",
      "Iteration 46128 => Loss: 44.26320786060822598529\n",
      "Iteration 46129 => Loss: 44.26306091412216403569\n",
      "Iteration 46130 => Loss: 44.26291396878933426251\n",
      "Iteration 46131 => Loss: 44.26276702460972245490\n",
      "Iteration 46132 => Loss: 44.26262008158332150742\n",
      "Iteration 46133 => Loss: 44.26247313971012431466\n",
      "Iteration 46134 => Loss: 44.26232619899013087661\n",
      "Iteration 46135 => Loss: 44.26217925942329145528\n",
      "Iteration 46136 => Loss: 44.26203232100964157780\n",
      "Iteration 46137 => Loss: 44.26188538374915282247\n",
      "Iteration 46138 => Loss: 44.26173844764181808387\n",
      "Iteration 46139 => Loss: 44.26159151268765157283\n",
      "Iteration 46140 => Loss: 44.26144457888659644595\n",
      "Iteration 46141 => Loss: 44.26129764623867401951\n",
      "Iteration 46142 => Loss: 44.26115071474387718808\n",
      "Iteration 46143 => Loss: 44.26100378440218463538\n",
      "Iteration 46144 => Loss: 44.26085685521359636141\n",
      "Iteration 46145 => Loss: 44.26070992717809104988\n",
      "Iteration 46146 => Loss: 44.26056300029570422794\n",
      "Iteration 46147 => Loss: 44.26041607456636484130\n",
      "Iteration 46148 => Loss: 44.26026914999008710083\n",
      "Iteration 46149 => Loss: 44.26012222656689942824\n",
      "Iteration 46150 => Loss: 44.25997530429670945296\n",
      "Iteration 46151 => Loss: 44.25982838317960244012\n",
      "Iteration 46152 => Loss: 44.25968146321549312461\n",
      "Iteration 46153 => Loss: 44.25953454440440992812\n",
      "Iteration 46154 => Loss: 44.25938762674634574523\n",
      "Iteration 46155 => Loss: 44.25924071024127215424\n",
      "Iteration 46156 => Loss: 44.25909379488920336598\n",
      "Iteration 46157 => Loss: 44.25894688069011806419\n",
      "Iteration 46158 => Loss: 44.25879996764399493259\n",
      "Iteration 46159 => Loss: 44.25865305575085528744\n",
      "Iteration 46160 => Loss: 44.25850614501066360162\n",
      "Iteration 46161 => Loss: 44.25835923542341987513\n",
      "Iteration 46162 => Loss: 44.25821232698910989711\n",
      "Iteration 46163 => Loss: 44.25806541970773366756\n",
      "Iteration 46164 => Loss: 44.25791851357929829192\n",
      "Iteration 46165 => Loss: 44.25777160860373982132\n",
      "Iteration 46166 => Loss: 44.25762470478111509919\n",
      "Iteration 46167 => Loss: 44.25747780211136017670\n",
      "Iteration 46168 => Loss: 44.25733090059448215925\n",
      "Iteration 46169 => Loss: 44.25718400023050946857\n",
      "Iteration 46170 => Loss: 44.25703710101938526122\n",
      "Iteration 46171 => Loss: 44.25689020296113085351\n",
      "Iteration 46172 => Loss: 44.25674330605571782371\n",
      "Iteration 46173 => Loss: 44.25659641030313906640\n",
      "Iteration 46174 => Loss: 44.25644951570338747615\n",
      "Iteration 46175 => Loss: 44.25630262225645594754\n",
      "Iteration 46176 => Loss: 44.25615572996233737513\n",
      "Iteration 46177 => Loss: 44.25600883882104596978\n",
      "Iteration 46178 => Loss: 44.25586194883251778265\n",
      "Iteration 46179 => Loss: 44.25571505999678834087\n",
      "Iteration 46180 => Loss: 44.25556817231383632816\n",
      "Iteration 46181 => Loss: 44.25542128578364042824\n",
      "Iteration 46182 => Loss: 44.25527440040622195738\n",
      "Iteration 46183 => Loss: 44.25512751618154538846\n",
      "Iteration 46184 => Loss: 44.25498063310959651062\n",
      "Iteration 46185 => Loss: 44.25483375119038242929\n",
      "Iteration 46186 => Loss: 44.25468687042388893360\n",
      "Iteration 46187 => Loss: 44.25453999081010891814\n",
      "Iteration 46188 => Loss: 44.25439311234902817205\n",
      "Iteration 46189 => Loss: 44.25424623504066090618\n",
      "Iteration 46190 => Loss: 44.25409935888497159340\n",
      "Iteration 46191 => Loss: 44.25395248388195312828\n",
      "Iteration 46192 => Loss: 44.25380561003159129996\n",
      "Iteration 46193 => Loss: 44.25365873733389321387\n",
      "Iteration 46194 => Loss: 44.25351186578885887002\n",
      "Iteration 46195 => Loss: 44.25336499539645274126\n",
      "Iteration 46196 => Loss: 44.25321812615668903845\n",
      "Iteration 46197 => Loss: 44.25307125806954644531\n",
      "Iteration 46198 => Loss: 44.25292439113501075099\n",
      "Iteration 46199 => Loss: 44.25277752535306774462\n",
      "Iteration 46200 => Loss: 44.25263066072373163706\n",
      "Iteration 46201 => Loss: 44.25248379724698111204\n",
      "Iteration 46202 => Loss: 44.25233693492280906412\n",
      "Iteration 46203 => Loss: 44.25219007375120838788\n",
      "Iteration 46204 => Loss: 44.25204321373213645074\n",
      "Iteration 46205 => Loss: 44.25189635486564299072\n",
      "Iteration 46206 => Loss: 44.25174949715169958608\n",
      "Iteration 46207 => Loss: 44.25160264059024939343\n",
      "Iteration 46208 => Loss: 44.25145578518135636159\n",
      "Iteration 46209 => Loss: 44.25130893092496364716\n",
      "Iteration 46210 => Loss: 44.25116207782109256641\n",
      "Iteration 46211 => Loss: 44.25101522586969338136\n",
      "Iteration 46212 => Loss: 44.25086837507080161913\n",
      "Iteration 46213 => Loss: 44.25072152542436043632\n",
      "Iteration 46214 => Loss: 44.25057467693038404377\n",
      "Iteration 46215 => Loss: 44.25042782958890086320\n",
      "Iteration 46216 => Loss: 44.25028098339984694576\n",
      "Iteration 46217 => Loss: 44.25013413836324360773\n",
      "Iteration 46218 => Loss: 44.24998729447908374368\n",
      "Iteration 46219 => Loss: 44.24984045174732472105\n",
      "Iteration 46220 => Loss: 44.24969361016798075070\n",
      "Iteration 46221 => Loss: 44.24954676974103051634\n",
      "Iteration 46222 => Loss: 44.24939993046650243969\n",
      "Iteration 46223 => Loss: 44.24925309234434678274\n",
      "Iteration 46224 => Loss: 44.24910625537457775636\n",
      "Iteration 46225 => Loss: 44.24895941955717404426\n",
      "Iteration 46226 => Loss: 44.24881258489211433016\n",
      "Iteration 46227 => Loss: 44.24866575137941282492\n",
      "Iteration 46228 => Loss: 44.24851891901908373939\n",
      "Iteration 46229 => Loss: 44.24837208781104891386\n",
      "Iteration 46230 => Loss: 44.24822525775536519177\n",
      "Iteration 46231 => Loss: 44.24807842885197572969\n",
      "Iteration 46232 => Loss: 44.24793160110090894932\n",
      "Iteration 46233 => Loss: 44.24778477450212932354\n",
      "Iteration 46234 => Loss: 44.24763794905562974691\n",
      "Iteration 46235 => Loss: 44.24749112476142443029\n",
      "Iteration 46236 => Loss: 44.24734430161946363569\n",
      "Iteration 46237 => Loss: 44.24719747962978289024\n",
      "Iteration 46238 => Loss: 44.24705065879235377224\n",
      "Iteration 46239 => Loss: 44.24690383910717628169\n",
      "Iteration 46240 => Loss: 44.24675702057420778601\n",
      "Iteration 46241 => Loss: 44.24661020319346960150\n",
      "Iteration 46242 => Loss: 44.24646338696496172815\n",
      "Iteration 46243 => Loss: 44.24631657188863442798\n",
      "Iteration 46244 => Loss: 44.24616975796453033354\n",
      "Iteration 46245 => Loss: 44.24602294519259970684\n",
      "Iteration 46246 => Loss: 44.24587613357287096960\n",
      "Iteration 46247 => Loss: 44.24572932310527306754\n",
      "Iteration 46248 => Loss: 44.24558251378986994951\n",
      "Iteration 46249 => Loss: 44.24543570562658345580\n",
      "Iteration 46250 => Loss: 44.24528889861545621898\n",
      "Iteration 46251 => Loss: 44.24514209275647402819\n",
      "Iteration 46252 => Loss: 44.24499528804961556716\n",
      "Iteration 46253 => Loss: 44.24484848449485951960\n",
      "Iteration 46254 => Loss: 44.24470168209222009637\n",
      "Iteration 46255 => Loss: 44.24455488084166177032\n",
      "Iteration 46256 => Loss: 44.24440808074322717403\n",
      "Iteration 46257 => Loss: 44.24426128179683104236\n",
      "Iteration 46258 => Loss: 44.24411448400252311330\n",
      "Iteration 46259 => Loss: 44.24396768736027496516\n",
      "Iteration 46260 => Loss: 44.24382089187009370335\n",
      "Iteration 46261 => Loss: 44.24367409753192958988\n",
      "Iteration 46262 => Loss: 44.24352730434583236274\n",
      "Iteration 46263 => Loss: 44.24338051231174517852\n",
      "Iteration 46264 => Loss: 44.24323372142966093179\n",
      "Iteration 46265 => Loss: 44.24308693169958672797\n",
      "Iteration 46266 => Loss: 44.24294014312152256707\n",
      "Iteration 46267 => Loss: 44.24279335569544002738\n",
      "Iteration 46268 => Loss: 44.24264656942135331974\n",
      "Iteration 46269 => Loss: 44.24249978429919849532\n",
      "Iteration 46270 => Loss: 44.24235300032904660839\n",
      "Iteration 46271 => Loss: 44.24220621751081949924\n",
      "Iteration 46272 => Loss: 44.24205943584455269502\n",
      "Iteration 46273 => Loss: 44.24191265533023198486\n",
      "Iteration 46274 => Loss: 44.24176587596780052536\n",
      "Iteration 46275 => Loss: 44.24161909775731515992\n",
      "Iteration 46276 => Loss: 44.24147232069872615057\n",
      "Iteration 46277 => Loss: 44.24132554479204060272\n",
      "Iteration 46278 => Loss: 44.24117877003725141094\n",
      "Iteration 46279 => Loss: 44.24103199643433725896\n",
      "Iteration 46280 => Loss: 44.24088522398327683050\n",
      "Iteration 46281 => Loss: 44.24073845268409144182\n",
      "Iteration 46282 => Loss: 44.24059168253675267124\n",
      "Iteration 46283 => Loss: 44.24044491354127472960\n",
      "Iteration 46284 => Loss: 44.24029814569763630061\n",
      "Iteration 46285 => Loss: 44.24015137900580185715\n",
      "Iteration 46286 => Loss: 44.24000461346581403177\n",
      "Iteration 46287 => Loss: 44.23985784907759466478\n",
      "Iteration 46288 => Loss: 44.23971108584120059959\n",
      "Iteration 46289 => Loss: 44.23956432375658209821\n",
      "Iteration 46290 => Loss: 44.23941756282376758236\n",
      "Iteration 46291 => Loss: 44.23927080304271441946\n",
      "Iteration 46292 => Loss: 44.23912404441340839867\n",
      "Iteration 46293 => Loss: 44.23897728693586373083\n",
      "Iteration 46294 => Loss: 44.23883053061008752138\n",
      "Iteration 46295 => Loss: 44.23868377543601582147\n",
      "Iteration 46296 => Loss: 44.23853702141368415823\n",
      "Iteration 46297 => Loss: 44.23839026854307832082\n",
      "Iteration 46298 => Loss: 44.23824351682417699294\n",
      "Iteration 46299 => Loss: 44.23809676625696596375\n",
      "Iteration 46300 => Loss: 44.23795001684145944409\n",
      "Iteration 46301 => Loss: 44.23780326857762901227\n",
      "Iteration 46302 => Loss: 44.23765652146546045742\n",
      "Iteration 46303 => Loss: 44.23750977550496799040\n",
      "Iteration 46304 => Loss: 44.23736303069612318950\n",
      "Iteration 46305 => Loss: 44.23721628703892605472\n",
      "Iteration 46306 => Loss: 44.23706954453338369149\n",
      "Iteration 46307 => Loss: 44.23692280317942504553\n",
      "Iteration 46308 => Loss: 44.23677606297712827654\n",
      "Iteration 46309 => Loss: 44.23662932392642943569\n",
      "Iteration 46310 => Loss: 44.23648258602731431210\n",
      "Iteration 46311 => Loss: 44.23633584927980422208\n",
      "Iteration 46312 => Loss: 44.23618911368387074390\n",
      "Iteration 46313 => Loss: 44.23604237923952098299\n",
      "Iteration 46314 => Loss: 44.23589564594671941222\n",
      "Iteration 46315 => Loss: 44.23574891380548024244\n",
      "Iteration 46316 => Loss: 44.23560218281579636823\n",
      "Iteration 46317 => Loss: 44.23545545297764647330\n",
      "Iteration 46318 => Loss: 44.23530872429101634680\n",
      "Iteration 46319 => Loss: 44.23516199675589177787\n",
      "Iteration 46320 => Loss: 44.23501527037230118822\n",
      "Iteration 46321 => Loss: 44.23486854514020905071\n",
      "Iteration 46322 => Loss: 44.23472182105960825993\n",
      "Iteration 46323 => Loss: 44.23457509813048460501\n",
      "Iteration 46324 => Loss: 44.23442837635282387510\n",
      "Iteration 46325 => Loss: 44.23428165572664738647\n",
      "Iteration 46326 => Loss: 44.23413493625191961200\n",
      "Iteration 46327 => Loss: 44.23398821792863344626\n",
      "Iteration 46328 => Loss: 44.23384150075680310010\n",
      "Iteration 46329 => Loss: 44.23369478473639304639\n",
      "Iteration 46330 => Loss: 44.23354806986738907426\n",
      "Iteration 46331 => Loss: 44.23340135614980539458\n",
      "Iteration 46332 => Loss: 44.23325464358362069106\n",
      "Iteration 46333 => Loss: 44.23310793216882785828\n",
      "Iteration 46334 => Loss: 44.23296122190541979080\n",
      "Iteration 46335 => Loss: 44.23281451279338938321\n",
      "Iteration 46336 => Loss: 44.23266780483272953006\n",
      "Iteration 46337 => Loss: 44.23252109802341891509\n",
      "Iteration 46338 => Loss: 44.23237439236544332744\n",
      "Iteration 46339 => Loss: 44.23222768785880987252\n",
      "Iteration 46340 => Loss: 44.23208098450352565578\n",
      "Iteration 46341 => Loss: 44.23193428229954093922\n",
      "Iteration 46342 => Loss: 44.23178758124687703912\n",
      "Iteration 46343 => Loss: 44.23164088134551974463\n",
      "Iteration 46344 => Loss: 44.23149418259545484489\n",
      "Iteration 46345 => Loss: 44.23134748499667523447\n",
      "Iteration 46346 => Loss: 44.23120078854915959710\n",
      "Iteration 46347 => Loss: 44.23105409325291503819\n",
      "Iteration 46348 => Loss: 44.23090739910792734690\n",
      "Iteration 46349 => Loss: 44.23076070611418231238\n",
      "Iteration 46350 => Loss: 44.23061401427167282918\n",
      "Iteration 46351 => Loss: 44.23046732358044152988\n",
      "Iteration 46352 => Loss: 44.23032063404036051679\n",
      "Iteration 46353 => Loss: 44.23017394565152926589\n",
      "Iteration 46354 => Loss: 44.23002725841389803918\n",
      "Iteration 46355 => Loss: 44.22988057232745973124\n",
      "Iteration 46356 => Loss: 44.22973388739218592036\n",
      "Iteration 46357 => Loss: 44.22958720360811213368\n",
      "Iteration 46358 => Loss: 44.22944052097518152777\n",
      "Iteration 46359 => Loss: 44.22929383949344384064\n",
      "Iteration 46360 => Loss: 44.22914715916283512342\n",
      "Iteration 46361 => Loss: 44.22900047998335537613\n",
      "Iteration 46362 => Loss: 44.22885380195502591505\n",
      "Iteration 46363 => Loss: 44.22870712507778989675\n",
      "Iteration 46364 => Loss: 44.22856044935171127008\n",
      "Iteration 46365 => Loss: 44.22841377477670476992\n",
      "Iteration 46366 => Loss: 44.22826710135279171254\n",
      "Iteration 46367 => Loss: 44.22812042907997209795\n",
      "Iteration 46368 => Loss: 44.22797375795821750444\n",
      "Iteration 46369 => Loss: 44.22782708798754924828\n",
      "Iteration 46370 => Loss: 44.22768041916792469692\n",
      "Iteration 46371 => Loss: 44.22753375149934385036\n",
      "Iteration 46372 => Loss: 44.22738708498183513029\n",
      "Iteration 46373 => Loss: 44.22724041961532748246\n",
      "Iteration 46374 => Loss: 44.22709375539984932857\n",
      "Iteration 46375 => Loss: 44.22694709233539356319\n",
      "Iteration 46376 => Loss: 44.22680043042191044833\n",
      "Iteration 46377 => Loss: 44.22665376965945682741\n",
      "Iteration 46378 => Loss: 44.22650711004799006787\n",
      "Iteration 46379 => Loss: 44.22636045158746043171\n",
      "Iteration 46380 => Loss: 44.22621379427794607864\n",
      "Iteration 46381 => Loss: 44.22606713811936174352\n",
      "Iteration 46382 => Loss: 44.22592048311172874264\n",
      "Iteration 46383 => Loss: 44.22577382925504707600\n",
      "Iteration 46384 => Loss: 44.22562717654928832189\n",
      "Iteration 46385 => Loss: 44.22548052499445248031\n",
      "Iteration 46386 => Loss: 44.22533387459053955126\n",
      "Iteration 46387 => Loss: 44.22518722533752821846\n",
      "Iteration 46388 => Loss: 44.22504057723541848191\n",
      "Iteration 46389 => Loss: 44.22489393028418191989\n",
      "Iteration 46390 => Loss: 44.22474728448383984869\n",
      "Iteration 46391 => Loss: 44.22460063983434253032\n",
      "Iteration 46392 => Loss: 44.22445399633572549192\n",
      "Iteration 46393 => Loss: 44.22430735398794610091\n",
      "Iteration 46394 => Loss: 44.22416071279101146274\n",
      "Iteration 46395 => Loss: 44.22401407274492157740\n",
      "Iteration 46396 => Loss: 44.22386743384965512860\n",
      "Iteration 46397 => Loss: 44.22372079610517658921\n",
      "Iteration 46398 => Loss: 44.22357415951150727551\n",
      "Iteration 46399 => Loss: 44.22342752406866139836\n",
      "Iteration 46400 => Loss: 44.22328088977657500891\n",
      "Iteration 46401 => Loss: 44.22313425663529073972\n",
      "Iteration 46402 => Loss: 44.22298762464478016909\n",
      "Iteration 46403 => Loss: 44.22284099380500066445\n",
      "Iteration 46404 => Loss: 44.22269436411596643666\n",
      "Iteration 46405 => Loss: 44.22254773557769169656\n",
      "Iteration 46406 => Loss: 44.22240110819014091703\n",
      "Iteration 46407 => Loss: 44.22225448195332830892\n",
      "Iteration 46408 => Loss: 44.22210785686722545051\n",
      "Iteration 46409 => Loss: 44.22196123293184655267\n",
      "Iteration 46410 => Loss: 44.22181461014714898283\n",
      "Iteration 46411 => Loss: 44.22166798851313274099\n",
      "Iteration 46412 => Loss: 44.22152136802981203800\n",
      "Iteration 46413 => Loss: 44.22137474869713713588\n",
      "Iteration 46414 => Loss: 44.22122813051512935090\n",
      "Iteration 46415 => Loss: 44.22108151348379578849\n",
      "Iteration 46416 => Loss: 44.22093489760307960523\n",
      "Iteration 46417 => Loss: 44.22078828287301632827\n",
      "Iteration 46418 => Loss: 44.22064166929357753588\n",
      "Iteration 46419 => Loss: 44.22049505686473480637\n",
      "Iteration 46420 => Loss: 44.22034844558651656143\n",
      "Iteration 46421 => Loss: 44.22020183545888016852\n",
      "Iteration 46422 => Loss: 44.22005522648183273304\n",
      "Iteration 46423 => Loss: 44.21990861865536714959\n",
      "Iteration 46424 => Loss: 44.21976201197947631272\n",
      "Iteration 46425 => Loss: 44.21961540645416022244\n",
      "Iteration 46426 => Loss: 44.21946880207937624618\n",
      "Iteration 46427 => Loss: 44.21932219885513859481\n",
      "Iteration 46428 => Loss: 44.21917559678144016289\n",
      "Iteration 46429 => Loss: 44.21902899585826673956\n",
      "Iteration 46430 => Loss: 44.21888239608561832483\n",
      "Iteration 46431 => Loss: 44.21873579746346649699\n",
      "Iteration 46432 => Loss: 44.21858919999181836147\n",
      "Iteration 46433 => Loss: 44.21844260367065970740\n",
      "Iteration 46434 => Loss: 44.21829600849996921852\n",
      "Iteration 46435 => Loss: 44.21814941447977531652\n",
      "Iteration 46436 => Loss: 44.21800282161002115799\n",
      "Iteration 46437 => Loss: 44.21785622989070674294\n",
      "Iteration 46438 => Loss: 44.21770963932187470391\n",
      "Iteration 46439 => Loss: 44.21756304990345398664\n",
      "Iteration 46440 => Loss: 44.21741646163546590742\n",
      "Iteration 46441 => Loss: 44.21726987451789625538\n",
      "Iteration 46442 => Loss: 44.21712328855071660882\n",
      "Iteration 46443 => Loss: 44.21697670373395538945\n",
      "Iteration 46444 => Loss: 44.21683012006757707013\n",
      "Iteration 46445 => Loss: 44.21668353755159586171\n",
      "Iteration 46446 => Loss: 44.21653695618596202621\n",
      "Iteration 46447 => Loss: 44.21639037597069687990\n",
      "Iteration 46448 => Loss: 44.21624379690579331736\n",
      "Iteration 46449 => Loss: 44.21609721899123002231\n",
      "Iteration 46450 => Loss: 44.21595064222701410017\n",
      "Iteration 46451 => Loss: 44.21580406661311002381\n",
      "Iteration 46452 => Loss: 44.21565749214953200408\n",
      "Iteration 46453 => Loss: 44.21551091883625161927\n",
      "Iteration 46454 => Loss: 44.21536434667326886938\n",
      "Iteration 46455 => Loss: 44.21521777566059085984\n",
      "Iteration 46456 => Loss: 44.21507120579818916895\n",
      "Iteration 46457 => Loss: 44.21492463708606379669\n",
      "Iteration 46458 => Loss: 44.21477806952420763764\n",
      "Iteration 46459 => Loss: 44.21463150311259227010\n",
      "Iteration 46460 => Loss: 44.21448493785122479949\n",
      "Iteration 46461 => Loss: 44.21433837374009101495\n",
      "Iteration 46462 => Loss: 44.21419181077918381106\n",
      "Iteration 46463 => Loss: 44.21404524896850318783\n",
      "Iteration 46464 => Loss: 44.21389868830804914523\n",
      "Iteration 46465 => Loss: 44.21375212879775773445\n",
      "Iteration 46466 => Loss: 44.21360557043767869345\n",
      "Iteration 46467 => Loss: 44.21345901322776938969\n",
      "Iteration 46468 => Loss: 44.21331245716805824486\n",
      "Iteration 46469 => Loss: 44.21316590225850262641\n",
      "Iteration 46470 => Loss: 44.21301934849908832348\n",
      "Iteration 46471 => Loss: 44.21287279588982244150\n",
      "Iteration 46472 => Loss: 44.21272624443068366418\n",
      "Iteration 46473 => Loss: 44.21257969412171462409\n",
      "Iteration 46474 => Loss: 44.21243314496283005610\n",
      "Iteration 46475 => Loss: 44.21228659695406548735\n",
      "Iteration 46476 => Loss: 44.21214005009540670699\n",
      "Iteration 46477 => Loss: 44.21199350438681818787\n",
      "Iteration 46478 => Loss: 44.21184695982832835170\n",
      "Iteration 46479 => Loss: 44.21170041641990167136\n",
      "Iteration 46480 => Loss: 44.21155387416156656855\n",
      "Iteration 46481 => Loss: 44.21140733305325909441\n",
      "Iteration 46482 => Loss: 44.21126079309501477610\n",
      "Iteration 46483 => Loss: 44.21111425428681940275\n",
      "Iteration 46484 => Loss: 44.21096771662862323637\n",
      "Iteration 46485 => Loss: 44.21082118012046890954\n",
      "Iteration 46486 => Loss: 44.21067464476232089510\n",
      "Iteration 46487 => Loss: 44.21052811055415787678\n",
      "Iteration 46488 => Loss: 44.21038157749600827628\n",
      "Iteration 46489 => Loss: 44.21023504558781525020\n",
      "Iteration 46490 => Loss: 44.21008851482962853652\n",
      "Iteration 46491 => Loss: 44.20994198522139839724\n",
      "Iteration 46492 => Loss: 44.20979545676311772695\n",
      "Iteration 46493 => Loss: 44.20964892945479363107\n",
      "Iteration 46494 => Loss: 44.20950240329640479331\n",
      "Iteration 46495 => Loss: 44.20935587828795831911\n",
      "Iteration 46496 => Loss: 44.20920935442940447047\n",
      "Iteration 46497 => Loss: 44.20906283172078587995\n",
      "Iteration 46498 => Loss: 44.20891631016204570415\n",
      "Iteration 46499 => Loss: 44.20876978975322657561\n",
      "Iteration 46500 => Loss: 44.20862327049425744008\n",
      "Iteration 46501 => Loss: 44.20847675238520224639\n",
      "Iteration 46502 => Loss: 44.20833023542599704570\n",
      "Iteration 46503 => Loss: 44.20818371961664894343\n",
      "Iteration 46504 => Loss: 44.20803720495715083416\n",
      "Iteration 46505 => Loss: 44.20789069144748850704\n",
      "Iteration 46506 => Loss: 44.20774417908765485663\n",
      "Iteration 46507 => Loss: 44.20759766787764988294\n",
      "Iteration 46508 => Loss: 44.20745115781745226968\n",
      "Iteration 46509 => Loss: 44.20730464890706201686\n",
      "Iteration 46510 => Loss: 44.20715814114646491362\n",
      "Iteration 46511 => Loss: 44.20701163453563964367\n",
      "Iteration 46512 => Loss: 44.20686512907460752331\n",
      "Iteration 46513 => Loss: 44.20671862476333302538\n",
      "Iteration 46514 => Loss: 44.20657212160181614991\n",
      "Iteration 46515 => Loss: 44.20642561959004268601\n",
      "Iteration 46516 => Loss: 44.20627911872802684456\n",
      "Iteration 46517 => Loss: 44.20613261901571888757\n",
      "Iteration 46518 => Loss: 44.20598612045316144759\n",
      "Iteration 46519 => Loss: 44.20583962304030478663\n",
      "Iteration 46520 => Loss: 44.20569312677714890469\n",
      "Iteration 46521 => Loss: 44.20554663166369380178\n",
      "Iteration 46522 => Loss: 44.20540013769992526704\n",
      "Iteration 46523 => Loss: 44.20525364488582198419\n",
      "Iteration 46524 => Loss: 44.20510715322139816408\n",
      "Iteration 46525 => Loss: 44.20496066270662538500\n",
      "Iteration 46526 => Loss: 44.20481417334150364695\n",
      "Iteration 46527 => Loss: 44.20466768512604005537\n",
      "Iteration 46528 => Loss: 44.20452119806017776682\n",
      "Iteration 46529 => Loss: 44.20437471214396651931\n",
      "Iteration 46530 => Loss: 44.20422822737735657483\n",
      "Iteration 46531 => Loss: 44.20408174376034793340\n",
      "Iteration 46532 => Loss: 44.20393526129293348959\n",
      "Iteration 46533 => Loss: 44.20378877997511324338\n",
      "Iteration 46534 => Loss: 44.20364229980687298394\n",
      "Iteration 46535 => Loss: 44.20349582078819850040\n",
      "Iteration 46536 => Loss: 44.20334934291906137105\n",
      "Iteration 46537 => Loss: 44.20320286619951133389\n",
      "Iteration 46538 => Loss: 44.20305639062948444007\n",
      "Iteration 46539 => Loss: 44.20290991620898068959\n",
      "Iteration 46540 => Loss: 44.20276344293802139873\n",
      "Iteration 46541 => Loss: 44.20261697081657814579\n",
      "Iteration 46542 => Loss: 44.20247049984462250904\n",
      "Iteration 46543 => Loss: 44.20232403002217580479\n",
      "Iteration 46544 => Loss: 44.20217756134920250588\n",
      "Iteration 46545 => Loss: 44.20203109382570261232\n",
      "Iteration 46546 => Loss: 44.20188462745169033496\n",
      "Iteration 46547 => Loss: 44.20173816222714435753\n",
      "Iteration 46548 => Loss: 44.20159169815202915288\n",
      "Iteration 46549 => Loss: 44.20144523522635182644\n",
      "Iteration 46550 => Loss: 44.20129877345014079992\n",
      "Iteration 46551 => Loss: 44.20115231282333212448\n",
      "Iteration 46552 => Loss: 44.20100585334595422182\n",
      "Iteration 46553 => Loss: 44.20085939501795024853\n",
      "Iteration 46554 => Loss: 44.20071293783936994259\n",
      "Iteration 46555 => Loss: 44.20056648181018488231\n",
      "Iteration 46556 => Loss: 44.20042002693036664596\n",
      "Iteration 46557 => Loss: 44.20027357319990812812\n",
      "Iteration 46558 => Loss: 44.20012712061882353964\n",
      "Iteration 46559 => Loss: 44.19998066918708445883\n",
      "Iteration 46560 => Loss: 44.19983421890469799109\n",
      "Iteration 46561 => Loss: 44.19968776977162860931\n",
      "Iteration 46562 => Loss: 44.19954132178790473517\n",
      "Iteration 46563 => Loss: 44.19939487495347663071\n",
      "Iteration 46564 => Loss: 44.19924842926837271762\n",
      "Iteration 46565 => Loss: 44.19910198473256457419\n",
      "Iteration 46566 => Loss: 44.19895554134603088414\n",
      "Iteration 46567 => Loss: 44.19880909910880006919\n",
      "Iteration 46568 => Loss: 44.19866265802082239134\n",
      "Iteration 46569 => Loss: 44.19851621808211206144\n",
      "Iteration 46570 => Loss: 44.19836977929264776321\n",
      "Iteration 46571 => Loss: 44.19822334165244370752\n",
      "Iteration 46572 => Loss: 44.19807690516145726178\n",
      "Iteration 46573 => Loss: 44.19793046981970974230\n",
      "Iteration 46574 => Loss: 44.19778403562717272735\n",
      "Iteration 46575 => Loss: 44.19763760258383911150\n",
      "Iteration 46576 => Loss: 44.19749117068970178934\n",
      "Iteration 46577 => Loss: 44.19734473994477497172\n",
      "Iteration 46578 => Loss: 44.19719831034900892064\n",
      "Iteration 46579 => Loss: 44.19705188190242495239\n",
      "Iteration 46580 => Loss: 44.19690545460499464525\n",
      "Iteration 46581 => Loss: 44.19675902845672510466\n",
      "Iteration 46582 => Loss: 44.19661260345759501433\n",
      "Iteration 46583 => Loss: 44.19646617960762569055\n",
      "Iteration 46584 => Loss: 44.19631975690674607904\n",
      "Iteration 46585 => Loss: 44.19617333535499881236\n",
      "Iteration 46586 => Loss: 44.19602691495237678510\n",
      "Iteration 46587 => Loss: 44.19588049569883025924\n",
      "Iteration 46588 => Loss: 44.19573407759438765652\n",
      "Iteration 46589 => Loss: 44.19558766063902055521\n",
      "Iteration 46590 => Loss: 44.19544124483272895532\n",
      "Iteration 46591 => Loss: 44.19529483017551285684\n",
      "Iteration 46592 => Loss: 44.19514841666732962722\n",
      "Iteration 46593 => Loss: 44.19500200430818637187\n",
      "Iteration 46594 => Loss: 44.19485559309809019624\n",
      "Iteration 46595 => Loss: 44.19470918303703399488\n",
      "Iteration 46596 => Loss: 44.19456277412498224066\n",
      "Iteration 46597 => Loss: 44.19441636636194203902\n",
      "Iteration 46598 => Loss: 44.19426995974790628452\n",
      "Iteration 46599 => Loss: 44.19412355428286787173\n",
      "Iteration 46600 => Loss: 44.19397714996681969524\n",
      "Iteration 46601 => Loss: 44.19383074679971912246\n",
      "Iteration 46602 => Loss: 44.19368434478159457512\n",
      "Iteration 46603 => Loss: 44.19353794391243184236\n",
      "Iteration 46604 => Loss: 44.19339154419218829162\n",
      "Iteration 46605 => Loss: 44.19324514562089945002\n",
      "Iteration 46606 => Loss: 44.19309874819855821215\n",
      "Iteration 46607 => Loss: 44.19295235192510062916\n",
      "Iteration 46608 => Loss: 44.19280595680057643904\n",
      "Iteration 46609 => Loss: 44.19265956282494300922\n",
      "Iteration 46610 => Loss: 44.19251316999822165599\n",
      "Iteration 46611 => Loss: 44.19236677832036264135\n",
      "Iteration 46612 => Loss: 44.19222038779138728160\n",
      "Iteration 46613 => Loss: 44.19207399841126004958\n",
      "Iteration 46614 => Loss: 44.19192761018000936701\n",
      "Iteration 46615 => Loss: 44.19178122309759970676\n",
      "Iteration 46616 => Loss: 44.19163483716404527968\n",
      "Iteration 46617 => Loss: 44.19148845237928213692\n",
      "Iteration 46618 => Loss: 44.19134206874336001647\n",
      "Iteration 46619 => Loss: 44.19119568625625049663\n",
      "Iteration 46620 => Loss: 44.19104930491793226111\n",
      "Iteration 46621 => Loss: 44.19090292472841952076\n",
      "Iteration 46622 => Loss: 44.19075654568769095931\n",
      "Iteration 46623 => Loss: 44.19061016779573947133\n",
      "Iteration 46624 => Loss: 44.19046379105253663511\n",
      "Iteration 46625 => Loss: 44.19031741545811797778\n",
      "Iteration 46626 => Loss: 44.19017104101241955050\n",
      "Iteration 46627 => Loss: 44.19002466771547688040\n",
      "Iteration 46628 => Loss: 44.18987829556726154578\n",
      "Iteration 46629 => Loss: 44.18973192456775933579\n",
      "Iteration 46630 => Loss: 44.18958555471697735584\n",
      "Iteration 46631 => Loss: 44.18943918601490139508\n",
      "Iteration 46632 => Loss: 44.18929281846150303181\n",
      "Iteration 46633 => Loss: 44.18914645205681068774\n",
      "Iteration 46634 => Loss: 44.18900008680078883572\n",
      "Iteration 46635 => Loss: 44.18885372269341615947\n",
      "Iteration 46636 => Loss: 44.18870735973471397529\n",
      "Iteration 46637 => Loss: 44.18856099792465386145\n",
      "Iteration 46638 => Loss: 44.18841463726325002881\n",
      "Iteration 46639 => Loss: 44.18826827775045273938\n",
      "Iteration 46640 => Loss: 44.18812191938631173116\n",
      "Iteration 46641 => Loss: 44.18797556217075594986\n",
      "Iteration 46642 => Loss: 44.18782920610380671178\n",
      "Iteration 46643 => Loss: 44.18768285118546401691\n",
      "Iteration 46644 => Loss: 44.18753649741568523268\n",
      "Iteration 46645 => Loss: 44.18739014479449167538\n",
      "Iteration 46646 => Loss: 44.18724379332189755587\n",
      "Iteration 46647 => Loss: 44.18709744299782471444\n",
      "Iteration 46648 => Loss: 44.18695109382232288908\n",
      "Iteration 46649 => Loss: 44.18680474579532813095\n",
      "Iteration 46650 => Loss: 44.18665839891688307262\n",
      "Iteration 46651 => Loss: 44.18651205318698060864\n",
      "Iteration 46652 => Loss: 44.18636570860556389562\n",
      "Iteration 46653 => Loss: 44.18621936517268267153\n",
      "Iteration 46654 => Loss: 44.18607302288827298753\n",
      "Iteration 46655 => Loss: 44.18592668175234905448\n",
      "Iteration 46656 => Loss: 44.18578034176491797780\n",
      "Iteration 46657 => Loss: 44.18563400292595133578\n",
      "Iteration 46658 => Loss: 44.18548766523543491758\n",
      "Iteration 46659 => Loss: 44.18534132869336161775\n",
      "Iteration 46660 => Loss: 44.18519499329975275259\n",
      "Iteration 46661 => Loss: 44.18504865905455147868\n",
      "Iteration 46662 => Loss: 44.18490232595780042857\n",
      "Iteration 46663 => Loss: 44.18475599400944986428\n",
      "Iteration 46664 => Loss: 44.18460966320952110209\n",
      "Iteration 46665 => Loss: 44.18446333355795729858\n",
      "Iteration 46666 => Loss: 44.18431700505480108632\n",
      "Iteration 46667 => Loss: 44.18417067770001693816\n",
      "Iteration 46668 => Loss: 44.18402435149359774869\n",
      "Iteration 46669 => Loss: 44.18387802643555772875\n",
      "Iteration 46670 => Loss: 44.18373170252585424578\n",
      "Iteration 46671 => Loss: 44.18358537976449440521\n",
      "Iteration 46672 => Loss: 44.18343905815145689076\n",
      "Iteration 46673 => Loss: 44.18329273768677012413\n",
      "Iteration 46674 => Loss: 44.18314641837039147276\n",
      "Iteration 46675 => Loss: 44.18300010020231383123\n",
      "Iteration 46676 => Loss: 44.18285378318250877783\n",
      "Iteration 46677 => Loss: 44.18270746731103315597\n",
      "Iteration 46678 => Loss: 44.18256115258782301680\n",
      "Iteration 46679 => Loss: 44.18241483901288546576\n",
      "Iteration 46680 => Loss: 44.18226852658618497571\n",
      "Iteration 46681 => Loss: 44.18212221530775707379\n",
      "Iteration 46682 => Loss: 44.18197590517756623285\n",
      "Iteration 46683 => Loss: 44.18182959619560534748\n",
      "Iteration 46684 => Loss: 44.18168328836188862851\n",
      "Iteration 46685 => Loss: 44.18153698167638054883\n",
      "Iteration 46686 => Loss: 44.18139067613907400300\n",
      "Iteration 46687 => Loss: 44.18124437174996188560\n",
      "Iteration 46688 => Loss: 44.18109806850903709119\n",
      "Iteration 46689 => Loss: 44.18095176641631383063\n",
      "Iteration 46690 => Loss: 44.18080546547174236593\n",
      "Iteration 46691 => Loss: 44.18065916567532980253\n",
      "Iteration 46692 => Loss: 44.18051286702709745668\n",
      "Iteration 46693 => Loss: 44.18036656952698848499\n",
      "Iteration 46694 => Loss: 44.18022027317500999288\n",
      "Iteration 46695 => Loss: 44.18007397797118329663\n",
      "Iteration 46696 => Loss: 44.17992768391544444739\n",
      "Iteration 46697 => Loss: 44.17978139100780055060\n",
      "Iteration 46698 => Loss: 44.17963509924828002795\n",
      "Iteration 46699 => Loss: 44.17948880863686156317\n",
      "Iteration 46700 => Loss: 44.17934251917350962913\n",
      "Iteration 46701 => Loss: 44.17919623085823843667\n",
      "Iteration 46702 => Loss: 44.17904994369100535323\n",
      "Iteration 46703 => Loss: 44.17890365767185301138\n",
      "Iteration 46704 => Loss: 44.17875737280072456770\n",
      "Iteration 46705 => Loss: 44.17861108907766976017\n",
      "Iteration 46706 => Loss: 44.17846480650260332368\n",
      "Iteration 46707 => Loss: 44.17831852507556078535\n",
      "Iteration 46708 => Loss: 44.17817224479652793434\n",
      "Iteration 46709 => Loss: 44.17802596566550477064\n",
      "Iteration 46710 => Loss: 44.17787968768247708340\n",
      "Iteration 46711 => Loss: 44.17773341084741645091\n",
      "Iteration 46712 => Loss: 44.17758713516034418944\n",
      "Iteration 46713 => Loss: 44.17744086062121056102\n",
      "Iteration 46714 => Loss: 44.17729458723006530363\n",
      "Iteration 46715 => Loss: 44.17714831498684446842\n",
      "Iteration 46716 => Loss: 44.17700204389156226625\n",
      "Iteration 46717 => Loss: 44.17685577394421159170\n",
      "Iteration 46718 => Loss: 44.17670950514476402304\n",
      "Iteration 46719 => Loss: 44.17656323749324087657\n",
      "Iteration 46720 => Loss: 44.17641697098962083601\n",
      "Iteration 46721 => Loss: 44.17627070563388969049\n",
      "Iteration 46722 => Loss: 44.17612444142604033459\n",
      "Iteration 46723 => Loss: 44.17597817836605855746\n",
      "Iteration 46724 => Loss: 44.17583191645395856995\n",
      "Iteration 46725 => Loss: 44.17568565568971195034\n",
      "Iteration 46726 => Loss: 44.17553939607330448780\n",
      "Iteration 46727 => Loss: 44.17539313760475039317\n",
      "Iteration 46728 => Loss: 44.17524688028398571760\n",
      "Iteration 46729 => Loss: 44.17510062411106019908\n",
      "Iteration 46730 => Loss: 44.17495436908597383763\n",
      "Iteration 46731 => Loss: 44.17480811520864847353\n",
      "Iteration 46732 => Loss: 44.17466186247914095020\n",
      "Iteration 46733 => Loss: 44.17451561089740863508\n",
      "Iteration 46734 => Loss: 44.17436936046345863360\n",
      "Iteration 46735 => Loss: 44.17422311117725541862\n",
      "Iteration 46736 => Loss: 44.17407686303882741186\n",
      "Iteration 46737 => Loss: 44.17393061604814619159\n",
      "Iteration 46738 => Loss: 44.17378437020519044154\n",
      "Iteration 46739 => Loss: 44.17363812550996726713\n",
      "Iteration 46740 => Loss: 44.17349188196246956295\n",
      "Iteration 46741 => Loss: 44.17334563956269022356\n",
      "Iteration 46742 => Loss: 44.17319939831060793267\n",
      "Iteration 46743 => Loss: 44.17305315820620847944\n",
      "Iteration 46744 => Loss: 44.17290691924950607472\n",
      "Iteration 46745 => Loss: 44.17276068144047940223\n",
      "Iteration 46746 => Loss: 44.17261444477911425111\n",
      "Iteration 46747 => Loss: 44.17246820926541772678\n",
      "Iteration 46748 => Loss: 44.17232197489935430212\n",
      "Iteration 46749 => Loss: 44.17217574168094529341\n",
      "Iteration 46750 => Loss: 44.17202950961016227893\n",
      "Iteration 46751 => Loss: 44.17188327868698394241\n",
      "Iteration 46752 => Loss: 44.17173704891143870555\n",
      "Iteration 46753 => Loss: 44.17159082028347683035\n",
      "Iteration 46754 => Loss: 44.17144459280312673854\n",
      "Iteration 46755 => Loss: 44.17129836647035290298\n",
      "Iteration 46756 => Loss: 44.17115214128516242909\n",
      "Iteration 46757 => Loss: 44.17100591724755531686\n",
      "Iteration 46758 => Loss: 44.17085969435747472289\n",
      "Iteration 46759 => Loss: 44.17071347261497038517\n",
      "Iteration 46760 => Loss: 44.17056725201998546027\n",
      "Iteration 46761 => Loss: 44.17042103257254126447\n",
      "Iteration 46762 => Loss: 44.17027481427262358693\n",
      "Iteration 46763 => Loss: 44.17012859712021821679\n",
      "Iteration 46764 => Loss: 44.16998238111531094319\n",
      "Iteration 46765 => Loss: 44.16983616625789466070\n",
      "Iteration 46766 => Loss: 44.16968995254796936933\n",
      "Iteration 46767 => Loss: 44.16954373998553506908\n",
      "Iteration 46768 => Loss: 44.16939752857057044366\n",
      "Iteration 46769 => Loss: 44.16925131830303996594\n",
      "Iteration 46770 => Loss: 44.16910510918298626848\n",
      "Iteration 46771 => Loss: 44.16895890121035250786\n",
      "Iteration 46772 => Loss: 44.16881269438516000037\n",
      "Iteration 46773 => Loss: 44.16866648870739453514\n",
      "Iteration 46774 => Loss: 44.16852028417703479590\n",
      "Iteration 46775 => Loss: 44.16837408079408788808\n",
      "Iteration 46776 => Loss: 44.16822787855853249539\n",
      "Iteration 46777 => Loss: 44.16808167747036151241\n",
      "Iteration 46778 => Loss: 44.16793547752959625541\n",
      "Iteration 46779 => Loss: 44.16778927873617988098\n",
      "Iteration 46780 => Loss: 44.16764308109011238912\n",
      "Iteration 46781 => Loss: 44.16749688459140088526\n",
      "Iteration 46782 => Loss: 44.16735068924003826396\n",
      "Iteration 46783 => Loss: 44.16720449503602452523\n",
      "Iteration 46784 => Loss: 44.16705830197929572023\n",
      "Iteration 46785 => Loss: 44.16691211006991579779\n",
      "Iteration 46786 => Loss: 44.16676591930784923079\n",
      "Iteration 46787 => Loss: 44.16661972969305338665\n",
      "Iteration 46788 => Loss: 44.16647354122556379252\n",
      "Iteration 46789 => Loss: 44.16632735390534492126\n",
      "Iteration 46790 => Loss: 44.16618116773238966744\n",
      "Iteration 46791 => Loss: 44.16603498270669803105\n",
      "Iteration 46792 => Loss: 44.16588879882827001211\n",
      "Iteration 46793 => Loss: 44.16574261609708429432\n",
      "Iteration 46794 => Loss: 44.16559643451311956142\n",
      "Iteration 46795 => Loss: 44.16545025407639002424\n",
      "Iteration 46796 => Loss: 44.16530407478688857736\n",
      "Iteration 46797 => Loss: 44.16515789664457258823\n",
      "Iteration 46798 => Loss: 44.16501171964946337312\n",
      "Iteration 46799 => Loss: 44.16486554380154672117\n",
      "Iteration 46800 => Loss: 44.16471936910080842154\n",
      "Iteration 46801 => Loss: 44.16457319554722715793\n",
      "Iteration 46802 => Loss: 44.16442702314083135207\n",
      "Iteration 46803 => Loss: 44.16428085188159258223\n",
      "Iteration 46804 => Loss: 44.16413468176946821586\n",
      "Iteration 46805 => Loss: 44.16398851280450088552\n",
      "Iteration 46806 => Loss: 44.16384234498666216950\n",
      "Iteration 46807 => Loss: 44.16369617831593075152\n",
      "Iteration 46808 => Loss: 44.16355001279231373701\n",
      "Iteration 46809 => Loss: 44.16340384841580402053\n",
      "Iteration 46810 => Loss: 44.16325768518634475868\n",
      "Iteration 46811 => Loss: 44.16311152310400700571\n",
      "Iteration 46812 => Loss: 44.16296536216872681280\n",
      "Iteration 46813 => Loss: 44.16281920238053260164\n",
      "Iteration 46814 => Loss: 44.16267304373936752881\n",
      "Iteration 46815 => Loss: 44.16252688624525291061\n",
      "Iteration 46816 => Loss: 44.16238072989817453617\n",
      "Iteration 46817 => Loss: 44.16223457469812530007\n",
      "Iteration 46818 => Loss: 44.16208842064507678060\n",
      "Iteration 46819 => Loss: 44.16194226773907161032\n",
      "Iteration 46820 => Loss: 44.16179611598003162953\n",
      "Iteration 46821 => Loss: 44.16164996536800657623\n",
      "Iteration 46822 => Loss: 44.16150381590296092327\n",
      "Iteration 46823 => Loss: 44.16135766758488756523\n",
      "Iteration 46824 => Loss: 44.16121152041376518582\n",
      "Iteration 46825 => Loss: 44.16106537438961510134\n",
      "Iteration 46826 => Loss: 44.16091922951240178463\n",
      "Iteration 46827 => Loss: 44.16077308578212523571\n",
      "Iteration 46828 => Loss: 44.16062694319879256000\n",
      "Iteration 46829 => Loss: 44.16048080176236823036\n",
      "Iteration 46830 => Loss: 44.16033466147285935222\n",
      "Iteration 46831 => Loss: 44.16018852233023750387\n",
      "Iteration 46832 => Loss: 44.16004238433450268531\n",
      "Iteration 46833 => Loss: 44.15989624748567621282\n",
      "Iteration 46834 => Loss: 44.15975011178370834841\n",
      "Iteration 46835 => Loss: 44.15960397722863461922\n",
      "Iteration 46836 => Loss: 44.15945784382037686555\n",
      "Iteration 46837 => Loss: 44.15931171155899903624\n",
      "Iteration 46838 => Loss: 44.15916558044441586617\n",
      "Iteration 46839 => Loss: 44.15901945047670551503\n",
      "Iteration 46840 => Loss: 44.15887332165580403398\n",
      "Iteration 46841 => Loss: 44.15872719398170431759\n",
      "Iteration 46842 => Loss: 44.15858106745440636587\n",
      "Iteration 46843 => Loss: 44.15843494207390307338\n",
      "Iteration 46844 => Loss: 44.15828881784019444012\n",
      "Iteration 46845 => Loss: 44.15814269475325914982\n",
      "Iteration 46846 => Loss: 44.15799657281307588619\n",
      "Iteration 46847 => Loss: 44.15785045201966596551\n",
      "Iteration 46848 => Loss: 44.15770433237299386064\n",
      "Iteration 46849 => Loss: 44.15755821387305957160\n",
      "Iteration 46850 => Loss: 44.15741209651986309837\n",
      "Iteration 46851 => Loss: 44.15726598031339023009\n",
      "Iteration 46852 => Loss: 44.15711986525362675593\n",
      "Iteration 46853 => Loss: 44.15697375134056557044\n",
      "Iteration 46854 => Loss: 44.15682763857419956821\n",
      "Iteration 46855 => Loss: 44.15668152695451453837\n",
      "Iteration 46856 => Loss: 44.15653541648149627008\n",
      "Iteration 46857 => Loss: 44.15638930715516607961\n",
      "Iteration 46858 => Loss: 44.15624319897548843983\n",
      "Iteration 46859 => Loss: 44.15609709194245624531\n",
      "Iteration 46860 => Loss: 44.15595098605606949604\n",
      "Iteration 46861 => Loss: 44.15580488131629977033\n",
      "Iteration 46862 => Loss: 44.15565877772318259531\n",
      "Iteration 46863 => Loss: 44.15551267527664691670\n",
      "Iteration 46864 => Loss: 44.15536657397672115621\n",
      "Iteration 46865 => Loss: 44.15522047382340531385\n",
      "Iteration 46866 => Loss: 44.15507437481666386248\n",
      "Iteration 46867 => Loss: 44.15492827695651101294\n",
      "Iteration 46868 => Loss: 44.15478218024291834354\n",
      "Iteration 46869 => Loss: 44.15463608467587874884\n",
      "Iteration 46870 => Loss: 44.15448999025539933427\n",
      "Iteration 46871 => Loss: 44.15434389698145878356\n",
      "Iteration 46872 => Loss: 44.15419780485404288584\n",
      "Iteration 46873 => Loss: 44.15405171387315874654\n",
      "Iteration 46874 => Loss: 44.15390562403879215481\n",
      "Iteration 46875 => Loss: 44.15375953535092179436\n",
      "Iteration 46876 => Loss: 44.15361344780954766520\n",
      "Iteration 46877 => Loss: 44.15346736141466976733\n",
      "Iteration 46878 => Loss: 44.15332127616627388988\n",
      "Iteration 46879 => Loss: 44.15317519206433161116\n",
      "Iteration 46880 => Loss: 44.15302910910886424745\n",
      "Iteration 46881 => Loss: 44.15288302729982916617\n",
      "Iteration 46882 => Loss: 44.15273694663725478904\n",
      "Iteration 46883 => Loss: 44.15259086712111269435\n",
      "Iteration 46884 => Loss: 44.15244478875138867124\n",
      "Iteration 46885 => Loss: 44.15229871152807561430\n",
      "Iteration 46886 => Loss: 44.15215263545118062893\n",
      "Iteration 46887 => Loss: 44.15200656052067529345\n",
      "Iteration 46888 => Loss: 44.15186048673656671326\n",
      "Iteration 46889 => Loss: 44.15171441409881936124\n",
      "Iteration 46890 => Loss: 44.15156834260745455367\n",
      "Iteration 46891 => Loss: 44.15142227226245097427\n",
      "Iteration 46892 => Loss: 44.15127620306380151760\n",
      "Iteration 46893 => Loss: 44.15113013501149197282\n",
      "Iteration 46894 => Loss: 44.15098406810551523449\n",
      "Iteration 46895 => Loss: 44.15083800234585709177\n",
      "Iteration 46896 => Loss: 44.15069193773253175550\n",
      "Iteration 46897 => Loss: 44.15054587426550369855\n",
      "Iteration 46898 => Loss: 44.15039981194479423721\n",
      "Iteration 46899 => Loss: 44.15025375077034652804\n",
      "Iteration 46900 => Loss: 44.15010769074220320363\n",
      "Iteration 46901 => Loss: 44.14996163186031452597\n",
      "Iteration 46902 => Loss: 44.14981557412468760049\n",
      "Iteration 46903 => Loss: 44.14966951753529400548\n",
      "Iteration 46904 => Loss: 44.14952346209216926809\n",
      "Iteration 46905 => Loss: 44.14937740779529917745\n",
      "Iteration 46906 => Loss: 44.14923135464463399558\n",
      "Iteration 46907 => Loss: 44.14908530264019503875\n",
      "Iteration 46908 => Loss: 44.14893925178194677983\n",
      "Iteration 46909 => Loss: 44.14879320206990342967\n",
      "Iteration 46910 => Loss: 44.14864715350405077743\n",
      "Iteration 46911 => Loss: 44.14850110608439592852\n",
      "Iteration 46912 => Loss: 44.14835505981089625038\n",
      "Iteration 46913 => Loss: 44.14820901468358016473\n",
      "Iteration 46914 => Loss: 44.14806297070239793356\n",
      "Iteration 46915 => Loss: 44.14791692786735666232\n",
      "Iteration 46916 => Loss: 44.14777088617848477270\n",
      "Iteration 46917 => Loss: 44.14762484563570410501\n",
      "Iteration 46918 => Loss: 44.14747880623905729180\n",
      "Iteration 46919 => Loss: 44.14733276798851591138\n",
      "Iteration 46920 => Loss: 44.14718673088408706917\n",
      "Iteration 46921 => Loss: 44.14704069492571392175\n",
      "Iteration 46922 => Loss: 44.14689466011345331253\n",
      "Iteration 46923 => Loss: 44.14674862644728392524\n",
      "Iteration 46924 => Loss: 44.14660259392714891646\n",
      "Iteration 46925 => Loss: 44.14645656255306960247\n",
      "Iteration 46926 => Loss: 44.14631053232505308870\n",
      "Iteration 46927 => Loss: 44.14616450324307805886\n",
      "Iteration 46928 => Loss: 44.14601847530710898582\n",
      "Iteration 46929 => Loss: 44.14587244851716718586\n",
      "Iteration 46930 => Loss: 44.14572642287323844812\n",
      "Iteration 46931 => Loss: 44.14558039837532277261\n",
      "Iteration 46932 => Loss: 44.14543437502337752676\n",
      "Iteration 46933 => Loss: 44.14528835281741692143\n",
      "Iteration 46934 => Loss: 44.14514233175745516746\n",
      "Iteration 46935 => Loss: 44.14499631184344252688\n",
      "Iteration 46936 => Loss: 44.14485029307540031596\n",
      "Iteration 46937 => Loss: 44.14470427545327879670\n",
      "Iteration 46938 => Loss: 44.14455825897712060168\n",
      "Iteration 46939 => Loss: 44.14441224364689730919\n",
      "Iteration 46940 => Loss: 44.14426622946257339208\n",
      "Iteration 46941 => Loss: 44.14412021642414885036\n",
      "Iteration 46942 => Loss: 44.14397420453165921117\n",
      "Iteration 46943 => Loss: 44.14382819378505473651\n",
      "Iteration 46944 => Loss: 44.14368218418431411010\n",
      "Iteration 46945 => Loss: 44.14353617572947285908\n",
      "Iteration 46946 => Loss: 44.14339016842048835088\n",
      "Iteration 46947 => Loss: 44.14324416225737479635\n",
      "Iteration 46948 => Loss: 44.14309815724009666837\n",
      "Iteration 46949 => Loss: 44.14295215336865396694\n",
      "Iteration 46950 => Loss: 44.14280615064304669204\n",
      "Iteration 46951 => Loss: 44.14266014906327484368\n",
      "Iteration 46952 => Loss: 44.14251414862928868388\n",
      "Iteration 46953 => Loss: 44.14236814934113084519\n",
      "Iteration 46954 => Loss: 44.14222215119875869505\n",
      "Iteration 46955 => Loss: 44.14207615420217223345\n",
      "Iteration 46956 => Loss: 44.14193015835136435498\n",
      "Iteration 46957 => Loss: 44.14178416364631374336\n",
      "Iteration 46958 => Loss: 44.14163817008703460942\n",
      "Iteration 46959 => Loss: 44.14149217767349142605\n",
      "Iteration 46960 => Loss: 44.14134618640569840409\n",
      "Iteration 46961 => Loss: 44.14120019628365554354\n",
      "Iteration 46962 => Loss: 44.14105420730731310641\n",
      "Iteration 46963 => Loss: 44.14090821947667819813\n",
      "Iteration 46964 => Loss: 44.14076223279177213499\n",
      "Iteration 46965 => Loss: 44.14061624725253807355\n",
      "Iteration 46966 => Loss: 44.14047026285899733011\n",
      "Iteration 46967 => Loss: 44.14032427961113569381\n",
      "Iteration 46968 => Loss: 44.14017829750897448093\n",
      "Iteration 46969 => Loss: 44.14003231655242132092\n",
      "Iteration 46970 => Loss: 44.13988633674154016262\n",
      "Iteration 46971 => Loss: 44.13974035807630258432\n",
      "Iteration 46972 => Loss: 44.13959438055669437517\n",
      "Iteration 46973 => Loss: 44.13944840418271553517\n",
      "Iteration 46974 => Loss: 44.13930242895435895889\n",
      "Iteration 46975 => Loss: 44.13915645487158201377\n",
      "Iteration 46976 => Loss: 44.13901048193443443779\n",
      "Iteration 46977 => Loss: 44.13886451014285228212\n",
      "Iteration 46978 => Loss: 44.13871853949685686302\n",
      "Iteration 46979 => Loss: 44.13857256999643396966\n",
      "Iteration 46980 => Loss: 44.13842660164156228575\n",
      "Iteration 46981 => Loss: 44.13828063443224891671\n",
      "Iteration 46982 => Loss: 44.13813466836848675712\n",
      "Iteration 46983 => Loss: 44.13798870345024027984\n",
      "Iteration 46984 => Loss: 44.13784273967753080115\n",
      "Iteration 46985 => Loss: 44.13769677705032989934\n",
      "Iteration 46986 => Loss: 44.13755081556864467984\n",
      "Iteration 46987 => Loss: 44.13740485523245382637\n",
      "Iteration 46988 => Loss: 44.13725889604177154979\n",
      "Iteration 46989 => Loss: 44.13711293799653390124\n",
      "Iteration 46990 => Loss: 44.13696698109677640787\n",
      "Iteration 46991 => Loss: 44.13682102534248485881\n",
      "Iteration 46992 => Loss: 44.13667507073365214865\n",
      "Iteration 46993 => Loss: 44.13652911727025696109\n",
      "Iteration 46994 => Loss: 44.13638316495231350700\n",
      "Iteration 46995 => Loss: 44.13623721377979336467\n",
      "Iteration 46996 => Loss: 44.13609126375266811237\n",
      "Iteration 46997 => Loss: 44.13594531487095906641\n",
      "Iteration 46998 => Loss: 44.13579936713464491049\n",
      "Iteration 46999 => Loss: 44.13565342054374696090\n",
      "Iteration 47000 => Loss: 44.13550747509820126879\n",
      "Iteration 47001 => Loss: 44.13536153079802915045\n",
      "Iteration 47002 => Loss: 44.13521558764324481672\n",
      "Iteration 47003 => Loss: 44.13506964563379142419\n",
      "Iteration 47004 => Loss: 44.13492370476969739457\n",
      "Iteration 47005 => Loss: 44.13477776505092720072\n",
      "Iteration 47006 => Loss: 44.13463182647750926435\n",
      "Iteration 47007 => Loss: 44.13448588904937253119\n",
      "Iteration 47008 => Loss: 44.13433995276658095008\n",
      "Iteration 47009 => Loss: 44.13419401762905636133\n",
      "Iteration 47010 => Loss: 44.13404808363684139749\n",
      "Iteration 47011 => Loss: 44.13390215078992184772\n",
      "Iteration 47012 => Loss: 44.13375621908822665773\n",
      "Iteration 47013 => Loss: 44.13361028853184819809\n",
      "Iteration 47014 => Loss: 44.13346435912070120366\n",
      "Iteration 47015 => Loss: 44.13331843085480699074\n",
      "Iteration 47016 => Loss: 44.13317250373414424303\n",
      "Iteration 47017 => Loss: 44.13302657775870585510\n",
      "Iteration 47018 => Loss: 44.13288065292849893240\n",
      "Iteration 47019 => Loss: 44.13273472924349505320\n",
      "Iteration 47020 => Loss: 44.13258880670370132293\n",
      "Iteration 47021 => Loss: 44.13244288530911063617\n",
      "Iteration 47022 => Loss: 44.13229696505968746578\n",
      "Iteration 47023 => Loss: 44.13215104595543181176\n",
      "Iteration 47024 => Loss: 44.13200512799635077954\n",
      "Iteration 47025 => Loss: 44.13185921118242305283\n",
      "Iteration 47026 => Loss: 44.13171329551363442079\n",
      "Iteration 47027 => Loss: 44.13156738098998488340\n",
      "Iteration 47028 => Loss: 44.13142146761150286238\n",
      "Iteration 47029 => Loss: 44.13127555537810309261\n",
      "Iteration 47030 => Loss: 44.13112964428981399578\n",
      "Iteration 47031 => Loss: 44.13098373434662846648\n",
      "Iteration 47032 => Loss: 44.13083782554856071556\n",
      "Iteration 47033 => Loss: 44.13069191789555389960\n",
      "Iteration 47034 => Loss: 44.13054601138762933488\n",
      "Iteration 47035 => Loss: 44.13040010602477281054\n",
      "Iteration 47036 => Loss: 44.13025420180697011574\n",
      "Iteration 47037 => Loss: 44.13010829873422125047\n",
      "Iteration 47038 => Loss: 44.12996239680651910930\n",
      "Iteration 47039 => Loss: 44.12981649602382816511\n",
      "Iteration 47040 => Loss: 44.12967059638617683959\n",
      "Iteration 47041 => Loss: 44.12952469789352960561\n",
      "Iteration 47042 => Loss: 44.12937880054588646317\n",
      "Iteration 47043 => Loss: 44.12923290434324030684\n",
      "Iteration 47044 => Loss: 44.12908700928558403120\n",
      "Iteration 47045 => Loss: 44.12894111537288921454\n",
      "Iteration 47046 => Loss: 44.12879522260516296228\n",
      "Iteration 47047 => Loss: 44.12864933098241948528\n",
      "Iteration 47048 => Loss: 44.12850344050460904555\n",
      "Iteration 47049 => Loss: 44.12835755117174585394\n",
      "Iteration 47050 => Loss: 44.12821166298380148874\n",
      "Iteration 47051 => Loss: 44.12806577594077594995\n",
      "Iteration 47052 => Loss: 44.12791989004268344843\n",
      "Iteration 47053 => Loss: 44.12777400528950977332\n",
      "Iteration 47054 => Loss: 44.12762812168119808121\n",
      "Iteration 47055 => Loss: 44.12748223921779100465\n",
      "Iteration 47056 => Loss: 44.12733635789924591109\n",
      "Iteration 47057 => Loss: 44.12719047772556280052\n",
      "Iteration 47058 => Loss: 44.12704459869678430550\n",
      "Iteration 47059 => Loss: 44.12689872081282516092\n",
      "Iteration 47060 => Loss: 44.12675284407370668305\n",
      "Iteration 47061 => Loss: 44.12660696847943597732\n",
      "Iteration 47062 => Loss: 44.12646109402998462201\n",
      "Iteration 47063 => Loss: 44.12631522072533130086\n",
      "Iteration 47064 => Loss: 44.12616934856549733013\n",
      "Iteration 47065 => Loss: 44.12602347755046139355\n",
      "Iteration 47066 => Loss: 44.12587760768020928026\n",
      "Iteration 47067 => Loss: 44.12573173895474809569\n",
      "Iteration 47068 => Loss: 44.12558587137402810185\n",
      "Iteration 47069 => Loss: 44.12544000493810614216\n",
      "Iteration 47070 => Loss: 44.12529413964690405692\n",
      "Iteration 47071 => Loss: 44.12514827550045737325\n",
      "Iteration 47072 => Loss: 44.12500241249877319660\n",
      "Iteration 47073 => Loss: 44.12485655064177336726\n",
      "Iteration 47074 => Loss: 44.12471068992950762322\n",
      "Iteration 47075 => Loss: 44.12456483036194043734\n",
      "Iteration 47076 => Loss: 44.12441897193908602048\n",
      "Iteration 47077 => Loss: 44.12427311466091595094\n",
      "Iteration 47078 => Loss: 44.12412725852740891241\n",
      "Iteration 47079 => Loss: 44.12398140353860043206\n",
      "Iteration 47080 => Loss: 44.12383554969443366645\n",
      "Iteration 47081 => Loss: 44.12368969699492282643\n",
      "Iteration 47082 => Loss: 44.12354384544007501745\n",
      "Iteration 47083 => Loss: 44.12339799502983339607\n",
      "Iteration 47084 => Loss: 44.12325214576424059487\n",
      "Iteration 47085 => Loss: 44.12310629764323977042\n",
      "Iteration 47086 => Loss: 44.12296045066687355529\n",
      "Iteration 47087 => Loss: 44.12281460483510642234\n",
      "Iteration 47088 => Loss: 44.12266876014791705529\n",
      "Iteration 47089 => Loss: 44.12252291660531966500\n",
      "Iteration 47090 => Loss: 44.12237707420728582974\n",
      "Iteration 47091 => Loss: 44.12223123295380844411\n",
      "Iteration 47092 => Loss: 44.12208539284489461352\n",
      "Iteration 47093 => Loss: 44.12193955388051591626\n",
      "Iteration 47094 => Loss: 44.12179371606070077405\n",
      "Iteration 47095 => Loss: 44.12164787938541365975\n",
      "Iteration 47096 => Loss: 44.12150204385461194079\n",
      "Iteration 47097 => Loss: 44.12135620946834535516\n",
      "Iteration 47098 => Loss: 44.12121037622655705945\n",
      "Iteration 47099 => Loss: 44.12106454412928258080\n",
      "Iteration 47100 => Loss: 44.12091871317646507578\n",
      "Iteration 47101 => Loss: 44.12077288336814007152\n",
      "Iteration 47102 => Loss: 44.12062705470427914634\n",
      "Iteration 47103 => Loss: 44.12048122718487519478\n",
      "Iteration 47104 => Loss: 44.12033540080990690058\n",
      "Iteration 47105 => Loss: 44.12018957557940268543\n",
      "Iteration 47106 => Loss: 44.12004375149329149508\n",
      "Iteration 47107 => Loss: 44.11989792855162306751\n",
      "Iteration 47108 => Loss: 44.11975210675436898100\n",
      "Iteration 47109 => Loss: 44.11960628610150081386\n",
      "Iteration 47110 => Loss: 44.11946046659302567150\n",
      "Iteration 47111 => Loss: 44.11931464822895065936\n",
      "Iteration 47112 => Loss: 44.11916883100923314487\n",
      "Iteration 47113 => Loss: 44.11902301493388733888\n",
      "Iteration 47114 => Loss: 44.11887720000291324141\n",
      "Iteration 47115 => Loss: 44.11873138621626821987\n",
      "Iteration 47116 => Loss: 44.11858557357395937970\n",
      "Iteration 47117 => Loss: 44.11843976207599382633\n",
      "Iteration 47118 => Loss: 44.11829395172233603262\n",
      "Iteration 47119 => Loss: 44.11814814251299310399\n",
      "Iteration 47120 => Loss: 44.11800233444796504045\n",
      "Iteration 47121 => Loss: 44.11785652752723763115\n",
      "Iteration 47122 => Loss: 44.11771072175077534894\n",
      "Iteration 47123 => Loss: 44.11756491711858529925\n",
      "Iteration 47124 => Loss: 44.11741911363066748208\n",
      "Iteration 47125 => Loss: 44.11727331128702189744\n",
      "Iteration 47126 => Loss: 44.11712751008761301819\n",
      "Iteration 47127 => Loss: 44.11698171003246216060\n",
      "Iteration 47128 => Loss: 44.11683591112151958669\n",
      "Iteration 47129 => Loss: 44.11669011335479240188\n",
      "Iteration 47130 => Loss: 44.11654431673230902788\n",
      "Iteration 47131 => Loss: 44.11639852125399841043\n",
      "Iteration 47132 => Loss: 44.11625272691991739293\n",
      "Iteration 47133 => Loss: 44.11610693372999492112\n",
      "Iteration 47134 => Loss: 44.11596114168427362756\n",
      "Iteration 47135 => Loss: 44.11581535078268956340\n",
      "Iteration 47136 => Loss: 44.11566956102528536121\n",
      "Iteration 47137 => Loss: 44.11552377241203259928\n",
      "Iteration 47138 => Loss: 44.11537798494290996132\n",
      "Iteration 47139 => Loss: 44.11523219861792455276\n",
      "Iteration 47140 => Loss: 44.11508641343706216276\n",
      "Iteration 47141 => Loss: 44.11494062940032279130\n",
      "Iteration 47142 => Loss: 44.11479484650768512211\n",
      "Iteration 47143 => Loss: 44.11464906475914204975\n",
      "Iteration 47144 => Loss: 44.11450328415467936338\n",
      "Iteration 47145 => Loss: 44.11435750469428995757\n",
      "Iteration 47146 => Loss: 44.11421172637798804317\n",
      "Iteration 47147 => Loss: 44.11406594920573809304\n",
      "Iteration 47148 => Loss: 44.11392017317754010719\n",
      "Iteration 47149 => Loss: 44.11377439829338698019\n",
      "Iteration 47150 => Loss: 44.11362862455327871203\n",
      "Iteration 47151 => Loss: 44.11348285195717267015\n",
      "Iteration 47152 => Loss: 44.11333708050509017085\n",
      "Iteration 47153 => Loss: 44.11319131019702410867\n",
      "Iteration 47154 => Loss: 44.11304554103294606193\n",
      "Iteration 47155 => Loss: 44.11289977301284892519\n",
      "Iteration 47156 => Loss: 44.11275400613674690931\n",
      "Iteration 47157 => Loss: 44.11260824040461159257\n",
      "Iteration 47158 => Loss: 44.11246247581642165869\n",
      "Iteration 47159 => Loss: 44.11231671237221974025\n",
      "Iteration 47160 => Loss: 44.11217095007193478295\n",
      "Iteration 47161 => Loss: 44.11202518891559520853\n",
      "Iteration 47162 => Loss: 44.11187942890317259526\n",
      "Iteration 47163 => Loss: 44.11173367003467404857\n",
      "Iteration 47164 => Loss: 44.11158791231007825218\n",
      "Iteration 47165 => Loss: 44.11144215572938520609\n",
      "Iteration 47166 => Loss: 44.11129640029259491030\n",
      "Iteration 47167 => Loss: 44.11115064599964341596\n",
      "Iteration 47168 => Loss: 44.11100489285060177735\n",
      "Iteration 47169 => Loss: 44.11085914084541315106\n",
      "Iteration 47170 => Loss: 44.11071338998408464249\n",
      "Iteration 47171 => Loss: 44.11056764026660204081\n",
      "Iteration 47172 => Loss: 44.11042189169292981887\n",
      "Iteration 47173 => Loss: 44.11027614426311060924\n",
      "Iteration 47174 => Loss: 44.11013039797710177936\n",
      "Iteration 47175 => Loss: 44.10998465283491754008\n",
      "Iteration 47176 => Loss: 44.10983890883651525883\n",
      "Iteration 47177 => Loss: 44.10969316598190914647\n",
      "Iteration 47178 => Loss: 44.10954742427108499214\n",
      "Iteration 47179 => Loss: 44.10940168370402858500\n",
      "Iteration 47180 => Loss: 44.10925594428073992503\n",
      "Iteration 47181 => Loss: 44.10911020600120480140\n",
      "Iteration 47182 => Loss: 44.10896446886543031951\n",
      "Iteration 47183 => Loss: 44.10881873287336674139\n",
      "Iteration 47184 => Loss: 44.10867299802506380502\n",
      "Iteration 47185 => Loss: 44.10852726432045756155\n",
      "Iteration 47186 => Loss: 44.10838153175955511642\n",
      "Iteration 47187 => Loss: 44.10823580034238489134\n",
      "Iteration 47188 => Loss: 44.10809007006887583202\n",
      "Iteration 47189 => Loss: 44.10794434093906346561\n",
      "Iteration 47190 => Loss: 44.10779861295292647583\n",
      "Iteration 47191 => Loss: 44.10765288611045775724\n",
      "Iteration 47192 => Loss: 44.10750716041164309900\n",
      "Iteration 47193 => Loss: 44.10736143585647539567\n",
      "Iteration 47194 => Loss: 44.10721571244494043640\n",
      "Iteration 47195 => Loss: 44.10706999017702401034\n",
      "Iteration 47196 => Loss: 44.10692426905276164462\n",
      "Iteration 47197 => Loss: 44.10677854907211070667\n",
      "Iteration 47198 => Loss: 44.10663283023502856395\n",
      "Iteration 47199 => Loss: 44.10648711254155784900\n",
      "Iteration 47200 => Loss: 44.10634139599167724555\n",
      "Iteration 47201 => Loss: 44.10619568058535833188\n",
      "Iteration 47202 => Loss: 44.10604996632262952971\n",
      "Iteration 47203 => Loss: 44.10590425320344110105\n",
      "Iteration 47204 => Loss: 44.10575854122781436217\n",
      "Iteration 47205 => Loss: 44.10561283039569957509\n",
      "Iteration 47206 => Loss: 44.10546712070713226694\n",
      "Iteration 47207 => Loss: 44.10532141216208401602\n",
      "Iteration 47208 => Loss: 44.10517570476056192774\n",
      "Iteration 47209 => Loss: 44.10502999850255179126\n",
      "Iteration 47210 => Loss: 44.10488429338800386859\n",
      "Iteration 47211 => Loss: 44.10473858941696079228\n",
      "Iteration 47212 => Loss: 44.10459288658940124606\n",
      "Iteration 47213 => Loss: 44.10444718490529680821\n",
      "Iteration 47214 => Loss: 44.10430148436464037331\n",
      "Iteration 47215 => Loss: 44.10415578496744615222\n",
      "Iteration 47216 => Loss: 44.10401008671369282865\n",
      "Iteration 47217 => Loss: 44.10386438960338750803\n",
      "Iteration 47218 => Loss: 44.10371869363650176865\n",
      "Iteration 47219 => Loss: 44.10357299881302139966\n",
      "Iteration 47220 => Loss: 44.10342730513293929562\n",
      "Iteration 47221 => Loss: 44.10328161259626256196\n",
      "Iteration 47222 => Loss: 44.10313592120295567156\n",
      "Iteration 47223 => Loss: 44.10299023095305415154\n",
      "Iteration 47224 => Loss: 44.10284454184650115849\n",
      "Iteration 47225 => Loss: 44.10269885388332511411\n",
      "Iteration 47226 => Loss: 44.10255316706349759670\n",
      "Iteration 47227 => Loss: 44.10240748138699018455\n",
      "Iteration 47228 => Loss: 44.10226179685385972107\n",
      "Iteration 47229 => Loss: 44.10211611346402094114\n",
      "Iteration 47230 => Loss: 44.10197043121750226646\n",
      "Iteration 47231 => Loss: 44.10182475011428238076\n",
      "Iteration 47232 => Loss: 44.10167907015438260032\n",
      "Iteration 47233 => Loss: 44.10153339133773897629\n",
      "Iteration 47234 => Loss: 44.10138771366441545752\n",
      "Iteration 47235 => Loss: 44.10124203713432677887\n",
      "Iteration 47236 => Loss: 44.10109636174753688920\n",
      "Iteration 47237 => Loss: 44.10095068750396052337\n",
      "Iteration 47238 => Loss: 44.10080501440365452481\n",
      "Iteration 47239 => Loss: 44.10065934244657626095\n",
      "Iteration 47240 => Loss: 44.10051367163271862637\n",
      "Iteration 47241 => Loss: 44.10036800196208872649\n",
      "Iteration 47242 => Loss: 44.10022233343466524502\n",
      "Iteration 47243 => Loss: 44.10007666605043397112\n",
      "Iteration 47244 => Loss: 44.09993099980940201021\n",
      "Iteration 47245 => Loss: 44.09978533471152672973\n",
      "Iteration 47246 => Loss: 44.09963967075685786767\n",
      "Iteration 47247 => Loss: 44.09949400794531726433\n",
      "Iteration 47248 => Loss: 44.09934834627696176312\n",
      "Iteration 47249 => Loss: 44.09920268575172741521\n",
      "Iteration 47250 => Loss: 44.09905702636964974772\n",
      "Iteration 47251 => Loss: 44.09891136813066481182\n",
      "Iteration 47252 => Loss: 44.09876571103484366176\n",
      "Iteration 47253 => Loss: 44.09862005508210103244\n",
      "Iteration 47254 => Loss: 44.09847440027245824012\n",
      "Iteration 47255 => Loss: 44.09832874660591528482\n",
      "Iteration 47256 => Loss: 44.09818309408245085024\n",
      "Iteration 47257 => Loss: 44.09803744270206493638\n",
      "Iteration 47258 => Loss: 44.09789179246477885954\n",
      "Iteration 47259 => Loss: 44.09774614337049314372\n",
      "Iteration 47260 => Loss: 44.09760049541927884320\n",
      "Iteration 47261 => Loss: 44.09745484861107200913\n",
      "Iteration 47262 => Loss: 44.09730920294592948494\n",
      "Iteration 47263 => Loss: 44.09716355842378732177\n",
      "Iteration 47264 => Loss: 44.09701791504467394134\n",
      "Iteration 47265 => Loss: 44.09687227280854671108\n",
      "Iteration 47266 => Loss: 44.09672663171541273641\n",
      "Iteration 47267 => Loss: 44.09658099176526491192\n",
      "Iteration 47268 => Loss: 44.09643535295809613217\n",
      "Iteration 47269 => Loss: 44.09628971529387797545\n",
      "Iteration 47270 => Loss: 44.09614407877263175806\n",
      "Iteration 47271 => Loss: 44.09599844339432905826\n",
      "Iteration 47272 => Loss: 44.09585280915896987608\n",
      "Iteration 47273 => Loss: 44.09570717606654710607\n",
      "Iteration 47274 => Loss: 44.09556154411701101026\n",
      "Iteration 47275 => Loss: 44.09541591331042553747\n",
      "Iteration 47276 => Loss: 44.09527028364673384431\n",
      "Iteration 47277 => Loss: 44.09512465512590750905\n",
      "Iteration 47278 => Loss: 44.09497902774799626968\n",
      "Iteration 47279 => Loss: 44.09483340151296459908\n",
      "Iteration 47280 => Loss: 44.09468777642077697010\n",
      "Iteration 47281 => Loss: 44.09454215247146180445\n",
      "Iteration 47282 => Loss: 44.09439652966500489129\n",
      "Iteration 47283 => Loss: 44.09425090800137070346\n",
      "Iteration 47284 => Loss: 44.09410528748056634640\n",
      "Iteration 47285 => Loss: 44.09395966810259892554\n",
      "Iteration 47286 => Loss: 44.09381404986742580832\n",
      "Iteration 47287 => Loss: 44.09366843277506120558\n",
      "Iteration 47288 => Loss: 44.09352281682551222275\n",
      "Iteration 47289 => Loss: 44.09337720201872912185\n",
      "Iteration 47290 => Loss: 44.09323158835472611372\n",
      "Iteration 47291 => Loss: 44.09308597583351030380\n",
      "Iteration 47292 => Loss: 44.09294036445504616495\n",
      "Iteration 47293 => Loss: 44.09279475421931948631\n",
      "Iteration 47294 => Loss: 44.09264914512633737331\n",
      "Iteration 47295 => Loss: 44.09250353717607850967\n",
      "Iteration 47296 => Loss: 44.09235793036855710625\n",
      "Iteration 47297 => Loss: 44.09221232470375895218\n",
      "Iteration 47298 => Loss: 44.09206672018164852034\n",
      "Iteration 47299 => Loss: 44.09192111680224002157\n",
      "Iteration 47300 => Loss: 44.09177551456551924502\n",
      "Iteration 47301 => Loss: 44.09162991347146487442\n",
      "Iteration 47302 => Loss: 44.09148431352010533146\n",
      "Iteration 47303 => Loss: 44.09133871471139798359\n",
      "Iteration 47304 => Loss: 44.09119311704534283081\n",
      "Iteration 47305 => Loss: 44.09104752052193276768\n",
      "Iteration 47306 => Loss: 44.09090192514114647793\n",
      "Iteration 47307 => Loss: 44.09075633090297685612\n",
      "Iteration 47308 => Loss: 44.09061073780743811312\n",
      "Iteration 47309 => Loss: 44.09046514585452314350\n",
      "Iteration 47310 => Loss: 44.09031955504417510383\n",
      "Iteration 47311 => Loss: 44.09017396537643662668\n",
      "Iteration 47312 => Loss: 44.09002837685125797407\n",
      "Iteration 47313 => Loss: 44.08988278946866756769\n",
      "Iteration 47314 => Loss: 44.08973720322863698584\n",
      "Iteration 47315 => Loss: 44.08959161813115912310\n",
      "Iteration 47316 => Loss: 44.08944603417621266317\n",
      "Iteration 47317 => Loss: 44.08930045136381181692\n",
      "Iteration 47318 => Loss: 44.08915486969393526806\n",
      "Iteration 47319 => Loss: 44.08900928916659722745\n",
      "Iteration 47320 => Loss: 44.08886370978174085167\n",
      "Iteration 47321 => Loss: 44.08871813153938745700\n",
      "Iteration 47322 => Loss: 44.08857255443952993801\n",
      "Iteration 47323 => Loss: 44.08842697848215408385\n",
      "Iteration 47324 => Loss: 44.08828140366725278909\n",
      "Iteration 47325 => Loss: 44.08813582999477631574\n",
      "Iteration 47326 => Loss: 44.08799025746479571808\n",
      "Iteration 47327 => Loss: 44.08784468607727546896\n",
      "Iteration 47328 => Loss: 44.08769911583216583040\n",
      "Iteration 47329 => Loss: 44.08755354672948811867\n",
      "Iteration 47330 => Loss: 44.08740797876922812293\n",
      "Iteration 47331 => Loss: 44.08726241195137873774\n",
      "Iteration 47332 => Loss: 44.08711684627591864682\n",
      "Iteration 47333 => Loss: 44.08697128174286206104\n",
      "Iteration 47334 => Loss: 44.08682571835219476952\n",
      "Iteration 47335 => Loss: 44.08668015610390256143\n",
      "Iteration 47336 => Loss: 44.08653459499795701504\n",
      "Iteration 47337 => Loss: 44.08638903503438655207\n",
      "Iteration 47338 => Loss: 44.08624347621314853996\n",
      "Iteration 47339 => Loss: 44.08609791853424297869\n",
      "Iteration 47340 => Loss: 44.08595236199768407914\n",
      "Iteration 47341 => Loss: 44.08580680660345763044\n",
      "Iteration 47342 => Loss: 44.08566125235149968375\n",
      "Iteration 47343 => Loss: 44.08551569924188129335\n",
      "Iteration 47344 => Loss: 44.08537014727453140495\n",
      "Iteration 47345 => Loss: 44.08522459644947844026\n",
      "Iteration 47346 => Loss: 44.08507904676670818844\n",
      "Iteration 47347 => Loss: 44.08493349822619222778\n",
      "Iteration 47348 => Loss: 44.08478795082792345283\n",
      "Iteration 47349 => Loss: 44.08464240457192317990\n",
      "Iteration 47350 => Loss: 44.08449685945814877641\n",
      "Iteration 47351 => Loss: 44.08435131548661445322\n",
      "Iteration 47352 => Loss: 44.08420577265731310490\n",
      "Iteration 47353 => Loss: 44.08406023097019499346\n",
      "Iteration 47354 => Loss: 44.08391469042529564604\n",
      "Iteration 47355 => Loss: 44.08376915102257243007\n",
      "Iteration 47356 => Loss: 44.08362361276206087268\n",
      "Iteration 47357 => Loss: 44.08347807564371834133\n",
      "Iteration 47358 => Loss: 44.08333253966752351971\n",
      "Iteration 47359 => Loss: 44.08318700483351193498\n",
      "Iteration 47360 => Loss: 44.08304147114166937627\n",
      "Iteration 47361 => Loss: 44.08289593859191768388\n",
      "Iteration 47362 => Loss: 44.08275040718430659581\n",
      "Iteration 47363 => Loss: 44.08260487691886453376\n",
      "Iteration 47364 => Loss: 44.08245934779549912719\n",
      "Iteration 47365 => Loss: 44.08231381981426011407\n",
      "Iteration 47366 => Loss: 44.08216829297509775643\n",
      "Iteration 47367 => Loss: 44.08202276727801205425\n",
      "Iteration 47368 => Loss: 44.08187724272302432382\n",
      "Iteration 47369 => Loss: 44.08173171931009903801\n",
      "Iteration 47370 => Loss: 44.08158619703922909139\n",
      "Iteration 47371 => Loss: 44.08144067591040737852\n",
      "Iteration 47372 => Loss: 44.08129515592364100485\n",
      "Iteration 47373 => Loss: 44.08114963707891575950\n",
      "Iteration 47374 => Loss: 44.08100411937620322078\n",
      "Iteration 47375 => Loss: 44.08085860281550338868\n",
      "Iteration 47376 => Loss: 44.08071308739680915778\n",
      "Iteration 47377 => Loss: 44.08056757312011342265\n",
      "Iteration 47378 => Loss: 44.08042205998540907785\n",
      "Iteration 47379 => Loss: 44.08027654799268191255\n",
      "Iteration 47380 => Loss: 44.08013103714192482130\n",
      "Iteration 47381 => Loss: 44.07998552743313069868\n",
      "Iteration 47382 => Loss: 44.07984001886627822842\n",
      "Iteration 47383 => Loss: 44.07969451144136741050\n",
      "Iteration 47384 => Loss: 44.07954900515841245578\n",
      "Iteration 47385 => Loss: 44.07940350001739204799\n",
      "Iteration 47386 => Loss: 44.07925799601825644913\n",
      "Iteration 47387 => Loss: 44.07911249316104118634\n",
      "Iteration 47388 => Loss: 44.07896699144572494333\n",
      "Iteration 47389 => Loss: 44.07882149087230061468\n",
      "Iteration 47390 => Loss: 44.07867599144075398954\n",
      "Iteration 47391 => Loss: 44.07853049315107085704\n",
      "Iteration 47392 => Loss: 44.07838499600327963890\n",
      "Iteration 47393 => Loss: 44.07823949999731638627\n",
      "Iteration 47394 => Loss: 44.07809400513320241544\n",
      "Iteration 47395 => Loss: 44.07794851141093772640\n",
      "Iteration 47396 => Loss: 44.07780301883047258116\n",
      "Iteration 47397 => Loss: 44.07765752739184961229\n",
      "Iteration 47398 => Loss: 44.07751203709503329264\n",
      "Iteration 47399 => Loss: 44.07736654794001651680\n",
      "Iteration 47400 => Loss: 44.07722105992679217934\n",
      "Iteration 47401 => Loss: 44.07707557305533185854\n",
      "Iteration 47402 => Loss: 44.07693008732564976526\n",
      "Iteration 47403 => Loss: 44.07678460273774589950\n",
      "Iteration 47404 => Loss: 44.07663911929159894498\n",
      "Iteration 47405 => Loss: 44.07649363698719469085\n",
      "Iteration 47406 => Loss: 44.07634815582451892624\n",
      "Iteration 47407 => Loss: 44.07620267580356454573\n",
      "Iteration 47408 => Loss: 44.07605719692435286561\n",
      "Iteration 47409 => Loss: 44.07591171918683414788\n",
      "Iteration 47410 => Loss: 44.07576624259102970882\n",
      "Iteration 47411 => Loss: 44.07562076713691112673\n",
      "Iteration 47412 => Loss: 44.07547529282447840160\n",
      "Iteration 47413 => Loss: 44.07532981965371021715\n",
      "Iteration 47414 => Loss: 44.07518434762463499510\n",
      "Iteration 47415 => Loss: 44.07503887673719589202\n",
      "Iteration 47416 => Loss: 44.07489340699140001334\n",
      "Iteration 47417 => Loss: 44.07474793838724735906\n",
      "Iteration 47418 => Loss: 44.07460247092474503461\n",
      "Iteration 47419 => Loss: 44.07445700460382909114\n",
      "Iteration 47420 => Loss: 44.07431153942454216121\n",
      "Iteration 47421 => Loss: 44.07416607538687003398\n",
      "Iteration 47422 => Loss: 44.07402061249077718230\n",
      "Iteration 47423 => Loss: 44.07387515073627781703\n",
      "Iteration 47424 => Loss: 44.07372969012332930561\n",
      "Iteration 47425 => Loss: 44.07358423065198849145\n",
      "Iteration 47426 => Loss: 44.07343877232217010942\n",
      "Iteration 47427 => Loss: 44.07329331513393100295\n",
      "Iteration 47428 => Loss: 44.07314785908720722318\n",
      "Iteration 47429 => Loss: 44.07300240418204140269\n",
      "Iteration 47430 => Loss: 44.07285695041836959263\n",
      "Iteration 47431 => Loss: 44.07271149779622732012\n",
      "Iteration 47432 => Loss: 44.07256604631558616347\n",
      "Iteration 47433 => Loss: 44.07242059597643191182\n",
      "Iteration 47434 => Loss: 44.07227514677876456517\n",
      "Iteration 47435 => Loss: 44.07212969872259833437\n",
      "Iteration 47436 => Loss: 44.07198425180788348143\n",
      "Iteration 47437 => Loss: 44.07183880603462000636\n",
      "Iteration 47438 => Loss: 44.07169336140284343628\n",
      "Iteration 47439 => Loss: 44.07154791791246850607\n",
      "Iteration 47440 => Loss: 44.07140247556355205916\n",
      "Iteration 47441 => Loss: 44.07125703435604435754\n",
      "Iteration 47442 => Loss: 44.07111159428995250664\n",
      "Iteration 47443 => Loss: 44.07096615536526940105\n",
      "Iteration 47444 => Loss: 44.07082071758198082989\n",
      "Iteration 47445 => Loss: 44.07067528094008679318\n",
      "Iteration 47446 => Loss: 44.07052984543955886920\n",
      "Iteration 47447 => Loss: 44.07038441108041126881\n",
      "Iteration 47448 => Loss: 44.07023897786262267573\n",
      "Iteration 47449 => Loss: 44.07009354578620019538\n",
      "Iteration 47450 => Loss: 44.06994811485109408977\n",
      "Iteration 47451 => Loss: 44.06980268505734699147\n",
      "Iteration 47452 => Loss: 44.06965725640491626791\n",
      "Iteration 47453 => Loss: 44.06951182889379481367\n",
      "Iteration 47454 => Loss: 44.06936640252398973416\n",
      "Iteration 47455 => Loss: 44.06922097729547971312\n",
      "Iteration 47456 => Loss: 44.06907555320827185596\n",
      "Iteration 47457 => Loss: 44.06893013026231642471\n",
      "Iteration 47458 => Loss: 44.06878470845765605191\n",
      "Iteration 47459 => Loss: 44.06863928779424099957\n",
      "Iteration 47460 => Loss: 44.06849386827209258399\n",
      "Iteration 47461 => Loss: 44.06834844989118238345\n",
      "Iteration 47462 => Loss: 44.06820303265151750338\n",
      "Iteration 47463 => Loss: 44.06805761655306241664\n",
      "Iteration 47464 => Loss: 44.06791220159584554494\n",
      "Iteration 47465 => Loss: 44.06776678777983136115\n",
      "Iteration 47466 => Loss: 44.06762137510502697069\n",
      "Iteration 47467 => Loss: 44.06747596357138263556\n",
      "Iteration 47468 => Loss: 44.06733055317894098835\n",
      "Iteration 47469 => Loss: 44.06718514392765939647\n",
      "Iteration 47470 => Loss: 44.06703973581755207078\n",
      "Iteration 47471 => Loss: 44.06689432884859769501\n",
      "Iteration 47472 => Loss: 44.06674892302079626916\n",
      "Iteration 47473 => Loss: 44.06660351833413358236\n",
      "Iteration 47474 => Loss: 44.06645811478860252919\n",
      "Iteration 47475 => Loss: 44.06631271238418179337\n",
      "Iteration 47476 => Loss: 44.06616731112085716404\n",
      "Iteration 47477 => Loss: 44.06602191099863574664\n",
      "Iteration 47478 => Loss: 44.06587651201753175201\n",
      "Iteration 47479 => Loss: 44.06573111417750254759\n",
      "Iteration 47480 => Loss: 44.06558571747854102796\n",
      "Iteration 47481 => Loss: 44.06544032192064008768\n",
      "Iteration 47482 => Loss: 44.06529492750380683219\n",
      "Iteration 47483 => Loss: 44.06514953422801283978\n",
      "Iteration 47484 => Loss: 44.06500414209327942672\n",
      "Iteration 47485 => Loss: 44.06485875109956396045\n",
      "Iteration 47486 => Loss: 44.06471336124686644098\n",
      "Iteration 47487 => Loss: 44.06456797253517265744\n",
      "Iteration 47488 => Loss: 44.06442258496448971528\n",
      "Iteration 47489 => Loss: 44.06427719853480340362\n",
      "Iteration 47490 => Loss: 44.06413181324609951162\n",
      "Iteration 47491 => Loss: 44.06398642909834961756\n",
      "Iteration 47492 => Loss: 44.06384104609159635402\n",
      "Iteration 47493 => Loss: 44.06369566422581129927\n",
      "Iteration 47494 => Loss: 44.06355028350095182077\n",
      "Iteration 47495 => Loss: 44.06340490391703212936\n",
      "Iteration 47496 => Loss: 44.06325952547405222504\n",
      "Iteration 47497 => Loss: 44.06311414817197658067\n",
      "Iteration 47498 => Loss: 44.06296877201084782882\n",
      "Iteration 47499 => Loss: 44.06282339699060202065\n",
      "Iteration 47500 => Loss: 44.06267802311125336701\n",
      "Iteration 47501 => Loss: 44.06253265037279476246\n",
      "Iteration 47502 => Loss: 44.06238727877519778531\n",
      "Iteration 47503 => Loss: 44.06224190831849796268\n",
      "Iteration 47504 => Loss: 44.06209653900263134574\n",
      "Iteration 47505 => Loss: 44.06195117082763346161\n",
      "Iteration 47506 => Loss: 44.06180580379346878317\n",
      "Iteration 47507 => Loss: 44.06166043790013731041\n",
      "Iteration 47508 => Loss: 44.06151507314765325418\n",
      "Iteration 47509 => Loss: 44.06136970953594556022\n",
      "Iteration 47510 => Loss: 44.06122434706506396651\n",
      "Iteration 47511 => Loss: 44.06107898573496584049\n",
      "Iteration 47512 => Loss: 44.06093362554567249845\n",
      "Iteration 47513 => Loss: 44.06078826649714841324\n",
      "Iteration 47514 => Loss: 44.06064290858940069029\n",
      "Iteration 47515 => Loss: 44.06049755182242222418\n",
      "Iteration 47516 => Loss: 44.06035219619618459319\n",
      "Iteration 47517 => Loss: 44.06020684171069490276\n",
      "Iteration 47518 => Loss: 44.06006148836592473117\n",
      "Iteration 47519 => Loss: 44.05991613616188118385\n",
      "Iteration 47520 => Loss: 44.05977078509858557709\n",
      "Iteration 47521 => Loss: 44.05962543517596685660\n",
      "Iteration 47522 => Loss: 44.05948008639403923326\n",
      "Iteration 47523 => Loss: 44.05933473875281691789\n",
      "Iteration 47524 => Loss: 44.05918939225228569967\n",
      "Iteration 47525 => Loss: 44.05904404689242426230\n",
      "Iteration 47526 => Loss: 44.05889870267322550035\n",
      "Iteration 47527 => Loss: 44.05875335959466099212\n",
      "Iteration 47528 => Loss: 44.05860801765676626474\n",
      "Iteration 47529 => Loss: 44.05846267685948447479\n",
      "Iteration 47530 => Loss: 44.05831733720284404399\n",
      "Iteration 47531 => Loss: 44.05817199868680944519\n",
      "Iteration 47532 => Loss: 44.05802666131138778383\n",
      "Iteration 47533 => Loss: 44.05788132507657905990\n",
      "Iteration 47534 => Loss: 44.05773598998234774626\n",
      "Iteration 47535 => Loss: 44.05759065602870094835\n",
      "Iteration 47536 => Loss: 44.05744532321565287702\n",
      "Iteration 47537 => Loss: 44.05729999154311826715\n",
      "Iteration 47538 => Loss: 44.05715466101116817299\n",
      "Iteration 47539 => Loss: 44.05700933161978127828\n",
      "Iteration 47540 => Loss: 44.05686400336889363416\n",
      "Iteration 47541 => Loss: 44.05671867625855497863\n",
      "Iteration 47542 => Loss: 44.05657335028872978455\n",
      "Iteration 47543 => Loss: 44.05642802545942515735\n",
      "Iteration 47544 => Loss: 44.05628270177061978075\n",
      "Iteration 47545 => Loss: 44.05613737922229944388\n",
      "Iteration 47546 => Loss: 44.05599205781447125219\n",
      "Iteration 47547 => Loss: 44.05584673754711388938\n",
      "Iteration 47548 => Loss: 44.05570141842021314460\n",
      "Iteration 47549 => Loss: 44.05555610043377612328\n",
      "Iteration 47550 => Loss: 44.05541078358779572000\n",
      "Iteration 47551 => Loss: 44.05526546788224351303\n",
      "Iteration 47552 => Loss: 44.05512015331714081867\n",
      "Iteration 47553 => Loss: 44.05497483989243079350\n",
      "Iteration 47554 => Loss: 44.05482952760814185922\n",
      "Iteration 47555 => Loss: 44.05468421646426691041\n",
      "Iteration 47556 => Loss: 44.05453890646078463078\n",
      "Iteration 47557 => Loss: 44.05439359759767370406\n",
      "Iteration 47558 => Loss: 44.05424828987495544652\n",
      "Iteration 47559 => Loss: 44.05410298329258722561\n",
      "Iteration 47560 => Loss: 44.05395767785059746302\n",
      "Iteration 47561 => Loss: 44.05381237354894352620\n",
      "Iteration 47562 => Loss: 44.05366707038764673143\n",
      "Iteration 47563 => Loss: 44.05352176836665734072\n",
      "Iteration 47564 => Loss: 44.05337646748601088120\n",
      "Iteration 47565 => Loss: 44.05323116774567182574\n",
      "Iteration 47566 => Loss: 44.05308586914562596348\n",
      "Iteration 47567 => Loss: 44.05294057168587329443\n",
      "Iteration 47568 => Loss: 44.05279527536642802943\n",
      "Iteration 47569 => Loss: 44.05264998018725464135\n",
      "Iteration 47570 => Loss: 44.05250468614833181391\n",
      "Iteration 47571 => Loss: 44.05235939324970217967\n",
      "Iteration 47572 => Loss: 44.05221410149129468437\n",
      "Iteration 47573 => Loss: 44.05206881087313064427\n",
      "Iteration 47574 => Loss: 44.05192352139523137566\n",
      "Iteration 47575 => Loss: 44.05177823305752582428\n",
      "Iteration 47576 => Loss: 44.05163294586003530640\n",
      "Iteration 47577 => Loss: 44.05148765980276692744\n",
      "Iteration 47578 => Loss: 44.05134237488568516028\n",
      "Iteration 47579 => Loss: 44.05119709110880421576\n",
      "Iteration 47580 => Loss: 44.05105180847208146133\n",
      "Iteration 47581 => Loss: 44.05090652697553821326\n",
      "Iteration 47582 => Loss: 44.05076124661916026071\n",
      "Iteration 47583 => Loss: 44.05061596740293339280\n",
      "Iteration 47584 => Loss: 44.05047068932686471499\n",
      "Iteration 47585 => Loss: 44.05032541239090448926\n",
      "Iteration 47586 => Loss: 44.05018013659507403190\n",
      "Iteration 47587 => Loss: 44.05003486193936623749\n",
      "Iteration 47588 => Loss: 44.04988958842378110603\n",
      "Iteration 47589 => Loss: 44.04974431604826889952\n",
      "Iteration 47590 => Loss: 44.04959904481287225053\n",
      "Iteration 47591 => Loss: 44.04945377471755563192\n",
      "Iteration 47592 => Loss: 44.04930850576229062199\n",
      "Iteration 47593 => Loss: 44.04916323794709853701\n",
      "Iteration 47594 => Loss: 44.04901797127195806070\n",
      "Iteration 47595 => Loss: 44.04887270573686208763\n",
      "Iteration 47596 => Loss: 44.04872744134179640696\n",
      "Iteration 47597 => Loss: 44.04858217808676812410\n",
      "Iteration 47598 => Loss: 44.04843691597175592278\n",
      "Iteration 47599 => Loss: 44.04829165499675980300\n",
      "Iteration 47600 => Loss: 44.04814639516175844847\n",
      "Iteration 47601 => Loss: 44.04800113646675896462\n",
      "Iteration 47602 => Loss: 44.04785587891171871888\n",
      "Iteration 47603 => Loss: 44.04771062249666613297\n",
      "Iteration 47604 => Loss: 44.04756536722157278518\n",
      "Iteration 47605 => Loss: 44.04742011308643867551\n",
      "Iteration 47606 => Loss: 44.04727486009125669852\n",
      "Iteration 47607 => Loss: 44.04712960823600553795\n",
      "Iteration 47608 => Loss: 44.04698435752069940463\n",
      "Iteration 47609 => Loss: 44.04683910794528856059\n",
      "Iteration 47610 => Loss: 44.04669385950979432209\n",
      "Iteration 47611 => Loss: 44.04654861221422379458\n",
      "Iteration 47612 => Loss: 44.04640336605851302920\n",
      "Iteration 47613 => Loss: 44.04625812104273308023\n",
      "Iteration 47614 => Loss: 44.04611287716677736626\n",
      "Iteration 47615 => Loss: 44.04596763443070273070\n",
      "Iteration 47616 => Loss: 44.04582239283450206813\n",
      "Iteration 47617 => Loss: 44.04567715237811853513\n",
      "Iteration 47618 => Loss: 44.04553191306160186969\n",
      "Iteration 47619 => Loss: 44.04538667488491654467\n",
      "Iteration 47620 => Loss: 44.04524143784805545465\n",
      "Iteration 47621 => Loss: 44.04509620195098307249\n",
      "Iteration 47622 => Loss: 44.04495096719373492533\n",
      "Iteration 47623 => Loss: 44.04480573357628259146\n",
      "Iteration 47624 => Loss: 44.04466050109859764916\n",
      "Iteration 47625 => Loss: 44.04451526976070141473\n",
      "Iteration 47626 => Loss: 44.04437003956257967729\n",
      "Iteration 47627 => Loss: 44.04422481050419690973\n",
      "Iteration 47628 => Loss: 44.04407958258559574460\n",
      "Iteration 47629 => Loss: 44.04393435580670512763\n",
      "Iteration 47630 => Loss: 44.04378913016754637511\n",
      "Iteration 47631 => Loss: 44.04364390566812659245\n",
      "Iteration 47632 => Loss: 44.04349868230841735794\n",
      "Iteration 47633 => Loss: 44.04335346008841156618\n",
      "Iteration 47634 => Loss: 44.04320823900811632257\n",
      "Iteration 47635 => Loss: 44.04306301906748188912\n",
      "Iteration 47636 => Loss: 44.04291780026653668756\n",
      "Iteration 47637 => Loss: 44.04277258260526650702\n",
      "Iteration 47638 => Loss: 44.04262736608366424207\n",
      "Iteration 47639 => Loss: 44.04248215070169436558\n",
      "Iteration 47640 => Loss: 44.04233693645938529926\n",
      "Iteration 47641 => Loss: 44.04219172335668730511\n",
      "Iteration 47642 => Loss: 44.04204651139362880485\n",
      "Iteration 47643 => Loss: 44.04190130057018848220\n",
      "Iteration 47644 => Loss: 44.04175609088635212629\n",
      "Iteration 47645 => Loss: 44.04161088234211973713\n",
      "Iteration 47646 => Loss: 44.04146567493746289301\n",
      "Iteration 47647 => Loss: 44.04132046867239580479\n",
      "Iteration 47648 => Loss: 44.04117526354690426160\n",
      "Iteration 47649 => Loss: 44.04103005956096694717\n",
      "Iteration 47650 => Loss: 44.04088485671457675608\n",
      "Iteration 47651 => Loss: 44.04073965500774789916\n",
      "Iteration 47652 => Loss: 44.04059445444043063844\n",
      "Iteration 47653 => Loss: 44.04044925501266050105\n",
      "Iteration 47654 => Loss: 44.04030405672439485443\n",
      "Iteration 47655 => Loss: 44.04015885957563369857\n",
      "Iteration 47656 => Loss: 44.04001366356639834976\n",
      "Iteration 47657 => Loss: 44.03986846869663196458\n",
      "Iteration 47658 => Loss: 44.03972327496633454302\n",
      "Iteration 47659 => Loss: 44.03957808237555582309\n",
      "Iteration 47660 => Loss: 44.03943289092419632880\n",
      "Iteration 47661 => Loss: 44.03928770061233421984\n",
      "Iteration 47662 => Loss: 44.03914251143987712567\n",
      "Iteration 47663 => Loss: 44.03899732340686057341\n",
      "Iteration 47664 => Loss: 44.03885213651329166851\n",
      "Iteration 47665 => Loss: 44.03870695075913488381\n",
      "Iteration 47666 => Loss: 44.03856176614438311390\n",
      "Iteration 47667 => Loss: 44.03841658266902925334\n",
      "Iteration 47668 => Loss: 44.03827140033308751299\n",
      "Iteration 47669 => Loss: 44.03812621913651526029\n",
      "Iteration 47670 => Loss: 44.03798103907931249523\n",
      "Iteration 47671 => Loss: 44.03783586016149342868\n",
      "Iteration 47672 => Loss: 44.03769068238300121720\n",
      "Iteration 47673 => Loss: 44.03754550574388559880\n",
      "Iteration 47674 => Loss: 44.03740033024408262463\n",
      "Iteration 47675 => Loss: 44.03725515588363492725\n",
      "Iteration 47676 => Loss: 44.03710998266249276867\n",
      "Iteration 47677 => Loss: 44.03696481058067035974\n",
      "Iteration 47678 => Loss: 44.03681963963813927876\n",
      "Iteration 47679 => Loss: 44.03667446983492084200\n",
      "Iteration 47680 => Loss: 44.03652930117099373319\n",
      "Iteration 47681 => Loss: 44.03638413364630821434\n",
      "Iteration 47682 => Loss: 44.03623896726091402343\n",
      "Iteration 47683 => Loss: 44.03609380201475431704\n",
      "Iteration 47684 => Loss: 44.03594863790787883318\n",
      "Iteration 47685 => Loss: 44.03580347494021651755\n",
      "Iteration 47686 => Loss: 44.03565831311180289731\n",
      "Iteration 47687 => Loss: 44.03551315242259533989\n",
      "Iteration 47688 => Loss: 44.03536799287259384528\n",
      "Iteration 47689 => Loss: 44.03522283446182683520\n",
      "Iteration 47690 => Loss: 44.03507767719023746622\n",
      "Iteration 47691 => Loss: 44.03493252105783994921\n",
      "Iteration 47692 => Loss: 44.03478736606461296788\n",
      "Iteration 47693 => Loss: 44.03464221221055652222\n",
      "Iteration 47694 => Loss: 44.03449705949567771768\n",
      "Iteration 47695 => Loss: 44.03435190791991971082\n",
      "Iteration 47696 => Loss: 44.03420675748333934507\n",
      "Iteration 47697 => Loss: 44.03406160818587267158\n",
      "Iteration 47698 => Loss: 44.03391646002751258493\n",
      "Iteration 47699 => Loss: 44.03377131300828040139\n",
      "Iteration 47700 => Loss: 44.03362616712814769926\n",
      "Iteration 47701 => Loss: 44.03348102238712868939\n",
      "Iteration 47702 => Loss: 44.03333587878519495007\n",
      "Iteration 47703 => Loss: 44.03319073632234648130\n",
      "Iteration 47704 => Loss: 44.03304559499856907223\n",
      "Iteration 47705 => Loss: 44.03290045481382719572\n",
      "Iteration 47706 => Loss: 44.03275531576814216805\n",
      "Iteration 47707 => Loss: 44.03261017786149977837\n",
      "Iteration 47708 => Loss: 44.03246504109392134296\n",
      "Iteration 47709 => Loss: 44.03231990546535712383\n",
      "Iteration 47710 => Loss: 44.03217477097579291012\n",
      "Iteration 47711 => Loss: 44.03202963762525001812\n",
      "Iteration 47712 => Loss: 44.03188450541372134239\n",
      "Iteration 47713 => Loss: 44.03173937434115714495\n",
      "Iteration 47714 => Loss: 44.03159424440757163666\n",
      "Iteration 47715 => Loss: 44.03144911561298613378\n",
      "Iteration 47716 => Loss: 44.03130398795732958206\n",
      "Iteration 47717 => Loss: 44.03115886144064461405\n",
      "Iteration 47718 => Loss: 44.03101373606290280804\n",
      "Iteration 47719 => Loss: 44.03086861182411126947\n",
      "Iteration 47720 => Loss: 44.03072348872422736576\n",
      "Iteration 47721 => Loss: 44.03057836676325820235\n",
      "Iteration 47722 => Loss: 44.03043324594121799009\n",
      "Iteration 47723 => Loss: 44.03028812625806409642\n",
      "Iteration 47724 => Loss: 44.03014300771381783761\n",
      "Iteration 47725 => Loss: 44.02999789030844368654\n",
      "Iteration 47726 => Loss: 44.02985277404194164319\n",
      "Iteration 47727 => Loss: 44.02970765891430460215\n",
      "Iteration 47728 => Loss: 44.02956254492551835256\n",
      "Iteration 47729 => Loss: 44.02941743207558999984\n",
      "Iteration 47730 => Loss: 44.02927232036449112229\n",
      "Iteration 47731 => Loss: 44.02912720979222171991\n",
      "Iteration 47732 => Loss: 44.02898210035878889812\n",
      "Iteration 47733 => Loss: 44.02883699206415712979\n",
      "Iteration 47734 => Loss: 44.02869188490831930949\n",
      "Iteration 47735 => Loss: 44.02854677889128254265\n",
      "Iteration 47736 => Loss: 44.02840167401303261840\n",
      "Iteration 47737 => Loss: 44.02825657027354111506\n",
      "Iteration 47738 => Loss: 44.02811146767282934888\n",
      "Iteration 47739 => Loss: 44.02796636621088310903\n",
      "Iteration 47740 => Loss: 44.02782126588767397379\n",
      "Iteration 47741 => Loss: 44.02767616670321615402\n",
      "Iteration 47742 => Loss: 44.02753106865746701715\n",
      "Iteration 47743 => Loss: 44.02738597175044787946\n",
      "Iteration 47744 => Loss: 44.02724087598215874095\n",
      "Iteration 47745 => Loss: 44.02709578135257117992\n",
      "Iteration 47746 => Loss: 44.02695068786165677466\n",
      "Iteration 47747 => Loss: 44.02680559550944394687\n",
      "Iteration 47748 => Loss: 44.02666050429589716941\n",
      "Iteration 47749 => Loss: 44.02651541422103775858\n",
      "Iteration 47750 => Loss: 44.02637032528483018723\n",
      "Iteration 47751 => Loss: 44.02622523748727445536\n",
      "Iteration 47752 => Loss: 44.02608015082834214127\n",
      "Iteration 47753 => Loss: 44.02593506530804745580\n",
      "Iteration 47754 => Loss: 44.02578998092639039896\n",
      "Iteration 47755 => Loss: 44.02564489768334254904\n",
      "Iteration 47756 => Loss: 44.02549981557891811690\n",
      "Iteration 47757 => Loss: 44.02535473461306025911\n",
      "Iteration 47758 => Loss: 44.02520965478579029195\n",
      "Iteration 47759 => Loss: 44.02506457609711532086\n",
      "Iteration 47760 => Loss: 44.02491949854701402955\n",
      "Iteration 47761 => Loss: 44.02477442213544378546\n",
      "Iteration 47762 => Loss: 44.02462934686245432658\n",
      "Iteration 47763 => Loss: 44.02448427272799591492\n",
      "Iteration 47764 => Loss: 44.02433919973208986676\n",
      "Iteration 47765 => Loss: 44.02419412787468644410\n",
      "Iteration 47766 => Loss: 44.02404905715580696324\n",
      "Iteration 47767 => Loss: 44.02390398757544431874\n",
      "Iteration 47768 => Loss: 44.02375891913357719432\n",
      "Iteration 47769 => Loss: 44.02361385183017716827\n",
      "Iteration 47770 => Loss: 44.02346878566527976773\n",
      "Iteration 47771 => Loss: 44.02332372063884946556\n",
      "Iteration 47772 => Loss: 44.02317865675089336719\n",
      "Iteration 47773 => Loss: 44.02303359400136884005\n",
      "Iteration 47774 => Loss: 44.02288853239031851672\n",
      "Iteration 47775 => Loss: 44.02274347191767134291\n",
      "Iteration 47776 => Loss: 44.02259841258345574033\n",
      "Iteration 47777 => Loss: 44.02245335438765749814\n",
      "Iteration 47778 => Loss: 44.02230829733027661632\n",
      "Iteration 47779 => Loss: 44.02216324141130598946\n",
      "Iteration 47780 => Loss: 44.02201818663071719584\n",
      "Iteration 47781 => Loss: 44.02187313298851734089\n",
      "Iteration 47782 => Loss: 44.02172808048467800290\n",
      "Iteration 47783 => Loss: 44.02158302911922049816\n",
      "Iteration 47784 => Loss: 44.02143797889210219410\n",
      "Iteration 47785 => Loss: 44.02129292980332309071\n",
      "Iteration 47786 => Loss: 44.02114788185288318800\n",
      "Iteration 47787 => Loss: 44.02100283504080380226\n",
      "Iteration 47788 => Loss: 44.02085778936703519548\n",
      "Iteration 47789 => Loss: 44.02071274483154184054\n",
      "Iteration 47790 => Loss: 44.02056770143438768628\n",
      "Iteration 47791 => Loss: 44.02042265917550878385\n",
      "Iteration 47792 => Loss: 44.02027761805492644953\n",
      "Iteration 47793 => Loss: 44.02013257807260515619\n",
      "Iteration 47794 => Loss: 44.01998753922855200926\n",
      "Iteration 47795 => Loss: 44.01984250152275279788\n",
      "Iteration 47796 => Loss: 44.01969746495521462748\n",
      "Iteration 47797 => Loss: 44.01955242952590907635\n",
      "Iteration 47798 => Loss: 44.01940739523483614448\n",
      "Iteration 47799 => Loss: 44.01926236208198162103\n",
      "Iteration 47800 => Loss: 44.01911733006733129514\n",
      "Iteration 47801 => Loss: 44.01897229919092069395\n",
      "Iteration 47802 => Loss: 44.01882726945266455232\n",
      "Iteration 47803 => Loss: 44.01868224085261260825\n",
      "Iteration 47804 => Loss: 44.01853721339073644003\n",
      "Iteration 47805 => Loss: 44.01839218706702183681\n",
      "Iteration 47806 => Loss: 44.01824716188146879858\n",
      "Iteration 47807 => Loss: 44.01810213783406311450\n",
      "Iteration 47808 => Loss: 44.01795711492480478455\n",
      "Iteration 47809 => Loss: 44.01781209315366538704\n",
      "Iteration 47810 => Loss: 44.01766707252067334366\n",
      "Iteration 47811 => Loss: 44.01752205302578602186\n",
      "Iteration 47812 => Loss: 44.01737703466898921079\n",
      "Iteration 47813 => Loss: 44.01723201745029001586\n",
      "Iteration 47814 => Loss: 44.01708700136969554251\n",
      "Iteration 47815 => Loss: 44.01694198642717026360\n",
      "Iteration 47816 => Loss: 44.01679697262271417912\n",
      "Iteration 47817 => Loss: 44.01665195995632728909\n",
      "Iteration 47818 => Loss: 44.01650694842798117179\n",
      "Iteration 47819 => Loss: 44.01636193803768293265\n",
      "Iteration 47820 => Loss: 44.01621692878541125538\n",
      "Iteration 47821 => Loss: 44.01607192067118035084\n",
      "Iteration 47822 => Loss: 44.01592691369493337561\n",
      "Iteration 47823 => Loss: 44.01578190785674138397\n",
      "Iteration 47824 => Loss: 44.01563690315651200535\n",
      "Iteration 47825 => Loss: 44.01549189959428076691\n",
      "Iteration 47826 => Loss: 44.01534689717003345777\n",
      "Iteration 47827 => Loss: 44.01520189588375586709\n",
      "Iteration 47828 => Loss: 44.01505689573543378401\n",
      "Iteration 47829 => Loss: 44.01491189672508141939\n",
      "Iteration 47830 => Loss: 44.01476689885265614066\n",
      "Iteration 47831 => Loss: 44.01462190211817926411\n",
      "Iteration 47832 => Loss: 44.01447690652161526259\n",
      "Iteration 47833 => Loss: 44.01433191206299966325\n",
      "Iteration 47834 => Loss: 44.01418691874226851724\n",
      "Iteration 47835 => Loss: 44.01404192655943603540\n",
      "Iteration 47836 => Loss: 44.01389693551450932318\n",
      "Iteration 47837 => Loss: 44.01375194560743153716\n",
      "Iteration 47838 => Loss: 44.01360695683825952074\n",
      "Iteration 47839 => Loss: 44.01346196920692932508\n",
      "Iteration 47840 => Loss: 44.01331698271347647733\n",
      "Iteration 47841 => Loss: 44.01317199735785123949\n",
      "Iteration 47842 => Loss: 44.01302701314008913869\n",
      "Iteration 47843 => Loss: 44.01288203006012622609\n",
      "Iteration 47844 => Loss: 44.01273704811800513426\n",
      "Iteration 47845 => Loss: 44.01259206731366901977\n",
      "Iteration 47846 => Loss: 44.01244708764714630433\n",
      "Iteration 47847 => Loss: 44.01230210911844409338\n",
      "Iteration 47848 => Loss: 44.01215713172749133264\n",
      "Iteration 47849 => Loss: 44.01201215547430933839\n",
      "Iteration 47850 => Loss: 44.01186718035891942691\n",
      "Iteration 47851 => Loss: 44.01172220638127186021\n",
      "Iteration 47852 => Loss: 44.01157723354137374372\n",
      "Iteration 47853 => Loss: 44.01143226183920376116\n",
      "Iteration 47854 => Loss: 44.01128729127480454508\n",
      "Iteration 47855 => Loss: 44.01114232184809083037\n",
      "Iteration 47856 => Loss: 44.01099735355909814416\n",
      "Iteration 47857 => Loss: 44.01085238640780517017\n",
      "Iteration 47858 => Loss: 44.01070742039421901382\n",
      "Iteration 47859 => Loss: 44.01056245551831125340\n",
      "Iteration 47860 => Loss: 44.01041749178008188892\n",
      "Iteration 47861 => Loss: 44.01027252917951670952\n",
      "Iteration 47862 => Loss: 44.01012756771660860977\n",
      "Iteration 47863 => Loss: 44.00998260739133627339\n",
      "Iteration 47864 => Loss: 44.00983764820372812210\n",
      "Iteration 47865 => Loss: 44.00969269015374862875\n",
      "Iteration 47866 => Loss: 44.00954773324139068791\n",
      "Iteration 47867 => Loss: 44.00940277746665429959\n",
      "Iteration 47868 => Loss: 44.00925782282950393665\n",
      "Iteration 47869 => Loss: 44.00911286932996091537\n",
      "Iteration 47870 => Loss: 44.00896791696800391946\n",
      "Iteration 47871 => Loss: 44.00882296574362584352\n",
      "Iteration 47872 => Loss: 44.00867801565681247666\n",
      "Iteration 47873 => Loss: 44.00853306670757092434\n",
      "Iteration 47874 => Loss: 44.00838811889587987025\n",
      "Iteration 47875 => Loss: 44.00824317222171799813\n",
      "Iteration 47876 => Loss: 44.00809822668509951882\n",
      "Iteration 47877 => Loss: 44.00795328228601732690\n",
      "Iteration 47878 => Loss: 44.00780833902443589523\n",
      "Iteration 47879 => Loss: 44.00766339690035522381\n",
      "Iteration 47880 => Loss: 44.00751845591378241807\n",
      "Iteration 47881 => Loss: 44.00737351606470326715\n",
      "Iteration 47882 => Loss: 44.00722857735309645477\n",
      "Iteration 47883 => Loss: 44.00708363977897619179\n",
      "Iteration 47884 => Loss: 44.00693870334229984564\n",
      "Iteration 47885 => Loss: 44.00679376804308162718\n",
      "Iteration 47886 => Loss: 44.00664883388131443098\n",
      "Iteration 47887 => Loss: 44.00650390085698404619\n",
      "Iteration 47888 => Loss: 44.00635896897006205108\n",
      "Iteration 47889 => Loss: 44.00621403822059107824\n",
      "Iteration 47890 => Loss: 44.00606910860848586253\n",
      "Iteration 47891 => Loss: 44.00592418013381745823\n",
      "Iteration 47892 => Loss: 44.00577925279652191648\n",
      "Iteration 47893 => Loss: 44.00563432659661344815\n",
      "Iteration 47894 => Loss: 44.00548940153408494780\n",
      "Iteration 47895 => Loss: 44.00534447760890799373\n",
      "Iteration 47896 => Loss: 44.00519955482108258593\n",
      "Iteration 47897 => Loss: 44.00505463317063714612\n",
      "Iteration 47898 => Loss: 44.00490971265747930374\n",
      "Iteration 47899 => Loss: 44.00476479328168721850\n",
      "Iteration 47900 => Loss: 44.00461987504318983611\n",
      "Iteration 47901 => Loss: 44.00447495794202268371\n",
      "Iteration 47902 => Loss: 44.00433004197816444503\n",
      "Iteration 47903 => Loss: 44.00418512715157248749\n",
      "Iteration 47904 => Loss: 44.00404021346228233824\n",
      "Iteration 47905 => Loss: 44.00389530091025847014\n",
      "Iteration 47906 => Loss: 44.00375038949549377776\n",
      "Iteration 47907 => Loss: 44.00360547921799536653\n",
      "Iteration 47908 => Loss: 44.00346057007776323644\n",
      "Iteration 47909 => Loss: 44.00331566207476896579\n",
      "Iteration 47910 => Loss: 44.00317075520897702745\n",
      "Iteration 47911 => Loss: 44.00302584948042294855\n",
      "Iteration 47912 => Loss: 44.00288094488907120194\n",
      "Iteration 47913 => Loss: 44.00273604143494310392\n",
      "Iteration 47914 => Loss: 44.00259113911797470564\n",
      "Iteration 47915 => Loss: 44.00244623793821574509\n",
      "Iteration 47916 => Loss: 44.00230133789565201141\n",
      "Iteration 47917 => Loss: 44.00215643899022666119\n",
      "Iteration 47918 => Loss: 44.00201154122196101071\n",
      "Iteration 47919 => Loss: 44.00186664459086216539\n",
      "Iteration 47920 => Loss: 44.00172174909688749267\n",
      "Iteration 47921 => Loss: 44.00157685474005120341\n",
      "Iteration 47922 => Loss: 44.00143196152035329760\n",
      "Iteration 47923 => Loss: 44.00128706943775114269\n",
      "Iteration 47924 => Loss: 44.00114217849226605495\n",
      "Iteration 47925 => Loss: 44.00099728868386961267\n",
      "Iteration 47926 => Loss: 44.00085240001255471043\n",
      "Iteration 47927 => Loss: 44.00070751247831424280\n",
      "Iteration 47928 => Loss: 44.00056262608117663149\n",
      "Iteration 47929 => Loss: 44.00041774082107082222\n",
      "Iteration 47930 => Loss: 44.00027285669801102586\n",
      "Iteration 47931 => Loss: 44.00012797371203276953\n",
      "Iteration 47932 => Loss: 43.99998309186306499896\n",
      "Iteration 47933 => Loss: 43.99983821115110771416\n",
      "Iteration 47934 => Loss: 43.99969333157618223140\n",
      "Iteration 47935 => Loss: 43.99954845313826012898\n",
      "Iteration 47936 => Loss: 43.99940357583735561775\n",
      "Iteration 47937 => Loss: 43.99925869967341185429\n",
      "Iteration 47938 => Loss: 43.99911382464646436574\n",
      "Iteration 47939 => Loss: 43.99896895075647051954\n",
      "Iteration 47940 => Loss: 43.99882407800345873738\n",
      "Iteration 47941 => Loss: 43.99867920638740059758\n",
      "Iteration 47942 => Loss: 43.99853433590826767841\n",
      "Iteration 47943 => Loss: 43.99838946656609550701\n",
      "Iteration 47944 => Loss: 43.99824459836083434539\n",
      "Iteration 47945 => Loss: 43.99809973129249840440\n",
      "Iteration 47946 => Loss: 43.99795486536107347320\n",
      "Iteration 47947 => Loss: 43.99781000056654534092\n",
      "Iteration 47948 => Loss: 43.99766513690890690214\n",
      "Iteration 47949 => Loss: 43.99752027438814394600\n",
      "Iteration 47950 => Loss: 43.99737541300427778879\n",
      "Iteration 47951 => Loss: 43.99723055275725158708\n",
      "Iteration 47952 => Loss: 43.99708569364709376259\n",
      "Iteration 47953 => Loss: 43.99694083567377589361\n",
      "Iteration 47954 => Loss: 43.99679597883730508556\n",
      "Iteration 47955 => Loss: 43.99665112313765291674\n",
      "Iteration 47956 => Loss: 43.99650626857481938714\n",
      "Iteration 47957 => Loss: 43.99636141514879739134\n",
      "Iteration 47958 => Loss: 43.99621656285958692933\n",
      "Iteration 47959 => Loss: 43.99607171170715957942\n",
      "Iteration 47960 => Loss: 43.99592686169150823616\n",
      "Iteration 47961 => Loss: 43.99578201281267553213\n",
      "Iteration 47962 => Loss: 43.99563716507056199134\n",
      "Iteration 47963 => Loss: 43.99549231846523156264\n",
      "Iteration 47964 => Loss: 43.99534747299664161346\n",
      "Iteration 47965 => Loss: 43.99520262866477082753\n",
      "Iteration 47966 => Loss: 43.99505778546966894282\n",
      "Iteration 47967 => Loss: 43.99491294341125779965\n",
      "Iteration 47968 => Loss: 43.99476810248958003058\n",
      "Iteration 47969 => Loss: 43.99462326270459300304\n",
      "Iteration 47970 => Loss: 43.99447842405631092788\n",
      "Iteration 47971 => Loss: 43.99433358654471959426\n",
      "Iteration 47972 => Loss: 43.99418875016978347503\n",
      "Iteration 47973 => Loss: 43.99404391493152388648\n",
      "Iteration 47974 => Loss: 43.99389908082993372318\n",
      "Iteration 47975 => Loss: 43.99375424786498456342\n",
      "Iteration 47976 => Loss: 43.99360941603669061806\n",
      "Iteration 47977 => Loss: 43.99346458534503057081\n",
      "Iteration 47978 => Loss: 43.99331975578997599996\n",
      "Iteration 47979 => Loss: 43.99317492737152690552\n",
      "Iteration 47980 => Loss: 43.99303010008970460376\n",
      "Iteration 47981 => Loss: 43.99288527394448777841\n",
      "Iteration 47982 => Loss: 43.99274044893581958604\n",
      "Iteration 47983 => Loss: 43.99259562506377818636\n",
      "Iteration 47984 => Loss: 43.99245080232827120881\n",
      "Iteration 47985 => Loss: 43.99230598072936260223\n",
      "Iteration 47986 => Loss: 43.99216116026697420693\n",
      "Iteration 47987 => Loss: 43.99201634094113444462\n",
      "Iteration 47988 => Loss: 43.99187152275182910444\n",
      "Iteration 47989 => Loss: 43.99172670569904397553\n",
      "Iteration 47990 => Loss: 43.99158188978280747961\n",
      "Iteration 47991 => Loss: 43.99143707500304145697\n",
      "Iteration 47992 => Loss: 43.99129226135979564560\n",
      "Iteration 47993 => Loss: 43.99114744885300609667\n",
      "Iteration 47994 => Loss: 43.99100263748272965358\n",
      "Iteration 47995 => Loss: 43.99085782724893078921\n",
      "Iteration 47996 => Loss: 43.99071301815156687098\n",
      "Iteration 47997 => Loss: 43.99056821019069474232\n",
      "Iteration 47998 => Loss: 43.99042340336622913810\n",
      "Iteration 47999 => Loss: 43.99027859767822690173\n",
      "Iteration 48000 => Loss: 43.99013379312663118981\n",
      "Iteration 48001 => Loss: 43.98998898971147752945\n",
      "Iteration 48002 => Loss: 43.98984418743273749897\n",
      "Iteration 48003 => Loss: 43.98969938629036136035\n",
      "Iteration 48004 => Loss: 43.98955458628439174618\n",
      "Iteration 48005 => Loss: 43.98940978741480734016\n",
      "Iteration 48006 => Loss: 43.98926498968162235315\n",
      "Iteration 48007 => Loss: 43.98912019308477994173\n",
      "Iteration 48008 => Loss: 43.98897539762428721133\n",
      "Iteration 48009 => Loss: 43.98883060330014416195\n",
      "Iteration 48010 => Loss: 43.98868581011235079359\n",
      "Iteration 48011 => Loss: 43.98854101806085736825\n",
      "Iteration 48012 => Loss: 43.98839622714572072937\n",
      "Iteration 48013 => Loss: 43.98825143736688403351\n",
      "Iteration 48014 => Loss: 43.98810664872435438610\n",
      "Iteration 48015 => Loss: 43.98796186121809626002\n",
      "Iteration 48016 => Loss: 43.98781707484813807696\n",
      "Iteration 48017 => Loss: 43.98767228961445852065\n",
      "Iteration 48018 => Loss: 43.98752750551703627480\n",
      "Iteration 48019 => Loss: 43.98738272255588555026\n",
      "Iteration 48020 => Loss: 43.98723794073097792534\n",
      "Iteration 48021 => Loss: 43.98709316004231340003\n",
      "Iteration 48022 => Loss: 43.98694838048986355261\n",
      "Iteration 48023 => Loss: 43.98680360207364259395\n",
      "Iteration 48024 => Loss: 43.98665882479365052404\n",
      "Iteration 48025 => Loss: 43.98651404864984471033\n",
      "Iteration 48026 => Loss: 43.98636927364223225823\n",
      "Iteration 48027 => Loss: 43.98622449977083448402\n",
      "Iteration 48028 => Loss: 43.98607972703559454430\n",
      "Iteration 48029 => Loss: 43.98593495543651954449\n",
      "Iteration 48030 => Loss: 43.98579018497362369544\n",
      "Iteration 48031 => Loss: 43.98564541564685015373\n",
      "Iteration 48032 => Loss: 43.98550064745624155194\n",
      "Iteration 48033 => Loss: 43.98535588040175525748\n",
      "Iteration 48034 => Loss: 43.98521111448339837580\n",
      "Iteration 48035 => Loss: 43.98506634970115669603\n",
      "Iteration 48036 => Loss: 43.98492158605503021818\n",
      "Iteration 48037 => Loss: 43.98477682354497630968\n",
      "Iteration 48038 => Loss: 43.98463206217103049767\n",
      "Iteration 48039 => Loss: 43.98448730193315725501\n",
      "Iteration 48040 => Loss: 43.98434254283134947627\n",
      "Iteration 48041 => Loss: 43.98419778486561426689\n",
      "Iteration 48042 => Loss: 43.98405302803593031058\n",
      "Iteration 48043 => Loss: 43.98390827234229050191\n",
      "Iteration 48044 => Loss: 43.98376351778468063003\n",
      "Iteration 48045 => Loss: 43.98361876436310069494\n",
      "Iteration 48046 => Loss: 43.98347401207753648578\n",
      "Iteration 48047 => Loss: 43.98332926092798089712\n",
      "Iteration 48048 => Loss: 43.98318451091442682355\n",
      "Iteration 48049 => Loss: 43.98303976203686715962\n",
      "Iteration 48050 => Loss: 43.98289501429528058907\n",
      "Iteration 48051 => Loss: 43.98275026768966000645\n",
      "Iteration 48052 => Loss: 43.98260552222003383349\n",
      "Iteration 48053 => Loss: 43.98246077788632391048\n",
      "Iteration 48054 => Loss: 43.98231603468859418626\n",
      "Iteration 48055 => Loss: 43.98217129262677360657\n",
      "Iteration 48056 => Loss: 43.98202655170089769854\n",
      "Iteration 48057 => Loss: 43.98188181191093093503\n",
      "Iteration 48058 => Loss: 43.98173707325687331604\n",
      "Iteration 48059 => Loss: 43.98159233573871773615\n",
      "Iteration 48060 => Loss: 43.98144759935647130078\n",
      "Iteration 48061 => Loss: 43.98130286411009137737\n",
      "Iteration 48062 => Loss: 43.98115812999959217677\n",
      "Iteration 48063 => Loss: 43.98101339702496659356\n",
      "Iteration 48064 => Loss: 43.98086866518617910060\n",
      "Iteration 48065 => Loss: 43.98072393448324390874\n",
      "Iteration 48066 => Loss: 43.98057920491615391256\n",
      "Iteration 48067 => Loss: 43.98043447648489490120\n",
      "Iteration 48068 => Loss: 43.98028974918945266381\n",
      "Iteration 48069 => Loss: 43.98014502302983430582\n",
      "Iteration 48070 => Loss: 43.98000029800601140550\n",
      "Iteration 48071 => Loss: 43.97985557411796975202\n",
      "Iteration 48072 => Loss: 43.97971085136573066166\n",
      "Iteration 48073 => Loss: 43.97956612974925860726\n",
      "Iteration 48074 => Loss: 43.97942140926855358884\n",
      "Iteration 48075 => Loss: 43.97927668992362271183\n",
      "Iteration 48076 => Loss: 43.97913197171441623823\n",
      "Iteration 48077 => Loss: 43.97898725464097680060\n",
      "Iteration 48078 => Loss: 43.97884253870326176639\n",
      "Iteration 48079 => Loss: 43.97869782390125692473\n",
      "Iteration 48080 => Loss: 43.97855311023498359191\n",
      "Iteration 48081 => Loss: 43.97840839770440624079\n",
      "Iteration 48082 => Loss: 43.97826368630951776595\n",
      "Iteration 48083 => Loss: 43.97811897605032527281\n",
      "Iteration 48084 => Loss: 43.97797426692680744509\n",
      "Iteration 48085 => Loss: 43.97782955893897138822\n",
      "Iteration 48086 => Loss: 43.97768485208678868048\n",
      "Iteration 48087 => Loss: 43.97754014637025932188\n",
      "Iteration 48088 => Loss: 43.97739544178936910157\n",
      "Iteration 48089 => Loss: 43.97725073834409670326\n",
      "Iteration 48090 => Loss: 43.97710603603446344323\n",
      "Iteration 48091 => Loss: 43.97696133486045511063\n",
      "Iteration 48092 => Loss: 43.97681663482206460003\n",
      "Iteration 48093 => Loss: 43.97667193591924217344\n",
      "Iteration 48094 => Loss: 43.97652723815202335800\n",
      "Iteration 48095 => Loss: 43.97638254152037262656\n",
      "Iteration 48096 => Loss: 43.97623784602430419000\n",
      "Iteration 48097 => Loss: 43.97609315166382515372\n",
      "Iteration 48098 => Loss: 43.97594845843884314718\n",
      "Iteration 48099 => Loss: 43.97580376634946475178\n",
      "Iteration 48100 => Loss: 43.97565907539558338613\n",
      "Iteration 48101 => Loss: 43.97551438557724168277\n",
      "Iteration 48102 => Loss: 43.97536969689441832543\n",
      "Iteration 48103 => Loss: 43.97522500934709910325\n",
      "Iteration 48104 => Loss: 43.97508032293525559453\n",
      "Iteration 48105 => Loss: 43.97493563765894464268\n",
      "Iteration 48106 => Loss: 43.97479095351810940429\n",
      "Iteration 48107 => Loss: 43.97464627051273566849\n",
      "Iteration 48108 => Loss: 43.97450158864283054072\n",
      "Iteration 48109 => Loss: 43.97435690790838691555\n",
      "Iteration 48110 => Loss: 43.97421222830939768755\n",
      "Iteration 48111 => Loss: 43.97406754984582022416\n",
      "Iteration 48112 => Loss: 43.97392287251768294709\n",
      "Iteration 48113 => Loss: 43.97377819632497164548\n",
      "Iteration 48114 => Loss: 43.97363352126767210848\n",
      "Iteration 48115 => Loss: 43.97348884734575591438\n",
      "Iteration 48116 => Loss: 43.97334417455927280116\n",
      "Iteration 48117 => Loss: 43.97319950290813039828\n",
      "Iteration 48118 => Loss: 43.97305483239239265458\n",
      "Iteration 48119 => Loss: 43.97291016301200983207\n",
      "Iteration 48120 => Loss: 43.97276549476698193075\n",
      "Iteration 48121 => Loss: 43.97262082765730184519\n",
      "Iteration 48122 => Loss: 43.97247616168296246997\n",
      "Iteration 48123 => Loss: 43.97233149684395669965\n",
      "Iteration 48124 => Loss: 43.97218683314028453424\n",
      "Iteration 48125 => Loss: 43.97204217057188913031\n",
      "Iteration 48126 => Loss: 43.97189750913885575301\n",
      "Iteration 48127 => Loss: 43.97175284884107782091\n",
      "Iteration 48128 => Loss: 43.97160818967858375572\n",
      "Iteration 48129 => Loss: 43.97146353165136645202\n",
      "Iteration 48130 => Loss: 43.97131887475944722610\n",
      "Iteration 48131 => Loss: 43.97117421900276212909\n",
      "Iteration 48132 => Loss: 43.97102956438134668815\n",
      "Iteration 48133 => Loss: 43.97088491089515116528\n",
      "Iteration 48134 => Loss: 43.97074025854418266590\n",
      "Iteration 48135 => Loss: 43.97059560732846961173\n",
      "Iteration 48136 => Loss: 43.97045095724794094849\n",
      "Iteration 48137 => Loss: 43.97030630830265351960\n",
      "Iteration 48138 => Loss: 43.97016166049253627079\n",
      "Iteration 48139 => Loss: 43.97001701381763183463\n",
      "Iteration 48140 => Loss: 43.96987236827788336768\n",
      "Iteration 48141 => Loss: 43.96972772387331218624\n",
      "Iteration 48142 => Loss: 43.96958308060391118488\n",
      "Iteration 48143 => Loss: 43.96943843846964483646\n",
      "Iteration 48144 => Loss: 43.96929379747052735183\n",
      "Iteration 48145 => Loss: 43.96914915760655873100\n",
      "Iteration 48146 => Loss: 43.96900451887770344683\n",
      "Iteration 48147 => Loss: 43.96885988128396149932\n",
      "Iteration 48148 => Loss: 43.96871524482533288847\n",
      "Iteration 48149 => Loss: 43.96857060950180340342\n",
      "Iteration 48150 => Loss: 43.96842597531336593875\n",
      "Iteration 48151 => Loss: 43.96828134226004181073\n",
      "Iteration 48152 => Loss: 43.96813671034174575425\n",
      "Iteration 48153 => Loss: 43.96799207955851329643\n",
      "Iteration 48154 => Loss: 43.96784744991035154271\n",
      "Iteration 48155 => Loss: 43.96770282139723207138\n",
      "Iteration 48156 => Loss: 43.96755819401914777700\n",
      "Iteration 48157 => Loss: 43.96741356777609865958\n",
      "Iteration 48158 => Loss: 43.96726894266807050826\n",
      "Iteration 48159 => Loss: 43.96712431869503490134\n",
      "Iteration 48160 => Loss: 43.96697969585701315509\n",
      "Iteration 48161 => Loss: 43.96683507415399105867\n",
      "Iteration 48162 => Loss: 43.96669045358594019035\n",
      "Iteration 48163 => Loss: 43.96654583415285344472\n",
      "Iteration 48164 => Loss: 43.96640121585476634891\n",
      "Iteration 48165 => Loss: 43.96625659869160784865\n",
      "Iteration 48166 => Loss: 43.96611198266341347107\n",
      "Iteration 48167 => Loss: 43.96596736777014768904\n",
      "Iteration 48168 => Loss: 43.96582275401181050256\n",
      "Iteration 48169 => Loss: 43.96567814138840191163\n",
      "Iteration 48170 => Loss: 43.96553352989989349453\n",
      "Iteration 48171 => Loss: 43.96538891954629946213\n",
      "Iteration 48172 => Loss: 43.96524431032758428728\n",
      "Iteration 48173 => Loss: 43.96509970224379060255\n",
      "Iteration 48174 => Loss: 43.96495509529484024824\n",
      "Iteration 48175 => Loss: 43.96481048948076164606\n",
      "Iteration 48176 => Loss: 43.96466588480155479601\n",
      "Iteration 48177 => Loss: 43.96452128125720548724\n",
      "Iteration 48178 => Loss: 43.96437667884767108717\n",
      "Iteration 48179 => Loss: 43.96423207757298712295\n",
      "Iteration 48180 => Loss: 43.96408747743313227829\n",
      "Iteration 48181 => Loss: 43.96394287842807102606\n",
      "Iteration 48182 => Loss: 43.96379828055782468255\n",
      "Iteration 48183 => Loss: 43.96365368382235772060\n",
      "Iteration 48184 => Loss: 43.96350908822171277279\n",
      "Iteration 48185 => Loss: 43.96336449375582589028\n",
      "Iteration 48186 => Loss: 43.96321990042470417848\n",
      "Iteration 48187 => Loss: 43.96307530822834053197\n",
      "Iteration 48188 => Loss: 43.96293071716673495075\n",
      "Iteration 48189 => Loss: 43.96278612723989454025\n",
      "Iteration 48190 => Loss: 43.96264153844776245705\n",
      "Iteration 48191 => Loss: 43.96249695079036001744\n",
      "Iteration 48192 => Loss: 43.96235236426768722140\n",
      "Iteration 48193 => Loss: 43.96220777887970854181\n",
      "Iteration 48194 => Loss: 43.96206319462642397866\n",
      "Iteration 48195 => Loss: 43.96191861150784063739\n",
      "Iteration 48196 => Loss: 43.96177402952393009627\n",
      "Iteration 48197 => Loss: 43.96162944867468524990\n",
      "Iteration 48198 => Loss: 43.96148486896012030911\n",
      "Iteration 48199 => Loss: 43.96134029038020685221\n",
      "Iteration 48200 => Loss: 43.96119571293493066833\n",
      "Iteration 48201 => Loss: 43.96105113662429175747\n",
      "Iteration 48202 => Loss: 43.96090656144828301422\n",
      "Iteration 48203 => Loss: 43.96076198740687601685\n",
      "Iteration 48204 => Loss: 43.96061741450010629251\n",
      "Iteration 48205 => Loss: 43.96047284272792410320\n",
      "Iteration 48206 => Loss: 43.96032827209033655436\n",
      "Iteration 48207 => Loss: 43.96018370258732232969\n",
      "Iteration 48208 => Loss: 43.96003913421888142921\n",
      "Iteration 48209 => Loss: 43.95989456698502095833\n",
      "Iteration 48210 => Loss: 43.95975000088571249535\n",
      "Iteration 48211 => Loss: 43.95960543592094182941\n",
      "Iteration 48212 => Loss: 43.95946087209072317137\n",
      "Iteration 48213 => Loss: 43.95931630939502099409\n",
      "Iteration 48214 => Loss: 43.95917174783385661385\n",
      "Iteration 48215 => Loss: 43.95902718740717318724\n",
      "Iteration 48216 => Loss: 43.95888262811502755767\n",
      "Iteration 48217 => Loss: 43.95873806995735577630\n",
      "Iteration 48218 => Loss: 43.95859351293415784312\n",
      "Iteration 48219 => Loss: 43.95844895704545507442\n",
      "Iteration 48220 => Loss: 43.95830440229121194307\n",
      "Iteration 48221 => Loss: 43.95815984867142134362\n",
      "Iteration 48222 => Loss: 43.95801529618607617067\n",
      "Iteration 48223 => Loss: 43.95787074483518352963\n",
      "Iteration 48224 => Loss: 43.95772619461873631508\n",
      "Iteration 48225 => Loss: 43.95758164553669899988\n",
      "Iteration 48226 => Loss: 43.95743709758907868945\n",
      "Iteration 48227 => Loss: 43.95729255077584696210\n",
      "Iteration 48228 => Loss: 43.95714800509703223952\n",
      "Iteration 48229 => Loss: 43.95700346055257767830\n",
      "Iteration 48230 => Loss: 43.95685891714251170015\n",
      "Iteration 48231 => Loss: 43.95671437486682719964\n",
      "Iteration 48232 => Loss: 43.95656983372548864963\n",
      "Iteration 48233 => Loss: 43.95642529371851026099\n",
      "Iteration 48234 => Loss: 43.95628075484587782285\n",
      "Iteration 48235 => Loss: 43.95613621710756291350\n",
      "Iteration 48236 => Loss: 43.95599168050357974380\n",
      "Iteration 48237 => Loss: 43.95584714503392831375\n",
      "Iteration 48238 => Loss: 43.95570261069855888536\n",
      "Iteration 48239 => Loss: 43.95555807749749988034\n",
      "Iteration 48240 => Loss: 43.95541354543070866612\n",
      "Iteration 48241 => Loss: 43.95526901449824208612\n",
      "Iteration 48242 => Loss: 43.95512448470002198064\n",
      "Iteration 48243 => Loss: 43.95497995603606256054\n",
      "Iteration 48244 => Loss: 43.95483542850634961496\n",
      "Iteration 48245 => Loss: 43.95469090211089024933\n",
      "Iteration 48246 => Loss: 43.95454637684967025280\n",
      "Iteration 48247 => Loss: 43.95440185272266830907\n",
      "Iteration 48248 => Loss: 43.95425732972989862901\n",
      "Iteration 48249 => Loss: 43.95411280787132568548\n",
      "Iteration 48250 => Loss: 43.95396828714696368934\n",
      "Iteration 48251 => Loss: 43.95382376755677000801\n",
      "Iteration 48252 => Loss: 43.95367924910078016865\n",
      "Iteration 48253 => Loss: 43.95353473177895864410\n",
      "Iteration 48254 => Loss: 43.95339021559129832895\n",
      "Iteration 48255 => Loss: 43.95324570053778501233\n",
      "Iteration 48256 => Loss: 43.95310118661842579968\n",
      "Iteration 48257 => Loss: 43.95295667383319937471\n",
      "Iteration 48258 => Loss: 43.95281216218209863200\n",
      "Iteration 48259 => Loss: 43.95266765166513778240\n",
      "Iteration 48260 => Loss: 43.95252314228226708792\n",
      "Iteration 48261 => Loss: 43.95237863403350786484\n",
      "Iteration 48262 => Loss: 43.95223412691883879688\n",
      "Iteration 48263 => Loss: 43.95208962093826698947\n",
      "Iteration 48264 => Loss: 43.95194511609174981004\n",
      "Iteration 48265 => Loss: 43.95180061237931568030\n",
      "Iteration 48266 => Loss: 43.95165610980092907312\n",
      "Iteration 48267 => Loss: 43.95151160835658998849\n",
      "Iteration 48268 => Loss: 43.95136710804630553184\n",
      "Iteration 48269 => Loss: 43.95122260887004728147\n",
      "Iteration 48270 => Loss: 43.95107811082780813194\n",
      "Iteration 48271 => Loss: 43.95093361391956676698\n",
      "Iteration 48272 => Loss: 43.95078911814535160829\n",
      "Iteration 48273 => Loss: 43.95064462350511291788\n",
      "Iteration 48274 => Loss: 43.95050012999888622289\n",
      "Iteration 48275 => Loss: 43.95035563762660046905\n",
      "Iteration 48276 => Loss: 43.95021114638830539434\n",
      "Iteration 48277 => Loss: 43.95006665628397257706\n",
      "Iteration 48278 => Loss: 43.94992216731358070092\n",
      "Iteration 48279 => Loss: 43.94977767947713687136\n",
      "Iteration 48280 => Loss: 43.94963319277461266665\n",
      "Iteration 48281 => Loss: 43.94948870720603650852\n",
      "Iteration 48282 => Loss: 43.94934422277136576440\n",
      "Iteration 48283 => Loss: 43.94919973947060043429\n",
      "Iteration 48284 => Loss: 43.94905525730372630733\n",
      "Iteration 48285 => Loss: 43.94891077627072917267\n",
      "Iteration 48286 => Loss: 43.94876629637164455744\n",
      "Iteration 48287 => Loss: 43.94862181760640851280\n",
      "Iteration 48288 => Loss: 43.94847733997505656589\n",
      "Iteration 48289 => Loss: 43.94833286347751766243\n",
      "Iteration 48290 => Loss: 43.94818838811384154042\n",
      "Iteration 48291 => Loss: 43.94804391388399977814\n",
      "Iteration 48292 => Loss: 43.94789944078800658644\n",
      "Iteration 48293 => Loss: 43.94775496882579801650\n",
      "Iteration 48294 => Loss: 43.94761049799741670085\n",
      "Iteration 48295 => Loss: 43.94746602830283421781\n",
      "Iteration 48296 => Loss: 43.94732155974203635651\n",
      "Iteration 48297 => Loss: 43.94717709231503022238\n",
      "Iteration 48298 => Loss: 43.94703262602178739371\n",
      "Iteration 48299 => Loss: 43.94688816086231497593\n",
      "Iteration 48300 => Loss: 43.94674369683659875818\n",
      "Iteration 48301 => Loss: 43.94659923394461031876\n",
      "Iteration 48302 => Loss: 43.94645477218636386851\n",
      "Iteration 48303 => Loss: 43.94631031156186651287\n",
      "Iteration 48304 => Loss: 43.94616585207107561928\n",
      "Iteration 48305 => Loss: 43.94602139371398408230\n",
      "Iteration 48306 => Loss: 43.94587693649060611278\n",
      "Iteration 48307 => Loss: 43.94573248040093460531\n",
      "Iteration 48308 => Loss: 43.94558802544491271647\n",
      "Iteration 48309 => Loss: 43.94544357162259018423\n",
      "Iteration 48310 => Loss: 43.94529911893393148148\n",
      "Iteration 48311 => Loss: 43.94515466737892950277\n",
      "Iteration 48312 => Loss: 43.94501021695756293184\n",
      "Iteration 48313 => Loss: 43.94486576766985308495\n",
      "Iteration 48314 => Loss: 43.94472131951576443498\n",
      "Iteration 48315 => Loss: 43.94457687249528987650\n",
      "Iteration 48316 => Loss: 43.94443242660843651493\n",
      "Iteration 48317 => Loss: 43.94428798185519013941\n",
      "Iteration 48318 => Loss: 43.94414353823553653910\n",
      "Iteration 48319 => Loss: 43.94399909574946860857\n",
      "Iteration 48320 => Loss: 43.94385465439696503154\n",
      "Iteration 48321 => Loss: 43.94371021417804712428\n",
      "Iteration 48322 => Loss: 43.94356577509269357051\n",
      "Iteration 48323 => Loss: 43.94342133714086173768\n",
      "Iteration 48324 => Loss: 43.94327690032259425834\n",
      "Iteration 48325 => Loss: 43.94313246463786271079\n",
      "Iteration 48326 => Loss: 43.94298803008664577874\n",
      "Iteration 48327 => Loss: 43.94284359666895056762\n",
      "Iteration 48328 => Loss: 43.94269916438475576115\n",
      "Iteration 48329 => Loss: 43.94255473323406846475\n",
      "Iteration 48330 => Loss: 43.94241030321682472959\n",
      "Iteration 48331 => Loss: 43.94226587433309560993\n",
      "Iteration 48332 => Loss: 43.94212144658285268406\n",
      "Iteration 48333 => Loss: 43.94197701996606042485\n",
      "Iteration 48334 => Loss: 43.94183259448269751601\n",
      "Iteration 48335 => Loss: 43.94168817013279237926\n",
      "Iteration 48336 => Loss: 43.94154374691633080374\n",
      "Iteration 48337 => Loss: 43.94139932483328436774\n",
      "Iteration 48338 => Loss: 43.94125490388366017669\n",
      "Iteration 48339 => Loss: 43.94111048406742270345\n",
      "Iteration 48340 => Loss: 43.94096606538461458058\n",
      "Iteration 48341 => Loss: 43.94082164783518607010\n",
      "Iteration 48342 => Loss: 43.94067723141913717200\n",
      "Iteration 48343 => Loss: 43.94053281613647499171\n",
      "Iteration 48344 => Loss: 43.94038840198716400209\n",
      "Iteration 48345 => Loss: 43.94024398897119709773\n",
      "Iteration 48346 => Loss: 43.94009957708858138403\n",
      "Iteration 48347 => Loss: 43.93995516633930975559\n",
      "Iteration 48348 => Loss: 43.93981075672335379068\n",
      "Iteration 48349 => Loss: 43.93966634824074191101\n",
      "Iteration 48350 => Loss: 43.93952194089142437861\n",
      "Iteration 48351 => Loss: 43.93937753467539408803\n",
      "Iteration 48352 => Loss: 43.93923312959267946098\n",
      "Iteration 48353 => Loss: 43.93908872564323786492\n",
      "Iteration 48354 => Loss: 43.93894432282706929982\n",
      "Iteration 48355 => Loss: 43.93879992114415955484\n",
      "Iteration 48356 => Loss: 43.93865552059452284084\n",
      "Iteration 48357 => Loss: 43.93851112117813073610\n",
      "Iteration 48358 => Loss: 43.93836672289497613519\n",
      "Iteration 48359 => Loss: 43.93822232574505903813\n",
      "Iteration 48360 => Loss: 43.93807792972833681233\n",
      "Iteration 48361 => Loss: 43.93793353484485209037\n",
      "Iteration 48362 => Loss: 43.93778914109457645054\n",
      "Iteration 48363 => Loss: 43.93764474847747436570\n",
      "Iteration 48364 => Loss: 43.93750035699356715213\n",
      "Iteration 48365 => Loss: 43.93735596664281928270\n",
      "Iteration 48366 => Loss: 43.93721157742525207368\n",
      "Iteration 48367 => Loss: 43.93706718934085131423\n",
      "Iteration 48368 => Loss: 43.93692280238960279348\n",
      "Iteration 48369 => Loss: 43.93677841657149230059\n",
      "Iteration 48370 => Loss: 43.93663403188650562470\n",
      "Iteration 48371 => Loss: 43.93648964833464987123\n",
      "Iteration 48372 => Loss: 43.93634526591590372391\n",
      "Iteration 48373 => Loss: 43.93620088463026007730\n",
      "Iteration 48374 => Loss: 43.93605650447771182598\n",
      "Iteration 48375 => Loss: 43.93591212545828028624\n",
      "Iteration 48376 => Loss: 43.93576774757190150922\n",
      "Iteration 48377 => Loss: 43.93562337081859681120\n",
      "Iteration 48378 => Loss: 43.93547899519835908677\n",
      "Iteration 48379 => Loss: 43.93533462071114570335\n",
      "Iteration 48380 => Loss: 43.93519024735700639894\n",
      "Iteration 48381 => Loss: 43.93504587513589143555\n",
      "Iteration 48382 => Loss: 43.93490150404779370774\n",
      "Iteration 48383 => Loss: 43.93475713409272742638\n",
      "Iteration 48384 => Loss: 43.93461276527066416975\n",
      "Iteration 48385 => Loss: 43.93446839758158972700\n",
      "Iteration 48386 => Loss: 43.93432403102553251983\n",
      "Iteration 48387 => Loss: 43.93417966560243570484\n",
      "Iteration 48388 => Loss: 43.93403530131231349287\n",
      "Iteration 48389 => Loss: 43.93389093815515167307\n",
      "Iteration 48390 => Loss: 43.93374657613095735087\n",
      "Iteration 48391 => Loss: 43.93360221523970210455\n",
      "Iteration 48392 => Loss: 43.93345785548137172327\n",
      "Iteration 48393 => Loss: 43.93331349685597331245\n",
      "Iteration 48394 => Loss: 43.93316913936349976666\n",
      "Iteration 48395 => Loss: 43.93302478300394398048\n",
      "Iteration 48396 => Loss: 43.93288042777727042676\n",
      "Iteration 48397 => Loss: 43.93273607368350042179\n",
      "Iteration 48398 => Loss: 43.93259172072260554387\n",
      "Iteration 48399 => Loss: 43.93244736889461421470\n",
      "Iteration 48400 => Loss: 43.93230301819946248543\n",
      "Iteration 48401 => Loss: 43.93215866863716456692\n",
      "Iteration 48402 => Loss: 43.93201432020772756459\n",
      "Iteration 48403 => Loss: 43.93186997291112305675\n",
      "Iteration 48404 => Loss: 43.93172562674733683252\n",
      "Iteration 48405 => Loss: 43.93158128171639020820\n",
      "Iteration 48406 => Loss: 43.93143693781824765665\n",
      "Iteration 48407 => Loss: 43.93129259505291628329\n",
      "Iteration 48408 => Loss: 43.93114825342036766642\n",
      "Iteration 48409 => Loss: 43.93100391292058759518\n",
      "Iteration 48410 => Loss: 43.93085957355364001842\n",
      "Iteration 48411 => Loss: 43.93071523531940414387\n",
      "Iteration 48412 => Loss: 43.93057089821796523665\n",
      "Iteration 48413 => Loss: 43.93042656224924513708\n",
      "Iteration 48414 => Loss: 43.93028222741327226686\n",
      "Iteration 48415 => Loss: 43.93013789371005373141\n",
      "Iteration 48416 => Loss: 43.92999356113955400360\n",
      "Iteration 48417 => Loss: 43.92984922970174466172\n",
      "Iteration 48418 => Loss: 43.92970489939666123291\n",
      "Iteration 48419 => Loss: 43.92956057022427529546\n",
      "Iteration 48420 => Loss: 43.92941624218455842765\n",
      "Iteration 48421 => Loss: 43.92927191527755326206\n",
      "Iteration 48422 => Loss: 43.92912758950318874440\n",
      "Iteration 48423 => Loss: 43.92898326486148619097\n",
      "Iteration 48424 => Loss: 43.92883894135244560175\n",
      "Iteration 48425 => Loss: 43.92869461897605276590\n",
      "Iteration 48426 => Loss: 43.92855029773228636714\n",
      "Iteration 48427 => Loss: 43.92840597762114640545\n",
      "Iteration 48428 => Loss: 43.92826165864262577543\n",
      "Iteration 48429 => Loss: 43.92811734079671026620\n",
      "Iteration 48430 => Loss: 43.92797302408338566693\n",
      "Iteration 48431 => Loss: 43.92782870850266618845\n",
      "Iteration 48432 => Loss: 43.92768439405452340907\n",
      "Iteration 48433 => Loss: 43.92754008073896443420\n",
      "Iteration 48434 => Loss: 43.92739576855594663130\n",
      "Iteration 48435 => Loss: 43.92725145750549131662\n",
      "Iteration 48436 => Loss: 43.92710714758757717391\n",
      "Iteration 48437 => Loss: 43.92696283880219709772\n",
      "Iteration 48438 => Loss: 43.92681853114935108806\n",
      "Iteration 48439 => Loss: 43.92667422462903203950\n",
      "Iteration 48440 => Loss: 43.92652991924121153033\n",
      "Iteration 48441 => Loss: 43.92638561498590377141\n",
      "Iteration 48442 => Loss: 43.92624131186308034103\n",
      "Iteration 48443 => Loss: 43.92609700987273413375\n",
      "Iteration 48444 => Loss: 43.92595270901486514958\n",
      "Iteration 48445 => Loss: 43.92580840928947338853\n",
      "Iteration 48446 => Loss: 43.92566411069653753430\n",
      "Iteration 48447 => Loss: 43.92551981323603627061\n",
      "Iteration 48448 => Loss: 43.92537551690796959747\n",
      "Iteration 48449 => Loss: 43.92523122171235172573\n",
      "Iteration 48450 => Loss: 43.92508692764916133910\n",
      "Iteration 48451 => Loss: 43.92494263471836291046\n",
      "Iteration 48452 => Loss: 43.92479834291995643980\n",
      "Iteration 48453 => Loss: 43.92465405225397034883\n",
      "Iteration 48454 => Loss: 43.92450976272036200498\n",
      "Iteration 48455 => Loss: 43.92436547431914561912\n",
      "Iteration 48456 => Loss: 43.92422118705027855867\n",
      "Iteration 48457 => Loss: 43.92407690091373950736\n",
      "Iteration 48458 => Loss: 43.92393261590959241403\n",
      "Iteration 48459 => Loss: 43.92378833203777332983\n",
      "Iteration 48460 => Loss: 43.92364404929831067648\n",
      "Iteration 48461 => Loss: 43.92349976769114761055\n",
      "Iteration 48462 => Loss: 43.92335548721629123747\n",
      "Iteration 48463 => Loss: 43.92321120787375576811\n",
      "Iteration 48464 => Loss: 43.92306692966351278073\n",
      "Iteration 48465 => Loss: 43.92292265258556938079\n",
      "Iteration 48466 => Loss: 43.92277837663986872485\n",
      "Iteration 48467 => Loss: 43.92263410182646055091\n",
      "Iteration 48468 => Loss: 43.92248982814533775354\n",
      "Iteration 48469 => Loss: 43.92234555559643638389\n",
      "Iteration 48470 => Loss: 43.92220128417977775825\n",
      "Iteration 48471 => Loss: 43.92205701389536898205\n",
      "Iteration 48472 => Loss: 43.92191274474317452814\n",
      "Iteration 48473 => Loss: 43.92176847672320150195\n",
      "Iteration 48474 => Loss: 43.92162420983544279807\n",
      "Iteration 48475 => Loss: 43.92147994407986999477\n",
      "Iteration 48476 => Loss: 43.92133567945649730291\n",
      "Iteration 48477 => Loss: 43.92119141596531051164\n",
      "Iteration 48478 => Loss: 43.92104715360628830467\n",
      "Iteration 48479 => Loss: 43.92090289237943778744\n",
      "Iteration 48480 => Loss: 43.92075863228472343280\n",
      "Iteration 48481 => Loss: 43.92061437332217366247\n",
      "Iteration 48482 => Loss: 43.92047011549173163303\n",
      "Iteration 48483 => Loss: 43.92032585879345418789\n",
      "Iteration 48484 => Loss: 43.92018160322727737821\n",
      "Iteration 48485 => Loss: 43.92003734879321541484\n",
      "Iteration 48486 => Loss: 43.91989309549124698151\n",
      "Iteration 48487 => Loss: 43.91974884332136497278\n",
      "Iteration 48488 => Loss: 43.91960459228359070494\n",
      "Iteration 48489 => Loss: 43.91946034237786733456\n",
      "Iteration 48490 => Loss: 43.91931609360420907251\n",
      "Iteration 48491 => Loss: 43.91917184596263012963\n",
      "Iteration 48492 => Loss: 43.91902759945308787337\n",
      "Iteration 48493 => Loss: 43.91888335407558230372\n",
      "Iteration 48494 => Loss: 43.91873910983011342068\n",
      "Iteration 48495 => Loss: 43.91859486671665990798\n",
      "Iteration 48496 => Loss: 43.91845062473521466018\n",
      "Iteration 48497 => Loss: 43.91830638388577057185\n",
      "Iteration 48498 => Loss: 43.91816214416833474843\n",
      "Iteration 48499 => Loss: 43.91801790558288587363\n",
      "Iteration 48500 => Loss: 43.91787366812939552574\n",
      "Iteration 48501 => Loss: 43.91772943180789212647\n",
      "Iteration 48502 => Loss: 43.91758519661833304326\n",
      "Iteration 48503 => Loss: 43.91744096256072538154\n",
      "Iteration 48504 => Loss: 43.91729672963506203587\n",
      "Iteration 48505 => Loss: 43.91715249784133590083\n",
      "Iteration 48506 => Loss: 43.91700826717951855471\n",
      "Iteration 48507 => Loss: 43.91686403764963841923\n",
      "Iteration 48508 => Loss: 43.91671980925165286180\n",
      "Iteration 48509 => Loss: 43.91657558198557609330\n",
      "Iteration 48510 => Loss: 43.91643135585135127030\n",
      "Iteration 48511 => Loss: 43.91628713084903523622\n",
      "Iteration 48512 => Loss: 43.91614290697858535850\n",
      "Iteration 48513 => Loss: 43.91599868423999453171\n",
      "Iteration 48514 => Loss: 43.91585446263325565042\n",
      "Iteration 48515 => Loss: 43.91571024215836871463\n",
      "Iteration 48516 => Loss: 43.91556602281531240806\n",
      "Iteration 48517 => Loss: 43.91542180460409383613\n",
      "Iteration 48518 => Loss: 43.91527758752465615544\n",
      "Iteration 48519 => Loss: 43.91513337157706331482\n",
      "Iteration 48520 => Loss: 43.91498915676123715457\n",
      "Iteration 48521 => Loss: 43.91484494307722030726\n",
      "Iteration 48522 => Loss: 43.91470073052498435118\n",
      "Iteration 48523 => Loss: 43.91455651910452218090\n",
      "Iteration 48524 => Loss: 43.91441230881580537471\n",
      "Iteration 48525 => Loss: 43.91426809965886945974\n",
      "Iteration 48526 => Loss: 43.91412389163366469802\n",
      "Iteration 48527 => Loss: 43.91397968474019108953\n",
      "Iteration 48528 => Loss: 43.91383547897847705599\n",
      "Iteration 48529 => Loss: 43.91369127434845154312\n",
      "Iteration 48530 => Loss: 43.91354707085015007806\n",
      "Iteration 48531 => Loss: 43.91340286848353713367\n",
      "Iteration 48532 => Loss: 43.91325866724863402624\n",
      "Iteration 48533 => Loss: 43.91311446714539812319\n",
      "Iteration 48534 => Loss: 43.91297026817384363540\n",
      "Iteration 48535 => Loss: 43.91282607033394214113\n",
      "Iteration 48536 => Loss: 43.91268187362573627297\n",
      "Iteration 48537 => Loss: 43.91253767804914787121\n",
      "Iteration 48538 => Loss: 43.91239348360419825212\n",
      "Iteration 48539 => Loss: 43.91224929029089452115\n",
      "Iteration 48540 => Loss: 43.91210509810920115115\n",
      "Iteration 48541 => Loss: 43.91196090705912524754\n",
      "Iteration 48542 => Loss: 43.91181671714064549406\n",
      "Iteration 48543 => Loss: 43.91167252835376189068\n",
      "Iteration 48544 => Loss: 43.91152834069847443743\n",
      "Iteration 48545 => Loss: 43.91138415417475471259\n",
      "Iteration 48546 => Loss: 43.91123996878260982157\n",
      "Iteration 48547 => Loss: 43.91109578452201844811\n",
      "Iteration 48548 => Loss: 43.91095160139298059221\n",
      "Iteration 48549 => Loss: 43.91080741939548204300\n",
      "Iteration 48550 => Loss: 43.91066323852951569506\n",
      "Iteration 48551 => Loss: 43.91051905879507444297\n",
      "Iteration 48552 => Loss: 43.91037488019214407586\n",
      "Iteration 48553 => Loss: 43.91023070272072459375\n",
      "Iteration 48554 => Loss: 43.91008652638080178576\n",
      "Iteration 48555 => Loss: 43.90994235117236144106\n",
      "Iteration 48556 => Loss: 43.90979817709542487592\n",
      "Iteration 48557 => Loss: 43.90965400414992814149\n",
      "Iteration 48558 => Loss: 43.90950983233590676491\n",
      "Iteration 48559 => Loss: 43.90936566165333942990\n",
      "Iteration 48560 => Loss: 43.90922149210222613647\n",
      "Iteration 48561 => Loss: 43.90907732368252425204\n",
      "Iteration 48562 => Loss: 43.90893315639426219832\n",
      "Iteration 48563 => Loss: 43.90878899023742576446\n",
      "Iteration 48564 => Loss: 43.90864482521197231790\n",
      "Iteration 48565 => Loss: 43.90850066131792317492\n",
      "Iteration 48566 => Loss: 43.90835649855528544094\n",
      "Iteration 48567 => Loss: 43.90821233692400937798\n",
      "Iteration 48568 => Loss: 43.90806817642411630231\n",
      "Iteration 48569 => Loss: 43.90792401705559200309\n",
      "Iteration 48570 => Loss: 43.90777985881840095317\n",
      "Iteration 48571 => Loss: 43.90763570171259999597\n",
      "Iteration 48572 => Loss: 43.90749154573810386637\n",
      "Iteration 48573 => Loss: 43.90734739089493388065\n",
      "Iteration 48574 => Loss: 43.90720323718309714423\n",
      "Iteration 48575 => Loss: 43.90705908460255102455\n",
      "Iteration 48576 => Loss: 43.90691493315332394332\n",
      "Iteration 48577 => Loss: 43.90677078283539458425\n",
      "Iteration 48578 => Loss: 43.90662663364872031480\n",
      "Iteration 48579 => Loss: 43.90648248559335087293\n",
      "Iteration 48580 => Loss: 43.90633833866924362610\n",
      "Iteration 48581 => Loss: 43.90619419287638436344\n",
      "Iteration 48582 => Loss: 43.90605004821477308496\n",
      "Iteration 48583 => Loss: 43.90590590468442400152\n",
      "Iteration 48584 => Loss: 43.90576176228527316425\n",
      "Iteration 48585 => Loss: 43.90561762101737031116\n",
      "Iteration 48586 => Loss: 43.90547348088067991512\n",
      "Iteration 48587 => Loss: 43.90532934187517355440\n",
      "Iteration 48588 => Loss: 43.90518520400089386158\n",
      "Iteration 48589 => Loss: 43.90504106725775557152\n",
      "Iteration 48590 => Loss: 43.90489693164582263307\n",
      "Iteration 48591 => Loss: 43.90475279716505241367\n",
      "Iteration 48592 => Loss: 43.90460866381544491333\n",
      "Iteration 48593 => Loss: 43.90446453159698592117\n",
      "Iteration 48594 => Loss: 43.90432040050966122635\n",
      "Iteration 48595 => Loss: 43.90417627055349214515\n",
      "Iteration 48596 => Loss: 43.90403214172844315044\n",
      "Iteration 48597 => Loss: 43.90388801403450003136\n",
      "Iteration 48598 => Loss: 43.90374388747164857705\n",
      "Iteration 48599 => Loss: 43.90359976203991720922\n",
      "Iteration 48600 => Loss: 43.90345563773926329532\n",
      "Iteration 48601 => Loss: 43.90331151456970104618\n",
      "Iteration 48602 => Loss: 43.90316739253118072384\n",
      "Iteration 48603 => Loss: 43.90302327162375917169\n",
      "Iteration 48604 => Loss: 43.90287915184738665175\n",
      "Iteration 48605 => Loss: 43.90273503320203474232\n",
      "Iteration 48606 => Loss: 43.90259091568773897052\n",
      "Iteration 48607 => Loss: 43.90244679930446380922\n",
      "Iteration 48608 => Loss: 43.90230268405221636385\n",
      "Iteration 48609 => Loss: 43.90215856993093979099\n",
      "Iteration 48610 => Loss: 43.90201445694069093406\n",
      "Iteration 48611 => Loss: 43.90187034508144137135\n",
      "Iteration 48612 => Loss: 43.90172623435317689200\n",
      "Iteration 48613 => Loss: 43.90158212475586907431\n",
      "Iteration 48614 => Loss: 43.90143801628953923455\n",
      "Iteration 48615 => Loss: 43.90129390895414474016\n",
      "Iteration 48616 => Loss: 43.90114980274971401286\n",
      "Iteration 48617 => Loss: 43.90100569767621152550\n",
      "Iteration 48618 => Loss: 43.90086159373364438352\n",
      "Iteration 48619 => Loss: 43.90071749092199837605\n",
      "Iteration 48620 => Loss: 43.90057338924125218682\n",
      "Iteration 48621 => Loss: 43.90042928869142002668\n",
      "Iteration 48622 => Loss: 43.90028518927248768478\n",
      "Iteration 48623 => Loss: 43.90014109098441963397\n",
      "Iteration 48624 => Loss: 43.89999699382724429597\n",
      "Iteration 48625 => Loss: 43.89985289780091193279\n",
      "Iteration 48626 => Loss: 43.89970880290547228242\n",
      "Iteration 48627 => Loss: 43.89956470914085429058\n",
      "Iteration 48628 => Loss: 43.89942061650709348442\n",
      "Iteration 48629 => Loss: 43.89927652500415433678\n",
      "Iteration 48630 => Loss: 43.89913243463204395312\n",
      "Iteration 48631 => Loss: 43.89898834539074101713\n",
      "Iteration 48632 => Loss: 43.89884425728025263425\n",
      "Iteration 48633 => Loss: 43.89870017030055038276\n",
      "Iteration 48634 => Loss: 43.89855608445164136810\n",
      "Iteration 48635 => Loss: 43.89841199973350427399\n",
      "Iteration 48636 => Loss: 43.89826791614614620585\n",
      "Iteration 48637 => Loss: 43.89812383368953163654\n",
      "Iteration 48638 => Loss: 43.89797975236369609320\n",
      "Iteration 48639 => Loss: 43.89783567216858983784\n",
      "Iteration 48640 => Loss: 43.89769159310420576503\n",
      "Iteration 48641 => Loss: 43.89754751517055808563\n",
      "Iteration 48642 => Loss: 43.89740343836761127250\n",
      "Iteration 48643 => Loss: 43.89725936269538664192\n",
      "Iteration 48644 => Loss: 43.89711528815385577218\n",
      "Iteration 48645 => Loss: 43.89697121474300445243\n",
      "Iteration 48646 => Loss: 43.89682714246286820980\n",
      "Iteration 48647 => Loss: 43.89668307131337599003\n",
      "Iteration 48648 => Loss: 43.89653900129455621482\n",
      "Iteration 48649 => Loss: 43.89639493240638046245\n",
      "Iteration 48650 => Loss: 43.89625086464884162751\n",
      "Iteration 48651 => Loss: 43.89610679802196102628\n",
      "Iteration 48652 => Loss: 43.89596273252568892076\n",
      "Iteration 48653 => Loss: 43.89581866816004662724\n",
      "Iteration 48654 => Loss: 43.89567460492501993485\n",
      "Iteration 48655 => Loss: 43.89553054282058042190\n",
      "Iteration 48656 => Loss: 43.89538648184674229924\n",
      "Iteration 48657 => Loss: 43.89524242200349135601\n",
      "Iteration 48658 => Loss: 43.89509836329079917050\n",
      "Iteration 48659 => Loss: 43.89495430570867284814\n",
      "Iteration 48660 => Loss: 43.89481024925711949436\n",
      "Iteration 48661 => Loss: 43.89466619393611779287\n",
      "Iteration 48662 => Loss: 43.89452213974561800569\n",
      "Iteration 48663 => Loss: 43.89437808668568408166\n",
      "Iteration 48664 => Loss: 43.89423403475625917736\n",
      "Iteration 48665 => Loss: 43.89408998395732908193\n",
      "Iteration 48666 => Loss: 43.89394593428891511167\n",
      "Iteration 48667 => Loss: 43.89380188575098884485\n",
      "Iteration 48668 => Loss: 43.89365783834356449233\n",
      "Iteration 48669 => Loss: 43.89351379206662073784\n",
      "Iteration 48670 => Loss: 43.89336974692012915966\n",
      "Iteration 48671 => Loss: 43.89322570290409686322\n",
      "Iteration 48672 => Loss: 43.89308166001851674309\n",
      "Iteration 48673 => Loss: 43.89293761826338879928\n",
      "Iteration 48674 => Loss: 43.89279357763867750464\n",
      "Iteration 48675 => Loss: 43.89264953814438996460\n",
      "Iteration 48676 => Loss: 43.89250549978051196831\n",
      "Iteration 48677 => Loss: 43.89236146254705772662\n",
      "Iteration 48678 => Loss: 43.89221742644399171240\n",
      "Iteration 48679 => Loss: 43.89207339147129971479\n",
      "Iteration 48680 => Loss: 43.89192935762900305008\n",
      "Iteration 48681 => Loss: 43.89178532491709461283\n",
      "Iteration 48682 => Loss: 43.89164129333551045420\n",
      "Iteration 48683 => Loss: 43.89149726288429320675\n",
      "Iteration 48684 => Loss: 43.89135323356340734335\n",
      "Iteration 48685 => Loss: 43.89120920537285996943\n",
      "Iteration 48686 => Loss: 43.89106517831267240126\n",
      "Iteration 48687 => Loss: 43.89092115238276647915\n",
      "Iteration 48688 => Loss: 43.89077712758317773023\n",
      "Iteration 48689 => Loss: 43.89063310391389194365\n",
      "Iteration 48690 => Loss: 43.89048908137488780312\n",
      "Iteration 48691 => Loss: 43.89034505996617241408\n",
      "Iteration 48692 => Loss: 43.89020103968772446024\n",
      "Iteration 48693 => Loss: 43.89005702053953683617\n",
      "Iteration 48694 => Loss: 43.88991300252162375273\n",
      "Iteration 48695 => Loss: 43.88976898563392836650\n",
      "Iteration 48696 => Loss: 43.88962496987648620461\n",
      "Iteration 48697 => Loss: 43.88948095524926173994\n",
      "Iteration 48698 => Loss: 43.88933694175229760503\n",
      "Iteration 48699 => Loss: 43.88919292938548721850\n",
      "Iteration 48700 => Loss: 43.88904891814890874002\n",
      "Iteration 48701 => Loss: 43.88890490804250532619\n",
      "Iteration 48702 => Loss: 43.88876089906629118786\n",
      "Iteration 48703 => Loss: 43.88861689122025921961\n",
      "Iteration 48704 => Loss: 43.88847288450439521057\n",
      "Iteration 48705 => Loss: 43.88832887891868494989\n",
      "Iteration 48706 => Loss: 43.88818487446310712130\n",
      "Iteration 48707 => Loss: 43.88804087113769725192\n",
      "Iteration 48708 => Loss: 43.88789686894240560378\n",
      "Iteration 48709 => Loss: 43.88775286787722507142\n",
      "Iteration 48710 => Loss: 43.88760886794217697116\n",
      "Iteration 48711 => Loss: 43.88746486913718314327\n",
      "Iteration 48712 => Loss: 43.88732087146234306374\n",
      "Iteration 48713 => Loss: 43.88717687491758567830\n",
      "Iteration 48714 => Loss: 43.88703287950288256525\n",
      "Iteration 48715 => Loss: 43.88688888521825504085\n",
      "Iteration 48716 => Loss: 43.88674489206369599970\n",
      "Iteration 48717 => Loss: 43.88660090003916991463\n",
      "Iteration 48718 => Loss: 43.88645690914469810195\n",
      "Iteration 48719 => Loss: 43.88631291938025924537\n",
      "Iteration 48720 => Loss: 43.88616893074582492318\n",
      "Iteration 48721 => Loss: 43.88602494324141645166\n",
      "Iteration 48722 => Loss: 43.88588095686701251452\n",
      "Iteration 48723 => Loss: 43.88573697162262732263\n",
      "Iteration 48724 => Loss: 43.88559298750821824342\n",
      "Iteration 48725 => Loss: 43.88544900452379238232\n",
      "Iteration 48726 => Loss: 43.88530502266932842304\n",
      "Iteration 48727 => Loss: 43.88516104194481926015\n",
      "Iteration 48728 => Loss: 43.88501706235027910452\n",
      "Iteration 48729 => Loss: 43.88487308388568663986\n",
      "Iteration 48730 => Loss: 43.88472910655100633903\n",
      "Iteration 48731 => Loss: 43.88458513034627372917\n",
      "Iteration 48732 => Loss: 43.88444115527145328315\n",
      "Iteration 48733 => Loss: 43.88429718132653079010\n",
      "Iteration 48734 => Loss: 43.88415320851152756632\n",
      "Iteration 48735 => Loss: 43.88400923682640808465\n",
      "Iteration 48736 => Loss: 43.88386526627115813426\n",
      "Iteration 48737 => Loss: 43.88372129684579192599\n",
      "Iteration 48738 => Loss: 43.88357732855028814356\n",
      "Iteration 48739 => Loss: 43.88343336138464678697\n",
      "Iteration 48740 => Loss: 43.88328939534885364537\n",
      "Iteration 48741 => Loss: 43.88314543044288740248\n",
      "Iteration 48742 => Loss: 43.88300146666674805829\n",
      "Iteration 48743 => Loss: 43.88285750402043561280\n",
      "Iteration 48744 => Loss: 43.88271354250393585517\n",
      "Iteration 48745 => Loss: 43.88256958211722746910\n",
      "Iteration 48746 => Loss: 43.88242562286031756003\n",
      "Iteration 48747 => Loss: 43.88228166473320612795\n",
      "Iteration 48748 => Loss: 43.88213770773587185658\n",
      "Iteration 48749 => Loss: 43.88199375186827921880\n",
      "Iteration 48750 => Loss: 43.88184979713048505801\n",
      "Iteration 48751 => Loss: 43.88170584352238989823\n",
      "Iteration 48752 => Loss: 43.88156189104406479373\n",
      "Iteration 48753 => Loss: 43.88141793969547421739\n",
      "Iteration 48754 => Loss: 43.88127398947659685291\n",
      "Iteration 48755 => Loss: 43.88113004038744691115\n",
      "Iteration 48756 => Loss: 43.88098609242797465413\n",
      "Iteration 48757 => Loss: 43.88084214559821560897\n",
      "Iteration 48758 => Loss: 43.88069819989814845940\n",
      "Iteration 48759 => Loss: 43.88055425532774478370\n",
      "Iteration 48760 => Loss: 43.88041031188701168730\n",
      "Iteration 48761 => Loss: 43.88026636957595627564\n",
      "Iteration 48762 => Loss: 43.88012242839452170529\n",
      "Iteration 48763 => Loss: 43.87997848834276481966\n",
      "Iteration 48764 => Loss: 43.87983454942060745907\n",
      "Iteration 48765 => Loss: 43.87969061162809936150\n",
      "Iteration 48766 => Loss: 43.87954667496520499981\n",
      "Iteration 48767 => Loss: 43.87940273943192437400\n",
      "Iteration 48768 => Loss: 43.87925880502823616780\n",
      "Iteration 48769 => Loss: 43.87911487175412617034\n",
      "Iteration 48770 => Loss: 43.87897093960960148706\n",
      "Iteration 48771 => Loss: 43.87882700859465501253\n",
      "Iteration 48772 => Loss: 43.87868307870928674674\n",
      "Iteration 48773 => Loss: 43.87853914995345405714\n",
      "Iteration 48774 => Loss: 43.87839522232714983829\n",
      "Iteration 48775 => Loss: 43.87825129583041672277\n",
      "Iteration 48776 => Loss: 43.87810737046319786714\n",
      "Iteration 48777 => Loss: 43.87796344622549327141\n",
      "Iteration 48778 => Loss: 43.87781952311729583016\n",
      "Iteration 48779 => Loss: 43.87767560113859133253\n",
      "Iteration 48780 => Loss: 43.87753168028941530565\n",
      "Iteration 48781 => Loss: 43.87738776056967537897\n",
      "Iteration 48782 => Loss: 43.87724384197944260677\n",
      "Iteration 48783 => Loss: 43.87709992451865304020\n",
      "Iteration 48784 => Loss: 43.87695600818732799553\n",
      "Iteration 48785 => Loss: 43.87681209298545326192\n",
      "Iteration 48786 => Loss: 43.87666817891302883936\n",
      "Iteration 48787 => Loss: 43.87652426597001920072\n",
      "Iteration 48788 => Loss: 43.87638035415643855686\n",
      "Iteration 48789 => Loss: 43.87623644347227980234\n",
      "Iteration 48790 => Loss: 43.87609253391750741002\n",
      "Iteration 48791 => Loss: 43.87594862549212137992\n",
      "Iteration 48792 => Loss: 43.87580471819615723916\n",
      "Iteration 48793 => Loss: 43.87566081202955103890\n",
      "Iteration 48794 => Loss: 43.87551690699228856829\n",
      "Iteration 48795 => Loss: 43.87537300308440535446\n",
      "Iteration 48796 => Loss: 43.87522910030589429198\n",
      "Iteration 48797 => Loss: 43.87508519865667722115\n",
      "Iteration 48798 => Loss: 43.87494129813683230168\n",
      "Iteration 48799 => Loss: 43.87479739874629558471\n",
      "Iteration 48800 => Loss: 43.87465350048507417569\n",
      "Iteration 48801 => Loss: 43.87450960335316096916\n",
      "Iteration 48802 => Loss: 43.87436570735054175429\n",
      "Iteration 48803 => Loss: 43.87422181247720232022\n",
      "Iteration 48804 => Loss: 43.87407791873317108866\n",
      "Iteration 48805 => Loss: 43.87393402611839121619\n",
      "Iteration 48806 => Loss: 43.87379013463286270280\n",
      "Iteration 48807 => Loss: 43.87364624427660686479\n",
      "Iteration 48808 => Loss: 43.87350235504958106958\n",
      "Iteration 48809 => Loss: 43.87335846695179242261\n",
      "Iteration 48810 => Loss: 43.87321457998324802929\n",
      "Iteration 48811 => Loss: 43.87307069414391946793\n",
      "Iteration 48812 => Loss: 43.87292680943377121139\n",
      "Iteration 48813 => Loss: 43.87278292585283168137\n",
      "Iteration 48814 => Loss: 43.87263904340110087787\n",
      "Iteration 48815 => Loss: 43.87249516207853616834\n",
      "Iteration 48816 => Loss: 43.87235128188514465819\n",
      "Iteration 48817 => Loss: 43.87220740282092634743\n",
      "Iteration 48818 => Loss: 43.87206352488585281435\n",
      "Iteration 48819 => Loss: 43.87191964807993116438\n",
      "Iteration 48820 => Loss: 43.87177577240314718665\n",
      "Iteration 48821 => Loss: 43.87163189785549377575\n",
      "Iteration 48822 => Loss: 43.87148802443696382625\n",
      "Iteration 48823 => Loss: 43.87134415214752891643\n",
      "Iteration 48824 => Loss: 43.87120028098720325715\n",
      "Iteration 48825 => Loss: 43.87105641095597974299\n",
      "Iteration 48826 => Loss: 43.87091254205382995224\n",
      "Iteration 48827 => Loss: 43.87076867428076809574\n",
      "Iteration 48828 => Loss: 43.87062480763675154094\n",
      "Iteration 48829 => Loss: 43.87048094212183002583\n",
      "Iteration 48830 => Loss: 43.87033707773593249613\n",
      "Iteration 48831 => Loss: 43.87019321447907316269\n",
      "Iteration 48832 => Loss: 43.87004935235124492010\n",
      "Iteration 48833 => Loss: 43.86990549135242645207\n",
      "Iteration 48834 => Loss: 43.86976163148264618030\n",
      "Iteration 48835 => Loss: 43.86961777274186147224\n",
      "Iteration 48836 => Loss: 43.86947391513008653874\n",
      "Iteration 48837 => Loss: 43.86933005864728585266\n",
      "Iteration 48838 => Loss: 43.86918620329345230857\n",
      "Iteration 48839 => Loss: 43.86904234906860722276\n",
      "Iteration 48840 => Loss: 43.86889849597270085724\n",
      "Iteration 48841 => Loss: 43.86875464400576873913\n",
      "Iteration 48842 => Loss: 43.86861079316776113046\n",
      "Iteration 48843 => Loss: 43.86846694345869224207\n",
      "Iteration 48844 => Loss: 43.86832309487856207397\n",
      "Iteration 48845 => Loss: 43.86817924742733509902\n",
      "Iteration 48846 => Loss: 43.86803540110502552807\n",
      "Iteration 48847 => Loss: 43.86789155591160493941\n",
      "Iteration 48848 => Loss: 43.86774771184708043847\n",
      "Iteration 48849 => Loss: 43.86760386891142360355\n",
      "Iteration 48850 => Loss: 43.86746002710465575092\n",
      "Iteration 48851 => Loss: 43.86731618642673424802\n",
      "Iteration 48852 => Loss: 43.86717234687767330570\n",
      "Iteration 48853 => Loss: 43.86702850845746581854\n",
      "Iteration 48854 => Loss: 43.86688467116608336482\n",
      "Iteration 48855 => Loss: 43.86674083500353304998\n",
      "Iteration 48856 => Loss: 43.86659699996980776859\n",
      "Iteration 48857 => Loss: 43.86645316606487909894\n",
      "Iteration 48858 => Loss: 43.86630933328873993560\n",
      "Iteration 48859 => Loss: 43.86616550164143291113\n",
      "Iteration 48860 => Loss: 43.86602167112287276041\n",
      "Iteration 48861 => Loss: 43.86587784173309501057\n",
      "Iteration 48862 => Loss: 43.86573401347209966161\n",
      "Iteration 48863 => Loss: 43.86559018633986539726\n",
      "Iteration 48864 => Loss: 43.86544636033635669037\n",
      "Iteration 48865 => Loss: 43.86530253546158775180\n",
      "Iteration 48866 => Loss: 43.86515871171555858155\n",
      "Iteration 48867 => Loss: 43.86501488909821944162\n",
      "Iteration 48868 => Loss: 43.86487106760963428087\n",
      "Iteration 48869 => Loss: 43.86472724724975336130\n",
      "Iteration 48870 => Loss: 43.86458342801854826121\n",
      "Iteration 48871 => Loss: 43.86443960991603319144\n",
      "Iteration 48872 => Loss: 43.86429579294217973029\n",
      "Iteration 48873 => Loss: 43.86415197709700919404\n",
      "Iteration 48874 => Loss: 43.86400816238052158269\n",
      "Iteration 48875 => Loss: 43.86386434879264584197\n",
      "Iteration 48876 => Loss: 43.86372053633343170986\n",
      "Iteration 48877 => Loss: 43.86357672500284365924\n",
      "Iteration 48878 => Loss: 43.86343291480087458467\n",
      "Iteration 48879 => Loss: 43.86328910572752448616\n",
      "Iteration 48880 => Loss: 43.86314529778277915284\n",
      "Iteration 48881 => Loss: 43.86300149096663147930\n",
      "Iteration 48882 => Loss: 43.86285768527908146552\n",
      "Iteration 48883 => Loss: 43.86271388072011490067\n",
      "Iteration 48884 => Loss: 43.86257007728968915217\n",
      "Iteration 48885 => Loss: 43.86242627498785395801\n",
      "Iteration 48886 => Loss: 43.86228247381455958021\n",
      "Iteration 48887 => Loss: 43.86213867376982022961\n",
      "Iteration 48888 => Loss: 43.86199487485358616823\n",
      "Iteration 48889 => Loss: 43.86185107706591423948\n",
      "Iteration 48890 => Loss: 43.86170728040673338910\n",
      "Iteration 48891 => Loss: 43.86156348487607914421\n",
      "Iteration 48892 => Loss: 43.86141969047393729397\n",
      "Iteration 48893 => Loss: 43.86127589720025099496\n",
      "Iteration 48894 => Loss: 43.86113210505504866887\n",
      "Iteration 48895 => Loss: 43.86098831403833742115\n",
      "Iteration 48896 => Loss: 43.86084452415008172466\n",
      "Iteration 48897 => Loss: 43.86070073539029579024\n",
      "Iteration 48898 => Loss: 43.86055694775895830162\n",
      "Iteration 48899 => Loss: 43.86041316125604083709\n",
      "Iteration 48900 => Loss: 43.86026937588155760750\n",
      "Iteration 48901 => Loss: 43.86012559163550150743\n",
      "Iteration 48902 => Loss: 43.85998180851785122059\n",
      "Iteration 48903 => Loss: 43.85983802652859253612\n",
      "Iteration 48904 => Loss: 43.85969424566772545404\n",
      "Iteration 48905 => Loss: 43.85955046593526418519\n",
      "Iteration 48906 => Loss: 43.85940668733118030786\n",
      "Iteration 48907 => Loss: 43.85926290985544540035\n",
      "Iteration 48908 => Loss: 43.85911913350806656808\n",
      "Iteration 48909 => Loss: 43.85897535828906512734\n",
      "Iteration 48910 => Loss: 43.85883158419837002384\n",
      "Iteration 48911 => Loss: 43.85868781123604520644\n",
      "Iteration 48912 => Loss: 43.85854403940201251544\n",
      "Iteration 48913 => Loss: 43.85840026869630037254\n",
      "Iteration 48914 => Loss: 43.85825649911888035604\n",
      "Iteration 48915 => Loss: 43.85811273066978088764\n",
      "Iteration 48916 => Loss: 43.85796896334895933478\n",
      "Iteration 48917 => Loss: 43.85782519715639438118\n",
      "Iteration 48918 => Loss: 43.85768143209214287026\n",
      "Iteration 48919 => Loss: 43.85753766815611243146\n",
      "Iteration 48920 => Loss: 43.85739390534834569735\n",
      "Iteration 48921 => Loss: 43.85725014366882845707\n",
      "Iteration 48922 => Loss: 43.85710638311753939433\n",
      "Iteration 48923 => Loss: 43.85696262369447140372\n",
      "Iteration 48924 => Loss: 43.85681886539963159066\n",
      "Iteration 48925 => Loss: 43.85667510823300574430\n",
      "Iteration 48926 => Loss: 43.85653135219456544291\n",
      "Iteration 48927 => Loss: 43.85638759728429647566\n",
      "Iteration 48928 => Loss: 43.85624384350223436968\n",
      "Iteration 48929 => Loss: 43.85610009084834359783\n",
      "Iteration 48930 => Loss: 43.85595633932260994925\n",
      "Iteration 48931 => Loss: 43.85581258892502631852\n",
      "Iteration 48932 => Loss: 43.85566883965559981107\n",
      "Iteration 48933 => Loss: 43.85552509151430911061\n",
      "Iteration 48934 => Loss: 43.85538134450113290086\n",
      "Iteration 48935 => Loss: 43.85523759861609960353\n",
      "Iteration 48936 => Loss: 43.85509385385914526978\n",
      "Iteration 48937 => Loss: 43.85495011023031253217\n",
      "Iteration 48938 => Loss: 43.85480636772956586356\n",
      "Iteration 48939 => Loss: 43.85466262635690526395\n",
      "Iteration 48940 => Loss: 43.85451888611230941706\n",
      "Iteration 48941 => Loss: 43.85437514699579253374\n",
      "Iteration 48942 => Loss: 43.85423140900731908687\n",
      "Iteration 48943 => Loss: 43.85408767214692460357\n",
      "Iteration 48944 => Loss: 43.85394393641452381871\n",
      "Iteration 48945 => Loss: 43.85380020181019489200\n",
      "Iteration 48946 => Loss: 43.85365646833388098003\n",
      "Iteration 48947 => Loss: 43.85351273598556076649\n",
      "Iteration 48948 => Loss: 43.85336900476524135684\n",
      "Iteration 48949 => Loss: 43.85322527467294406733\n",
      "Iteration 48950 => Loss: 43.85308154570861916000\n",
      "Iteration 48951 => Loss: 43.85293781787226663482\n",
      "Iteration 48952 => Loss: 43.85279409116387938639\n",
      "Iteration 48953 => Loss: 43.85265036558346452011\n",
      "Iteration 48954 => Loss: 43.85250664113097940344\n",
      "Iteration 48955 => Loss: 43.85236291780647377436\n",
      "Iteration 48956 => Loss: 43.85221919560986236775\n",
      "Iteration 48957 => Loss: 43.85207547454119492158\n",
      "Iteration 48958 => Loss: 43.85193175460042880331\n",
      "Iteration 48959 => Loss: 43.85178803578759243464\n",
      "Iteration 48960 => Loss: 43.85164431810264318301\n",
      "Iteration 48961 => Loss: 43.85150060154557394299\n",
      "Iteration 48962 => Loss: 43.85135688611639182000\n",
      "Iteration 48963 => Loss: 43.85121317181507549776\n",
      "Iteration 48964 => Loss: 43.85106945864162497628\n",
      "Iteration 48965 => Loss: 43.85092574659603315013\n",
      "Iteration 48966 => Loss: 43.85078203567827159759\n",
      "Iteration 48967 => Loss: 43.85063832588836163495\n",
      "Iteration 48968 => Loss: 43.85049461722627484050\n",
      "Iteration 48969 => Loss: 43.85035090969199700339\n",
      "Iteration 48970 => Loss: 43.85020720328552812362\n",
      "Iteration 48971 => Loss: 43.85006349800688241203\n",
      "Iteration 48972 => Loss: 43.84991979385601013064\n",
      "Iteration 48973 => Loss: 43.84977609083292549030\n",
      "Iteration 48974 => Loss: 43.84963238893759296388\n",
      "Iteration 48975 => Loss: 43.84948868817005518395\n",
      "Iteration 48976 => Loss: 43.84934498853025530707\n",
      "Iteration 48977 => Loss: 43.84920129001822886039\n",
      "Iteration 48978 => Loss: 43.84905759263391900049\n",
      "Iteration 48979 => Loss: 43.84891389637733283280\n",
      "Iteration 48980 => Loss: 43.84877020124847746274\n",
      "Iteration 48981 => Loss: 43.84862650724733157404\n",
      "Iteration 48982 => Loss: 43.84848281437388806125\n",
      "Iteration 48983 => Loss: 43.84833912262814692440\n",
      "Iteration 48984 => Loss: 43.84819543201007974176\n",
      "Iteration 48985 => Loss: 43.84805174251967940791\n",
      "Iteration 48986 => Loss: 43.84790805415698144998\n",
      "Iteration 48987 => Loss: 43.84776436692191481370\n",
      "Iteration 48988 => Loss: 43.84762068081450081536\n",
      "Iteration 48989 => Loss: 43.84747699583473945495\n",
      "Iteration 48990 => Loss: 43.84733331198257388905\n",
      "Iteration 48991 => Loss: 43.84718962925808227737\n",
      "Iteration 48992 => Loss: 43.84704594766118646021\n",
      "Iteration 48993 => Loss: 43.84690226719188643756\n",
      "Iteration 48994 => Loss: 43.84675858785020352570\n",
      "Iteration 48995 => Loss: 43.84661490963608798666\n",
      "Iteration 48996 => Loss: 43.84647123254955403127\n",
      "Iteration 48997 => Loss: 43.84632755659058744868\n",
      "Iteration 48998 => Loss: 43.84618388175918113348\n",
      "Iteration 48999 => Loss: 43.84604020805534929650\n",
      "Iteration 49000 => Loss: 43.84589653547905641062\n",
      "Iteration 49001 => Loss: 43.84575286403028826498\n",
      "Iteration 49002 => Loss: 43.84560919370905196502\n",
      "Iteration 49003 => Loss: 43.84546552451530487815\n",
      "Iteration 49004 => Loss: 43.84532185644908963695\n",
      "Iteration 49005 => Loss: 43.84517818951037781972\n",
      "Iteration 49006 => Loss: 43.84503452369914811015\n",
      "Iteration 49007 => Loss: 43.84489085901540761370\n",
      "Iteration 49008 => Loss: 43.84474719545914922492\n",
      "Iteration 49009 => Loss: 43.84460353303033031125\n",
      "Iteration 49010 => Loss: 43.84445987172897929440\n",
      "Iteration 49011 => Loss: 43.84431621155506775267\n",
      "Iteration 49012 => Loss: 43.84417255250860989690\n",
      "Iteration 49013 => Loss: 43.84402889458957019997\n",
      "Iteration 49014 => Loss: 43.84388523779794155644\n",
      "Iteration 49015 => Loss: 43.84374158213373817716\n",
      "Iteration 49016 => Loss: 43.84359792759693164044\n",
      "Iteration 49017 => Loss: 43.84345427418751484083\n",
      "Iteration 49018 => Loss: 43.84331062190548067292\n",
      "Iteration 49019 => Loss: 43.84316697075083624213\n",
      "Iteration 49020 => Loss: 43.84302332072353891590\n",
      "Iteration 49021 => Loss: 43.84287967182360290508\n",
      "Iteration 49022 => Loss: 43.84273602405102820967\n",
      "Iteration 49023 => Loss: 43.84259237740577219711\n",
      "Iteration 49024 => Loss: 43.84244873188789881624\n",
      "Iteration 49025 => Loss: 43.84230508749728016937\n",
      "Iteration 49026 => Loss: 43.84216144423400862706\n",
      "Iteration 49027 => Loss: 43.84201780209805576760\n",
      "Iteration 49028 => Loss: 43.84187416108937895842\n",
      "Iteration 49029 => Loss: 43.84173052120799241038\n",
      "Iteration 49030 => Loss: 43.84158688245388901805\n",
      "Iteration 49031 => Loss: 43.84144324482705457058\n",
      "Iteration 49032 => Loss: 43.84129960832746775168\n",
      "Iteration 49033 => Loss: 43.84115597295514277221\n",
      "Iteration 49034 => Loss: 43.84101233871006542131\n",
      "Iteration 49035 => Loss: 43.84086870559220017185\n",
      "Iteration 49036 => Loss: 43.84072507360160386725\n",
      "Iteration 49037 => Loss: 43.84058144273817703152\n",
      "Iteration 49038 => Loss: 43.84043781300197650808\n",
      "Iteration 49039 => Loss: 43.84029418439298808607\n",
      "Iteration 49040 => Loss: 43.84015055691116913295\n",
      "Iteration 49041 => Loss: 43.84000693055652675412\n",
      "Iteration 49042 => Loss: 43.83986330532908226587\n",
      "Iteration 49043 => Loss: 43.83971968122877882479\n",
      "Iteration 49044 => Loss: 43.83957605825565195801\n",
      "Iteration 49045 => Loss: 43.83943243640963771668\n",
      "Iteration 49046 => Loss: 43.83928881569080004965\n",
      "Iteration 49047 => Loss: 43.83914519609906790265\n",
      "Iteration 49048 => Loss: 43.83900157763446259196\n",
      "Iteration 49049 => Loss: 43.83885796029694148501\n",
      "Iteration 49050 => Loss: 43.83871434408653300352\n",
      "Iteration 49051 => Loss: 43.83857072900323004205\n",
      "Iteration 49052 => Loss: 43.83842711504699707348\n",
      "Iteration 49053 => Loss: 43.83828350221785541407\n",
      "Iteration 49054 => Loss: 43.83813989051576953671\n",
      "Iteration 49055 => Loss: 43.83799627994076786308\n",
      "Iteration 49056 => Loss: 43.83785267049277933893\n",
      "Iteration 49057 => Loss: 43.83770906217183238596\n",
      "Iteration 49058 => Loss: 43.83756545497793410959\n",
      "Iteration 49059 => Loss: 43.83742184891103477185\n",
      "Iteration 49060 => Loss: 43.83727824397115568900\n",
      "Iteration 49061 => Loss: 43.83713464015829686105\n",
      "Iteration 49062 => Loss: 43.83699103747242986628\n",
      "Iteration 49063 => Loss: 43.83684743591353338843\n",
      "Iteration 49064 => Loss: 43.83670383548162874376\n",
      "Iteration 49065 => Loss: 43.83656023617668040515\n",
      "Iteration 49066 => Loss: 43.83641663799868126716\n",
      "Iteration 49067 => Loss: 43.83627304094766685694\n",
      "Iteration 49068 => Loss: 43.83612944502358033105\n",
      "Iteration 49069 => Loss: 43.83598585022640747866\n",
      "Iteration 49070 => Loss: 43.83584225655618382689\n",
      "Iteration 49071 => Loss: 43.83569866401286674318\n",
      "Iteration 49072 => Loss: 43.83555507259645622753\n",
      "Iteration 49073 => Loss: 43.83541148230693806909\n",
      "Iteration 49074 => Loss: 43.83526789314431937328\n",
      "Iteration 49075 => Loss: 43.83512430510858592925\n",
      "Iteration 49076 => Loss: 43.83498071819970931529\n",
      "Iteration 49077 => Loss: 43.83483713241770374225\n",
      "Iteration 49078 => Loss: 43.83469354776254789385\n",
      "Iteration 49079 => Loss: 43.83454996423422755925\n",
      "Iteration 49080 => Loss: 43.83440638183274984385\n",
      "Iteration 49081 => Loss: 43.83426280055810764225\n",
      "Iteration 49082 => Loss: 43.83411922041027963814\n",
      "Iteration 49083 => Loss: 43.83397564138925872612\n",
      "Iteration 49084 => Loss: 43.83383206349505201160\n",
      "Iteration 49085 => Loss: 43.83368848672762396745\n",
      "Iteration 49086 => Loss: 43.83354491108696038282\n",
      "Iteration 49087 => Loss: 43.83340133657309678483\n",
      "Iteration 49088 => Loss: 43.83325776318601185721\n",
      "Iteration 49089 => Loss: 43.83311419092564165112\n",
      "Iteration 49090 => Loss: 43.83297061979203590454\n",
      "Iteration 49091 => Loss: 43.83282704978517330119\n",
      "Iteration 49092 => Loss: 43.83268348090504673564\n",
      "Iteration 49093 => Loss: 43.83253991315164199705\n",
      "Iteration 49094 => Loss: 43.83239634652493776912\n",
      "Iteration 49095 => Loss: 43.83225278102494826271\n",
      "Iteration 49096 => Loss: 43.83210921665165216154\n",
      "Iteration 49097 => Loss: 43.83196565340502814934\n",
      "Iteration 49098 => Loss: 43.83182209128509754237\n",
      "Iteration 49099 => Loss: 43.83167853029181060265\n",
      "Iteration 49100 => Loss: 43.83153497042519575189\n",
      "Iteration 49101 => Loss: 43.83139141168524588466\n",
      "Iteration 49102 => Loss: 43.83124785407191836839\n",
      "Iteration 49103 => Loss: 43.83110429758522030852\n",
      "Iteration 49104 => Loss: 43.83096074222516591590\n",
      "Iteration 49105 => Loss: 43.83081718799171966339\n",
      "Iteration 49106 => Loss: 43.83067363488488155099\n",
      "Iteration 49107 => Loss: 43.83053008290462315699\n",
      "Iteration 49108 => Loss: 43.83038653205096579768\n",
      "Iteration 49109 => Loss: 43.83024298232389526220\n",
      "Iteration 49110 => Loss: 43.83009943372339733969\n",
      "Iteration 49111 => Loss: 43.82995588624944360845\n",
      "Iteration 49112 => Loss: 43.82981233990204117390\n",
      "Iteration 49113 => Loss: 43.82966879468119714147\n",
      "Iteration 49114 => Loss: 43.82952525058689019488\n",
      "Iteration 49115 => Loss: 43.82938170761909901785\n",
      "Iteration 49116 => Loss: 43.82923816577783782122\n",
      "Iteration 49117 => Loss: 43.82909462506306397245\n",
      "Iteration 49118 => Loss: 43.82895108547481299865\n",
      "Iteration 49119 => Loss: 43.82880754701304226728\n",
      "Iteration 49120 => Loss: 43.82866400967776598918\n",
      "Iteration 49121 => Loss: 43.82852047346894153179\n",
      "Iteration 49122 => Loss: 43.82837693838659021139\n",
      "Iteration 49123 => Loss: 43.82823340443070492256\n",
      "Iteration 49124 => Loss: 43.82808987160126434901\n",
      "Iteration 49125 => Loss: 43.82794633989826138531\n",
      "Iteration 49126 => Loss: 43.82780280932166760977\n",
      "Iteration 49127 => Loss: 43.82765927987151854950\n",
      "Iteration 49128 => Loss: 43.82751575154777157195\n",
      "Iteration 49129 => Loss: 43.82737222435041246626\n",
      "Iteration 49130 => Loss: 43.82722869827947675958\n",
      "Iteration 49131 => Loss: 43.82708517333490760848\n",
      "Iteration 49132 => Loss: 43.82694164951671922381\n",
      "Iteration 49133 => Loss: 43.82679812682490450015\n",
      "Iteration 49134 => Loss: 43.82665460525943501580\n",
      "Iteration 49135 => Loss: 43.82651108482033208702\n",
      "Iteration 49136 => Loss: 43.82636756550755308126\n",
      "Iteration 49137 => Loss: 43.82622404732110510395\n",
      "Iteration 49138 => Loss: 43.82608053026098104965\n",
      "Iteration 49139 => Loss: 43.82593701432718091837\n",
      "Iteration 49140 => Loss: 43.82579349951969049926\n",
      "Iteration 49141 => Loss: 43.82564998583848137059\n",
      "Iteration 49142 => Loss: 43.82550647328358195409\n",
      "Iteration 49143 => Loss: 43.82536296185493540634\n",
      "Iteration 49144 => Loss: 43.82521945155257725446\n",
      "Iteration 49145 => Loss: 43.82507594237647907676\n",
      "Iteration 49146 => Loss: 43.82493243432662666237\n",
      "Iteration 49147 => Loss: 43.82478892740302001130\n",
      "Iteration 49148 => Loss: 43.82464542160564491269\n",
      "Iteration 49149 => Loss: 43.82450191693449426111\n",
      "Iteration 49150 => Loss: 43.82435841338958937285\n",
      "Iteration 49151 => Loss: 43.82421491097085919364\n",
      "Iteration 49152 => Loss: 43.82407140967833214518\n",
      "Iteration 49153 => Loss: 43.82392790951200822747\n",
      "Iteration 49154 => Loss: 43.82378441047185191337\n",
      "Iteration 49155 => Loss: 43.82364091255787741375\n",
      "Iteration 49156 => Loss: 43.82349741577007051774\n",
      "Iteration 49157 => Loss: 43.82335392010840280363\n",
      "Iteration 49158 => Loss: 43.82321042557288848229\n",
      "Iteration 49159 => Loss: 43.82306693216351334286\n",
      "Iteration 49160 => Loss: 43.82292343988028449076\n",
      "Iteration 49161 => Loss: 43.82277994872314508257\n",
      "Iteration 49162 => Loss: 43.82263645869215196171\n",
      "Iteration 49163 => Loss: 43.82249296978724117935\n",
      "Iteration 49164 => Loss: 43.82234948200843405175\n",
      "Iteration 49165 => Loss: 43.82220599535568084093\n",
      "Iteration 49166 => Loss: 43.82206250982902417945\n",
      "Iteration 49167 => Loss: 43.82191902542842854018\n",
      "Iteration 49168 => Loss: 43.82177554215390813397\n",
      "Iteration 49169 => Loss: 43.82163206000543453911\n",
      "Iteration 49170 => Loss: 43.82148857898297933389\n",
      "Iteration 49171 => Loss: 43.82134509908657094002\n",
      "Iteration 49172 => Loss: 43.82120162031618804122\n",
      "Iteration 49173 => Loss: 43.82105814267180932120\n",
      "Iteration 49174 => Loss: 43.82091466615344899083\n",
      "Iteration 49175 => Loss: 43.82077119076106441753\n",
      "Iteration 49176 => Loss: 43.82062771649468402302\n",
      "Iteration 49177 => Loss: 43.82048424335427228016\n",
      "Iteration 49178 => Loss: 43.82034077133981497809\n",
      "Iteration 49179 => Loss: 43.82019730045134764396\n",
      "Iteration 49180 => Loss: 43.82005383068882764519\n",
      "Iteration 49181 => Loss: 43.81991036205224077094\n",
      "Iteration 49182 => Loss: 43.81976689454158702119\n",
      "Iteration 49183 => Loss: 43.81962342815688060682\n",
      "Iteration 49184 => Loss: 43.81947996289806468440\n",
      "Iteration 49185 => Loss: 43.81933649876516767563\n",
      "Iteration 49186 => Loss: 43.81919303575817536966\n",
      "Iteration 49187 => Loss: 43.81904957387705934480\n",
      "Iteration 49188 => Loss: 43.81890611312184802273\n",
      "Iteration 49189 => Loss: 43.81876265349247745462\n",
      "Iteration 49190 => Loss: 43.81861919498899027303\n",
      "Iteration 49191 => Loss: 43.81847573761135805626\n",
      "Iteration 49192 => Loss: 43.81833228135955948801\n",
      "Iteration 49193 => Loss: 43.81818882623360877915\n",
      "Iteration 49194 => Loss: 43.81804537223348461339\n",
      "Iteration 49195 => Loss: 43.81790191935917988530\n",
      "Iteration 49196 => Loss: 43.81775846761067327861\n",
      "Iteration 49197 => Loss: 43.81761501698800032045\n",
      "Iteration 49198 => Loss: 43.81747156749108285112\n",
      "Iteration 49199 => Loss: 43.81732811911995639775\n",
      "Iteration 49200 => Loss: 43.81718467187462806578\n",
      "Iteration 49201 => Loss: 43.81704122575505522263\n",
      "Iteration 49202 => Loss: 43.81689778076124497375\n",
      "Iteration 49203 => Loss: 43.81675433689316889740\n",
      "Iteration 49204 => Loss: 43.81661089415084830989\n",
      "Iteration 49205 => Loss: 43.81646745253425478950\n",
      "Iteration 49206 => Loss: 43.81632401204337412537\n",
      "Iteration 49207 => Loss: 43.81618057267821342293\n",
      "Iteration 49208 => Loss: 43.81603713443875847133\n",
      "Iteration 49209 => Loss: 43.81589369732498084886\n",
      "Iteration 49210 => Loss: 43.81575026133690897723\n",
      "Iteration 49211 => Loss: 43.81560682647451443472\n",
      "Iteration 49212 => Loss: 43.81546339273778301049\n",
      "Iteration 49213 => Loss: 43.81531996012672180996\n",
      "Iteration 49214 => Loss: 43.81517652864130241142\n",
      "Iteration 49215 => Loss: 43.81503309828153902572\n",
      "Iteration 49216 => Loss: 43.81488966904739612573\n",
      "Iteration 49217 => Loss: 43.81474624093888081688\n",
      "Iteration 49218 => Loss: 43.81460281395597178289\n",
      "Iteration 49219 => Loss: 43.81445938809869034003\n",
      "Iteration 49220 => Loss: 43.81431596336700806660\n",
      "Iteration 49221 => Loss: 43.81417253976088233003\n",
      "Iteration 49222 => Loss: 43.81402911728037707917\n",
      "Iteration 49223 => Loss: 43.81388569592542125974\n",
      "Iteration 49224 => Loss: 43.81374227569605750432\n",
      "Iteration 49225 => Loss: 43.81359885659221475862\n",
      "Iteration 49226 => Loss: 43.81345543861391433893\n",
      "Iteration 49227 => Loss: 43.81331202176116335067\n",
      "Iteration 49228 => Loss: 43.81316860603395468843\n",
      "Iteration 49229 => Loss: 43.81302519143223861420\n",
      "Iteration 49230 => Loss: 43.81288177795606486598\n",
      "Iteration 49231 => Loss: 43.81273836560536949492\n",
      "Iteration 49232 => Loss: 43.81259495438018092273\n",
      "Iteration 49233 => Loss: 43.81245154428047072770\n",
      "Iteration 49234 => Loss: 43.81230813530621048812\n",
      "Iteration 49235 => Loss: 43.81216472745746415285\n",
      "Iteration 49236 => Loss: 43.81202132073413224589\n",
      "Iteration 49237 => Loss: 43.81187791513625739981\n",
      "Iteration 49238 => Loss: 43.81173451066383961461\n",
      "Iteration 49239 => Loss: 43.81159110731684336315\n",
      "Iteration 49240 => Loss: 43.81144770509526154001\n",
      "Iteration 49241 => Loss: 43.81130430399910835604\n",
      "Iteration 49242 => Loss: 43.81116090402836249496\n",
      "Iteration 49243 => Loss: 43.81101750518298842962\n",
      "Iteration 49244 => Loss: 43.81087410746301458175\n",
      "Iteration 49245 => Loss: 43.81073071086841252963\n",
      "Iteration 49246 => Loss: 43.81058731539917516784\n",
      "Iteration 49247 => Loss: 43.81044392105532381265\n",
      "Iteration 49248 => Loss: 43.81030052783678030437\n",
      "Iteration 49249 => Loss: 43.81015713574361569727\n",
      "Iteration 49250 => Loss: 43.81001374477577314792\n",
      "Iteration 49251 => Loss: 43.80987035493325976176\n",
      "Iteration 49252 => Loss: 43.80972696621606132794\n",
      "Iteration 49253 => Loss: 43.80958357862416363560\n",
      "Iteration 49254 => Loss: 43.80944019215755957930\n",
      "Iteration 49255 => Loss: 43.80929680681626336991\n",
      "Iteration 49256 => Loss: 43.80915342260023948029\n",
      "Iteration 49257 => Loss: 43.80901003950948080501\n",
      "Iteration 49258 => Loss: 43.80886665754399444950\n",
      "Iteration 49259 => Loss: 43.80872327670375199204\n",
      "Iteration 49260 => Loss: 43.80857989698876053808\n",
      "Iteration 49261 => Loss: 43.80843651839898456046\n",
      "Iteration 49262 => Loss: 43.80829314093448090262\n",
      "Iteration 49263 => Loss: 43.80814976459517140484\n",
      "Iteration 49264 => Loss: 43.80800638938106317255\n",
      "Iteration 49265 => Loss: 43.80786301529217752204\n",
      "Iteration 49266 => Loss: 43.80771964232848603160\n",
      "Iteration 49267 => Loss: 43.80757627048995317409\n",
      "Iteration 49268 => Loss: 43.80743289977660026580\n",
      "Iteration 49269 => Loss: 43.80728953018843441214\n",
      "Iteration 49270 => Loss: 43.80714616172538455885\n",
      "Iteration 49271 => Loss: 43.80700279438752176020\n",
      "Iteration 49272 => Loss: 43.80685942817479627820\n",
      "Iteration 49273 => Loss: 43.80671606308718679657\n",
      "Iteration 49274 => Loss: 43.80657269912468620987\n",
      "Iteration 49275 => Loss: 43.80642933628731583440\n",
      "Iteration 49276 => Loss: 43.80628597457505435386\n",
      "Iteration 49277 => Loss: 43.80614261398787334656\n",
      "Iteration 49278 => Loss: 43.80599925452578702334\n",
      "Iteration 49279 => Loss: 43.80585589618878117335\n",
      "Iteration 49280 => Loss: 43.80571253897684869116\n",
      "Iteration 49281 => Loss: 43.80556918288995404964\n",
      "Iteration 49282 => Loss: 43.80542582792812567050\n",
      "Iteration 49283 => Loss: 43.80528247409134934287\n",
      "Iteration 49284 => Loss: 43.80513912137958243420\n",
      "Iteration 49285 => Loss: 43.80499576979285336620\n",
      "Iteration 49286 => Loss: 43.80485241933114792801\n",
      "Iteration 49287 => Loss: 43.80470906999444480334\n",
      "Iteration 49288 => Loss: 43.80456572178271557050\n",
      "Iteration 49289 => Loss: 43.80442237469600996747\n",
      "Iteration 49290 => Loss: 43.80427902873427825625\n",
      "Iteration 49291 => Loss: 43.80413568389750622600\n",
      "Iteration 49292 => Loss: 43.80399234018570098215\n",
      "Iteration 49293 => Loss: 43.80384899759885541926\n",
      "Iteration 49294 => Loss: 43.80370565613694111562\n",
      "Iteration 49295 => Loss: 43.80356231579997228209\n",
      "Iteration 49296 => Loss: 43.80341897658792760240\n",
      "Iteration 49297 => Loss: 43.80327563850082128738\n",
      "Iteration 49298 => Loss: 43.80313230153859649363\n",
      "Iteration 49299 => Loss: 43.80298896570128874828\n",
      "Iteration 49300 => Loss: 43.80284563098886252419\n",
      "Iteration 49301 => Loss: 43.80270229740131782137\n",
      "Iteration 49302 => Loss: 43.80255896493866885066\n",
      "Iteration 49303 => Loss: 43.80241563360085876866\n",
      "Iteration 49304 => Loss: 43.80227230338792310249\n",
      "Iteration 49305 => Loss: 43.80212897429983343045\n",
      "Iteration 49306 => Loss: 43.80198564633657554168\n",
      "Iteration 49307 => Loss: 43.80184231949813522533\n",
      "Iteration 49308 => Loss: 43.80169899378454800853\n",
      "Iteration 49309 => Loss: 43.80155566919575704787\n",
      "Iteration 49310 => Loss: 43.80141234573177655420\n",
      "Iteration 49311 => Loss: 43.80126902339257810581\n",
      "Iteration 49312 => Loss: 43.80112570217819722984\n",
      "Iteration 49313 => Loss: 43.80098238208856287201\n",
      "Iteration 49314 => Loss: 43.80083906312369634861\n",
      "Iteration 49315 => Loss: 43.80069574528357634335\n",
      "Iteration 49316 => Loss: 43.80055242856825969966\n",
      "Iteration 49317 => Loss: 43.80040911297763983612\n",
      "Iteration 49318 => Loss: 43.80026579851177359615\n",
      "Iteration 49319 => Loss: 43.80012248517061834718\n",
      "Iteration 49320 => Loss: 43.79997917295418830008\n",
      "Iteration 49321 => Loss: 43.79983586186246213856\n",
      "Iteration 49322 => Loss: 43.79969255189543986262\n",
      "Iteration 49323 => Loss: 43.79954924305310726140\n",
      "Iteration 49324 => Loss: 43.79940593533544301863\n",
      "Iteration 49325 => Loss: 43.79926262874246134515\n",
      "Iteration 49326 => Loss: 43.79911932327411250299\n",
      "Iteration 49327 => Loss: 43.79897601893046044097\n",
      "Iteration 49328 => Loss: 43.79883271571143410483\n",
      "Iteration 49329 => Loss: 43.79868941361704060000\n",
      "Iteration 49330 => Loss: 43.79854611264727992648\n",
      "Iteration 49331 => Loss: 43.79840281280213787340\n",
      "Iteration 49332 => Loss: 43.79825951408159312450\n",
      "Iteration 49333 => Loss: 43.79811621648565989062\n",
      "Iteration 49334 => Loss: 43.79797292001432396091\n",
      "Iteration 49335 => Loss: 43.79782962466754980824\n",
      "Iteration 49336 => Loss: 43.79768633044537295973\n",
      "Iteration 49337 => Loss: 43.79754303734776499368\n",
      "Iteration 49338 => Loss: 43.79739974537471169924\n",
      "Iteration 49339 => Loss: 43.79725645452617754927\n",
      "Iteration 49340 => Loss: 43.79711316480221228176\n",
      "Iteration 49341 => Loss: 43.79696987620277326414\n",
      "Iteration 49342 => Loss: 43.79682658872783918014\n",
      "Iteration 49343 => Loss: 43.79668330237742424060\n",
      "Iteration 49344 => Loss: 43.79654001715151423468\n",
      "Iteration 49345 => Loss: 43.79639673305009495152\n",
      "Iteration 49346 => Loss: 43.79625345007316639112\n",
      "Iteration 49347 => Loss: 43.79611016822072855348\n",
      "Iteration 49348 => Loss: 43.79596688749276722774\n",
      "Iteration 49349 => Loss: 43.79582360788921135963\n",
      "Iteration 49350 => Loss: 43.79568032941014621429\n",
      "Iteration 49351 => Loss: 43.79553705205554336999\n",
      "Iteration 49352 => Loss: 43.79539377582533177247\n",
      "Iteration 49353 => Loss: 43.79525050071956115971\n",
      "Iteration 49354 => Loss: 43.79510722673821732087\n",
      "Iteration 49355 => Loss: 43.79496395388126472881\n",
      "Iteration 49356 => Loss: 43.79482068214870338352\n",
      "Iteration 49357 => Loss: 43.79467741154054039043\n",
      "Iteration 49358 => Loss: 43.79453414205676864412\n",
      "Iteration 49359 => Loss: 43.79439087369735261746\n",
      "Iteration 49360 => Loss: 43.79424760646229941585\n",
      "Iteration 49361 => Loss: 43.79410434035161614474\n",
      "Iteration 49362 => Loss: 43.79396107536527438242\n",
      "Iteration 49363 => Loss: 43.79381781150325281260\n",
      "Iteration 49364 => Loss: 43.79367454876555854071\n",
      "Iteration 49365 => Loss: 43.79353128715219156675\n",
      "Iteration 49366 => Loss: 43.79338802666314478529\n",
      "Iteration 49367 => Loss: 43.79324476729838977462\n",
      "Iteration 49368 => Loss: 43.79310150905791232390\n",
      "Iteration 49369 => Loss: 43.79295825194174085482\n",
      "Iteration 49370 => Loss: 43.79281499594983273482\n",
      "Iteration 49371 => Loss: 43.79267174108218085848\n",
      "Iteration 49372 => Loss: 43.79252848733879233123\n",
      "Iteration 49373 => Loss: 43.79238523471967425849\n",
      "Iteration 49374 => Loss: 43.79224198322475558598\n",
      "Iteration 49375 => Loss: 43.79209873285408605170\n",
      "Iteration 49376 => Loss: 43.79195548360764433937\n",
      "Iteration 49377 => Loss: 43.79181223548541623813\n",
      "Iteration 49378 => Loss: 43.79166898848738753713\n",
      "Iteration 49379 => Loss: 43.79152574261356534180\n",
      "Iteration 49380 => Loss: 43.79138249786388570328\n",
      "Iteration 49381 => Loss: 43.79123925423842678128\n",
      "Iteration 49382 => Loss: 43.79109601173711752153\n",
      "Iteration 49383 => Loss: 43.79095277035997213488\n",
      "Iteration 49384 => Loss: 43.79080953010697641048\n",
      "Iteration 49385 => Loss: 43.79066629097813034832\n",
      "Iteration 49386 => Loss: 43.79052305297341263213\n",
      "Iteration 49387 => Loss: 43.79037981609280194562\n",
      "Iteration 49388 => Loss: 43.79023658033633381592\n",
      "Iteration 49389 => Loss: 43.79009334570397271591\n",
      "Iteration 49390 => Loss: 43.78995011219568311844\n",
      "Iteration 49391 => Loss: 43.78980687981150765609\n",
      "Iteration 49392 => Loss: 43.78966364855138237999\n",
      "Iteration 49393 => Loss: 43.78952041841537123901\n",
      "Iteration 49394 => Loss: 43.78937718940338896800\n",
      "Iteration 49395 => Loss: 43.78923396151547819954\n",
      "Iteration 49396 => Loss: 43.78909073475160340649\n",
      "Iteration 49397 => Loss: 43.78894750911177169428\n",
      "Iteration 49398 => Loss: 43.78880428459595464119\n",
      "Iteration 49399 => Loss: 43.78866106120416645808\n",
      "Iteration 49400 => Loss: 43.78851783893639293410\n",
      "Iteration 49401 => Loss: 43.78837461779260564754\n",
      "Iteration 49402 => Loss: 43.78823139777279749296\n",
      "Iteration 49403 => Loss: 43.78808817887700399751\n",
      "Iteration 49404 => Loss: 43.78794496110517542320\n",
      "Iteration 49405 => Loss: 43.78780174445731887545\n",
      "Iteration 49406 => Loss: 43.78765852893340593255\n",
      "Iteration 49407 => Loss: 43.78751531453345791078\n",
      "Iteration 49408 => Loss: 43.78737210125742507216\n",
      "Iteration 49409 => Loss: 43.78722888910532873297\n",
      "Iteration 49410 => Loss: 43.78708567807716178777\n",
      "Iteration 49411 => Loss: 43.78694246817290292029\n",
      "Iteration 49412 => Loss: 43.78679925939255213052\n",
      "Iteration 49413 => Loss: 43.78665605173609520762\n",
      "Iteration 49414 => Loss: 43.78651284520351083529\n",
      "Iteration 49415 => Loss: 43.78636963979482032983\n",
      "Iteration 49416 => Loss: 43.78622643550999526951\n",
      "Iteration 49417 => Loss: 43.78608323234904986521\n",
      "Iteration 49418 => Loss: 43.78594003031192016806\n",
      "Iteration 49419 => Loss: 43.78579682939864170521\n",
      "Iteration 49420 => Loss: 43.78565362960919316038\n",
      "Iteration 49421 => Loss: 43.78551043094358163899\n",
      "Iteration 49422 => Loss: 43.78536723340179293018\n",
      "Iteration 49423 => Loss: 43.78522403698378440140\n",
      "Iteration 49424 => Loss: 43.78508084168957736892\n",
      "Iteration 49425 => Loss: 43.78493764751917893818\n",
      "Iteration 49426 => Loss: 43.78479445447255358204\n",
      "Iteration 49427 => Loss: 43.78465126254970130049\n",
      "Iteration 49428 => Loss: 43.78450807175060788268\n",
      "Iteration 49429 => Loss: 43.78436488207527332861\n",
      "Iteration 49430 => Loss: 43.78422169352366921657\n",
      "Iteration 49431 => Loss: 43.78407850609582396828\n",
      "Iteration 49432 => Loss: 43.78393531979168784574\n",
      "Iteration 49433 => Loss: 43.78379213461128216522\n",
      "Iteration 49434 => Loss: 43.78364895055457139961\n",
      "Iteration 49435 => Loss: 43.78350576762159107602\n",
      "Iteration 49436 => Loss: 43.78336258581225592934\n",
      "Iteration 49437 => Loss: 43.78321940512662990841\n",
      "Iteration 49438 => Loss: 43.78307622556467038066\n",
      "Iteration 49439 => Loss: 43.78293304712639866239\n",
      "Iteration 49440 => Loss: 43.78278986981177212101\n",
      "Iteration 49441 => Loss: 43.78264669362079075654\n",
      "Iteration 49442 => Loss: 43.78250351855346167440\n",
      "Iteration 49443 => Loss: 43.78236034460974224203\n",
      "Iteration 49444 => Loss: 43.78221717178963956485\n",
      "Iteration 49445 => Loss: 43.78207400009317495915\n",
      "Iteration 49446 => Loss: 43.78193082952029868693\n",
      "Iteration 49447 => Loss: 43.78178766007101074820\n",
      "Iteration 49448 => Loss: 43.78164449174533245923\n",
      "Iteration 49449 => Loss: 43.78150132454322118747\n",
      "Iteration 49450 => Loss: 43.78135815846466272205\n",
      "Iteration 49451 => Loss: 43.78121499350969259012\n",
      "Iteration 49452 => Loss: 43.78107182967826105369\n",
      "Iteration 49453 => Loss: 43.78092866697035390189\n",
      "Iteration 49454 => Loss: 43.78078550538600666187\n",
      "Iteration 49455 => Loss: 43.78064234492514827934\n",
      "Iteration 49456 => Loss: 43.78049918558784270317\n",
      "Iteration 49457 => Loss: 43.78035602737402598450\n",
      "Iteration 49458 => Loss: 43.78021287028371943961\n",
      "Iteration 49459 => Loss: 43.78006971431690885765\n",
      "Iteration 49460 => Loss: 43.77992655947355160606\n",
      "Iteration 49461 => Loss: 43.77978340575367610654\n",
      "Iteration 49462 => Loss: 43.77964025315726814824\n",
      "Iteration 49463 => Loss: 43.77949710168432062574\n",
      "Iteration 49464 => Loss: 43.77935395133481222274\n",
      "Iteration 49465 => Loss: 43.77921080210873583383\n",
      "Iteration 49466 => Loss: 43.77906765400608435357\n",
      "Iteration 49467 => Loss: 43.77892450702685778197\n",
      "Iteration 49468 => Loss: 43.77878136117103480274\n",
      "Iteration 49469 => Loss: 43.77863821643860831045\n",
      "Iteration 49470 => Loss: 43.77849507282960672683\n",
      "Iteration 49471 => Loss: 43.77835193034395899758\n",
      "Iteration 49472 => Loss: 43.77820878898170064986\n",
      "Iteration 49473 => Loss: 43.77806564874279615651\n",
      "Iteration 49474 => Loss: 43.77792250962725972840\n",
      "Iteration 49475 => Loss: 43.77777937163505583840\n",
      "Iteration 49476 => Loss: 43.77763623476620580277\n",
      "Iteration 49477 => Loss: 43.77749309902068119982\n",
      "Iteration 49478 => Loss: 43.77734996439848202954\n",
      "Iteration 49479 => Loss: 43.77720683089959408107\n",
      "Iteration 49480 => Loss: 43.77706369852400314358\n",
      "Iteration 49481 => Loss: 43.77692056727171632247\n",
      "Iteration 49482 => Loss: 43.77677743714270519604\n",
      "Iteration 49483 => Loss: 43.77663430813699818600\n",
      "Iteration 49484 => Loss: 43.77649118025453134351\n",
      "Iteration 49485 => Loss: 43.77634805349534730112\n",
      "Iteration 49486 => Loss: 43.77620492785938921543\n",
      "Iteration 49487 => Loss: 43.77606180334667840270\n",
      "Iteration 49488 => Loss: 43.77591867995722196838\n",
      "Iteration 49489 => Loss: 43.77577555769097727989\n",
      "Iteration 49490 => Loss: 43.77563243654794433724\n",
      "Iteration 49491 => Loss: 43.77548931652813024584\n",
      "Iteration 49492 => Loss: 43.77534619763151368943\n",
      "Iteration 49493 => Loss: 43.77520307985805914086\n",
      "Iteration 49494 => Loss: 43.77505996320780923270\n",
      "Iteration 49495 => Loss: 43.77491684768073554324\n",
      "Iteration 49496 => Loss: 43.77477373327681675619\n",
      "Iteration 49497 => Loss: 43.77463061999605287156\n",
      "Iteration 49498 => Loss: 43.77448750783843678391\n",
      "Iteration 49499 => Loss: 43.77434439680394717698\n",
      "Iteration 49500 => Loss: 43.77420128689259826160\n",
      "Iteration 49501 => Loss: 43.77405817810436161608\n",
      "Iteration 49502 => Loss: 43.77391507043924434583\n",
      "Iteration 49503 => Loss: 43.77377196389721802916\n",
      "Iteration 49504 => Loss: 43.77362885847830398234\n",
      "Iteration 49505 => Loss: 43.77348575418243825652\n",
      "Iteration 49506 => Loss: 43.77334265100967769513\n",
      "Iteration 49507 => Loss: 43.77319954895995834931\n",
      "Iteration 49508 => Loss: 43.77305644803331574622\n",
      "Iteration 49509 => Loss: 43.77291334822972146412\n",
      "Iteration 49510 => Loss: 43.77277024954914708132\n",
      "Iteration 49511 => Loss: 43.77262715199164233582\n",
      "Iteration 49512 => Loss: 43.77248405555711485704\n",
      "Iteration 49513 => Loss: 43.77234096024561438298\n",
      "Iteration 49514 => Loss: 43.77219786605712670280\n",
      "Iteration 49515 => Loss: 43.77205477299163760563\n",
      "Iteration 49516 => Loss: 43.77191168104914709147\n",
      "Iteration 49517 => Loss: 43.77176859022959831691\n",
      "Iteration 49518 => Loss: 43.77162550053304812536\n",
      "Iteration 49519 => Loss: 43.77148241195946098969\n",
      "Iteration 49520 => Loss: 43.77133932450880848819\n",
      "Iteration 49521 => Loss: 43.77119623818109772628\n",
      "Iteration 49522 => Loss: 43.77105315297632159854\n",
      "Iteration 49523 => Loss: 43.77091006889448721040\n",
      "Iteration 49524 => Loss: 43.77076698593553771843\n",
      "Iteration 49525 => Loss: 43.77062390409953707149\n",
      "Iteration 49526 => Loss: 43.77048082338641421529\n",
      "Iteration 49527 => Loss: 43.77033774379616204442\n",
      "Iteration 49528 => Loss: 43.77019466532881608600\n",
      "Iteration 49529 => Loss: 43.77005158798434791834\n",
      "Iteration 49530 => Loss: 43.76990851176272911971\n",
      "Iteration 49531 => Loss: 43.76976543666397390098\n",
      "Iteration 49532 => Loss: 43.76962236268806094586\n",
      "Iteration 49533 => Loss: 43.76947928983499735978\n",
      "Iteration 49534 => Loss: 43.76933621810471919389\n",
      "Iteration 49535 => Loss: 43.76919314749729750247\n",
      "Iteration 49536 => Loss: 43.76905007801267544210\n",
      "Iteration 49537 => Loss: 43.76890700965086011820\n",
      "Iteration 49538 => Loss: 43.76876394241183731992\n",
      "Iteration 49539 => Loss: 43.76862087629559283641\n",
      "Iteration 49540 => Loss: 43.76847781130211245681\n",
      "Iteration 49541 => Loss: 43.76833474743142460284\n",
      "Iteration 49542 => Loss: 43.76819168468347953649\n",
      "Iteration 49543 => Loss: 43.76804862305827725777\n",
      "Iteration 49544 => Loss: 43.76790556255583908296\n",
      "Iteration 49545 => Loss: 43.76776250317612237950\n",
      "Iteration 49546 => Loss: 43.76761944491912004196\n",
      "Iteration 49547 => Loss: 43.76747638778482496491\n",
      "Iteration 49548 => Loss: 43.76733333177323714835\n",
      "Iteration 49549 => Loss: 43.76719027688434948686\n",
      "Iteration 49550 => Loss: 43.76704722311815487501\n",
      "Iteration 49551 => Loss: 43.76690417047464620737\n",
      "Iteration 49552 => Loss: 43.76676111895379506223\n",
      "Iteration 49553 => Loss: 43.76661806855560854501\n",
      "Iteration 49554 => Loss: 43.76647501928005823402\n",
      "Iteration 49555 => Loss: 43.76633197112717965638\n",
      "Iteration 49556 => Loss: 43.76618892409692307410\n",
      "Iteration 49557 => Loss: 43.76604587818929559262\n",
      "Iteration 49558 => Loss: 43.76590283340427589565\n",
      "Iteration 49559 => Loss: 43.76575978974186398318\n",
      "Iteration 49560 => Loss: 43.76561674720205274980\n",
      "Iteration 49561 => Loss: 43.76547370578483509007\n",
      "Iteration 49562 => Loss: 43.76533066549021100400\n",
      "Iteration 49563 => Loss: 43.76518762631812364816\n",
      "Iteration 49564 => Loss: 43.76504458826862276055\n",
      "Iteration 49565 => Loss: 43.76490155134167991946\n",
      "Iteration 49566 => Loss: 43.76475851553728091403\n",
      "Iteration 49567 => Loss: 43.76461548085542574427\n",
      "Iteration 49568 => Loss: 43.76447244729607888303\n",
      "Iteration 49569 => Loss: 43.76432941485926164660\n",
      "Iteration 49570 => Loss: 43.76418638354496692955\n",
      "Iteration 49571 => Loss: 43.76404335335318052103\n",
      "Iteration 49572 => Loss: 43.76390032428386689389\n",
      "Iteration 49573 => Loss: 43.76375729633703315358\n",
      "Iteration 49574 => Loss: 43.76361426951268640551\n",
      "Iteration 49575 => Loss: 43.76347124381081243882\n",
      "Iteration 49576 => Loss: 43.76332821923138283182\n",
      "Iteration 49577 => Loss: 43.76318519577441179536\n",
      "Iteration 49578 => Loss: 43.76304217343989222400\n",
      "Iteration 49579 => Loss: 43.76289915222778859061\n",
      "Iteration 49580 => Loss: 43.76275613213812931690\n",
      "Iteration 49581 => Loss: 43.76261311317085045403\n",
      "Iteration 49582 => Loss: 43.76247009532599463455\n",
      "Iteration 49583 => Loss: 43.76232707860352633134\n",
      "Iteration 49584 => Loss: 43.76218406300345264981\n",
      "Iteration 49585 => Loss: 43.76204104852575227369\n",
      "Iteration 49586 => Loss: 43.76189803517044651926\n",
      "Iteration 49587 => Loss: 43.76175502293747143767\n",
      "Iteration 49588 => Loss: 43.76161201182685545064\n",
      "Iteration 49589 => Loss: 43.76146900183859145272\n",
      "Iteration 49590 => Loss: 43.76132599297266523308\n",
      "Iteration 49591 => Loss: 43.76118298522905547543\n",
      "Iteration 49592 => Loss: 43.76103997860776928519\n",
      "Iteration 49593 => Loss: 43.76089697310879245151\n",
      "Iteration 49594 => Loss: 43.76075396873209655269\n",
      "Iteration 49595 => Loss: 43.76061096547771001042\n",
      "Iteration 49596 => Loss: 43.76046796334560440300\n",
      "Iteration 49597 => Loss: 43.76032496233576551958\n",
      "Iteration 49598 => Loss: 43.76018196244819336016\n",
      "Iteration 49599 => Loss: 43.76003896368289503016\n",
      "Iteration 49600 => Loss: 43.75989596603982079159\n",
      "Iteration 49601 => Loss: 43.75975296951899906617\n",
      "Iteration 49602 => Loss: 43.75960997412038722132\n",
      "Iteration 49603 => Loss: 43.75946697984402078418\n",
      "Iteration 49604 => Loss: 43.75932398668983580592\n",
      "Iteration 49605 => Loss: 43.75918099465787491908\n",
      "Iteration 49606 => Loss: 43.75903800374810259655\n",
      "Iteration 49607 => Loss: 43.75889501396050462745\n",
      "Iteration 49608 => Loss: 43.75875202529510943350\n",
      "Iteration 49609 => Loss: 43.75860903775186727671\n",
      "Iteration 49610 => Loss: 43.75846605133077105165\n",
      "Iteration 49611 => Loss: 43.75832306603182786375\n",
      "Iteration 49612 => Loss: 43.75818008185505192387\n",
      "Iteration 49613 => Loss: 43.75803709880038638858\n",
      "Iteration 49614 => Loss: 43.75789411686784546873\n",
      "Iteration 49615 => Loss: 43.75775113605741495348\n",
      "Iteration 49616 => Loss: 43.75760815636911615911\n",
      "Iteration 49617 => Loss: 43.75746517780289934763\n",
      "Iteration 49618 => Loss: 43.75732220035875741360\n",
      "Iteration 49619 => Loss: 43.75717922403669746245\n",
      "Iteration 49620 => Loss: 43.75703624883672659962\n",
      "Iteration 49621 => Loss: 43.75689327475879508711\n",
      "Iteration 49622 => Loss: 43.75675030180293845206\n",
      "Iteration 49623 => Loss: 43.75660732996911406190\n",
      "Iteration 49624 => Loss: 43.75646435925732902206\n",
      "Iteration 49625 => Loss: 43.75632138966756201626\n",
      "Iteration 49626 => Loss: 43.75617842119982014992\n",
      "Iteration 49627 => Loss: 43.75603545385408921220\n",
      "Iteration 49628 => Loss: 43.75589248763036209766\n",
      "Iteration 49629 => Loss: 43.75574952252861749002\n",
      "Iteration 49630 => Loss: 43.75560655854884117844\n",
      "Iteration 49631 => Loss: 43.75546359569105447918\n",
      "Iteration 49632 => Loss: 43.75532063395524318139\n",
      "Iteration 49633 => Loss: 43.75517767334137175794\n",
      "Iteration 49634 => Loss: 43.75503471384946152511\n",
      "Iteration 49635 => Loss: 43.75489175547949116662\n",
      "Iteration 49636 => Loss: 43.75474879823141804991\n",
      "Iteration 49637 => Loss: 43.75460584210529901839\n",
      "Iteration 49638 => Loss: 43.75446288710107722864\n",
      "Iteration 49639 => Loss: 43.75431993321876689151\n",
      "Iteration 49640 => Loss: 43.75417698045836090159\n",
      "Iteration 49641 => Loss: 43.75403402881983794259\n",
      "Iteration 49642 => Loss: 43.75389107830316959280\n",
      "Iteration 49643 => Loss: 43.75374812890837716850\n",
      "Iteration 49644 => Loss: 43.75360518063546777512\n",
      "Iteration 49645 => Loss: 43.75346223348439167466\n",
      "Iteration 49646 => Loss: 43.75331928745514176171\n",
      "Iteration 49647 => Loss: 43.75317634254773224711\n",
      "Iteration 49648 => Loss: 43.75303339876216313087\n",
      "Iteration 49649 => Loss: 43.75289045609839178042\n",
      "Iteration 49650 => Loss: 43.75274751455643240661\n",
      "Iteration 49651 => Loss: 43.75260457413627790402\n",
      "Iteration 49652 => Loss: 43.75246163483791406179\n",
      "Iteration 49653 => Loss: 43.75231869666131956365\n",
      "Iteration 49654 => Loss: 43.75217575960650151501\n",
      "Iteration 49655 => Loss: 43.75203282367343859960\n",
      "Iteration 49656 => Loss: 43.75188988886213081742\n",
      "Iteration 49657 => Loss: 43.75174695517257106303\n",
      "Iteration 49658 => Loss: 43.75160402260475223102\n",
      "Iteration 49659 => Loss: 43.75146109115866721595\n",
      "Iteration 49660 => Loss: 43.75131816083429470154\n",
      "Iteration 49661 => Loss: 43.75117523163162758237\n",
      "Iteration 49662 => Loss: 43.75103230355063743673\n",
      "Iteration 49663 => Loss: 43.75088937659138821346\n",
      "Iteration 49664 => Loss: 43.75074645075378043657\n",
      "Iteration 49665 => Loss: 43.75060352603787805492\n",
      "Iteration 49666 => Loss: 43.75046060244361711966\n",
      "Iteration 49667 => Loss: 43.75031767997103315793\n",
      "Iteration 49668 => Loss: 43.75017475862007643173\n",
      "Iteration 49669 => Loss: 43.75003183839078246820\n",
      "Iteration 49670 => Loss: 43.74988891928310863477\n",
      "Iteration 49671 => Loss: 43.74974600129705493146\n",
      "Iteration 49672 => Loss: 43.74960308443260714739\n",
      "Iteration 49673 => Loss: 43.74946016868977238801\n",
      "Iteration 49674 => Loss: 43.74931725406852223159\n",
      "Iteration 49675 => Loss: 43.74917434056887088900\n",
      "Iteration 49676 => Loss: 43.74903142819078993853\n",
      "Iteration 49677 => Loss: 43.74888851693429359102\n",
      "Iteration 49678 => Loss: 43.74874560679933210849\n",
      "Iteration 49679 => Loss: 43.74860269778593391266\n",
      "Iteration 49680 => Loss: 43.74845978989408479265\n",
      "Iteration 49681 => Loss: 43.74831688312375632677\n",
      "Iteration 49682 => Loss: 43.74817397747496272586\n",
      "Iteration 49683 => Loss: 43.74803107294768267366\n",
      "Iteration 49684 => Loss: 43.74788816954190195929\n",
      "Iteration 49685 => Loss: 43.74774526725761347734\n",
      "Iteration 49686 => Loss: 43.74760236609483143866\n",
      "Iteration 49687 => Loss: 43.74745946605352742154\n",
      "Iteration 49688 => Loss: 43.74731656713370142597\n",
      "Iteration 49689 => Loss: 43.74717366933533924112\n",
      "Iteration 49690 => Loss: 43.74703077265840533983\n",
      "Iteration 49691 => Loss: 43.74688787710294946010\n",
      "Iteration 49692 => Loss: 43.74674498266891475851\n",
      "Iteration 49693 => Loss: 43.74660208935631544591\n",
      "Iteration 49694 => Loss: 43.74645919716513020603\n",
      "Iteration 49695 => Loss: 43.74631630609533772258\n",
      "Iteration 49696 => Loss: 43.74617341614697352270\n",
      "Iteration 49697 => Loss: 43.74603052731998786840\n",
      "Iteration 49698 => Loss: 43.74588763961438075967\n",
      "Iteration 49699 => Loss: 43.74574475303016640737\n",
      "Iteration 49700 => Loss: 43.74560186756730928437\n",
      "Iteration 49701 => Loss: 43.74545898322580939066\n",
      "Iteration 49702 => Loss: 43.74531610000566672625\n",
      "Iteration 49703 => Loss: 43.74517321790685997485\n",
      "Iteration 49704 => Loss: 43.74503033692936782018\n",
      "Iteration 49705 => Loss: 43.74488745707323289480\n",
      "Iteration 49706 => Loss: 43.74474457833837703902\n",
      "Iteration 49707 => Loss: 43.74460170072484999082\n",
      "Iteration 49708 => Loss: 43.74445882423258780136\n",
      "Iteration 49709 => Loss: 43.74431594886164020863\n",
      "Iteration 49710 => Loss: 43.74417307461196458007\n",
      "Iteration 49711 => Loss: 43.74403020148355381025\n",
      "Iteration 49712 => Loss: 43.74388732947642211002\n",
      "Iteration 49713 => Loss: 43.74374445859051974139\n",
      "Iteration 49714 => Loss: 43.74360158882587512608\n",
      "Iteration 49715 => Loss: 43.74345872018245273694\n",
      "Iteration 49716 => Loss: 43.74331585266027389025\n",
      "Iteration 49717 => Loss: 43.74317298625928884803\n",
      "Iteration 49718 => Loss: 43.74303012097951892656\n",
      "Iteration 49719 => Loss: 43.74288725682095702041\n",
      "Iteration 49720 => Loss: 43.74274439378357470787\n",
      "Iteration 49721 => Loss: 43.74260153186739330522\n",
      "Iteration 49722 => Loss: 43.74245867107234886362\n",
      "Iteration 49723 => Loss: 43.74231581139850533191\n",
      "Iteration 49724 => Loss: 43.74217295284581297210\n",
      "Iteration 49725 => Loss: 43.74203009541425046791\n",
      "Iteration 49726 => Loss: 43.74188723910383203020\n",
      "Iteration 49727 => Loss: 43.74174438391453634267\n",
      "Iteration 49728 => Loss: 43.74160152984637051077\n",
      "Iteration 49729 => Loss: 43.74145867689932032363\n",
      "Iteration 49730 => Loss: 43.74131582507335735954\n",
      "Iteration 49731 => Loss: 43.74117297436848872394\n",
      "Iteration 49732 => Loss: 43.74103012478472152225\n",
      "Iteration 49733 => Loss: 43.74088727632202022733\n",
      "Iteration 49734 => Loss: 43.74074442898037773375\n",
      "Iteration 49735 => Loss: 43.74060158275980825238\n",
      "Iteration 49736 => Loss: 43.74045873766027625607\n",
      "Iteration 49737 => Loss: 43.74031589368178174482\n",
      "Iteration 49738 => Loss: 43.74017305082434603491\n",
      "Iteration 49739 => Loss: 43.74003020908789096666\n",
      "Iteration 49740 => Loss: 43.73988736847248048889\n",
      "Iteration 49741 => Loss: 43.73974452897808617990\n",
      "Iteration 49742 => Loss: 43.73960169060467251256\n",
      "Iteration 49743 => Loss: 43.73945885335223238144\n",
      "Iteration 49744 => Loss: 43.73931601722080841910\n",
      "Iteration 49745 => Loss: 43.73917318221031536041\n",
      "Iteration 49746 => Loss: 43.73903034832080294336\n",
      "Iteration 49747 => Loss: 43.73888751555224985168\n",
      "Iteration 49748 => Loss: 43.73874468390462766365\n",
      "Iteration 49749 => Loss: 43.73860185337792927385\n",
      "Iteration 49750 => Loss: 43.73845902397217599855\n",
      "Iteration 49751 => Loss: 43.73831619568734652148\n",
      "Iteration 49752 => Loss: 43.73817336852341242093\n",
      "Iteration 49753 => Loss: 43.73803054248038790774\n",
      "Iteration 49754 => Loss: 43.73788771755825166565\n",
      "Iteration 49755 => Loss: 43.73774489375700369465\n",
      "Iteration 49756 => Loss: 43.73760207107661557302\n",
      "Iteration 49757 => Loss: 43.73745924951710861706\n",
      "Iteration 49758 => Loss: 43.73731642907845440504\n",
      "Iteration 49759 => Loss: 43.73717360976062451527\n",
      "Iteration 49760 => Loss: 43.73703079156363315860\n",
      "Iteration 49761 => Loss: 43.73688797448749454588\n",
      "Iteration 49762 => Loss: 43.73674515853218025541\n",
      "Iteration 49763 => Loss: 43.73660234369766186546\n",
      "Iteration 49764 => Loss: 43.73645952998395358691\n",
      "Iteration 49765 => Loss: 43.73631671739104120888\n",
      "Iteration 49766 => Loss: 43.73617390591891762597\n",
      "Iteration 49767 => Loss: 43.73603109556755441645\n",
      "Iteration 49768 => Loss: 43.73588828633695868575\n",
      "Iteration 49769 => Loss: 43.73574547822715885559\n",
      "Iteration 49770 => Loss: 43.73560267123806966083\n",
      "Iteration 49771 => Loss: 43.73545986536976215575\n",
      "Iteration 49772 => Loss: 43.73531706062214396979\n",
      "Iteration 49773 => Loss: 43.73517425699527905181\n",
      "Iteration 49774 => Loss: 43.73503145448910345294\n",
      "Iteration 49775 => Loss: 43.73488865310365270034\n",
      "Iteration 49776 => Loss: 43.73474585283889126686\n",
      "Iteration 49777 => Loss: 43.73460305369482625792\n",
      "Iteration 49778 => Loss: 43.73446025567144346269\n",
      "Iteration 49779 => Loss: 43.73431745876872867029\n",
      "Iteration 49780 => Loss: 43.73417466298667477531\n",
      "Iteration 49781 => Loss: 43.73403186832527467232\n",
      "Iteration 49782 => Loss: 43.73388907478453546673\n",
      "Iteration 49783 => Loss: 43.73374628236440742057\n",
      "Iteration 49784 => Loss: 43.73360349106492606097\n",
      "Iteration 49785 => Loss: 43.73346070088604875536\n",
      "Iteration 49786 => Loss: 43.73331791182778260918\n",
      "Iteration 49787 => Loss: 43.73317512389012051699\n",
      "Iteration 49788 => Loss: 43.73303233707304826794\n",
      "Iteration 49789 => Loss: 43.73288955137656586203\n",
      "Iteration 49790 => Loss: 43.73274676680065908840\n",
      "Iteration 49791 => Loss: 43.73260398334532084164\n",
      "Iteration 49792 => Loss: 43.73246120101053691087\n",
      "Iteration 49793 => Loss: 43.73231841979627887440\n",
      "Iteration 49794 => Loss: 43.73217563970258225936\n",
      "Iteration 49795 => Loss: 43.73203286072942574947\n",
      "Iteration 49796 => Loss: 43.73189008287678092302\n",
      "Iteration 49797 => Loss: 43.73174730614461225287\n",
      "Iteration 49798 => Loss: 43.73160453053301210957\n",
      "Iteration 49799 => Loss: 43.73146175604185970087\n",
      "Iteration 49800 => Loss: 43.73131898267121187018\n",
      "Iteration 49801 => Loss: 43.73117621042105440665\n",
      "Iteration 49802 => Loss: 43.73103343929134467771\n",
      "Iteration 49803 => Loss: 43.73089066928211110508\n",
      "Iteration 49804 => Loss: 43.73074790039331816160\n",
      "Iteration 49805 => Loss: 43.73060513262497295273\n",
      "Iteration 49806 => Loss: 43.73046236597706837301\n",
      "Iteration 49807 => Loss: 43.73031960044958310618\n",
      "Iteration 49808 => Loss: 43.73017683604250294138\n",
      "Iteration 49809 => Loss: 43.73003407275583498404\n",
      "Iteration 49810 => Loss: 43.72989131058958633957\n",
      "Iteration 49811 => Loss: 43.72974854954369305915\n",
      "Iteration 49812 => Loss: 43.72960578961818356447\n",
      "Iteration 49813 => Loss: 43.72946303081307917182\n",
      "Iteration 49814 => Loss: 43.72932027312833014321\n",
      "Iteration 49815 => Loss: 43.72917751656392226778\n",
      "Iteration 49816 => Loss: 43.72903476111987686181\n",
      "Iteration 49817 => Loss: 43.72889200679615129275\n",
      "Iteration 49818 => Loss: 43.72874925359275266601\n",
      "Iteration 49819 => Loss: 43.72860650150968098160\n",
      "Iteration 49820 => Loss: 43.72846375054692202866\n",
      "Iteration 49821 => Loss: 43.72832100070445449091\n",
      "Iteration 49822 => Loss: 43.72817825198229968464\n",
      "Iteration 49823 => Loss: 43.72803550438040787185\n",
      "Iteration 49824 => Loss: 43.72789275789880036882\n",
      "Iteration 49825 => Loss: 43.72775001253745585927\n",
      "Iteration 49826 => Loss: 43.72760726829638855406\n",
      "Iteration 49827 => Loss: 43.72746452517556292605\n",
      "Iteration 49828 => Loss: 43.72732178317497186981\n",
      "Iteration 49829 => Loss: 43.72717904229460827992\n",
      "Iteration 49830 => Loss: 43.72703630253446505094\n",
      "Iteration 49831 => Loss: 43.72689356389454928831\n",
      "Iteration 49832 => Loss: 43.72675082637483967574\n",
      "Iteration 49833 => Loss: 43.72660808997530068609\n",
      "Iteration 49834 => Loss: 43.72646535469596784651\n",
      "Iteration 49835 => Loss: 43.72632262053681984071\n",
      "Iteration 49836 => Loss: 43.72617988749784245783\n",
      "Iteration 49837 => Loss: 43.72603715557901438160\n",
      "Iteration 49838 => Loss: 43.72589442478034271744\n",
      "Iteration 49839 => Loss: 43.72575169510182746535\n",
      "Iteration 49840 => Loss: 43.72560896654344730905\n",
      "Iteration 49841 => Loss: 43.72546623910516672140\n",
      "Iteration 49842 => Loss: 43.72532351278702122954\n",
      "Iteration 49843 => Loss: 43.72518078758897530633\n",
      "Iteration 49844 => Loss: 43.72503806351104316263\n",
      "Iteration 49845 => Loss: 43.72489534055321058759\n",
      "Iteration 49846 => Loss: 43.72475261871544205405\n",
      "Iteration 49847 => Loss: 43.72460989799773756204\n",
      "Iteration 49848 => Loss: 43.72446717840011132239\n",
      "Iteration 49849 => Loss: 43.72432445992254201883\n",
      "Iteration 49850 => Loss: 43.72418174256501544050\n",
      "Iteration 49851 => Loss: 43.72403902632753158741\n",
      "Iteration 49852 => Loss: 43.72389631121006914327\n",
      "Iteration 49853 => Loss: 43.72375359721262810808\n",
      "Iteration 49854 => Loss: 43.72361088433520848184\n",
      "Iteration 49855 => Loss: 43.72346817257779605370\n",
      "Iteration 49856 => Loss: 43.72332546194035529652\n",
      "Iteration 49857 => Loss: 43.72318275242292884286\n",
      "Iteration 49858 => Loss: 43.72304004402545984931\n",
      "Iteration 49859 => Loss: 43.72289733674796252672\n",
      "Iteration 49860 => Loss: 43.72275463059042976965\n",
      "Iteration 49861 => Loss: 43.72261192555284026184\n",
      "Iteration 49862 => Loss: 43.72246922163520110871\n",
      "Iteration 49863 => Loss: 43.72232651883747678312\n",
      "Iteration 49864 => Loss: 43.72218381715970281221\n",
      "Iteration 49865 => Loss: 43.72204111660183656340\n",
      "Iteration 49866 => Loss: 43.72189841716386382586\n",
      "Iteration 49867 => Loss: 43.72175571884579881043\n",
      "Iteration 49868 => Loss: 43.72161302164759888456\n",
      "Iteration 49869 => Loss: 43.72147032556930668079\n",
      "Iteration 49870 => Loss: 43.72132763061087246115\n",
      "Iteration 49871 => Loss: 43.72118493677231754191\n",
      "Iteration 49872 => Loss: 43.72104224405361350136\n",
      "Iteration 49873 => Loss: 43.72089955245473902323\n",
      "Iteration 49874 => Loss: 43.72075686197570121294\n",
      "Iteration 49875 => Loss: 43.72061417261650007049\n",
      "Iteration 49876 => Loss: 43.72047148437710717417\n",
      "Iteration 49877 => Loss: 43.72032879725753673483\n",
      "Iteration 49878 => Loss: 43.72018611125776743620\n",
      "Iteration 49879 => Loss: 43.72004342637777796199\n",
      "Iteration 49880 => Loss: 43.71990074261757541763\n",
      "Iteration 49881 => Loss: 43.71975805997715980311\n",
      "Iteration 49882 => Loss: 43.71961537845650269674\n",
      "Iteration 49883 => Loss: 43.71947269805559699307\n",
      "Iteration 49884 => Loss: 43.71933001877444979755\n",
      "Iteration 49885 => Loss: 43.71918734061303268845\n",
      "Iteration 49886 => Loss: 43.71904466357134566579\n",
      "Iteration 49887 => Loss: 43.71890198764939583498\n",
      "Iteration 49888 => Loss: 43.71875931284713345804\n",
      "Iteration 49889 => Loss: 43.71861663916459406209\n",
      "Iteration 49890 => Loss: 43.71847396660176343630\n",
      "Iteration 49891 => Loss: 43.71833129515859184266\n",
      "Iteration 49892 => Loss: 43.71818862483510770289\n",
      "Iteration 49893 => Loss: 43.71804595563130391156\n",
      "Iteration 49894 => Loss: 43.71790328754714494153\n",
      "Iteration 49895 => Loss: 43.71776062058264500365\n",
      "Iteration 49896 => Loss: 43.71761795473777567622\n",
      "Iteration 49897 => Loss: 43.71747529001254406467\n",
      "Iteration 49898 => Loss: 43.71733262640696437984\n",
      "Iteration 49899 => Loss: 43.71718996392097267290\n",
      "Iteration 49900 => Loss: 43.71704730255459736554\n",
      "Iteration 49901 => Loss: 43.71690464230783135235\n",
      "Iteration 49902 => Loss: 43.71676198318063200077\n",
      "Iteration 49903 => Loss: 43.71661932517302773249\n",
      "Iteration 49904 => Loss: 43.71647666828500433667\n",
      "Iteration 49905 => Loss: 43.71633401251654049702\n",
      "Iteration 49906 => Loss: 43.71619135786761489726\n",
      "Iteration 49907 => Loss: 43.71604870433824174825\n",
      "Iteration 49908 => Loss: 43.71590605192842815541\n",
      "Iteration 49909 => Loss: 43.71576340063813148618\n",
      "Iteration 49910 => Loss: 43.71562075046733752970\n",
      "Iteration 49911 => Loss: 43.71547810141607470769\n",
      "Iteration 49912 => Loss: 43.71533545348429328214\n",
      "Iteration 49913 => Loss: 43.71519280667202167479\n",
      "Iteration 49914 => Loss: 43.71505016097923856933\n",
      "Iteration 49915 => Loss: 43.71490751640591554406\n",
      "Iteration 49916 => Loss: 43.71476487295205970440\n",
      "Iteration 49917 => Loss: 43.71462223061768526122\n",
      "Iteration 49918 => Loss: 43.71447958940274247652\n",
      "Iteration 49919 => Loss: 43.71433694930724556116\n",
      "Iteration 49920 => Loss: 43.71419431033117319885\n",
      "Iteration 49921 => Loss: 43.71405167247453249502\n",
      "Iteration 49922 => Loss: 43.71390903573729502796\n",
      "Iteration 49923 => Loss: 43.71376640011946790310\n",
      "Iteration 49924 => Loss: 43.71362376562102980415\n",
      "Iteration 49925 => Loss: 43.71348113224200204741\n",
      "Iteration 49926 => Loss: 43.71333849998234910572\n",
      "Iteration 49927 => Loss: 43.71319586884204966282\n",
      "Iteration 49928 => Loss: 43.71305323882113214040\n",
      "Iteration 49929 => Loss: 43.71291060991956101134\n",
      "Iteration 49930 => Loss: 43.71276798213733627563\n",
      "Iteration 49931 => Loss: 43.71262535547442951156\n",
      "Iteration 49932 => Loss: 43.71248272993086914084\n",
      "Iteration 49933 => Loss: 43.71234010550661253092\n",
      "Iteration 49934 => Loss: 43.71219748220166678720\n",
      "Iteration 49935 => Loss: 43.71205486001603190971\n",
      "Iteration 49936 => Loss: 43.71191223894967237129\n",
      "Iteration 49937 => Loss: 43.71176961900260948823\n",
      "Iteration 49938 => Loss: 43.71162700017480773340\n",
      "Iteration 49939 => Loss: 43.71148438246628131765\n",
      "Iteration 49940 => Loss: 43.71134176587700181926\n",
      "Iteration 49941 => Loss: 43.71119915040698344910\n",
      "Iteration 49942 => Loss: 43.71105653605619778546\n",
      "Iteration 49943 => Loss: 43.71091392282465193375\n",
      "Iteration 49944 => Loss: 43.71077131071231036685\n",
      "Iteration 49945 => Loss: 43.71062869971918019019\n",
      "Iteration 49946 => Loss: 43.71048608984525429833\n",
      "Iteration 49947 => Loss: 43.71034348109054690212\n",
      "Iteration 49948 => Loss: 43.71020087345497984188\n",
      "Iteration 49949 => Loss: 43.71005826693863127730\n",
      "Iteration 49950 => Loss: 43.70991566154145147038\n",
      "Iteration 49951 => Loss: 43.70977305726339778857\n",
      "Iteration 49952 => Loss: 43.70963045410452707529\n",
      "Iteration 49953 => Loss: 43.70948785206478959253\n",
      "Iteration 49954 => Loss: 43.70934525114417823488\n",
      "Iteration 49955 => Loss: 43.70920265134269300233\n",
      "Iteration 49956 => Loss: 43.70906005266033389489\n",
      "Iteration 49957 => Loss: 43.70891745509705827999\n",
      "Iteration 49958 => Loss: 43.70877485865290168476\n",
      "Iteration 49959 => Loss: 43.70863226332782147665\n",
      "Iteration 49960 => Loss: 43.70848966912183897193\n",
      "Iteration 49961 => Loss: 43.70834707603490443262\n",
      "Iteration 49962 => Loss: 43.70820448406707470212\n",
      "Iteration 49963 => Loss: 43.70806189321825740990\n",
      "Iteration 49964 => Loss: 43.70791930348850229393\n",
      "Iteration 49965 => Loss: 43.70777671487777382708\n",
      "Iteration 49966 => Loss: 43.70763412738607911479\n",
      "Iteration 49967 => Loss: 43.70749154101341815704\n",
      "Iteration 49968 => Loss: 43.70734895575975542670\n",
      "Iteration 49969 => Loss: 43.70720637162509802920\n",
      "Iteration 49970 => Loss: 43.70706378860943175368\n",
      "Iteration 49971 => Loss: 43.70692120671271396759\n",
      "Iteration 49972 => Loss: 43.70677862593502993604\n",
      "Iteration 49973 => Loss: 43.70663604627628018306\n",
      "Iteration 49974 => Loss: 43.70649346773649313036\n",
      "Iteration 49975 => Loss: 43.70635089031566167250\n",
      "Iteration 49976 => Loss: 43.70620831401375738778\n",
      "Iteration 49977 => Loss: 43.70606573883080869791\n",
      "Iteration 49978 => Loss: 43.70592316476675875947\n",
      "Iteration 49979 => Loss: 43.70578059182162178331\n",
      "Iteration 49980 => Loss: 43.70563801999540487486\n",
      "Iteration 49981 => Loss: 43.70549544928807961242\n",
      "Iteration 49982 => Loss: 43.70535287969961757426\n",
      "Iteration 49983 => Loss: 43.70521031123006849839\n",
      "Iteration 49984 => Loss: 43.70506774387937554138\n",
      "Iteration 49985 => Loss: 43.70492517764755291410\n",
      "Iteration 49986 => Loss: 43.70478261253455798396\n",
      "Iteration 49987 => Loss: 43.70464004854043338355\n",
      "Iteration 49988 => Loss: 43.70449748566512937487\n",
      "Iteration 49989 => Loss: 43.70435492390866016876\n",
      "Iteration 49990 => Loss: 43.70421236327099734353\n",
      "Iteration 49991 => Loss: 43.70406980375213379375\n",
      "Iteration 49992 => Loss: 43.70392724535208373027\n",
      "Iteration 49993 => Loss: 43.70378468807083294223\n",
      "Iteration 49994 => Loss: 43.70364213190835300793\n",
      "Iteration 49995 => Loss: 43.70349957686466524365\n",
      "Iteration 49996 => Loss: 43.70335702293970570054\n",
      "Iteration 49997 => Loss: 43.70321447013353122202\n",
      "Iteration 49998 => Loss: 43.70307191844608496467\n",
      "Iteration 49999 => Loss: 43.70292936787739535021\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T17:28:15.165705Z",
     "start_time": "2025-05-27T17:28:15.156031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Weights: %s\" % w.T)\n",
    "print(\"A few predictions:\")\n",
    "for i in range(10):\n",
    "    print(\"X[%d] -> %.4f (label: %.2f)\" % (i, predict(X[i], w).item(), Y[i].item()))"
   ],
   "id": "8d91ecd23e886747",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[6.61493096 0.0548485  0.73998444 0.64724206]]\n",
      "A few predictions:\n",
      "X[0] -> 74.9189 (label: 76.25)\n",
      "X[1] -> 76.0303 (label: 74.25)\n",
      "X[2] -> 78.6369 (label: 82.56)\n",
      "X[3] -> 80.5338 (label: 81.25)\n",
      "X[4] -> 68.4105 (label: 71.80)\n",
      "X[5] -> 76.7855 (label: 75.38)\n",
      "X[6] -> 78.3341 (label: 76.62)\n",
      "X[7] -> 69.2669 (label: 71.80)\n",
      "X[8] -> 77.5062 (label: 75.60)\n",
      "X[9] -> 76.4526 (label: 72.50)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T17:21:22.846909Z",
     "start_time": "2025-05-27T17:21:22.594081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x1 = X[:, 1]  # Pollution\n",
    "x2 = X[:, 2]  # Healthcare\n",
    "z = Y[:, 0]  # Life (flattened for plotting)\n",
    "\n",
    "# Plot the axes\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"figure.facecolor\": \"white\"})\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.set_xlabel(\"Pollution\", labelpad=15, fontsize=15)\n",
    "ax.set_ylabel(\"Healthcare\", labelpad=15, fontsize=15)\n",
    "ax.set_zlabel(\"Life Expectancy\", labelpad=10, fontsize=15)\n",
    "\n",
    "# Plot the data points\n",
    "ax.scatter3D(x1, x2, z, color='blue', label='Data Points')\n",
    "\n",
    "# Plot the regression plane\n",
    "MARGIN = 5\n",
    "edges_x1 = np.linspace(np.min(x1) - MARGIN, np.max(x1) + MARGIN, 2)\n",
    "edges_x2 = np.linspace(np.min(x2) - MARGIN, np.max(x2) + MARGIN, 2)\n",
    "xs1, xs2 = np.meshgrid(edges_x1, edges_x2)\n",
    "\n",
    "# Calculate zs using the model: z = w0 + w1*x2 + w2*x1\n",
    "zs = w[0] + w[1] * xs1 + w[2] * xs2 + w[3] * np.mean(X[:, 3])  # Keep 'Water' constant for 3D plot\n",
    "\n",
    "ax.plot_surface(xs1, xs2, zs, alpha=0.3, cmap=cm.viridis)\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "id": "87dd4ae19f3c1950",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
